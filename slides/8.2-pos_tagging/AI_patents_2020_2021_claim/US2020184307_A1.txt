<document>

<filing_date>
2018-12-11
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-11
</priority_date>

<ipc_classes>
G06N3/02
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
LIPKA, NEDIM
VEDULA, NIKHITA
</inventors>

<docdb_family_id>
70970229
</docdb_family_id>

<title>
UTILIZING RECURRENT NEURAL NETWORKS TO RECOGNIZE AND EXTRACT OPEN INTENT FROM TEXT INPUTS
</title>

<abstract>
The present disclosure relates to systems, non-transitory computer-readable media, and methods that utilize recurrent neural networks to determine the existence of one or more open intents in a text input, and then extract the one or more open intents from the text input. In particular, in one or more embodiments, the disclosed systems utilize a trained intent existence neural network to determine the existence of an actionable intent within a text input. In response to verifying the existence of an actionable intent, the disclosed systems can apply a trained intent extraction neural network to extract the actionable intent from the text input. Furthermore, in one or more embodiments, the disclosed systems can generate a digital response based on the intent identified from the text input.
</abstract>

<claims>
We claim:
1. A computer-implemented method of utilizing recurrent neural networks to determine open intent from conversational text comprising: a step for training an intent existence long short-term memory neural network and an intent extraction long short-term memory neural network; receiving, from a client computing device, a text input; a step for determining, via the intent existence long short-term memory neural network, that an intent exists in the text input; and a step for determining, via the intent extraction long short-term memory neural network, the intent from the text input.
2. The method as recited in claim 1, wherein the intent is an open intent that is unclassified relative to intent categories.
3. The method as recited in claim 1, further comprising: identifying intent existence training data comprising an intent existence training text and a plurality of intent existence training markers corresponding to the intent existence training text; and identifying intent extraction training data comprising an intent extraction training text and a plurality of intent extraction training markers corresponding to the intent extraction training text.
4. The method as recited in claim 3, wherein the intent existence training text comprises one or more positive text inputs comprising at least one intent and one or more negative text inputs comprising no intent.
5. The method as recited in claim 4, wherein each of the plurality of intent extraction training markers comprises a training verb and a training object.
6. A non-transitory computer-readable storage medium storing instructions thereon that, when executed by at least one processor, cause a system to: identify a text input via a client computing device; determine that an intent exists in the text input by: applying an intent existence long short-term memory neural network to the text input, wherein the intent existence long short-term memory neural network is trained to determine existence of training intents from intent existence training text and corresponding intent existence training markers; and in response to determining that the intent exists in the text input, determining the intent by extracting a verb object pair from the text input.
7. The non-transitory computer-readable storage medium as recited in claim 6, wherein applying the intent existence long short-term memory neural network to the text input comprises: embedding the text input into one or more neural network input vectors; and generating an intent existence prediction by analyzing the one or more neural network input vectors via a plurality of long short-term memory units of the intent existence long short-term memory neural network.
8. The non-transitory computer-readable storage medium as recited in claim 7, wherein: generating the intent prediction further comprises applying a max pooling layer to outputs of the plurality of long short-term memory units; and the plurality of long short-term memory units are organized bi-directionally in two layers.
9. The non-transitory computer-readable storage medium as recited in claim 6, wherein the intent is an open intent and the intent existence training text and corresponding intent existence training markers correspond to one or more open training intents.
10. The non-transitory computer-readable storage medium as recited in claim 6, further comprising instructions that, when executed by the at least one processor, cause the system to extract the verb object pair from the text input by: applying an intent extraction long short-term memory neural network to the text input, wherein the intent extraction long short-term memory neural network is trained to extract intent tags from intent extraction training text and corresponding intent extraction training markers.
11. The non-transitory computer-readable storage medium as recited in claim 10, wherein applying the intent extraction long short-term memory neural network to the text input comprises: embedding the text input into at least one neural network input vector; and generating at least one vector vector representation by analyzing the at least one neural network input vector via a plurality of long short-term memory units of the intent extraction long short-term memory neural network.
12. The non-transitory computer-readable storage medium as recited in claim 11, wherein applying the intent extraction long short-term memory neural network to the text input further comprises: applying a conditional random field layer to the at least one vector representation from the plurality of long short-term memory units of the intent extraction long short-term memory neural network to identify at least one intent tag; and determining the verb object pair based on the at least one intent tag.
13. The non-transitory computer-readable storage medium as recited in claim 6, further comprising, in response to extracting a verb object pair from the text input: querying a customer support database based on the verb object pair; generating a digital response to the text input based on the query results; and providing the generated digital response to the client computing device.
14. A system comprising: at least one processor; and at least one non-transitory computer-readable medium storing instructions that, when executed by the at least one processor, cause the system to: train an intent existence long short-term memory neural network to determine whether text comprises an intent by: applying the intent existence long short-term memory neural network to intent existence training text to generate a prediction of whether the intent existence training text comprises at least one training intent; comparing the prediction of whether the intent existence training text comprises the at least one training intent with an intent existence training marker to modify parameters of the intent existence long short-term memory neural network; train an intent extraction long short-term memory neural network to extract one or more intents from text input by: applying the intent extraction long short-term memory neural network to intent extraction training text comprising a training intent to generate an intent comprising a verb and an object; and comparing the intent comprising the verb and the object with an intent extraction training marker comprising a training verb and training object to modify parameters of the intent extraction long short-term memory neural network.
15. The system as recited in claim 14, wherein applying the intent existence long short-term memory neural network to intent existence training text to generate a prediction of whether the intent existence training text comprises at least one training intent comprises applying the intent existence long short-term memory neural network to: a plurality of positive text inputs comprising at least one training intent, and a plurality of negative text inputs comprising no training intent.
16. The system as recited in claim 15, wherein applying the intent extraction long short-term memory neural network to intent extraction training text comprises applying the intent extraction long short-term memory neural network to dependency parser training data.
17. The system as recited in claim 16, wherein the dependency parser training data comprises training sentences labeled for verbs and objects via a dependency parsing model from unlabeled sentences.
18. The system as recited in claim 17, wherein applying the intent extraction long short-term memory neural network to intent extraction training text further comprises applying the intent extraction long short-term memory neural network to user-labeled training data.
19. The system as recited in claim 18, wherein the intent existence training text and the intent extraction training text are not classified to an intent category.
20. The system as recited in claim 19, wherein: the intent existence long short-term memory neural network comprises a plurality of long short-term memory units organized bi-directionally in two layers and a soft max pooling layer; and the intent extraction long short-term memory neural network comprises a plurality of long short-term memory units organized bi-directionally in a single layer and a conditional random field layer.
</claims>
</document>
