<document>

<filing_date>
2018-04-05
</filing_date>

<publication_date>
2020-03-10
</publication_date>

<priority_date>
2017-04-06
</priority_date>

<ipc_classes>
G06K9/46,G06K9/62,G06N3/04,G06N3/08,G06T15/06,G06T5/00,G06T5/50,G06T7/00,G06T7/90
</ipc_classes>

<assignee>
DISNEY ENTERPRISES
PIXAR
DISNEY ENTERPRISES
</assignee>

<inventors>
MCWILLIAMS, BRIAN
ROUSSELLE, FABRICE
NOVAK, JAN
VOGELS, THIJS
MEYER, MARK
</inventors>

<docdb_family_id>
63711051
</docdb_family_id>

<title>
Denoising Monte Carlo renderings using generative adversarial neural networks
</title>

<abstract>
Supervised machine learning using neural networks is applied to denoising images rendered by MC path tracing. Specialization of neural networks may be achieved by using a modular design that allows reusing trained components in different networks and facilitates easy debugging and incremental building of complex structures. Specialization may also be achieved by using progressive neural networks. In some embodiments, training of a neural-network based denoiser may use importance sampling, where more challenging patches or patches including areas of particular interests within a training dataset are selected with higher probabilities than others. In some other embodiments, generative adversarial networks (GANs) may be used for training a machine-learning based denoiser as an alternative to using pre-defined loss functions.
</abstract>

<claims>
1. A method of denoising images rendered by Monte Carlo (MC) path tracing, the method comprising: receiving an input image rendered by MC path tracing and a corresponding reference image; configuring a generative adversarial network (GAN), the GAN comprising: a generator comprising a first neural network having a first set of parameters to be optimized, the generator configured to receive the input image and produce an output image corresponding to the input image using the first set of parameters; and a discriminator coupled to the generator, the discriminator comprising a second neural network having a second set of parameters to be optimized, the discriminator configured to: receive the input image, the reference image, and the output image produced by the generator; generate a quality metric based on a comparison of the output image or the reference image with the input image using the second set of parameters, the quality metric indicating a relative probability of the output image or the reference image belonging to a first class of denoised images as compared to a second class of ground truth images; and output the quality metric to the generator, wherein the generator is further configured to update the first set of parameters based on the quality metric and to produce an updated output image using the updated first set of parameters; training the GAN to obtain an optimized first set of parameters and an optimized second set of parameters, such that a statistical value of the quality metric generated by the discriminator approaches a predetermined value; receiving a new input image rendered by MC path tracing; and generating a denoised image corresponding to the new input image by passing the new input image through the generator using the optimized first set of parameters.
2. The method of claim 1, further comprising receiving one or more auxiliary buffers, wherein the generator is further configured to receive and use the one or more auxiliary buffers for producing the output image, and the discriminator is further configured to receive and use the one or more auxiliary buffers for generating the quality metric.
3. The method of claim 2, wherein the one or more auxiliary buffers include one or more of surface normal information, albedo information, or depth information.
4. The method of claim 1, wherein the quality metric has a numerical value ranging from zero to one, the statistical value of the quality metric is a mean value, and the predetermined value of the quality metric is about 0.5.
5. The method of claim 1, wherein the quality metric has a numerical value that is any real number.
6. The method of claim 1, wherein training the GAN comprises training the generator and the discriminator jointly and in turn by: training the generator to obtain an intermediate first set of parameters while the second set of parameters of the discriminator is fixed; training the discriminator to obtain an intermediate second set of parameters while the intermediate first set of parameters is fixed; and repeating training the generator and the discriminator in turn to obtain the optimized first set of parameters and the optimized second set of parameters.
7. The method of claim 6, wherein in each turn, the first set of parameters of the generator is updated for a first number of times, and the second set of parameters of the discriminator is updated for a second number of times.
8. The method of claim 7, wherein the first number of times is different from the second number of times.
9. The method of claim 1, wherein training the GAN further comprises: pre-training the generator to obtain an intermediate first set of parameters; pre-training the discriminator to obtain an intermediate second set of parameters; and after the generator and the discriminator are pre-trained individually, training the generator and the discriminator jointly and in turn to obtain the optimized first set of parameters and the optimized second set of parameters.
10. The method of claim 1, wherein training the GAN comprises training the generator and the discriminator jointly and simultaneously to obtain the optimized first set of parameters and the optimized second set of parameters.
11. The method of claim 1, wherein the input image is rendered by path tracing with a first number of rays per pixel, the reference image is rendered by path tracing with a second number of rays per pixel greater than the first number of rays.
12. The method of claim 11, wherein the reference image is rendered by path tracing and subsequently denoised using a denoiser.
13. The method of claim 1, wherein each of the first neural network and the second neural network comprises a convolutional neural network.
14. The method of claim 1, wherein each of the first neural network and the second neural network comprises a multilayer perceptron neural network.
15. A computer product comprising a non-transitory computer readable medium storing a plurality of instructions that when executed control a computer system to denoise images rendered by Monte Carlo (MC) path tracing, the instructions comprising: receiving an input image rendered by MC path tracing and a corresponding reference image; configuring a generative adversarial network (GAN), the GAN comprising: a generator comprising a first neural network having a first set of parameters to be optimized, the generator configured to receive the input image and produce an output image corresponding to the input image using the first set of parameters; and a discriminator coupled to the generator, the discriminator comprising a second neural network having a second set of parameters to be optimized, the discriminator configured to: receive the input image, the reference image, and the output image produced by the generator; generate a quality metric based on a comparison of the output image or the reference image with the input image using the second set of parameters, the quality metric indicating a relative probability of the output image or the reference image belonging to a first class of denoised images as compared to a second class of ground truth images; and output the quality metric to the generator, wherein the generator is further configured to update the first set of parameters based on the quality metric and to produce an updated output image using the updated first set of parameters; training the GAN to obtain an optimized first set of parameters and an optimized second set of parameters, such that a statistical value of the quality metric generated by the discriminator approaches a predetermined value; receiving a new input image rendered by MC path tracing; and generating a denoised image corresponding to the new input image by passing the new input image through the generator using the optimized first set of parameters.
16. The computer product of claim 15, wherein the instructions further comprising: further comprising receiving one or more auxiliary buffers, wherein the generator is further configured to receive and use the one or more auxiliary buffers for producing the output image, and the discriminator is further configured to receive and use the one or more auxiliary buffers for generating the quality metric.
17. The computer product of claim 15, wherein the quality metric has a numerical value ranging from zero to one, the statistical value of the quality metric is a mean value, and the predetermined value of the quality metric is about 0.5.
18. The computer product of claim 15, wherein training the GAN comprises training the generator and the discriminator jointly and in turn by: training the generator to obtain an intermediate first set of parameters while the second set of parameters of the discriminator is fixed; training the discriminator to obtain an intermediate second set of parameters while the intermediate first set of parameters is fixed; and repeating training the generator and the discriminator in turn to obtain the optimized first set of parameters and the optimized second set of parameters.
19. The computer product of claim 15, wherein training the GAN further comprises: pre-training the generator to obtain an intermediate first set of parameters; pre-training the discriminator to obtain an intermediate second set of parameters; and after the generator and the discriminator are pre-trained individually, training the generator and the discriminator jointly and in turn to obtain the optimized first set of parameters and the optimized second set of parameters.
20. The computer product of claim 15, wherein training the GAN comprises training the generator and the discriminator jointly and simultaneously to obtain the optimized first set of parameters and the optimized second set of parameters.
</claims>
</document>
