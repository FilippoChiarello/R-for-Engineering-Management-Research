<document>

<filing_date>
2018-06-07
</filing_date>

<publication_date>
2020-08-04
</publication_date>

<priority_date>
2018-06-07
</priority_date>

<ipc_classes>
G08G1/01,G08G1/09
</ipc_classes>

<assignee>
COMPLETE INNOVATIONS
</assignee>

<inventors>
CHATZINIKOLIS, PANTELIS
ZHOU, WEI
LOURAKIS, TONY
SAMJI, MUHAMAD
LAN, VICTOR
CHO, JIHYUN
FONG, ALAN
</inventors>

<docdb_family_id>
68765290
</docdb_family_id>

<title>
Multi-vehicle prediction system
</title>

<abstract>
A method of operating an incident avoidance system for use in a vehicle comprises a gateway receiving a plurality of vehicular data samples from a plurality of data sources in a vicinity of a target vehicle. A stream processor coupled to the gateway, categorizes a first plurality of low latency data samples from the plurality of vehicular data samples based on an allowable latency of each of the plurality of vehicular data samples. A rules engine coupled to the stream processor, receives the plurality of low latency data samples. The rules engine produces a predictive model based on the plurality of low latency data samples. A notification service accesses the predictive model and situational data of the target vehicle to predict an incident. The notification service transmits a notification of the incident to the target vehicle.
</abstract>

<claims>
1. A method of operating an incident avoidance system for use in a vehicle, the method comprising: receiving, by a gateway, a plurality of vehicular data samples from a plurality of data sources in a vicinity of a target vehicle; categorizing, by a stream processor coupled to the gateway, a plurality of low latency data samples from the plurality of vehicular data samples based on an allowable latency of each of the plurality of vehicular data samples; receiving, by a rules engine coupled to the stream processor, the plurality of low latency data samples, the rules engine deriving a predictive model based on the plurality of low latency data samples; accessing, by a notification service, the predictive model and situational data of the target vehicle to predict an incident; transmitting, by the notification service, a notification of the incident to the target vehicle and: categorizing, by the stream processor, a plurality of high latency data samples from the plurality of vehicular data samples based on a predefined latency of each of the plurality of vehicular data samples; storing, by the stream processor, the plurality of high latency data samples in a data lake; and processing, by a batch processor, the plurality of high latency data samples.
2. The method of claim 1 further comprising: converting, by the gateway, each of the plurality of vehicular data samples into a common internal format.
3. The method of claim 2 further comprising storing a copy of each of the plurality of vehicular data samples in the common internal format.
4. The method of claim 1 wherein a subsequent low latency data sample received by the rules engine is used to update the predictive model.
5. The method of claim 1, wherein the predictive model is also derived based on the plurality of high latency data samples.
6. The method of claim 5, wherein the predictive model is a machine learning model trained in part, on the plurality of high-latency data samples stored in the data lake.
7. The method of claim 1 wherein the predictive model comprises an offline model and an online model.
8. An incident avoidance system comprising: a gateway coupled to a plurality of data sources in a vicinity of a target vehicle over a network, the gateway configured to receive a plurality of vehicular data samples from the plurality of data sources; a stream processor coupled to the gateway, the stream processor categorizing a plurality of low latency data samples from the plurality of vehicular data samples based on an allowable latency of each of the plurality of vehicular data samples; a rules engine coupled to the stream processor, the rules engine receiving the plurality of low latency data samples, the rules engine deriving a predictive model based on the plurality of low latency data samples; and a notification service coupled to the rules engine, the notification service accessing the predictive model and situational data of the target vehicle to predict an incident, the notification service configured to transmit a notification of the incident to the target vehicle; and the stream processor further categorizes a plurality of high latency data samples from the plurality of vehicular data samples based on a predefined latency of each of the plurality of vehicular data samples, the system further comprising a data lake and a batch processor, the stream processor storing the plurality of high latency data samples in the data lake, the batch processor processing the plurality of high latency data samples.
9. The system of claim 8 further wherein the gateway converts each of the plurality of vehicular data samples into a common internal format.
10. The system of claim 9 wherein a copy of each of the plurality of vehicular data samples is stored in the common internal format.
11. The system of claim 8 wherein a subsequent low latency data sample received by the rules engine is used to update the predictive model.
12. The system of claim 8, wherein the predictive model is also derived based on the plurality of high latency data samples.
13. The system of claim 12, wherein the predictive model is a machine learning model trained in part, on the plurality of high-latency data samples stored in the data lake.
14. The system of claim 8 wherein the predictive model comprises an offline model and an online model.
</claims>
</document>
