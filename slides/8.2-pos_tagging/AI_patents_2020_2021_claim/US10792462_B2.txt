<document>

<filing_date>
2017-06-05
</filing_date>

<publication_date>
2020-10-06
</publication_date>

<priority_date>
2017-06-05
</priority_date>

<ipc_classes>
A61M21/00,A61M21/02,G06N20/00,G06N99/00,H04R5/04,H04S1/00,H04S7/00
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
PICKOVER CLIFFORD A.
GORDON, MICHAEL, S.
KOZLOSKI, JAMES R.
KUNDU, ASHISH
</inventors>

<docdb_family_id>
64458504
</docdb_family_id>

<title>
Context-sensitive soundscape generation
</title>

<abstract>
A context-sensitive soundscape is generated by receiving a first identifier for identifying a target cognitive state for a user, and a second identifier for identifying a user cohort for the user. A present context is determined for the user. A machine-learning procedure is performed to map the target cognitive state to a set of audio output characteristics based upon the identified user cohort and the determined present context. An audio output is generated to create the context-sensitive soundscape that includes the set of audio output characteristics.
</abstract>

<claims>
1. A computer-implemented method, comprising: receiving, by one or more processors, a user target cognitive state indicia identifying a target cognitive state of a user, and receiving a user cohort indicia identifying other persons having one or more common conditions or indicia in common with said user; determining, by the one or more processors, a present user context, in response to said receiving a user target cognitive state indicia and the user cohort indicia; performing a machine-learning procedure, by the one or more processors, to map the target cognitive state to a set of audio output characteristics based upon one or more parameters of the identified other persons from the received user cohort indicia and the present user context, said parameters comprising parameters obtained from an identified social media network associated with the user; and generating a context-sensitive soundscape with the set of audio output characteristics, based on the user target cognitive state indicia.
2. The computer-implemented method of claim 1 wherein the target cognitive state is selected from a group consisting of: relaxation, stimulation, falling asleep, and focusing on a task.
3. The computer-implemented method of claim 1 wherein the one or more common conditions of a user cohort indicia is selected from a group consisting of: demographic indicia, occupational indicia, medical or psychological indicia, cultural indicia, verbal language indicia, written language indicia, and medical history indicia.
4. The computer-implemented method of claim 1, wherein the set of audio output characteristics is selected from a group consisting of: music, environmental sounds, pink noise, white noise, another spectrally-shaped noise, ambient sounds of individuals engaging in an activity, and animal sounds.
5. The computer-implemented method of claim 1, wherein the performing of the machine-learning procedure is based on an assessment of user-related data.
6. The computer-implemented method of claim 1, further comprising collecting feedback and determining a level of effectiveness of the generated audio output characteristics for facilitating the target cognitive state, based on the collecting of the feedback.
7. The computer-implemented method of claim 1, further comprising using a multi-dimensional array configured for associating each of a respective plurality of cognitive states, including the target cognitive state, with at least one corresponding user cohort, at least one corresponding user medical or psychological condition, at least one corresponding user demographic, at least one corresponding task, or at least one context.
8. The computer-implemented method of claim 7, further comprising accessing the multi-dimensional array according to at least one learned useful value for an individual or a cohort.
9. The computer-implemented method of claim 1, wherein the set of audio output characteristics comprises a binaural beat comprising a first tone and a second tone, and the method further comprises feeding the first tone to a right-side element of a set of headphones, and feeding the second tone to a left-side element of the set of headphones, such that the first tone is fed to the right-side element for presentation to a right ear of the user, and the second tone is fed to the left-side element for presentation to a left ear of the user.
10. The computer-implemented method of claim 1, wherein the machine-learning procedure further comprises learning one or more SPLs; and modulating the one or more SPLs to enhance a noise masking.
11. The computer-implemented method of claim 1, wherein the machine-learning procedure further comprises modulating ambient noise.
12. A computer program product, the computer program product comprising a non-transitory computer-readable storage medium having a computer-readable program stored therein, wherein the computer-readable program, when executed on a computer including at least one processor, causes the at least one processor to: receive a user target cognitive state indicia identifying a target cognitive state of a user, and receiving a user cohort indicia identifying other persons having one or more common conditions or indicia in common with said user; determine a present user context, in response to said receiving a user target cognitive state indicia and the user cohort indicia in common with said user; perform a machine-learning procedure, by the at least one processor, to map the target cognitive state to a set of audio output characteristics based upon one or more parameters of the identified other persons from the received user cohort indicia and the present user context, said parameters comprising parameters obtained from an identified social media network associated with the user; and generate a context-sensitive soundscape with the set of audio output characteristics, based on the user target cognitive state indicia.
13. The computer program product of claim 12 wherein the target cognitive state is selected from a group consisting of: relaxation, stimulation, falling asleep, and focusing on a task.
14. The computer program product of claim 12 wherein the one or more common conditions of a user cohort indicia that is selected from a group consisting of: demographic indicia, occupational indicia, medical or psychological indicia, cultural indicia, verbal language indicia, written language indicia, and medical history indicia.
15. The computer program product of claim 12, wherein the set of audio output characteristics is selected from a group consisting of: music, environmental sounds, pink noise, white noise, another spectrally-shaped noise, ambient sounds of individuals engaging in an activity, and animal sounds.
16. The computer program product of claim 12, wherein the computer-readable program, when executed on the computer, causes the at least one processor to perform: the machine-learning procedure based on an assessment of user-related data.
17. The computer program product of claim 12, wherein the computer-readable program, when executed on the computer, causes the at least one processor to perform: collecting feedback and determining a level of effectiveness of the generated audio output characteristics for facilitating the target cognitive state, based on the collecting of the feedback.
18. The computer program product of claim 12, wherein the computer-readable program, when executed on the computer, causes the at least one processor to perform: using a multi-dimensional array configured for associating each of a respective plurality of cognitive states, including the target cognitive state, with at least one corresponding user cohort, at least one corresponding user medical or psychological condition, at least one corresponding user demographic, at least one corresponding task, or at least one context.
19. A system for generating a context-sensitive soundscape, the system comprising a computer including at least one processor and a memory coupled to the at least one processor, wherein the memory comprises instructions which, when executed by the at least one processor, cause the at least one processor to: receive a user target cognitive state indicia identifying a target cognitive state of a user, and receiving a user cohort indicia identifying other persons having one or more common conditions or indicia in common with said user; determine a present user context, in response to said receiving a user target cognitive state indicia and the user cohort indicia in common with said user; perform a machine-learning procedure, by the at least one processor, to map the target cognitive state to a set of audio output characteristics based upon one or more parameters of the identified other persons from the received user cohort indicia and the present user context, said parameters comprising parameters obtained from an identified social media network associated with the user; and generate a context-sensitive soundscape with the set of audio output characteristics, based on the user target cognitive state indicia.
20. The system of claim 19 wherein the target cognitive state is selected from a group consisting of: relaxation, stimulation, falling asleep, and focusing on a task.
</claims>
</document>
