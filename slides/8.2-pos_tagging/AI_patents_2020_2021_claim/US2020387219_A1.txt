<document>

<filing_date>
2020-02-04
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-07
</priority_date>

<ipc_classes>
G06F3/00,G06F3/01,G06K9/00,G06K9/32,H04L12/26,H04L29/08,H04N5/232
</ipc_classes>

<assignee>
EYETECH DIGITAL SYSTEMS
</assignee>

<inventors>
CHAPPELL, ROBERT C.
Hinton, Caleb R.
Holford, Michael S
Whitehead, William B.
</inventors>

<docdb_family_id>
73651502
</docdb_family_id>

<title>
Devices And Methods For Reducing Computational And Transmission Latencies In Cloud Based Eye Tracking Systems
</title>

<abstract>
Systems and methods for cloud-based eye tracking with reduced computing and network overhead are provided. Computational latency is reduced by isolating an eye region within a facial image and transmitting it to the remote server for further image processing. Transmission latency is reduced by identifying available servers on the network, assigning transmission latency values to each server based on various attributes, and proactively selecting the server having the lowest transmission latency.
</abstract>

<claims>
1. An eye tracking system, comprising: a client computer including a display panel, a native processor, an eye tracking assembly, and a network interface module; wherein the eye tracking assembly includes an image sensor, a lens, and an illuminator; and wherein the native processor is configured to: operate the image sensor to record first and second facial image data frames; establish a network connection, using the network interface module, between the client computer and a remote image processor; transmit the first facial image data frame to the remote image processor receive, from the remote image processor, a first eye region data set derived from the first facial image data frame; derive a second eye region data set from the second facial image data frame using information obtained from the first eye region data set; and transmit the second eye region data set to the remote image processor.
2. The eye tracking system of claim 1, wherein the native processor is configured to discard that portion of the second facial image data frame which is not included in the second eye region data set.
3. The eye tracking system of claim 1, wherein transmitting the second eye region data set comprises transmitting only data that is within the second eye region data set, and not transmitting the portion of the second facial image data frame which is not included in the second eye region data set.
4. The eye tracking system of claim 1, wherein the native processor is further configured to: record successive facial image data frames on the image sensor; recursively isolate respective eye region data sets for each successive facial image data frame based on information received from the remote image processor; and transmit successive eye region data sets to the remote image processor.
5. The eye tracking system of claim 4, wherein the native processor is further configured to: receive, from the remote image processor, eye location information corresponding to at least one successive facial image data frame transmitted to the remote image processor; and predict the eye location for a future facial image data frame based on eye location information received from the remote image processor for a previous facial image data frame.
6. The eye tracking system of claim 5, wherein the native processor is configured to position the image sensor in accordance with eye location information for a previous facial image data frame.
7. The eye tracking system of claim 6, wherein the native processor is configured to adjust the position of the image sensor in accordance with the predicted eye location.
8. The eye tracking system of claim 6, wherein the native processor is configured to algorithmically predict future eye locations using a polynomial expression incorporating eye location information from previous facial image data frames.
9. The eye tracking system of claim 8, wherein the native processor is further configured to: receive an indication from the remote image processor that eye location information cannot be derived from a corresponding eye region data set for at least one successive facial image data frame; in response to the indication, suppress discarding for a series of data frames; transmit the entire facial image data frame for the series of data frames to the remote image processor; and thereafter recalibrate an eye region data set for a subsequent facial image data frame after receiving eye location information from the remote image processor corresponding to the series of data frames.
10. The eye tracking system of claim 1, wherein the native processor is further configured to establish the network connection with a selected one of a plurality of available remote image processors based on respective latency values associated with the plurality of remote image processors.
11. The eye tracking system of claim 10, wherein the native processor is further configured to determine the respective latency values for the plurality of remote image processors using an initialization algorithm.
12. The eye tracking system of claim 11, wherein the initialization algorithm, upon execution by the native processor, causes the system to: perform a network scan to identify said plurality of available image processors; determine respective geo-coordinates for at least two of the available image processors; compute a respective distance between the client computer and each of the at least two image processor using their respective geo-coordinates; and assign a geo-latency value to each of the at least two available remote image processors based on its distance from the client computer; and establish the network connection with a selected one of the available image processors based on the geo-latency values.
13. The eye tracking system of claim 12, wherein the initialization algorithm causes the system to: elicit respective ping trace values for each available image processor; and establish the network connection with a selected one of the available image processors based on the geo-latency values and the ping trace values.
14. The eye tracking system of claim 13, wherein the initialization algorithm causes the system to: identify a respective application programming interface (API) protocol for each available image processor; transmit an initialization data frame to each available image processor using its API protocol; measure each available image processor's response to the initialization data frame; assign a payload trace value to each available image processor based its measured response; and establish the network connection with a selected one of the available image processors based on the geo-latency values, the ping trace values, and the payload trace values.
15. The eye tracking system of claim 14, wherein the initialization algorithm further causes the system to populate a resource array with indicia of the following attributes for at least one of the available image processors: hosting entity; upload speed; geo-latency values; accelerated hardware chip configuration; ping tracer value; available access ports; and payload tracer value.
16. The eye tracking system of claim 15, wherein the initialization algorithm causes the system to establish the network connection with a selected one of the available image processors based on said attributes.
17. A method of reducing computational and transmission latencies for an eye tracking camera coupled to a client computer, the computer configured to interact with a cloud based server through a network connection, the method comprising the steps of: mitigating computational latency by: capturing sequential data frames of facial images at the client computer; sending a subset of each data frame to the server for image processing; receiving eye region and eye location information from the server for each data frame; and determining a subset of a current data frame based on eye region information for a previous data frame; and mitigating transmission latency by establishing the network connection with a selected one of a plurality of available servers based on their respective transmission latency values.
18. The method of claim 17, wherein reducing transmission latency further comprises: determining respective distance values between the client computer and each of the plurality of available servers; assigning geo-latency values to each server based on its distance value; and establishing the network connection with the selected server based on the geo-latency values.
19. The method of claim 18, wherein reducing transmission latency further comprises: determining at least one of a ping trace value and a payload trace value for each of the plurality of available servers; and establishing the network connection with the selected server based on the geo-latency values, the ping trace values, and the payload trace values.
20. An eye tracking computer, comprising: a display panel; a native processor; a network connection module; and a camera having an image sensor; wherein the native processor is configured to: transmit sequential data frames to a remote image processor, where each data frame comprises at least a portion of a facial image; receive eye region information from the remote image processor for each of the sequential data frames; define a region of each facial image which includes the eyes based on eye region information from a previous facial image; identify, for each of a plurality of remote image processors, at least one of a geo-latency value, a ping trace value, and a payload trace value; and establish a connection between the network connection module and a selected one of the remote image processors based on at least one of the geo-latency, a ping trace, and a payload trace values.
</claims>
</document>
