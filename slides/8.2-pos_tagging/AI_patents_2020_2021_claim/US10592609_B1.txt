<document>

<filing_date>
2019-04-26
</filing_date>

<publication_date>
2020-03-17
</publication_date>

<priority_date>
2019-04-26
</priority_date>

<assignee>
TUCKNOLOGIES HOLDINGS
</assignee>

<inventors>
NOVAK, BRYAN
TUCKER, CRAIG
</inventors>

<docdb_family_id>
69778838
</docdb_family_id>

<title>
Human emotion detection
</title>

<abstract>
Disclosed herein are system, method, and computer program product embodiments for recognizing a human emotion in a message. An embodiment operates by receiving a message from a user. The embodiment labels each word of the message with a part of speech (POS) thereby creating a POS set. The embodiment creates a bag of words (BOW) for the message. The embodiment determines an incongruity score for a combination of words in the POS set using a knowledgebase. The embodiment determines a preliminary emotion detection score for an emotion for the message based on the POS set and the BOW. Finally, the embodiment calculates a final emotion detection score for the emotion for the message based on the preliminary emotion detection score and the incongruity score.
</abstract>

<claims>
1. A computer implemented method for detecting an emotion in a message, comprising: receiving, by at least one processor, the message; labeling, by the at least one processor, each word of the message with a part of speech (POS) thereby creating a POS set; determining, by the at least one processor, an incongruity score for a combination of words in the POS set based on a collocation variable, a correlation variable, and a frequency variable for the combination of words in the POS set; determining, by the at least one processor, a preliminary emotion detection score for an emotion for the message based on the POS set; and calculating, by the at least one processor, a final emotion detection score for the emotion for the message based on the preliminary emotion detection score and the incongruity score.
2. The method of claim 1, wherein the message comprises text data, visual data, or audio data.
3. The method of claim 1, wherein the determining the incongruity score for the combination of words in the POS set comprises: calculating the collocation variable for the combination of words in the POS set based on a knowledgebase; calculating the correlation variable for the combination of words in the POS set based on the knowledgebase; and calculating the frequency variable for the combination of words in the POS set based on the knowledgebase.
4. The method of claim 1, wherein the determining the preliminary emotion detection score for the emotion for the message comprises: determining a contextual clue score based on the POS set; determining a frame of reference score based on characteristics associated with a sender of the message; determining a personal frame of reference score based on characteristics associated with a receiver of the message; and determining a preliminary emotion detection score for humor based on the contextual clue score, the frame of reference score, and the personal frame of reference score.
5. The method of claim 1, further comprising: outputting the final emotion detection score for the emotion for the message to a client device based on the final emotion detection score for the message being above a detection threshold value.
6. The method of claim 1, further comprising: determining a second preliminary emotion detection score for a second emotion for the message based on the POS set; and determining a second final emotion detection score for a third emotion for the message based on the preliminary emotion detection score, the second preliminary emotion score, and the incongruity score.
7. The method of claim 1, further comprising: training the at least one processor configured to determine the preliminary emotion detection score for the emotion for the message based on the final emotion detection score for the emotion for the message being above a machine learning threshold value.
8. A system, comprising: a memory; a sensor configured to receive a message; and at least one processor coupled to the memory and configured to: convert the message to text; label each word of the message with a part of speech (POS) thereby creating a POS set; create a bag of words (BOW) for the message; determine an incongruity score for a combination of words in the POS set based on a collocation variable, a correlation variable, and a frequency variable for the combination of words in the POS set; determine a preliminary emotion detection score for an emotion for the message based on the POS set and the BOW; and calculate a final emotion detection score for the emotion for the message based on the preliminary emotion detection score and the incongruity score.
9. The system of claim 8, wherein the message comprises text data, visual data, or audio data.
10. The system of claim 8, wherein to determine the incongruity score for the combination of words in the POS set, the at least one processor is configured to: calculate the collocation variable for the combination of words in the POS set based on a knowledgebase; calculate the correlation variable for the combination of words in the POS set based on the knowledgebase; and calculate the frequency variable for the combination of words in the POS set based on the knowledgebase.
11. The system of claim 8, wherein to determine the preliminary emotion detection score for the emotion for the message, the at least one processor is configured to: determine a contextual clue score based on the POS set and the BOW; determine a frame of reference score based on characteristics associated with a sender of the message; determine a personal frame of reference score based on characteristics associated with a receiver of the message; and determine a preliminary emotion detection score for humor based on the contextual clue score, the frame of reference score, and the personal frame of reference score.
12. The system of claim 8, the at least one processor further configured to: output the final emotion detection score for the emotion for the message to a client device based on the final emotion detection score for the message being above a detection threshold value.
13. The system of claim 8, the at least one processor further configured to: determine a second preliminary emotion detection score for a second emotion for the message based on the POS set and the BOW; and determine a second final emotion detection score for a third emotion for the message based on the preliminary emotion detection score, the second preliminary emotion score, and the incongruity score.
14. The system of claim 8, the at least one processor further configured to: train the at least one processor configured to determine the preliminary emotion detection score for the emotion for the message based on the final emotion detection score for the emotion for the message being above a machine learning threshold value.
15. A non-transitory computer-readable device having instructions stored thereon that, when executed by at least one computing device, causes the at least one computing device to perform operations comprising: receiving a message; labeling each word of the message with a part of speech (POS) thereby creating a POS set; creating a bag of words (BOW) for the message; determining an incongruity score for a combination of words in the POS set based on a collocation variable, a correlation variable, and a frequency variable for the combination of words in the POS set; determining a preliminary emotion detection score for an emotion for the message based on the POS set and the BOW; and calculating a final emotion detection score for the emotion for the message based on the preliminary emotion detection score and the incongruity score.
16. The non-transitory computer-readable device of claim 15, the determining the incongruity score for the combination of words in the POS set comprising: calculating the collocation variable for the combination of words in the POS set based on a knowledgebase; calculating the correlation variable for the combination of words in the POS set based on the knowledgebase; and calculating the frequency variable for the combination of words in the POS set based on the knowledgebase.
17. The non-transitory computer-readable device of claim 15, the determining the preliminary emotion detection score for the emotion for the message comprising: determining a contextual clue score based on the POS set and the BOW; determining a frame of reference score based on characteristics associated with a sender of the message; determining a personal frame of reference score based on characteristics associated with a receiver of the message; and determining a preliminary emotion detection score for humor based on the contextual clue score, the frame of reference score, and the personal frame of reference score.
18. The non-transitory computer-readable device of claim 15, the operations further comprising: outputting the final emotion detection score for the emotion for the message to a client device based on the final emotion detection score for the message being above a detection threshold value.
19. The non-transitory computer-readable device of claim 15, the operations further comprising: determining a second preliminary emotion detection score for a second emotion for the message based on the POS set and the BOW.
20. The non-transitory computer-readable device of claim 19, the operations further comprising: determining a second final emotion detection score for a third emotion for the message based on the preliminary emotion detection score, the second preliminary emotion score, and the incongruity score.
</claims>
</document>
