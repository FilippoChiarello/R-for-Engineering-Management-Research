<document>

<filing_date>
2015-08-05
</filing_date>

<publication_date>
2020-08-11
</publication_date>

<priority_date>
2014-10-23
</priority_date>

<ipc_classes>
A61B8/00,A61B8/08,A61B8/14,G06K9/62,G06T11/60,G06T3/00,G06T7/00,G06T7/30
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
BANG, WON CHUL
KIM, SUNKWON
RYU, JIWON
CHANG, JUNGWOO
</inventors>

<docdb_family_id>
55791021
</docdb_family_id>

<title>
Ultrasound imaging apparatus and method of controlling the same
</title>

<abstract>
An ultrasound imaging apparatus includes an image generator configured to scan an object to obtain an ultrasound image; a neural network configured to generate a virtual ultrasound image based on matching medical images of different modalities; an image converting part configured to convert a medical image of a different modality, previously obtained by scanning the object, into the virtual ultrasound image by using the neural network; and a matching part configured to determine a position of a virtual probe based on the ultrasound image and the virtual ultrasound image, and configured to match the ultrasound image with the medical image that corresponds to the determined position of the virtual probe.
</abstract>

<claims>
1. An ultrasound imaging apparatus comprising: an image generator, implemented by at least one processor, configured to scan an object to obtain an ultrasound image; a matching part, implemented by the at least one processor, configured to set a position of a virtual probe for a medical image, wherein the medical image is obtained from a medical apparatus having a modality different from that of the ultrasound imaging apparatus; and an image converting part, implemented by the at least one processor, configured to convert the medical image into a virtual ultrasound image, based on the position of the virtual probe that is set for the medical image, using a neural network that is previously trained, wherein the neural network uses a plurality of ultrasound images and a plurality of medical images which are matched to each other to learn a correlation between the plurality of ultrasound images and the plurality of medical images, and is trained to output a correlated ultrasound image when the medical image is input as an input data, wherein the matching part is configured to match the ultrasound image with the medical image that corresponds to the position of the virtual probe and to reset the position of the virtual probe based on an error between the ultrasound image and the virtual ultrasound image.
2. The ultrasound imaging apparatus according to claim 1, wherein the image converting part is configured to generate the virtual ultrasound image based on the position of the virtual probe.
3. The ultrasound imaging apparatus according to claim 2, wherein the image converting part is configured to select a first region from the medical image based on the position of the virtual probe, to input the selected first region into the neural network, and to obtain an image of a second region of the virtual ultrasound image.
4. The ultrasound imaging apparatus according to claim 3, wherein the first region has a length determined based on a range of ultrasound transmission in the object.
5. The ultrasound imaging apparatus according to claim 3, wherein the first region has a width determined based on a resolution of the ultrasound image.
6. The ultrasound imaging apparatus according to claim 1, further comprising: a learning part, implemented by the at least one processor, configured to train the neural network using the ultrasound image and the medical image that are matched with each other by the matching part.
7. The ultrasound imaging apparatus according to claim 6, wherein the learning part is configured to train the neural network such that the ultrasound image matched with the medical image is output as the virtual ultrasound image in response to an input of the medical image.
8. The ultrasound imaging apparatus according to claim 1, wherein the medical image includes at least one of a magnetic resonance (MR) image, a computed tomography (CT) image, a positron emission tomography (PET) image, and a single photon emission computed tomography (SPECT) image.
9. The ultrasound imaging apparatus according to claim 1, wherein the neural network has a multilayer perceptron structure.
10. The ultrasound imaging apparatus according to claim 1, further comprising: a display configured to display the medical image that is matched with the ultrasound image together with the ultrasound image.
11. A method of controlling an ultrasound imaging apparatus, the method comprising: scanning an object to obtain an ultrasound image; setting a position of a virtual probe for a medical image, wherein the medical image is obtained from a medical apparatus having a modality different from that of the ultrasound imaging apparatus; generating a virtual ultrasound image by converting the medical image into the virtual ultrasound image, based on the position of the virtual probe that is set for the medical image, using a neural network that is previously trained, wherein the neural network uses a plurality of ultrasound images and a plurality of medical images which are matched to each other to learn a correlation between the plurality of ultrasound images and the plurality of medical images, and is trained to output a correlated ultrasound image when the medical image is input as an input data; matching the ultrasound image with the medical image that corresponds to the position of the virtual probe; and resetting the position of the virtual probe based on an error between the ultrasound image and the virtual ultrasound image.
12. The method according to claim 11, wherein the converting comprises converting the medical image into the virtual ultrasound image based on the position of the virtual probe.
13. The method according to claim 11, wherein the generating comprises generating a second virtual ultrasound image by applying the neural network to the medical image based on the reset position of the virtual probe.
14. The method according to claim 13, wherein the matching comprises matching the medical image and the ultrasound image based on the reset position of the virtual probe in response to the error between the ultrasound image and the second virtual ultrasound image being equal to or less than a reference value.
15. The method according to claim 13, wherein the converting comprises: selecting a first region from the medical image based on the position of the virtual probe; and inputting the selected first region into the neural network to obtain an image of a second region of the virtual ultrasound image.
16. The method according to claim 15, wherein the first region has a length determined based on a range of ultrasound transmission in the object, and a width determined based on a resolution of the ultrasound image.
17. The method according to claim 11, further comprising: training the neural network using the medical image and the ultrasound image that are matched with each other.
18. The method according to claim 11, wherein the medical image comprises at least one of a magnetic resonance (MR) image, a computed tomography (CT) image, a positron emission tomography (PET) image, and a single photon emission computed tomography (SPECT) image.
</claims>
</document>
