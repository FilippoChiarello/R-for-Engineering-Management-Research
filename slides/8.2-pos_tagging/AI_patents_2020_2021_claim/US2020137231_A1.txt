<document>

<filing_date>
2018-10-26
</filing_date>

<publication_date>
2020-04-30
</publication_date>

<priority_date>
2018-10-26
</priority_date>

<ipc_classes>
H04M3/51,H04M3/523
</ipc_classes>

<assignee>
CISCO TECHNOLOGY
</assignee>

<inventors>
MS, MANIGANDAN
REVANUR, AMBAREESH
VENKATA, SATEESH KUMAR POTTURU NAGA
</inventors>

<docdb_family_id>
70325920
</docdb_family_id>

<title>
CONTACT CENTER INTERACTION ROUTING USING MACHINE LEARNING
</title>

<abstract>
A computer system routes contact center interactions. Interactions between contact center agents and contact center queries that are received at a contact center are monitored. A ranking model is trained according to the categories of the contact center queries and the interaction scores of each handled query using machine learning. The ranking model is tested according to various metrics to ensure that the ranking model ranks the agents according to one or more selected business outcomes. A net score may be determined for each contact center agent for each query category based on a predicted interaction score and one or more non-interaction features. Incoming queries may then be routed to an appropriate contact center agent based on the category of the incoming query. Embodiments may further include a method and program product for routing contact center interactions in substantially the same manner described above.
</abstract>

<claims>
1. A computer-implemented method comprising: at a contact center control server associated with a contact center that includes a plurality of agent terminals at which contact center agents serve contact center queries: monitoring over time interactions between contact center agents and contact center queries received at the contact center; training a ranking model according to one or more contact center query categories and corresponding interaction scores of each contact center query, wherein an interaction score corresponds to a resolution of a contact center interaction, and wherein the ranking model utilizes machine learning to score each contact center agent for a given contact center query; testing the ranking model using one or more test metrics to determine that the ranking model ranks the plurality of agents according to one or more selected business outcomes; determining a net score for each contact center agent for each contact center query category according to a predicted interaction score and one or more non-interaction features of each query, wherein the non-interaction features are features that are available before routing a contact center query; and routing each incoming contact center query to a contact center agent according to the net score of the contact center agent for the incoming query category.
2. The method of claim 1, wherein the one or more test metrics comprise one or more of: a normalized discounted cumulative gain metric, an F1 score, and a top K metric.
3. The method of claim 1, wherein the one or more non-interaction features comprise one or more of: average customer satisfaction scores by hour, average customer satisfaction scores by sentiment, customer wait time, and contact center agent idle time.
4. The method of claim 1, wherein the one or more selected business outcomes include one or more of a call duration, a customer satisfaction score, and contact center agent idle time.
5. The method of claim 1, wherein routing comprises routing an incoming query to a contact center agent every n seconds or until m contact center agents become available.
6. The method of claim 1, wherein routing comprises routing an incoming query to a contact center agent when n incoming queries arrive or until m contact center agents become available.
7. The method of claim 1, further comprising updating the ranking model to provide latent information for one or more agents.
8. The method of claim 1, wherein updating the ranking model comprises comparing the ranking model against an older model to determine that the older model is outperformed.
9. The method of claim 1, wherein the predicted interaction score is generated by the ranking model.
10. An apparatus comprising: one or more computer processors; one or more computer readable storage media; program instructions stored on the one or more computer readable storage media for execution by at least one of the one or more computer processors, the program instructions comprising instructions to, on behalf of a contact center control server associated with a contact center that includes a plurality of agent terminals at which contact center agents serve contact center queries: monitor over time interactions between contact center agents and contact center queries received at the contact center; train a ranking model according to one or more contact center query categories and corresponding interaction scores of each contact center query, wherein an interaction score corresponds to a resolution of a contact center interaction, and wherein the ranking model utilizes machine learning to score each contact center agent for a given contact center query; test the ranking model using one or more test metrics to determine that the ranking model ranks the plurality of agents according to one or more selected business outcomes; determine a net score for each contact center agent for each contact center query category according to a predicted interaction score and one or more non-interaction features of each query, wherein the non-interaction features are features that are available before routing a contact center query; and route each incoming contact center query to a contact center agent according to the net score of the contact center agent for the incoming query category.
11. The apparatus of claim 10, wherein the one or more test metrics comprise one or more of: a normalized discounted cumulative gain metric, an F1 score, and a top K metric.
12. The apparatus of claim 10, wherein the one or more non-interaction features comprise one or more of: average customer satisfaction scores by hour, average customer satisfaction scores by sentiment, customer wait time, and contact center agent idle time.
13. The apparatus of claim 10, wherein the one or more selected business outcomes include one or more of a call duration, a customer satisfaction score, and contact center agent idle time.
14. The apparatus of claim 10, wherein routing comprises routing an incoming query to a contact center agent every n seconds or until m contact center agents become available.
15. The apparatus of claim 10, wherein routing comprises routing an incoming query to a contact center agent when n incoming queries arrive or until m contact center agents become available.
16. One or more non-transitory computer readable storage media encoded with instructions that, when executed by a processor, cause the processor to: at a contact center control server associated with a contact center that includes a plurality of agent terminals at which contact center agents serve contact center queries: monitor over time interactions between contact center agents and contact center queries received at the contact center; train a ranking model according to one or more contact center query categories and corresponding interaction scores of each contact center query, wherein an interaction score corresponds to a resolution of a contact center interaction, and wherein the ranking model utilizes machine learning to score each contact center agent for a given contact center query; test the ranking model using one or more test metrics to determine that the ranking model ranks the plurality of agents according to one or more selected business outcomes; determine a net score for each contact center agent for each contact center query category according to a predicted interaction score and one or more non-interaction features of each query, wherein the non-interaction features are features that are available before routing a contact center query; and route each incoming contact center query to a contact center agent according to the net score of the contact center agent for the incoming query category.
17. The one or more non-transitory computer readable storage media of claim 16, wherein the one or more test metrics comprise one or more of: a normalized discounted cumulative gain metric, an F1 score, and a top K metric.
18. The one or more non-transitory computer readable storage media of claim 16, wherein the one or more non-interaction features comprise one or more of: average customer satisfaction scores by hour, average customer satisfaction scores by sentiment, customer wait time, and contact center agent idle time.
19. The one or more non-transitory computer readable storage media of claim 16, wherein routing comprises routing an incoming query to a contact center agent every n seconds or until m contact center agents become available.
20. The one or more non-transitory computer readable storage media of claim 16, wherein routing comprises routing an incoming query to a contact center agent when n incoming queries arrive or until m contact center agents become available.
</claims>
</document>
