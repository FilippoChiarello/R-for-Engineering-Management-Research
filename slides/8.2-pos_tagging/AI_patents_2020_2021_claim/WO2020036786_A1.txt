<document>

<filing_date>
2019-08-07
</filing_date>

<publication_date>
2020-02-20
</publication_date>

<priority_date>
2018-08-13
</priority_date>

<ipc_classes>
A61B34/00,A61B34/30,A61B34/37,A61B5/11,A61B90/00
</ipc_classes>

<assignee>
VERILY LIFE SCIENCES
</assignee>

<inventors>
BARRAL, JÃ–ELLE K.
DONHOWE, CAITLIN
TEKIELA, KAMILLA
</inventors>

<docdb_family_id>
69405241
</docdb_family_id>

<title>
DETECTION OF UNINTENTIONAL MOVEMENT OF A USER INTERFACE DEVICE
</title>

<abstract>
A user interface system includes one or more controllers configured to move freely in three dimensions, where the one or more controllers include an inertial sensor coupled to measure movement of the one or more controllers, and output movement data including information about the movement. The user interface system further includes a processor coupled to receive the movement data, where the processor includes logic that, when executed by the processor, causes the user interface system to perform operations, including receiving the movement data with the processor, identifying an unintentional movement in the movement data with the processor, and outputting unintentional movement data that identifies the unintentional movement.
</abstract>

<claims>
What is claimed is:
1. A user interface system, comprising:
one or more controllers configured to move freely in three dimensions, wherein the one or more controllers include:
an inertial sensor coupled to measure movement of the one or more controllers, and output movement data including information about the movement; and
a processor coupled to receive the movement data from the one or more controllers, wherein the processor includes logic that, when executed by the processor, causes the user interface system to perform operations, including:
receiving the movement data with the processor;
identifying an unintentional movement in the movement data with the processor; and
outputting unintentional movement data that identifies the unintentional movement.
2. The user interface system of claim 1, wherein the processor further includes logic that, when executed by the processor, causes the user interface system to perform operations, including:
sending the unintentional movement data to a surgical robot including one or more arms, wherein in response to the unintentional movement data the surgical robot restricts the movement of the one or more arms.
3. The user interface system of claim 1, wherein the unintentional movement includes at least one of a dropped controller, a jerked controller, a hobbled controller, or a shaken controller.
4. The user interface system of claim 1, further comprising:
a tactile interface disposed in the one or more controllers and coupled to sense tactile input from a user of the user interface system and output tactile data including infonnation about the tactile input, and wherein identifying the unintentional movement includes analyzing the tactile data, output from the tactile interface, with the processor.
5. The user interface system of claim 4, wherein the tactile interface includes at least one of a button, a pressure sensor, or a capacitive sensor.
6. The user interface system of claim 1, further comprising a machine learning algorithm disposed in logic, and wherein identifying an unintentional movement includes using the machine learning algorithm.
7. The user interface system of claim 6, wherein the machine learning algorithm includes at least one of recurrent neural network (RNN) or a long-short term memory (LSTM) network.
8. The user interface of claim 6, wherein the machine learning algorithm is used in conjunction with one or more heuristics to identify the unintentional movement.
9. The user interface of claim 1, wherein the processor further includes logic that, when executed by the processor, causes the user interface system to perform operations, including:
outputting, in the unintentional movement data, a confidence interval that the unintentional movement occurred.
10. The user interface system of claim 1, wherein the one or more controllers are physically unsupported when the user is operating the user interface system, and wherein the one or more controllers are shaped to be hand held or hand worn.
11. The user interface system of claim 10, wherein the one or more controllers have six degrees of freedom.
12. A method of interacting with a robot, comprising:
receiving movement data, with a processor, from one or more controllers configured to move freely in three dimensions, wherein the one or more controllers include an inertial sensor disposed within the one or more controllers to measure movement of the one or more controllers, and output movement data including information about the movement;
identifying an unintentional movement in the movement data with the processor; and
outputting unintentional movement data, wherein the unintentional movement data includes information identifying the unintentional movement.
13. The method of claim 12, further comprising:
sending the unintentional movement data to a surgical robot including one or more arms; and
in response to the unintentional movement data, restricting the movement of the one or more arms.
14. The method of claim 12, wherein the unintentional movement includes at least one of a dropped controller, a jerked controller, a hobbled controller, or a shaken controller.
15. The method of claim 12, further comprising:
receiving, with the processor, tactile data from the controller, wherein the tactile data is indicative of a user touching the controller, and wherein the unintentional movement is identified at least in part using the tactile data.
16. The method of claim 12, and wherein the tactile data is output from at least one of a button, a pressure sensor, or a capacitive sensor.
17. The method of claim 16, wherein the processor includes a machine learning algorithm disposed in logic, wherein the machine learning algorithm is used to identify the unintentional movement from the movement data and tactile data.
18. The method of claim 17, wherein the machine learning algorithm includes at least one of recurrent neural network (RNN) or a long-short term memory (LSTM) network.
19. The method of claim 17, wherein the machine learning algorithm is used in conjunction with one or more heuristics in the logic to identify the unintentional movement.
20. The method of claim 11, wherein the movement data includes information about six degrees of freedom of the one or more controller.
</claims>
</document>
