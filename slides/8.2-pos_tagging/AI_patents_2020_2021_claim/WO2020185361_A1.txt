<document>

<filing_date>
2020-02-18
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2019-03-14
</priority_date>

<ipc_classes>
G06F1/3203,G06N3/08,G06T5/20,G06T7/11,G06T9/00,H04W52/02
</ipc_classes>

<assignee>
MAPBOX
</assignee>

<inventors>
BUSLAEV, Aleksandr
</inventors>

<docdb_family_id>
72423034
</docdb_family_id>

<title>
LOW POWER CONSUMPTION DEEP NEURAL NETWORK FOR SIMULTANEOUS OBJECT DETECTION AND SEMANTIC SEGMENTATION IN IMAGES ON A MOBILE COMPUTING DEVICE
</title>

<abstract>
A mobile computing device receives an image from a camera physically located within a vehicle. The mobile computing device inputs the image into a convolutional model that generates a set of object detections and a set of segmented environment blocks in the image. The convolutional model includes subsets of encoding and decoding layers, as well as parameters associated with the layers. The convolutional model relates the image and parameters to the sets of object detections and segmented environment blocks. A server that stores object detections and segmented environment blocks is updated with the sets of object detections and segmented environment blocks detected in the image.
</abstract>

<claims>
1. A method to be performed by a mobile computing device comprising:
receiving an image from a camera physically located within a vehicle;
inputting the image into a convolution model loaded into a memory of the mobile computing device and configured to generate a set of object detections for objects appearing in the received image and a set of segmented environment blocks, the convolution model comprising:
a plurality of parameters associated with a plurality of layers of the convolution model, the layers comprising:
a subset of encoding layers and a subset of decoding layers;
at least one skip connection between the encoding layers and the decoding layers, the subset of decoding layers comprising:
a first set of paired detector block heads for generating object detections of a large size;
a first linknet block and a second set of paired detector head blocks for generating object detections of a medium size;
a second linknet block and a third set of paired detector head blocks for generating object detections of a small size; and
a third linknet block and at least one up-sampling layer to generate the set of segmented environment blocks; and
a function relating the image and the parameters to the set of object detections and the set of segmented environment blocks; and
providing the set of object detections and the set of segmented environment blocks to a server computing device.
2. The method of claim 1, wherein the objects identified in the set of object detections are physically located in the environment about the vehicle and are captured within the image by the camera, wherein:
the objects comprise discrete shapes around which bounding boxes can be placed,
the objects are represented by a number of pixels located in the image, and the objects are one of a plurality of object types.
3. The method of claim 1, wherein the segmented environment blocks identified in the set of segmented environment blocks are physically located in the environment about the vehicle and are captured within the image by the camera, wherein:
the segmented environment blocks comprise unbounded shapes, including those behind or crossing one or more of the objects,
the segmented environment blocks are represented by a number of pixels located in the image, and
the segmented environment blocks are one of a plurality of block types.
4. The method of claim 1, wherein the parameters were obtained using a set of training images, each training image associated with a set of training object detections and a set of training segmented environment blocks.
5. The method of claim 1, wherein the encoding layers each comprise at least one resnet block.
6. The method of claim 5, wherein the resnet block comprises:
a first convolution layer receiving an input layer;
a first batch norm layer;
a first ReLU layer;
a second convolution layer;
a second batch norm layer;
a second ReLU layer; and
an addition layer receiving an output of the second ReLU layer and the input layer.
7. The method of claim 1, wherein the decoding layers further comprise a plurality of linknet blocks.
8. The method of claim 7, wherein the linknet block comprises:
a first convolution layer;
an upsampling layer; a second convolution layer; and
a third convolution layer.
9. The method of claim 1, wherein the detector block heads comprise at least three convolution layers.
10. The method of claim 1, wherein the image is a plurality of pixels, and wherein when the image is input into the convolution model, the pixels of the image are input into the convolution model.
11. The method of claim 1, further comprising:
responsive to determining that one of the identified set of object detections adheres to a set of rules loaded into the memory of the mobile computing device, providing a notification via the mobile computing device to the user.
12. The method of claim 11, wherein providing the notification comprises displaying the notification on a screen of the mobile computing device.
13. The method of claim 11, wherein providing of the notification comprises playing an audio alert on a speaker of the mobile computing device.
14. The method of claim 11, wherein the rule indicates that a road hazard has been detected within a proximity of the vehicle and wherein the notification informs the user of the road hazard.
15. The method of claim 11, wherein the rule indicates that a waypoint or a destination has been detected within a proximity of the vehicle and wherein the notification informs the user of the presence of the waypoint or the destination.
16. The method of claim 1, wherein the camera is an integrated component of the mobile computing device.
17. The method of claim 16, wherein the camera is configured to capture infrared light.
18. The method of claim 1 further comprising storing the set of object detections and the set of segmented environment blocks in the memory of the mobile computing device.
19. The method of claim 1, further comprising:
sending updates to an existing repository of map data located on a remote computing server physically distant from the mobile computing device, the updates comprising:
adding new objects and segmented environment blocks identified by the set of object detections and the set of segmented environment blocks; and
adjusting existing objects and segmented environment blocks stored in the map data by comparing what is identified by the set of object detections and the set of segmented environment blocks.
20. A set of computer program instructions configured to be stored within a non-transitory computer readable storage medium of a mobile computing device, the instructions, when executed by a computer processor the mobile computing device causing the mobile computing device to:
receive an image from a camera physically located within a vehicle;
input the image into a convolution model loaded into a memory of the mobile computing device and configured to generate a set of object detections for objects appearing in the received image and a set of segmented environment blocks, the convolution model comprising:
a plurality of parameters associated with a plurality of layers of the convolution model, the layers comprising:
a subset of encoding layers and a subset of decoding layers,
at least one skip connection between the encoding layers and the decoding layers, the subset of decoding layers comprising:
a first set of paired detector block heads for generating object detections of a large size;
a first linknet block and a second set of paired detector head blocks for generating object detections of a medium size;
a second linknet block and a third set of paired detector head blocks for generating object detections of a small size; and a third linknet block and at least one up-sampling layer to generate the set of segmented environment blocks;
a function relating the image and the parameters to the set of object detections and the set of segmented environment blocks; and
provide the set of object detections and the set of segmented environment blocks to a server computing device.
</claims>
</document>
