<document>

<filing_date>
2019-05-23
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2019-05-23
</priority_date>

<ipc_classes>
B23K9/095,B23K9/32,G02B27/01,G09B19/24,G09B5/02,H04N13/156,H04N13/239,H04N13/344,H04N13/361,H04N13/398,H04N5/235
</ipc_classes>

<assignee>
SRI INTERNATIONAL
Kawada Technologies, Inc.
</assignee>

<inventors>
VAN DER WAL, GOOITZEN
ZHANG, DAVID
Homma, Atsushi
Tsuyama, Tadahisa
Berends, David
Kanehira, Noriyuki
Yamaoka, Chiharu
Fuse, Naohiko
Piacentino, Michael
</inventors>

<docdb_family_id>
73453302
</docdb_family_id>

<title>
HDR IMAGE CAPTURE AND DISPLAY SYSTEM FOR ENHANCED REAL-TIME WELDING VISUALIZATION AND ASSISTANCE
</title>

<abstract>
A method, apparatus and system for enhanced welding visualization include splitting incoming light from the welding environment into at least a first optical path and a second optical path having different light levels using at least one beam splitter. Images of the split light having different light levels are captured using a respective imaging sensor. The images from the respective imaging sensors are fused to create a left-eye fused image and a right-eye fused image. The left-eye fused image is displayed on a display at a location of a left eye of a user and the right-eye fused image is displayed on a display at a location of a right eye of the user to provide a parallax-free, high dynamic range, representation of the welding environment.
</abstract>

<claims>
1. An apparatus for enhanced real-time welding visualization in a welding environment, comprising: a beam splitter splitting incoming light from the welding environment into at least a first optical path and a second optical path having different light levels, the at least first and second optical paths each comprising a respective imaging sensor; a control unit receiving and fusing the images from each of the respective imaging sensors in the at least first optical path and second optical path to create a left eye fused image and a right eye fused image; and a display assembly displaying the left eye fused image at a location of a left eye of a user of the apparatus and the right eye fused image at a location of a right eye of the user of the apparatus.
2. The apparatus of claim 1, comprising: a left eye imaging assembly and a right eye imaging assembly, each of the left eye imaging assembly and the right eye imaging assembly, comprising; at least one beam splitter splitting incoming light from the welding environment into at least a first optical path and a second optical path having different light levels, the at least first and second optical paths each comprising a respective imaging sensor; wherein images captured in the left eye imaging assembly are fused and then are displayed at the location of the left eye of the user of the apparatus and images captured in the right eye imaging assembly are fused and displayed at the location of the right eye of the user of the apparatus to provide a three dimensional representation of the welding environment.
3. The apparatus of claim 1, further comprising at least one photo sensor for sensing light levels in the welding environment and the control unit determines from which imaging sensor to display images based on a signal received from at least one of the at least one photo sensor and at least one of the imaging sensors, the received signal indicative of a sensed light level in the welding environment.
4. The apparatus of claim 1, further comprising at least one temperature sensor for sensing temperatures in the welding environment.
5. The apparatus of claim 4, wherein the control unit causes a display, on the display assembly of a message indicative of a sensed temperature in the welding environment in response to a signal communicated from the at least one temperature sensor indicative of a sensed temperature in the welding environment.
6. The apparatus of claim 1, wherein the displaying of the images of the welding environment comprises a simultaneous display of images of an arc of a weld in progress, a welding wire a welding torch, a puddle of molten metal just welded, a glowing bead of a weld that just solidified, the bead of the weld as the bead cools down and no longer glows, a region of a sample to be welded, and a background region surrounding the weld area, wherein the simultaneous display includes all of the details of an individual display of images of the arc of a weld in progress, the welding wire, the tip of the welding torch, the puddle of molten metal just welded, the glowing bead of the weld that just solidified, the bead of the weld as the bead cools down and no longer glows, the region of the sample to be welded, and the background region surrounding the weld area.
7. The apparatus of claim 1, wherein the control unit causes a display, on the display assembly, of information to assist in the performance of a weld.
8. The apparatus of claim 7, wherein the information to assist in the performance of a weld comprises at least one of an image generated by the control unit and welding parameters of the welding environment.
9. The apparatus of claim 1, wherein the control unit comprises a memory for recording welding processes in the welding environment.
10. The apparatus of claim 1, further comprising at least one near infrared imaging sensor for enabling imaging of the welding environment in the presence of smoke.
11. The apparatus of claim 1, wherein the imaging sensors comprise printed circuit board cameras.
12. The apparatus of claim 1, further comprising at least one of a neutral density filter and a camera lens in at least one of the at least first and second optical paths for further differentiating the light level between the at least first and second optical paths.
13. A method for enhancing real-time welding visualization in a welding environment, the method comprising: in a wearable welding apparatus, splitting incident light from the welding environment into at least a first optical path and a second optical path having different light levels using at least one beam splitter; in each of the at least first optical path and second optical path, capturing images of the respective, split light using an imaging sensor; fusing the images from the respective imaging sensors of the at least first optical path and second optical path to create a left eye fused image and a right eye fused image; and displaying the left eye fused image on a display at a location of a left eye of a user of the wearable welding apparatus and the right eye fused image on a display at a location of a right eye of the user of the wearable welding apparatus.
14. The method of claim 13, comprising: in each of a left eye imaging assembly and a right eye imaging assembly, splitting the incident light from the welding environment into at least a first optical path and a second optical path having different light levels using at least one beam splitter; in each of the left eye imaging assembly and the right eye imaging assembly, capturing images in each of the at least first optical path and second optical path using an imaging sensor; fusing images from the respective imaging sensors of the at least first optical path and second optical path of the left eye imaging assembly and the right eye imaging assembly to create a left eye fused image and a right eye fused image; and displaying the left eye fused image at a location of a left eye of a user of the wearable welding apparatus and the right eye fused image is displayed at a location of a right eye of the user of the wearable welding apparatus.
15. The method of claim 13, further comprising determining from which imaging sensor to display images in response to a signal indicative of a sensed light level in the welding environment.
16. The method of claim 13, further comprising displaying at least one of information and images to assist the user of the wearable welding apparatus in the performance of a weld in the welding environment, wherein the information comprises at least welding parameters of the welding environment including at least one of at least one temperature in the welding environment, a feed speed of a weld wire, a position of a weld wire, a position of a weld torch, a current or voltage of a power supply associated with the weld torch, and a dwell time and the images comprise augmented reality images including at least one of a thermal image overlaid on an image of the welding environment and a path overlaid on an image of the welding environment along which to perform a weld.
17. The method of claim 13, further comprising removing sparks from at least one image of the welding environment.
18. The method of claim 13, further comprising communicating with a welding station for determining at least operating parameters of the welding environment.
19. (canceled)
20. The method of claim 13, further comprising evaluating images of a welding process captured by the imaging sensors and providing feedback to a user regarding weld quality.
21. The method of claim 13, further comprising configuring the imaging sensors to capture images of the welding environment at different frame rates to create images of the welding environment having different exposures.
</claims>
</document>
