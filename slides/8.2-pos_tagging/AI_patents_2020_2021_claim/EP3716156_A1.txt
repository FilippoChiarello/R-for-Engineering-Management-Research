<document>

<filing_date>
2018-11-20
</filing_date>

<publication_date>
2020-09-30
</publication_date>

<priority_date>
2017-12-29
</priority_date>

<ipc_classes>
G06N3/08
</ipc_classes>

<assignee>
HUAWEI TECHNOLOGIES COMPANY
</assignee>

<inventors>
MA, Tao
JIN, Ying
SU, Qing
</inventors>

<docdb_family_id>
67063024
</docdb_family_id>

<title>
NEURAL NETWORK MODEL TRAINING METHOD AND APPARATUS
</title>

<abstract>
This application provides a method for training a neural network model and an apparatus. The method is applied to a terminal device, the terminal device includes a first neural network model and a second neural network model that are used to process a service, precision of the first neural network model is lower than precision of the second neural network model, and the method includes: obtaining annotation data that is of the service and that is generated by the terminal device in a specified period (301); training the second neural network model by using the annotation data that is of the service and that is generated in the specified period, to obtain a trained second neural network model (302); and updating the first neural network model based on the trained second neural network model (303). In the method, training is performed based on the annotation data generated by the terminal device, so that in an updated first neural network model compared with a universal model, an inference result has a higher confidence level, and a personalized requirement of a user can be better met.
</abstract>

<claims>
1. A method for training a neural network model, wherein the method is applied to a terminal device, the terminal device comprises a first neural network model and a second neural network model that are used to process a service, precision of the first neural network model is lower than precision of the second neural network model, and the method comprises: obtaining annotation data that is of the service and that is generated by the terminal device in a specified period; training the second neural network model by using the annotation data that is of the service and that is generated in the specified period, to obtain a trained second neural network model; and updating the first neural network model based on the trained second neural network model.
2. The method according to claim 1, wherein after the trained second neural network model is obtained, before the updating the first neural network model, the method further comprises: if it is determined that the trained second neural network model is an initial update of a second neural network model corresponding to a first version, storing the first neural network model; and after the updating the first neural network model, the method further comprises: receiving a second version software package sent by a cloud server, wherein the second version software package comprises a first neural network model corresponding to a second version; and if it is determined that the first neural network model corresponding to the second version is different from the stored first neural network model, updating the first neural network model corresponding to the second version.
3. The method according to claim 2, wherein the updating the first neural network model corresponding to the second version comprises: obtaining annotation data that is of the service and that is generated in a plurality of historical specified periods; training, by using the annotation data that is of the service and that is generated in the plurality of historical specified periods, a second neural network model corresponding to the second version, to obtain a trained second neural network model corresponding to the second version; and updating, based on the trained second neural network model corresponding to the second version, the first neural network model corresponding to the second version.
4. The method according to any one of claims 1 to 3, wherein the terminal device generates the annotation data of the service in the specified period in the following manner: performing online inference on first input data of the service in the specified period by using the first neural network model, to obtain an online inference result; and if a valid feedback of a user for the online inference result is received, generating the annotation data of the service based on the first input data and the valid feedback of the user for the online inference result; or if no valid feedback of a user for the online inference is received, after it is determined that a confidence level of the online inference result is greater than a first threshold, generating the annotation data of the service based on the first input data and the online inference result.
5. The method according to any one of claims 1 to 3, wherein the terminal device generates the annotation data of the service in the specified period in the following manner: performing offline inference on second input data of the service in the specified period by using a third neural network model, to obtain an offline inference result, wherein precision of the third neural network model is higher than the precision of the second neural network model, or the third neural network model is the second neural network model; and if it is determined that a confidence level of the offline inference result is greater than a second threshold, generating the annotation data of the service based on the second input data and the offline inference result.
6. The method according to any one of claims 1 to 5, wherein the training the second neural network model by using the annotation data that is of the service and that is generated in the specified period comprises:
when the terminal device is in a charging state, training the second neural network model by using the annotation data that is of the service and that is generated in the specified period.
7. A terminal device, wherein the terminal device comprises a first neural network model and a second neural network model that are used to process a service, precision of the first neural network model is lower than precision of the second neural network model, and the terminal device further comprises: an obtaining module, configured to obtain annotation data that is of the service and that is generated by the terminal device in a specified period; and a processing module, configured to: train the second neural network model by using the annotation data that is of the service and that is generated in the specified period, to obtain a trained second neural network model; and update the first neural network model based on the trained second neural network model.
8. The terminal device according to claim 7, wherein after obtaining the trained second neural network model and before updating the first neural network model, the processing module is further configured to: if it is determined that the trained second neural network model is an initial update of a second neural network model corresponding to a first version, store the first neural network model; the terminal device further comprises a transceiver module, the transceiver module is configured to receive a second version software package sent by a cloud server, and the second version software package comprises a first neural network model corresponding to a second version; and the processing module is further configured to: if it is determined that the first neural network model corresponding to the second version is different from the stored first neural network model, update the first neural network model corresponding to the second version.
9. The terminal device according to claim 8, wherein the processing module is specifically configured to: obtain annotation data that is of the service and that is generated in a plurality of historical specified periods; train, by using the annotation data that is of the service and that is generated in the plurality of historical specified periods, a second neural network model corresponding to the second version, to obtain a trained second neural network model corresponding to the second version; and update, based on the trained second neural network model corresponding to the second version, the first neural network model corresponding to the second version.
10. The terminal device according to any one of claims 7 to 9, wherein the processing module is further configured to: perform online inference on first input data of the service in the specified period by using the first neural network model, to obtain an online inference result; and
if the transceiver module receives a valid feedback of a user for the online inference result, generate the annotation data of the service based on the first input data and the valid feedback of the user for the online inference result; or if the transceiver module receives no valid feedback of a user for the online inference, after it is determined that a confidence level of the online inference result is greater than a first threshold, generate the annotation data of the service based on the first input data and the online inference result.
11. The terminal device according to any one of claims 7 to 9, wherein the processing module is further configured to: perform offline inference on second input data of the service in the specified period by using a third neural network model, to obtain an offline inference result, wherein precision of the third neural network model is higher than the precision of the second neural network model, or the third neural network model is the second neural network model; and if it is determined that a confidence level of the offline inference result is greater than a second threshold, generate the annotation data of the service based on the second input data and the offline inference result.
12. The terminal device according to any one of claims 7 to 11, wherein the processing module is specifically configured to:
when the terminal device is in a charging state, train the second neural network model by using the annotation data that is of the service and that is generated in the specified period.
13. A terminal device, wherein the terminal device comprises: a memory, configured to store a software program; and a processor, configured to: read the software program in the memory, and perform the method for training a neural network model according to any one of claims 1 to 6.
14. A computer storage medium, wherein the storage medium stores a software program, and when the software program is read and executed by one or more processors, the signal processing method according to any one of claims 1 to 6 is implemented.
15. A computer program product, wherein the computer program product comprises an instruction, and when the instruction is run on a computer, the computer is enabled to perform the method according to any one of claims 1 to 6.
</claims>
</document>
