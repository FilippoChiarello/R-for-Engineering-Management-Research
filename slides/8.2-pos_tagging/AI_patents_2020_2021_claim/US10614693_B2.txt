<document>

<filing_date>
2019-04-04
</filing_date>

<publication_date>
2020-04-07
</publication_date>

<priority_date>
2018-04-10
</priority_date>

<ipc_classes>
G06F3/01,G06N5/04,G08B21/04,G08B23/00
</ipc_classes>

<assignee>
ETRI (ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE)
</assignee>

<inventors>
SOHN, JONG-MOO
KIM, MOO SEOP
</inventors>

<docdb_family_id>
68097290
</docdb_family_id>

<title>
Dangerous situation notification apparatus and method
</title>

<abstract>
A dangerous situation notification apparatus includes an acoustic information management unit identifying and providing acoustic information including an acoustic source type and acoustic scene information; a user behavior information identification unit generating and providing user behavior information; a behavior context information management unit storing user behavior context information generated using the acoustic information and the user behavior information in advance, and analyzing user's current behavior context information corresponding to the acoustic information and the user behavior information detected in real time; a dangerous situation inference unit inferring whether the acoustic information or the user behavior information corresponds to a dangerous situation; and a dangerous situation notification unit providing a dangerous situation notification.
</abstract>

<claims>
1. A dangerous situation notification apparatus comprising: an acoustic information management unit identifying and providing acoustic information including an acoustic source type and acoustic scene information; a user behavior information identification unit generating and providing user behavior information on the basis of at least one of terminal usage information of a user, sensing information of a user terminal, and ambience information of the user terminal; a behavior context information management unit storing user behavior context information generated using the acoustic information and the user behavior information in advance, and analyzing user's current behavior context information corresponding to the acoustic information and the user behavior information detected in real time on the basis of the user behavior context information stored in advance; a dangerous situation inference unit inferring whether the acoustic information or the user behavior information corresponds to a dangerous situation on the basis of the user's current behavior context information; and a dangerous situation notification unit providing a dangerous situation notification on the basis of a result inferred by the dangerous situation inference unit.
2. The apparatus of claim 1, wherein the behavior context information management unit includes: a user behavior event recognition unit detecting at least one user behavior event using at least one of the acoustic information and the user behavior information; and a behavior context information generation unit generating the user behavior context information by combining the at least one user behavior event.
3. The apparatus of claim 2, wherein the user behavior context information includes semantic information inferred from a pattern in which the at least one user behavior event occurs repeatedly, periodically, or regularly.
4. The apparatus of claim 2, wherein the user behavior context information includes a behavior context element that defines the behavior of the user using rule-based reasoning based on the at least one user behavior event.
5. The apparatus of claim 4, wherein the user behavior context information includes a behavior context entity that describes the behavior of the user in detail by combining the behavior context elements.
6. The apparatus of claim 1, wherein the dangerous situation inference unit infers the dangerous situation when the acoustic source type corresponds to a risk factor and the acoustic source type is suitable for the user behavior context information.
7. The apparatus of claim 1, wherein the dangerous situation inference unit infers the dangerous situation, when the acoustic source type corresponds to a risk factor, a user's trajectory identified from the user behavior information corresponds to a origin of the sound source, and the user is estimated to collide with the origin of the sound source on the basis of the user behavior context information.
8. The apparatus of claim 6, wherein the dangerous situation inference unit infers the dangerous situation, when the acoustic source type corresponds to the risk factor, the acoustic source type is suitable for the user behavior context information, and a distance between a origin of the sound source and a user's position identified from the user behavior information is within a dangerous situation estimation range calculated based on the user behavior context information.
9. A dangerous situation notification method comprising: identifying acoustic information including an acoustic source type and acoustic scene information; generating user behavior information on the basis of at least one of terminal usage information of a user, sensing information of a user terminal, and ambience information of the user terminal; generating and storing user behavior context information in advance using the acoustic information and the user behavior information; analyzing user's current behavior context information corresponding to the acoustic information and the user behavior information detected in real time on the basis of the user behavior context information stored in advance; inferring whether the acoustic information or the user behavior information corresponds to a dangerous situation on the basis of the user's current behavior context information; and providing a dangerous situation notification on the basis of a result inferred by the dangerous situation inference unit.
10. The method of claim 9, wherein the analyzing of the user's current behavior context information includes: detecting at least one user behavior event using at least one of the acoustic information and the user behavior information; and identifying the current behavior context information by combining the at least one user behavior event.
11. The method of claim 9, wherein the user behavior context information includes semantic information inferred from a pattern in which the at least one user behavior event occurs repeatedly, periodically, or regularly.
12. The method of claim 9, wherein the user behavior context information includes a behavior context element that defines a behavior of the user using rule-based reasoning based on the at least one user behavior event.
13. The method of claim 12, wherein the user behavior context information includes a behavior context entity that describes the behavior of the user in detail by combining the behavior context elements.
14. The method of claim 9, wherein the inferring of whether the acoustic information or the user behavior information corresponds to the dangerous situation is performed by inferring the dangerous situation, when the acoustic information corresponds to a risk factor and the acoustic information is suitable for the user's current behavior context information.
15. The method of claim 14, wherein the inferring of whether the acoustic information or the user behavior information corresponds to the dangerous situation is performed by inferring the dangerous situation, when the acoustic source type corresponds to the risk factor, the acoustic source type is suitable for the user behavior context information, and a distance between the origin of the sound source and a user's position identified from the user behavior information is within a dangerous situation estimation range calculated based on the user's current behavior context information.
16. The method of claim 9, wherein the inferring of whether the acoustic information or the user behavior information corresponds to the dangerous situation is performed by inferring the dangerous situation, when the acoustic source type corresponds to a risk factor, a user's trajectory identified from the user behavior information corresponds to a origin of the sound source, and the user is estimated to collide with the origin of the sound source on the basis of the user behavior context information.
</claims>
</document>
