<document>

<filing_date>
2018-12-21
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2018-12-21
</priority_date>

<ipc_classes>
G10L25/30,G10L25/51
</ipc_classes>

<assignee>
HUAWEI TECHNOLOGIES COMPANY
LACOUTURE PARODI, YESENIA
</assignee>

<inventors>
CRESPI, ANDREA
DENG, JUN
EYBEN, FLORIAN
LACOUTURE PARODI, YESENIA
</inventors>

<docdb_family_id>
64899365
</docdb_family_id>

<title>
AN AUDIO PROCESSING APPARATUS AND METHOD FOR AUDIO SCENE CLASSIFICATION
</title>

<abstract>
The invention relates to an audio processing apparatus (200) configured to classify an audio signal into one or more audio scene classes, the audio signal comprising a component signal. The apparatus (200) comprises: processing circuitry configured to classify the component signal of the audio signal as a foreground layer component signal or a background layer component signal; obtain an audio signal feature on the basis of the audio signal; select, depending on the classification of the component signal, a first set of weights or a second set of weights; and to classify the audio signal on the basis of the audio signal features, the foreground layer component signal or the background layer component signal and the selected set of weights.
</abstract>

<claims>
1. An audio processing apparatus (200) configured to classify an audio signal into one or more audio scene classes, the audio signal comprising a component signal, wherein the apparatus (200) comprises a processing circuitry configured to: classify the component signal of the audio signal as a foreground layer component signal or a background layer component signal; obtain an audio signal feature on the basis of the audio signal; select, depending on the classification of the component signal, a first set of weights or a second set of weights; and classify the audio signal, on the basis of the audio signal feature, the foreground layer component signal or background layer component signal, and the selected set of weights.
2. The apparatus (200) of claim 1 , wherein the processing circuitry is configured to classify the component signal of the audio signal as a foreground layer component signal, when the component signal of the audio signal has a short-term audio event or a long term audio event;
or
classify the component signal of the audio signal as a background layer component signal, when the component signal of the audio signal has no short-term audio event and no long-term audio event.
3. The apparatus (200) of claim 2, wherein the processing circuitry is configured to partition the audio signal into a plurality of frames, and to classify the component signal of the audio signal by determining for each frame of the audio signal a complex domain difference, CDD.
4. The apparatus (200) of claim 3, wherein the CDD is determined on the basis of the following equation: wherein n denotes a frame index, k denotes a frequency bin index, N denotes a frame size in samples and wherein a spectrum XT(n, k ) is defined as: where
Y' (n, k) = Y (n, k)— Y(h— 1, k) denotes a phase difference in the kth frequency bin.
5. The apparatus (200) of claim 3, wherein the processing circuitry is configured to apply for each frame of the audio signal a high-pass filter to the CDD and to identify a peak in the high-pass filtered CDD as a short-term audio event.
6. The apparatus (200) of claims 4 or 5, wherein the processing circuitry is configured to apply for each frame of the audio signal a low-pass filter to the CDD and to identify a long-term audio event by determining a peak in the low-pass filtered CDD.
7. The apparatus (200) of any one of the preceding claims, wherein the processing circuitry is configured to transform the audio signal from the time domain to the frequency domain and to obtain the audio signal feature from the audio signal in the frequency domain.
8. The apparatus (200) of claim 7, wherein the audio signal feature comprise a logMel spectrum of the audio signal.
9. The apparatus (200) of any one of the preceding claims, wherein the processing circuitry is configured to provide a neural network (220), wherein the neural network (200) is configured to perform the classification of the audio signal.
10. The apparatus (200) of claim 9, wherein the neural network (200) comprises a first neural subnetwork (221 ) and a second neural subnetwork (223), wherein the first neural subnetwork (221 ) is configured to provide, depending on the classification of the component signal, the first set of weights or the second set of weights to the second neural subnetwork (223) and wherein the second neural subnetwork (223) is configured to classify the audio signal on the basis of the audio signal feature, the foreground layer component signal or the background layer component signal and the selected set of weights provided by the first neural subnetwork (221 ).
1 1 . An audio processing method (700) for classifying an audio signal into one or more audio scene classes, the audio signal comprising a component signal, wherein the method (700) comprises: classifying (701 ) the component signal as a foreground layer component signal or a background layer component signal; obtaining (703) an audio signal features on the basis of the audio signal; selecting (705), depending on the classification of the component signal, a first set of weights or a second set of weights; and classifying (707) the audio signal on the basis of the audio signal feature, the foreground layer component signal or the background layer component signal and the selected set of weights.
12. A computer program product comprising program code for performing the method (700) of claim 1 1 , when executed on a computer or a processor.
</claims>
</document>
