<document>

<filing_date>
2019-12-04
</filing_date>

<publication_date>
2020-12-24
</publication_date>

<priority_date>
2019-06-21
</priority_date>

<ipc_classes>
G06F16/532,G06F16/58,G06F16/587,G06K9/62,G06N3/08
</ipc_classes>

<assignee>
WHITE RAVEN LTD
</assignee>

<inventors>
SPIEGEL, EHUD
Peer, Shai
Shvartzman, Boaz
Avni, Ofer
Demri, Aaron
</inventors>

<docdb_family_id>
74039276
</docdb_family_id>

<title>
VISUAL POSITIONING SYSTEM
</title>

<abstract>
Systems and methods for image-based self-localization of an image capture device, include receiving a query image of an undetermined location of the image and comparing the query image to a set of geotagged reference images to determine a location of the query image. The system and method may alternatively compare a series of query images to reference images or portions of feature vectors generated from said query images and reference images to determine the closest query image in the series to respective reference images. The set of geotagged reference images may include a sequence of previously obtained reference images of a route, each reference image corresponding to a known geolocation. The geolocation of the user may be determined based on the location of the query image within the set. Ambient conditions of the images may be used to improve comparison of a query image to reference images. Segment and/or abstractions of cell images may be used to reduce computational and/or communications resources.
</abstract>

<claims>
1. A method for image based self-localization of a user comprising the steps of: receiving one or more query images at a processor; identifying an approximate location of query image capture; selecting a subset of geotagged reference images proximal to said approximate location of query image capture, wherein said reference images, each correspond to a known geolocation; using the processor to compare said query images to a said subset of geotagged reference images to determine which reference image most closely matches a query image; and using the processor to determine a geolocation of the capture of said query image by reference to the geotag of the reference image most similar to said query image.
2. The method of claim 1 comprising using the processor to control a device based on determination of the geolocation of the user.
3. The method of claim 1 comprising: assigning a location sensitive tag to the query image; and comparing the tag of the query image to tags linked to each reference image to determine the location capture of the query image.
4. The method of claim 1 comprising using the processor to determine the location of capture of the query image within the reference images based on a known parameter of the user's movement.
5. The method of claim 1 wherein the step of comparing comprises using a Convolutional Neural Network.
6. The method of claim 1 wherein the reference images are linked to known ambient conditions.
7. The method of claim 1 comprising using the query image to update the reference images.
8. The method of claim 1 comprising using the processor to select a subset of reference images based on a previously determined geolocation of the image capture and based on a probable route.
9. The method of claim 1 comprising: assigning a location sensitive tag to the query image; comparing the tag assigned to the query image to tags linked to each reference image in the sequence of reference images, the tags sensitive to location of each reference image within the sequence, to determine a location of the query image within the sequence; and determining the matching image based on the location of the query image within the sequence.
10. The method of claim 9 wherein determining ambient conditions is based on information automatically obtained from a time recording device associated with the user.
11. The method of claim 10 comprising: determining a location of the first matching reference image within a sequence of the first set of reference images to determine a first geolocation; determining a location of the second matching reference image within a sequence of the second set of reference images to determine a second geolocation; combining the first and second geolocations to a combined geolocation; and determining the geolocation of the user based on the combined geolocation.
12. The method of claim 1 comprising using the query image to update the sequence of images linked to known ambient conditions.
13. The method according to claim 1 wherein one or more reference images are processed to determine features that contrast similar reference images proximal said one or more references image(s); weighting said features that contrast in the reference images in the processor determination of similarity of said reference images to said query image.
14. A method for self-geolocation comprising the steps of: determining approximate location of a query image capture; identifying a geotagged reference image captured proximally to said location of said image capture, wherein said geotagged reference image includes a marked point of interest; comparing a series of query images to said identified geotagged reference image to find the query image that best matches the reference image; tracking a current location relative to a location of capture of the query image that best matches the reference image.
15. The method according to claim 14 further comprising the step of identifying aspects of a query image corresponding to a marked point of interest in said reference image to determine the relative location of the query image that best matches the reference image and the geotagged position of the reference image.
</claims>
</document>
