<document>

<filing_date>
2019-05-07
</filing_date>

<publication_date>
2020-11-12
</publication_date>

<priority_date>
2019-05-07
</priority_date>

<ipc_classes>
G06N3/04,G06N3/063,G06N3/08
</ipc_classes>

<assignee>
HUAWEI TECHNOLOGIES COMPANY
IGNATOV, DMITRY YURIEVICH
</assignee>

<inventors>
FILIPPOV, ALEXANDER NIKOLAEVICH
IGNATOV, DMITRY YURIEVICH
ZOU, Xueyi
</inventors>

<docdb_family_id>
67137997
</docdb_family_id>

<title>
DEVICE, METHOD AND SYSTEM FOR REGULARIZATION OF A BINARY NEURAL NETWORK
</title>

<abstract>
The present invention relates to the field of neural networks, in particular Binary Neural Networks (BNN). The invention proposes a device and method for regularization of a BNN. The device is configured to obtain binary weights of the BNN, and to change the binary weights of the BNN using a backpropagation method. Thereby, changing the binary weights increases or minimizes decrease of an information entropy of a weight distribution.
</abstract>

<claims>
1. Device ( 100) for regularization of a Binary Neural Network, BNN, ( 101 ) wherein the device (100) is configured to:
obtain binary weights (102) of the BNN ( 101 ); and
change the binary weights ( 102) of the BNN ( 101 ) using a backpropagation method
( 103),
wherein changing the binary weights (102) increases or minimizes decrease of an information entropy of a weight distribution of the weights ( 102).
2. Device ( 100) according to claim 1 , wherein:
the backpropagation method ( 103) includes a backpropagation of error gradients (401) obtained during training of the BNN ( 101 ).
3. Device (100) according to claim 1 or 2, configured to:
change the binary weights ( 102) of the BNN ( 101 ) separately for at least one filter or layer of the BNN ( 101 ).
4. Device ( 100) according to one of the claims 1 to 3, configured to:
change the binary weights ( 102) of the BNN (101 ) in real-time during training of the BNN ( 101 ).
5. Device ( 100) according to one of the claims 1 to 4, configured to change the binary weights ( 102) of the BNN ( 101 ) by:
randomly replacing (500), for one or more layers of the BNN ( 101 ), at least one prevalent weight ( 102) by a minority weight ( 102).
6. Device ( 100) according to one of the claims 1 to 5, configured to change the binary weights ( 102) of the BNN ( 101 ) by:
determining a weight distribution for each of a plurality of layers of the BNN, determining, per layer of the plurality of layers, an information entropy based on the determined weight distribution, and
increasing (400) a backpropagation gradient (401 ) for each layer of the plurality of layers, for which an information entropy is determined below a certain threshold value.
7. Device (100) according to claim 6, configured to:
increase (400) the backpropagation gradient (401) for a given layer by a value that is proportional to the loss of information entropy in the following layer of the BNN ( 101 ).
8. Device ( 100) according to one of the claims 1 to 7, configured to change the binary weights ( 102) of the BNN (101) by:
determining one or more weight distributions for one or more layers and/or filters of the BNN ( 101 ), or determining a weight distribution for the entire BNN ( 101 ),
determining (301 ) an information entropy based on each determined weight distribution, and
appending (303) a cost function, used for training the BNN ( 101 ), with a penalty term based on the one or more determined information entropies.
9. Device (100) according to claim 8, configured to:
determine (302) an information loss based on the one or more determined information entropies, and
append (303) the information loss as the penalty term to the cost function.
10. Device ( 100) according to claim 9, configured to:
determine (302) the information loss with respect to a maximum information entropy of the one or more weight distributions, or with respect to a constant value.
11. System (700) for training a BNN (101 ), the system (700) comprising:
a training device (701 ) to obtain and train the BNN ( 101 ), and
a device ( 100) according to one of the claims 1 to 10.
12. System (700) according to claim 11, wherein the device ( 100) according to one of the claims 1 to 10 is included in the training device (701 ) and/or in an updating device (702), wherein:
the training device (701 ) is configured to change the binary weights ( 101 ) of the BNN ( 102) by: determining one or more weight distributions for one or more layers and/or filters of the BNN (101 ), or determining a weight distribution for the entire BNN ( 101 ),
determining (301) an information entropy based on each determined weight distribution, and
appending (303) a cost function, used for training the BNN ( 101 ), with a penalty term based on the one or more determined information entropies; the updating device (702) is configured to change the binary weights (102) of the BNN ( 101 ) by at least one of:
randomly replacing (500) at least one prevalent weight ( 102) by a minority weight (102);
determining a weight distribution of weights for each of a plurality of layers of the BNN ( 101 ),
determining, per layer of the plurality of layers, an information entropy based on the determined weight distribution, and
increasing (400) a backpropagation gradient (401) for each layer, for which an information entropy is determined below a certain threshold value.
13. System (700) according to claim 12, further comprising at least one of:
a terminal device (703) configured to provide the BNN (101) to the training device
(701 );
a prediction device (704) configured to provide a prediction result based on trained data produced by the BNN ( 101 ) and received from the training device (701);
a data storage (705) configured to store the BNN ( 101 ) and/or training data and/or the trained data.
14. Method (200) for regularization of a Binary Neural Network, BNN, ( 101 ) wherein the method (200) comprises:
obtaining (201 ) binary weights ( 102) of the BNN ( 101 ); and
changing (202) the binary weights (102) of the BNN ( 101) using a backpropagation method ( 103),
wherein changing (202) the binary weights ( 102) increases or minimizes decrease of (203) an information entropy of a weight distribution of the weights (102).
15. Computer program product comprising a program code for controlling a device ( 100) according to any one of the claims 1 to 10, or for controlling a system (700) according to one of the claims 1 1 to 13, or for carrying out, when implemented on a processor, the method (200) according to claim 14.
</claims>
</document>
