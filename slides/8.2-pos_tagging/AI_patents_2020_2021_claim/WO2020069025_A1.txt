<document>

<filing_date>
2019-09-25
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-28
</priority_date>

<ipc_classes>
B60W30/09,G01S13/93,G05D1/02
</ipc_classes>

<assignee>
ZOOX
</assignee>

<inventors>
COHEN, JOSHUA
LIU YU
WANG, CHUANG
</inventors>

<docdb_family_id>
69945441
</docdb_family_id>

<title>
RADAR SPATIAL ESTIMATION
</title>

<abstract>
Techniques are discussed for generating a spatial grid based on radar sensor data. The spatial grid may include cells, which may be designated as being occupied, occluded, and/or free space. A cell may be designated as being occupied if radar sensor data is associated with a region of an environment associated with the cell. A field may be designated as being occluded if a region of the environment associated with the cell is obstructed, relative to a radar sensor, by a cell that is designated as being occupied. In some instances, objects may be detected and/or tracked in occluded regions. A cell may be designated as being free space if a region associated with the cell is within a field of view of a radar sensor and is unoccupied and un-occluded. In some instances, the spatial grid may be used to control a vehicle, such as an autonomous vehicle, in the environment.
</abstract>

<claims>
What is claimed is:
1. An autonomous vehicle comprising:
a radar system;
one or more processors communicatively coupled to the radar system; and one or more computer-readable media storing instructions executable by the one or more processors, wherein the instructions, when executed, cause the autonomous vehicle to perform operations comprising:
capturing, by the radar system, radar sensor data of an environment; detecting, based at least in part on the radar sensor data, an object in a first region of the environment;
designating, based at least in part on detecting the object in the first region of the environment, a first cell of a spatial grid as being occupied, the first cell being associated with the first region of the environment;
designating, based at least in part on a location of the first cell relative to a location of a radar sensor of the radar system, a second cell of the spatial grid as being occluded, the second cell being associated with a second region of the environment; and
controlling the autonomous vehicle within the environment based at least in part on the designations of the first cell and the second cell of the spatial grid.
2. The autonomous vehicle of claim 1, wherein:
the radar sensor comprises a first radar sensor and the radar system comprises the first radar sensor and a second radar sensor,
designating the first cell of the spatial grid as being occupied is based on radar sensor data of at least one of the first radar sensor or the second radar sensor indicating that the region corresponding to the first cell of the spatial grid is occupied, and
designating the second cell of the spatial grid as being occluded by the object is based on radar sensor data of the first radar sensor and the second radar sensor indicating that the region corresponding to the second cell of the spatial grid is occluded.
3. The autonomous vehicle of any one of claims 1 or 2, the operations further comprising:
designating, based at least in part on the radar sensor data, a third cell of the spatial grid as being free space, the third cell being associated with a region of the environment that is within the field of view of the radar sensor and is unoccupied and un-occluded,
wherein controlling the autonomous vehicle within the environment is further based at least in part on the designations of the third cell of the spatial grid.
4. The autonomous vehicle of any one of claims 1 or 2, the operations further comprising:
determining that the object is a static object;
computing an occupancy probability of a neighboring cell to the first cell of the spatial grid; and
designating the neighboring cell to the first cell as being occupied by the static object based at least in part on the occupancy probability of the neighboring cell to the first cell being above a threshold probability.
5. The autonomous vehicle of any one of claims 1-4, the operations further comprising:
determining, based at least in part on the radar sensor data or other sensor data, a second region comprising a second cell;
detecting, based at least in part on the radar sensor data, the object entering the second region;
determining, based at least in part on the object entering the second region, that the second region is unoccupied; and
updating the second cell of the spatial grid to indicate that the second region is unoccupied.
6. The autonomous vehicle of any one of claims 1-3 or 5, the operations further comprising:
determining that the object is a dynamic object;
determining a bounding box associated with a track of the dynamic object; and designating one or more cells of the spatial grid associated with an area of the bounding box as being occupied.
7. The autonomous vehicle of any one of claims 1-6, wherein:
the spatial grid comprises a radar system spatial grid, and
controlling the autonomous vehicle in the environment is further based at least in part on at least one of a lidar spatial grid or a camera spatial grid.
8. A method comprising:
capturing, by a radar sensor, radar sensor data of an environment;
designating, based at least in part on the radar data, a first cell of a spatial grid as being occupied, the first cell being associated with a first region of the environment; designating, based at least in part on a location of the first cell relative to a location of the radar sensor and relative to a second cell, the second cell as being occluded; and
outputting the spatial grid associated with the environment.
9. The method of claim 8, wherein the radar sensor comprises a first radar sensor, and the method further comprises:
capturing, by a second radar sensor, radar sensor data of an environment, wherein:
designating the first cell of the spatial grid as being occupied is based on radar sensor data of at least one of the first radar sensor or the second radar sensor indicating that the region corresponding to the first cell of the spatial grid is occupied, and
designating the second cell of the spatial grid as being occluded by the object is based on radar sensor data of the first radar sensor and the second radar sensor indicating that the region corresponding to the second cell of the spatial grid is occluded.
10. The method of any one claims 8 or 9, further comprising:
determining, based at least in part on the radar sensor data, a third cell of the spatial grid as being free space, the third cell being associated with a region of the environment that is within the field of view of the radar sensor and is unoccupied and un-occluded,
wherein controlling the autonomous vehicle within the environment is further based at least in part on the designations of the third cell of the spatial grid.
11. The method of any one of claims 8-10, further comprising:
computing an occupancy probability of a neighboring cell to the first cell of the spatial grid; and
designating the neighboring cell to the first cell as being occupied based at least in part on the occupancy probability of the neighboring cell to the first cell being above a threshold probability.
12. The method of any one of claims 8-11, further comprising:
detecting, based at least in part on the radar sensor data, an object entering the first region,
determining, based at least in part on the object entering the first region, that the first region is unoccupied; and
updating the first cell of the spatial grid to indicate that the first region is unoccupied.
13. The method of any one of claims 8-12, further comprising:
determining that the occupied region is associated with a dynamic object; determining a bounding box associated with a track of the dynamic object; and designating one or more cells of the spatial grid associated with an area of the track of the bounding box as being occupied.
14. The method of any one of claims 8-13, the method further comprising: fusing the occupancy grid with at least one of lidar data or camera data.
15. One or more non-transitory computer-readable media storing instructions that, when executed, cause one or more processors to perform the method of any one of claims 8-14.
</claims>
</document>
