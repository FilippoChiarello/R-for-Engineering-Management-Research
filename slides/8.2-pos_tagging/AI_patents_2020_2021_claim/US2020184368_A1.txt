<document>

<filing_date>
2018-12-10
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-10
</priority_date>

<ipc_classes>
G06F9/50,G06N20/00
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
POZIDIS, CHARALAMPOS
PARNELL, THOMAS
DUENNER, CELESTINE
</inventors>

<docdb_family_id>
70970256
</docdb_family_id>

<title>
MACHINE LEARNING IN HETEROGENEOUS PROCESSING SYSTEMS
</title>

<abstract>
Computer-implemented methods are provided for implementing training of a machine learning model in a heterogeneous processing system that includes a host computer operatively interconnected to an accelerator unit. The training operation involves an iterative optimization process for optimizing a model vector defining the model. Such a method includes, in the host computer, storing a matrix of training data and partitioning the matrix into a plurality of batches of data vectors. For each of successive iterations of the optimization process, a selected subset of the batches is provided to the accelerator unit. In the accelerator unit, each iteration of the optimization process is performed to update the model vector in dependence on vectors in the selected subset for that iteration. In the host computer, batch importance values are calculated for respective batches. The batch importance value is dependent on contributions of vectors in that batch to sub-optimality of the model vector.
</abstract>

<claims>
1. A computer-implemented method for training a machine learning model in a heterogeneous processing system comprising a host computer operatively interconnected with an accelerator unit, the computer-implemented method using an iterative optimization process for optimizing a model vector defining said model, the computer-implemented method comprising: in the host computer, storing a matrix of training data and partitioning the matrix into a plurality of batches of data vectors; for each of successive iterations of the optimization process, providing a selected subset of said batches to the accelerator unit; in the accelerator unit, performing each iteration of the optimization process to update the model vector in dependence on vectors in said selected subset for that iteration; and in the host computer, in parallel with each iteration in the accelerator unit, calculating batch importance values for respective batches, the batch importance value for each batch being dependent on contributions of vectors in that batch to sub-optimality of the model vector; wherein said subset of batches for each iteration is selected by the host computer in dependence on said batch importance values.
2. The computer-implemented method as claimed in claim 1, wherein the batch importance value for each batch is dependent on the coordinate-wise duality gap associated with vectors in that batch.
3. The computer-implemented method as claimed in claim 1 further including, in the host computer, selecting said subset of batches for each iteration by: sorting the importance values for the batches; and selecting for said subset one or more batches having importance values indicative of the largest contributions to sub-optimality of the model vector;
4. The computer-implemented method as claimed in claim 3, wherein said subset of batches for each iteration comprises a plurality of batches.
5. The computer-implemented method as claimed in claim 1 further including, in the host computer, calculating the batch importance value for each batch by: calculating respective vector importance values for vectors in that batch, the vector importance value for a vector being indicative of the contribution of that vector to sub-optimality of the model vector; and calculating the batch importance value in dependence on said vector importance values.
6. The computer-implemented method as claimed in claim 5 further including calculating vector importance values for all vectors in the batch.
7. The computer-implemented method as claimed in claim 5 further including calculating vector importance values for a random sub-sample of vectors in the batch.
8. The computer-implemented method as claimed in claim 5 further including calculating the batch importance value in dependence on at least one of an average, a maximum and a sum of said vector importance values.
9. The computer-implemented method as claimed in claim 5, wherein the vector importance value for each vector comprises the coordinate-wise duality gap associated with that vector.
10. The computer-implemented method as claimed in claim 1 further including, in the host computer, calculating batch importance values for randomly-selected batches until the accelerator unit has completed said iteration of the optimization process.
11. The computer-implemented method as claimed in claim 1, wherein the host computer partitions said matrix into a plurality of batches of respective sizes dependent on the number of non-zero vector elements in the data vectors in each batch.
12. A heterogeneous processing system for training a machine learning model via an iterative optimization process for optimizing a model vector defining said model, the system comprising a host computer, for storing a matrix of training data, which is operatively interconnected with an accelerator unit, wherein the heterogeneous processing system is adapted such that: the host computer partitions said matrix into a plurality of batches of data vectors; for each of successive iterations of the optimization process, a selected subset of said batches is provided to the accelerator unit; the accelerator unit performs each iteration of the optimization process to update the model vector in dependence on vectors in said selected subset for that iteration; and the host computer, in parallel with each iteration in the accelerator unit, calculates batch importance values for respective batches, the batch importance value for each batch being dependent on contributions of vectors in that batch to sub-optimality of the model vector; wherein said subset of batches for each iteration is selected by the host computer in dependence on said batch importance values.
13. The system as claimed in claim 12, wherein the batch importance value for each batch is dependent on the coordinate-wise duality gap associated with vectors in that batch.
14. The system as claimed in claim 12, wherein the host computer is adapted to select said subset of batches for each iteration by: sorting the importance values for the batches; and selecting for said subset a plurality of batches having importance values indicative of the largest contributions to sub-optimality of the model vector;
15. The system as claimed in claim 12, wherein the host computer is adapted to calculate the batch importance value for each batch by: calculating respective vector importance values for vectors in that batch, the vector importance value for a vector being indicative of the contribution of that vector to sub-optimality of the model vector; and calculating the batch importance value in dependence on said vector importance values.
16. The system as claimed in claim 15, wherein the vector importance value for each vector comprises the coordinate-wise duality gap associated with that vector.
17. The system as claimed in claim 15, wherein the host computer is adapted to calculate batch importance values for randomly-selected batches until the accelerator unit has completed said iteration of the optimization process.
18. The system as claimed in claim 12, wherein the accelerator unit comprises at least one graphics processing unit.
19. The system as claimed in claim 12, wherein the accelerator unit comprises at least one field-programmable gate array.
20. A computer program product for training a machine learning model in a heterogeneous processing system comprising a host computer operatively interconnected with an accelerator unit, via an iterative optimization process for optimizing a model vector defining said model, said computer program product comprising a computer readable storage medium having program instructions embodied therein, the program instructions being executable by the processing system to cause the system to perform a method comprising: in the host computer, storing a matrix of training data and partitioning the matrix into a plurality of batches of data vectors; for each of successive iterations of the optimization process, providing a selected subset of said batches to the accelerator unit; in the accelerator unit, performing each iteration of the optimization process to update the model vector in dependence on vectors in said selected subset for that iteration; and in the host computer, in parallel with each iteration in the accelerator unit, calculating batch importance values for respective batches, the batch importance value for each batch being dependent on contributions of vectors in that batch to sub-optimality of the model vector; wherein said subset of batches for each iteration is selected by the host computer in dependence on said batch importance values.
</claims>
</document>
