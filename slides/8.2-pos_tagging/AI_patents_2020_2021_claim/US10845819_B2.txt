<document>

<filing_date>
2018-02-08
</filing_date>

<publication_date>
2020-11-24
</publication_date>

<priority_date>
2017-07-21
</priority_date>

<ipc_classes>
A47L9/00,A47L9/28,A47L9/30,G05D1/02,G06K9/00,G06K9/20,G06K9/62,H04N5/225
</ipc_classes>

<assignee>
LG ELECTRONICS
</assignee>

<inventors>
LEE, SUNG HUN
PARK, SANGYEOL
</inventors>

<docdb_family_id>
65016380
</docdb_family_id>

<title>
Cleaner and control method thereof
</title>

<abstract>
A cleaner performing autonomous traveling includes a main body, a driving unit moving the main body, a camera capturing an image around the main body at every preset period, and a controller selecting at least one of a plurality of traveling modes and controlling the driving unit and the camera to perform the selected traveling mode, wherein the controller changes a set value related to illumination of the camera while the camera is continuously capturing images.
</abstract>

<claims>
1. A robot comprising: a main body; a motor that selectively provides a driving force to move the main body; a camera that captures a plurality of images of a space around the main body; and a controller that selects between a plurality of traveling modes, and manages the motor and the camera based on selecting between the traveling modes, wherein the controller changes a setting of the camera related to illumination in the images based on selecting between the traveling modes while the camera is capturing the images, and wherein the camera captures a particular number of images per unit time, and the controller changes the setting of the camera such that the particular number of images are captured during the unit time with a plurality of different illuminations.
2. The robot of claim 1, wherein the controller changes the setting of the camera such that a first number of the images captured with one of the plurality of illuminations is different from a second number of images captured with another one of the plurality of illuminations.
3. The robot of claim 1, wherein the controller performs one of a plurality of traveling modes using one of the images captured with one of the plurality of illuminations, and performs another one of the plurality of traveling modes using another one of the images captured with another one of the plurality of illuminations.
4. The robot of claim 3, wherein the plurality of traveling modes include an obstacle recognition mode, a monitoring mode, and a position recognition mode.
5. The robot of claim 4, wherein the controller changes the setting of the camera such that illumination of a first image used to perform the position recognition mode is lower than illumination of a second image used to perform at least one of the obstacle recognition mode or the monitoring mode.
6. The robot of claim 1, wherein the camera obtains images at 30 frames per second, the controller changes the setting of the camera to capture 3 frames of the 30 frames with first illumination and capture another 27 frames of the 30 frames with second illumination, and the first illumination is set to be lower than the second illumination.
7. The robot of claim 1, wherein a first traveling mode and a second traveling mode are selected from the plurality of traveling modes, first images of the plurality of images relate to the first traveling mode, and second images of the plurality of images relate to the second traveling mode, and the controller detects information related to illumination of the first images used in the first traveling mode and information related to illumination of the second images used in the second traveling mode.
8. The robot of claim 7, wherein when the first traveling mode and the second traveling mode are selected from the plurality of traveling modes, the controller detects a first number of images used per unit time in the first traveling mode and a second number of images used per unit time in the second traveling mode.
9. The robot of claim 8, wherein the illumination of the first images used in the first traveling mode is a first illumination, the illumination of the second images used in the second traveling mode is a second illumination, and when the first and second traveling modes are selected and while the camera is obtaining a preset number of images per second, the controller controls the camera such that the preset number of images per second includes at least the first number of the first images captured with the first illumination and at least the second number of images captured with the second illumination.
10. The robot of claim 1, wherein the controller classifies the images captured by the camera into a plurality of groups based on the different illuminations of the images.
11. The robot of claim 10, further comprising: a memory that stores the images captured by the camera, wherein the controller labels the images based on classifying the images into the plurality of groups and stores the labeled images in the memory.
12. The robot of claim 10, wherein after the images are classified, the controller executes a first traveling mode selected from the traveling modes using a first group of the images captured with a first illumination associated with the first travel mode, and executes a second traveling mode selected from the traveling modes using a second group of the images captured with a second illumination associated with the second travel mode.
13. The robot of claim 12, wherein the first traveling mode is a simultaneous localization and mapping (SLAM) traveling mode, and the controller executes the first traveling mode based on detecting information related to a position of the main body using one of the first group of images captured with the first illumination.
14. The robot of claim 13, further comprising: a sensor that senses a brightness of the space in which the main body is positioned, wherein the controller determines, based on information collected by the sensor, a change in the brightness of the space, and changes the setting of the camera related to illumination of the first group of the images used in the first traveling mode to correct for the change in the brightness of the space.
15. The robot of claim 12, further comprising: a communication interface that exchanges signals with another device that is external to the robot, wherein the second traveling mode includes a monitoring traveling mode, and the controller directs the communication interface to transmit at least one of the second group of images captured with the second illumination to a server or a user terminal.
16. The robot of claim 15, wherein the controller selects a quantity of images from the second group of the images captured with the second illumination, and directs the communication interface to transmit the selected quantity of images to at least one of the server or the user terminal.
17. The robot of claim 16, wherein when information related to a user input applied to one or more of the server or the user terminal is received through the communication interface, the controller changes the quantity of images based on the user input, selects the change quantity of images from the second group of the images captured with the second illumination, and transmits the changed quantity of images to the at least one of the server or the user terminal via the communication interface.
18. The robot of claim 1, wherein the controller, when changing the setting of the camera, performs first illumination control to cause the camera to capture a first number of images with a first illumination of the different illuminations, and when the first illumination control is completed, the controller performs second illumination control to cause the camera to capture a second number of images with a second illumination of the different illuminations.
19. The robot of claim 18, wherein the controller sequentially and repeatedly performs the first illumination control and the second illumination control.
20. The robot of claim 1, wherein the robot is an autonomous cleaner.
</claims>
</document>
