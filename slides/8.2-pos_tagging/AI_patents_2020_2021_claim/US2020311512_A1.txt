<document>

<filing_date>
2020-06-15
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2018-07-24
</priority_date>

<ipc_classes>
G06N3/04,G06N3/063,G06N3/08,G11C11/16,G11C11/56,G11C13/00,G11C16/04,G11C16/26
</ipc_classes>

<assignee>
SANDISK TECHNOLOGIES
</assignee>

<inventors>
HEMINK, GERRIT JAN
CHOI, WON HO
QIN, MINGHAI
MA, WEN
LUEKER-BODEN, MARTIN
CHIU, PI-FENG
</inventors>

<docdb_family_id>
69178555
</docdb_family_id>

<title>
REALIZATION OF BINARY NEURAL NETWORKS IN NAND MEMORY ARRAYS
</title>

<abstract>
Use of a NAND array architecture to realize a binary neural network (BNN) allows for matrix multiplication and accumulation to be performed within the memory array. A unit synapse for storing a weight of a BNN is stored in a pair of series connected memory cells. A binary input is applied as a pattern of voltage values on a pair of word lines connected to the unit synapse to perform the multiplication of the input with the weight by determining whether or not the unit synapse conducts. The results of such multiplications are determined by a sense amplifier, with the results accumulated by a counter.
</abstract>

<claims>
1. An apparatus, comprising: one or more control circuits configured to connect to an array of non-volatile memory cells, the memory cells of the array arranged as NAND strings configured to store a plurality of weights of a neural network in a binary format with each of the weights stored in a pair of memory cells on a shared NAND string, the one or more control circuits configured to: receive a plurality of binary valued inputs for a layer of a neural network; and perform an in-array inference operation between the plurality of inputs for the layer of the neural network and the weights of the neural network.
2. The apparatus of claim 1, wherein, in performing the in-array inference operation, the one or more control circuits are configured to: convert each of the plurality of inputs into a corresponding one of a plurality of voltage patterns, each of the voltage patterns including a pair of voltage values; apply the plurality of voltage patterns to the array of non-volatile memory cells to thereby perform an in-array multiplication of the plurality of inputs with the weights; and accumulate results of the in-array multiplication.
3. The apparatus of claim 2, further comprising: a memory die comprising the memory array, wherein each of the plurality of weights is stored in a pair of non-volatile memory cells, one of which is in a programmed state and the other of which is in an erased state.
4. The apparatus of claim 3, wherein the array includes: a bit line; and a source line, wherein the NAND strings each include a plurality of memory cells and are each connected between the bit line and the source line, and wherein the one or more control circuits include: a word line decoder connected to the memory cells and configured to bias a first plurality of the NAND strings to perform a concurrent sensing operation on the first plurality of the NAND strings; and a multi-bit sense amplifier connected to the bit line and configured to determine a number of the first plurality of the NAND strings conducting in the concurrent sensing operation.
5. The apparatus of claim 4, the one or more control circuits further including: a counter connected to the multi-bit sense amplifier and configured to increment a count value by corresponding to the number of the first plurality of the NAND strings conducting in the concurrent sensing operation.
6. The apparatus of claim 5, wherein each of the concurrent sensing operations includes simultaneously sensing a plurality of memory cells on each of the first plurality of the NAND strings.
7. The apparatus of claim 3, wherein: the array of non-volatile memory cells includes a plurality of NAND strings connected to a shared bit line; and the one or more control circuits are further configured to concurrently apply the plurality of voltage patterns to the plurality of NAND strings connected to the shared bit line and accumulate the results of the in-array multiplication in a multi-bit sensing operation for the shared bit line.
8. The apparatus of claim 3, wherein: the array of non-volatile memory cells includes a plurality of NAND strings connected to a shared bit line; and the one or more control circuits are further configured to sequentially apply the plurality of voltage patterns to the plurality of NAND strings connected to the shared bit line and accumulate the results of the in-array multiplication in sequential sensing operations.
9. The apparatus of claim 3, wherein the array of non-volatile memory cells includes: a first plurality of NAND strings each connected to a corresponding bit line; and the one or more control circuits are further configured to concurrently apply a first of the plurality of voltage patterns to the first plurality of NAND strings and independently accumulate a result of the in-array multiplication for each of the first plurality of NAND strings concurrently.
10. The apparatus of claim 2, wherein the one or more control circuits are further configured to provide accumulated results of the in-array multiplication as inputs for a subsequent layer of the neural network.
11. A method, comprising: receiving one or more input values; translating each of the one or more input values input values into one or more voltage values; applying the one or more voltage values to a plurality of word lines of a non-volatile memory array, the array including a plurality of NAND strings, each including a plurality of memory cells connected to one of the word; while applying the one or more voltage values to the plurality of word lines of the array, performing a concurrent sensing operation on the plurality of NAND strings; and determining a number of the plurality of NAND strings that are conducting in the concurrent sensing operation.
12. The method of claim 11, further comprising: incrementing a count value by corresponding to the number of the plurality of NAND strings conducting in the concurrent sensing operation.
13. The method of claim 11, wherein performing the concurrent sensing operation includes: simultaneously sensing a plurality of memory cells on each of the plurality of NAND strings.
14. The method of claim 13, wherein each of the plurality of memory cells on each of the plurality of NAND strings stores a weight of a neural network.
15. The method of claim 14, wherein the weights are binary weights.
16. An apparatus, comprising: an array of non-volatile memory cells including a bit line, a plurality of word lines, and a first plurality of NAND strings each connected to the bit line and each including a plurality of memory cells each connected to a corresponding one of the word lines; and one or more control circuits connected to the word lines and the NAND strings, the one or more control circuits configured to: concurrently apply, for each of a first plurality of the NAND strings, one of a plurality of sensing voltages to one or more first word lines connected to a corresponding one or more memory cells; and determining a number of the first plurality of the NAND strings that conduct in response to concurrently applying, for each of a first plurality of the NAND strings, the one of the plurality of sensing voltages to the one or more first word lines connected to a corresponding one or more memory cells.
17. The apparatus of claim 16, wherein the one or more control circuits are further configured to: increment a count value by a number corresponding to the number of the first plurality of NAND strings conducting in response concurrently applying the one of the plurality of sensing voltages to the one or more first word lines connected to a corresponding one or more memory cells.
18. The apparatus of claim 17, wherein the one or more control circuits are further configured to: subsequent to incrementing the count value, concurrently apply, for each of one or more of the first plurality of the NAND strings, one of a plurality of sensing voltages to one or more second word lines connected to a corresponding one or more memory cells; determining a number of the first plurality of the NAND strings that conduct in response to concurrently applying, for each of a first plurality of the NAND strings, the one of the plurality of sensing voltages to the one or more second word lines connected to a corresponding one or more memory cells; and further increment the count value by a number corresponding to the number of the first plurality of NAND strings conducting in response concurrently applying the one of the plurality of sensing voltages to the one or more second word lines connected to a corresponding one or more memory cells.
19. The apparatus of claim 16, wherein each of the plurality of memory cells on each of the first plurality of NAND strings corresponds to a weight of a neural network.
20. The apparatus of claim 19, wherein the weights are binary weights.
</claims>
</document>
