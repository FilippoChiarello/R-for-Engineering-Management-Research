<document>

<filing_date>
2020-06-05
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-07
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46
</ipc_classes>

<assignee>
BASF COATINGS (BADISCHE ANILIN & SODA FABRIK COATINGS)
</assignee>

<inventors>
CHILDERS, MATTHEW IAN
KURTOGLU, YUNUS EMRE
</inventors>

<docdb_family_id>
70977985
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR OBJECT RECOGNITION USING 3D MAPPING AND MODELING OF LIGHT
</title>

<abstract>
The present invention refers to a method and a system for object recognition via a computer vision application, wherein at least one object (110) to be recognized is illuminated by at least one light source (121, 122) having light source specific radiance values, and radiance data of a scene (130) including the object are measured when the scene (130) is illuminated by the light source (121, 122). Further the scene is mapped by a scene mapping tool (150) rendering at least a partial 3D map of the scene (130). The data received from the scene mapping tool (150) are analysed and merged with the light source specific radiance values, and, based thereon, radiance of light incident at points in the scene (130), particularly at the at least one object (110), are calculated and combined with the measured radiance of light returned to the sensor (140) from points in the scene (130), particularly from the at least one object (110), thus forming a model of light spectral distribution and intensity at the at least one object (110) in the scene (130). An object specific luminescence and/or reflectance spectral pattern of the at least one object is extracted out of the model of light spectral distribution and intensity and matched with luminescence and/or reflectance spectral patterns stored in a data storage unit (160). Thus, a best matching luminescence and/or reflectance spectral pattern is identified.
</abstract>

<claims>
1 . A system for object recognition via a computer vision application, the system comprising at least the following components:
- at least one object (1 10) to be recognized, the object (1 10) having object specific reflectance and luminescence spectral patterns,
- at least one light source (121 , 122) which is configured to illuminate under ambient light conditions a scene (130), the scene including the at least one object (1 10), the at least one light source (121 , 122) having light source specific radiance values,
- a sensor (140) which is configured to measure radiance data of the scene (130) when the scene (130) is illuminated by the light source
(121 , 122),
- a scene mapping tool (150) which is configured to map the scene (130) rendering at least a partial 3D map of the scene (130),
- a data storage unit (160) which comprises luminescence and/or reflectance spectral patterns together with appropriately assigned respective objects,
- a data processing unit (170) which is configured to analyse data received from the scene mapping tool (150) and to merge the analysed data with the light source specific radiance values, and, based thereon, to calculate radiance of light incident at points in the scene (130), particularly at the at least one object (1 10), and to combine the calculated radiance of light incident at the points in the scene (130) with the measured radiance of light returned to the sensor (140) from points in the scene (130), particularly from the at least one object
(1 10), thus forming a model of light spectral distribution and intensity at the at least one object (1 10) in the scene (130), and to extract the object specific luminescence and/or reflectance spectral pattern of the at least one object to be recognized out of the model of light spectral distribution and intensity and to match the extracted object specific luminescence and/or reflectance spectral pattern with the luminescence and/or reflectance spectral patterns stored in the data storage unit (160), and to identify a best matching luminescence and/or reflectance spectral pattern and, thus, its assigned object,
wherein at least the sensor (140), the scene mapping tool (150), the data storage unit (160) and the data processing unit (170) are in communicative connection with each other and linked together wirelessly and/or through wires and synchronized with the light source (121 , 122) by default, thus forming an integrated system.
2. The system according to claim 1 which is configured to calculate radiance of the at least one light source (121 , 122) at the at least one object (1 10) in the scene (130) by using the light source specific radiance values, particularly spectral characteristics, power and/or an emission angle profile of the at least one light source in the scene, and mapping a distance from the at least one light source (121 , 122) to the at least one object (1 10) in the scene (130).
3. The system according to claim 1 or 2 wherein the light source (121 , 122) is linked with the scene mapping tool (150), the data storage unit (160) and/or the data processing unit (170).
4. The system according to claim 1 , 2 or 3 wherein the sensor (140) is a multispectral or hyperspectral camera.
5. The system according to any one of the preceding claims wherein the scene mapping tool (150) is configured to perform a scene mapping by using a technique based on at least one of time of flight (TOF), stereovision, structured light, radar and/or ultrasound. 6. The system according to any one of the preceding claims, which is configured to use physical location, compass orientation, time of day, and/or weather conditions to model an effect of solar radiation on the illumination of the at least one object (1 10) in the scene (130).
7. The system according to any one of the preceding claims, which is configured to use information of the reflective and fluorescence properties of the at least one object in the scene (130) to improve radiance mapping of the scene (130) by means of bidirectional reflectance distribution functions (BRDFs) and bidirectional fluorescence distribution functions (BFDFs) to account for interreflections of reflected and fluoresced light throughout the scene. 8. The system according to any one of the preceding claims, further comprising at least one white tile located at at least one point in the scene (130), the white tile being configured to be used to measure radiance of the light source (121 , 122) at the at least one point in the scene (130), wherein the measured radiance of the light source at the at least one point in the scene (130) is used in conjunction with the 3D map and a light output profile of the light source (121 , 122) to estimate radiance at other points in the scene (130).
9. A method for object recognition via a computer vision application, the method comprising at least the following steps:
- providing at least one object to be recognized, the object having object specific reflectance and luminescence spectral patterns,
- illuminating, by at least one light source, a scene which includes the at least one object under ambient light conditions, the light source having light source specific radiance values,
- measuring, using a sensor, radiance data of the scene including the at least one object when the scene is illuminated by the light source, - mapping, using a scene mapping tool, the scene rendering an at least partial 3D map of the scene,
- providing a data storage unit which comprises luminescence and/or reflectance spectral patterns together with appropriately assigned respective objects,
- providing a data processing unit which is programmed to analyse data received from the scene mapping tool and merge the analysed data with the light source specific radiance values to calculate radiance of light incident at points in the scene, particularly at the at least one object, and to combine the calculated radiance of light incident at the points in the scene with the measured radiance of light returned to the sensor from points in the scene, particularly from the at least one object, thus forming a model of light spectral distribution and intensity at the at least one object in the scene, and to extract the object specific luminescence and/or reflectance spectral pattern of the at least one object to be recognized out of the model of light spectral distribution and intensity and to match the extracted object specific luminescence and/or reflectance spectral pattern with the luminescence and/or reflectance spectral patterns stored in the data storage unit, and to identify a best matching luminescence and/or reflectance spectral pattern and, thus, its assigned object,
wherein the sensor, the scene mapping tool, the data storage unit and the data processing unit are communicating with each other wirelessly and/or through wires and are synchronized with the light source by default, thus forming an integrated system.
10. The method according to claim 9 wherein a scene mapping is performed by using a technique based on at least one of time of flight (TOF), stereovision, structured light, radar, and/or ultrasound.
1 1 . The method according to any one of claims 9 or 10 wherein radiance of the at least one light source at the at least one object in the scene is calculated using spectral characteristics, power and/or an emission angle profile of the at least one light source in the scene, and mapping a distance from the at least one light source to the at least one object in the scene.
12. The method according to any one of the claims 9 to 1 1 , wherein physical location, compass orientation, time of day, and/or weather conditions are used to model an effect of solar radiation on the illumination of the scene. io 13. The method according to any one of the claims 9 to 12, wherein information of the reflective and fluorescence properties of the at least one object in the scene is used to improve radiance mapping of the scene by means of bidirectional reflectance distribution functions (BRDFs) and bidirectional fluorescence distribution functions (BFDFs) to account for is interreflections of reflected and fluoresced light throughout of the scene.
14. The method according to any one of the claims 9 to 13, wherein the model of light spectral distribution and intensity can be analysed and displayed on a 2D map or as a 3D view.
20
15. A non-transitory computer-readable medium storing instructions that, when executed by one or more data processing units as provided as component of a system according to any one of the claims 1 to 8, cause the system to:
25
- analyse data received from the scene mapping tool,
- merge the analysed data with the light source specific radiance data,
- calculate radiance of light incident at points in a scene, particularly at points of at least one object to be recognized, based on the merged
30 data,
- combine the calculated radiance of light incident at the points in the scene with the measured radiance of light returned to the sensor from points in the scene, particularly from points of the at least one object, thus forming a model of light spectral distribution and intensity at the at least one object in the scene,
- extract an object specific luminescence and/or reflectance spectral pattern of the at least one object to be recognized out of the model of light spectral distribution and intensity,
- match the extracted object specific luminescence and/or reflectance spectral pattern with luminescence and/or reflectance spectral patterns stored in the data storage unit, and,
- identify a best matching luminescence and/or reflectance spectral pattern and, thus, its assigned object.
</claims>
</document>
