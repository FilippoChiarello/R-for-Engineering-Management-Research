<document>

<filing_date>
2019-05-20
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2019-05-20
</priority_date>

<ipc_classes>
G06N20/00,G06N5/02
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
VARADARAJULU, GOPIKRISHNAN
KULKARNI, VAIBHAV MURLIDHAR
ARORA, RAKHI S.
KRISHNAN, PADMANABHAN
</inventors>

<docdb_family_id>
73456888
</docdb_family_id>

<title>
MACHINE LEARNING WITH DIFFERENTLY MASKED DATA IN SECURE MULTI-PARTY COMPUTING
</title>

<abstract>
In a secure multi-party computation (sMPC) system, a super mask is constructed using a set of masks corresponding to a set of data contributors. Each data contributor uses a corresponding different mask to obfuscate the data of the data contributor. a first scaled masked data is formed by applying a first scale factor to first masked data of the first data contributor, the scale factor being computed specifically for the first data contributor from the super mask. A union is constructed of all scaled masked data from all data contributors, including the first scaled masked data. A machine learning (ML) model is trained using the union as training data, where the union continues to keep obfuscated the differently masked data from the different data contributors. The training produces a trained ML model usable in the sMPC with the set of data contributors.
</abstract>

<claims>
1. A method comprising: constructing, in a secure multi-party computation (sMPC) system, a super mask using a set of masks corresponding to a set of data contributors, wherein a first data contributor in the set of data contributors uses a corresponding first mask from the set of masks to obfuscate first data of the first data contributor; applying, using a processor and a memory, to form a first scaled masked data, a first scale factor to first masked data of the first data contributor, the scale factor being computed specifically for the first data contributor from the super mask; constructing a union of all scaled masked data from all data contributors in the set of data contributors, the union including the first scaled masked data of the first data contributor; training a machine learning (ML) model using the union as training data, wherein the union continues to keep obfuscated differently masked data from different data contributors, the training resulting in a trained ML model usable in the sMPC with the set of data contributors.
2. The method of claim 1, further comprising: receiving new masked data from the first data contributor; scaling the new masked data using the first scale factor; inputting the scaled new masked data into the trained ML model; de-scaling an output of the trained ML model using the first scale factor; transmitting to the first data contributor the de-scaled output as a prediction based on the new masked data.
3. The method of claim 2, wherein subjecting the prediction to a reverse of a masking operation using a first mask of the first data contributor produces an actual predicted value.
4. The method of claim 1, wherein the first data contributor uses a first mask from the set of masks to obfuscate only a portion of original data of the first data contributor and form the first masked data.
5. The method of claim 1, further comprising: receiving an encrypted first mask from the first data contributor; decrypting the encrypted first mask to obtain the first mask, wherein the super mask uses the first mask in a function.
6. The method of claim 1, further comprising: applying, as a part of constructing the super mask, a polynomial function to the set of masks, the polynomial function using a set of pseudo-random values in conjunction with the set of masks to compute the super mask.
7. The method of claim 1, wherein the first data contributor in the set of data contributors uses a first mask from the set of masks in a multiplication operation to obfuscate original data of the first data contributor to form the first masked data.
8. The method of claim 1, further comprising: computing a first multiplication factor corresponding to the first data contributor by using the super mask and a first mask corresponding to the first data contributor.
9. The method of claim 8, wherein the first multiplication factor is computed by dividing the super mask by the first mask, and wherein the first scale factor further divides the first multiplication factor by a transformation value.
10. A computer usable program product comprising a computer readable storage medium, and program instructions stored on the storage medium, the stored program instructions comprising: program instructions to construct, in a secure multi-party computation (sMPC) system, a super mask using a set of masks corresponding to a set of data contributors, wherein a first data contributor in the set of data contributors uses a corresponding first mask from the set of masks to obfuscate first data of the first data contributor; program instructions to apply, using a processor and a memory, to form a first scaled masked data, a first scale factor to first masked data of the first data contributor, the scale factor being computed specifically for the first data contributor from the super mask; program instructions to construct a union of all scaled masked data from all data contributors in the set of data contributors, the union including the first scaled masked data of the first data contributor; and program instructions to train a machine learning (ML) model using the union as training data, wherein the union continues to keep obfuscated differently masked data from different data contributors, the training resulting in a trained ML model usable in the sMPC with the set of data contributors.
11. The computer usable program product of claim 10, further comprising: program instructions to receive new masked data from the first data contributor; program instructions to scale the new masked data using the first scale factor; program instructions to input the scaled new masked data into the trained ML model; program instructions to de-scale an output of the trained ML model using the first scale factor; and program instructions to transmit to the first data contributor the de-scaled output as a prediction based on the new masked data.
12. The computer usable program product of claim 11, wherein subjecting the prediction to a reverse of a masking operation using a first mask of the first data contributor produces an actual predicted value.
13. The computer usable program product of claim 10, wherein the first data contributor uses a first mask from the set of masks to obfuscate only a portion of original data of the first data contributor and form the first masked data.
14. The computer usable program product of claim 10, further comprising: program instructions to receive an encrypted first mask from the first data contributor; decrypting the encrypted first mask to obtain the first mask, wherein the super mask uses the first mask in a function.
15. The computer usable program product of claim 10, further comprising: program instructions to apply, as a part of constructing the super mask, a polynomial function to the set of masks, the polynomial function using a set of pseudo-random values in conjunction with the set of masks to compute the super mask.
16. The computer usable program product of claim 10, wherein the first data contributor in the set of data contributors uses a first mask from the set of masks in a multiplication operation to obfuscate original data of the first data contributor to form the first masked data.
17. The computer usable program product of claim 10, further comprising: program instructions to compute a first multiplication factor corresponding to the first data contributor by using the super mask and a first mask corresponding to the first data contributor.
18. The computer usable program product of claim 10, wherein the stored program instructions are stored in a computer readable storage device in a data processing system, and wherein the stored program instructions are transferred over a network from a remote data processing system.
19. The computer usable program product of claim 10, wherein the stored program instructions are stored in a computer readable storage device in a server data processing system, and wherein the computer usable code is stored program instructions are downloaded over a network to a remote data processing system for use in a computer readable storage device associated with the remote data processing system.
20. A computer system comprising a processor, a computer-readable memory, and a computer readable storage medium, and program instructions stored on the storage medium for execution by the processor via the memory, the stored program instructions comprising: program instructions to construct, in a secure multi-party computation (sMPC) system, a super mask using a set of masks corresponding to a set of data contributors, wherein a first data contributor in the set of data contributors uses a corresponding first mask from the set of masks to obfuscate first data of the first data contributor; program instructions to apply, using a processor and a memory, to form a first scaled masked data, a first scale factor to first masked data of the first data contributor, the scale factor being computed specifically for the first data contributor from the super mask; program instructions to construct a union of all scaled masked data from all data contributors in the set of data contributors, the union including the first scaled masked data of the first data contributor; and program instructions to train a machine learning (ML) model using the union as training data, wherein the union continues to keep obfuscated differently masked data from different data contributors, the training resulting in a trained ML model usable in the sMPC with the set of data contributors.
</claims>
</document>
