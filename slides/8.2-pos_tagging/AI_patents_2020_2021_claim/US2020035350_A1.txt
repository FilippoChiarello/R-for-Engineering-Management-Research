<document>

<filing_date>
2018-02-21
</filing_date>

<publication_date>
2020-01-30
</publication_date>

<priority_date>
2017-02-21
</priority_date>

<ipc_classes>
G06N20/00,G06N3/08,G06T11/00,G16H30/40,G16H50/20,G16H50/50
</ipc_classes>

<assignee>
KOH YOUNG TECHNOLOGY
</assignee>

<inventors>
KANG, JIN MAN
SULLIVAN, KENNETH MARK
</inventors>

<docdb_family_id>
63252850
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR PROCESSING HISTOLOGICAL IMAGE CAPTURED BY MEDICAL IMAGING DEVICE
</title>

<abstract>
A method for processing one or more histological images captured by a medical imaging device is disclosed. In this method, the histological image is received, and target regions each of which corresponds to a candidate type of tissue are identified based on a predictive model as sociating one more sample histological images with one or more sample target histological images. One or more display characteristics associated with the identified at least one target histological image is applied to the histological image.
</abstract>

<claims>
1. A method, performed by a computer, for processing a histological image captured by a medical imaging device, the method comprising: receiving the histological image including at least one type of tissue; determining, by a first autoencoder, a candidate type of tissue in the histological image; identifying, by the first autoencoder, a target region corresponding to the candidate type of tissue in the histological image; identifying at least one target histological image corresponding to the target region in the histological image based on a predictive model associating one or more sample histological images with one or more sample target histological images; and applying one or more display characteristics associated with the identified at least one target histological image to the histological image.
2. The method of claim 1, further comprising generating a modified image of the histological image including the applied display characteristics.
3. The method of claim 1, wherein the predictive model comprises a first set of patches in each of the sample histological images and a second set of patches in each of the sample target histological images, wherein the first set of patches is associated with the second set of patches in the predictive model, and wherein applying the one or more display characteristics comprises modifying a plurality of patches in the received histological image based on the second set of patches in the identified at least one target histological image.
4. The method of claim 1, wherein identifying the target region corresponding to the candidate type of tissue comprises identifying a plurality of regions comprising the target region in the histological image, wherein the predictive model comprises a first set of regions in each of the sample histological images and a second set of regions in each of the sample target histological images, wherein the first set of regions is associated with the second set of regions in the predictive model, and wherein applying one or more display characteristics comprises modifying the plurality of regions in the received histological image based on the second set of regions in the identified at least one target histological image.
5. The method of claim 1, wherein a first unsupervised learning model is generated by training the first autoencoder based on a first set of sample histological images.
6. The method of claim 5, wherein the predictive model is generated based on the first unsupervised learning model and a second unsupervised learning model, and wherein the second unsupervised learning model is generated by training a second set of sample target histological images.
7. The method of claim 6, wherein one or more anatomical locations of M sample histological images in the first set of sample histological images are aligned to match one or more anatomical locations of N sample target histological images in the second set of sample target histological images, M and N being positive integers.
8. The method of claim 7, wherein the predictive model comprises data regarding one or more features indicative of one or more display characteristics and is trained by associating one or more features from the N sample target histological images with one or more features from the M sample histological images.
9. The method of claim 5, wherein the first unsupervised learning model is trained based on one or more features associated with the target region in the histological image.
10. The method of claim 5, wherein the first unsupervised learning model is trained based on one or more features associated with the target region in the histological image.
11. The method of claim 6, wherein each of the first unsupervised learning model, the second unsupervised learning model, and the predictive model comprises a multilayer model defined by one or more model hyperparameters and one or more weights of an artificial neural network.
12. An image processing device for processing a histological image captured by a medical imaging device, the image processing device comprising: a first autoencoder configured to: receive the histological image including at least one type of tissue; determine a candidate type of tissue in the histological image; and identify a target region corresponding to the candidate type of tissue in the histological image; and an image generating unit configured to: identify at least one target histological image corresponding to the target region in the histological image based on a predictive model associating one or more sample histological images with one or more sample target histological images; and apply one or more display characteristics associated with the identified at least one target histological image to the histological image.
13. The image processing device of claim 12, wherein the image generating unit is further configured to generate a modified image of the histological image including the applied display characteristics.
14. The image processing device of claim 12, wherein the first autoencoder is further configured to identify a plurality of regions comprising the target region in the histological image, wherein the predictive model comprises a first set of regions in each of the sample histological images and a second set of regions in each of the sample target histological images, wherein the first set of regions is associated with the second set of regions in the predictive model, and wherein the image generating unit is further configured to modify the plurality of regions in the received histological image based on the second set of regions in the identified at least one target histological image.
15. The image processing device of claim 12, wherein a first unsupervised learning model is generated by training the first autoencoder based on a first set of sample histological images.
16. The image processing device of claim 15, wherein the predictive model is generated based on the first unsupervised learning model and a second unsupervised learning model, and wherein the second unsupervised learning model is generated by training a second set of sample target histological images.
17. The image processing device of claim 16, wherein one or more anatomical locations of M sample histological images in the first set of sample histological images are aligned to match one or more anatomical locations of N sample target histological images in the second set of sample target histological images, M and N being positive integers.
18. A non-transitory computer-readable storage medium comprising instructions for processing a histological image, the instructions causing a processor of a computer to perform operations comprising: receiving the histological image including at least one type of tissue; determining a candidate type of tissue in the histological image; identifying a target region corresponding to the candidate type of tissue in the histological image; identifying at least one target histological image corresponding to the target region in the histological image based on a predictive model associating one or more sample histological images with one or more sample target histological images; and applying one or more display characteristics associated with the identified at least one target histological image to the histological image.
19. The medium of claim 18, wherein identifying the target region corresponding to the candidate type of tissue comprises identifying a plurality of regions comprising the target region in the histological image, wherein the predictive model comprises a first set of regions in each of the sample histological images and a second set of regions in each of the sample target histological images, wherein the first set of regions is associated with the second set of regions in the predictive model, and wherein applying one or more display characteristics comprises modifying the plurality of regions in the received histological image based on the second set of regions in the identified at least one target histological image.
20. The medium of claim 18, wherein the predictive model includes one or more features indicative of a plurality of display characteristics and is trained by associating one or more features from N sample target histological images in a second set of sample target histological images with one or more features from M sample histological images in a first set of sample histological images, M and N being positive integers.
</claims>
</document>
