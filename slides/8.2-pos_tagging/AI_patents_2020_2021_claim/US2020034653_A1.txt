<document>

<filing_date>
2019-10-01
</filing_date>

<publication_date>
2020-01-30
</publication_date>

<priority_date>
2017-03-28
</priority_date>

<ipc_classes>
G06F15/76,G06K9/00,G06K9/46,G06K9/62,G06K9/68,G06N20/00,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
FACEBOOK
</assignee>

<inventors>
COLLOBERT, RONAN STEFAN
DOLLAR, PIOTR
PINHEIRO, PEDRO HENRIQUE OLIVEIRA
</inventors>

<docdb_family_id>
63669645
</docdb_family_id>

<title>
GENERATING REFINED OBJECT PROPOSALS USING DEEP-LEARNING MODELS
</title>

<abstract>
In one embodiment, a feature map of an image having h×w pixels and a patch having one or more pixels of the image are received. The patch has been processed by a first set of layers of a convolutional neural network and contains an object centered within the patch. The patch is then processed using the feature map and one or more pixel classifiers of a classification layer of a deep-learning model, where the classification layer includes h×w pixel classifiers, with each pixel classifier corresponding to a respective pixel of the patch. Each of the pixel classifiers used to process the patch outputs a respective value indicating whether the corresponding pixel belongs to the object centered in the patch.
</abstract>

<claims>
1. A method comprising: receiving a feature map of an input image having h×w pixels; receiving a patch of the input image, wherein the patch contains an object centered within the patch; processing the patch using the feature map and a classification layer of a deep-learning model, wherein the classification layer comprises h×w pixel classifiers, each pixel classifier corresponding to a respective pixel of the patch; and outputting, by each of one or more of the h×w pixel classifiers, a value indicating whether the corresponding pixel belongs to the object centered in the patch.
2. The method of claim 1, wherein the feature map is represented by a first vector having no spatial dimensions.
3. The method of claim 1, wherein the pixel classifiers are locally connected.
4. The method of claim 1, wherein the pixel classifiers are fully connected.
5. The method of claim 1, further comprising: selecting a set of n×m pixel classifiers from among the h×w pixel classifiers; and processing the patch using the feature map and the selected set of n×m pixel classifiers.
6. The method of claim 5, further comprising: upsampling the respective output values of the selected set of n×m pixel classifiers to h×w.
7. The method of claim 1, wherein the deep-learning model comprises a convolutional neural network.
8. The method of claim 1, further comprising: processing a plurality of patches of the input image to generate, using a set of feature-extraction layers, the feature map of the input image.
9. The method of claim 1, further comprising: outputting, based on the respective value of each of the one or more h×w pixel classifiers, an object proposal for the object from among a plurality of objects in the input image
10. The method of claim 9, wherein the object proposal comprises a prediction of a location of the object in the patch.
11. The method of claim 10, further comprising: computing, using the feature map, a score for the object proposal, wherein the score indicates a likelihood that the patch contains the entire object.
12. One or more computer-readable non-transitory storage media embodying software that is operable when executed to: receive a feature map of an input image having h×w pixels; receive a patch of the input image, wherein the patch contains an object centered within the patch; process the patch using the feature map and a classification layer of a deep-learning model, wherein the classification layer comprises h×w pixel classifiers, each pixel classifier corresponding to a respective pixel of the patch; and output, by each of one or more of the h×w pixel classifiers, a value indicating whether the corresponding pixel belongs to the object centered in the patch.
13. The media of claim 12, wherein the feature map is represented by a first vector having no spatial dimensions.
14. The media of claim 12, wherein the software is further operable when executed to: select a set of n×m pixel classifiers from among the h×w pixel classifiers; and process the patch using the feature map and the selected set of n×m pixel classifiers.
15. The media of claim 14, wherein the software is further operable when executed to upsample the respective output values of the selected set of n×m pixel classifiers to h×w.
16. A system comprising: one or more processors; and a memory coupled to the processors comprising instructions executable by the processors, the processors operable when executing the instructions to: receive a feature map of an input image having h×w pixels; receive a patch of the input image, wherein the patch contains an object centered within the patch; process the patch using the feature map and a classification layer of a deep-learning model, wherein the classification layer comprises h×w pixel classifiers, each pixel classifier corresponding to a respective pixel of the patch; and output, by each of one or more of the h×w pixel classifiers, a value indicating whether the corresponding pixel belongs to the object centered in the patch.
17. The system of claim 16, wherein the feature map is represented by a first vector having no spatial dimensions.
18. The system of claim 16, wherein the pixel classifiers are locally connected or fully connected.
19. The system of claim 16, wherein the processors are further operable when executing the instructions to: select a set of n×m pixel classifiers from among the h×w pixel classifiers; and process the patch using the feature map and the selected set of n×m pixel classifiers.
20. The system of claim 19, wherein the processors are further operable when executing the instructions to upsample the respective output values of the selected set of n×m pixel classifiers to h×w.
</claims>
</document>
