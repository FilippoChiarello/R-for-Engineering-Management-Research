<document>

<filing_date>
2018-05-31
</filing_date>

<publication_date>
2020-04-30
</publication_date>

<priority_date>
2017-06-01
</priority_date>

<ipc_classes>
A61B3/00,A61B3/11,A61B3/14,A61B5/00,G06K9/00,G06N20/00,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
UNIVERSITY OF WASHINGTON
</assignee>

<inventors>
PATEL, SHWETAK, N.
BLY, RANDALL
LAW, ANTHONY
MARIAKAKIS, ALEX T.
BAUDIN, JACOB
MCGRATH, LYNN B.
</inventors>

<docdb_family_id>
64456168
</docdb_family_id>

<title>
SMARTPHONE-BASED DIGITAL PUPILLOMETER
</title>

<abstract>
In some embodiments, techniques for using machine learning to enable visible light pupilometry are provided. In some embodiments, a smartphone may be used to create a visible light video recording of a pupillary light reflex (PLR). A machine learning model may be used to detect a size of a pupil in the video recording over time, and the size over time may be presented to a clinician. In some embodiments, a system that includes a smartphone and a box that holds the smartphone in a predetermined relationship to a subject's face is provided. In some embodiments, a sequential convolutional neural network architecture is used. In some embodiments, a fully convolutional neural network architecture is used.
</abstract>

<claims>
1. A system, comprising: a mobile computing device comprising a camera, a light source, a display, and a non-transitory computer-readable medium, wherein the computer-readable medium has computer-executable instructions stored thereon which, in response to execution by at least one processor of the mobile computing device, cause the mobile computing device to perform actions comprising: initiating a video recording of at least one eye of a subject; activating and deactivating the light source during the video recording; ending the video recording; using a machine learning model to process the video recording to generate at least one dilation curve for the at least one eye; and presenting the at least one dilation curve on the display.
2. The system of claim 1, wherein the machine learning model includes at least a first convolutional neural network (CNN) configured to output an X coordinate of a pupil center and a Y coordinate of a pupil center and a second CNN configured to output a pupil diameter.
3. (canceled)
4. The system of claim 2, wherein using the machine learning model to generate at least one dilation curve includes: providing a down-sampled version of the video recording to the first CNN; cropping the video recording based on the X coordinate and the Y coordinate output by the first CNN; and providing the cropped video recording to the second CNN.
5. The system of claim 2, wherein at least one of the first CNN and the second CNN includes five convolutional layers and three fully connected layers.
6. The system of claim 5, wherein each convolutional layer includes a rectified linear (ReLU) activation function followed by 2×2 mean-pooling layers.
7. (canceled)
8. The system of claim 1, wherein the actions further comprise preprocessing the video recording before using the machine learning model, and wherein preprocessing the video recording includes: cropping out a bottom third of the video recording; splitting the video recording horizontally into a first video recording and a second video recording, wherein the first video recording depicts a right eye of the subject and the second video recording depicts a left eye of the subject; and horizontally flipping the first video recording or the second video recording.
9. The system of claim 1, wherein the actions further comprise preprocessing the video recording before using the machine learning model, and wherein preprocessing the video recording includes: converting the video recording to a hue, saturation, and lightness (HSL) color space if the video recording is not already in the HSL color space; applying contrast-limited adaptive histogram equalization (CLAHE) to the lightness channel of the video recording; and converting the video recording to grayscale.
10. The system of claim 1, further comprising a box configured to hold the mobile computing device in a fixed relationship to the at least one eye of the subject to screen out ambient light from the video recording, and to hold a filter over the light source of the mobile computing device.
11. (canceled)
12. The system of claim 1, wherein presenting the at least one dilation curve includes presenting the at least one dilation curve along with a baseline dilation curve to assist a diagnosis of a brain injury based on differences between the at least one dilation curve and the baseline.
13. The system of claim 1, wherein presenting the at least one dilation curve includes presenting a first dilation curve for a left eye along with a second dilation curve for a right eye to assist a diagnosis of a brain injury based on differences between the first dilation curve and the second dilation curve.
14. A non-transitory computer-readable medium having computer-executable instructions stored thereon that, in response to execution by one or more processors of a computing device, cause the computing device to perform actions for measuring changes in a size of a pupil over time in response to a light stimulus, the actions comprising: receiving, by the computing device, a video recording of an eye of a subject, wherein the video recording was recorded by a visible light camera; using, by the computing device, a machine learning model to detect changes in the size of a pupil of the eye during the video recording; and providing, by the computing device, the detected changes in the size of the pupil for presentation on a display.
15. 15-16. (canceled)
17. The computer-readable medium of claim 14, wherein using the machine learning model to detect changes in the size of the pupil of the eye during the video recording includes: providing a down-sampled version of the video recording to a first convolutional neural network (CNN) configured to output an X coordinate of a pupil center and a Y coordinate of a pupil center; cropping the video recording based on the X coordinate and the Y coordinate output by the first CNN; and providing the cropped video recording to a second CNN configured to output a pupil diameter.
18. 18-20. (canceled)
21. The computer-readable medium of claim 14, wherein the actions further comprise preprocessing the video recording before using the machine learning model, and wherein preprocessing the video recording includes: cropping out a bottom third of the video recording; splitting the video recording horizontally into a first video recording and a second video recording, wherein the first video recording depicts a right eye of the subject and the second video recording depicts a left eye of the subject; and horizontally flipping the first video recording or the second video recording.
22. The computer-readable medium of claim 14, wherein the actions further comprise preprocessing the video recording before using the machine learning model, and wherein preprocessing the video recording includes: converting the video recording to a hue, saturation, and lightness (HSL) color space if the video recording is not already in the HSL color space; applying contrast-limited adaptive histogram equalization (CLAHE) to the lightness channel of the video recording; and converting the video recording to grayscale.
23. 23-24. (canceled)
25. A non-transitory computer-readable medium having computer-executable instructions stored thereon that, in response to execution by one or more processors of at least one computing device, cause the at least one computing device to perform actions for generating and using a machine learning model to measure pupillary response for diagnosis of brain injury, the actions comprising: receiving, by the at least one computing device, training data comprising video recordings of eyes responding to light stimuli collected using one or more mobile computing devices; receiving, by the at least one computing device, tagging information indicating a location and a size of pupils in frames of each video recording; using, by the least one computing device, the training data and the tagging information to train a machine learning model to recognize pupil location and size in video frames; and storing, by the at least one computing device, the machine learning model on a mobile computing device.
26. (canceled)
27. The computer-readable medium of claim 25, wherein the machine learning model includes at least one convolutional neural network (CNN), and wherein the at least one CNN includes a first CNN configured to recognize a pupil location and a second CNN configured to determine a pupil diameter.
28. (canceled)
29. The computer-readable medium of claim 27, wherein the at least one CNN includes 5 convolutional layers and three fully connected layers.
30. The computer-readable medium of claim 27, wherein convolutional layers of the at last one CNN include a rectified linear (ReLU) activation function followed by 2×2 mean-pooling layers.
31. The computer-readable medium of claim 25, the actions further comprising preprocessing at least one of the training data and the experimental data.
32. The method of claim 31, wherein preprocessing includes one or more of: cropping the video recording; down-sampling the video recording; converting the video recording to a hue, saturation, and lightness (HSL) color space; applying contrast-limited adaptive histogram equalization (CLAHE) to a lightness channel of the video recording; and converting the video recording to grayscale.
33. 33-34. (canceled)
</claims>
</document>
