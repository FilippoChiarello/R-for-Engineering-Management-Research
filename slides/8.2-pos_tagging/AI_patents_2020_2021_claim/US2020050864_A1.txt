<document>

<filing_date>
2018-08-13
</filing_date>

<publication_date>
2020-02-13
</publication_date>

<priority_date>
2018-08-13
</priority_date>

<ipc_classes>
G06K9/00,G06K9/78,G06T7/80
</ipc_classes>

<assignee>
PLANGRID
</assignee>

<inventors>
ENCZ, BENJAMIN DENIS
MARTIN, RONALD STEVEN
NAYINI, ARJUN A.
</inventors>

<docdb_family_id>
69407242
</docdb_family_id>

<title>
Real-Time Location Tagging
</title>

<abstract>
Techniques for real-time location tagging are disclosed. A camera-enabled device presents an image of a physical space currently being captured by the camera-enabled device. Responsive to detecting user input while the image of the physical space is being captured by the camera-enabled device, the camera-enabled device tags a location in a plan of the physical space with information based at least in part on the user input.
</abstract>

<claims>
1. A non-transitory computer readable medium comprising instructions which, when executed by one or more hardware processors, cause performance of operations comprising: presenting an image of a physical space currently being captured by a camera-enabled device; responsive to detecting user input while the image of the physical space is being captured by the camera-enabled device: tagging a location in a plan of the physical space with information based at least in part on the user input.
2. The medium of claim 1, further comprising: determining that the user input is associated with a selected physical feature in the image; determining a feature location corresponding to the physical feature, based at least in part on a location of the camera-enabled device and a distance of the selected physical feature from the camera-enabled device; using the feature location as the location in the plan of the physical space.
3. The medium of claim 2, wherein determining the location comprises: determining a type of the selected physical feature; analyzing metadata associated with the plan to identify known physical features, of the type of the selected physical features, as a set of candidate physical features; selecting a candidate physical feature from the set of candidate physical features, based on the location of the camera-enabled device and the distance of the selected physical feature from the camera-enabled device; determining a known location of the candidate physical feature in the plan of the physical space; selecting the known location of the candidate physical feature as the location of the selected physical feature.
4. The medium of claim 1, the operations further comprising: cross-referencing the location with architectural metadata associated with the location.
5. The medium of claim 4, the operations further comprising: refining the location based at least in part on the architectural metadata.
6. The medium of claim 4, the operations further comprising: populating at least a portion of the information based on the architectural metadata.
7. The medium of claim 1, the operations further comprising: applying an image recognition process to the image; based on the image recognition process: populating at least a portion of the information.
8. The medium of claim 1, wherein the information comprises a category of work to be performed at the location.
9. The medium of claim 8, the operations further comprising: syncing the information to a separate device that is separate from the camera-enabled device; based at least in part on the information: managing, via the separate device, work to be performed at the location.
10. The medium of claim 1, the operations further comprising: recording the location as a point along a traveled path in the physical space.
11. The medium of claim 10, wherein recording the location is performed relative to a calibration point associated with the traveled path.
12. The medium of claim 11, wherein the calibration point is associated with a visual anchor, the operations further comprising: calibrating the camera-enabled device relative to the calibration point, at least by capturing the visual anchor via the camera-enabled device.
13. The medium of claim 10, wherein the path is associated with a plurality of timestamps, such that a plurality of timestamps indicate a direction and times at which the traveled path was traveled.
14. The medium of claim 10, the operations further comprising: based at least in part on the traveled path: performing an audit of work to be performed in the physical space.
15. The medium of claim 10, the operations further comprising: based at least in part on a relationship between an actual scale of the physical space and a reduced scale of the plan: transforming data that represents the traveled path, to obtain a transformed path representation; storing the transformed path representation in association with the plan.
16. The medium of claim 1, the operations further comprising: responsive to detecting that the location is being captured by a separate camera-enabled device: overlaying at least a portion of the information in a display of the separate camera-enabled device.
17. The medium of claim 1, wherein the information comprises user-provided audio input.
18. The medium of claim 1, wherein the information comprises user-provided text input.
19. A system comprising: at least one device including a hardware processor; the system being configured to perform operations comprising: presenting an image of a physical space currently being captured by a camera-enabled device; responsive to detecting user input while the image of the physical space is being captured by the camera-enabled device: tagging a location in a plan of the physical space with information based at least in part on the user input.
20. A method comprising: presenting an image of a physical space currently being captured by a camera-enabled device: responsive to detecting user input while the image of the physical space is being captured by the camera-enabled device: tagging a location in a plan of the physical space with information based at least in part on the user input, wherein the method is performed by at least one device comprising a hardware processor.
</claims>
</document>
