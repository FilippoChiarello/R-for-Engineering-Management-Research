<document>

<filing_date>
2018-12-19
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2018-12-19
</priority_date>

<ipc_classes>
B60W30/12,G05D1/00,G05D1/02,G06K9/00,G06N20/00,G06N3/08,G06N5/04
</ipc_classes>

<assignee>
CRUTCHLOW, SEAN
FCA US
WANG ZIJIAN
</assignee>

<inventors>
CRUTCHLOW, SEAN
WANG ZIJIAN
</inventors>

<docdb_family_id>
71096831
</docdb_family_id>

<title>
Using a long-term recurrent convolutional network to plan a sequence of lateral controls in autonomous driving
</title>

<abstract>
Systems and methods for planning and executing a sequence of lateral controls for a vehicle comprise determining a set of parameters comprising road lane lines, a pose of the vehicle, a movement state of the vehicle, and actions by a driver of the vehicle and, while operating the vehicle in an autonomous driving mode, obtaining a long-term recurrent convolutional network (LRCN) model that has been trained with training data captured during controlled test driving by a human driver, using the LRCN model and the set of parameters as inputs, determining a sequence of a plurality of desired steering wheel angles for the vehicle, and when the sequence of the plurality of desired steering wheel angles is verified via comparison to one or more mathematical models, controlling steering of the vehicle according to the sequence of a plurality of desired steering wheel angles.
</abstract>

<claims>
1. An advanced driver assistance system (ADAS) for a vehicle, the ADAS comprising: a set of sensors configured to determine a set of parameters comprising road lane lines, a pose of the vehicle, a movement state of the vehicle, and actions by a driver of the vehicle; and a controller configured to operate the vehicle in an autonomous driving mode and during the autonomous driving mode: receive the set of parameters from the set of sensors; obtain a long-term recurrent convolutional network (LRCN) model that has been trained with training data captured during controlled test driving by a human driver; using the LRCN model and the set of parameters as inputs, determine a sequence of a plurality of desired steering wheel angles for the vehicle; verify the sequence of the plurality of desired steering wheel angles based on a comparison to outputs of one or more mathematical models that each model a specific driving scenario; and when the sequence of the plurality of desired steering wheel angles is verified, control steering of the vehicle according to the sequence of a plurality of desired steering wheel angles.
2. The ADAS of claim 1, wherein the controller is further configured to apply a penalty to the sequence of steering wheel angles at consecutive time steps to smooth the control of the steering of the vehicle.
3. The ADAS of claim 1, wherein the controller does not utilize a deep neural network (DNN).
4. The ADAS of claim 1, wherein the set of sensors comprises a camera system configured to capture an image of a road on which the vehicle is traveling and detect lane lines on the road.
5. The ADAS of claim 1, wherein the pose of the vehicle comprises yaw, pitch, and roll of the vehicle.
6. The ADAS of claim 1, wherein the movement state of the vehicle comprises velocity, acceleration, road wheel angle, and angular acceleration of the vehicle.
7. The ADAS of claim 1, wherein the actions by the driver of the vehicle comprise steering wheel angle, throttle position, and brake pedal position.
8. The ADAS of claim 1, wherein the one or more mathematical models comprise Simulink models.
9. A method for planning and executing a sequence of lateral controls for a vehicle, the method comprising: determining, by a set of sensors of the vehicle, a set of parameters comprising road lane lines, a pose of the vehicle, a movement state of the vehicle, and actions by a driver of the vehicle; operating, by a controller of the vehicle, in an autonomous driving mode; and during the autonomous driving mode: receiving, by the controller and from the set of sensors, the set of parameters; obtaining, by the controller, a long-term recurrent convolutional network (LRCN) model that has been trained with training data captured during controlled test driving by a human driver; using the LRCN model and the set of parameters as inputs, determining, by the controller, a sequence of a plurality of desired steering wheel angles for the vehicle; verifying, by the controller, the sequence of the plurality of desired steering wheel angles based on a comparison to outputs of one or more mathematical models that each model a specific driving scenario; and when the sequence of the plurality of desired steering wheel angles is verified, controlling, by the controller, steering of the vehicle according to the sequence of a plurality of desired steering wheel angles.
10. The method of claim 9, wherein the set of sensors comprises a camera system configured to capture an image of a road on which the vehicle is traveling and detect lane lines on the road.
11. The method of claim 9, wherein the pose of the vehicle comprises yaw, pitch, and roll of the vehicle.
12. The method of claim 9, wherein the movement state of the vehicle comprises velocity, acceleration, road wheel angle, and angular acceleration of the vehicle.
13. The method of claim 9, wherein the actions by the driver of the vehicle comprise steering wheel angle, throttle position, and brake pedal position.
14. The method of claim 9, wherein the one or more mathematical models comprise Simulink models.
15. The method of claim 9, further comprising applying, by the controller, a penalty to the sequence of steering wheel angles at consecutive time steps to smooth the control of the steering of the vehicle.
16. The method of claim 9, wherein the controller does not utilize a deep neural network (DNN).
</claims>
</document>
