<document>

<filing_date>
2019-08-05
</filing_date>

<publication_date>
2020-05-27
</publication_date>

<priority_date>
2018-11-23
</priority_date>

<ipc_classes>
G06T13/40,G06T19/00
</ipc_classes>

<assignee>
SONY INTERACTIVE ENTERTAINMENT
</assignee>

<inventors>
CAPPELLO, FABIO
HUME, OLIVER
</inventors>

<docdb_family_id>
65024681
</docdb_family_id>

<title>
METHOD AND SYSTEM FOR DETERMINING IDENTIFIERS FOR TAGGING VIDEO FRAMES WITH
</title>

<abstract>
A method of determining identifiers for tagging frames of animation with is provided. The method comprises obtaining data indicating motion of an animated object in a plurality of frames and detecting the object as performing a pre-determined motion in at least some of the plurality of frames. For a given frame, it is determined based on the detected pre-determined motion, whether to associate an identifier with the pre-determined motion, the identifier indicating an event that is to be triggered in response to the pre-determined motion. The frames of the animation comprising the detected pre-determined motion are tagged, in response to a determination of an identifier. The pre-determined motion and corresponding identifier are determined by inputting the obtained data to machine learning model. A corresponding system is also provided.
</abstract>

<claims>
1. A method of determining identifiers for tagging frames of an animation with, the method comprising: obtaining data indicating motion of an animated object in a plurality of frames; detecting the object as performing a pre-determined motion in at least some of the plurality of frames; determining, for a given frame, based on the detected pre-determined motion, whether to associate an identifier with the pre-determined motion, the identifier indicating an event that is to be triggered in response to the pre-determined motion; tagging the frames of the animation comprising the detected motion responsive to the determination to associate an identifier; and wherein detecting the pre-determined motion and determining the corresponding identifier comprises inputting the obtained data to a machine learning model, the machine learning model being trained to map data indicating motion of an animated object to a corresponding identifier.
2. A method according to claim 1, wherein the determined identifier indicates at least one of: an audio event that is to be triggered in response to the detected pre-determined motion; and an in-game event that is to be triggered by a game engine, wherein the game engine is configured to receive the determined identifier.
3. A method according to claim 1 or 2, wherein the animated object comprises a computer-generated character; and
wherein detecting the pre-determined motion comprises detecting the character as performing one of a plurality of pre-determined motions.
4. A method according to claim 3, wherein the obtained data comprises pose data indicating a pose of the character; and
wherein detecting the pre-determined motion comprises determining whether a change in pose over successive frames corresponds to at least one of a plurality of pre-determined changes in pose.
5. A method according to claim 4, wherein the character comprises a plurality of bones defining a skeleton of the character; and
wherein the pose data comprises at least some of the bones of the character and the corresponding transforms, wherein each transform defines at least one of a position, scale and orientation of a respective bone.
6. A method according to claim 5, wherein detecting the pre-determined motion comprises detecting a change in the transforms of at least one of the bones over successive frames as corresponding to at least one of a plurality of pre-determined changes in transforms.
7. A method according to any of claims 4 to 6, wherein the model comprises a neural network, the neural network being configured to map changes in pose over successive frames to corresponding identifiers.
8. A method according to any preceding claim, wherein the identifier indicates an audio event associated with the detected motion, the method comprising: selecting, based on the determined identifier, a sound effect for synchronization with the frames tagged with the identifier; and synchronizing the selected sound effect with the tagged frames.
9. A method according to claim 8, comprising outputting audio-visual content comprising the tagged frames of the animated object and the synchronized sound effect at a computing device.
10. A computer program comprising computer-implemented instructions that, when run on a computer, cause the computer to implement the method of any of claims 1 to 9.
11. A system for tagging frames of an animation with respective identifiers, the system comprising: a motion unit configured to obtain data indicating motion of an animated object in a plurality of frames; a modelling unit configured to identify the object as performing a pre-determined motion in at least some of the frames and to determine, for a given frame, whether to associate an identifier with the pre-determined motion, the identifier indicating an event that is to be triggered in response to the identified pre-determined motion; wherein the modelling unit comprises a machine learning model trained to map data indicating motion of animated objects to corresponding identifiers; and a tagging unit configured to tag the frames of the animation comprising a pre-determined motion with a corresponding identifier, responsive to the determination to associate an identifier.
12. A system according to claim 11, wherein the animated object comprises a computer-generated character and the motion unit is configured to obtain pose data indicating a pose of the character over successive frames; and
wherein the modelling unit is configured to identify the object as performing at least one of a plurality of pre-determined motions based on changes in pose of the character over successive frames.
13. A system according to any of claims 11 to 12, wherein the pose data comprises bones defining a skeleton of the character and respective transforms of the bones; and
wherein the modelling unit is configured to detect the pre-determined motion based on a variation in the transforms of one or more bones, over successive frames.
14. A system according to any of claims 11 to 13, comprising: a storage unit for storing a plurality of sound effects; and a synchronization unit configured to select a sound effect from the storage unit for synchronizing with frames tagged with an identifier; wherein the synchronization unit is configured to select the sound effect based on the identifier with which the tagged frames are tagged; and wherein the synchronization unit is configured to synchronize the selected sound effect with the tagged frames.
15. A system according to claim 14, comprising an output unit, the output unit being configured to output audio-visual content, the audio-visual content comprising the tagged frames of the animated object and the synchronized sound effect.
</claims>
</document>
