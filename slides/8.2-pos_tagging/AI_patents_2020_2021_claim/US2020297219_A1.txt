<document>

<filing_date>
2019-03-18
</filing_date>

<publication_date>
2020-09-24
</publication_date>

<priority_date>
2019-03-18
</priority_date>

<ipc_classes>
A61B5/00,A61B5/02,A61B8/08,G06N20/00,G06N3/08
</ipc_classes>

<assignee>
GE (GENERAL ELECTRIC COMPANY)
</assignee>

<inventors>
MARINELLI, LUCA
MITRA, JHIMLI
Singanamalli, Asha
</inventors>

<docdb_family_id>
72515926
</docdb_family_id>

<title>
AUTOMATED DETECTION AND LOCALIZATION OF BLEEDING
</title>

<abstract>
In accordance with the present disclosure, deep-learning techniques are employed to find anomalies corresponding to bleed events. By way of example, a deep convolutional neural network or combination of such networks may be trained to determine the location of a bleed event, such as an internal bleed event, based on ultrasound data acquired at one or more locations on a patient anatomy. Such a technique may be useful in non-clinical settings.
</abstract>

<claims>
1. A method for training one or more neural networks for localization of bleed events, the method comprising: acquiring a plurality of data representations, wherein each data representation corresponds to a healthy region of vasculature; training at least one neural network using only the plurality of data representations to generate one or more trained neural networks, wherein the one or more trained neural networks are trained to generate, in response to an input data representation, a synthetic representation based on healthy vasculature, and to output one or more differences between the synthetic representation and the input data representation.
2. The method of claim 1, wherein each data representation corresponds to a healthy region of vasculature in which no bleeds are present.
3. The method of claim 1, wherein the input data representation and the data representations of the plurality of data representations are images.
4. The method of claim 1, wherein the input data representation and the data representations of the plurality of data representations are unreconstructed image data.
5. The method of claim 1, wherein the input data representation and the data representations of the plurality of data representations are one or more of Doppler ultrasound data, structural ultrasound data, or computed tomography structural data.
6. The method of claim 1, wherein the one or more differences correspond to bleed locations.
7. The method of claim 1, wherein training the at least one neural network comprises training the at least one neural network using a generative adversarial network to implement an unsupervised machine learning process.
8. A method for localizing a bleed event, the method comprising: receiving an input data representation as an input to a trained neural network; processing the input data representation using the trained neural network, wherein processing the input data representation comprises generating a synthetic representation based on healthy vasculature in response to the input data representation; identifying one or more differences between the synthetic representation and the input data representation; and determining the location of the bleed event using the one or more differences.
9. The method of claim 8, further comprising: providing the input data representation or a different input data representation to a different trained neural network; generating, on the different trained neural network, a different synthetic representation based on healthy vasculature in response to the input data representation or the different input data representation; identifying one or more additional differences between the different synthetic representation and the input data representation or the different input data representation; and determining the location of a bleed event using the one or more differences and the one or more additional differences.
10. The method of claim 9, wherein the trained neural network is trained to process reconstructed or unreconstructed Doppler ultrasound data and the different trained neural network is trained to process reconstructed or unreconstructed structural ultrasound data.
11. The method of claim 9, wherein determining the location of the bleed event comprises performing a weighted combination of the one or more differences and the one or more additional differences.
12. The method of claim 11, wherein the weighted combination is based on one or more probabilities associated with respective differences.
13. The method of claim 11, wherein the weighted combination is based on one or more threshold operations.
14. The method of claim 8, wherein the trained neural network is trained using unsupervised learning using only data representations of healthy vasculature.
15. The method of claim 8, further comprising: providing the location of the bleed event to a person to perform a treatment.
16. The method of claim 8, further comprising: providing the location of the bleed event to a treatment device to automatically perform a treatment.
17. A system for localizing bleed events, comprising: an ultrasound scanner configured to generate ultrasound data at one or more locations of a body of a patient; a memory component configured to store one or more processor-executable routines; and a processing component configured to receive or access the ultrasound data and to execute the one or more processor-executable routines, wherein the one or more routines, when executed by the processing component, cause the processing component to perform acts comprising: receiving respective input data representations as inputs to one or more trained neural networks; processing the respective input data representations using the one or more trained neural networks, wherein processing the respective input data representations comprises generating, on each trained neural network, a respective synthetic representation based on healthy vasculature in response to the respective input data representation; identifying one or more differences between each respective synthetic representation and the respective input data representation; and determining the location of a bleed event using the one or more differences.
18. The system of claim 17, wherein one of the one or more trained neural networks is trained to process reconstructed or unreconstructed Doppler ultrasound data and another of the trained neural networks is trained to process reconstructed or unreconstructed structural ultrasound data.
19. The system of claim 17, wherein determining the location of the bleed event comprises performing a weighted combination of the one or more differences from different trained neural networks.
20. The system of claim 17, wherein the one or more trained neural networks are trained using unsupervised learning using only data representations of healthy vasculature.
</claims>
</document>
