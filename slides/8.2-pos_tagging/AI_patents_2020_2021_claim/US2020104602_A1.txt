<document>

<filing_date>
2019-12-03
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-05-03
</priority_date>

<ipc_classes>
A01K61/10,A01K61/95,G06K9/00,G06T7/20,H04N5/232
</ipc_classes>

<assignee>
X DEVELOPMENT
</assignee>

<inventors>
JAMES, BARNABY JOHN
ATWATER, JOEL FRASER
MESSANA, MATTHEW
</inventors>

<docdb_family_id>
66669041
</docdb_family_id>

<title>
FISH MEASUREMENT STATION KEEPING
</title>

<abstract>
A fish monitoring system deployed in a particular area to obtain fish images is described. Neural networks and machine-learning techniques may be implemented to periodically train fish monitoring systems and generate monitoring modes to capture high quality images of fish based on the conditions in the determined area. The camera systems may be configured according to the settings, e.g., positions, viewing angles, specified by the monitoring modes when conditions matching the monitoring modes are detected. Each monitoring mode may be associated with one or more fish activities, such as sleeping, eating, swimming alone, and one or more parameters, such as time, location, and fish type.
</abstract>

<claims>
1. (canceled)
2. A computer-implemented method comprising: obtaining data that reflects current, sensed conditions associated with the fish pen; providing, to a model that is trained to output, for given, input parameters that reflect sensed conditions associated with a fish pen, a given set of output parameters for generating images of fish that are contained within the fish pen using one or more underwater cameras, particular parameters that reflect the current, sensed conditions associated with the fish pen; obtaining, from the model, a particular set of output parameters; and configuring the one or more underwater cameras based on the particular set of output parameters.
3. The method of claim 2, wherein the input parameters reflect a fish type, a fish activity type, a time or time range, a location within the fish pen, a water current within the fish pen, or a light level within the fish pen.
4. The method of claim 2, wherein the particular set of output parameters identifies a subset of the underwater cameras that are to be used to generate the images of the fish.
5. The method of claim 2, wherein the particular set of output parameters identifies one or more camera angles associated with the underwater cameras that are to be used to generate the images of the fish.
6. The method of claim 2, comprising training the model using machine learning.
7. The method of claim 2, wherein the particular set of output of output parameters specifies a particular mode of the one or more underwater cameras, selected from among multiple modes that are pre-associated with the one or more underwater cameras.
8. The method of claim 2, wherein configuring the one or more underwater cameras comprises adjusting an orientation of one or more of the underwater cameras with respect to the fish pen.
9. A system comprising: one or more computing devices and one or more storage devices that store instructions which, when executed by the one or more computing devices, cause the one or more computing devices to perform operations comprising: obtaining data that reflects current, sensed conditions associated with the fish pen; providing, to a model that is trained to output, for given, input parameters that reflect sensed conditions associated with a fish pen, a given set of output parameters for generating images of fish that are contained within the fish pen using one or more underwater cameras, particular parameters that reflect the current, sensed conditions associated with the fish pen; obtaining, from the model, a particular set of output parameters; and configuring the one or more underwater cameras based on the particular set of output parameters.
10. The system of claim 9, wherein the input parameters reflect a fish type, a fish activity type, a time or time range, a location within the fish pen, a water current within the fish pen, or a light level within the fish pen.
11. The system of claim 9, wherein the particular set of output parameters identifies a subset of the underwater cameras that are to be used to generate the images of the fish.
12. The system of claim 9, wherein the particular set of output parameters identifies one or more camera angles associated with the underwater cameras that are to be used to generate the images of the fish.
13. The system of claim 9, wherein the operations comprise training the model using machine learning.
14. The system of claim 9, wherein the particular set of output of output parameters specifies a particular mode of the one or more underwater cameras, selected from among multiple modes that are pre-associated with the one or more underwater cameras.
15. The system of claim 9, wherein configuring the one or more underwater cameras comprises adjusting an orientation of one or more of the underwater cameras with respect to the fish pen.
16. One or more non-transitory computer-readable storage media comprising instructions, which, when executed by one or more computing devices, cause the one or more computing devices to perform operations comprising: obtaining data that reflects current, sensed conditions associated with the fish pen; providing, to a model that is trained to output, for given, input parameters that reflect sensed conditions associated with a fish pen, a given set of output parameters for generating images of fish that are contained within the fish pen using one or more underwater cameras, particular parameters that reflect the current, sensed conditions associated with the fish pen; obtaining, from the model, a particular set of output parameters; and configuring the one or more underwater cameras based on the particular set of output parameters.
17. The media of claim 9, wherein the input parameters reflect a fish type, a fish activity type, a time or time range, a location within the fish pen, a water current within the fish pen, or a light level within the fish pen.
18. The media of claim 9, wherein the particular set of output parameters identifies a subset of the underwater cameras that are to be used to generate the images of the fish.
19. The media of claim 9, wherein the particular set of output parameters identifies one or more camera angles associated with the underwater cameras that are to be used to generate the images of the fish.
20. The media of claim 9, wherein the operations training the model using machine learning.
21. The media of claim 9, wherein the particular set of output of output parameters specifies a particular mode of the one or more underwater cameras, selected from among multiple modes that are pre-associated with the one or more underwater cameras.
</claims>
</document>
