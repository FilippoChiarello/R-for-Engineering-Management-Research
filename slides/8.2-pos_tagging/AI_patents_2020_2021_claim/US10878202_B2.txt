<document>

<filing_date>
2018-08-03
</filing_date>

<publication_date>
2020-12-29
</publication_date>

<priority_date>
2018-08-03
</priority_date>

<ipc_classes>
G06F40/56,G06F40/58,G10L15/08,G10L15/18,G10L15/26
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
ANDERSON, EVELYN R.
KEEN, MARTIN G.
BROOKS POWELL, NATALIE
CONLEY, KRISTEN
</inventors>

<docdb_family_id>
69228676
</docdb_family_id>

<title>
Natural language processing contextual translation
</title>

<abstract>
Ingesting user information from one or more forms of electronic communication. Parsing the ingested user information. Based on the parsed user information, one or more trigger words are determined. Receiving monitored audio of a surrounding environment. Transcribing the monitored audio into a textual format. Parsing the transcribed text. Identifying one or more trigger words. Determining a context of the one or more trigger words. Determining the context satisfies a user criteria. Translating the monitored audio in real-time.
</abstract>

<claims>
1. A method for dynamically utilizing natural language processing to display real-time translations, the method comprising: ingesting, by a natural language processor, user information; finding, by the natural language processor, one or more trigger words in the user information, comprising: determining one or more user information entities through parsing the user information; finding one or more first concepts within a respective portion of the one or more user information entities; establishing a relevance of each user information entity; establishing, subject to the established user information entity relevance, one or more of the first concepts as one or more trigger words; and storing the established trigger words; receiving, by utilizing one or more sensors to monitor audio, monitored audio of a surrounding environment within a predetermined proximity of a user; transcribing the monitored audio into a textual format; parsing, by a natural language processor, the transcribed text; identifying, based on the parsing of the transcribed text, one or more of the trigger words within the transcribed text; determining, by the natural language processor, a context of the one or more trigger words within the transcribed text, comprising: finding one or more of second concepts and the first concepts within a respective portion of the one or more transcribed text entities; determining one or more of the first concepts and the second concepts surrounding the identified trigger words; and establishing, subject to the concepts determination, a context of the identified one or more trigger words; determining that the context of the identified one or more trigger words satisfies a predetermined user criteria; and translating, in real-time, at least a portion of the monitored audio.
2. The method of claim 1, wherein: the user information is ingested from one or more forms of electronic communication within a social networking system; establishing a relevance of each user information entity comprises detecting correlations and linguistic links between the one or more user information entities; and the method further comprises: displaying, within a user interface, a notification to the user that includes a short summary describing the context and an option to view a translation of the monitored audio; receiving a user selection to translate the monitored audio; and displaying the translation within the user interface.
3. The method of claim 1, wherein monitoring the audio of the surrounding environment is performed by a plurality of audio recording devices embedded within an electronic device, the method further comprising: recording, by the plurality of microphones, audio within the predetermined proximity of the user; determining, by analyzing the recorded audio from the plurality of microphones; a geographic location of a source of the monitored audio, relative to the user, wherein the geographic location of the source is an indication of confidence of the trigger word and the context of the trigger word; prompting, within a user interface, an option to view the geographic location of the source; receiving, from the user, the option to view the geographic location; and displaying, within the user interface, the geographic location.
4. The method of claim 2, further comprising: continuing to display the translation within the user interface; receiving, from the user, a request to terminate the display of the translation; and terminating the display of the translation.
5. The method of claim 3, further comprising: receiving a request from the user to store the translation within a data corpus; storing the translation within the data corpus; and determining, based on the monitored audio, that a distance from the user and a source of the monitored audio satisfies a threshold.
6. The method of claim 1, wherein the determining that the context satisfies the predetermined user criteria further comprises: generating a knowledge graph based on the transcribed text, wherein the knowledge graph includes a first plurality of concept nodes representing a first plurality of content and a second plurality of concept nodes representing a second plurality of content, wherein edges between the first plurality of concept nodes and the second plurality of concept nodes represent links between the first plurality of content and the second plurality of content; and calculating a uniqueness score that is a numerical value for each concept node in the second plurality of concept nodes based on a number of edges between the first plurality of concept nodes and the second plurality of concept nodes, thereby determining a relatedness between the first plurality of concept nodes and the second plurality of concept nodes, and further according to the predetermined user criteria, wherein the first plurality of concept nodes is the transcribed text and the second plurality of concept nodes is the one or more trigger words.
7. The method of claim 6, wherein the predetermined user criteria are selected from a group consisting of a number of trigger words within the transcribed text, a weight of each trigger word, and a distance from the user to a source of the monitored audio.
8. A computer system for dynamically utilizing natural language processing to display real-time translations, a method comprising: one or more processors, one or more computer-readable memories, one or more computer-readable tangible storage medium, and program instructions stored on at least one of the one or more tangible storage medium for execution by at least one of the one or more processors via at least one of the one or more memories, wherein the computer system is capable of performing the method comprising: ingesting, by a natural language processor, user information; finding, by the natural language processor, one or more trigger words in the user information, comprising: determining one or more user information entities through parsing the user information; finding one or more first concepts within a respective portion of the one or more user information entities; establishing a relevance of each user information entity; establishing, subject to the established user information entity relevance, one or more of the first concepts as one or more trigger words; and storing the established trigger words; receiving, by utilizing one or more sensors to monitor audio, monitored audio of a surrounding environment within a predetermined proximity of a user; transcribing the monitored audio into a textual format; parsing, by a natural language processor, the transcribed text; identifying, based on the parsing of the transcribed text, one or more of the trigger words within the transcribed text; determining, by the natural language processor, a context of the one or more trigger words within the transcribed text, comprising: finding one or more of second concepts and the first concepts within a respective portion of the one or more transcribed text entities; determining one or more of the first concepts and the second concepts surrounding the identified trigger words; and establishing, subject to the concepts determination, a context of the identified one or more trigger words; determining that the context of the identified one or more trigger words satisfies a predetermined user criteria; and translating, in real-time, at least a portion of the monitored audio.
9. The computer system of claim 8, wherein: the user information is ingested from one or more forms of electronic communication within a social networking system; establishing a relevance of each user information entity comprises detecting correlations and linguistic links between the one or more user information entities; and the method further comprises: displaying, within a user interface, a notification to the user that includes a short summary describing the context and an option to view a translation of the monitored audio; receiving a user selection to translate the monitored audio; and displaying the translation within the user interface.
10. The computer system of claim 8, wherein monitoring the audio of the surrounding environment is performed by a plurality of audio recording devices embedded within an electronic device, the method further comprising: recording, by the plurality of microphones, audio within the predetermined proximity of the user; determining, by analyzing the recorded audio from the plurality of microphones; a geographic location of a source of the monitored audio, relative to the user, wherein the geographic location of the source is an indication of confidence of the trigger word and the context of the trigger word; prompting, within a user interface, an option to view the geographic location of the source; receiving, from the user, the option to view the geographic location; and displaying, within the user interface, the geographic location.
11. The computer system of claim 9, the method further comprising: continuing to display the translation within the user interface; receiving, from the user, a request to terminate the display of the translation; and terminating the display of the translation.
12. The computer system of claim 10, the method further comprising: receiving a request from the user to store the translation within a data corpus; storing the translation within the data corpus; and determining, based on the monitored audio, that a distance from the user and a source of the monitored audio satisfies a threshold.
13. The computer system of claim 8, wherein the determining that the context satisfies the predetermined user criteria further comprises: generating a knowledge graph based on the transcribed text, wherein the knowledge graph includes a first plurality of concept nodes representing a first plurality of content and a second plurality of concept nodes representing a second plurality of content, wherein edges between the first plurality of concept nodes and the second plurality of concept nodes represent links between the first plurality of content and the second plurality of content; and calculating a uniqueness score that is a numerical value for each concept node in the second plurality of concept nodes based on a number of edges between the first plurality of concept nodes and the second plurality of concept nodes, thereby determining a relatedness between the first plurality of concept nodes and the second plurality of concept nodes, and further according to the predetermined user criteria, wherein the first plurality of concept nodes is the transcribed text and the second plurality of concept nodes is the one or more trigger words.
14. The computer system of claim 13, wherein the predetermined user criteria are selected from a group consisting of a number of trigger words within the transcribed text, a weight of each trigger word, and a distance from the user to a source of the monitored audio.
15. A computer program product for dynamically utilizing natural language processing to display real-time translations, the computer program product comprising: one or more computer-readable storage medium and program instructions stored on at least one of the one or more tangible storage medium, the program instructions executable by a processor, the program instructions executable by a computer to perform a method comprising: ingesting, by a natural language processor, user information; finding, by the natural language processor, one or more trigger words in the user information, comprising: determining one or more user information entities through parsing the user information; finding one or more first concepts within a respective portion of the one or more user information entities; establishing a relevance of each user information entity; establishing, subject to the established user information entity relevance, one or more of the first concepts as one or more trigger words; and storing the established trigger words; receiving, by utilizing one or more sensors to monitor audio, monitored audio of a surrounding environment within a predetermined proximity of a user; transcribing the monitored audio into a textual format; parsing, by a natural language processor, the transcribed text; identifying, based on the natural language processor parsing the transcribed text, one or more trigger words within the transcribed text; determining, by the natural language processor, a context of the one or more trigger words within the transcribed text, comprising: finding one or more of second concepts and the first concepts within a respective portion of the one or more transcribed text entities; determining one or more of the first concepts and the second concepts surrounding the identified trigger words; and establishing, subject to the concepts determination, a context of the identified one or more trigger words; determining that the context of the identified one or more trigger words satisfies a predetermined user criteria; and translating, in real-time, at least a portion of the monitored audio.
16. The computer program product of claim 15, wherein: the user information is ingested from one or more forms of electronic communication within a social networking system; establishing a relevance of each user information entity comprises detecting correlations and linguistic links between the one or more user information entities; and the method further comprises: displaying, within a user interface, a notification to the user that includes a short summary describing the context and an option to view a translation of the monitored audio; receiving a user selection to translate the monitored audio; and displaying the translation within the user interface.
17. The computer program product of claim 15, wherein monitoring the audio of the surrounding environment is performed by a plurality of audio recording devices embedded within an electronic device, the method further comprising: recording, by the plurality of microphones, audio within the predetermined proximity of the user; determining, by analyzing the recorded audio from the plurality of microphones; a geographic location of a source of the monitored audio, relative to the user, wherein the geographic location of the source is an indication of confidence of the trigger word and the context of the trigger word; prompting, within a user interface, an option to view the geographic location of the source; receiving, from the user, the option to view the geographic location; and displaying, within the user interface, the geographic location.
18. The computer program product of claim 16, the method further comprising: continuing to display the translation within the user interface; receiving, from the user, a request to terminate the display of the translation; and terminating the display of the translation.
19. The computer program product of claim 17, the method further comprising: receiving a request from the user to store the translation within a data corpus; storing the translation within the data corpus; and determining, based on the monitored audio, that a distance from the user and a source of the monitored audio satisfies a threshold.
20. The computer program product of claim 15, wherein the determining that the context satisfies the predetermined user criteria further comprises: generating a knowledge graph based on the transcribed text, wherein the knowledge graph includes a first plurality of concept nodes representing a first plurality of content and a second plurality of concept nodes representing a second plurality of content, wherein edges between the first plurality of concept nodes and the second plurality of concept nodes represent links between the first plurality of content and the second plurality of content; and calculating a uniqueness score that is a numerical value for each concept node in the second plurality of concept nodes based on a number of edges between the first plurality of concept nodes and the second plurality of concept nodes, thereby determining a relatedness between the first plurality of concept nodes and the second plurality of concept nodes, and further according to the predetermined user criteria, wherein the first plurality of concept nodes is the transcribed text and the second plurality of concept nodes is the one or more trigger words.
</claims>
</document>
