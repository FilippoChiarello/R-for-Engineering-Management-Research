<document>

<filing_date>
2020-02-26
</filing_date>

<publication_date>
2020-09-22
</publication_date>

<priority_date>
2020-02-26
</priority_date>

<ipc_classes>
G06F9/38,G06K9/00,G06T15/00,G09B19/00,G09B5/06
</ipc_classes>

<assignee>
UNIVERSITY OF CENTRAL FLORIDA
</assignee>

<inventors>
INGRAHAM, KATHLEEN
Bousfield, Taylor
Donehower, Claire
Dieker, Lisa A.
Hughes, Charles
Vasquez, Eleazar
Hynes, Michael
</inventors>

<docdb_family_id>
72516935
</docdb_family_id>

<title>
Sensor-based complexity modulation for therapeutic computer-simulations
</title>

<abstract>
An apparatus is disclosed for developing routine and specific task competencies of an individual having an environmental anxiety disorder. The subject is tasked with an executive function wherein the subject is fully or partially immersed in a computer-simulated environment for a time-limited session. Real-time monitoring of the human subject is performed for a change in a sensor-derived, quantified anxiety level. Responsive to an increase in anxiety level, the computer-simulated environment modulates the sensory complexity of one or more features of the simulation wherein the human subject therapeutically develops proficiency in executive functions in increasingly complex environments.
</abstract>

<claims>
1. An apparatus for a therapeutic treatment of a human subject with environmental anxiety disorder, the system comprising: a control module comprising a computer processor communicatively coupled to a simulation data store, the simulation data store having machine-readable values for computer-generated features in a computer-simulated environment in which the human subject is immersed and tasked to perform an executive function whereby a increase in anxiety state by the human subject hinders successful completion of the executive function, the computer-generated features include visual objects and an audio output; a rendering module communicatively coupled to the control module; the rendering module is further communicatively coupled to a graphic processing unit (GPU) that generates the visual objects in the computer-simulated environment; a visual display device communicatively coupled to the rendering module and the GPU, the visual display device displaying the visual objects in the computer-simulated environment; an array of sensory variables accessible by the rendering module, the sensory variables quantifying an amount of visual information generated by the rendering module and presented in the computer-simulated environment, the sensory variables selected from the group consisting of polygon count of rendered objects in the environment, lighting complexity of the environment, texture complexity of rendered objects in the environment and rendered frames-per-second; a sensing module communicatively coupled to the control module and at least one or more digital sensors, the sensing module receiving non-transitory data signals from the digital sensors indicative of a physiological parameter of the human subject and quantifying a real-time anxiety value of the human subject from the data signals indicative of the physiological parameter, the real-time anxiety value readable by the control module; an anxiety threshold datastore communicatively coupled to the control module, the anxiety threshold datastore storing an upper anxiety state value constant representing a physiological diminished capability of performing executive functions, the anxiety threshold datastore also storing a lower anxiety state value constant associated with a low physiological anxiety state whereby executive functions may be successfully performed with additional stress-induced anxiety; an anxiety threshold function operable on the control module, the anxiety threshold function receiving the real-time anxiety value of the human subject, the upper anxiety value constant and the lower anxiety value constant whereby the anxiety threshold function returns a low result responsive to the real-time anxiety value of the human subject being less than the lower anxiety value; a high result responsive to the real-time anxiety value of the human subject being greater than the upper anxiety value; and an inbounds result responsive to the real-time anxiety value of the human subject being above the lower anxiety value and less than the upper anxiety value; whereby responsive to a low result returned from the anxiety threshold function, the control module instructs the rendering module to increase the values of the sensory variables to thereby increase the amount of visual information generated by the rendering module and presented within the computer-simulated environment; responsive to a high result returned from the anxiety threshold function, the control module instructs the rendering module to decrease the values of the sensory variables to thereby decrease the amount of visual information generated by the rendering module and presented within the computer-simulated environment; and responsive to an inbounds result returned from the anxiety threshold function, the control module instructs the rendering module to maintain substantially the same values of the sensory variables to thereby sustain the same amount of visual information generated by the rendering module and presented within the computer-simulated environment; whereby the human subject therapeutically develops proficiency in the executive function by optimizing the amount of visual information presented within the computer-simulated environment to sufficiently challenge the human subject by increasing visual information rendered in the computer-simulated environment without detrimentally overloading the human subject with excessive visual information that prevents them from performing the executive function.
2. The apparatus of claim 1 wherein the physiological parameter detectable by the at least one or more sensors is selected from the group consisting of facial tracking, body movement, body temperature, pulse rate, respiratory rate, eye movement, and speech patterns.
3. The apparatus of claim 1 further comprising an executive function evaluation module communicatively coupled to the control module, the executive function evaluation module providing real-time quantitative values on a competency level of the human subject performing the executive function wherein, responsive to a quantitative value of competency level of the human subject performing the executive function the control module automatically instructs the rendering module to increase the values of the sensory variables to thereby increase the amount of visual and audible information generated by the rendering module presented within the computer-simulated environment.
4. The apparatus of claim 3 wherein the executive function evaluation module measures dexterity with physical objects by the human subject to derive its real-time quantitative values.
5. The apparatus of claim 3 wherein the executive function evaluation module measures comprehension of information presented in the computer-simulated environment by movement of physical objects by the human subject.
6. The apparatus of claim 3 wherein the executive function evaluation module measures comprehension by entries on a computing device made by the human subject responsive to prompts presented in the computer-simulated environment.
7. The apparatus of claim 1 wherein the visual display device is selected from the group consisting of single panel display monitors, multi-panel display monitors, rear projection displays, front projection displays, head-mounted virtual reality displays, and head-mounted augmented reality displays.
8. The apparatus of claim 1 further comprising an audio processing unit (APU) communicatively coupled to the rendering module, the APU generates the audio output in the computer-simulated environment.
9. The apparatus of claim 1 wherein the digital sensors are selected from the group consisting of cameras, radar, thermometers, heart rate monitor, pulse-oximeters, and microphones.
10. The apparatus of claim 1 wherein the rendering module generates a computer-generated simulation of a classroom.
11. The apparatus of claim 1 wherein the rendering module generates a computer-generated simulation of a workplace.
12. The apparatus of claim 1 wherein the rendering module generates a computer-generated simulation of a vehicle.
13. The apparatus of claim 1 wherein the rendering module generates a computer-generated simulation of a battlefield.
14. The apparatus of claim 1 wherein the rendering module generates a computer-generated simulation of a hospital.
15. The apparatus of claim 1 wherein the rendering module generates a computer-generated simulation of an athletic event.
</claims>
</document>
