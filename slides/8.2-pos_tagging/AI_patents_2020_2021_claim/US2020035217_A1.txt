<document>

<filing_date>
2019-10-04
</filing_date>

<publication_date>
2020-01-30
</publication_date>

<priority_date>
2019-08-08
</priority_date>

<ipc_classes>
G10L13/033,G10L13/04,G10L13/047,G10L15/16,G10L15/18,G10L15/22
</ipc_classes>

<assignee>
LG ELECTRONICS
</assignee>

<inventors>
CHAE, JONG HOON
</inventors>

<docdb_family_id>
67775151
</docdb_family_id>

<title>
METHOD AND DEVICE FOR SPEECH PROCESSING
</title>

<abstract>
Disclosed are a speech processing method and a speech processing device, for performing speech processing by executing artificial intelligence (AI) algorithms and/or machine learning algorithms installed thereon, thus enabling the communication between a user terminal and a server in a 5G communication environment. The speech processing method according to an embodiment of the present disclosure includes receiving a user spoken utterance, outputting a voice actor spoken utterance in a voice actor's voice having the highest degree of similarity with a user's voice by using a user-voice actor mapping learning model, the voice actor spoken utterance corresponding to the user spoken utterance, and performing speech recognition for the voice actor spoken utterance.
</abstract>

<claims>
1. A speech processing method, comprising: receiving a user spoken utterance; outputting, in a voice actor's voice having the highest degree of similarity with a user voice, a voice actor spoken utterance corresponding to the user spoken utterance by using a user-voice actor mapping learning model; and performing speech recognition for the voice actor spoken utterance.
2. The speech processing method of claim 1, further comprising generating the user-voice actor mapping learning model prior to outputting the voice actor spoken utterance by using the user-voice actor mapping learning model, wherein the generating the user-voice actor mapping learning model comprises: determining a voice actor's voice having the highest degree of similarity with the user spoken utterance through comparison between characteristics information of the user spoken utterance and characteristics information of a plurality of voice actors' voices previously established in database; receiving a user utterance text obtained by converting the user spoken utterance to text; generating a voice actor spoken utterance obtained by synthesizing the user utterance text with the voice actor's voice having the highest degree of similarity with the user spoken utterance; training a deep neural network model by using the user spoken utterance and the voice actor spoken utterance as a training dataset; and storing the user-voice actor mapping learning model, wherein the user-voice actor mapping learning model, through training the deep neural network, outputs the user spoken utterance as the voice actor spoken utterance being uttered in the voice actor's voice having the highest degree of similarity with the user voice.
3. The speech processing method of claim 2, further comprising, prior to determining the voice actor's voice having the highest degree of similarity with the user spoken utterance, generating the characteristics information, which includes at least one of tone, accent, gender, pitch, speed, or age of the user spoken utterance, by analyzing the user spoken utterance.
4. The speech processing method of claim 3, wherein the determining the voice actor's voice having the highest degree of similarity with the user spoken utterance comprises determining the voice actor's voice having the highest degree of similarity with the user spoken utterance through comparison between characteristics information including at least one of tone, accent, gender, pitch, speed, or age of the user spoken utterance and characteristics information including at least one of tone, accent, gender, pitch, speed, or age of the plurality of voice actors' voices previously established in the database.
5. The speech processing method of claim 3, wherein the determining the voice actor's voice having the highest degree of similarity with the user spoken utterance comprises: extracting a characteristics vector of the user spoken utterance; comparing the characteristics vector of the user spoken utterance to each of characteristics vectors of the plurality of voice actors' voices previously established in the database; and determining a characteristics vector of a voice actor's voice having the highest degree of similarity with the characteristics vector of the user spoken utterance based on a result of comparing.
6. The speech processing method of claim 1, wherein the performing the speech recognition for the voice actor spoken utterance comprises: once the voice actor spoken utterance determined as corresponding to the user spoken utterance is outputted by executing the user-voice actor mapping learning model, generating a voice actor utterance text obtained by converting the voice actor spoken utterance to text; learning speech intent of the voice actor spoken utterance by performing syntactic analysis or semantic analysis on the voice actor utterance text; generating a response text by using a knowledge base corresponding to the speech intent; and converting the response text to a response spoken utterance in the form of natural language speech to output the response spoken utterance.
7. The speech processing method of claim 1, further comprising determining whether to execute the user-voice actor mapping learning model on the basis of a predetermined condition.
8. The speech processing method of claim 7, wherein the determining whether to execute the user-voice actor mapping learning model comprises: on the basis of characteristics information of the user spoken utterance, executing the user-voice actor mapping learning model to monitor outputting of the voice actor spoken utterance determined as corresponding to the user spoken utterance; generating a voice actor utterance text obtained by converting the voice actor spoken utterance to text, learning speech intent of the voice actor spoken utterance by performing syntactic analysis or semantic analysis on the voice actor utterance text, generating a response text using a knowledge base corresponding to the speech intent, and monitoring a state in which where the response text is converted to and outputted as a response spoken utterance in the form of natural language speech; assessing speech recognition success/failure by monitoring user reaction information in response to outputting of the response spoken utterance; withholding execution of the user-voice actor mapping learning model if a speech recognition success rate is less than a reference value, wherein the speech recognition success rate is obtained by digitizing the speech recognition success/failure; and applying execution of the user-voice actor mapping learning model if the speech recognition success rate is greater than or equal to the reference value.
9. The speech processing method of claim 8, wherein the assessing the speech recognition success/failure comprises assessing the speech recognition success/failure by monitoring the user reaction information from one or more user image information obtained using a camera within a predetermined time or user speech information obtained using a microphone within a predetermined time, after outputting of the response spoken utterance.
10. The speech processing method of claim 8, wherein the withholding execution of the user-voice actor mapping learning model comprises: generating a user utterance text obtained by converting the user spoken utterance to text; learning a speech intent of the user spoken utterance by performing syntactic analysis or semantic analysis on the user utterance text; generating a response text by using a knowledge base corresponding to the speech intent; and converting the response text to a response spoken utterance in the form of natural language speech to output the response spoken utterance.
11. A speech processing device, comprising: a receiver receiving a user spoken utterance; a processor outputting a voice actor spoken utterance in a voice actor's voice having the highest degree of similarity with a user voice by using a user-voice actor mapping learning model, the voice actor spoken utterance corresponding to the user spoken utterance; and a speech recognizer performing speech recognition for the voice actor spoken utterance.
12. The speech processing device of claim 11, further comprising a generator for generating the user-voice actor mapping learning model prior to outputting the voice actor spoken utterance by using the user-voice actor mapping learning model, wherein the generator is configured to: determine the voice actor's voice having the highest degree of similarity with the user spoken utterance through comparison between characteristics information of the user spoken utterance and characteristics information of a plurality of voice actors' voices previously established in a database; receive a user utterance text obtained by converting the user spoken utterance to text; generate a voice actor spoken utterance obtained by synthesizing the user utterance text with the voice actor's voice having the highest degree of similarity with the user spoken utterance; train a deep neural network model by using the user spoken utterance and the voice actor spoken utterance as a training dataset; and store the user-voice actor mapping learning model, wherein the user-voice actor mapping learning model outputs, through training the deep neural network, the user spoken utterance as the voice actor spoken utterance, the voice actor spoken utterance uttered in the voice actor's voice having the highest degree of similarity with the user spoken utterance.
13. The speech processing device of claim 12, wherein the generator is configured to generate characteristics information including at least one of tone, accent, gender, pitch, speed, or age of the user spoken utterance, by analyzing the user spoken utterance prior to determining the voice actor's voice having the highest degree of similarity with the user spoken utterance.
14. The speech processing device of claim 13, wherein the generator is configured to, when determining the voice actor spoken utterance having the highest degree of similarity with the user spoken utterance, determine the voice actor's voice having the highest degree of similarity with the user spoken utterance by comparing the characteristics information including at least one of tone, accent, gender, pitch, speed, or age of the user spoken utterance, to the characteristics information including at least one of tone, accent, gender, pitch, speed, or age of the plurality of voice actors' voices previously established in the database.
15. The speech processing device of claim 13, wherein the generator is configured to, when determining the voice actor's voice having the highest degree of similarity with the user spoken utterance: extract a characteristics vector of the user spoken utterance; compare the characteristics vector of the user spoken utterance to each of characteristics vectors of the plurality of voice actors' voices previously established in the database; and determine a characteristics vector of a voice actor's voice, having the highest degree of similarity with the characteristics vector of the user spoken utterance based on a result of comparing.
16. The speech processing device of claim 11, wherein the speech recognizer comprises: an auto-speech recognizer generating a voice actor utterance text obtained by converting the voice actor spoken utterance to text when a voice actor spoken utterance determined as corresponding to the user spoken utterance is outputted by executing the user-voice actor mapping learning model; a natural language processor learning speech intent of the voice actor spoken utterance by performing syntactic analysis or semantic analysis on the voice actor utterance text; a natural language generator generating a response text by using a knowledge base corresponding to the speech intent; and a text-to-speech converter converting the response text to a response spoken utterance in the form of natural language speech to output the response spoken utterance.
17. The speech processing device of claim 11, further comprising a determiner determining whether to execute the user-voice actor mapping learning model on the basis of a predetermined condition.
18. The speech processing device of claim 17, wherein the determiner is configured to: Monitor, on the basis of the characteristics information of the user spoken utterance, outputting of the voice actor spoken utterance determined as corresponding to the user spoken utterance by executing the user-voice actor mapping learning model; generate a voice actor utterance text obtained by converting the voice actor spoken utterance to text, learn speech intent of the voice actor spoken utterance by performing syntactic analysis or semantic analysis on the voice actor utterance text, generate a response text by using a knowledge base corresponding to the speech intent, and monitor a state in which the response text is converted to and outputted as a response spoken utterance in the form of natural language speech; assess speech recognition success/failure by monitoring user reaction information in response to outputting of the response spoken utterance; withhold execution of the user-voice actor mapping learning model if a speech recognition success rate is less than a reference value, the speech recognition success rate being obtained by digitizing the speech recognition success/failure; and apply execution of the user-voice actor mapping learning model if the speech recognition success rate is greater than or equal to the reference value.
19. The speech processing device of claim 18, wherein the determiner is configured to assess the speech recognition success/failure by monitoring the user reaction information from one or more of user image information obtained using a camera within a predetermined time or user speech information obtained using a microphone within a predetermined time, after outputting of the response spoken utterance.
20. The speech processing method of claim 18, wherein the determiner is configured to: generate a user utterance text obtained by converting the user spoken utterance to text when withholding execution of the user-voice actor mapping learning model; learn speech intent of the user spoken utterance by performing syntactic analysis or semantic analysis on the user utterance text; generate a response text by using a knowledge base corresponding to the speech intent; and convert the response text to a response spoken utterance in the form of natural language speech to output the response spoken utterance.
</claims>
</document>
