<document>

<filing_date>
2019-08-16
</filing_date>

<publication_date>
2020-02-20
</publication_date>

<priority_date>
2018-08-17
</priority_date>

<ipc_classes>
A61B5/00,G06N3/04,G06N3/08,G16H30/20
</ipc_classes>

<assignee>
INVENTIVE GOVERNMENT SOLUTIONS
</assignee>

<inventors>
KULHARE, SOURABH
MEHANIAN, COUROSH
WILSON, BENJAMIN, K.
ZHENG, XINLIANG
</inventors>

<docdb_family_id>
69524194
</docdb_family_id>

<title>
AUTOMATED ULTRASOUND VIDEO INTERPRETATION OF A BODY PART, SUCH AS A LUNG, WITH ONE OR MORE CONVOLUTIONAL NEURAL NETWORKS SUCH AS A SINGLE-SHOT-DETECTOR CONVOLUTIONAL NEURAL NETWORK
</title>

<abstract>
In an embodiment, an intelligent system includes an electronic circuit configured to execute a neural network, to detect at least one feature in an image of a body portion while executing the neural network, and to determine a respective position and a respective class of each of the detected at least one feature while executing the neural network. For example, such a system can execute a neural network to detect at least one feature in an image of a lung, to determine a respective position within the image of each detected feature, and to classify each of the detected features as one of the following: A-line, B-line, pleural line, consolidation, and pleural effusion.
</abstract>

<claims>
1. A method, comprising:
receiving an image of a body portion;
detecting, with a neural network, at least one feature in the image; and
determining, with the neural network, a respective position and a respective class of each of the detected at least one feature.
2. The method of claim 1 wherein the image of the body portion includes an image of a lung.
3. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes:
determining a respective probability that the feature belongs to the respective class; and determining that the feature belongs to the respective class in response to the respective probability being greater than a threshold for the respective class.
4. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes:
determining probabilities that the detected at least one feature belongs to respective
classes; and
determining that the feature belongs to the one of the respective classes corresponding to the highest one of the probabilities. 5. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes an A4ine.
6. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural line.
7. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural effusion.
8. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a B-line.
9. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes merged B-lines.
10. The method of claim 1, further comprising:
detecting, with the neural network, at least one respective feature in each of multiple ones of the image and at least one other image of the body portion;
determining, with the neural network, that each of the detected at least one respective feature is a respective detected B-line, and a respective position of each of the detected B-lines;
grouping the detected B-lines in at least one cluster in response to the respective positions of the detected B-lines, each cluster corresponding to a respective actual B-line; and
determining, with the neural network, a respective position of each actual B-line in
response to a corresponding one of the at least one cluster.
11. The method of claim 1, further comprising:
detecting, with the neural network, at least one respective feature in each of multiple ones of the image and at least one other image of the body portion;
determining, with the neural network, that each of the detected at least one respective feature belongs to a same class, and a respective position of each of the detected at least one of the respective feature;
grouping the detected features in at least one cluster in response to the respective positions of the detected features, each cluster corresponding to a respective actual feature; and
determining, with the neural network, a respective position of each actual feature in
response to a corresponding one of the at least one cluster.
12. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a consolidation.
13. The method of claim 1, further comprising:
wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural effusion; and
determining a severity of the pleural effusion.
14. The method of claim 1, further comprising:
wherein the image of the body portion includes an image of a lung; and
diagnosing a pathology of the lung in response to the respective determined class of each of the detected at least one feature.
15. The method of claim 1, further comprising:
wherein the image of the body portion includes an image of a lung; and
diagnosing a pathology of the lung in response to the respective position and to the
respective determined class of each of the detected at least one feature.
16. A method, comprising:
receiving an image of a body portion; and
determining, with a classifier neural network, a probability that the image includes a
feature belonging to a particular class.
17. A method, comprising:
receiving each of an image of a body portion and at least one modified version of the image with a respective input channel of a neural network;
detecting, with the neural network, at least one feature in the image in response to the image and the at least one modified version of the image; and
determining, with the neural network, a respective position and a respective class of each of the detected at least one feature in response to the image and the at least one modified version of the image.
18. The method of claim 17 wherein the image of the body portion includes an image of a lung.
19. The method of claim 17 wherein determining a respective class of each of the detected at least one feature includes:
determining a respective probability that the feature belongs to the respective class; and determining that the feature belongs to the respective class in response to the respective probability being greater than a threshold for the respective class.
20. The method of claim 17 wherein determining a respective class of each of the detected at least one feature includes:
determining probabilities that the detected at least one feature belongs to respective
classes; and
determining that the feature belongs to the one of the respective classes corresponding to the highest one of the probabilities.
21. The method of claim 17 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes an A-line.
22. The method of claim 17 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural line. 23. The method of claim 17 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural effusion.
24. The method of claim 17 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a B-line.
25. The method of claim 17 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes merged B-lines.
26. The method of claim 17 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a consolidation.
27. The method of claim 17, further comprising:
wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural effusion; and
determining a severity of the pleural effusion.
28. The method of claim 17, further comprising:
wherein the image of the body portion includes an image of a lung; and
diagnosing a pathology of the lung in response to the respective determined class of each of the detected at least one feature.
29. The method of claim 17, further comprising:
wherein the image of the body portion includes an image of a lung; and
diagnosing a pathology of the lung in response to the respective position and to the
respective determined class of each of the detected at least one feature.
30. A method, comprising:
detecting at least one feature in an image of a body portion with a neural network
configured to detect, in the image, at least one feature belonging to a class; and determining, with the neural network, for each of the detected at least one feature, a
respective position and a respective confidence level that the respective one of the detected at least one feature belongs to the class.
31. The method of claim 30, further comprising:
wherein detecting includes detecting, with the neural network, the at least one feature in the image in response to at least one modified version of the image; and wherein determining includes determining, with the neural network, for each of the
detected at least one feature, the respective position and the respective confidence level in response to the at least one modified version of the image.
32. The method of claim 30, further comprising: wherein detecting includes detecting, with the neural network, the at least one feature in the image in response to the image and at least one modified version of the image; and
wherein determining includes determining, with the neural network, for each of the
detected at least one feature, the respective position and the respective confidence level in response to the image and the at least one modified version of the image.
33. A method, comprising:
generating, from each of at least one first training image, at least one second training
image;
determining, with a neural network, a respective probability that each of at least one
feature in at least one of the at least one first training image and the at least one second training image belongs to a feature class;
determining, for each of the detected at least one feature, a probability difference between the determined respective probability and a corresponding annotated probability; and
changing a respective weighting of each of at least one synapse of the neural network in response to the probability difference.
34. The method of claim 33, further comprising:
detecting, with the neural network, each of the at least one feature;
determining a respective location of each of the detected at least one feature;
determining, for each of the detected at least one feature, a location difference between the determined respective location and a corresponding annotated location; and wherein changing a respective weighting of each of at least one synapse of the neural network includes changing the respective weighting in response to the location difference.
35. The method of claim 33, further comprising:
repeating determining a respective probability, determining a probability difference, and changing a respective weighting for at least one iteration, for one or more additional iterations;
generating, after each iteration, a respective training model for the neural network; and configuring the neural network in response to the one of the training models that yields a highest value of a metric.
36. The method of claim 33, further comprising:
repeating determining a respective probability, determining a probability difference, and changing a respective weighting for at least one iteration, for one or more additional iterations;
generating, after each iteration, a respective training model for the neural network; and configuring the neural network in response to the one of the training models that yields a highest value of a weighted Fl metric. 37. The method of claim 33, further comprising:
repeating determining a respective probability, determining a probability difference, and changing a respective weighting for at least one iteration, for one or more additional iterations;
generating, after each iteration for which the probability difference is less than or equal to a threshold, a respective training model for the neural network; and
configuring the neural network in response to the one of the training models that yields a highest value of a metric.
38. A system, comprising:
an electronic circuit configured
to execute a neural network;
to detect at least one feature in an image of a body portion while executing the neural network; and
to determine a respective position and a respective class of each of the detected at least one feature while executing the neural network. 39. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by:
determining probabilities that the detected at least one feature belongs to respective
classes; and determining that the feature belongs to the one of the respective classes corresponding to the highest one of the probabilities.
40. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes an A-line.
41. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes a pleural line.
42. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes a pleural effusion. 43. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes a B-line.
44. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes merged B-lines.
45. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured:
to receive at least one other image of the body portion;
to detect at least one respective feature in each of multiple ones of the images;
to determine which of the detected at least one respective feature is a respective detected B-line, and a respective position of each of the detected B-lines; to group multiple detected B-lines in at least one cluster in response to the respective positions of the detected B-lines, each cluster corresponding to a respective actual B-line; and
to determine a respective position of each actual B-line in response to a corresponding one of the at least one cluster.
46. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining that at least one of the detected at least one feature includes a consolidation. 47. The system of claim 38 wherein the electronic circuit, while executing the neural network, is configured:
to determine a respective class of each of the detected at least one feature by determining that at least one of the detected at least one feature includes a pleural effusion; and to determine a severity of the pleural effusion. 48. The system of claim 38 wherein:
the image of the body portion includes an image of a lung; and
the electronic circuit is configured to diagnose a pathology of the lung in response to the respective determined class of each of the detected at least one feature.
49. The system of claim 38 wherein:
the image of the body portion includes an image of a lung; and
the electronic circuit is configured to diagnose a pathology of the lung in response to the respective position and to the respective determined class of each of the detected at least one feature.
50. A system, comprising:
an electronic circuit configured
to execute a classifier neural network,
to receive, while executing the classifier neural network, an image of a body
portion, and to determine, while executing the classifier neural network, a probability that the image indicates a state of a function of the body portion, the function belonging to a particular class.
51. The system of claim 50 wherein the electronic circuit is configured:
to receive, while executing the classifier neural network, a time sequence of images of the body portion, the time sequence of images including the image; and
to determine, while executing the classifier neural network, the probability that the images indicate the state of the function of the body portion.
52. The system of claim 50 wherein the electronic circuit is configured:
to receive, while executing the classifier neural network, a video of the body portion, the video including the image; and
to determine, while executing the classifier neural network, the probability that the video indicates the state of the function of the body portion.
53. The system of claim 50 wherein the image includes an M-mode image. 54. The system of claim 50 wherein the body portion includes a lung and the function is lung sliding.
55. The system of claim 50 wherein the particular class is lung sliding.
56. The system of claim 50, wherein the electronic circuit, while executing the neural network, is configured to determine that the image indicates a state of a function belonging to the particular class in response to the probability being greater than or equal to a threshold.
57. A system, comprising:
an electronic circuit configured to execute a neural network having input channels, and, while executing the neural network, configured
to receive each of an image of a body portion and at least one modified version of the image with a respective input channel,
to detect at least one feature in the image in response to the image and the at least one modified version of the image; and to determine a respective position and a respective class of each of the detected at least one feature in response to the image and the at least one modified version of the image.
58. The system of claim 57 wherein the image of the body portion includes an image of a lung.
59. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature:
by determining a respective probability that the feature belongs to the respective class; and by determining that the feature belongs to the respective class in response to the respective probability being greater than a threshold for the respective class.
60. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature:
by determining probabilities that the detected at least one feature belongs to respective classes; and
by determining that the feature belongs to the one of the respective classes corresponding to the highest one of the probabilities.
61. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes an A-line.
62. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes a pleural line.
63. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes a pleural effusion.
64. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes a B-line.
65. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes merged Bdines.
66. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes a consolidation. 67. The system of claim 57 wherein the electronic circuit, while executing the neural network, is configured:
to determine a respective class of each of the detected at least one feature by determining whether at least one of the detected at least one feature includes a pleural effusion; and
determining a severity of a detected pleural effusion.
68. The system of claim 57 wherein:
the image of the body portion includes an image of a lung; and
the electronic circuit is configured to diagnose a pathology of the lung in response to the respective determined class of each of the detected at least one feature. 69. The system of claim 57 wherein:
the image of the body portion includes an image of a lung; and
the electronic circuit is configured to diagnose a pathology of the lung in response to the respective position and to the respective determined class of each of the detected at least one feature.
70. A system, comprising:
an electronic circuit configured to execute a neural network and configured, while
executing the neural network,
to receive an image of a body portion, the image including at least one feature belonging to a class,
to detect at least one feature in the image; and
to determine, for each of the detected at least one feature, a respective position and a respective confidence level that the respective one of the detected at least one feature belongs to the class.
71. The system of claim 70 wherein the electronic circuit, while executing the neural network, is configured:
to receive at least one modified version of the image with the neural network;
to detect the at least one feature in the image in response to the image and the at least one modified version of the image; and
to determine, for each of the detected at least one feature, the respective position and the respective confidence level in response to the image and the at least one modified version of the image.
72. A system, comprising:
an electronic circuit configured
to generate, from each of at least one first training image, at least one second
training image, and
to train a neural network
by executing the neural network to determine a respective probability that each of at least one feature in at least one of the at least one first training image and the at least one second training image belongs to a feature class,
by determining, for each of the at least one feature, a probability difference between the determined respective probability and a corresponding annotated probability, and
by changing a respective weighting of each of at least one synapse of the neural network in response to the probability difference.
73. The system of claim 72 wherein the electronic circuit is further configured
to train the neural network:
by executing the neural network to detect each of the at least one feature;
by executing the neural network to determine a respective location of each of the detected at least one feature;
by executing the neural network to determine, for each of the detected at least one feature, a location difference between the determined respective location and a
corresponding annotated location; and
by changing the respective weighting of each of at least one synapse of the neural network in response to the location difference.
74. The system of claim 72 wherein the electronic circuit is further configured to train the neural network:
by executing the neural network to repeat determining a respective probability,
determining a probability difference, and changing a respective weighting for at least one iteration, for one or more additional iterations;
by generating, after each iteration, a respective training model for the neural network; and by configuring the neural network in response to the one of the training models that yields a highest value of a metric.
75. The system of claim 72 wherein the electronic circuitry is further configured to train the neural network:
by executing the neural network to repeat determining a respective probability,
determining a probability difference, and changing a respective weighting for at least one iteration, for one or more additional iterations;
by generating, after each iteration, a respective training model for the neural network; and by configuring the neural network in response to the one of the training models that yields a highest value of a weighted F l metric.
76. The system of claim 72 wherein the electronic circuitry is further configured to train the neural network:
by executing the neural network to repeat determining a respective probability,
determining a probability difference, and changing a respective weighting for at least one iteration, for one or more additional iterations; by generating, after each iteration for which the probability difference is less than or equal to a threshold, a respective training model for the neural network; and
by configuring the neural network in response to the one of the training models that yields a highest value of a metric.
77. A tangible, non-transitory computer-readable medium storing instructions that, when executed by a computing circuit, cause the computing circuit, or another circuit under control of the computing circuit, to execute a neural network:
to detect at least one feature in an image of a body portion; and
to determine a respective position and a respective class of each of the detected at least one feature.
78. A tangible, non-transitory computer-readable medium storing instructions that, when executed by a computing circuit, cause the computing circuit, or another circuit under control of the computing circuit, to execute a classifier neural network:
to determine a probability that an image of a body portion includes a feature belonging to a particular class.
79. A tangible, non-transitory computer-readable medium storing instructions that, when executed by a computing circuit, cause the computing circuit, or another circuit under control of the computing circuit to execute a neural network:
to receive each of an image of a body portion and at least one modified version of the image with a respective input channel;
to detect at least one feature in the image in response to the image and the at least one modified version of the image; and
to determine a respective position and a respective class of each of the detected at least one feature in response to the image and the at least one modified version of the image.
80. A tangible, non-transitory computer-readable medium storing instructions that, when executed by a computing circuit, cause the computing circuit, or another circuit under control of the computing circuit to execute a neural network configured to detect, in an image of a body portion, at least one feature belonging to a class:
to detect at least one feature in an image of a body portion; and to determine for each of the detected at least one feature a respective position and a respective confidence level that the respective one of the detected at least one feature belongs to the class.
81. A tangible, non-transitory computer-readable medium storing instructions that, when executed by a computing circuit, cause the computing circuit, or another circuit under control of the computing circuit:
to generate, from each of at least one first training image, at least one second training image;
to determine, with a neural network, a respective probability that each of at least one feature in at least one of the at least one first training image and the at least one second training image belongs to a feature class;
to determine, for each of the detected at least one feature, a probability difference between the determined respective probability and a corresponding annotated probability; and
to change a respective weighting of each of at least one synapse of the neural network in response to the probability difference.
</claims>
</document>
