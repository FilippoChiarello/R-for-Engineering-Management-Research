<document>

<filing_date>
2019-05-02
</filing_date>

<publication_date>
2020-12-17
</publication_date>

<priority_date>
2019-05-02
</priority_date>

<ipc_classes>
G05D1/00,G05D1/02
</ipc_classes>

<assignee>
LG ELECTRONICS
</assignee>

<inventors>
KIM, JOOHAN
KIM, SUN RYANG
KIM, YOONSIK
SA, JAECHEON
</inventors>

<docdb_family_id>
67622465
</docdb_family_id>

<title>
METHOD OF IDENTIFYING DRIVING SPACE USING ARTIFICIAL INTELLIGENCE, AND LEARNING MODULE AND ROBOT IMPLEMENTING SAME
</title>

<abstract>
Disclosed herein are a method of identifying a driving space using artificial intelligence, and a learning module and a robot implementing the same, and the robot according to an embodiment identifies a space in which the robot is moving by extracting feature data from data sensed by a vibration sensor and by comparing the feature data and parameters, and controls directions or speeds of movements of a moving unit to fit for the identified space, or changes magnitude of electric energy supplied to the moving unit.
</abstract>

<claims>
1. A robot, which identifies a driving space using artificial intelligence, comprising; a moving unit configured to move the robot; a vibration sensor configured to sense vibrations generated while the robot is moving; and a control unit configured to identify a space in which the robot is moving by extracting feature data from data sensed by the vibration sensor and by comparing the feature data and parameters, and configured to control directions or speeds of movements of the moving unit to fit for the identified space, or configured to change magnitude of electric energy supplied to the moving unit.
2. The robot of claim 1, wherein the robot further includes a force sensor configured to sense a change in forces applied to a handle assembly of the robot, the vibration sensor is a load cell constituting the force sensor.
3. The robot of claim 1, wherein the control unit adjusts PID values of a motor supplying electric energy to the moving unit on the basis of results of identifying the space.
4. The robot of claim 1, wherein the control unit buffers data sensed by the vibration sensor while the robot is moving, and then extracts the feature data from the buffered data.
5. The robot of claim 1, wherein the vibration sensor includes a first vibration sensor including a load cell, and a second vibration sensor including an IMU sensor, when the control unit may not identify a space in which the robot is moving after buffering signals of the first vibration sensor and generating first feature data, the control unit identifies a space in which the robot is moving after buffering signals of the second vibration sensor and generating second feature data.
6. The robot of claim 1, wherein the robot further comprises a weight sensor configured to sense weight of objects piled in a storage part of the robot, the control unit identifies the space using weight information sensed by the weight sensor.
7. The robot of claim 1, wherein the control unit further comprises a learning module configured to learn the extracted feature data, the learning module generates space-classifying parameters configured to map the feature data on any one space among two or more spaces.
8. (canceled)
9. The robot of claim 1, wherein the robot further comprises an obstacle sensor configured to sense obstacles around the robot, the control unit controls the obstacle sensor such that the obstacle sensor senses any one or more of an object or a human body more accurately to fit for the identified space.
10. A learning module, comprising: a storage unit configured to store first data sensed by a vibration sensor of a robot while the robot is moving in a first space, and second data sensed by the vibration sensor of the robot while the robot is moving in a second space; and a learning unit configured to generate parameters identifying a plurality of first data as the first space and identifying a plurality of second data as the second space by classifying the plurality of first data and the plurality of second data stored in the storage unit.
11. The learning module of claim 10, wherein the first data includes speeds of movements of the robot in the first space, and sizes of amplitude sensed by the vibration sensor of the robot or magnitude of time during which amplitude is maintained, the second data includes speeds of movements of the robot in the second space, and sizes of amplitude sensed by the vibration sensor of the robot in the second space or magnitude of time during which amplitude is maintained, the parameters indicate a boundary line between the plurality of first data and the plurality of second data.
12. The learning module of claim 10, wherein the first data and the second data includes weight information on objects piled in a storage part of the robot.
13. The learning module of claim 10, wherein the learning module is disposed in a server, the server further comprises a communication unit configured to receive the first data and the second data from a plurality of robots.
14. A method of identifying a driving space using artificial intelligence by a robot, comprising: moving a robot by a moving unit of the robot; sensing vibrations generated while the robot is moving by a vibration sensor of the robot; extracting feature data from data sensed by the vibration sensor by a control unit of the robot; identifying a space in which the robot is moving by comparing the feature data and parameters by the control unit; and controlling directions or speeds of movements of the moving unit to fit for the identified space by the control unit or changing magnitude of electric energy supplied to the moving unit by the control unit.
15. The method of claim 14, wherein the robot further includes a force sensor configured to sense a change in forces applied to a handle assembly of the robot, the vibration sensor is a load cell constituting the force sensor.
16. The method of claim 14, wherein the method further comprises adjusting PID values of a motor supplying electric energy to the moving unit on the basis of results of identifying the space by the control unit.
17. The method of claim 14, further comprising: buffering data sensed by the vibration sensor while the robot is moving by the control unit; and extracting the feature data from the buffered data by the control unit.
18. The method of claim 14, wherein the vibration sensor includes a first vibration sensor including a load cell, and a second vibration sensor including an IMU sensor, the method further comprises identifying a space in which the robot is moving after buffering signals of the second vibration sensor and generating second feature data by the control unit, when the control unit may not identify a space in which the robot is moving after buffering signals of the first vibration sensor and generating first feature data.
19. The method of claim 14, wherein the robot further comprises a weight sensor configured to sense weight of objects piled in a storage part of the robot, the method further comprises identifying the space using weight information sensed by the weight sensor by the control unit.
20. The method of claim 14, wherein the control unit further comprises a learning module configured to learn the extracted feature data, the method further comprises generating space-classifying parameters configured to map the feature data on any one space among two or more spaces by the learning module.
21. (canceled)
22. The method of claim 14, wherein the robot further comprises an obstacle sensor configured to sense obstacles around the robot, the method further comprises controlling the obstacle sensor such that the obstacle sensor senses any one or more of an object or a person more accurately to fit for the identified space by the control unit.
</claims>
</document>
