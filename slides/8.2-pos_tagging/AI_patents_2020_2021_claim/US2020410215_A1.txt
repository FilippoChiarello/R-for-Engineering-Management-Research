<document>

<filing_date>
2020-08-20
</filing_date>

<publication_date>
2020-12-31
</publication_date>

<priority_date>
2016-08-23
</priority_date>

<ipc_classes>
G06F21/32,G06K9/00,G06N3/04,G06N3/08,G06Q20/40
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
KIM, JUNG BAE
YOO, BYUNGIN
CHOI, CHANG KYU
HAN, JAE JOON
LEE, CHANGKYO
KWAK, YOUNGJUN
SON, JINWOO
</inventors>

<docdb_family_id>
59631524
</docdb_family_id>

<title>
LIVENESS TEST METHOD AND APPARATUS
</title>

<abstract>
A liveness test method and apparatus is disclosed. A processor implemented liveness test method includes extracting an interest region of an object from a portion of the object in an input image, performing a liveness test on the object using a neural network model-based liveness test model, the liveness test model using image information of the interest region as provided first input image information to the liveness test model and determining liveness based at least on extracted texture information from the information of the interest region by the liveness test model, and indicating a result of the liveness test.
</abstract>

<claims>
1. A processor implemented liveness test method, the liveness test method comprising: extracting an interest region in a face region of a user by cropping the interest region from an input image; and performing a liveness test on a face of the user based on the interest region, wherein a result of the liveness test is determined based on an output of a neural network model-based liveness test model.
2. The method of claim 1, wherein the extracting comprises extracting a portion including at least one of an eye, a nose, and lips from the face region of the user in the input image, as the interest region.
3. (canceled)
4. The method of claim 1, wherein the extracting comprises: detecting facial landmarks in the face region; and extracting the interest region based on the facial landmarks detected in the face region.
5. The method of claim 4, wherein the interest region is smaller than the face region.
6. The method of claim 1, wherein the liveness test model outputs a reference value to determine a liveness based on local texture information indicated in the interest region.
7. 7-10. (canceled)
11. A non-transitory computer-readable storage medium storing instructions, that when executed by a processor, cause the processor to perform the method of claim 1.
12. A liveness test computing apparatus comprising: one or more processors configured to: extract an interest region in a face region a user by cropping the interest region from an input image; and perform a liveness test on the face based on the interest region, wherein a result of the liveness test is determined based on an output of a neural network model-based liveness test model.
13. The liveness test computing apparatus of claim 12, wherein the one or more processors are further configured to extract a portion including at least one of an eye, a nose, and lips from the face region of the user in the input image, as the interest region.
14. (canceled)
15. The liveness test computing apparatus of claim 12, wherein the liveness test model outputs a reference value to determine a liveness based on local texture information indicated in the interest region.
16. 16-18. (canceled)
19. The liveness test computing apparatus of claim 12, wherein the one or more processors are further configured to: detect facial landmarks in the face region; and extract the interest region based on the facial landmarks detected in the face region.
20. The liveness test computing apparatus of claim 19, wherein the interest region is smaller than the face region.
</claims>
</document>
