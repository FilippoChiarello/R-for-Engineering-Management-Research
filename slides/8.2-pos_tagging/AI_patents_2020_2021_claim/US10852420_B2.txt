<document>

<filing_date>
2018-06-15
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2018-05-18
</priority_date>

<ipc_classes>
G01S13/86,G01S13/93,G01S13/931,G01S7/41
</ipc_classes>

<assignee>
ITRI (INDUSTRIAL TECHNOLOGY RESEARCH INSTITUTE)
</assignee>

<inventors>
CHONDRO, PETER
LIANG, PEI-JUNG
</inventors>

<docdb_family_id>
68533550
</docdb_family_id>

<title>
Object detection system, autonomous vehicle using the same, and object detection method thereof
</title>

<abstract>
In one of the exemplary embodiments, the disclosure is directed to an object detection system including a first type of sensor for generating a first sensor data; a second type of sensor for generating a second sensor data; and a processor coupled to the first type of sensor and the second type of sensor and configured at least for: processing the first sensor data by using a first plurality of object detection algorithms and processing the second sensor data by using a second plurality of object detection algorithms, wherein each of the first plurality of object detection algorithms and each of the second plurality of object detection algorithms include environmental parameters calculated from a plurality of parameter detection algorithms; and determining for each detected object a bounding box resulted from processing the first sensor data and processing the second sensor data.
</abstract>

<claims>
1. An object detection system comprising: a first type of sensor for generating a first sensor data; a second type of sensor for generating a second sensor data; and a processor coupled to the first type of sensor and the second type of sensor and configured at least for: processing the first sensor data by using a first plurality of object detection algorithms to generate first preliminary detection results which correspond to the first type of sensor; processing the second sensor data by using a second plurality of object detection algorithms to generate second preliminary detection results which correspond to the second type of sensor; applying a parameter detection algorithm which comprises a plurality of environmental parameters for each of the first preliminary detection results and the second preliminary detection results to generate a plurality of confidence values with each confidence value corresponding to a different environmental parameter of the plurality of environmental parameters, wherein the plurality of confidence values are generated according to the first sensor data and the second sensor data; and determining a detected object based on characteristics of the first type of sensor, characteristics of the second type of sensor, relationships among the first preliminary detection results and the second preliminary detection results, and the plurality of confidence values, comprising: determining the detected object from multiple bounding boxes according to the plurality of confidence values, wherein the plurality of confidence values are corresponded to the multiple bounding boxes respectively, wherein the processor is further configured for: fusing the first preliminary detection results and the second preliminary detection results to generate a fused preliminary detection results; paring two bounding boxes; and performing an overlap and clutter analysis from the fused preliminary detection results by determining whether two bounding boxes are overlapping above a predetermined overlapping threshold and are separated above a predetermined distance threshold, wherein the paired bounding boxes are determined as being either independent or dependent based on at least a spatial distance between the paired bounding boxes, depth information of the bounding boxes, and detected classes of the bounding boxes.
2. The object detection system of claim 1, wherein the processor is further configured for: using a Dempster-Shafer module when both the predetermined overlapping threshold and the predetermined distance threshold are exceeded.
3. The object detection system of claim 1, wherein the processor is further configured for: using a parameter filtering module when one of the predetermined overlapping threshold and the predetermined distance threshold are not exceeded.
4. The object detection system of claim 2, wherein the processor is further configured for: preserving a first bounding box which is determined as being more reliable of the paired bounding boxes and discarding the other bounding box of the pair bounding boxes based on at least the plurality of confidence values.
5. The object detection system of claim 3, wherein the processor is further configured for: determining a pseudo bounding box; and determining whether each bounding box from the fused preliminary detection results is preserved or removed based on at least the plurality of confidence values.
6. The object detection system of claim 1, wherein the plurality of environmental parameters comprises at least one of a weather condition, a local intensity measurement, an over-exposure detection, an under-exposure detection, relative distance of an object, angular position of the object, and a confidence of the object corresponding to an object detection algorithm.
7. The object detection system of claim 6, wherein the plurality of environmental parameters are normalized to conform to the ranges of the first type of sensor and the second type of sensor.
8. The object detection system of claim 1, wherein the first type of sensor comprises a RaDAR sensor, and the second type of sensor comprises a camera.
9. An autonomous vehicle comprising: an object detection system comprising: a first type of sensor for generating a first sensor data; a second type of sensor for generating a second sensor data; and a processor coupled to the first type of sensor and the second type of sensor and configured at least for: processing the first sensor data by using a first plurality of object detection algorithms to generate first preliminary detection results which correspond to the first type of sensor; processing the second sensor data by using a second plurality of object detection algorithms to generate second preliminary detection results which correspond to the second type of sensor; applying a parameter detection algorithm which comprises a plurality of environmental parameters for each of the first preliminary detection results and the second preliminary detection results to generate a plurality of confidence values with each confidence value corresponding to a different environmental parameter of the plurality of environmental parameters, wherein the plurality of confidence values are generated according to the first sensor data and the second sensor data; and determining a detected object based on characteristics of the first type of sensor, characteristics of the second type of sensor, relationships among the first preliminary detection results and the second preliminary detection results, and the plurality of confident values, comprising: determining the detected object from multiple bounding boxes according to the plurality of confidence values, wherein the plurality of confidence values are corresponded to the multiple bounding boxes respectively, wherein the processor is further configured for: fusing the first preliminary detection results and the second preliminary detection results to generate a fused preliminary detection results; paring two bounding boxes; and performing an overlap and clutter analysis from the fused preliminary detection results by determining whether two bounding boxes are overlapping above a predetermined overlapping threshold and are separated above a predetermined distance threshold, wherein the paired bounding boxes are determined as being either independent or dependent based on at least a spatial distance between the paired bounding boxes, depth information of the bounding boxes, and detected classes of the bounding boxes.
10. An object detection method used by an autonomous vehicle, the method comprising: generating, by using a first type of sensor, a first sensor data; generating, by using a second type of sensor, a second sensor data; processing the first sensor data by using a first plurality of object detection algorithms to generate first preliminary detection results which correspond to the first type of sensor; processing the second sensor data by using a second plurality of object detection algorithms to generate second preliminary detection results which correspond to the second type of sensor; applying a parameter detection algorithm which comprises a plurality of environmental parameters for each of the first preliminary detection results and the second preliminary detection results to generate a plurality of confidence values with each confidence value corresponding to a different environmental parameter of the plurality of environmental parameters, wherein the plurality of confidence values are generated according to the first sensor data and the second sensor data; and determining a detected object based on characteristics of the first type of sensor, characteristics of the second type of sensor, relationships among the first preliminary detection results and the second preliminary detection results, and the plurality of confident values, comprising: determining the detected object from multiple bounding boxes according to the plurality of confidence values, wherein the plurality of confidence values are corresponded to the multiple bounding boxes respectively, the object detection method further comprising: fusing the first preliminary detection results and the second detection results to generate a fused preliminary detection results; paring two bounding boxes; and performing an overlap and clutter analysis from the fused preliminary detection results by determining whether two bounding boxes are overlapping above a predetermined overlapping threshold and are separated above a predetermined distance threshold, wherein the paired bounding boxes are determined as being either independent or dependent based on at least a spatial distance between the paired bounding boxes, depth information of the bounding boxes, and detected classes of the bounding boxes.
11. The object detection method of claim 10 further comprising: using a Dempster-Shafer module when both the predetermined overlapping threshold and the predetermined distance threshold are exceeded.
12. The object detection method of claim 10 further comprising: using a parameter filtering module when one of the predetermined overlapping threshold and the predetermined distance threshold are not exceeded.
13. The object detection method of claim 11 further comprising: preserving a first bounding box which is determined as being more reliable of the paired bounding boxes and discarding the other bounding box of the pair bounding boxes based on at least the plurality of confidence values.
14. The object detection method of claim 12 further comprising: determining a pseudo bounding box; and determining whether each bounding box from the fused preliminary detection results is preserved or removed based on at least the plurality of confidence values.
15. The object detection method of claim 10, wherein the plurality of environmental parameters comprises at least one of a weather condition, a local intensity measurement, an over-exposure detection, an under-exposure detection, relative distance of an object, angular position of the object, and a confidence of the object corresponding to an object detection algorithm.
16. The object detection method of claim 15, wherein the plurality of environmental parameters are normalized to conform to the ranges of the first type of sensor and the second type of sensor.
</claims>
</document>
