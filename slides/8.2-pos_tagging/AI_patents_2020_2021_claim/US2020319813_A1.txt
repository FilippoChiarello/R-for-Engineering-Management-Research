<document>

<filing_date>
2020-06-18
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2018-02-05
</priority_date>

<ipc_classes>
G06F12/0811,G06F13/16,G06F3/06,G06N3/08
</ipc_classes>

<assignee>
MICRON TECHNOLOGY
</assignee>

<inventors>
RAY, ANIRBAN
ANAND, GURPREET
MITTAL, SAMIR
</inventors>

<docdb_family_id>
67475108
</docdb_family_id>

<title>
Predictive Data Orchestration in Multi-Tier Memory Systems
</title>

<abstract>
A computing system having memory components of different tiers. The computing system further includes a controller, operatively coupled between a processing device and the memory components, to: receive from the processing device first data access requests that cause first data movements across the tiers in the memory components; service the first data access requests after the first data movements; predict, by applying data usage information received from the processing device in a prediction model trained via machine learning, second data movements across the tiers in the memory components; and perform the second data movements before receiving second data access requests, where the second data movements reduce third data movements across the tiers caused by the second data access requests.
</abstract>

<claims>
1. A method, comprising: receiving, in a computing device, data usage information identifying first data movements across a plurality of tiers of memory, the first data movements caused by a processing device accessing first data; predicting, by the computing device based on the data usage information and a prediction model trained via machine learning, second data movements across the plurality of tiers of memory, the second data movement predicted to be caused by the processing device accessing second data; and initiating, by the computing device, the second data movements before the processing device requesting to access the second data.
2. The method of claim 1, wherein the prediction model comprises an artificial neural network; and the method further comprises: training the prediction model using the data usage information identifying the first data movements across the plurality of tiers of memory.
3. The method of claim 2, wherein the predicting is performed in real time for the second data access requests.
4. The method of claim 2, further comprising: performing third data movements in response to the processing device requesting to access the second data; and training the prediction model based on the third data movements.
5. The method of claim 1, further comprising: grouping data blocks that are used together to identify a mapping between data blocks and data objects, wherein the predicting is based at least in part on the mapping.
6. The method of claim 1, further comprising: adjusting the prediction model based on a performance measurement of the plurality of tiers of memory in servicing data access requests from the processing device.
7. A computing system, comprising: a processing device; a plurality of memory components of different tiers; and a controller, operatively coupled between the processing device and the plurality of memory components, and configured to at least: receive data usage information identifying first data movements across a plurality of tiers of memory in the computing system, the first data movements caused by a processing device accessing first data; predict, based on the data usage information and a prediction model trained via machine learning, second data movements across the plurality of tiers of memory, the second data movement predicted to be caused by the processing device accessing second data; and initiate, by the computing device, the second data movements before the processing device requesting to access the second data.
8. The computing system of claim 7, wherein the controller is further configured to: adjust the prediction model based on a performance measurement of the plurality of memory components in servicing data access requests from the processing device.
9. The computing system of claim 8, wherein the plurality of memory components include first memory and second memory; the first memory functions as cache of the second memory; the performance measurement is a cache hit ratio of data access requests; and requests of the processing device for data in the second memory causes movements of the requested data from the second memory to the first memory.
10. The computing system of claim 9, wherein the controller is configured to adjust the prediction model using a hybrid reinforcement learning technique by adjusting an artificial neural network to generate predictions that improves the cache hit ratio measured at the controller for the requests of the processing device.
11. The computing system of claim 10, wherein the controller is configured to communicate with the processing device over a memory bus; and the controller and the plurality of memory components are configured on a memory module connected to the memory bus.
12. The computing system of claim 11, wherein the first data movements and the second data movement do not go through the memory bus.
13. The computing system of claim 9, wherein the first memory is volatile dynamic random-access memory and the second memory is non-volatile cross-point memory; and the controller comprises a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC).
14. The computing system of claim 7, wherein the controller is further configured to: identify a mapping between data blocks in the plurality of memory components and data objects as organized in applications running in the processing device.
15. A non-transitory computer storage medium storing instructions which, when executed by a computing system, cause the computing system to perform a method, the method comprising: receiving, in a computing device, data usage information identifying first data movements across a plurality of tiers of memory, the first data movements caused by a processing device accessing first data; predicting, by the computing device based on the data usage information and a prediction model trained via machine learning, second data movements across the plurality of tiers of memory, the second data movement predicted to be caused by the processing device accessing second data; and initiating, by the computing device, the second data movements before the processing device requesting to access the second data.
16. The non-transitory computer storage medium of claim 15, wherein the prediction model includes an artificial neural network; and the method further comprises: training the prediction model using the data usage information identifying the first data movements across the plurality of tiers of memory.
17. The non-transitory computer storage medium of claim 16, wherein the predicting is performed in real time for the second data access requests.
18. The non-transitory computer storage medium of claim 16, wherein the method further comprises: performing third data movements in response to the processing device requesting to access the second data; and training the prediction model based on the third data movements.
19. The non-transitory computer storage medium of claim 15, wherein the method further comprises: grouping data blocks that are used together to identify a mapping between data blocks and data objects, wherein the predicting is based at least in part on the mapping.
20. The non-transitory computer storage medium of claim 15, wherein the method further comprises: adjusting the prediction model based on a performance measurement of the plurality of tiers of memory in servicing data access requests from the processing device.
</claims>
</document>
