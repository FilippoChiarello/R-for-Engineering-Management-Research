<document>

<filing_date>
2019-04-03
</filing_date>

<publication_date>
2020-04-14
</publication_date>

<priority_date>
2017-08-31
</priority_date>

<ipc_classes>
G06F16/632,G06F16/68,G06F16/683
</ipc_classes>

<assignee>
SNAP
</assignee>

<inventors>
CHEN, XIN
CHUNG, JAEWOOK
HU, YU
JIANG, JINHUA
MEI, XING
OUIMET, KIRK
XU NING
</inventors>

<docdb_family_id>
66541040
</docdb_family_id>

<title>
Generating a probability of music
</title>

<abstract>
Systems and Methods describe capturing a plurality of segments of an audio stream, analyzing at least one feature of each segment of the plurality of segments of the audio stream to generate for each segment a prediction value indicating whether there is music in the segment, generating a probability value that there is music in the audio stream based on aggregating the prediction values of the plurality of segments, determining that the probability value that there is music in the audio stream meets a predetermined threshold, and causing the audio stream to be identified based on determining that the probability value that there is music in the audio stream meets a predetermined threshold.
</abstract>

<claims>
1. A method comprising: capturing, by a computing device, a plurality of segments of an audio stream; analyzing, by the computing device, at least one feature of each segment of the plurality of segments of the audio stream to generate for each segment a prediction value indicating whether there is music in the segment; generating, by the computing device, a probability value that there is music in the audio stream based on aggregating the prediction values of the plurality of segments; determining, by the computing device, that the probability value that there is music in the audio stream meets a predetermined threshold; and causing the audio stream to be identified based on determining that the probability value that there is music in the audio stream meets a predetermined threshold.
2. The method of claim 1, wherein the audio stream has a first sampling rate, and wherein after capturing the plurality of segments of the audio stream, the method further comprises: resampling the plurality of audio segments of the audio stream to a second sampling rate.
3. The method of claim 2, wherein the plurality of segments of the audio stream is down sampled from the first sampling rate to the second sampling rate.
4. The method of claim 1, further comprising: determining a first sampling rate of the audio stream; determining that the first sampling rate of the audio stream is different than a predetermined sampling rate; and resampling the audio stream from the first sampling rate to the predetermined sampling rate.
5. The method of claim 1, wherein the prediction value is generated using a music detector machine learning model that analyzes a feature vector of the segment to generate the prediction value.
6. The method of claim 5, wherein the feature vector is a two dimensional feature vector, wherein a first dimension of the two dimensional feature vector is a time-domain for the segment, and a second dimension of the two dimensional feature vector is a feature-domain for the segment.
7. The method of claim 5, wherein the feature-domain for the segment is a frequency domain.
8. The method of claim 5, wherein the music detection machine learning model is trained using a plurality of messages comprising media content.
9. The method of claim 1, wherein the plurality of segments of the audio stream are captured from media content of a message in a messaging system and the method further comprises: setting a flag associated with the message indicating that the audio stream has already been processed.
10. The method of claim 1, wherein each segment comprises a slide-window that overlaps in time with another segment.
11. The method of claim 10, wherein each slide-window comprises a predetermined stride size corresponding to an amount of time between the start of a first segment and the start of a next segment following the first segment.
12. The method of claim 1, wherein causing the audio stream to be identified based on determining that the probability value that there is music in the audio stream meeting a predetermined threshold comprises: sending a request to a server computing device to request that the audio stream be identified; and receiving a response, from the server computing device, that includes identity information for the audio stream.
13. A computing device comprising: a processor; and a computer readable medium coupled with the processor, the computer readable medium comprising instructions stored thereon that are executable by the processor to cause a computing device to perform operations comprising: capturing a plurality of segments of an audio stream; analyzing at least one feature of each segment of the plurality of segments of the audio stream to generate for each segment a prediction value indicating whether there is music in the segment; generating a probability value that there is music in the audio stream based on aggregating the prediction values of the plurality of segments; determining that the probability value that there is music in the audio stream meets a predetermined threshold; and causing the audio stream to be identified based on determining that the probability value that there is music in the audio stream meets a predetermined threshold.
14. The computing device of claim 13, the operations further comprising: determining a first sampling rate of the audio stream; determining that the first sampling rate of the audio stream is different than a predetermined sampling rate; and resampling the audio stream from the first sampling rate to the predetermined sampling rate.
15. The computing device of claim 13, wherein the prediction value is generated using a music detector machine learning model that analyzes a feature vector of the segment to generate the prediction value.
16. The computing device of claim 15, wherein the feature vector is a two dimensional feature vector, wherein a first dimension of the two dimensional feature vector is a time-domain for the segment, and a second dimension of the two dimensional feature vector is a feature-domain for the segment, and wherein the feature-domain for the segment is a frequency domain.
17. The computing device of claim 15, wherein the music detection machine learning model is trained using a plurality of messages comprising media content.
18. The computing device of claim 1, wherein each segment comprises a slide-window that overlaps in time with another segment.
19. The computing device of claim 18, wherein each slide-window comprises a predetermined stride size corresponding to an amount of time between the start of a first segment and the start of a next segment following the first segment.
20. A non-transitory computer readable medium comprising instructions stored thereon that are executable by at least one processor to cause a computing device to perform operations comprising: capturing a plurality of segments of an audio stream; analyzing at least one feature of each segment of the plurality of segments of the audio stream to generate for each segment a prediction value indicating whether there is music in the segment; generating a probability value that there is music in the audio stream based on aggregating the prediction values of the plurality of segments; determining that the probability value that there is music in the audio stream meets a predetermined threshold; and causing the audio stream to be identified based on determining that the probability value that there is music in the audio stream meets a predetermined threshold.
</claims>
</document>
