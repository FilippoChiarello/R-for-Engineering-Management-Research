<document>

<filing_date>
2018-11-14
</filing_date>

<publication_date>
2020-05-14
</publication_date>

<priority_date>
2018-11-14
</priority_date>

<ipc_classes>
G05D1/00,G05D1/02,G06N3/08
</ipc_classes>

<assignee>
HONDA MOTOR COMPANY
</assignee>

<inventors>
FUJIMURA KIKUO
ISELE, DAVID FRANCIS
</inventors>

<docdb_family_id>
70550178
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR PROVIDING AUTONOMOUS VEHICULAR NAVIGATION WITHIN A CROWDED ENVIRONMENT
</title>

<abstract>
A system and method for providing autonomous vehicular navigation within a crowded environment that include receiving data associated with an environment in which an ego vehicle and a target vehicle are traveling. The system and method also include determining an action space based on the data associated with the environment. The system and method additionally include executing a stochastic game associated with navigation of the ego vehicle and the target vehicle within the action space. The system and method further include controlling at least one of the ego vehicle and the target vehicle to navigate in the crowded environment based on execution of the stochastic game.
</abstract>

<claims>
1. A computer-implemented method for providing autonomous vehicular navigation within a crowded environment, comprising: receiving data associated with an environment in which an ego vehicle and a target vehicle are traveling; determining an action space based on the data associated with the environment; executing a stochastic game associated with navigation of the ego vehicle and the target vehicle within the action space, wherein a neural network is trained with stochastic game reward data based on the execution of the stochastic game; and controlling at least one of the ego vehicle and the target vehicle to navigate in the crowded environment based on execution of the stochastic game.
2. The computer-implemented method of claim 1, wherein receiving data associated with the environment includes receiving image data and LiDAR data from at least one of the: ego vehicle and the target vehicle, wherein the image data and the LiDAR data are aggregated into fused environmental data that is associated with the crowded environment.
3. The computer-implemented method of claim 2, wherein determining the action space includes evaluating the fused environmental data and determining at least one set of action space coordinates that correspond to the action space, wherein the action space is a virtual grid world that is representative of the crowded environment.
4. The computer-implemented method of claim 3, wherein the at least one set of action space coordinates include positional coordinates that represent the ego vehicle, the target vehicle, a pathway on which the ego vehicle and target vehicle are traveling, an end goal of the ego vehicle, and an end goal of the target vehicle.
5. The computer-implemented method of claim 3, wherein determining the action space includes evaluating the at least one set of the action space coordinates and determining at least one model of the action space, wherein the at least one model of the action space is utilized in at least one iteration of the stochastic game.
6. The computer-implemented method of claim 5, wherein executing the stochastic game includes executing the at least one iteration of the stochastic game with at least one model of the action space configured as at least one of: a discrete domain model and a continuous domain model.
7. The computer-implemented method of claim 6, wherein executing the stochastic game includes implementing a reward format in the discrete domain model that includes rewarding a virtual ego agent that represents the ego vehicle and a virtual target agent that represents the target vehicle for reaching a respective virtual end goal without intersection.
8. The computer-implemented method of claim 7, wherein executing the stochastic game includes implementing the reward format in the continuous domain model that includes implementing potential based reward shaping that makes states further from respective virtual end goals negative and provides a gradient signal that encourages the virtual ego agent and the virtual target agent to move toward the respective virtual end goal.
9. The computer-implemented method of claim 8, wherein controlling at least one of the ego vehicle and the target vehicle includes accessing the neural network to evaluate the game reward data and the reward format implemented during the at least one iteration of the stochastic game to determine a travel path to autonomously navigate at least one of: the ego vehicle and the target vehicle in the crowded environment.
10. A system for providing autonomous vehicular navigation within a crowded environment, comprising: a memory storing instructions when executed by a processor cause the processor to: receive data associated with an environment in which an ego vehicle and a target vehicle are traveling; determine an action space based on the data associated with the environment; execute a stochastic game associated with navigation of the ego vehicle and the target vehicle within the action space, wherein a neural network is trained with stochastic game reward data based on the execution of the stochastic game; and control at least one of the ego vehicle and the target vehicle to navigate in the crowded environment based on execution of the stochastic game.
11. The system of claim 10, wherein receiving data associated with the environment includes receiving image data and LiDAR data from at least one of the: ego vehicle and the target vehicle, wherein the image data and the LiDAR data are aggregated into fused environmental data that is associated with the crowded environment.
12. The system of claim 11, wherein determining the action space includes evaluating the fused environmental data and determining at least one set of action space coordinates that correspond to the action space, wherein the action space is a virtual grid world that is representative of the crowded environment.
13. The system of claim 12, wherein the at least one set of action space coordinates include positional coordinates that represent the ego vehicle, the target vehicle, a pathway on which the ego vehicle and target vehicle are traveling, an end goal of the ego vehicle, and an end goal of the target vehicle.
14. The system of claim 12, wherein determining the action space includes evaluating the at least one set of the action space coordinates and determining at least one model of the action space, wherein the at least one model of the action space is utilized in at least one iteration of the stochastic game.
15. The system of claim 14, wherein executing the stochastic game includes executing the at least one iteration of the stochastic game with at least one model of the action space configured as at least one of: a discrete domain model and a continuous domain model.
16. The system of claim 15, wherein executing the stochastic game includes implementing a reward format in the discrete domain model that includes rewarding a virtual ego agent that represents the ego vehicle and a virtual target agent that represents the target vehicle for reaching a respective virtual end goal without intersection.
17. The system of claim 16, wherein executing the stochastic game includes implementing the reward format in the continuous domain model that includes implementing potential based reward shaping that makes states further from respective virtual end goals negative and provides a gradient signal that encourages the virtual ego agent and the virtual target agent to move toward the respective virtual end goal.
18. The system of claim 17, wherein controlling at least one of the ego vehicle and the target vehicle includes accessing the neural network to evaluate the game reward data and the reward format implemented during the at least one iteration of the stochastic game to determine a travel path to autonomously navigate at least one of: the ego vehicle and the target vehicle in the crowded environment.
19. A non-transitory computer readable storage medium storing instructions that when executed by a computer, which includes a processor perform a method, the method comprising: receiving data associated with an environment in which an ego vehicle and a target vehicle are traveling; determining an action space based on the data associated with the environment; executing a stochastic game associated with navigation of the ego vehicle and the target vehicle within the action space, wherein a neural network is trained with stochastic game reward data based on the execution of the stochastic game; and controlling at least one of the ego vehicle and the target vehicle to navigate in a crowded environment based on execution of the stochastic game.
20. The non-transitory computer readable storage medium of claim 19, wherein controlling at least one of the ego vehicle and the target vehicle includes accessing the neural network to evaluate game reward data and a reward format implemented during at least one iteration of the stochastic game to determine a travel path to autonomously navigate at least one of: the ego vehicle and the target vehicle in the crowded environment.
</claims>
</document>
