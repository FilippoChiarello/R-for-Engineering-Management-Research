<document>

<filing_date>
2019-09-05
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-07
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
POSTECH ACADEMY-INDUSTRY FOUNDATION
</assignee>

<inventors>
KIM, HYUNG JUN
KIM, SUNGHO
KIM, JAE-JOON
KIM, JINSEOK
KIM, YULHWA
</inventors>

<docdb_family_id>
70971077
</docdb_family_id>

<title>
DIVIDING NEURAL NETWORKS
</title>

<abstract>
A method of implementing a neural network in a neuromorphic apparatus having a memory and processing circuitry, where the method includes dividing, by the processing circuitry, the neural network into a plurality of sub-networks based on a size of a core of the memory to implement the neural network, initializing, by the processing circuitry, a hyper-parameter used in the sub-networks, and training, by the processing circuitry, the sub-networks by using the hyper-parameter.
</abstract>

<claims>
1. A method of implementing a neural network in a neuromorphic apparatus having a memory and processing circuitry, the method comprising: dividing, by the processing circuitry, the neural network into a plurality of sub-networks based on a size of a core of the memory; initializing, by the processing circuitry, a hyper-parameter used in the sub-networks; and training, by the processing circuitry, the sub-networks by using the hyper-parameter.
2. The method of claim 1, wherein the initializing further comprises initializing, by the processing circuitry, a hyper-parameter with an initial value based on the size of the core.
3. The method of claim 1, wherein the initializing further comprises initializing, by the processing circuitry, a hyper-parameter with a value selected from among values indicating a standard deviation of input activations of a sub-network of the neural network.
4. The method of claim 3, wherein the standard deviation is based on a number of the input activations of the sub-network with a number of sub-networks.
5. The method of claim 1, wherein the dividing further comprises dividing, by the processing circuitry, the neural network into a plurality of sub-networks where each sub-network has a number of input activations that is equal to a number of rows of the core.
6. The method of claim 1, wherein the dividing comprises dividing, by the processing circuitry, the neural network into a plurality of sub-networks including, a first sub-network that generates an intermediate activation, and a second sub-network that receives the intermediate activation.
7. The method of claim 1, further comprising: mapping, by the processing circuitry, the sub-networks to the memory, and driving the sub-networks by the processing circuitry.
8. The method of claim 1, wherein an element corresponding to a synapse in the core comprises a variable resistance element.
9. A non-transitory computer-readable recording medium having recorded thereon a program for executing the method of claim 1 on a computer.
10. An apparatus for implementing a neural network, the apparatus comprising: a memory comprising a core; and processing circuitry configured to drive the neural network by, dividing the neural network into a plurality of sub-networks based on a size of the core of the memory; initializing a hyper-parameter used in the sub-networks; and training the sub-networks by using the hyper-parameter.
11. The apparatus of claim 10, wherein the processing circuitry is further configured to initialize the hyper-parameter with an initial value selected based on the size of the core.
12. The apparatus of claim 10, wherein the processing circuitry is further configured to initialize the hyper-parameter with a value selected from among values indicating a standard deviation.
13. The apparatus of claim 12, wherein the processing circuitry is further configured to initialize the hyper-parameter by calculating the standard deviation by merging a number of input activations of the sub-network with a number of sub-networks.
14. The apparatus of claim 10, wherein the processing circuitry is further configured to divide the neural network such that a number of rows of the core equals a number of input activations of at least one sub-network of the plurality of sub-networks.
15. The apparatus of claim 10, wherein the processing circuitry is further configured to drive the neural network by generating at least one intermediate activation by dividing the neural network.
16. The apparatus of claim 10, wherein the processing circuitry is further configured to drive the neural network by mapping the sub-networks to the memory and drive the sub-networks.
17. The apparatus of claim 10, wherein an element corresponding to a synapse in the core comprises a variable resistance element.
</claims>
</document>
