<document>

<filing_date>
2019-10-15
</filing_date>

<publication_date>
2020-02-06
</publication_date>

<priority_date>
2019-10-01
</priority_date>

<ipc_classes>
G06N20/00,G10L15/06,G10L15/16,G10L15/22
</ipc_classes>

<assignee>
LG ELECTRONICS
</assignee>

<inventors>
LEE, KWANGYONG
</inventors>

<docdb_family_id>
69229812
</docdb_family_id>

<title>
ARTIFICIAL INTELLIGENCE APPARATUS FOR PERFORMING SPEECH RECOGNITION AND METHOD THEREOF
</title>

<abstract>
Disclosed herein is an artificial intelligence apparatus for performing speech recognition including a microphone configured to receive a speech command of a user, a learning processor configured to determine anaphora included in text data corresponding to the speech command using an anaphora recognition model for determining anaphora included in predetermined text data, and a processor configured to specify an object referred to by the determined anaphora based on context information including information input to or output from the artificial intelligence apparatus, determine a response to the speech command based on the specified object, and control the artificial intelligence apparatus according to the determined response.
</abstract>

<claims>
1. An artificial intelligence apparatus for performing speech recognition, the artificial intelligence apparatus comprising: a microphone configured to receive a speech command of a user; a learning processor configured to determine anaphora included in text data corresponding to the speech command using an anaphora recognition model for determining anaphora included in predetermined text data; and a processor configured to specify an object referred to by the determined anaphora based on context information including information input to or output from the artificial intelligence apparatus, determine a response to the speech command based on the specified object, and control the artificial intelligence apparatus according to the determined response.
2. The artificial intelligence apparatus of claim 1, wherein the context information includes screen context information including at least one of information on output content output via a display of the artificial intelligence apparatus or information on selected content selected by the user.
3. The artificial intelligence apparatus of claim 2, wherein the processor specifies the object referred to by the anaphora based on the selected content when at least one selected content is present.
4. The artificial intelligence apparatus of claim 2, wherein, if the output content is full-screen content output on a full screen of the display, the processor specifies the object referred to by the anaphora based on the full-screen content.
5. The artificial intelligence apparatus of claim 2, wherein the context information includes conversation context information which is information on a conversation history between the user and the artificial intelligence apparatus via a speech command and a response to the speech command.
6. The artificial intelligence apparatus of claim 5, wherein the anaphora includes at least one of adjacent anaphora referring to an object adjacent to a person or a thing or non-adjacent anaphora referring to an object which is not adjacent to a person or a thing, and wherein the learning processor determines the adjacent anaphora or the non-adjacent anaphora included in the text data corresponding to the speech command using the anaphora recognition model.
7. The artificial intelligence apparatus of claim 6, wherein the processor specifies the object referred to by the determined adjacent anaphora based on the screen context information.
8. The artificial intelligence apparatus of claim 6, wherein the processor specifies the object referred to by the determined non-adjacent anaphora based on the conversation context information.
9. The artificial intelligence apparatus of claim 8, wherein the conversation context information includes information on a candidate of an object referred to by anaphora included in text data corresponding to each speech command included in the conversation history, and wherein the processor specifies the object referred to by the determined non-adjacent anaphora based on the candidate of the object referred to by the anaphora.
10. The artificial intelligence apparatus of claim 1, wherein the anaphora recognition model is a neural network trained by a machine learning algorithm or a deep learning algorithm to output an anaphora tagging value of each character or word included in the predetermined text data when the predetermined text data is input to an input layer.
11. A speech recognition method performed by an artificial intelligence apparatus, the speech recognition method comprising: receiving a speech command of a user; determining anaphora included in text data corresponding to the speech command using an anaphora recognition model for determining anaphora included in predetermined text data; specifying an object referred to by the determined anaphora based on context information including information input to or output from the artificial intelligence apparatus; determining a response to the speech command based on the specified object; and controlling the artificial intelligence apparatus according to the determined response.
12. The speech recognition method of claim 11, wherein the context information includes screen context information including at least one of information on output content output via a display of the artificial intelligence apparatus or information on selected content selected by the user.
13. The speech recognition method of claim 12, wherein the specifying of the object includes specifying the object referred to by the anaphora based on the selected content when at least one selected content is present.
14. The speech recognition method of claim 12, wherein the specifying of the object includes, if the output content is full-screen content output on a full screen of the display, specifying the object referred to by the anaphora based on the full-screen content.
15. The speech recognition method of claim 12, wherein the context information includes conversation context information which is information on a conversation history between the user and the artificial intelligence apparatus via a speech command and a response to the speech command.
16. The speech recognition method of claim 15, wherein the anaphora includes at least one of adjacent anaphora referring to an object adjacent to a person or a thing or non-adjacent anaphora referring to an object which is not adjacent to a person or a thing, and wherein the determining of the anaphora includes determining the adjacent anaphora or the non-adjacent anaphora included in the text data corresponding to the speech command using the anaphora recognition model.
17. The speech recognition method of claim 16, wherein the specifying of the object includes specifying the object referred to by the determined adjacent anaphora based on the screen context information.
18. The speech recognition method of claim 16, wherein the specifying of the object includes specifying the object referred to by the determined non-adjacent anaphora based on the conversation context information.
19. The speech recognition method of claim 18, wherein the conversation context information includes information on a candidate of an object referred to by anaphora included in text data corresponding to each speech command included in the conversation history, and wherein the specifying of the object includes specifying the object referred to by the determined non-adjacent anaphora based on the candidate of the object referred to by the anaphora.
20. The speech recognition method of claim 11, wherein the anaphora recognition model is a neural network trained by a machine learning algorithm or a deep learning algorithm to output an anaphora tagging value of each character or word included in the predetermined text data when the predetermined text data is input to an input layer.
</claims>
</document>
