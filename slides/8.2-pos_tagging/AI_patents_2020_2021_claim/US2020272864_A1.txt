<document>

<filing_date>
2018-11-06
</filing_date>

<publication_date>
2020-08-27
</publication_date>

<priority_date>
2017-11-06
</priority_date>

<ipc_classes>
G06K9/62,G06N3/04,G06N3/08,G06T7/00
</ipc_classes>

<assignee>
UNIVERSITY HEALTH NETWORK
</assignee>

<inventors>
DIAMANDIS, PHEDIAS
VOLYNSKAYA, ZOYA
FAUST, KEVIN
DJURIC, UGLJESA
</inventors>

<docdb_family_id>
66331256
</docdb_family_id>

<title>
PLATFORM, DEVICE AND PROCESS FOR ANNOTATION AND CLASSIFICATION OF TISSUE SPECIMENS USING CONVOLUTIONAL NEURAL NETWORK
</title>

<abstract>
Embodiments described herein provide a platform, device and process for digital pathology that enable multi-level annotation and visualization of histopathologic slides using a modular arrangement of deep convolutional neural networks (CNNs). The CNNs can be trained using pathology images (e.g., in some cases increasing the base of data by breaking larger fields of view into smaller ones) to learn features consistent with certain pathologies. The platform can use the CNNs to visually annotate pathology slides at an interface tool of a display device. The platform can automate the process of selection, as well as provide an opportunity for the pathologist to see a depiction of predicted results. The platform can use the CNNs to identify regions of interest on pathology slides. The interface tool can enable a predicted region of interest (ROI) type to be visually presented on a surface map showing the basis of the prediction. If the ROI primarily lands in part of the hyperdimensional space not occupied by any training set, then the interface tool is capable of marking it as an ROI of unknown type.
</abstract>

<claims>
1. A computer platform for digital pathology comprising: memory having a stored data structure defining a convolutional neural network that models a hyperdimensional space, the convolutional neural network trained using pathology images; one or more processors in communication with the memory having the stored data structure defining the convolutional neural network; and one or more programs, wherein the one or more program are stored in the memory and configured to be executed by the one or more processors, the one or more programs including instructions to: determine a region of interest on a pathology slide and a predicted region of interest (ROI) type by classifying a plurality of pathology features abstracted from the pathology slide by a processor of the one or more processors using the convolutional neural network defined by the data structure stored in the memory; and generate, at an interface tool for display on a display device, output indications of the region of interest on a visual representation of the pathology slide and annotations of the predicted region of interest type on the visual representation of the pathology slide.
2. The platform of claim 1, wherein the processor executes the instructions to determine the predicted region of interest type by determining a mapping of the region of interest to a portion of the hyperdimensional space, wherein the portion recognizes one or more of the plurality of pathology features consistent with the predicted region of interest type.
3. The platform of claim 1, wherein the processor executes the instructions to generate the output indications comprising a surface map showing the basis of a prediction for the predicted region of interest type, the surface map being a reduced dimensionality view of a classification for the predicted region of interest type.
4. The platform of claim 1, wherein the processor executes the instructions to use a first convolutional neural network to classify the pathology slide and, based on the classification, select a second convolutional neural network to determine the region of interest on the pathology slide.
5. The platform of claim 1, wherein the output indications comprise an original pathology slide, a false colour slide showing the region of interest, an overall view of the original pathology slide and the false colour slide, and a legend indicating the predicted region of interest type and an associated false colour.
6. The platform of claim 1, wherein the processor executes the instructions to receive, at the interface tool, an input indication that a specific region of interest is of an unknown type.
7. The platform of claim 1, wherein the processor executes the instructions to determine a prediction score for the predicted region of interest type using the convolutional neural network.
8. The platform of claim 1, wherein the processor executes the instructions to generate, at the interface tool, a t-distributed stochastic neighbor embedding visualization of the convolutional neural network, the t-distributed stochastic neighbor embedding visualization depicting the hyperdimensional space modeled by the convolutional neural network.
9. The platform of claim 1, wherein the processor executes the instructions to determine the region of interest on the pathology slide and the predicted region of interest (ROI) type by tiling an image on the pathology slide into a plurality of image tiles and classifying the plurality of image tiles using the convolutional neural network.
10. The platform of claim 1 wherein the processor executes the instructions to generate a distribution of a plurality of image tiles on a t-distributed Stochastic Neighbour Embedding plot to display, at the interface tool, a planar representation of the convolutional neural network.
11. The platform of claim 10 wherein the processor executes the instructions to project representative image tiles from the plurality of image tiles onto the planar representation.
12. The platform of claim 1, wherein the processor executes the instructions to generate, at the interface tool, a class activation map having the region of interest and the predicted region of interest type.
13. The platform of claim 1, wherein the pathology features and the predicted region of interest type comprise a tumor type selected from the group of a cancer tumor type, a brain tumor type, and a lung tumor type.
14. (canceled)
15. (canceled)
16. A process for digital pathology upon an unclassified pathology image comprising: receiving the unclassified pathology image; determining a region of interest on a pathology slide and a predicted region of interest (ROI) type by classifying a plurality of pathology features abstracted from the pathology slide by the processor using a convolutional neural network that models a hyperdimensional space, the convolutional neural network trained using pathology images, the convolutional neural network stored on a memory accessible by the processor; generating output indications on the pathology image by the processor using the classification data, the output indications comprising the region of interest, the predicted region of interest type, and optionally a surface map showing a basis of the prediction for the predicted region of interest type; and visually annotating the pathology image using the processor to generate an interface tool with the output indications.
17. A computer product with non-transitory computer readable media storing program instructions to configure a processor to: determine a region of interest on a pathology slide and a predicted region of interest (ROI) type by classifying a plurality of pathology features abstracted from the pathology slide by the processor using a convolutional neural network that models a hyperdimensional space, the convolutional neural network trained using pathology images, the convolutional neural network stored on a memory accessible by the processor; generate output indications of the region of interest on a visual representation of the pathology slide and annotations of the predicted region of interest type on the visual representation of the pathology slide; and update an interface tool to display the output indications and the annotations on a display device.
18. The computer product of claim 17, wherein the instructions configure the processor to determine the predicted region of interest type by determining a mapping of the region of interest to a portion of the hyperdimensional space, wherein the portion recognizes one or more of the plurality of pathology features consistent with the predicted region of interest type.
19. The computer product of claim 17, wherein the instructions configure the processor to generate the output indications comprising a surface map showing the basis of a prediction for the predicted region of interest type, the surface map being a reduced dimensionality view of a classification for the predicted region of interest type.
20. The computer product of claim 17, wherein the instructions configure the processor to use a first convolutional neural network to classify the pathology slide and, based on the classification, select a second convolutional neural network to determine the region of interest on the pathology slide.
21. The computer product of claim 17, wherein the output indications comprise an original pathology slide, a false colour slide showing the region of interest, an overall view of the original pathology slide and the false colour slide, and a legend indicating the predicted region of interest type and an associated false colour.
22. 22-31. (canceled)
32. The computer platform for digital pathology of claim 1 wherein the processor executes the instructions to: detect a lesion on a pathology slide by implementing multi-class lesion segmentation using the convolutional neural network; determine a lesion classification of the detected lesion by implementing multi-class lesion classification using the convolutional neural network; determine a lesion sub-classification of the lesion classification by implementing lesion sub-classification using the convolutional neural network; and generate, at the interface tool for display on the display device, the output indication comprising the lesion sub-classification on a visual representation of the pathology slide.
</claims>
</document>
