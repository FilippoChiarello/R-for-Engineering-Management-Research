<document>

<filing_date>
2020-07-02
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2019-07-03
</priority_date>

<ipc_classes>
G06F3/01,G06N20/00,G06N5/04
</ipc_classes>

<assignee>
SAEC/Kinetic Vision, Inc.
</assignee>

<inventors>
JARRETT, JEREMY, DAVID
Schweet, Richard Raymond
Hartshorn, Kyle Robert
Cypher, Kyle Dean
Fye, Matthew David
Scharf, Melissa Yenni
Lisy, Alec Brenders
Meyer, Emily Ann
Sweeney, Gregory Ryan
Ruggiero, Bendenetto Christopher
</inventors>

<docdb_family_id>
74065207
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR VIRTUAL ARTIFICIAL INTELLIGENCE DEVELOPMENT AND TESTING
</title>

<abstract>
Systems and methods are provided to create training data, validate, deploy and test artificial intelligence (AI) systems in a virtual development environment, incorporating virtual spaces, objects, machinery, devices, subsystems, and actual human action and behavior.
</abstract>

<claims>
We claim:
1. A computer implemented method, comprising: provisioning, by a virtual environment computer system, a virtual environment to a first human actor through a first virtual reality interface of a first virtual reality device worn by the first human actor; simultaneously provisioning, by the virtual environment computer system, the virtual environment to a second human actor through a second virtual reality interface of a second virtual reality device worn by the second human actor, wherein the first and second human actors are physically positioned in a studio, wherein the virtual environment is a digital twin of a real-world physical environment; tracking, by the virtual environment computer system, real-time physical motion of the first human actor within the studio; tracking, by the virtual environment computer system, real-time physical motion of the second human actor within the studio; presenting in the virtual environment of the first human actor, at least a portion of a first humanoid avatar replicating the real-time physical motion of the first human actor and a second humanoid avatar replicating the real-time physical motion of the second human actor; presenting in the virtual environment of the second human actor, at least a portion of the second humanoid avatar replicating the real-time physical motion of the second human actor and the first humanoid avatar replicating the real-time physical motion of the first human actor; and testing an artificial intelligence computing system based on the tracking of the real-time physical motion of the first and second human actors within the studio.
2. The computer implemented method of claim 1, wherein the tracking of the real-time physical motion of the first and second human actors comprises tracking the real-time physical motion of the first and second human actors using a motion capture system.
3. The computer implemented method of claim 2, wherein the motion capture system comprises a first plurality of markers worn by the first human actor in the studio and a second plurality of markers worn by the second human actor in the studio.
4. The computer implemented method of claim 3, wherein the first and second plurality of spatial markers are any of passive markers and active trackers.
5. The computer implemented method of claim 2, wherein the motion capture system is a non-optical motion capture system.
6. The computer implemented method of claim 1, wherein the tracking of the real-time physical motion of the first and second human actors comprises tracking real-time physical motion of appendages of the first human actor using a motion capture system and tracking real-time physical motion of appendages of the second human actor using a motion capture system.
7. The computer implemented method of claim 1, wherein tracking of the real-time physical motion of the first and second human actors comprises tracking real-time physical motion of digits of the first human actor using a motion capture system and tracking real-time physical motion of digits of the second human actor using a motion capture system.
8. The computer implemented method of claim 1, wherein a virtual object is presented to the virtual environments of the first and second human actors through the first and second virtual reality interfaces, respectively, wherein the virtual object is modeled from a real-world physical object associated with the real-world physical environment, wherein a physical training object is physically positioned in the studio with the human actor, wherein the physical training object is either a mock-up of the real-world physical object or the real-world physical object.
9. The computer implemented method of claim 8, wherein the real-world physical environment is a retail environment, and wherein the virtual object is modeled from a real-world retail product.
10. The computer implemented method of claim 8, wherein the real-world physical environment is a surgical environment, and wherein the virtual object is modeled from a real-world surgical instrument.
11. The computer implemented method of claim 10, wherein the physical training object is an interactive mock-up of the surgical instrument, wherein the interactive mock-up of the surgical instrument comprises a physical actuator.
12. The computer implemented method of claim 11, further comprising: responsive to either of the first or second human actors actuating the physical actuator of the interactive mock-up, presenting to the first and second human actors an actuation of the virtual object in the virtual environment through the first and second virtual reality interfaces, respectively.
13. The computer implemented method of claim 8, wherein the physical training obj ect comprises a physical actuator.
14. The computer implemented method of claim 13, further comprising: responsive to either of the first or second human actors actuating the physical actuator of the physical training object, presenting to the first and second human actors an actuation of the virtual object in the virtual environment through the first and second virtual reality interfaces, respectively.
15. The computer implemented method of claim 8, wherein a plurality of virtual objects are presented in the virtual environment and a plurality of corresponding physical training objects are physically positioned within the studio.
16. The computer implemented method of claim 8, wherein the virtual object is modeled from an object actual physical object that is in existence at the time of modeling.
17. The computer implemented method of claim 8, wherein the virtual object is modeled from a proposed real-world physical object.
18. The computer implemented method of claim 1, wherein testing the artificial intelligence computing system comprises: varying a plurality of operational conditions of the virtual environment; and identifying a performance metric based on the interaction of the first and second human actors.
19. The computer implemented method of claim 18, subsequent to testing the artificial intelligence computing system, deploying the artificial intelligence computing system at the real-world physical environment for tracking of humans and human actions within the real-world physical environment.
20. The computer implemented method of claim 1, wherein the virtual environment is a digital twin of an actual real-world physical environment that is in existence at the time of modeling.
21. The computer implemented method of claim 1, wherein the virtual environment is a digital twin of a proposed real-world physical environment.
22. A computer implemented method, comprising: provisioning, by a virtual environment computer system, a virtual environment to a human actor through a virtual reality interface of a virtual reality device worn by the human actor, wherein the human actor is physically positioned in a studio, wherein the virtual environment is a digital twin of a real-world physical environment, wherein a virtual object is presented to the human actor in the virtual environment through the virtual reality interface, wherein the virtual object is modeled from a real-world physical obj ect associated with the real-world physical environment, wherein a physical training object is physically positioned in the studio with the human actor, wherein the physical training object is either a mock-up of the real-world physical object or the real-world physical object; tracking, by the virtual environment computer system, real-time physical motion of the human actor within the studio; tracking, by the virtual environment computer system, an interaction of the human actor with the physical training object; and testing an artificial intelligence computing system based on the tracking of the real-time physical motion of the human actor within the studio and the tracking of the interaction of the human actor with the physical training object.
23. The computer implemented method of claim 22, wherein the tracking of the real-time physical motion of the human actor comprises tracking the real-time physical motion of the human actor using a motion capture system.
24. The computer implemented method of claim 22, wherein the real-world physical environment is any of a retail environment, a surgical environment, an industrial environment, a medical environment, a marine environment, a manufacturing environment, a military environments, and an outdoor environment.
25. The computer implemented method of claim 22, wherein real-world physical environment is a surgical environment and the physical training object is an interactive mock-up of the surgical instrument, wherein the interactive mock-up of the surgical instrument comprises a physical actuator, and wherein the method further comprises: responsive to the human actor actuating the physical actuator of the interactive mock-up, presenting to the human actor in the virtual environment through the virtual reality interface an actuation of the virtual object.
26. The computer implemented method of claim 22, wherein the physical training object comprises a physical actuator and wherein the method further comprises: responsive to the human actor actuating the physical actuator of the physical training object, presenting to the human actor in the virtual environment through the virtual reality interface an actuation of the virtual object.
27. The computer implemented method of claim 22, wherein testing an artificial intelligence computing system further comprises: varying a plurality of operational conditions of the virtual environment; and identifying a performance metric based on the interaction of the human actor with the virtual object.
28. The computer implemented method of claim 27, subsequent to testing the artificial intelligence computing system, deploying the artificial intelligence computing system at the real-world physical environment for tracking of humans and human actions within the real-world physical environment.
29. The computer implemented method of claim 22, wherein the virtual environment is a digital twin of a real-world physical environment that is in existence at the time of modeling or a digital twin of a proposed real-world physical environment
30. The computer implemented method of claim 22, wherein the virtual object is modeled from a real-world physical object that is in existence at the time of modeling or a proposed real-world physical object.
</claims>
</document>
