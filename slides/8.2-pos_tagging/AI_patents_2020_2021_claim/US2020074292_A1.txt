<document>

<filing_date>
2018-08-29
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2018-08-29
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
KURATA, GAKUTO
AUDHKHASI, KARTIK
</inventors>

<docdb_family_id>
69642330
</docdb_family_id>

<title>
KNOWLEDGE TRANSFER BETWEEN RECURRENT NEURAL NETWORKS
</title>

<abstract>
Knowledge transfer between recurrent neural networks is performed by obtaining a first output sequence from a bidirectional Recurrent Neural Network (RNN) model for an input sequence, obtaining a second output sequence from a unidirectional RNN model for the input sequence, selecting at least one first output from the first output sequence based on a similarity between the at least one first output and a second output from the second output sequence; and training the unidirectional RNN model to increase the similarity between the at least one first output and the second output.
</abstract>

<claims>
1. A computer-implemented method comprising: obtaining a first output sequence from a bidirectional Recurrent Neural Network (RNN) model for an input sequence; obtaining a second output sequence from a unidirectional RNN model for the input sequence; selecting at least one first output from the first output sequence based on a similarity between the at least one first output and a second output from the second output sequence; and training the unidirectional RNN model to increase the similarity between the at least one first output and the second output.
2. The computer-implemented method of claim 1, wherein the at least one first output includes an output that appears sequentially earlier in the first output sequence than the second output appears in the second output sequence.
3. The computer-implemented method of claim 1, wherein selecting the at least one first output includes searching for the at least one first output within a predetermined range in the first output sequence, wherein the predetermined range is determined from an index of the second output in the second output sequence.
4. The computer-implemented method of claim 1, wherein selecting the at least one first output includes selecting, for each second output from the second output sequence, at least one first corresponding output from the first output sequence, wherein each second output appears in a same relative sequential order in the second output sequence as each of the at least one corresponding first output in the first output sequence.
5. The computer-implemented method of claim 1, wherein training the unidirectional RNN model includes training the unidirectional RNN model to increase the similarity between a first distribution of the at least one first output and a second distribution of the second output.
6. The computer-implemented method of claim 5, wherein training the unidirectional RNN model includes training the unidirectional RNN model to decrease Kullback-Leibler (KL) divergence between the first distribution and the second distribution.
7. The computer-implemented method of claim 5, wherein the first distribution is a weighted sum of distributions of each of the at least one first output.
8. The computer-implemented method of claim 7, wherein selecting the at least one first output includes determining weights of the weighted sum of distributions of each of the at least one first output based on similarity of distribution of each of the at least one first output individually compared with the second output.
9. The computer-implemented method of claim 1, further comprising training the bidirectional RNN model before training the unidirectional RNN model.
10. The computer-implemented method of claim 1, wherein the bidirectional RNN model is a bidirectional Long Short-Term Memory (LSTM) and the unidirectional RNN model is a unidirectional LSTM.
11. The computer-implemented method of claim 10, further comprising training the unidirectional LSTM model by using Connectionist Temporal Classification (CTC) training.
12. The computer-implemented method of claim 1, wherein the input sequence is an audio sequence of a speech, and the first output sequence and the second output sequence are phoneme sequences.
13. A computer program product including one or more computer readable storage mediums collectively storing program instructions that are executable by a processor or programmable circuitry to cause the processor or programmable circuitry to perform operations comprising: obtaining a first output sequence from a bidirectional RNN (Recurrent Neural Network) model for an input sequence; obtaining a second output sequence from a unidirectional RNN model for the input sequence; selecting at least one first output from the first output sequence based on a similarity between the at least one first output and a second output from the second output sequence; and training the unidirectional RNN model to increase the similarity between the at least one first output and the second output.
14. The computer program product of claim 13, wherein selecting the at least one first output includes searching for the at least one first output within a predetermined range in the first output sequence, wherein the predetermined range is determined from an index of the second output in the second output sequence.
15. The computer program product of claim 13, wherein training the unidirectional RNN model includes training the unidirectional RNN model to increase the similarity between a first distribution of the at least one first output and a second distribution of the second output.
16. The computer program product of claim 13, wherein the first distribution is a weighted sum of distributions of each of the at least one first output.
17. An apparatus comprising: a processor or a programmable circuitry; and one or more computer readable mediums collectively including instructions that, when executed by the processor or the programmable circuitry, cause the processor or the programmable circuitry to: obtain a first output sequence from a bidirectional RNN (Recurrent Neural Network) model for an input sequence; obtain a second output sequence from a unidirectional RNN model for the input sequence; select at least one first output from the first output sequence based on a similarity between the at least one first output and a second output from the second output sequence; and train the unidirectional RNN model to increase the similarity between the at least one first output and the second output.
18. The apparatus of claim 17, wherein the instructions that cause the processor or the programmable circuitry to select the at least one first output include instructions that cause the processor or the programmable circuitry to search for the at least one first output within a predetermined range in the first output sequence, wherein the predetermined range is determined from an index of the second output in the second output sequence.
19. The apparatus of claim 17, wherein instructions that cause the processor or the programmable circuitry to train the unidirectional RNN model include instructions that cause the processor or the programmable circuitry to train the unidirectional RNN model to increase the similarity between a first distribution of the at least one first output and a second distribution of the second output.
20. The apparatus of claim 17, wherein the first distribution is a weighted sum of distributions of each of the at least one first output.
21. A computer-implemented method comprising: obtaining a first output sequence from a bidirectional RNN (Recurrent Neural Network) model for an input sequence; obtaining a second output sequence from a unidirectional RNN model for the input sequence; selecting at least one first output from the first output sequence, where the at least one first output includes a first output that appears sequentially earlier in the first output sequence than a second output appears in the second sequence; and training the unidirectional RNN model to increase the similarity between the at least one first output and the second output.
22. The computer-implemented method of claim 21, wherein training the unidirectional RNN model includes training the unidirectional RNN model to increase the similarity between a first distribution of the at least one first output and a second distribution of the second output.
23. The computer-implemented method of claim 22, wherein the first distribution is a weighted sum of distributions of each of the at least one first output.
24. A computer program product including one or more computer readable storage mediums collectively storing program instructions that are executable by a processor or programmable circuitry to cause the processor or programmable circuitry to perform operations comprising: obtaining a first output sequence from a bidirectional RNN (Recurrent Neural Network) model for an input sequence; obtaining a second output sequence from a unidirectional RNN model for the input sequence; selecting at least one first output from the first output sequence, where the at least one first output includes a first output that appears sequentially earlier in the first output sequence than a second output appears in the second sequence; and training the unidirectional RNN model to increase the similarity between the at least one first output and the second output.
25. The computer program product of claim 13, wherein training the unidirectional RNN model includes training the unidirectional RNN model to increase the similarity between a first distribution of the at least one first output and a second distribution of the second output.
</claims>
</document>
