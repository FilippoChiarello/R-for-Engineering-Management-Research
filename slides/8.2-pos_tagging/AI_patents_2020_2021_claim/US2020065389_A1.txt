<document>

<filing_date>
2019-11-01
</filing_date>

<publication_date>
2020-02-27
</publication_date>

<priority_date>
2017-10-10
</priority_date>

<ipc_classes>
G06F17/16,G06K9/62,G06N3/08
</ipc_classes>

<assignee>
TENCENT TECHNOLOGY (SHENZHEN) COMPANY
</assignee>

<inventors>
CAO, RONGYU
LIN, FEN
LU, YANAN
</inventors>

<docdb_family_id>
63375263
</docdb_family_id>

<title>
SEMANTIC ANALYSIS METHOD AND APPARATUS, AND STORAGE MEDIUM
</title>

<abstract>
A semantic analysis method includes: inputting a word vector of each word in each sample sentence in a dialog flow into an encoder model, to obtain a sentence vector representing semantics of the sample sentence; inputting the sentence vector into a first decoder model corresponding to each context sentence of the sample sentence and a second decoder model corresponding to each word of the sample sentence, to obtain a first identifier corresponding to the context sentence and a second identifier corresponding to the word; obtaining a probability of the first identifier and a probability of the second identifier, and determining a value of a target function; performing parameter training on the encoder model according to the value of the target function; and inputting a word vector of each word in a test sentence into the trained encoder model, to obtain a sentence vector representing semantics of the test sentence.
</abstract>

<claims>
1. A semantic analysis method for a computer device, comprising: inputting, for each sample sentence in a dialog flow, a word vector of each word in the sample sentence into an encoder model, to obtain a sentence vector representing semantics of the sample sentence; inputting the sentence vector of the sample sentence into a first decoder model corresponding to each context sentence of the sample sentence, to obtain a first identifier corresponding to the context sentence; inputting the sentence vector of the sample sentence into a second decoder model corresponding to each word of the sample sentence, to obtain a second identifier corresponding to the word; obtaining a first probability corresponding to the first identifier according to the first decoder models, obtaining a second probability corresponding to the second identifier according to the second decoder models, and determining a value of a target function, the value of the target function being used for indicating that the sentence vector of the sample sentence represents a semantic accuracy degree; performing parameter training on the encoder model according to the value of the target function; and inputting a word vector of each word in a test sentence into the trained encoder model, to obtain a sentence vector representing semantics of the test sentence.
2. The semantic analysis method according to claim 1, wherein: the encoder model uses a convolutional neural network model; and the inputting, for each sample sentence in a dialog flow, a word vector of each word in the sample sentence into an encoder model, to obtain a sentence vector representing semantics of the sample sentence comprises: inputting the word vector of each word in the sample sentence into the convolutional neural network model, to obtain a sentence vector of the sample sentence that is outputted by a last layer in the convolutional neural network model.
3. The semantic analysis method according to claim 2, wherein a word vector of a kth word of the sample sentence is Wjk(i)·Eencoder in a case that the sample sentence is a jth sentence in an ith group of dialog flows, wherein Wjk(i) is an identifier of the kth word of the sample sentence, and Eencoder is a word vector matrix of the convolutional neural network model.
4. The semantic analysis method according to claim 2, wherein the first decoder model and the second decoder model both use a deep neural network model; the performing parameter training on the encoder model according to the value of the target function comprises: performing parameter training on a word vector matrix of the convolutional neural network model, a weight matrix of the convolutional neural network model, and a bias vector of the convolutional neural network model in the encoder model according to the value of the target function; and the method further comprises: performing parameter training on a weight matrix of the deep neural network model and a bias vector of the deep neural network model in the first decoder model and the second decoder model according to the value of the target function.
5. The semantic analysis method according to claim 1, wherein the obtaining a first probability corresponding to the first identifier according to the first decoder models, obtaining a second probability corresponding to the second identifier according to the second decoder models, and determining a value of a target function comprises: calculating, in a case that the sample sentence is an jth sentence in an ith group of dialog flows, a value of a first term of the target function according to a probability at which each first decoder model outputs a first identifier sj±q(i) corresponding to a context sentence in response to inputting a sentence vector vj(i) of the sample sentence, wherein q=1, 2, . . . , Q, N is a total number of groups of dialog flows, and T is a total number of sentences comprised in the ith group of dialog flows; calculating a value of a second term of the target function according to a probability at which each second decoder model outputs a second identifier Wjk(i) corresponding to a word in the sample sentence in response to inputting the sentence vector vj(i) of the sample sentence, wherein M is a total number of words in the sample sentence; and summing the value of the first term and the value of the second term, to obtain the value of the target function.
6. The semantic analysis method according to claim 1, wherein: before the inputting a word vector of each word in a test sentence into the trained encoder model, the method further comprises: using a question inputted by a user end as the test sentence; and after the obtaining a sentence vector representing semantics of the test sentence, the method further comprises: querying, according to the sentence vector of the test sentence, a question library to obtain a prestored question; and sending an answer corresponding to the prestored question to the user end.
7. A semantic analysis apparatus, comprising: a memory storing computer program instructions; and a processor coupled to the memory and, when executing the computer program instructions, configured to perform: inputting, for each sample sentence in a dialog flow, a word vector of each word in the sample sentence into an encoder model, to obtain a sentence vector representing semantics of the sample sentence; inputting the sentence vector of the sample sentence into a first decoder model corresponding to each context sentence of the sample sentence, to obtain a first identifier corresponding to the context sentence; inputting the sentence vector of the sample sentence into a second decoder model corresponding to each word of the sample sentence, to obtain a second identifier corresponding to the word; obtaining a first probability corresponding to the first identifier according to the first decoder models, obtaining a second probability corresponding to the second identifier according to the second decoder models, and determining a value of a target function, the value of the target function being used for indicating that the sentence vector of the sample sentence represents a semantic accuracy degree; performing parameter training on the encoder model according to the value of the target function; and inputting a word vector of each word in a test sentence into the trained encoder model, to obtain a sentence vector representing semantics of the test sentence.
8. The semantic analysis apparatus according to claim 7, wherein: the encoder model uses a convolutional neural network model; and the inputting, for each sample sentence in a dialog flow, a word vector of each word in the sample sentence into an encoder model, to obtain a sentence vector representing semantics of the sample sentence comprises: inputting the word vector of each word in the sample sentence into the convolutional neural network model, to obtain a sentence vector of the sample sentence that is outputted by a last layer in the convolutional neural network model.
9. The semantic analysis apparatus according to claim 8, wherein a word vector of a kth word of the sample sentence is Wjk(i)·Eencoder in a case that the sample sentence is a jth sentence in an ith group of dialog flows, wherein Wjk(i) is an identifier of the kth word of the sample sentence, and Eencoder is a word vector matrix of the convolutional neural network model.
10. The semantic analysis apparatus according to claim 8, wherein the first decoder model and the second decoder model both use a deep neural network model; the performing parameter training on the encoder model according to the value of the target function comprises: performing parameter training on a word vector matrix of the convolutional neural network model, a weight matrix of the convolutional neural network model, and a bias vector of the convolutional neural network model in the encoder model according to the value of the target function; and the processor is further configured to perform: performing parameter training on a weight matrix of the deep neural network model and a bias vector of the deep neural network model in the first decoder model and the second decoder model according to the value of the target function.
11. The semantic analysis apparatus according to claim 7, wherein the obtaining a first probability corresponding to the first identifier according to the first decoder models, obtaining a second probability corresponding to the second identifier according to the second decoder models, and determining a value of a target function comprises: calculating, in a case that the sample sentence is an jth sentence in an ith group of dialog flows, a value of a first term of the target function according to a probability at which each first decoder model outputs a first identifier sj±q(i) corresponding to a context sentence in response to inputting a sentence vector vj(i) of the sample sentence, wherein q=1, 2, . . . , Q, N is a total number of groups of dialog flows, and T is a total number of sentences comprised in the ith group of dialog flows; calculating a value of a second term of the target function according to a probability at which each second decoder model outputs a second identifier Wjk(i) corresponding to a word in the sample sentence in response to inputting the sentence vector vj(i) of the sample sentence, wherein M is a total number of words in the sample sentence; and summing the value of the first term and the value of the second term, to obtain the value of the target function.
12. The semantic analysis apparatus according to claim 7, wherein: before the inputting a word vector of each word in a test sentence into the trained encoder model, the processor is further configured to perform: using a question inputted by a user end as the test sentence; and after the obtaining a sentence vector representing semantics of the test sentence, the processor is further configured to perform: querying, according to the sentence vector of the test sentence, a question library to obtain a prestored question; and sending an answer corresponding to the prestored question to the user end.
13. A non-transitory computer-readable storage medium storing computer program instructions executable by at least one processor to perform: inputting, for each sample sentence in a dialog flow, a word vector of each word in the sample sentence into an encoder model, to obtain a sentence vector representing semantics of the sample sentence; inputting the sentence vector of the sample sentence into a first decoder model corresponding to each context sentence of the sample sentence, to obtain a first identifier corresponding to the context sentence; inputting the sentence vector of the sample sentence into a second decoder model corresponding to each word of the sample sentence, to obtain a second identifier corresponding to the word; obtaining a first probability corresponding to the first identifier according to the first decoder models, obtaining a second probability corresponding to the second identifier according to the second decoder models, and determining a value of a target function, the value of the target function being used for indicating that the sentence vector of the sample sentence represents a semantic accuracy degree; performing parameter training on the encoder model according to the value of the target function; and inputting a word vector of each word in a test sentence into the trained encoder model, to obtain a sentence vector representing semantics of the test sentence.
14. The non-transitory computer-readable storage medium according to claim 13, wherein: the encoder model uses a convolutional neural network model; and the inputting, for each sample sentence in a dialog flow, a word vector of each word in the sample sentence into an encoder model, to obtain a sentence vector representing semantics of the sample sentence comprises: inputting the word vector of each word in the sample sentence into the convolutional neural network model, to obtain a sentence vector of the sample sentence that is outputted by a last layer in the convolutional neural network model.
15. The non-transitory computer-readable storage medium according to claim 14, wherein a word vector of a kth word of the sample sentence is Wjk(i)·Eencoder in a case that the sample sentence is a jth sentence in an ith group of dialog flows, wherein Wjk(i) is an identifier of the kth word of the sample sentence, and Eencoder is a word vector matrix of the convolutional neural network model.
16. The non-transitory computer-readable storage medium according to claim 14, wherein the first decoder model and the second decoder model both use a deep neural network model; the performing parameter training on the encoder model according to the value of the target function comprises: performing parameter training on a word vector matrix of the convolutional neural network model, a weight matrix of the convolutional neural network model, and a bias vector of the convolutional neural network model in the encoder model according to the value of the target function; and the computer program instructions are executable by the processor to further perform: performing parameter training on a weight matrix of the deep neural network model and a bias vector of the deep neural network model in the first decoder model and the second decoder model according to the value of the target function.
17. The non-transitory computer-readable storage medium according to claim 13, wherein the obtaining a first probability corresponding to the first identifier according to the first decoder models, obtaining a second probability corresponding to the second identifier according to the second decoder models, and determining a value of a target function comprises: calculating, in a case that the sample sentence is an jth sentence in an ith group of dialog flows, a value of a first term of the target function according to a probability at which each first decoder model outputs a first identifier sj±q(i) corresponding to a context sentence in response to inputting a sentence vector vj(i) of the sample sentence, wherein q=1, 2, . . . , Q, N is a total number of groups of dialog flows, and T is a total number of sentences comprised in the ith group of dialog flows; calculating a value of a second term of the target function according to a probability at which each second decoder model outputs a second identifier Wjk(i) corresponding to a word in the sample sentence in response to inputting the sentence vector vj(i) of the sample sentence, wherein M is a total number of words in the sample sentence; and summing the value of the first term and the value of the second term, to obtain the value of the target function.
18. The non-transitory computer-readable storage medium according to claim 13, wherein: before the inputting a word vector of each word in a test sentence into the trained encoder model, the computer program instructions are executable by the processor to further perform: using a question inputted by a user end as the test sentence; and after the obtaining a sentence vector representing semantics of the test sentence, the computer program instructions are executable by the processor to further perform: querying, according to the sentence vector of the test sentence, a question library to obtain a prestored question; and sending an answer corresponding to the prestored question to the user end.
</claims>
</document>
