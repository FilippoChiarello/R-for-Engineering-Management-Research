<document>

<filing_date>
2020-04-21
</filing_date>

<publication_date>
2020-10-29
</publication_date>

<priority_date>
2019-04-22
</priority_date>

<ipc_classes>
G03H1/00,G03H1/08
</ipc_classes>

<assignee>
UNIVERSITY OF CALIFORNIA
</assignee>

<inventors>
OZCAN, AYDOGAN
ZHANG, YIBO
RIVENSON, YAIR
WEI, ZHENSONG
LIU, TAIRAN
</inventors>

<docdb_family_id>
72941351
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR DEEP LEARNING-BASED COLOR HOLOGRAPHIC MICROSCOPY
</title>

<abstract>
A method for performing color image reconstruction of a single super-resolved holographic sample image includes obtaining a plurality of sub-pixel shifted lower resolution hologram images of the sample using an image sensor by simultaneous illumination at multiple color channels. Super-resolved hologram intensity images for each color channel are digitally generated based on the lower resolution hologram images. The super-resolved hologram intensity images for each color channel are back propagated to an object plane with image processing software to generate a real and imaginary input images of the sample for each color channel. A trained deep neural network is provided and is executed by image processing software using one or more processors of a computing device and configured to receive the real input image and the imaginary input image of the sample for each color channel and generate a color output image of the sample.
</abstract>

<claims>
1. A method of performing color image reconstruction of a single super-resolved holographic image of a sample comprising:
obtaining a plurality of sub-pixel shifted lower resolution hologram intensity images of the sample using an image sensor by simultaneous illumination of the sample at a plurality of color channels;
digitally generating super-resolved hologram intensity images for each of the plurality of color channels based on the plurality of sub-pixel shifted lower resolution hologram intensity images;
back propagating the super-resolved hologram intensity images for each of the plurality of color channels to an object plane with image processing software to generate an amplitude input image and a phase input image of the sample for each of the plurality of color channels; and
providing a trained deep neural network that is executed by image processing software using one or more processors of a computing device and configured to receive the amplitude input image and the phase input image of the sample for each of the plurality of color channels and output a color output image of the sample.
2. The method of claim 1, wherein the plurality of color channels comprises three color channels.
3. The method of claim 2, wherein the three color channels comprise red, green, and blue color channels.
4. The method of claim 1, wherein simultaneous illumination of the sample comprises illuminating the sample simultaneously with three different wavelengths of illumination.
5. The method of claim 4, wherein the three different wavelengths comprise 450 nm, 540 run, and 590 nm.
6. The method of claim 1, wherein the plurality of sub-pixel shifted low er resolution hologram intensity images are obtained by moving the image sensor in an x, y plane coupled to a moveable stage.
7. The method of claim 1, wherein the plurality of sub-pixel shifted lower resolution hologram intensity images are obtained by moving a sample holder holding the sample in an x, y plane.
8. The method of claim 1 , wherein the plurality of sub-pixel shifted lower resolution hologram intensity images are obtained by selective illumination of light sources from an array of light sources.
9. The method of claim 1, wherein the plurality of sub-pixel shifted lower resolution hologram intensity images are obtained by moving an illumination source in a plane or by using illumination from a plurality of illumination sources.
10. The method of any of claims 1-7, wherein the sample comprises stained or labeled tissue.
11. The method of any of claims 1-7, wherein the sample comprises stained cytology' slides.
12. The method of claim 1 , further comprising digitally stitching with image processing software a plurality of color output images into a larger output image.
13. The method of claim 12, wherein the larger output image comprises a field-ofview comprising at least 10 mm2 and wherein the larger output image is generated in under 10 minutes.
14. The method of claim 12, wherein the trained deep neural network outputs the color output image of the sample within several minutes of receiving the amplitude input image(s) and the phase input image(s) of the sample.
15. The method of claim 1, wherein the trained deep neural network is trained using a Generative Adversarial Network (GAN) model.
16. A system for performing color image reconstruction of a super-resolved holographic image of a sample comprising: a computing device having image processing software executed thereon, the image processing software comprising attained deep neural network that is executed using one or more processors of the computing device, wherein the trained deep neural network is trained with a plurality of training images or image patches from a super-resolved hologram of the image of the sample and corresponding ground truth or target color images or image patches , the trained deep neural network configured to receive one or more super-resolved holographic images of the sample generated by the image processing softw are from multiple low-resolution images of the sample obtained with simultaneous illumination of the sample at a plurality of illumination wavelengths and output a reconstructed color image of the sample.
17. The system of claim 16, wherein the corresponding ground truth or target color images are numerically computed.
18. The system of claim 16, wherein the corresponding ground truth or target color images are obtained from brightfield color images of the same samples.
19. The system of claim 16, further comprising a microscope device that obtains multiple low-resolution images of the sample, the microscope device comprising a sample holder for holding the sample, a color image sensor, and one or more light sources emitting light at the plurality of wavelengths.
20. The system of claim 17, wherein the microscope device comprises a moveable stage configured to move one or both of the color image sensor and/or sample holder in an x, y plane to obtain the multiple low-resolution images of the sample.
21. The system of claim 17, wherein the plurality of light sources comprise an array of light sources.
22. The system of claim 16, wherein the trained deep neural network is trained using a Generative Adversarial Network (GAN) model.
23. A system for performing color image reconstruction of a one or more superresolved holographic image(s) of a sample comprising:
a lensfree microscope device comprising a sample holder for holding the sample, a color image sensor, and one or more optical fiber(s) or cable(s) coupled to respective different colored light sources configured to simultaneously emit light at a plurality of wavelengths;
at least one of a moveable stage or an array of light sources configured to obtain sub-pixel shifted lower resolution hologram intensity images of the sample; and
a computing device having image processing software executed thereon, the image processing software comprising a trained deep neural network that is executed using one or more processors of the computing device, wherein the trained deep neural network is trained with a plurality of training images or image patches from a super-resolved hologram of the image of the sample and corresponding ground truth or target color images or image patches generated from hyperspectral imaging or brightfield microscop)', the trained deep neural network configured to receive one or more super-resolved holographic images of the sample generated by the image processing software from the sub-pixel shifted lower resolution hologram intensity images of the sample obtained with simultaneous illumination of the sample and output a reconstructed color image of the sample.
24. The system of claim 23, wherein the trained deep neural network is trained using a Generative Adversarial Network (GAN) model.
</claims>
</document>
