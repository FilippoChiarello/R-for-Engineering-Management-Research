<document>

<filing_date>
2019-04-08
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-08
</priority_date>

<ipc_classes>
G06F17/15,G06K9/62,G06N3/04,G06N3/08,G06T7/143
</ipc_classes>

<assignee>
NVIDIA CORPORATION
</assignee>

<inventors>
KAUTZ, JAN
HUNG, WEI-CHIH
LIU, SIFEI
MOLCHANOV, PAVLO
Jampani, Varun
</inventors>

<docdb_family_id>
70110156
</docdb_family_id>

<title>
SEGMENTATION USING AN UNSUPERVISED NEURAL NETWORK TRAINING TECHNIQUE
</title>

<abstract>
Systems and methods to detect one or more segments of one or more objects within one or more images based, at least in part, on a neural network trained in an unsupervised manner to infer the one or more segments. Systems and methods to help train one or more neural networks to detect one or more segments of one or more objects within one or more images in an unsupervised manner.
</abstract>

<claims>
1. A processor, comprising: one or more arithmetic logic units (ALUs) to be configured to detect one or more segments of one or more objects within one or more images based, at least in part, on a neural network trained in an unsupervised manner to infer the one or more segments.
2. The processor of claim 1, wherein the neural network is trained in an unsupervised manner based at least in part on one or more loss functions that encode rules that constrain how segments are determined.
3. The processor of claim 2, wherein the one or more loss functions encode one or more constraints on how segments are generated, including at least one of: a geometric concentration constraint; a spatial invariance constraint; and a semantic consistency constraint.
4. The processor of claim 1, wherein the neural network is trained on a set of images without requiring ground truth indicating whether a segmentation has correctly been identified.
5. The processor of claim 1, wherein the neural network is trained in an unsupervised manner on images that are from any of at least two categories of images.
6. The processor of claim 1, wherein how many segments to detect in an image is a parameter specified by a user to train the neural network.
7. A system, comprising: one or more processors to detect one or more segments of one or more objects within one or more images based, at least in part on a neural network trained in an unsupervised manner to infer the one or more segments; and one or more memories to store parameters associated with the one or more neural networks.
8. The system of claim 7, wherein the neural network is trained based on a set of differentiable loss functions that encode constraints on how to generate the one or more segments.
9. The system of claim 8, wherein the neural network is trained to detect a fixed number of segments in one or more images.
10. The system of claim 7, wherein the neural network is trained in a collection of images that share a category in common with the one or more images.
11. The system of claim 10, wherein the one or more images is one image.
12. The system of claim 7, the neural network is trained without ground truth data indicating whether a segmentation has correctly been identified.
13. The system of claim 7, wherein the neural network is a fully convolutional neural network.
14. An image recognition system comprising: one or more hardware sensors to capture one or more images; one or more processors to detect one or more segments of one or more objects within the one or more images based at least in part on a neural network trained in an unsupervised manner to infer the one or more segments; and one or more memories to store parameters associated with the one or more neural networks.
15. The image recognition system of claim 14, wherein the one or more hardware sensors includes a video capture device and at least a portion of the one or more images is from a video captured by the video capture device.
16. The image recognition system of claim 14, wherein: the image recognition system further comprises one or more data storage systems to store an identity and metadata associated with segments of the identity; and the one or more processors are to be configured to determine, based on having detected the one or more segments, whether the identity is identified in the one or more images.
17. The image recognition system of claim 16, wherein the metadata includes at least one of: skin color; hair color; height; weight; and facial features.
18. The image recognition system of claim 16, wherein the one or more processors to determine whether the identity is an individual.
19. The image recognition system of claim 14, wherein the image recognition system comprises a first computer system comprising the one or more hardware sensors to communicate, via a network, with a second computer system comprising the one or more processors.
20. The image recognition system of claim 14, wherein the one or more segments comprises a background segment.
21. A processor, comprising: one or more arithmetic logic units (ALUs) to be configured to help train one or more neural networks to detect one or more segments of one or more objects within one or more images in an unsupervised manner.
22. The processor of claim 21, wherein the one or more ALUs to help train the one or more neural networks are one or more ALUs to help train the one or more neural networks to detect the one or more segments on a set of training images that lack ground truth annotations.
23. The processor of claim 21, wherein the one or more neural networks are neural networks to be trained based at least in part on one or more rules that constrain segmentation generation based on one or more properties, wherein the one or more properties includes at least one of: geometric density; invariance to spatial transformation; and semantic consistency.
24. The processor of claim 21, wherein neural network is to be trained on a set of images of a category and to predict segments in another image of the category.
25. The processor of claim 21, wherein the processor is communicatively coupled to an image processing system comprising one or more hardware sensors to generate the one or more images.
26. The processor of claim 21, wherein a first segmentation of a first image corresponds to pixels of the first image that are of an object and a second segmentation of a second image corresponds to pixels of the second image that are of the object.
27. A system, comprising: one or more processors to help train one or more neural networks to detect one or more segments of one or more objects within one or more images in an unsupervised manner; and one or more memories to store parameters associated with the one or more neural networks.
28. The system of claim 27, wherein the one or more processors are to help train the one or more neural networks based at least in part on a loss function that encodes one or more constraints on segmentation generation.
29. The system of claim 28, wherein the one or more constraints includes a constraint on geometric concentration that conditions the neural network to minimize variance of a spatial probability distribution.
30. The system of claim 28, wherein the one or more constraints includes a constraint on equivariance and the loss function is calculated based in instructions that, if executed by the one or more processors, causes the one or more processors to: detect a first segmentation of an image; apply one or more transformation operation on the image, thereby generating a transformed image; detect a second segmentation of the transformed image; apply at least a portion of the one or more transformation operations on the image, thereby generating a transformed first segmentation; and compare the transformed first segmentation with the second segmentation.
31. The system of claim 30, wherein: the one or more transformation operations comprises a spatial transform and an appearance perturbation; and the at least portion of the one or more transformation operations includes the spatial transform but lacks the appearance perturbation.
32. The system of claim 30, wherein the transformed first segmentation and the second segmentation are compared by at least computing a Kullback-Leibler divergence distance.
33. The system of claim 27, wherein the one or more processors are to further determine one or more boundaries from the one or more segments.
34. A machine-readable medium having stored thereon a set of instructions, which if performed by one or more processors, cause the one or more processors to at least: train one or more neural networks to detect one or more segments of one or more objects within one or more images in an unsupervised manner; and store parameters associated with the one or more neural networks in one or more memories.
35. The machine-readable medium of claim 34, wherein the instructions to train the one or more neural networks in the unsupervised manner include instructions, which if performed by the one or more processors, cause the one or more processors to at least: obtain an image of the one or more images; obtain, based at least in part on a classification network, a feature map of the image; obtain, based at least in part on a fully convolutional network, a part response map of the image; and determine a loss function to be back-propagated based at least in part on the feature map and the part response map.
36. The machine-readable medium of claim 35, wherein the feature map is bi-linearly upsampled to have a spatial resolution matching that of the image.
37. The machine-readable medium of claim 35, wherein the instructions to train the one or more neural networks in the unsupervised manner include instructions, which if performed by the one or more processors, cause the one or more processors to at least learn a set of part basis vectors shared across at least a portion of the one or more images, wherein the loss function is determined further based at least in part on the set of part basis vectors.
38. The machine-readable medium of claim 37 wherein the instructions to train the one or more neural networks in the unsupervised manner include instructions, which if performed by the one or more processors, cause the one or more processors to at least apply an orthonormal restraint to reduce correlation between vectors of the set of part basis vectors.
39. The machine-readable medium of claim 34, wherein the instructions to train the one or more neural networks in the unsupervised manner include instructions, which if performed by the one or more processors, cause the one or more processors to at least apply a saliency constraint to reduce correlation between a learned part basis and a background of the image.
40. The machine-readable medium of claim 34, wherein the parameters associated with the one or more neural networks include one or more weights determined as part of training the one or more neural networks that are used to detect the one or more segments.
</claims>
</document>
