<document>

<filing_date>
2018-09-25
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-25
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08,H04L25/00
</ipc_classes>

<assignee>
NOKIA TECHNOLOGIES
</assignee>

<inventors>
AIT AOUDIA, FAYCAL
HOYDIS, JAKOB
TCHIKOU, ABDERRAHMANE
</inventors>

<docdb_family_id>
63722374
</docdb_family_id>

<title>
END-TO-END LEARNING IN COMMUNICATION SYSTEMS
</title>

<abstract>
An apparatus, method and computer program is described comprising: initialising parameters of a transmission system, wherein the transmission system comprises a transmitter, a channel and a receiver, wherein the transmitter includes a transmitter algorithm having at least some trainable weights and the receiver includes a receiver algorithm having at least some trainable weights; updating trainable parameters of the transmission system based on a loss function, wherein the trainable parameters include the trainable weights of the transmitter and the trainable weights ofthe receiver and wherein the loss function includes a penalty term; quantizing said trainable parameters, such that said weights can only take values within a codebook having a finite number of entries that is a subset of the possible values available during updating; and repeating the updating and quantizing until a first condition is reached.
</abstract>

<claims>
1. An apparatus comprising:
means for initialising parameters of a transmission system, wherein the
transmission system comprises a transmitter, a channel and a receiver, wherein the transmitter includes a transmitter algorithm having at least some trainable weights and the receiver includes a receiver algorithm having at least some trainable weights;
means for updating trainable parameters of the transmission system based on a loss function, wherein the trainable parameters include the trainable weights of the transmitter and the trainable weights of the receiver and wherein the loss function includes a penalty term;
means for quantizing said trainable parameters, such that said weights can only take values within a codebook having a finite number of entries that is a subset of the possible values available during updating; and
means for repeating the updating and quantizing until a first condition is reached.
2. An apparatus as claimed in claim 1 , wherein said penalty term includes a variable that is adjusted on each repetition of the updating and quantizing such that, on each repetition, more weight is given in the loss function to a difference between the trainable parameters and the quantized trainable parameters.
3. An apparatus as claimed in claim 1 or claim 2, wherein the means for quantizing said trainable parameters expresses said quantized weights using fixed point arithmetic. 4. An apparatus as claimed in any one of claims 1 to 3, further comprising means for updating variables on each repetition.
5. An apparatus as claimed in any one of the preceding claims, wherein the first condition is met when a difference between the trainable parameters and the quantized trainable parameters is below a threshold level.
6. An apparatus as claimed in any one of the preceding claims, wherein the first condition comprises a defined number of iterations. 7. An apparatus as claimed in any one of the preceding claims, further comprising means for scaling a signal received at the receiver by a scaling factor.
8. An apparatus as claimed in claim 7, wherein the scaling factor is such that a dynamic range of the received signal is matched to the codebook.
9. An apparatus as claimed in any one of the preceding claims, wherein said transmitter is implemented as a look-up table.
10. An apparatus as claimed in any one of the preceding claims, wherein the loss function is related to one or more of block error rate, bit error rate and categorical crossentropy.
1 1. An apparatus as claimed in any one of the preceding claims, wherein the means for updating trainable parameters of the transmission system comprises optimising one or more of a batch size of the transmitter-training sequence of messages, a learning rate, and a distribution of the perturbations applied to the perturbed versions of the transmittertraining sequence of messages.
12. An apparatus as claimed in any preceding claim, wherein said at least some weights of the transmitter and receiver algorithms are trained using stochastic gradient descent.
13. An apparatus as claimed in any one of the preceding claims, wherein the transmitter algorithm comprises a transmitter neural network and/or the receiver algorithm comprises a receiver neural network. 14. An apparatus as claimed in any one of the preceding claims, wherein the means comprise:
at least one processor; and
at least one memory including computer program code, the at least one memory and the computer program configured, with the at least one processor, to cause the performance of the apparatus.
15. A method comprising:
initialising parameters of a transmission system, wherein the transmission system comprises a transmitter, a channel and a receiver, wherein the transmitter includes a transmitter algorithm having at least some trainable weights and the receiver includes a receiver algorithm having at least some trainable weights; updating trainable parameters of the transmission system based on a loss function, wherein the trainable parameters include the trainable weights of the transmitter and the trainable weights of the receiver and wherein the loss function includes a penalty term;
quantizing said trainable parameters, such that said weights can only take values within a codebook having a finite number of entries that is a subset of the possible values available during updating; and
repeating the updating and quantizing until a first condition is reached. 16. A method as claimed in claim 15, wherein said penalty term includes a variable that is adjusted on each repetition of the updating and quantizing such that, on each repetition, more weight is given in the loss function to a difference between the trainable parameters and the quantized trainable parameters. 17. A work product comprising a look up table or array, created by means of the method of claim 15 or claim 16.
18. A computer program comprising instructions for causing an apparatus to perform at least the following:
initialise parameters of a transmission system, wherein the transmission system comprises a transmitter, a channel and a receiver, wherein the transmitter includes a transmitter algorithm having at least some trainable weights and the receiver includes a receiver algorithm having at least some trainable weights;
update trainable parameters of the transmission system based on a loss function, wherein the trainable parameters include the trainable weights of the transmitter and the trainable weights of the receiver and wherein the loss function includes a penalty term; quantize said trainable parameters, such that said weights can only take values within a codebook having a finite number of entries that is a subset of the possible values available during updating; and
repeat the updating and quantizing until a first condition is reached.
</claims>
</document>
