<document>

<filing_date>
2018-01-30
</filing_date>

<publication_date>
2020-06-02
</publication_date>

<priority_date>
2017-03-31
</priority_date>

<ipc_classes>
G06K9/00,G06K9/20,G06K9/62,G06K9/78,G06T7/73,G09G5/00
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
MARSHALL, CARL
PANNEER, SELVAKUMAR
RAFFA, GIUSEPPE
TICKOO, OMESH
VARADARAJAN, SRENIVAS
</inventors>

<docdb_family_id>
63670538
</docdb_family_id>

<title>
Technologies for detecting interactions with surfaces from a spherical view of a room
</title>

<abstract>
Technologies for detecting interactions with surfaces from a spherical view of a room include a compute device. The compute device includes an image capture manager to obtain one or more images that depict a spherical view of a room that includes multiple surfaces. Additionally, the compute device includes a surface interaction detection manager to detect, from the one or more images, a person in the room, generate a bounding box around the person, preprocess the bounding box to represent the person in an upright orientation, determine a pose of the person from the preprocessed bounding box, detect an outstretched hand from the determined pose, and determine, from the detected outstretched hand, a surface of interaction in the room.
</abstract>

<claims>
1. A compute device to detect an interaction with a surface in a room from a spherical view of the room, the compute device comprising: an image capture manager to obtain one or more images of a room that includes multiple surfaces, wherein the one or more images depict a spherical view of the room; and a surface interaction detection manager to detect, from the one or more images, a person in the room, generate a bounding box around the person, preprocess the bounding box to represent the person in an upright orientation, determine a pose of the person from the preprocessed bounding box, detect an outstretched hand from the determined pose, and determine, from the detected outstretched hand, a surface of interaction in the room; wherein to determine the pose of the person comprises to provide the bounding box to a deep neural network trained to determine poses.
2. The compute device of claim 1, wherein to determine a surface of interaction in the room comprises to: identify the surfaces in the room; determine a ray along a shoulder of the outstretched hand to a wrist of the outstretched hand; and determine the surface in the room that intersects with the ray as the surface of interaction.
3. The compute device of claim 1, wherein the surface interaction detection manager is further to identify a medial axis of the detected person and identify positions of the wrists and shoulders of the detected person.
4. The compute device of claim 3, wherein to detect an outstretched hand comprises to determine whether a perpendicular displacement of a wrist of the detected person from the medial axis of the detected person satisfies a predefined threshold distance.
5. The compute device of claim 4, wherein the surface interaction detection manager is further to determine, in response to a determination that the perpendicular displacement of the wrist satisfies the predefined threshold, an orientation of the outstretched hand as an angle made by a line that joins the wrist to the shoulder of the outstretched hand with a horizontal axis of the one or more images.
6. The compute device of claim 1, wherein the surface interaction detection manager is further to determine an orientation of the bounding box and wherein to preprocess the bounding box comprises to rotate the bounding box as a function of the determined orientation.
7. The compute device of claim 6, wherein to determine the orientation of the bounding box comprises to determine an angle made by a line between a center of the bounding box and the center of the one or more images with a horizontal axis of the one or more images.
8. The compute device of claim 7, wherein to rotate the bounding box comprises to rotate the bounding box by 90 degrees minus the determined angle.
9. One or more non-transitory, machine-readable storage media comprising a plurality of instructions stored thereon that, in response to being executed, cause a compute device to: obtain one or more images of a room that includes multiple surfaces, wherein the one or more images depict a spherical view of the room; detect, from the one or more images, a person in the room; generate a bounding box around the person; preprocess the bounding box to represent the person in an upright orientation; determine a pose of the person from the preprocessed bounding box, wherein to determine the pose of the person comprises to provide the bounding box to a deep neural network trained to determine poses; detect an outstretched hand from the determined pose; and determine, from the detected outstretched hand, a surface of interaction in the room.
10. The one or more machine-readable storage media of claim 9, wherein to determine a surface of interaction in the room comprises to: identify the surfaces in the room; determine a ray along a shoulder of the outstretched hand to a wrist of the outstretched hand; and determine the surface in the room that intersects with the ray as the surface of interaction.
11. The one or more machine-readable storage media of claim 9, wherein, when executed, the plurality of instructions further cause the compute device to: identify a medial axis of the detected person; and identify positions of the wrists and shoulders of the detected person.
12. The one or more machine-readable storage media of claim 11, wherein to detect an outstretched hand comprises to determine whether a perpendicular displacement of a wrist of the detected person from the medial axis of the detected person satisfies a predefined threshold distance.
13. The one or more machine-readable storage media of claim 12, wherein, when executed, the plurality of instructions further cause the compute device to determine, in response to a determination that the perpendicular displacement of the wrist satisfies the predefined threshold, an orientation of the outstretched hand as an angle made by a line that joins the wrist to the shoulder of the outstretched hand with a horizontal axis of the one or more images.
14. The one or more machine-readable storage media of claim 9, wherein, when executed, the plurality of instructions further cause the compute device to determine an orientation of the bounding box, and wherein to preprocess the bounding box comprises to rotate the bounding box as a function of the determined orientation.
15. The one or more machine-readable storage media of claim 14, wherein to determine the orientation of the bounding box comprises to determine an angle made by a line between a center of the bounding box and the center of the one or more images with a horizontal axis of the one or more images.
16. The one or more machine-readable storage media of claim 15, wherein to rotate the bounding box comprises to rotate the bounding box by 90 degrees minus the determined angle.
17. A method for detecting an interaction with a surface in a room from a spherical view of the room, the method comprising: obtaining, by a compute device, one or more images of a room that includes multiple surfaces, wherein the one or more images depict a spherical view of the room; detecting, by the compute device and from the one or more images, a person in the room; generating, by the compute device, a bounding box around the person; preprocessing, by the compute device, the bounding box to represent the person in an upright orientation; determining, by the compute device, a pose of the person from the preprocessed bounding box, wherein determining the pose of the person comprises providing the bounding box to a deep neural network trained to determine poses; detecting, by the compute device, an outstretched hand from the determined pose; and determining, by the compute device and from the detected outstretched hand, a surface of interaction in the room.
18. The method of claim 17, wherein determining a surface of interaction in the room comprises: identifying, by the compute device, the surfaces in the room; determining, by the compute device, a ray along a shoulder of the outstretched hand to a wrist of the outstretched hand; and determining, by the compute device, the surface in the room that intersects with the ray as the surface of interaction.
19. The method of claim 17, further comprising: identifying, by the compute device, a medial axis of the detected person; and identifying, by the compute device, positions of the wrists and shoulders of the detected person.
20. The method of claim 19, wherein detecting an outstretched hand comprises determining whether a perpendicular displacement of a wrist of the detected person from the medial axis of the detected person satisfies a predefined threshold distance.
21. The method of claim 20, further comprising determining, by the compute device and in response to a determination that the perpendicular displacement of the wrist satisfies the predefined threshold, an orientation of the outstretched hand as an angle made by a line that joins the wrist to the shoulder of the outstretched hand with a horizontal axis of the one or more images.
22. The method of claim 17, further comprising determining, by the compute device, an orientation of the bounding box, and wherein preprocessing the bounding box comprises rotating the bounding box as a function of the determined orientation.
23. The method of claim 22, wherein determining the orientation of the bounding box comprises determining an angle made by a line between a center of the bounding box and the center of the one or more images with a horizontal axis of the one or more images.
24. The method of claim 23, wherein rotating the bounding box comprises rotating the bounding box by 90 degrees minus the determined angle.
</claims>
</document>
