<document>

<filing_date>
2020-02-19
</filing_date>

<publication_date>
2020-09-08
</publication_date>

<priority_date>
2020-02-19
</priority_date>

<ipc_classes>
G06K9/62,G06N20/00,G06Q30/00,G06Q30/06,G06T5/50,G06T7/194
</ipc_classes>

<assignee>
NICOM LIVING
</assignee>

<inventors>
NUNN, DANIEL JAMES
</inventors>

<docdb_family_id>
72290072
</docdb_family_id>

<title>
Method, medium, and system for live preview via machine learning models
</title>

<abstract>
Machine learning-based approaches are used to create instances or visualizations of content appearing within an object in an image. For example, a user may submit a request for a preview or visualization of content within an object or other media such as a glass crystal. A trained model can process the content to generate adjustment data or other data that can be used to control image blending operations. The adjustment data can be applied to the pixel values of the content to modify the content in order to enable a visualization of the content within an object. The image portion can be modified such that the object appears to "blend" with and appear within the object. Image transformation techniques can be used to project the modified content onto a representation of an object. Thereafter, a visualization or preview of the content within the representation of the object can be presented.
</abstract>

<claims>
1. A computer-implemented method, comprising: obtaining a plurality of image pairs, an image pair associated with a particular object classification and including a first image associated with a first representation of content and a second image associated with a second representation of the content appearing with one of a plurality of object representations specified by the particular object classification; training image adjustment models on the plurality of image pairs for a plurality of object classifications; receiving a request to view desired content represented in query image data, the query image data associated with a first representation of desired content that is be viewed with a type of object, the type of object associated with an object classification; evaluating a trained image adjustment model for the object classification on the query image data to generate image adjustment data; applying the image adjustment data to pixels values of the first representation of desired content to generate a second representation of the desired content; using an image transformation technique on the second representation of the desired content to project the second representation of the desired content to an image template that includes the object representation; generating a visualization of the desired content with the object representation; and presenting the visualization of the desired content with the object representation, wherein the visualization includes an image that previews what the desired content looks like when the desired content is one of etched or engraved within at least one of a crystal object or a glass object.
2. The computer-implemented method of claim 1, further comprising: receiving a selection of the object representations from a set of object representations, individual object representations associated with respective object classifications and respective trained image adjustment models; obtaining the image template that includes the object representation; and obtaining the trained adjustment model corresponding to the image template.
3. The computer-implemented method of claim 1, further comprising: receiving a selection of a different object representation from a set of object representations; and presenting an updated visualization of the desired content based at least in part upon a shape of the different object representation.
4. The computer-implemented method of claim 1, further comprising: receiving at least one parameter for use in generating a stylized visualization, the at least one parameter including at least one of a size, aspect ratio, opacity, style, or weighting.
5. The computer-implemented method of claim 1, further comprising: determining a set of pixel locations associated with the object representation; determining a respective pixel value for an individual pixel location of the set of pixel locations; determining a corresponding pixel location in the template image for the individual pixel location; and blending the respective pixel value with the corresponding pixel value for the corresponding pixel location based at least in part on the adjustment data.
6. The computer-implemented method of claim 5, further comprising: changing a weighting of the respective pixel value with respect to a corresponding pixel value for the corresponding pixel location to affect a visibility of the object in the visualization when presented.
7. A system, comprising: at least one computer comprising at least one processor and at least one memory, the at least one computer configured to: obtain a plurality of image pairs, an image pair associated with a particular object classification and including a first image associated with a first representation of content and a second image associated with a second representation of the content appearing with one of a plurality of object representations specified by the particular object classification; train models on the plurality of image pairs for a plurality of object classifications; receive a request to view content represented in query image data with a type of object, the type of object associated with a template image that includes a representation of the type of object, the type of object associated with an object classification; evaluate a trained model for the object classification on the query image data to generate image adjustment data; apply the image adjustment data to the content to generate modified content; use an image transformation technique on the modified content to project the modified content to the image template; and generate a visualization of the modified content with the type of object, wherein the visualization includes an image that previews what the content looks like when the content is one of etched or engraved within at least one of a crystal object or a glass object.
8. The system of claim 7, wherein the type of object further represents one of a lens, a prism, a plaque, a trophy, an award, or a window.
9. The system of claim 7, wherein the type of object is at least partially transparent, and wherein a shape of the type of object is three-dimensional.
10. The system of claim 7, wherein the visualization includes text appearing with the content.
11. The system of claim 7, wherein the at least one computer is further configured to: train a plurality of models using images of objects of different types corresponding to a plurality of object classifications; and store a plurality of trained models.
12. The system of claim 7, wherein the at least one computer is further configured to: compare the object classification associated with the request with a set of object classifications for trained models; select a matching object classification that corresponds to the object classification with at least a minimum level of confidence; and obtain the trained model associated with the matching object classification.
13. The system of claim 7, wherein the at least one computer is further configured to: use a segmentation process to determine a foreground image portion of the query image data and a background image portion, the foreground image portion including the content.
14. The system of claim 7, wherein the content includes one of a person, an animal, a building, nature, geography, or an event.
15. One or more non-transitory, computer-readable media comprising computer executable instructions that, when executed, cause at least one processor to perform actions comprising: obtaining a plurality of image pairs, an image pair associated with a particular object classification and including a first image associated with a first representation of content and a second image associated with a second representation of the content appearing with one of a plurality of object representations specified by the particular object classification; training models on the plurality of image pairs for a plurality of object classifications; receiving a request to view content represented in query image data with a type of object, the type of object associated with a template image that includes a representation of the type of object, the type of object associated with an object classification; evaluating a trained model for the object classification on the query image data to generate image adjustment data; applying the image adjustment data to the content to generate modified content; using an image transformation technique on the modified content to project the modified content to the image template; and generating a visualization of the modified content with the type of object, wherein the visualization includes an image that previews what the content looks like when the content is one of etched or engraved within at least one of a crystal object or a glass object.
16. The one or more non-transitory, computer-readable media of claim 15, wherein the at least one processor further performs actions comprising: receiving a selection of the type of object from a set of object types, individual object types associated with respective object classifications and respective trained models; and obtaining the trained model corresponding to the type of object.
17. The one or more non-transitory, computer-readable media of claim 15, wherein the at least one processor further performs actions comprising: receiving a request of text to appear with the content; and presenting the visualization of the modified content with the text.
18. The one or more non-transitory, computer-readable media of claim 15, wherein an image pair includes an input image and an output image, the input image corresponding to a representation of content, the output image including a representation of the content modified to appear engraved.
</claims>
</document>
