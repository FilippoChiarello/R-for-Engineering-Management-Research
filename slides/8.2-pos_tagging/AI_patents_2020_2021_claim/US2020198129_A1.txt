<document>

<filing_date>
2019-12-19
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2018-12-19
</priority_date>

<ipc_classes>
B25J9/16
</ipc_classes>

<assignee>
ABB SCHWEIZ
</assignee>

<inventors>
FUHLBRIGGE, THOMAS
BOCA, REMUS
TENG, ZHOU
HOLMBERG, JOHNNY
WAHLSTROM, MAGNUS
</inventors>

<docdb_family_id>
71098040
</docdb_family_id>

<title>
DISTRIBUTED INFERENCE MULTI-MODELS FOR INDUSTRIAL APPLICATIONS
</title>

<abstract>
Robotic visualization systems and methods include running and analyzing perception algorithms and models for robotic visualization systems on multiple computing platforms to obtain a successful complete an object processing request.
</abstract>

<claims>
1. A system comprising: an edge computer for running a first set of paired algorithms and models for performing one or more perception tasks and evaluating results thereof; and a server computer in operative communication with the edge computer for running a second set of paired algorithms and models for performing one or more perception tasks and evaluating results thereof, wherein the edge computer and the server computer are in operative communication with a robotic cell operable to perform the one or more perception tasks.
2. The system of claim 1, wherein the first set of paired algorithms and models are ranked in a first priority for performance and the second set of pair algorithms and models are ranked in a second priority for performance below the first priority.
3. The system of claim 1, wherein the edge computer is local to a robotic cell that includes a robot for performing the one or more perception tasks.
4. The system of claim 2, wherein the server computer is remote from the robotic cell.
5. The system of claim 1, wherein the one or more perception tasks include categorization, classification, detection, location, sorting, segmentation, tracking, and image extraction of one or more objects.
6. The system of claim 1, wherein the edge computer and the server computer are each configured to: receive an object processing request; select a paired algorithm and model to perform the perception task for the object processing request; and run the perception task with the selected paired algorithm and model.
7. The system of claim 6, wherein the perception task is ran by one of the edge computer and the server computer with the selected paired algorithm and model according to a ranked priority between the edge computer and the server computer.
8. A method, comprising: generating an object processing request; obtaining a paired algorithm and model for evaluation in response to the object processing request; running the obtained paired algorithm and model on a computing platform; evaluating a result for the object processing request from running of the obtained paired algorithm and model; and running a training algorithm to upgrade one or more models for performing the object processing request in response to the result indicating a failure of the object processing request.
9. The method of claim 8, wherein running the training algorithm is triggered in response to at least two failures of the object processing request using the paired algorithm and model.
10. The method of claim 8, further comprising: determining the object processing request using the paired algorithm and model has failed; obtaining a second paired algorithm and model for evaluation of the object processing request; running the second paired algorithm and model on the computing platform; and evaluating a second result for the object processing request from running of the second paired algorithm and model.
11. The method of claim 10, further comprising: determining the object processing request using the second paired algorithm and model has failed; obtaining a third paired algorithm and model for evaluation of the object processing request; running the third paired algorithm and model on a second computing platform; and evaluating a third result for the object processing request from running of the second paired algorithm and model on the second computing platform.
12. The method of claim 11, wherein the computing platform is an edge computer and the second computing platform is a server computer.
13. The method of claim 8, further comprising: determining the object processing request using the paired algorithm and model has failed; obtaining a second paired algorithm and model for evaluation of the object processing request; running the second paired algorithm and model on a second computing platform; and evaluating a second result for the object processing request from running of the second paired algorithm and model on the second computing platform.
14. The method of claim 13, wherein the computing platform is an edge computer and the second computing platform is a server computer.
15. A method, comprising: generating an object processing request; obtaining a first paired algorithm and model for evaluation in response to the object processing request; running the paired algorithm and model on a first computing platform; evaluating a result for the object processing request from running of the first paired algorithm and model; and in response to the result indicating a failed object processing request, obtaining a second paired algorithm and model for evaluation of the object processing request, running the second paired algorithm and model, and evaluating the result for the object processing request from running the second paired algorithm and model.
16. The method of claim 15, further comprising running a training algorithm to upgrade one or more models for performing the object processing request in response to the result indicating at least two failed object processing requests.
17. The method of claim 15, wherein the first computing platform is an edge computer.
18. The method of claim 15, further comprising storing the failed object processing request and associated data.
19. The method of claim 15, further comprising determining the second paired algorithm and model for evaluation of the object processing request is available before obtaining the second paired algorithm and model.
20. The method of claim 15, wherein the second paired algorithm and model are ran on a second computing platform, wherein the first computing platform is an edge computer and the second computing platform is a server computer.
</claims>
</document>
