<document>

<filing_date>
2019-07-29
</filing_date>

<publication_date>
2020-04-16
</publication_date>

<priority_date>
2018-10-10
</priority_date>

<ipc_classes>
G06F12/0811,G06F12/0862,G06F12/0897,G06F12/126,G06N20/20,G06N5/02
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
JOUPPI, NORMAN PAUL
PATIL, NISHANT
YOON, DOE HYUN
</inventors>

<docdb_family_id>
67551741
</docdb_family_id>

<title>
MODIFYING MACHINE LEARNING MODELS TO IMPROVE LOCALITY
</title>

<abstract>
Methods, systems, and apparatus for updating machine learning models to improve locality are described. In one aspect, a method includes receiving data of a machine learning model. The data represents operations of the machine learning model and data dependencies between the operations. Data specifying characteristics of a memory hierarchy for a machine learning processor on which the machine learning model is going to be deployed is received. The memory hierarchy includes multiple memories at multiple memory levels for storing machine learning data used by the machine learning processor when performing machine learning computations using the machine learning model. An updated machine learning model is generated by modifying the operations and control dependencies of the machine learning model to account for the characteristics of the memory hierarchy. Machine learning computations are performed using the updated machine learning model.
</abstract>

<claims>
What is claimed is:
1. A method performed by data processing apparatus, the method comprising: receiving data of a machine learning model, the data representing operations of the machine learning model and data dependencies between the operations;
receiving data specifying characteristics of a memory hierarchy for a machine learning processor on which the machine learning model is going to be deployed, the memory hierarchy including multiple memories at multiple memory levels for storing machine learning data used by the machine learning processor when performing machine learning computations using the machine learning model, the characteristics including a data storage capacity of each memory and a memory bandwidth of each memory, wherein at least one of the memories has a different memory bandwidth than at least one other memory;
generating, based on the data of the machine learning model and the characteristics of the memory hierarchy, an updated machine learning model by modifying the operations and control dependencies of the machine learning model to account for the characteristics of the memory hierarchy; and
performing machine learning computations using the updated machine learning model.
2. The method of claim 1 , wherein the data of the machine learning model comprises a graph that represents the operations of the machine learning model, the control dependencies between the operations, and data dependencies between the operations.
3. The method of claim 1 , wherein generating the updated machine learning model comprises selecting, for at least a portion of the operations, one of the memories to store outputs of the operation based on when the outputs will be used as inputs to another operation.
4. The method of claim 1 , wherein generating the updated machine learning model comprises:
determining that output data for a first operation is to be stored in a first memory of the multiple memories based on when the output data for the first operation will be used as input by a second operation, the first memory having a lower memory bandwidth than a second memory of the multiple memories and, in response:
including in the updated machine learning model:
first control data that causes the machine learning processor to store the output data for the first operation in the first memory after the output data is generated by the first operation; and
second control data that causes the machine learning processor to transfer the output data from the first memory to the second memory prior to the output data being used as input to the second operation
5 The method of claim 4, wherein the second control data causes the machine learning processor to transfer the output data from the first memory to the second memory in response to a third operation being executed, the third operation being different from the first and second operations
6 The method of claim 4, wherein determining that output data for a first operation is to be stored in a first memory of the multiple memories based on when the output data for the first operation will be used as input by a second operation comprises:
determining that the output data for the first operation is to be stored in the first memory based on at least one of (i) a number of operations that will be executed between the first operation and the second operation or (ii) an estimated duration of time between when the first operation will be executed and the second operation will be executed.
7. The method of claim 1 , wherein generating the updated machine learning model comprises:
determining that input data for a particular sequence of operations of the machine learning mode! requires more data storage capacity than a particular memory of the multiple memories and, in response:
including in the updated machine learning model:
multiple sequences of operations that include a same sequence of operations as the particular sequence of operations;
first control data that causes the machine learning processor to split the input data into multiple portions of data;
second control data that causes the machine learning processor to assign each portion of data to a respective sequence of operations of the multiple sequence of operations; and
third control data that causes the machine learning processor to perform the multiple sequences of operations in series
8. The method of claim 1 , wherein generating the updated machine learning mode! comprises using a second machine learning model to generate the updated machine learning model based on the machine learning model and the characteristics of the memory hierarchy.
9 A system, comprising:
a data processing apparatus; and
a memory storage apparatus in data communication with the data processing apparatus, the memory storage apparatus storing instructions executable by the data processing apparatus and that upon such execution cause the data processing apparatus to perform operations comprising:
receiving data of a machine learning model, the data representing operations of the machine learning model and data dependencies between the operations;
receiving data specifying characteristics of a memory hierarchy for a machine learning processor on which the machine learning model is going to be deployed, the memory hierarchy including multiple memories at multiple memory levels for storing machine learning data used by the machine learning processor when performing machine learning computations using the machine learning model, the characteristics including a data storage capacity of each memory and a memory bandwidth of each memory, wherein at least one of the memories has a different memory bandwidth than at least one other memory;
generating, based on the data of the machine learning model and the characteristics of the memory hierarchy, an updated machine learning model by modifying the operations and control dependencies of the machine learning model to account for the characteristics of the memory hierarchy; and
performing machine learning computations using the updated machine learning model
10 The system of claim 9, wherein the data of the machine learning model comprises a graph that represents the operations of the machine learning model, the control dependencies between the operations, and data dependencies between the operations
1 1 The system of claim 9, wherein generating the updated machine learning model comprises selecting, for at least a portion of the operations, one of the memories to store outputs of the operation based on when the outputs will be used as inputs to another operation.
12 The system of claim 9, wherein generating the updated machine learning model comprises:
determining that output data for a first operation is to be stored in a first memory of the multiple memories based on when the output data for the first operation will be used as input by a second operation, the first memory having a lower memory bandwidth than a second memory of the multiple memories and, in response:
including in the updated machine learning model:
first control data that causes the machine learning processor to store the output data for the first operation in the first memory after the output data is generated by the first operation; and second control data that causes the machine learning processor to transfer the output data from the first memory to the second memory prior to the output data being used as input to the second operation.
13. The system of claim 12, wherein the second control data causes the machine learning processor to transfer the output data from the first memory to the second memory in response to a third operation being executed, the third operation being different from the first and second operations.
14. The system of claim 12, wherein determining that output data for a first operation is to be stored in a first memory of the multiple memories based on when the output data for the first operation will be used as input by a second operation comprises:
determining that the output data for the first operation is to be stored in the first memory based on at least one of (i) a number of operations that will be executed between the first operation and the second operation or (ii) an estimated duration of time between when the first operation will be executed and the second operation will be executed.
15. The system of claim 9, wherein generating the updated machine learning model comprises:
determining that input data for a particular sequence of operations of the machine learning model requires more data storage capacity than a particular memory of the multiple memories and, in response:
including in the updated machine learning model:
multiple sequences of operations that include a same sequence of operations as the particular sequence of operations;
first control data that causes the machine learning processor to split the input data into multiple portions of data;
second control data that causes the machine learning processor to assign each portion of data to a respective sequence of operations of the multiple sequence of operations; and third control data that causes the machine learning processor to perform the multiple sequences of operations in series.
16. The system of claim 9, wherein generating the updated machine learning model comprises using a second machine learning model to generate the updated machine learning model based on the machine learning model and the characteristics of the memory hierarchy.
17. A non-transitory computer storage medium encoded with a computer program, the program comprising instructions that when executed by one or more data processing apparatus cause the data processing apparatus to perform operations comprising:
receiving data of a machine learning model, the data representing operations of the machine learning model and data dependencies between the operations;
receiving data specifying characteristics of a memory hierarchy for a machine learning processor on which the machine learning model is going to be deployed, the memory hierarchy including multiple memories at multiple memory levels for storing machine learning data used by the machine learning processor when performing machine learning computations using the machine learning model, the characteristics including a data storage capacity of each memory and a memory bandwidth of each memory, wherein at least one of the memories has a different memory bandwidth than at least one other memory;
generating, based on the data of the machine learning model and the
characteristics of the memory hierarchy, an updated machine learning model by modifying the operations and control dependencies of the machine learning model to account for the characteristics of the memory hierarchy; and
performing machine learning computations using the updated machine learning model.
18. The non-transitory computer storage medium of claim 17, wherein the data of the machine learning model comprises a graph that represents the operations of the machine learning model, the control dependencies between the operations, and data dependencies between the operations.
19. The non-transitory computer storage medium of claim 17, wherein generating the updated machine learning model comprises selecting, for at least a portion of the operations, one of the memories to store outputs of the operation based on when the outputs will be used as inputs to another operation.
20. The non-transitory computer storage medium of claim 17, wherein generating the updated machine learning model comprises:
determining that output data for a first operation is to be stored in a first memory of the multiple memories based on when the output data for the first operation will be used as input by a second operation, the first memory having a lower memory bandwidth than a second memory of the multiple memories and, in response:
including in the updated machine learning model:
first control data that causes the machine learning processor to store the output data for the first operation in the first memory after the output data is generated by the first operation; and
second control data that causes the machine learning processor to transfer the output data from the first memory to the second memory prior to the output data being used as input to the second operation.
</claims>
</document>
