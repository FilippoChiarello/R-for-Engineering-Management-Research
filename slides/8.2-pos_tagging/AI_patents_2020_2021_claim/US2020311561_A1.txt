<document>

<filing_date>
2019-03-27
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-27
</priority_date>

<ipc_classes>
G06F9/50,G06N5/02
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
NAAMAN, NIR
ROSEN, IRA
KALLNER, SAMUEL
GUY, NILI
TURGEMAN, LIOR
Amir, Adar
</inventors>

<docdb_family_id>
72606403
</docdb_family_id>

<title>
MODIFYING ARTIFICIAL INTELLIGENCE MODELS USING MODEL FRAGMENTS
</title>

<abstract>
An example system includes a processor to monitor system resources and performance preferences. The processor is to select model fragments based on the system resources and the performance preferences. The processor is to also construct a running artificial intelligence (AI) model from the selected model fragments. The processor is to further automatically modify the running AI model using the model fragments in response to detecting a change in the system resources or a change in the performance preferences.
</abstract>

<claims>
1. A system, comprising a processor to: monitor system resources and performance preferences; select model fragments based on the system resources and the performance preferences; construct a running artificial intelligence (AI) model from the selected model fragments; and automatically modify the running AI model using the model fragments in response to detecting a change in the system resources or a change in the performance preferences.
2. The system of claim 1, wherein the system resources are associated with an edge computing device executing the running AI model.
3. The system of claim 1, wherein the system resources comprise available processing, free memory, free storage space, available power, or any combination thereof.
4. The system of claim 1, wherein the performance preferences comprise power consumption, model size, inference time, model accuracy, adaptability to new input, or any combination thereof.
5. The system of claim 1, wherein the processor is to select the model fragments based on the system resources, the performance preferences, current model fragments being used and a cost of migrating to a new set of model fragments.
6. The system of claim 1, wherein the model fragments comprise different model types, parameter tunings, or compressions of an AI model.
7. The system of claim 1, wherein the processor is to predict a change in system resources and construct a modified AI model to replace the running AI model.
8. A computer-implemented method, comprising: monitoring, via a processor, system resources and performance preferences; selecting, via the processor, model fragments based on the system resources and the performance preferences; constructing, via the processor, a running artificial intelligence (AI) model from the selected model fragments; and automatically modify, via the processor, the running AI model using the model fragments in response to detecting a change in the system resources or a change in the performance preferences.
9. The computer-implemented method of claim 8, wherein selecting the model fragments is based on the system resources and the performance preferences, current model fragments being used, and a cost of migrating to a new set of model fragments.
10. The computer-implemented method of claim 8, wherein automatically modifying the running AI model comprises enhancing the running AI model using a model fragment in response to detecting an increase in a system resource or reducing the running AI model using a model fragment in response to detecting a decrease in a system resource.
11. The computer-implemented method of claim 8, comprising predicting a change in system resources and constructing a modified AI model to replace the running AI model.
12. The computer-implemented method of claim 8, comprising generating the model fragments, wherein generating the model fragments comprises pruning a node or an edge of a generated AI model.
13. The computer-implemented method of claim 8, comprising generating the model fragments, wherein generating the model fragments comprises quantizing a weight of a generated AI model.
14. The computer-implemented method of claim 8, comprising generating the model fragments, wherein generating the model fragments comprises weight rounding a weight of a generated AI model.
15. The computer-implemented method of claim 8, comprising retraining the modified running AI model.
16. A computer program product for automatically modify running AI models using model fragments, the computer program product comprising a computer-readable storage medium having program code embodied therewith, wherein the computer readable storage medium is not a transitory signal per se, the program code executable by a processor to cause the processor to: monitor system resources and performance preferences; select model fragments based on the system resources and the performance preferences; construct a running artificial intelligence (AI) model from the selected model fragments; and automatically modify the running AI model using the model fragments in response to detecting a change in the system resources or a change in the performance preferences.
17. The computer program product of claim 16, further comprising program code executable by the processor to select the model fragments based on the system resources, the performance preferences, current model fragments being used, and a cost of migrating to a new set of model fragments.
18. The computer program product of claim 16, further comprising program code executable by the processor to enhance the running AI model using a model fragment in response to detecting an increase in a system resource or reduce the running AI model using a model fragment in response to detecting a decrease in a system resource.
19. The computer program product of claim 16, further comprising program code executable by the processor to predict a change in system resources and construct a modified AI model to replace the running AI model.
20. The computer program product of claim 16, further comprising program code executable by the processor to predict the system resources based on historical data or usage profiles, wherein the processor is to store a subset of the model fragments on a local storage based on the predicted system resources.
</claims>
</document>
