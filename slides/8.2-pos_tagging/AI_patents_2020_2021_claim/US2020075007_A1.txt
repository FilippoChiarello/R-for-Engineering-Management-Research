<document>

<filing_date>
2019-08-29
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2018-08-31
</priority_date>

<ipc_classes>
G06N20/00,G10L15/02,G10L15/06,G10L15/22
</ipc_classes>

<assignee>
TOYOTA MOTOR CORPORATION
KYOTO UNIVERSITY
</assignee>

<inventors>
WATANABE, NARIMASA
HORI, TATSURO
KAWAHARA, TATSUYA
</inventors>

<docdb_family_id>
67620297
</docdb_family_id>

<title>
VOICE INTERACTION SYSTEM, VOICE INTERACTION METHOD, PROGRAM, LEARNING MODEL GENERATION APPARATUS, AND LEARNING MODEL GENERATION METHOD
</title>

<abstract>
A voice interaction system capable of appropriately handling a situation so as to effectively prevent a response error from occurring is provided. A speech acquisition unit acquires user speech. A feature extraction unit extracts a feature of the user speech. A response determination unit determines a response corresponding to the extracted feature vector using any one of a plurality of learning models. A response execution unit executes the determined response. A user state detection unit detects a user state. A learning model selection unit selects a learning model from a plurality of learning models in accordance with the detected user state. The response determination unit determines a response using the selected learning model.
</abstract>

<claims>
1. A voice interaction system that has a conversation with a user by using a voice, comprising: hardware, including at least one memory configured to store a computer program and at least one processor configured to execute the computer program; a speech acquisition unit, implemented by the hardware, configured to acquire user speech given by the user; a feature extraction unit, implemented by the hardware, configured to extract at least a feature of the acquired user speech; a response determination unit, implemented by the hardware, configured to determine a response in accordance with the extracted feature using any one of a plurality of learning, models generated in advance by machine learning; a response execution unit, implemented by the hardware, configured to perform control in order to execute the determined response; a user state detection unit, implemented by the hardware, configured to detect a user state, which is a state of the user; and a learning model selection unit, implemented by the hardware, configured to select a learning model from the plurality of learning models in accordance with the detected user state, wherein the response determination unit, implemented by the hardware, determines the response using the learning model selected by the learning model selection unit.
2. The voice interaction system according to claim 1, wherein the user state detection unit detects a degree of activeness of the user in the conversation as the user state, and the learning model selection unit selects the learning model that corresponds to the degree of the activeness of the user.
3. The voice interaction system according to claim 2, wherein the user state detection unit detects an amount of speech given by the user in a predetermined period or a percentage of time during which the user has made a speech with respect to a sum of time during which the voice interaction system has output a voice as a response and the time during which the user has made a speech in the predetermined period, and the learning, model selection unit selects the learning model that corresponds to the amount of speech given by the user or the percentage of the time during which the user has made a speech.
4. The voice interaction system according to claim 1, wherein the user state detection unit detects identification information on the user as the user state, and the learning model selection unit selects the learning model that corresponds to the identification information on the user.
5. The voice interaction system according to claim 1, wherein the user state detection unit detects emotion of the user as the user state, and the learning model selection unit selects the learning model that corresponds to the emotion of the user.
6. The voice interaction system, according to claim 1, wherein the user state detection unit detects a health condition of the user as the user state, and the learning model selection unit selects the learning model that corresponds to the health condition of the user.
7. The voice interaction system according to claim 1, wherein the user state detection unit detects a degree of an awakening state of the user as the user state, and the learning model selection unit selects the learning model that corresponds to the degree of the awakening state of the user.
8. A voice interaction method performed by a voice interaction system that has a conversation with a user by using a voice, the voice interaction method comprising: acquiring user speech given by the user; extracting at least a feature of the acquired user speech; determining a response in accordance with the extracted feature using any one of a plurality of learning models generated in advance by machine learning; performing control in order to execute the determined response; detecting a user state, which is a state of the user; and selecting a learning model from the plurality of learning models in accordance with the detected user state, wherein the response is determined using the selected learning model.
9. A non-transitory computer readable medium storing a program for executing a voice interaction method performed by a voice interaction system that has a conversation with a user by using a voice, the program causing a computer to execute the steps of: acquiring user speech given by the user; extracting at least a feature of the acquired user speech; determining a response in accordance with the extracted feature using any one of a plurality of learning models generated in advance by machine learning; performing control in order to execute the determined response; detecting a user state, which is a state of the user; selecting a learning model from the plurality of learning models in accordance with the detected user state; and determining the response using the selected learning model.
10. A learning model generation apparatus configured to generate a learning model used in a voice interaction system that has a conversation with a user by using a voice, the apparatus comprising: hardware, including at least one memory configured to store a computer program and at least one processor configured to execute the computer program; a speech acquisition unit, implemented by the hardware, configured to acquire user speech, which is speech given by at least one desired user, by having a conversation with the desired user; a feature extraction unit, implemented by the hardware, configured to extract a feature vector indicating at least a feature of the acquired user speech; a sample data generation unit configured to generate sample data in which a correct label indicating a response to the user speech and the feature vector are associated with each other; a user state acquisition unit, implemented by the hardware, configured to acquire a user state, which is a state of the desired user when the user has made a speech, to associate the acquired user state with the sample data that corresponds to the user speech; a sample data classification unit, implemented by the hardware, configured to classify the sample data for each of the user states; and a learning model generation, unit, implemented by the hardware, configured to generate a plurality of learning models by machine learning for each of pieces of the classified sample data.
11. A learning model generation method for generating a learning model used in a voice interaction system that has a conversation with a user by using a voice, the method comprising: acquiring user speech, which is speech given by at least one desired user, by having a conversation with the desired user; extracting a feature vector indicating at least a feature of the acquired user speech; generating sample data in which a correct label indicating a response to the user speech and the feature vector are associated with each other; acquiring a user state, which is a state of the desired user when the user has made a speech, to associate the acquired user state with the sample data that corresponds to the user speech; classifying the sample data for each of the user states; and generating a plurality of learning models by machine learning for each pieces of the classified sample data.
</claims>
</document>
