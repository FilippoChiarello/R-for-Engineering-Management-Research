<document>

<filing_date>
2018-02-07
</filing_date>

<publication_date>
2021-01-05
</publication_date>

<priority_date>
2018-02-07
</priority_date>

<ipc_classes>
G06K9/62,G06N20/10,G06N20/20,G06N3/04,G06N3/08,G06N5/00,H04N17/00,H04N19/154,H04N19/91,H04N21/235
</ipc_classes>

<assignee>
NETFLIX
</assignee>

<inventors>
LI ZHI
BAMPIS, CHRISTOS
</inventors>

<docdb_family_id>
65529795
</docdb_family_id>

<title>
Techniques for modeling temporal distortions when predicting perceptual video quality
</title>

<abstract>
In various embodiments, a prediction application computes a quality score for re-constructed visual content that is derived from visual content. The prediction application generates a frame difference matrix based on two frames included in the re-constructed video content. The prediction application then generates a first entropy matrix based on the frame difference matrix and a first scale. Subsequently, the prediction application computes a first value for a first temporal feature based on the first entropy matrix and a second entropy matrix associated with both the visual content and the first scale. The prediction application computes a quality score for the re-constructed video content based on the first value, a second value for a second temporal feature associated with a second scale, and a machine learning model that is trained using subjective quality scores. The quality score indicates a level of visual quality associated with streamed video content.
</abstract>

<claims>
1. A computer-implemented method, comprising: generating a frame difference matrix based on a first frame and a second frame that are included in re-constructed video content; computing a first entropy matrix based on the frame difference matrix and a first scale; computing a first value for a first temporal feature associated with the first scale based on the first entropy matrix and a second entropy matrix associated with both video content from which the re-constructed video content is derived and the first scale; and computing a quality score for the re-constructed video content based on the first value, a second value for a second temporal feature associated with a second scale, and a machine learning model trained using a plurality of subjective quality scores, wherein each of the first temporal feature and the second temporal feature measures one or more temporal visual distortions, and wherein the quality score indicates a level of visual quality associated with streamed video content.
2. The computer-implemented method of claim 1, wherein computing the first entropy matrix comprises: performing one or more down-sampling operations on the frame difference matrix based on the first scale to generate a scaled frame difference matrix; performing one or more spatial filtering operations on the scaled frame difference matrix to generate a local mean-subtracted matrix; and performing one or more conditioning operations on the local mean-subtracted matrix.
3. The computer-implemented method of claim 1, wherein computing the first value for the first temporal feature comprises performing a subtraction operation between a first entropy value included in the first entropy matrix and a second entropy value included in the second entropy matrix.
4. The computer-implemented method of claim 1, wherein computing the quality score comprises: determining a first frame quality score associated with the first frame based on a plurality of values for a plurality of temporal features, one or more values for one or more spatial features, and the machine learning model, wherein the plurality of values includes the first value and the second value; and performing one or more temporal pooling operations between the first frame quality score and a second frame quality score associated with the second frame.
5. The computer-implemented method of claim 4, wherein performing the one or more temporal pooling operations comprises performing at least one of a linear low pass operation and a non-linear rank-order weighting operation on the first frame quality score and the second frame quality score.
6. The computer implemented method of claim 4, further comprising computing the one or more values for the one or more spatial features based on the re-constructed video content.
7. The computer-implemented method of claim 1, wherein generating the frame difference matrix comprises, for each of a plurality of pixels, computing a luminance difference between a first luminance of the pixel in the first frame and a second luminance of the pixel in the second frame.
8. The computer-implemented method of claim 1, further comprising training the machine learning model based on one or more machine learning algorithms and the plurality of subjective quality scores, wherein each subjective quality score included in the plurality of subjective quality scores is associated with different re-constructed test video content.
9. The computer-implemented method of claim 8, wherein the one or more machine learning algorithms comprises at least one of a support vector machine algorithm and an artificial neural network algorithm.
10. The computer-implemented method of claim 1, wherein the one or more temporal visual distortions includes at least one of motion estimation mismatches, flicker, or ghosting.
11. The computer-implemented method of claim 1, wherein the first temporal feature comprises an entropy feature.
12. The computer-implemented method of claim 11, wherein the second temporal feature comprises at least one of a frame difference feature or an entropy feature.
13. One or more non-transitory computer-readable media including instructions that, when executed by one or more processors, cause the one or more processors to perform the steps of: generating a first scaled frame difference matrix based on a first frame, a second frame, and a first scale, wherein the first frame and the second frame are included in re-constructed video content; generating a second scaled frame difference matrix based on a third frame, a fourth frame, and the first scale, wherein the third frame and the fourth frame are included in video content from which the re-constructed video content is derived; computing a first entropy matrix based on the first scaled frame difference matrix; computing a first value for a first temporal feature associated with the first scale based on the first entropy matrix and a second entropy matrix associated with the second scaled frame difference matrix; and computing a quality score for the re-constructed video content based on the first value, a second value for a second temporal feature associated with a second scale, and a machine learning model trained using a plurality of subjective quality scores, wherein each of the first temporal feature and the second temporal feature measures one or more temporal visual distortions, and wherein the quality score indicates a level of visual quality associated with streamed video content.
14. The one or more non-transitory computer-readable media of claim 13, wherein computing the first entropy matrix comprises: performing one or more spatial filtering operations on the first scaled frame difference matrix to generate a local mean-subtracted matrix; and performing one or more conditioning operations on the local mean-subtracted matrix.
15. The one or more non-transitory computer-readable media of claim 14, wherein performing the one or more spatial filtering operations comprises applying a spatial isotropic Gaussian filter to the first scaled frame difference matrix.
16. The one or more non-transitory computer-readable media of claim 13, wherein computing the quality score comprises: determining a first frame quality score associated with the first frame based on a plurality of values for a plurality of temporal features, one or more values for one or more spatial features, and the machine learning model, wherein the plurality of values includes the first value and the second value; and performing one or more temporal pooling operations between the first frame quality score and a second frame quality score associated with the second frame.
17. The one or more non-transitory computer-readable media of claim 16, wherein performing the one or more temporal pooling operations comprises performing at least one of a linear low pass operation and a non-linear rank-order weighting operation on the first frame quality score and the second frame quality score.
18. The one or more non-transitory computer-readable media of claim 16, wherein the one or more spatial features comprise at least one of an additive impairment measure feature, a blind or referenceless image spatial quality evaluator feature, and a visual information fidelity feature.
19. The one or more non-transitory computer-readable media of claim 13, wherein generating the first scaled frame difference matrix comprises: for each of a plurality of pixels, computing a luminance difference between a first luminance of the pixel in the first frame and a second luminance of the pixel in the second frame to generate a frame difference matrix; and performing one or more down-sampling operations on the frame difference matrix based on the first scale.
20. The one or more non-transitory computer-readable media of claim 13, wherein a first subjective quality score included in the plurality of subjective quality scores is associated with one or more human-observed visual quality scores for re-constructed test video content.
21. The one or more non-transitory computer-readable media of claim 13, further comprising training the machine learning model based on the plurality of subjective quality scores and at least one of a support vector machine algorithm and an artificial neural network algorithm.
22. A system, comprising: a memory storing instructions; and a processor that is coupled to the memory and, when executing the instructions, is configured to: generate a frame difference matrix based on a first frame and a second frame that are included in re-constructed video content; perform one or more down-sampling operations on the frame difference matrix based on a first scale to generate a first scaled frame difference matrix; compute a first entropy matrix based on the first scaled frame difference matrix; compute a first value for a first temporal feature associated with the first scale based on the first entropy matrix and a second entropy matrix associated with both video content from which the re-constructed video content is derived and the first scale; perform one or more down-sampling operations on the frame difference matrix based on a second scale to generate a second scaled frame difference matrix; and compute a quality score for the re-constructed video content based on the first value, a second value for a second temporal feature associated with the second scale and the second scaled frame difference matrix, and a machine learning model trained using a plurality of subjective quality scores, wherein each of the first temporal feature and the second temporal feature measures one or more temporal visual distortions, and wherein the quality score indicates a level of visual quality associated with streamed video content.
23. The system of claim 22, wherein the processor is configured to compute the first entropy matrix by: performing one or more spatial filtering operations on the first scaled frame difference matrix to generate a local mean-subtracted matrix; and performing one or more conditioning operations on the local mean-subtracted matrix.
</claims>
</document>
