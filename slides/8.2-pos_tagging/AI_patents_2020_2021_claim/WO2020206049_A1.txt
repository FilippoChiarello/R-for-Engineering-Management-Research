<document>

<filing_date>
2020-04-02
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-02
</priority_date>

<ipc_classes>
G06K9/62
</ipc_classes>

<assignee>
BODYGRAM INC.
</assignee>

<inventors>
SATO, YU
KOH, CHONG
KAMIYAMA, KYOHEI
</inventors>

<docdb_family_id>
72661557
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR WEIGHT MEASUREMENT FROM USER PHOTOS USING DEEP LEARNING NETWORKS
</title>

<abstract>
Disclosed are systems and methods for body weight prediction from one or more images. The method includes the steps of receiving one or more subject parameters; receiving one or more images containing a subject; identifying one or more annotation key points for one or more body features underneath a clothing of the subject from the one or more images utilizing one or more annotation deep-leaming networks; calculating one or more geometric features of the subject based on the one or more annotation key points; and generating a prediction of the body weight of the subject utilizing a weight machine-learning module based on the one or more geometric features of the subject and the one or more subject parameters.
</abstract>

<claims>
What is claimed is:
1. A computer-implemented method for predicting a body weight of a subject, the computerimplemented method executable by a hardware processor, the method comprising:
receiving one or more subject parameters;
receiving one or more images containing the subject;
identifying one or more annotation key points for one or more body parts underneath a clothing of the subject from the one or more images utilizing one or more annotation deep-leaming modules; calculating one or more geometric features of the subject based on the one or more annotation key points; and
generating a prediction of the body weight of the subject utilizing a weight machine-learning module based on the one or more geometric features of the subject and the one or more subject parameters.
2. The method of claim 1, wherein the one or more geometric features are selected from the group consisting of body part circumference(s), body part length(s), body image area(s), body part image area(s), body volume(s), and body part volume(s).
3. The method of claim 2, wherein the body part circumference(s) comprise multiple body part circumferences for at least one body part.
4. The method of claim 1 , wherein the generating the prediction of the body weight of the subj ect further comprises:
generating a feature vector comprising the one or more geometric features and the one or more subject parameters as input to the weight machine-learning module.
5. The method of claim 4, wherein the weight machine-learning module comprises one or more of a linear regressor, a nonlinear regressor, and a random forest algorithm, and
wherein the weight machine-learning module is trained on ground truth data comprising one or more sample body weights and one or more sample feature vectors for one or more sample subjects.
6. The method of claim 1, wherein one or more of the subject parameters are used as normalization data to scale from pixel coordinates to real-world coordinates in the one or more images.
7. The method of claim 6, wherein a height of the subject is used as the normalization data.
8. The method of claim 1, wherein the one or more images comprises at least two images, and wherein the at least two images contain the subject in at least two perspective views.
9. The method of claim 8, wherein the at least two images comprise at least a front-view image and a side-view image of the subject, and
wherein the generating the one or more geometric features based on the one or more annotation key points comprises one step selected from the group consisting of:
(a) calculating at least one circumference of at least one annotated body part utilizing annotated frontview and side-view images and a height of the subject;
(b) calculating at least one body part image area of at least one annotated body part utilizing annotated frontview and side-view images and a height of the subject; and
(c) calculating at least one body part volume of at least one annotated body part utilizing annotated frontview and side-view images and a height of the subject.
10. The method of claim 1, further comprising the following steps after the receiving the one or more images:
performing body segmentation on the images to identify the one or more body parts associated with the subject from a background,
wherein the body segmentation utilizes a segmentation deep-leaming module that has been trained on segmentation training data, and wherein the segmentation training data comprise one or more images for one or more sample subjects and a body part segmentation for each body part for the one or more sample subjects.
11. The method of claim 1, wherein the annotation deep-leaming modules utilize training data comprising one or more images for one or more sample subjects and one or more annotation key points for each body part for the one or more sample subjects.
12. The method of claim 1 , wherein the one or more subj ect parameters are selected from the group consisting of a height, a received subject weight estimate, a gender, an age, an ethnicity, and a demographic information associated with the subject.
13. The method of claim 1, wherein the prediction of the body weight of the subject is a first estimate, and wherein the method further comprises:
generating a second estimate of the body weight of the subject using a second machine-learning module;
comparing a first confidence score of the first estimate and a second confidence score of the second estimate; and
selecting either the first estimate or the second estimate as the body weight of the subject based on the first and the second confidence scores.
14. The method of claim 1, further comprising:
determining whether the prediction of the body weight of the subject corresponds to a confidence level below a predetermined value; and
in response to determining that the prediction of the body weight of the subject corresponds to a confidence level below the predetermined value,
comparing the prediction of the body weight of the subject to a received subject weight estimate,
updating the prediction of the body weight of the subject, wherein the received subject weight estimate is used to guide the weight machine-learning module, and
replacing the prediction of the body weight of the subject with an updated prediction of the body weight of the subject.
15. The method of claim 1 , wherein the one or more subj ect parameters are received from a mobile computing device, and wherein the images of the subject are received from a camera on the mobile computing device.
16. The method of claim 15, wherein the one or more subj ect parameters received from the mobile computing device comprises receiving a measurement performed by the mobile computing device.
17. The method of claim 15, wherein a depth data from a depth sensor on the mobile computing device is used as normalization data to scale from pixel coordinates to real-world coordinates in the one or more images.
18. The method of claim 15, further comprising:
pre-processing the one or more images of the subject and a background before identifying the annotation key points,
wherein the pre-processing comprises at least a perspective correction on the one or more images, and
wherein the perspective correction is selected from the group consisting of perspective correction utilizing a head of the subject, perspective correction utilizing a gyroscope of the mobile computing device, and a perspective correction utilizing another sensor of the mobile computing device.
19. A computer program product for predicting a body weight of a subject, comprising a nontransitory computer readable storage medium having program instructions embodied therein, the program instructions executable by a processor to cause the processor to:
receive one or more subject parameters;
receive one or more images containing the subject;
identify one or more annotation key points for one or more body parts underneath a clothing of the subject from the one or more images utilizing one or more annotation deep-leaming modules; calculate one or more geometric features of the subject based on the one or more annotation key points; and
generate a prediction of the body weight of the subject utilizing a weight machine-learning module based on the one or more geometric features of the subject and the one or more subject parameters.
20. The computer program product of claim 19, wherein the one or more geometric features are selected from the group consisting of body part circumference(s), body part length(s), body image area(s), body part image area(s), body volume(s), and body part volume(s).
</claims>
</document>
