<document>

<filing_date>
2018-09-04
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2018-09-04
</priority_date>

<ipc_classes>
G06N99/00
</ipc_classes>

<assignee>
TOYOTA CONNECTED NORTH AMERICA
</assignee>

<inventors>
KURSAR, BRIAN M.
</inventors>

<docdb_family_id>
67957415
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR QUERYING A DISTRIBUTED INVENTORY OF VISUAL DATA
</title>

<abstract>
System, methods, and other embodiments described herein relate to using vehicles as mobile observation platforms and improving the querying of visual data within the vehicles by leveraging edge computing resources of the vehicles in a distributed network. In one embodiment, a method includes, in response to receiving, in a selected vehicle that is equipped with at least one camera, a visual query from a remote device, identifying search parameters from the query that specify at least visual content that is to be identified. The method includes analyzing a subset of a visual inventory to identify whether the subset includes the visual content by using at least a machine vision model executing on a processor within the selected vehicle. The visual inventory includes camera data that is acquired by the selected vehicle. The method includes communicating detection results about whether the subset includes the visual content to the remote device.
</abstract>

<claims>
1. A vision system for improving the querying of visual data by using edge computing resources of collection devices in a distributed network, comprising: one or more processors; a memory communicably coupled to the one or more processors and storing: an acquisition module including instructions that when executed by the one or more processors cause the one or more processors to, in response to receiving, from a remote device, a visual query in a selected vehicle that is equipped with at least one camera, identify search parameters from the query that specify at least visual content that is to be identified; and a search module including instructions that when executed by the one or more processors cause the one or more processors to analyze a subset of a visual inventory to identify whether the subset includes the visual content by using at least a machine vision model executing on a processor within the selected vehicle, wherein the visual inventory includes camera data that is acquired by the selected vehicle from the at least one camera, wherein the search module further includes instructions to communicate detection results about whether the subset includes the visual content to the remote device.
2. The vision system of claim 1, wherein the search parameters specify the visual content by providing the machine vision model pre-trained to recognize the visual content and as part of the visual query, and wherein the machine vision model is a machine learning algorithm that identifies segments of the subset that include the visual content, and wherein the visual content includes one or more of a person of interest, a group of people, an animal of interest, a specific vehicle, environmental characteristics, and objects of interest.
3. The vision system of claim 1, wherein the acquisition module further includes instructions to load the subset of the visual inventory that correlates with a time window that is specified by the visual query into a memory for analysis by the machine vision model, and wherein the visual inventory includes previously recorded video acquired by the at least one camera and real-time video that the at least one camera is presently acquiring.
4. The vision system of claim 3, wherein the time window indicates a time associated with a location of the selected vehicle that is targeted for querying by the visual query, wherein the selected vehicle qualifies as one of the collection devices according to correlations between a location history of the selected vehicle and a targeted location associated with the visual query, wherein the visual query indicates a termination parameter for terminating analysis of real-time video within the visual inventory, and wherein the termination parameter indicates one or more of a frequency of detections for the visual content, a time limit, a data quota, and a stop request.
5. The vision system of claim 1, wherein the acquisition module further includes instructions to: acquire video data as a video stream from the at least one camera about a surrounding environment of the selected vehicle; analyze the video data according to an object recognition model to generate labels for classes of objects represented in the video data; and store the video data including the labels as the visual inventory in a data store of the vehicle.
6. The vision system of claim 5, wherein the acquisition module further includes instructions to, in response to a positive identification of the visual content existing in the subset by the machine vision model, collecting, in real-time by the at least one camera, additional visual data about a subject of the visual content, and wherein the acquisition module further includes instructions to collect the additional data further includes broadcasting the positive identification to nearby vehicles that are proximate to the selected vehicle to cause the nearby vehicles to collect visual data about the subject.
7. The vision system of claim 6, wherein the search module further includes instructions to: analyze the additional visual data according to the machine vision model to further identify characteristics of the subject, and provide, to the remote device from the selected vehicle, a refinement to the detection results that includes at least the identified characteristics.
8. The vision system of claim 5, wherein the acquisition module further includes instructions to communicate a location history of the selected vehicle to the remote device periodically to maintain the location history in a current state for accurate selection by the remote device of vehicles that are to be queried by the visual query, wherein the acquisition module further including instructions to provide the labels to the remote device for pre-filtering of vehicles that are to be selected for querying, wherein the visual query further includes query parameters for pre-filtering the subset, the query parameters indicating at least object classes for objects associated with the visual content.
9. A non-transitory computer-readable medium for improving the querying of visual data by using edge computing resources of collection devices in a distributed network and including instructions that when executed by one or more processors cause the one or more processors to: in response to receiving, from a remote device, a visual query in a selected vehicle that is equipped with at least one camera, identify search parameters from the query that specify at least visual content that is to be identified, analyze a subset of a visual inventory to identify whether the subset includes the visual content by using at least a machine vision model executing on a processor within the selected vehicle, wherein the visual inventory includes camera data that is acquired by the selected vehicle from the at least one camera, and communicate detection results about whether the subset includes the visual content to the remote device.
10. The non-transitory computer-readable medium of claim 9, wherein the search parameters specify the visual content by providing the machine vision model pre-trained to recognize the visual content and as part of the visual query, and wherein the machine vision model is a machine learning algorithm that identifies segments of the subset that include the visual content, and wherein the visual content includes one or more of a person of interest, a group of people, an animal of interest, a specific vehicle, environmental characteristics, and objects of interest.
11. The non-transitory computer-readable medium of claim 10, wherein the instructions further include instructions to, in response to a positive identification of the visual content existing in the subset by the machine vision model, collect, in real-time by the at least one camera, additional visual data about a subject of the visual content, and wherein the instructions further include instructions to collect the additional data further includes broadcasting the positive identification to nearby vehicles that are proximate to the selected vehicle to cause the nearby vehicles to collect visual data about the subject.
12. The non-transitory computer-readable medium of claim 11, wherein the instructions further include instructions to load the subset of the visual inventory that correlates with a time window that is specified by the visual query into a memory for analysis by the machine vision model, and wherein the visual inventory includes previously recorded video acquired by the at least one camera and real-time video that the at least one camera is presently acquiring, wherein the time window indicates a time associated with a location of the selected vehicle that is targeted for querying by the visual query, and wherein the selected vehicle qualifies as one of the collection devices according to correlations between a location history of the selected vehicle and a targeted location associated with the visual query.
13. A method of improving the querying of visual data by using edge computing resources of collection devices in a distributed network, comprising: in response to receiving, in a selected vehicle that is equipped with at least one camera, a visual query from a remote device, identifying search parameters from the query that specify at least visual content that is to be identified; analyzing a subset of a visual inventory to identify whether the subset includes the visual content by using at least a machine vision model executing on a processor within the selected vehicle, wherein the visual inventory includes camera data that is acquired by the selected vehicle from the at least one camera; and communicating detection results about whether the subset includes the visual content to the remote device.
14. The method of claim 13, wherein the search parameters specify the visual content by providing the machine vision model pre-trained to recognize the visual content and as part of the visual query, and wherein the machine vision model is a machine learning algorithm that identifies segments of the subset that include the visual content, and wherein the visual content includes one or more of a person of interest, a group of people, an animal of interest, a specific vehicle, environmental characteristics, and objects of interest.
15. The method of claim 13, further comprising: loading the subset of the visual inventory that correlates with a time window that is specified by the visual query into a memory for analysis by the machine vision model, wherein the visual inventory includes previously recorded video acquired by the at least one camera and real-time video that the at least one camera is presently acquiring, wherein the time window indicates a time associated with a location of the selected vehicle that is targeted for querying by the visual query, and wherein the selected vehicle qualifies as one of the collection devices according to correlations between a location history of the selected vehicle and a targeted location associated with the visual query.
16. The method of claim 13, further comprising: acquiring video data as a video stream from the at least one camera about a surrounding environment of the vehicle; analyzing the video data according to an object recognition model to generate labels for classes of objects represented in the video data; and storing the video data including the labels as the visual inventory in a data store of the vehicle.
17. The method of claim 13, further comprising: in response to a positive identification of the visual content existing in the subset by the machine vision model, collecting, in real-time by the at least one camera, additional visual data about a subject of the visual content, wherein collecting the additional data further includes broadcasting the positive identification to nearby vehicles that are proximate to the selected vehicle to cause the nearby vehicles to collect visual data about the subject; analyzing the additional visual data according to the machine vision model to further identify characteristics of the subject; and providing, to the remote device from the selected vehicle, a refinement to the detection results that includes at least the identified characteristics.
18. The method of claim 16, further comprising: communicating a location history of the selected vehicle to the remote device periodically to maintain the location history in a current state for accurate selection by the remote device of vehicles that are to be queried, wherein communicating further includes providing the labels to the remote device for pre-filtering of vehicles that are to be selected for querying, wherein the visual query further includes query parameters for pre-filtering the subset, the query parameters indicating at least object classes for objects associated with the visual content.
19. The method of claim 13, further comprising: generating the visual query, by the remote device, in response to receiving electronic inputs specifying the visual content about which to query, wherein generating the visual query includes at least training the machine vision model using training data embodied in the electronic inputs and by a cloud-computing system associated with the remote device; identifying a pool of available vehicles that correspond with a targeted location for a time window; and communicating the visual query to a sample of vehicles from the pool.
20. The method of claim 13, further comprising: terminating ongoing analysis of real-time video in the visual inventory responsive to determining that a termination parameter of the visual query has been satisfied, wherein the termination parameter indicates one or more of a frequency of detections for the visual content, a time limit, a data quota, and a stop request.
</claims>
</document>
