<document>

<filing_date>
2019-03-11
</filing_date>

<publication_date>
2020-01-16
</publication_date>

<priority_date>
2018-07-13
</priority_date>

<ipc_classes>
G06F16/21,G06F16/25,G06F16/28,G06F21/62
</ipc_classes>

<assignee>
ACCENTURE GLOBAL SOLUTIONS
</assignee>

<inventors>
DAS, JAYANTA
GUPTA, SUDHANSHU
SHRIVASTAVA, AMIT CHANDRA
OKORAFOR, EKPE
GUPTA, NAVEEN
KUMAR, VINEET
PAUL, NAYANJYOTI
RAY, ATISH
</inventors>

<docdb_family_id>
69138238
</docdb_family_id>

<title>
INTELLIGENT DATA INGESTION SYSTEM AND METHOD FOR GOVERNANCE AND SECURITY
</title>

<abstract>
An intelligent data ingestion and governance method and system is disclosed. A set of data requirements is received from a user. The set of data requirements includes multiple different formats and corresponding location information indicating a plurality of corresponding different data sources. One or more data policies are also received from the user as part of the set of data requirements. A configuration file is automatically generated using the set of data requirements. A new dataset is retrieved from the plurality of corresponding different sources of data, using the generated configuration file. The retrieved dataset is classified, and metadata for the retrieved dataset is provided. Actionable policies are automatically generated using the metadata and the user defined data policies, and a compliance engine is generated. Security of access to the retrieved input data is controlled using the generated compliance engine.
</abstract>

<claims>
We claim:
1. A method for intelligent data ingestion and governance within a data repository, comprising: receiving a set of data requirements for a new dataset from a user, the set of data requirements including location information for a data source and a data policy; automatically generating a configuration file using the received set of data requirements; automatically initiating retrieval of the new dataset from the data source using the generated configuration file; automatically saving the retrieved dataset in the data repository; automatically identifying and extracting a set of metadata from the retrieved dataset; automatically classifying the retrieved dataset and identifying the retrieved dataset with a first classification; automatically saving the set of metadata and the first classification; automatically retrieving the data policy from the configuration file and converting the data policy into executable code; automatically processing the retrieved dataset using the executable code to generate a curated dataset; and automatically saving the curated dataset in the data repository, wherein the curated dataset is accessible to one or more users.
2. The method according to claim 1, wherein retrieving the data policy includes identifying a data policy that is appropriate for the first classification.
3. The method according to claim 1, wherein the first classification indicates that the retrieved dataset includes sensitive information.
4. The method according to claim 3, wherein the data policy comprises a rule for hiding the sensitive information in the retrieved dataset.
5. The method according to claim 1, wherein the data policy is specified in natural language by the user and wherein converting the data policy into executable code comprises processing the data policy using natural language processing.
6. The method according to claim 1, wherein the set of data requirements includes a second data policy, and wherein the method further comprises: automatically determining that a context of the retrieved dataset has changed; automatically reclassifying the retrieved dataset according to the change in context of the dataset and identifying the retrieved dataset with a second classification; automatically retrieving the second data policy from the configuration file and converting the second data policy into new executable code; automatically reprocessing the retrieved dataset using the new executable code to generate a new curated dataset; and automatically saving the new curated dataset in the data repository.
7. The method according to claim 6, wherein retrieving the second data policy includes identifying a data policy that is appropriate for the second classification.
8. The method according to claim 6, wherein context of the retrieved dataset is dependent on relationships with other datasets in the data repository.
9. A system for intelligent data ingestion and governance, the system comprising: a device processor; and a non-transitory computer readable medium storing instructions that are executable by the device processor to implement: an intelligent governance portal that receives a set of data requirements from a user, the set of data requirements including location information for a data source and a data policy; a universal ingestion module that automatically initiates retrieval of a new dataset from the data source, using the generated configuration file; a classification module that initiates extracting metadata from the retrieved dataset and classification of the retrieved dataset; and a compliance engine module that automatically generates a compliance engine and controls security of access to the retrieved dataset using the generated compliance engine.
10. The system according to claim 9, wherein the classification module recommends the data policy to the compliance engine module based on the metadata.
11. The system according to claim 10, wherein the compliance engine module generates the compliance engine using the data policy recommended by the classification module.
12. The system according to claim 11, wherein the classification of the retrieved dataset is controlled by artificial intelligence processing.
13. The system according to claim 9, wherein the compliance engine module identifies the data policy for use in the compliance engine based on the metadata.
14. The system according to claim 9, wherein the system further comprises a data quality control module for monitoring the quality of the dataset.
15. The system according to claim 9, wherein the system further comprises a module that generates a knowledge graph for the retrieved dataset.
16. The system according to claim 9, wherein the set of data requirements includes a format for the retrieved dataset.
17. The system according to claim 9, wherein the classification module stores the metadata on a central repository and makes the metadata accessible on the central repository to other modules using an application programming interface.
18. The system according to claim 17, wherein the compliance engine module can access the metadata for the retrieved dataset on the central repository using the application programming interface.
19. The system according to claim 9, wherein the compliance engine module retrieves the data policy from the configuration file and converts the data policy into executable code that can be used to process the retrieved data.
20. A non-transitory computer-readable medium storing software comprising instructions executable by one or more computers which, upon such execution, cause the one or more computers to: receive a set of data requirements for a new dataset from a user, the set of data requirements including location information for a data source and a data policy; generate a configuration file using the received set of data requirements; initiate retrieval of a new dataset from the data source using the generated configuration file; save the retrieved dataset in a data repository; extract a set of metadata from the retrieved dataset; classify the retrieved dataset and identify the retrieved dataset with a first classification; save the metadata and the first classification; retrieve the data policy from the configuration file and convert the data policy into executable code; process the retrieved dataset using the executable code to generate a curated dataset; and save the curated dataset in the data repository.
</claims>
</document>
