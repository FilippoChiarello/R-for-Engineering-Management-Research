<document>

<filing_date>
2019-07-31
</filing_date>

<publication_date>
2020-02-27
</publication_date>

<priority_date>
2018-08-23
</priority_date>

<ipc_classes>
G10L15/02,G10L15/06,G10L15/18,G10L15/22,G10L19/00
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
LI WEI
MCGRAW, IAN C.
PRABHAVALKAR, ROHIT PRAKASH
RAO, KANURY KANISHKA
HE, YANZHANG
BAKHTIN, ANTON
</inventors>

<docdb_family_id>
69583593
</docdb_family_id>

<title>
KEY PHRASE SPOTTING
</title>

<abstract>
Methods, systems, and apparatus, including computer programs encoded on computer storage media, for detecting utterances of a key phrase in an audio signal. One of the methods includes receiving, by a key phrase spotting system, an audio signal encoding one or more utterances; while continuing to receive the audio signal, generating, by the key phrase spotting system, an attention output using an attention mechanism that is configured to compute the attention output based on a series of encodings generated by an encoder comprising one or more neural network layers; generating, by the key phrase spotting system and using attention output, output that indicates whether the audio signal likely encodes the key phrase; and providing, by the key phrase spotting system, the output that indicates whether the audio signal likely encodes the key phrase.
</abstract>

<claims>
1. A system comprising one or more computers and one or more storage devices on which are stored instructions that are operable, when executed by the one or more computers, to cause the one or more computers to perform operations comprising: receiving, by a key phrase spotting system, an audio signal encoding one or more utterances; while continuing to receive the audio signal, generating, by the key phrase spotting system, an attention output using an attention mechanism that is configured to compute the attention output based on a series of encodings generated by an encoder comprising one or more neural network layers; generating, by the key phrase spotting system and using attention output, output that indicates whether the audio signal likely encodes the key phrase; and providing, by the key phrase spotting system, the output that indicates whether the audio signal likely encodes the key phrase.
2. The system of claim 1, wherein: the attention mechanism comprises an attention-based biasing mechanism a) included in the key phrase spotting system b) that biases key phrase detection toward a sequence of sub-word units corresponding to a key phrase; the operations comprise predicting sub-word units corresponding to the audio signal using the attention output; and generating the output that indicates whether the audio signal likely encodes the key phrase comprises generating the output using the predicted sub-word units corresponding to the attention output.
3. The system of claim 2, wherein predicting the sub-word units corresponding to the audio signal comprises: generating, using the attention-based biasing mechanism, a context vector using an encoding of the key phrase and a representation of a prior state of at least a portion of the key phrase spotting system; and predicting, using the attention-based biasing mechanism, the sub-word units corresponding to the audio signal.
4. The system of claim 3, wherein predicting the sub-word units corresponding to the audio signal comprises: determining, using the attention-based biasing mechanism and for a frame from multiple frames representing the audio signal, that a particular predicted sub-word unit for the frame is likely a sub-word unit for the key phrase; and in response to determining that the particular predicted sub-word unit for the frame is likely a sub-word unit for the key phrase, activating an attention layer in the attention-based biasing mechanism to cause the attention layer to generate the context vector for a current frame from the multiple frames.
5. The system of claim 4, wherein determining, for the frame from the multiple frames, that the particular predicted sub-word unit for the frame is likely a sub-word unit for the key phrase comprises determining, for the frame from the multiple frames, that the particular predicted sub-word unit for the frame is likely a first sub-word unit in the key phrase.
6. The system of claim 4, wherein the representation of the prior state of at least a portion of the key phrase spotting system comprises a representation of a state, after processing data for one or more of any frames in the multiple frames prior to a current frame in the audio signal, of the attention layer and a prediction network that generates a predicted label using the context vector and a second representation of a prior state of at least a portion of the key phrase spotting system.
7. The system of claim 3, wherein generating the context vector comprises: for each frame of multiple frames representing the audio signal: generating the context vector for a current frame that represents a predicted sub-word unit for the key phrase using the encoding of the key phrase and a representation of the prior state of at least a portion of the key phrase spotting system after predicting sub-word units for one or more of any frames in the multiple frames prior to the current frame in the audio signal.
8. The system of claim 3, wherein predicting the sub-word units corresponding to the audio signal comprises: for each frame of multiple frames representing the audio signal: generating, by a prediction network included in the key phrase spotting system, a predicted label for a current frame from the multiple frames using the context vector for the current frame and data representing a previously predicted sub-word for a previous frame.
9. The system of claim 8, wherein generating the predicted label for the current frame comprises generating, for a first frame in the multiple frames that is located before the other frames in the audio signal, the predicted label for the current frame using, as input to the prediction network, the context vector for the current frame and a value that identifies the current frame as the first frame.
10. The system of claim 2, wherein generating the output that indicates whether the audio signal likely encodes the key phrase comprises: generating, by a softmax layer included in the key phrase spotting system, a probability that the audio signal includes the predicted sub-word unit; and generating, by the key phrase spotting system and using the probability, the output that indicates whether the audio signal likely encodes the key phrase.
11. The system of claim 2, the operations comprising: generating, by a keyword encoder included in the key phrase spotting system, data representing the key phrase, wherein predicting sub-word units corresponding to the audio signal comprises predicting sub-word units corresponding to the audio signal using the attention output and the data representing the key phrase.
12. The system of claim 11, the operations comprising: while continuing to receive the audio signal: receiving, by the key phrase spotting system, data that identifies a new key phrase that is a different key phrase from the key phrase; generating, by the keyword encoder included in the key phrase spotting system, updated data representing the new key phrase; and predicting, using the attention-based biasing mechanism that biases key phrase detection prediction toward a sequence of sub-word units corresponding to the new key phrase, sub-word units corresponding to the audio signal using data that represents the new key phrase.
13. The system of claim 2, the operations comprising: for each of multiple, different key phrases during a training process: generating, by a keyword encoder included in the key phrase spotting system, data representing the respective key phrase; and training the key phrase spotting system for the key phrase by adjusting one or more parameters in an encoder network that generates encoder output that represents an encoding of a current frame, the attention-based biasing mechanism, wherein predicting sub-word units corresponding to the audio signal comprises predicting sub-word units corresponding to the audio signal using the attention output and the data representing the key phrase.
14. The system of claim 13, wherein training the key phrase spotting for each of the multiple, different key phrases comprises: training the key phrase spotting system only for key phrases in a set of key phrases that includes the multiple, different key phrases and does not include the key phrase.
15. The system of claim 2, wherein each of the predicted sub-word units comprises the same one of: a grapheme, a phoneme, or a hidden Markov model state.
16. The system of claim 2, the operations comprising: for each frame of multiple frames representing the audio signal: generating, by an encoder network included in the key phrase spotting system, an encoder output that represents an encoding of a current frame from the multiple frames; and generating, using the encoder output for the current frame and the predicted sub-word unit, a combined output for the current frame that represents a predicted sub-word unit.
17. The system of claim 16, the operations comprising: generating, by a keyword encoder included in the key phrase spotting system, data representing the key phrase that is in a format that is similar to a format of the encoder output, wherein predicting sub-word units corresponding to the audio signal comprises predicting sub-word units corresponding to the audio signal using the attention output and the data representing the key phrase.
18. The system of claim 1, wherein providing the output that indicates whether the audio signal encodes the key phrase comprises providing, to an automated speech recognition system, output that indicates that the audio signal encodes the key phrase to cause the automated speech recognition system to detect other words encoded in the audio signal.
19. A computer-implemented method comprising: receiving, by a key phrase spotting system, an audio signal encoding one or more utterances; while continuing to receive the audio signal, generating, by the key phrase spotting system, an attention output using an attention mechanism that is configured to compute the attention output based on a series of encodings generated by an encoder comprising one or more neural network layers; generating, by the key phrase spotting system and using attention output, output that indicates whether the audio signal likely encodes the key phrase; and providing, by the key phrase spotting system, the output that indicates whether the audio signal likely encodes the key phrase.
20. A non-transitory computer storage medium encoded with instructions that, when executed by a data processing apparatus, cause the data processing apparatus to perform operations comprising: receiving, by a key phrase spotting system, an audio signal encoding one or more utterances; while continuing to receive the audio signal, generating, by the key phrase spotting system, an attention output using an attention mechanism that is configured to compute the attention output based on a series of encodings generated by an encoder comprising one or more neural network layers; generating, by the key phrase spotting system and using attention output, output that indicates whether the audio signal likely encodes the key phrase; and providing, by the key phrase spotting system, the output that indicates whether the audio signal likely encodes the key phrase.
</claims>
</document>
