<document>

<filing_date>
2019-01-25
</filing_date>

<publication_date>
2020-05-12
</publication_date>

<priority_date>
2016-08-30
</priority_date>

<ipc_classes>
G06F16/33,G06F16/9535,G06F3/0482,G06Q10/10,G10L15/06,G10L15/16,G10L15/18,G10L15/22,G10L15/26
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
DESELAERS, THOMAS
KEYSERS, DANIEL
CARBUNE, VICTOR
</inventors>

<docdb_family_id>
59901573
</docdb_family_id>

<title>
Using textual input and user state information to generate reply content to present in response to the textual input
</title>

<abstract>
Methods, apparatus, and computer readable media related to receiving textual input of a user during a dialog between the user and an automated assistant (and optionally one or more additional users), and generating responsive reply content based on the textual input and based on user state information. The reply content is provided for inclusion in the dialog. In some implementations, the reply content is provided as a reply, by the automated assistant, to the user's textual input and may optionally be automatically incorporated in the dialog between the user and the automated assistant. In some implementations, the reply content is suggested by the automated assistant for inclusion in the dialog and is only included in the dialog in response to further user interface input.
</abstract>

<claims>
1. A computer-implemented method comprising: receiving textual input, the textual input being based on user interface input generated by a user via one or more user interface input devices of a computing device of the user, wherein the user interface input is generated by the user and is directed to an automated assistant, implemented by one or more processors of the computing device, as part of a dialog that is only between the user and the automated assistant; determining user state information for the user, wherein the user state information identifies a state of the user, is in addition to the textual input, and is based on sensor data generated by the computing device or an additional computing device of the user; generating, by the one or more processors, reply content in response to the textual input, wherein generating the reply content is based on the textual input and on the user state information and is not based on input from other users; and providing the reply content as part of the dialog that is only between the user and the automated assistant in response to the user interface input, wherein the reply content is provided as part of the dialog as a reply to the textual input, and wherein the reply content is provided for presentation via one or more user interface output devices.
2. The computer-implemented method of claim 1, wherein a transcript of the dialog between the user and the automated assistant is displayed in a graphical user interface rendered by one of the one or more user interface output devices and wherein providing the reply content comprises: incorporating the reply content into the transcript for display along with previous content of the dialog.
3. The computer-implemented method of claim 2, wherein the incorporating the reply content into the transcript comprises: transmitting, via one or more network interfaces, a command to the computing device, wherein the command causes the computing device to incorporate the reply content into the transcript.
4. The computer-implemented method of claim 1, wherein the user interface input includes a query directed to the automated assistant to request the reply that is generated by the automated assistant without using input from the other users, and wherein the reply content is generated as the reply to the query.
5. The computer-implemented method of claim 1, wherein generating the reply content based on the textual input and on the user state information comprises: providing the textual input to a text generation engine; receiving an initial textual output generated from the text generation engine based on the textual input; and generating the reply content by modifying the initial textual output based on the user state information.
6. The computer-implemented method of claim 5, wherein modifying the initial textual output based on the user state information comprises: applying input to a model stored in one or more computer readable media, the input being one or more segments of the initial textual output; and generating, using the model and based on the input, output that indicates one or more terms for modifying the initial textual output.
7. The computer-implemented method of claim 6, wherein the model includes mappings of neutral textual segments to corresponding user state textual segments that are specific to user states, wherein the user state textual segments are different than the corresponding neutral textural segments, wherein the neutral textual segments are not indicative of the user states, and wherein each of the user state textual segments includes at least one of: one or more terms added to a corresponding neutral textual segment, one or more terms replacing at least one term of the corresponding neutral textual segment, one or more fewer terms than the corresponding neutral textual segment, or non-textual content that is not included in the corresponding neutral textual segment, wherein modifying the initial text output includes using one or more of the mappings to determine a particular user state textual segment that corresponds to a particular neutral textual segment in the initial text output, and providing the particular user state textual segment in the reply content.
8. The computer-implemented method of claim 1, wherein the reply content includes at least one selectable graphical element that, when selected via further user interface input, causes the computing device of the user to present additional content via at least one of the one or more user interface output devices.
9. The computer-implemented method of claim 8, wherein selection of the selectable graphical element causes the computing device of the user to establish a network connection with a computing device of an additional user and wherein the additional content indicates initiation of a new dialog with the additional user, wherein the new dialog enables transmission and display of messages between the user and the additional user via a graphical user interface.
10. The computer-implemented method of claim 1, wherein determining the user state information comprises: identifying a plurality of user state indicators based on the sensor data; applying the user state indicators as input to at least one user state model stored in one or more computer readable media; and generating, over the at least one user state model and based on the user state indicators, output that indicates the user state information.
11. The computer-implemented method of claim 1, wherein generating the reply content based on the textual input and on the user state information comprises: determining a plurality of reply options based on the textual input; selecting one of the reply options based on a first conformity of a user sentiment associated with the selected one of the reply options to a user sentiment associated with the user state information, wherein the first conformity is closer than a second conformity of a user sentiment associated with other ones of the reply options to the user sentiment associated with the user state information; and generating the reply content based on the selected one of the reply options.
12. The computer-implemented method of claim 1, wherein generating the reply content based on the textual input and on the user state information comprises: determining, based on a sentiment classifier, a first textual output that indicates a first user state that is different than the state of the user; determining, based on a sentiment classifier, a second textual output that indicates a second user state that is the same as the state of the user; and selecting the first textual output and not the second textual output as the reply content, wherein the selecting is based on a mapping of the state of the user to the first textual output.
13. The computer-implemented method of claim 1, further comprising: adding an additional user to the dialog; determining additional user state information for the additional user; and generating, by the one or more processors, second reply content based on the textual input, the user state information, and the additional user state information.
14. The computer-implemented method of claim 13, further comprising receiving additional user interface input from an additional computing device of the additional user, and further comprising providing the second reply content for presentation to the computing device of the user and to the additional computing device of the additional user.
15. The computer-implemented method of claim 1, wherein generating the reply content based on the user state information comprises: determining a style feature of the reply content based on the user state information, wherein the style feature includes at least one of: a font size of text of the reply content, a font type of the text of the reply content, or a font color of the text of the reply content.
16. A computer-implemented method implemented by one or more processors, the computer-implemented method comprising: receiving textual input, the textual input based on user interface input generated via one or more user interface input devices of a computing device of a user, wherein the user interface input is generated as part of a dialog between the user and an automated assistant implemented by one or more of the processors of the computing device, wherein the automated assistant is interacted with by the user; determining user state information for the user, wherein the user state information identifies a state of the user and is based on sensor data generated by the computing device or an additional computing device of the user; generating reply content in response to the textual input, the reply content based on the textual input and on the user state information, wherein generating the reply content comprises: generating, by the one or more processors, an initial textual output based on the textual input, wherein the initial textual output is a response to the textual input in the dialog between the user and the automated assistant; and generating the reply content by modifying the initial textual output based on the user state information; and providing the reply content as part of the dialog between the user and the automated assistant in response to the textual input, wherein the reply content is provided as part of the dialog as a reply to the textual input, and wherein the reply content is provided for presentation via one or more user interface output devices.
17. The computer-implemented method of claim 16, wherein the user interface input includes a query directed to the automated assistant to request a reply that is generated by the automated assistant without using input from other users, and wherein the reply content is created as a response to the query.
18. The computer-implemented method of claim 16, wherein generating the initial textual output based on the textual input includes using a text generation engine operative to predict the initial textual output as responsive to the textual input based on features of textual input that include at least one of: one or more terms included in the textual input, one or more syntactic structures of the textual input, or length of the textual input.
19. A system comprising: a memory; and one or more processors coupled to the memory and configured to execute instructions stored in the memory, and wherein the instructions cause performance of operations comprising: receiving textual input, the textual input being based on user interface input generated by a user via one or more user interface input devices of a computing device of the user, wherein the user interface input is generated by the user and is directed to an automated assistant implemented by one or more processors of the computing device, as part of a dialog that is only between the user and the automated assistant; determining user state information for the user, wherein the user state information identifies a state of the user, is in addition to the textual input, and is based on sensor data generated by the computing device or an additional computing device of the user; generating, by the one or more processors, reply content in response to the textual input, wherein generating the reply content is based on the textual input and on the user state information and is not based on input from other users; and providing the reply content as part of the dialog that is only between the user and the automated assistant in response to the user interface input, wherein the reply content is provided as part of the dialog as a reply to the textual input, and wherein the reply content is provided for presentation via one or more user interface output devices.
20. The system of claim 19, where generating the reply content based on the textual input and on the user state information comprises: providing the textual input to a text generation engine; receiving an initial textual output generated from the text generation engine based on the textual input; and generating the reply content by modifying the initial textual output based on the user state information.
</claims>
</document>
