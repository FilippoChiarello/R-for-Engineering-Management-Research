<document>

<filing_date>
2020-08-20
</filing_date>

<publication_date>
2020-12-31
</publication_date>

<priority_date>
2018-01-23
</priority_date>

<ipc_classes>
G06N20/00,G06N3/08,G06N5/02,G06N5/04,G06N7/00
</ipc_classes>

<assignee>
LANG, ULRICH
SCHREINER, RUDOLF
</assignee>

<inventors>
LANG, ULRICH
SCHREINER, RUDOLF
</inventors>

<docdb_family_id>
67616469
</docdb_family_id>

<title>
METHOD AND SYSTEM FOR DETERMINING POLICIES, RULES, AND AGENT CHARACTERISTICS, FOR AUTOMATING AGENTS, AND PROTECTION
</title>

<abstract>
A method of automatically configuring an action determination model includes determining an environment model, determining an action determination model that indicates an action option, determining whether the action determination model indicates a next action option, and if so, determining an action based on the action determination model, simulating execution of the action across the environment model, obtaining a simulated result, adjusting the action determination model. Then, until environment or an agent reach an end state, the following are repeated: determining whether the action determination model indicates the next action option, and if so, determining the action based on the action determination model, simulating the execution of the action across the environment model, obtaining the simulated result, and adjusting the action determination model.
</abstract>

<claims>
1. A method of automatically configuring at least one action determination model for at least one agent that indicates at least one action option to be executed on at least one environment by the at least one agent, the method comprising: determining, via a processor, at least one environment model for the at least one environment which indicates attributes and behaviors of the environment and/or its context, and/or agents; determining, via the processor, the at least one action determination model for the at least one agent that indicates the at least one action option to be executed by the at least one agent, the indication being determined by at least one objective of the at least one agent; determining, via the processor, whether the at least one action determination model indicates at least one next action option to be executed by the at least one agent, and if so, determining, via the processor, from the at least one action option, at least one action to be executed based on the action determination model; simulating, via the processor, at least one execution of the at least one action across the environment model, and obtaining at least one simulated result of the simulated execution; adjusting, via the processor, the at least one action determination model based on a difference between the at least one objective and the at least one simulated result; and repeating, via the processor, until the environment or the at least one agent reach at least one end state: determining whether the at least one action determination model indicates the at least one next action option to be executed by the at least one agent, and if so, determining from the at least one action option, the at least one action to be executed based on the action determination model; simulating the at least one execution of the at least one action across the environment model, and obtaining the at least one simulated result of the at least one simulated execution; and adjusting the at least one action determination model based on the differences between the at least one objective and the at least one simulated result.
2. The method according to claim 1, wherein the at least one end state is reached when the differences between the at least one expected result and the at least one simulated result are below a threshold.
3. The method according to claim 1, wherein simulating, via the processor, the at least one execution of the at least one action across the environment model comprises simulating the effects of executing logic on at least one IT system.
4. The method according to claim 1, wherein adjusting via the processor, the at least one action determination model based on the difference between the at least one objective and the at least one simulated result involves optimizers, machine learning, or reinforcement learning.
5. The method according to claim 1, wherein the at least one action determination model is at least one of a trained neural network, rule engine, model transformation, model execution, statistical model, stochastic model, probabilistic model, artificial reasoning model, reinforcement learning model, inference model, program, fuzzy logic, or decision tree.
6. The method according to claim 1, wherein the at least one action determination model defines the at least one next action to select in at least one given context.
7. The method according to claim 1, wherein the at least one action determination model determines at least one of an attacker action, an attack action, an exploit action, a defender action, a defending action, a detection action, a mitigation action, a prevention action, an alarm/alert action, a monitoring action, an evaluator action, a tester action, a penetration testing action, a vulnerability assessment action, a recommendation for human users, a configuration action for machines, a policy based action, a rule-based action, a user input action, a user output action, a data ingestion action, a repair action, assembly/disassembly action, a preparing action, a use action, a disposal action, a maintenance action, a directing action, an informational action, an entertaining action, a diagnosing action, transaction action, a purchasing action, a selling action, decision action, training action, education action, buying action, notification action, deception action, distraction action, timing action, delay action, support action, redirect action, or a transfer action.
8. The method according to claim 1, wherein determining the at least one action option is partly or fully based on success likelihood of the at least one action.
9. The method according to claim 1, wherein the at least one result of the at least one action includes at least one of an environment effect, an agent effect, console output, data returned by the action, data returned by the environment, context data, metadata, or data returned by the agent.
10. The method according to claim 1, wherein the at least one objective of the at least one agent includes successful attacking, defending, preventing, assessing, testing, evaluating, alarming, monitoring of the environment, providing a service, maintaining, updating, analyzing, deceiving, action execution, action sequence execution.
11. The method according to claim 1, wherein the at least one end state includes success or failure of the at least one objective of the at least one agent.
</claims>
</document>
