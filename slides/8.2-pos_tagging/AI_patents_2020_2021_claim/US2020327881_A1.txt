<document>

<filing_date>
2019-04-11
</filing_date>

<publication_date>
2020-10-15
</publication_date>

<priority_date>
2019-04-11
</priority_date>

<ipc_classes>
G10L15/06,G10L15/16,G10L15/183,G10L15/22
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
KURATA, GAKUTO
</inventors>

<docdb_family_id>
72748448
</docdb_family_id>

<title>
TRAINING DATA MODIFICATION FOR TRAINING MODEL
</title>

<abstract>
A computer-implemented method for training a model is disclosed. The model is capable of retaining a history of one or more preceding elements and has a direction of prediction. The method includes obtaining a training sequence of elements. The method also includes splitting the training sequence into a plurality of parts. The method further includes selecting one part of the plurality of the parts depending on the direction of the model to generate a modified training data. The method includes further training the model using the modified training data.
</abstract>

<claims>
1. A computer-implemented method for training a model, the method comprising: obtaining a training sequence of elements for the model, the model being capable of retaining a history of one or more preceding elements and having a direction of prediction; splitting the training sequence into a plurality of parts; selecting one part of the plurality of the parts depending on the direction of the prediction to generate a modified training data; and training the model using the modified training data.
2. The method of claim 1, wherein the model is used for rescoring one or more input sequences obtained as hypotheses of a recognition process.
3. The method of claim 2, wherein the model includes a recurrent type neural network language model, the training sequence of the elements includes a training sentence including a plurality of words, the recognition process includes speech recognition and a result outputted from the speech recognition is rescored with the model as the hypothesis.
4. The method of claim 2, wherein the recognition process is selected from the group consisting of speech recognition, machine translation, part-of-speech tagging, parsing, optical character recognition, handwriting recognition, image captioning, and video captioning.
5. The method of claim 2, wherein, in rescoring each input sequence with the model, the history is discarded at least in part in response to a condition related to a confidence of the recognition process about one input element in the input sequence being satisfied.
6. The method of claim 5, wherein the model has a hidden state representing the history, the history is discarded by resetting the hidden state of the model to a state having accepted a predetermined symbol and the rescoring is restarted in response to one satisfying the condition.
7. The method of claim 1, wherein the method further comprises: adding a predetermined symbol at a boundary of the one part, the modified training data including the one part and the predetermined symbol.
8. The method of claim 7, wherein the predetermined symbol represents a beginning of a sequence or an end of a sequence depending on the direction of the prediction.
9. The method of claim 7, wherein the predetermined symbol represents occurrence of an error of recognition and the model has an additional token corresponding to the predetermined symbol.
10. The method of claim 7, wherein the direction of the prediction is a forward direction, a latter part of the plurality of the parts is selected as the one part and the boundary is a beginning of the latter part.
11. The method of claim 7, wherein the direction of the prediction is a backward direction, a former part of the plurality of the parts is selected as the one part and the boundary is an end of the former part.
12. The method of claim 1, wherein the training sequence is divided at a position determined randomly or statistically.
13. A computer-implemented method for rescoring an input sequence obtained as a hypothesis of a recognition process, the method comprising: preparing a model for rescoring the hypothesis, the model being capable of retaining a history of one or more preceding elements and having a direction of rescoring; feeding the input sequence into the model according to the direction; in response to a condition related to confidence of the recognition process about one input element in the input sequence being satisfied, discarding the history at least in part: and outputting a result of rescoring the input sequence.
14. The method of claim 13, wherein the model has a hidden state representing the history, the history is discarded by resetting the hidden state of the model to a state having accepted a predetermined symbol and the rescoring is restarted in response to one satisfying the condition.
15. The method of claim 13, wherein the model is built by: obtaining a training sequence of elements; splitting the training sequence into a plurality of parts; selecting one part of the plurality of the parts depending on the direction of the rescoring to generate a modified training data; and training the model using the modified training data.
16. The method of claim 13, wherein the model has an additional token representing an error of the recognition process.
17. A computer system for training a model, by executing program instructions, the computer system comprising: a memory storing the program instructions; a processing unit in communications with the memory for executing the program instructions, wherein the processing unit is configured to: obtain a training sequence of elements for the model, the model being capable of retaining a history of one or more preceding elements and having a direction of prediction; split the training sequence into a plurality of parts; select one part of the plurality of the parts depending on the direction of the prediction to generate a modified training data; and train the model using the modified training data.
18. The computer system of claim 17, wherein the model is used for rescoring one or more input sequences obtained as hypotheses of a recognition process.
19. The computer system of claim 17, wherein the processing unit is configured to: add a predetermined symbol at a boundary of the one part, wherein the modified training data includes the one part and the predetermined symbol.
20. A computer system for rescoring an input sequence obtained as a hypothesis of a recognition process, by executing program instructions, the computer system comprising: a memory storing the program instructions; a processing unit in communications with the memory for executing the program instructions, wherein the processing unit is configured to: prepare a model for rescoring the hypothesis, wherein the model is capable of retaining a history of one or more preceding elements and has a direction of rescoring; feed the input sequence into the model according to the direction; in response to a condition related to confidence of the recognition process about one input element in the input sequence being satisfied, discard the history at least in part; and output a result of rescoring the input sequence.
21. The computer system of claim 20, wherein the model has a hidden state representing the history, the history is discarded by resetting the hidden state of the model to a state having accepted a predetermined symbol and the rescoring is restarted in response to one satisfying the condition.
22. A computer program product for training a model, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a computer-implemented method comprising: obtaining a training sequence of elements for the model, the model being capable of retaining a history of one or more preceding elements and having a direction of prediction; splitting the training sequence into a plurality of parts; selecting one part of the plurality of the parts depending on the direction of the prediction to generate a modified training data; and training the model using the modified training data.
23. The computer program product of claim 22, wherein the model is used for rescoring one or more input sequences obtained as hypotheses of a recognition process.
24. The computer program product of claim 22, wherein the method further comprises: adding a predetermined symbol at a boundary of the one part, the modified training data including the one part and the predetermined symbol.
25. A computer program product for rescoring an input sequence obtained from a recognition process, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform the method of claim 13.
</claims>
</document>
