<document>

<filing_date>
2019-04-25
</filing_date>

<publication_date>
2020-03-11
</publication_date>

<priority_date>
2018-09-05
</priority_date>

<ipc_classes>
G06K9/00,G06K9/32,G06K9/46,G06K9/62
</ipc_classes>

<assignee>
STRADVISION
</assignee>

<inventors>
BOO, SUKHOON
CHO, HOJIN
JANG, TAEWOONG
JE, HONGMO
JEONG, KYUNGJOONG
KIM, HAK-KYOUNG
KIM, INSU
KIM, KYE-HYEON
KIM, YONGJOONG
NAM, WOONHYUN
RYU, WOOJU
SUNG, MYUNGCHUL
YEO, DONGHUN
</inventors>

<docdb_family_id>
66286251
</docdb_family_id>

<title>
METHOD AND DEVICE FOR GENERATING IMAGE DATA SET TO BE USED FOR LEARNING CNN CAPABLE OF DETECTING OBSTRUCTION IN AUTONOMOUS DRIVING CIRCUMSTANCE
</title>

<abstract>
A method of generating at least one training data set including steps of: (a) a computing device acquiring (i) an original image and (ii) an initial synthesized label generated by using an original label and a bounding box corresponding to an arbitrary specific object (b) the computing device supporting a CNN module to generate a first synthesized image and a first synthesized label by using the original image and the initial synthesized label, wherein the first synthesized label is created by adding a specific label to the original label at a location in the original label corresponding to a location of the bounding box in the initial synthesized label, and wherein the first synthesized image is created by adding a specific image o to the original image at a location in the original image corresponding to the location of the bounding box in the initial synthesized label.
</abstract>

<claims>
1. A method of generating at least one image data set to be used for learning CNN capable of detecting at least one obstruction in one or more autonomous driving circumstances, comprising steps of: (a) a computing device acquiring (i) an original image representing a road driving circumstance and (ii) an initial synthesized label generated by using an original label corresponding to the original image and a bounding box corresponding to an arbitrary specific object wherein the arbitrary specific object does not relate to the original image (b) the computing device supporting a CNN module to generate a first synthesized image and a first synthesized label by using the original image and the initial synthesized label, wherein the first synthesized label is created by adding a specific label corresponding to the specific object to the original label at a location in the original label corresponding to a location of the bounding box, corresponding to the specific object, in the initial synthesized label, and wherein the first synthesized image is created by adding a specific image of the specific object to the original image at a location in the original image corresponding to the location of the bounding box, corresponding to the specific object, in the initial synthesized label.
2. The method of claim 1, wherein, at the step of (a), the computing device further acquires (iii) a value of a random seed, and
wherein, at the step of (b), the computing device supports the CNN module to generate a plurality of adjusted first synthesized images by using the original image, the initial synthesized label, and the value of the random seed, wherein the adjusted first synthesized images are derived from the first synthesized image such that at least part of a size, a location, and a color of the specific object in each of the adjusted first synthesized images are adjusted from those of the specific object in the first synthesized image while changing the value of the random seed.
3. The method of claim 1, wherein, at the step of (a), the computing device further acquires (iii) a value of a random seed, and
wherein the method further comprises a step of :
(c) the computing device supporting the CNN module to receive the first synthesized label, the first synthesized image, and the value of the random seed as inputs of the CNN module, and then supporting the CNN module to iteratively (i) generate one or more intermediate synthesized labels and one or more intermediate synthesized images and (ii) receive the generated intermediate synthesized labels and the generated intermediate synthesized images as the inputs of the CNN module,
wherein, at the step of (c), while iteratively generating the intermediate synthesized labels and the intermediate synthesized images, the computing device iteratively combines the specific label and the specific image corresponding to the specific object with the generated intermediate synthesized labels and the generated intermediate synthesized images, respectively, such that the specific label and the specific image are respectively located at a same or similar location, corresponding to the location of the bounding box in the initial synthesized label, in the generated intermediate synthesized images and the generated intermediate synthesized labels, to thereby generate a second synthesized label and a second synthesized image.
4. The method of claim 1, wherein, on condition that shapes of bounding box candidates, to be provided for allowing the bounding box to be selected thereamong, corresponding to the specific object follow a probability distribution, a shape of the bounding box is determined by referring to the probability distribution.
5. The method of claim 4, wherein, on condition that widths and heights of the bounding box candidates corresponding to the specific object follow a first probability distribution and a second probability distribution respectively, the shape of the bounding box is determined by determining the width and the height by referring to the first and the second probability distributions respectively.
6. The method of claim 1, wherein, on condition that locations of the bounding box candidates corresponding to the specific object follow a probability distribution which is acquired by referring to information on relative locations of various objects, in various images, whose types and sizes are similar to a type and a size of the specific object, the location of the bounding box corresponding to the specific object is determined by referring to the probability distribution.
7. The method of claim 1, further comprising a step of:
(d) the computing device adding the first synthesized image and the first synthesized label into a database including training data sets to be used for one of object detection and image segmentation.
8. A computing device of generating at least one image data set to be used for learning CNN capable of detecting at least one obstruction in one or more autonomous driving circumstances, comprising: a communication part for acquiring (i) an original image representing a road driving circumstance and (ii) an initial synthesized label generated by using an original label corresponding to the original image and a bounding box corresponding to an arbitrary specific object wherein the arbitrary specific object does not relate to the original image; and a processor for performing a process of (I) supporting a CNN module to generate a first synthesized image and a first synthesized label by using the original image and the initial synthesized label, wherein the first synthesized label is created by adding a specific label corresponding to the specific object to the original label at a location in the original label corresponding to a location of the bounding box, corresponding to the specific object, in the initial synthesized label, and wherein the first synthesized image is created by adding a specific image of the specific object to the original image at a location in the original image corresponding to the location of the bounding box, corresponding to the specific object, in the initial synthesized label.
9. The device of claim 8, wherein, the communication part further acquires (iii) a value of a random seed, and
wherein, at the process (I), the processor performs a process of supporting the CNN module to generate a plurality of adjusted first synthesized images by using the original image, the initial synthesized label, and the value of the random seed, wherein the adjusted first synthesized images are derived from the first synthesized image such that at least part of a size, a location, and a color of the specific object in each of the adjusted first synthesized images are adjusted from those of the specific object in the first synthesized image while changing the value of the random seed.
10. The device of claim 8, wherein the communication part further acquires (iii) a value of a random seed, and
wherein the processor further performs a process of:
(II) supporting the CNN module to receive the first synthesized label, the first synthesized image, and the value of the random seed as inputs of the CNN module, and then supporting the CNN module to iteratively (i) generate one or more intermediate synthesized labels and one or more intermediate synthesized images and (ii) receive the generated intermediate synthesized labels and the generated intermediate synthesized images as the inputs of the CNN module,
wherein, at the process of (II), while iteratively generating the intermediate synthesized labels and the intermediate synthesized images, the processor iteratively combines the specific label and the specific image corresponding to the specific object with the generated intermediate synthesized labels and the generated intermediate synthesized images, respectively, such that the specific label and the specific image are respectively located at a same or similar location corresponding to the location of the bounding box in the initial synthesized label, in the generated intermediate synthesized images and the generated intermediate synthesized labels, to thereby generate a second synthesized label and a second synthesized image.
11. The device of claim 8, wherein, on condition that shapes of bounding box candidates, to be provided for allowing the bounding box to be selected thereamong, corresponding to the specific object, follow a probability distribution, a shape of the bounding box is determined by referring to the probability distribution.
12. The device of claim 11, wherein, on condition that widths and heights of the bounding box candidates corresponding to the specific object follow a first probability distribution and a second probability distribution respectively, the shape of the bounding box is determined by determining the width and the height by referring to the first probability distribution and the second probability distributions respectively.
13. The device of claim 8, wherein, on condition that locations of the bounding box candidates corresponding to the specific object follow a probability distribution which is acquired by referring to information on relative locations of various objects, in various images, whose types and sizes are similar to a type and a size of the specific object, the location of the bounding box corresponding to the specific object is determined by referring to the probability distribution.
14. The device of claim 8, wherein the processor further performs a process of:
(III) adding the first synthesized image and the first synthesized label into a database including training data sets to be used for one of object detection and image segmentation.
</claims>
</document>
