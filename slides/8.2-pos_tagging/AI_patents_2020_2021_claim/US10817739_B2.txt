<document>

<filing_date>
2019-01-31
</filing_date>

<publication_date>
2020-10-27
</publication_date>

<priority_date>
2019-01-31
</priority_date>

<ipc_classes>
G06F3/0482,G06F3/0484,G06K9/00,G06K9/20,G06K9/72,G10L15/22,G10L15/26
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
BEDI, AJAY
BHALLA, POONAM
GUPTA, SUBHAM
SINGH KARI, KRISHNA
</inventors>

<docdb_family_id>
71837526
</docdb_family_id>

<title>
Content-aware selection
</title>

<abstract>
An image editing program can include a content-aware selection system. The content-aware selection system can enable a user to select an area of an image using a label or a tag that identifies object in the image, rather than having to make a selection area based on coordinates and/or pixel values. The program can receive a digital image and metadata that describes an object in the image. The program can further receive a label, and can determine from the metadata that the label is associated with the object. The program can then select a bounding box for the object, and identify in the bounding box, pixels that represent the object. The program can then output a selection area that surrounds the pixels.
</abstract>

<claims>
1. A computer-implemented method, comprising: receiving, at a content-aware selection system executing on a computing device, a digital image and metadata associated with the digital image, wherein the metadata describes an object in the digital image using a bounding box and a label, the bounding box including a rectangular region of the digital image, the rectangular region including a set of pixels that represent the object; receiving input identifying a particular label; determining that the particular label corresponds to the label describing the object; selecting, using the label the bounding box describing the object; identifying, within the rectangular region included in the bounding box, the set of pixels that represent the object; and outputting a selection area, the selection area surrounding the set of pixels.
2. The computer-implemented method of claim 1, further comprising: receiving input corresponding to selection of a location within the digital image; determining that the location is within the rectangular region included by the bounding box; and generating a list of objects for which the selection area can be generated, the list of objects including the label.
3. The computer-implemented method of claim 2, further comprising: generating an onscreen menu, the onscreen menu including the list of objects, wherein the input identifying the particular label is received when the particular label is selected from the onscreen menu.
4. The computer-implemented method of claim 2, further comprising: determining, from the metadata, that a second bounding box has a second label that is similar to the label; and adding a pluralized version of the label to the list of objects.
5. The computer-implemented method of claim 2, further comprising: determining, from the metadata, a second label, wherein the second label is for a super-category of the label; determining that the super-category includes more than one object; and adding the second label to the list of objects.
6. The computer-implemented method of claim 1, further comprising: determining that the particular label is for a super-category, the super-category including the label; determining that the super-category includes a second label associated with a second bounding box; and identifying, within the a second rectangular region, a second set of pixels representing a second object, wherein the selection area also surrounds the second set of pixels.
7. The computer-implemented method of claim 1, wherein the input includes selection of a location within the digital image, and wherein identifying the particular label includes determining a particular bounding box that includes the location.
8. The computer-implemented method of claim 1, wherein the input is derived from an onscreen menu.
9. The computer-implemented method of claim 1, wherein the input is a text string derived from voice input.
10. The computer-implemented method of claim 1, further comprising: performing object recognition on the digital image, wherein the object recognition produces the bounding box and one or more labels for the object; filtering the one or more labels using a lexical dictionary, wherein filtering produces a set of labels from the one or more labels; determining one or more hierarchical relationships between the set of labels; and generating the metadata, the metadata further including the one or more hierarchical relationships.
11. A computing device executing a content-aware selection system, comprising: one or more processors; and a non-transitory computer-readable medium including instructions that, when executed by the one or more processors, cause the one or more processors to perform operations including: receiving a digital image and metadata associated with the digital image, wherein the metadata describes an object in the digital image using a bounding box and a label, the bounding box including a rectangular region of the digital image, the rectangular region including a set of pixels that represent the object; receiving input identifying a particular label; determining that the particular label corresponds to the label describing the object; selecting, using the label the bounding box describing the object; identifying, within the rectangular region included in the bounding box, the set of pixels that represent the object; and outputting a selection area, the selection area surrounding the set of pixels.
12. The computing device of claim 11, wherein the instructions further cause the one or more processors to perform operations including: receiving input corresponding to selection of a location within the digital image; determining that the location is within the rectangular region included by the bounding box; and generating a list of objects for which the selection area can be generated, the list of objects including the label.
13. The computing device of claim 11, wherein the instructions further cause the one or more processors to perform operations including: determining that the particular label is for a super-category, the super-category including the label; determining that the super-category includes a second label associated with a second bounding box; and identifying, within the a second rectangular region, a second set of pixels representing a second object, wherein the selection area also surrounds the second set of pixels.
14. The computing device of claim 11, wherein the input includes selection of a location within the digital image, and wherein identifying the particular label includes determining a particular bounding box that includes the location.
15. The computing device of claim 11, wherein the input is derived from an onscreen menu.
16. The computing device of claim 11, wherein the input is a text string derived from voice input.
17. The computing device of claim 11, wherein the instructions further cause the one or more processors to perform operations including: performing object recognition on the digital image, wherein the object recognition produces the bounding box and one or more labels for the object; filtering the one or more labels using a lexical dictionary, wherein filtering produces a set of labels from the one or more labels; determining one or more hierarchical relationships between the set of labels; and generating the metadata, the metadata further including the one or more hierarchical relationships.
18. A non-transitory computer-readable medium having stored thereon instructions that, when executed by one or more processors, cause the one or more processors to perform operations including: receiving a digital image and metadata associated with the digital image, wherein the metadata describes an object in the digital image using a bounding box and a label, the bounding box including a rectangular region of the digital image, the rectangular region including a set of pixels that represent the object; receiving input identifying a particular label; determining that the particular label corresponds to the label describing the object; selecting, using the label, the bounding box describing the object; identifying, within the rectangular region included in the bounding box, the set of pixels that represent the object; and outputting a selection area, the selection area surrounding the set of pixels.
19. The non-transitory computer-readable medium of claim 18, further comprising instructions that, when executed by the one or more processors, cause the one or more processors to perform operations including: receiving input corresponding to selection of a location within the digital image; determining that the location is within the rectangular region included by the bounding box; and generating a list of objects for which the selection area can be generated, the list of objects including the label.
20. The non-transitory computer-readable medium of claim 18, further comprising instructions that, when executed by the one or more processors, cause the one or more processors to perform operations including: determining that the particular label is for a super-category, the super-category including the label; determining that the super-category includes a second label associated with a second bounding box; and identifying, within the a second rectangular region, a second set of pixels representing a second object, wherein the selection area also surrounds the second set of pixels.
</claims>
</document>
