<document>

<filing_date>
2019-09-19
</filing_date>

<publication_date>
2020-04-09
</publication_date>

<priority_date>
2018-10-09
</priority_date>

<ipc_classes>
G06K9/62,G06T3/00,G06T5/00,G06T5/50,G06T7/73
</ipc_classes>

<assignee>
NAVER CORPORATION
</assignee>

<inventors>
REVAUD, JÉRÔME
SAMPAIO DE REZENDE, RAFAEL
</inventors>

<docdb_family_id>
65138788
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR DETECTING A POINT OF INTEREST CHANGE USING A CONVOLUTIONAL NEURAL NETWORK
</title>

<abstract>
A method for detecting a point of interest (POI) change in a pair of inputted POI images. A first processor of the method: generates triplets of training POI images using a base of training POI images and trains a convolutional neural network (CNN) of three-stream Siamese type based on the triplets of training POI images. A second processor of the method: computes, for each image of the pair of inputted POI images, a descriptor of that image using a stream of the CNN of three-stream Siamese type, computes a similarity score based on the descriptors of the images of the pair of inputted POI images using a similarity score function, and selectively detects the POI change based on the similarity score. A third processor of the method generates the base of training POI images to include an initial set of POI images and a set of synthetic POI images.
</abstract>

<claims>
1. A method for detecting a point of interest (POI) change in a pair of inputted POI images, the method comprising: by a first processor, training a convolutional neural network (CNN) of three-stream Siamese type based on triplets of training POI images; by a second processor, computing, for each image of the pair of inputted POI images, a descriptor of that image using a stream of the CNN of three-stream Siamese type; by the second processor, computing a similarity score based on the descriptors of the images of the pair of inputted POI images using a similarity score function; and by the second processor, selectively detecting the POI change based on the similarity score.
2. The method of claim 1 wherein selectively detecting the POI change includes, by the second processor, detecting the POI change when the similarity score is greater than a threshold value.
3. The method of claim 2 wherein selectively detecting the POI change includes, by the second processor, not detecting the POI change when the similarity score is less than the threshold value.
4. The method of claim 1 wherein the images of a pair of inputted POI images are captured at the same location at two different times.
5. The method of claim 1 wherein the training a CNN of three-stream Siamese type based on triplets of training POI images further comprises: by a third processor, generating a base of training POI images; by the first processor, generating a plurality of triplets of training POI images using the base of training POI images, each triplet comprising a first training POI image, a second training POI image that is related to the first training POI image, and a third POI training image that is unrelated to the first and second training POI images; by the first processor, determining whether training POI images are related or unrelated based on labels associated with the training POI images, respectively; and by the first processor, training a CNN of three-stream Siamese type based on the triplets of training POI images.
6. The method of claim 5 wherein the labels each include a 6-degrees-of-freedom pose of the associated training POI image.
7. The method of claim 6 wherein determining whether the training POI images are related or unrelated includes: by the first processor, determining that two training POI images are related when the two training POI images present a geometric overlap greater than a third threshold value; and by the first processor, determining that the two training POI images are unrelated when the geometric overlap is less than a second threshold value.
8. The method of claim 7 further comprising, by the first processor, computing the geometric overlap between the two training POI images based on the intersection-over-union between sets of corridor outlines respectively visible in each of the two POI images.
9. The method of claim 5 wherein at least one triplet includes a synthetic POI image generated by replacing a first signage region of a first training image with a second signage region from another training POI image.
10. The method of claim 5 wherein the generating a base of training POI images further comprises: by the third processor, obtaining an initial set of POI images having associated labels, respectively; by the third processor, for each POI image in a subset of the initial set, identifying a signage region in that POI image, the signage region including signage located on a POI depicted by the POI image; by the third processor, generating a synthetic POI image corresponding to a first POI image of the subset by replacing the signage region of the first POI image with the signage region of a second POI image; by the third processor, associating to the synthetic POI image the label of the second POI image; and storing, as the base of training POI images, a final set of POI images comprising the initial set of POI images and the synthetic POI image.
11. The method of claim 10 further comprising: by the third processor, generating a second synthetic POI image corresponding to a third POI image of the subset by replacing the signage region of the third POI image with the signage region of a fourth POI image; and by the third processor, associating to the synthetic POI image the label of the fourth POI image, wherein the storing further includes storing the second synthetic POI image in the final set.
12. The method of claim 11 wherein at least 5 percent of a total number of POI images in the final set are synthetic POI images generated with signage regions from other POI images.
13. The method of claim 11 wherein at least 25 percent of a total number of POI images in the final set are synthetic POI images generated with signage regions from other POI images.
14. A method according to claim 10 further comprising: obtaining a collection of cropped signage images, wherein generating the synthetic POI image includes replacing the signage region of the first POI image with the cropped signage image of a chosen one of the cropped signage images from the collection of cropped signage images.
15. The method of claim 14 further comprising randomly choosing the chosen one of the cropped signage images from the collection of cropped signage images.
16. The method of claim 15 further comprising performing affine warping of the chosen one of the copped signage images for adaptation to size and shape of the signage region of the first POI image.
17. The method of claim 16 further comprising performing Poisson blending.
18. The method of claim 10 wherein the signage includes at least one of (a) a name located on the POI depicted by the POI image and (b) a logo located on the POI depicted by the POI image.
19. The method of claim 18 wherein identifying the signage region in each of the POI image includes identifying the signage region in each of the POI images using at least one of optical character recognition and logo detection.
20. The method of claim 10 wherein the labels associated with the POI images each include a label identifying the POI depicted by that one of the POI images.
21. The method of claim 10 wherein the labels associated with the POI images each include a label defining at least one of a position and an orientation of that one of the POI images.
22. The method of claim 10 wherein the labels associated with the POI images each include a label defining a 6-degrees-of-freedom pose of that one of the POI images.
23. The method of claim 10 further comprising generating the initial set of POI images by acquiring geo-localized images of POIs using an image acquisition device.
24. The method of claim 10 wherein the subset includes all of the initial set.
25. A method for generating a base of training images for training a convolutional neural network (CNN) for detecting a point of interest (POI) change in a pair of inputted POI images, the method comprising: by a processor, obtaining an initial set of POI images having associated labels, respectively; by the processor, for each POI image in a subset of the initial set, identifying a signage region in that POI image, the signage region including signage located on a POI depicted by the POI image; by the processor, generating a synthetic POI image corresponding to a first POI image of the subset by replacing the signage region of the first POI image with the signage region of a second POI image; by the processor, associating to the synthetic POI image the label of the second POI image; and storing, as the base of training images, a final set of POI images comprising the initial set of POI images and the synthetic POI image.
26. A method for training a convolutional neural network (CNN) for detecting a point of interest (POI) change in a pair of inputted POI images, the method comprising: by a first processor, generating a base of training POI images; by a second processor, generating a plurality of triplets of training POI images, each triplet comprising a first POI image, a second POI image that is related to the first POI image, and a third POI image that is unrelated to the first and second POI images; by the second processor, determining whether POI images are related or unrelated based on labels associated with the POI images, respectively; and by the second processor, training a CNN of three-stream Siamese type based on the triplets of training POI images.
</claims>
</document>
