<document>

<filing_date>
2019-11-11
</filing_date>

<publication_date>
2020-09-15
</publication_date>

<priority_date>
2017-07-03
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06K9/62,G10L21/02,G10L21/0216,G10L21/0232,G10L21/0272,G10L25/18,G10L25/30,G10L25/57,G10L25/78
</ipc_classes>

<assignee>
HEBREW UNIVERSITY OF JERUSALEM
</assignee>

<inventors>
EPHRAT, ARIEL
GABBAY, AVIV
HALPERIN, TAVI
PELEG, SHMUEL
SHAMIR, ASAPH
</inventors>

<docdb_family_id>
63165423
</docdb_family_id>

<title>
Method and system for enhancing a speech signal of a human speaker in a video using visual information
</title>

<abstract>
A method and system for enhancing a speech signal is provided herein. The method may include the following steps: obtaining an original video, wherein the original video includes a sequence of original input images showing a face of at least one human speaker, and an original soundtrack synchronized with said sequence of images; and processing, using a computer processor, the original video, to yield an enhanced speech signal of said at least one human speaker, by detecting sounds that are acoustically unrelated to the speech of the at least one human speaker, based on visual data derived from the sequence of original input images.
</abstract>

<claims>
1. A method of enhancing a speech signal of a target human speaker, the method comprising: obtaining a video, wherein said video comprises a sequence of images showing a face or parts of a face of the target human speaker, and an original soundtrack corresponding with said video; representing said original soundtrack by a discrete time-frequency (DTF) audio transform; generating a time-frequency filter, having same dimensions as said DTF audio transform, by analyzing said video; obtaining a filtered DTF audio transform by applying said time-frequency filter to said DTF audio transform; and generating an enhanced speech signal based on said filtered DTF audio transform, wherein said enhanced speech signal exhibits a removal, from the original soundtrack, of sounds that are unrelated to the speech of said target human speaker.
2. The method according to claim 1, wherein said DTF audio transform is a Short-Term Fourier Transform (STFT) or a spectrogram.
3. The method according to claim 1, wherein said generating of the 2D time frequency filter is carried out, at least in part, using a neural network.
4. The method according to claim 3, wherein the neural network is trained on a set of videos having respective clean speech signals.
5. The method according to claim 1, wherein said 2D time-frequency filter is generated using an articulatory-to-acoustic mapping having as an input said sequence of original input images.
6. The method according to claim 1, wherein said enhanced speech signal exhibits less noise compared with the original soundtrack.
7. The method according to claim 1, wherein said enhanced speech signal exhibits a better speaker separation of said target human speaker from another speaker included in the original soundtrack, compared with the original soundtrack.
8. The method according to claim 1, wherein said enhanced speech signal is suitable for voice enhancement in video conference systems.
9. The method according to claim 1, wherein said enhanced speech signal is suitable for voice enhancement in hearing aid devices configured to access a video of a camera viewing the mouth of the speaking person.
10. The method according to claim 1, wherein said enhanced speech signal is suitable for voice enhancement in cellular phones configured to access a video of a camera viewing the mouth of the speaking person.
11. A system for enhancing a speech signal of a target human speaker, the system comprising: a computer memory configured to obtain a video, wherein said video comprises a sequence of images showing a face or parts of a face of the target human speaker, and an original soundtrack corresponding with said video; and a computer processor configured to: represent said original soundtrack by a discrete time-frequency (DTF) audio transform; generate a time-frequency filter, having same dimensions as said DTF audio transform, by analyzing said video; obtain a filtered DTF audio transform by applying said time-frequency filter to said DTF audio transform; and generate an enhanced speech signal based on said filtered DTF audio transform, wherein said enhanced speech signal exhibits a removal, from the original soundtrack, of sounds that are unrelated to the speech of said target human speaker.
12. The system according to claim 11, wherein said DTF audio transform is a Short-Term Fourier Transform (STFT) or a spectrogram.
13. The system according to claim 11 wherein said generating of the 2D time frequency filter is carried out, at least in part, using a neural network.
14. The system according to claim 13, wherein the neural network is trained on a set of videos having respective clean speech signals.
15. The system according to claim 11, wherein said 2D time-frequency filter is generated using an articulatory-to-acoustic mapping having as an input said sequence of original input images.
16. The system according to claim 11, wherein said enhanced speech signal exhibits less noise compared with the original soundtrack.
17. A non-transitory computer readable medium for enhancing a speech signal of a target human speaker, the non-transitory computer readable medium comprising a set of instructions that when executed cause at least one computer processor to: obtain a video, wherein said video comprises a sequence of images showing a face or parts of a face of the target human speaker, and an original soundtrack corresponding with said video; represent said original soundtrack by a discrete time-frequency (DTF) audio transform; generate a time-frequency filter, having same dimensions as said DTF audio transform, by analyzing said video; obtain a filtered DTF audio transform by applying said time-frequency filter to said DTF audio transform; and generate an enhanced speech signal based on said filtered DTF audio transform, wherein said enhanced speech signal exhibits a removal, from the original soundtrack, of sounds that are unrelated to the speech of said target human speaker.
18. The non-transitory computer readable medium according to claim 17, wherein said DTF audio transform is a Short-Term Fourier Transform (STFT) or a spectrogram.
19. The non-transitory computer readable medium according to claim 17, wherein said generating of the 2D time frequency filter is carried out, at least in part, using a neural network.
20. The non-transitory computer readable medium according to claim 17, wherein said 2D time-frequency filter is generated using an articulatory-to-acoustic mapping having as an input said sequence of original input images.
</claims>
</document>
