<document>

<filing_date>
2019-10-22
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2018-11-15
</priority_date>

<ipc_classes>
A61B5/00,G06N20/00,G10L15/00,G10L15/26,G10L25/66
</ipc_classes>

<assignee>
THERAPY BOX
</assignee>

<inventors>
BRIGHT, REBECCA LOUISE
GADGIL, SWAPNIL RAVINDRA
</inventors>

<docdb_family_id>
64740069
</docdb_family_id>

<title>
LANGUAGE DISORDER DIAGNOSIS/SCREENING
</title>

<abstract>
Language disorder diagnostic/screening methods, tools and software are provided. Audio data including speech of a subject is received. The audio data is transcribed to provide text data. Speech and language features are extracted from the text data and from the audio data. The extracted features are evaluated using a classification system to diagnose/screen whether the subject has a language disorder. The classification system includes at least one machine learning classifier. A diagnosis/screening is output.
</abstract>

<claims>
1. A language disorder diagnostic/screening method, the method comprising: receiving audio data including speech of a subject; transcribing, via at least one processor, the audio data to provide text data; extracting, via at least one processor, speech and language features from the text data and from the audio data; evaluating the extracted features using a classification system to diagnose/screen whether the subject has a language disorder, wherein the classification system includes at least one machine learning classifier; and outputting the diagnosis/screening.
2. The method of claim 1, wherein the language disorder is Developmental Language Disorder.
3. The method of claim 1, wherein the classification system includes a plurality of classifiers, the method comprising combining, via at least one processor, classification outputs from each of the plurality of classifiers.
4. The method of claim 3, wherein classification outputs from each of the plurality of classifiers is combined using a different weighting.
5. The method of claim 1, wherein the classification system includes a random forest classifier.
6. The method of claim 1, wherein the classification system includes a convolution neural network.
7. The method of claim 1, wherein the classification system includes a linear regression classifier.
8. The method of claim 1, wherein the classification system includes at least two of a random forest classifier, a linear regression classifier and a convolutional neural network.
9. The method of claim 1, comprising transforming, via at least one processor, the audio data into a spectrogram and evaluating the extracted features and the spectrogram images using the classification system to diagnose/screen whether the subject has a language disorder.
10. The method of claim 1, comprising pre-processing of the audio data prior to extracting speech features, wherein pre-processing comprises at least one of denoising and speaker separation.
11. The method of claim 1, wherein the extracted features includes at least one of audio features, acoustic features and mapping features derived from the text data.
12. The method of claim 11, wherein audio features include features related to time of speech by subject in the audio data and/or time of pauses by the subject in the audio data, wherein the acoustic features include loudness, pitch and/or intonation and wherein the mapping features include features related to variety of language in the text data, sophistication of language in the text data and/or grammar related features derived from the text data.
13. The method of claim 11, wherein the audio features includes at least one of number of pauses in the audio data, number of pauses per minute in the audio data, maximum length of utterances in the audio data, average length of utterances in the audio data, total length of time of speech of the subject in the audio data, maximum length of a pause in the audio data, ratio of maximum length of a pause and total length of time of speech of subject in the audio data, average length of pauses in the audio data, ratio of average length of pauses and total speech length, number of pauses having a length greater than five seconds in the audio data, number of pauses having a length greater than ten seconds in the audio data, the number of pauses per minute greater than ten seconds.
14. The method of claim 11, wherein the acoustic features are extracted from a spectrogram of the audio data.
15. The method of claim 11, wherein the acoustic features include at least one of loudness, pitch and intonation of the speech of the subject.
16. The method of claim 11, wherein the mapping features include at least one of synonyms to story keywords, a count of the number of unique synonyms achieved for each word divided by the total number of words, a count of the number of unique synonyms achieved for each word, a ratio representing how many plural words were used in the sentence, number of story keywords that were detected, a ratio representing how many pronouns were used per sentence, a ratio representing how many present progressive phrases were used per sentence, a measure of how cohesive the sentence is based on subjective and dominant clauses, a ratio that indicates how many words are incorrectly spelled in the text data, a count of the number of unique words that appeared in the list, a ratio that indicates how many different unique words were used per sentence, the ratio of the words: and/or in the document, a ratio that indicates how many low frequency words were used in the sentence, a count of the number of subordinate clauses that were used in the sentence, a ratio that indicates how many subordinate clauses were used in the sentence, a total number of words in the text data and an average number of words per utterance in the text data.
17. A language disorder diagnosis/screening tool, comprising: at least one processor configured to receive audio data including speech of a subject; at least one processor configured to transcribe the audio data to provide text data; at least one processor configured to extract speech features from the text data and from the audio data; a classification system configured to evaluate the extracted features to diagnose/screen whether the subject has a language disorder, wherein the classification system includes at least one machine learning classifier; and at least one processor configured to output the diagnosis/screening.
18. The language disorder diagnosis/screening tool of claim 17, wherein at least one of: the audio data is recorded on a user device; the output of the diagnosis/screening is to a user device; and the classification system is at a server remote from a user device or the classification system is at the user device.
19. The language disorder diagnosis/screening tool of claim 18, wherein the language disorder is Developmental Language Disorder DLD.
20. At least one software application configured to be run by at least processor to cause: transcribing received audio data to provide text data; extracting speech and language features from the text data and from the audio data; evaluating the extracted features using a classification system to diagnose/screen whether the subject has a language disorder, wherein the classification system includes at least one machine learning classifier; and outputting the diagnosis/screening.
</claims>
</document>
