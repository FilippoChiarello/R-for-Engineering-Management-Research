<document>

<filing_date>
2019-10-11
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2019-05-02
</priority_date>

<ipc_classes>
G06N20/10,G06N5/04
</ipc_classes>

<assignee>
KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS
</assignee>

<inventors>
Abudalfa, Shadi
Ahmed, Moataz
</inventors>

<docdb_family_id>
73016244
</docdb_family_id>

<title>
OPEN DOMAIN TARGETED SENTIMENT CLASSIFICATION USING SEMISUPERVISED DYNAMIC GENERATION OF FEATURE ATTRIBUTES
</title>

<abstract>
Methods for classification of microblogs using semi-supervised open domain targeted sentiment classification. A hidden Markov model support vector machine (SVM HMM) is trained with a training dataset combined with discrete features. A portion of the training dataset is clustered by k-means clustering to generate cluster IDs which are normalized and combined with the discrete features. After formatting, the combined dataset is applied to the SVM HMM and the C parameter, which is optimized by calculating a zero-one error at each iteration. The open domain targeted sentiment classification methods uses less labelled data than previous sentiment analysis techniques, thus decreasing processing costs. Additionally, a supervised learning model for improving the accuracy of open domain targeted sentiment classification is presented using an SVM HMM.
</abstract>

<claims>
1. A semi-supervised learning method for dynamically generating feature attributes in open domain targeted sentiment classification of a dataset of microblogs, comprising: training, with a computing system having circuitry configured for modelling and processing, a hidden Markov model support vector machine (SVM HMM), wherein the circuitry is configured to: dynamically generate feature attributes by combining pre-trained word embeddings from a plurality of different sources to form a first training dataset; normalizing the first training dataset to generate a normalized training dataset; concatenating, with a summer, discrete features with the normalized training set to generate a second training dataset; formatting the second training dataset; initializing a C parameter; applying the second training dataset and the C parameter to the SVM HMM; training the SVM HMM to classify the second training dataset set by word frequency and sentiment; generating a development dataset by selecting a subset of the second dataset; classifying the development dataset with the SVM HMM; calculating a first zero/one error of the classified development dataset; comparing the first zero/one error to an initial zero/one error value to determine whether the first zero/one error is less than the threshold; if the first zero/one error equals the initial zero/one error value, then stop training the SVM HMM; if the first zero/one error is less than the initial zero/one error value, increasing the C parameter; reclassifying the development dataset; calculating a second zero/one error using the reclassified development dataset; comparing the second zero/one error to the first zero/one error value to determine whether the second zero/one error is less than the first zero/one error; if the second zero/one error equals the first zero/one error value, stop training the SVM HMM; if the second zero/one error is less than the first zero/one error value, repeating the steps of increasing the value of the C parameter, reclassifying the development set, and calculating the zero/one error until a current zero/one error equals a previous zero/one error, then stop training the SVM HMM; identifying, by the computing system, sentiment polarities within a dataset of micro-blogs, wherein the computing system includes circuitry configured to: extract word embedding from the dataset of micro-blogs; normalize the word embedded dataset of micro-blogs; format the normalized word embedded dataset of micro-blogs to form a formatted dataset; classify the formatted dataset by applying the formatted dataset to the trained SVM HMM; and outputting a sentiment analysis of the dataset of micro-blogs.
2. The semi-supervised learning method of claim 1, further comprising: testing the trained SVM HMM by the steps of: classifying a dataset of testing data by applying word embeddings extracted from the dataset of testing data; normalizing the word embeddings; concatenating discrete features with the word embedded testing data formatting the normalized word embedded dataset of microblogs to form a formatted testing dataset; classifying the formatted testing dataset by applying the formatted dataset to the trained SVM HMM; and calculating metrics of the classified testing dataset.
3. The semi-supervised learning method of claim 2, wherein calculating metrics further comprises calculating, by the computer system, at least one of a named entity recognition (NER) evaluation measurement and a sentiment analysis (SA) evaluation measurement.
4. The semi-supervised learning method of claim 3, wherein the evaluation measures for NER comprise at least one of precision, recall and F1 measures and the evaluation measures for SA comprise at least one of precision, recall and F1 measures.
5. The semi-supervised learning method of claim 1, further comprising selecting a subset of the training dataset, clustering the subset by k-means clustering, determining the cluster IDs for the training dataset, normalizing the cluster IDs and concatenating the normalized cluster IDs with the second dataset.
6. The semi-supervised learning method of claim 1, the discrete features including at least one of: surface features; linguistic features, clustering features including cluster length; and sentiment lexicon features.
7. The semi-supervised learning method of claim 1, wherein extracting word embeddings from a dataset of micro-blogs further comprises converting each microblog to a numeric vector.
8. The semi-supervised learning method of claim 7, wherein normalizing the dataset of micro-blogs further comprises calculating the norm of each vector so that all numeric values of each vector fall in the range between âˆ’1 and 1 based on the following equation:
9. The semi-supervised learning method of claim 1, wherein formatting a dataset further comprises fitting the format of each normalized vector to represent collapsed labels selected from the group comprising b-negative labels, b-neutral labels, b-positive labels, i-negative labels, i-neutral labels, i-positive labels and o labels.
10. The semi-supervised learning method of claim 1, further comprising selecting the subset of the second dataset by selecting a fold of the second dataset.
11. The semi-supervised learning method of claim 9, further comprising calculating the zero-one error by determining a percentage of the classified development set which has at least one misclassified label.
12. The semi-supervised learning method of claim 1, further comprising initializing the C parameter to 1.
13. The semi-supervised learning method of claim 1, further comprising selecting the increase in the value of the C parameter from a range of 1 to 550 with a step increase of 10.
14. The semi-supervised learning method of claim 1, wherein outputting a sentiment analysis of the dataset of microblogs comprises determining a list of named entities in the dataset of microblogs; and listing each named entity in the dataset of microblogs with a polarity of a sentiment associated with the named entity, wherein the polarity is positive, negative or neutral.
15. A method for determining sentiment in a dataset of micro-blogs, comprising: word embedding, with a computing system having circuitry configured for modelling and processing, the dataset of micro-blogs; normalizing the word embedded dataset of micro-blogs; formatting the normalized word embedded dataset of micro-blogs to generate a formatted dataset; classifying the formatted dataset by applying the applying the formatted dataset to a trained SVM HMM; and outputting a sentiment analysis of the dataset of micro-blogs.
16. The semi-supervised learning method of claim 15, wherein outputting a sentiment analysis of the dataset of microblogs comprises determining a list of named entities in the dataset of microblogs; and listing each named entity in the dataset of microblogs with a polarity of a sentiment associated with the named entity, wherein the polarity is positive, negative or neutral.
17. A non-transitory computer readable medium having instructions stored therein that, when executed by one or more processors, causes the one or more processors to perform a semi-supervised learning method for generating feature attributes in open domain targeted sentiment classification of a dataset of microblogs, comprising: training, with a computing system having circuitry configured for modelling and processing, a hidden Markov model support vector machine (SVM HMM) by the steps of: dynamically generating feature attributes by combining pre-trained word embeddings from a plurality of different sources to form a first training dataset; normalizing the first training dataset to generate a normalized training dataset; concatenating, with a summer, discrete features with the normalized training set to form a second training dataset; formatting the second training dataset; initializing a C parameter; applying the second training dataset and the C parameter to a SVM HMM; training the SVM HMM to classify the second training dataset set by word frequency and sentiment; generating a development dataset by selecting a subset of the second dataset; classifying the development dataset with the SVM HMM; calculating a first zero/one error of the classified development dataset; comparing the first zero/one error to an initial zero/one error value to determine whether the first zero/one error is less than the threshold; if the first zero/one error equals the initial zero/one error value, the stop training the SVM HMM; if the first zero/one error is less than the initial zero/one error value, increasing the C parameter; reclassifying the development dataset; calculating a second zero/one error using the reclassified development dataset; comparing the second zero/one error to the first zero/one error value to determine whether the second zero/one error is less than the first zero/one error; if the second zero/one error equals the first zero/one error value, stop training the SVM HMM; if the second zero/one error is less than the first zero/one error value, repeating the steps of increasing the value of the C parameter, reclassifying the development set, and calculating the zero/one error until a current zero/one error equals a previous zero/one error, then stop training the SVM HMM; identifying, by the computing system, sentiment polarities within a dataset of micro-blogs, by word embeddings extracted from the dataset of micro-blogs; normalizing the word embedded dataset of micro-blogs; formatting the normalized word embedded dataset of micro-blogs to form a formatted dataset; classifying the formatted dataset by applying the formatted dataset to the trained SVM HMM; and outputting a sentiment analysis of the dataset of micro-blogs.
18. The non-transitory computer readable medium semi-supervised learning method of claim 17, further comprising: testing the trained SVM HMM by the steps of: classifying a dataset of testing data by word embeddings extracted from the dataset of testing data; normalizing the word embedded testing data; concatenating discrete features with the word embedded testing data formatting the normalized word embedded dataset of microblogs to form a formatted testing dataset; classifying the formatted testing dataset by applying the formatted dataset to the trained SVM HMM; and calculating metrics of the classified testing dataset.
19. The non-transitory computer readable medium semi-supervised learning method of claim 18, wherein: calculating metrics by calculating, by the computer system, at least one of an evaluation measure for named entity recognition (NER) and and evaluation measure for sentiment analysis (SA), wherein each of the evaluation measures comprise at least one of precision, recall and F1 scores.
20. The non-transitory computer readable medium semi-supervised learning method of claim 18, wherein normalizing a dataset of micro-blogs further comprises calculating the norm of each vector so that all numeric values of each vector fall in the range between âˆ’1 and 1 based on the following equation:
</claims>
</document>
