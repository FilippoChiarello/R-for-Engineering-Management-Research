<document>

<filing_date>
2017-12-15
</filing_date>

<publication_date>
2020-08-13
</publication_date>

<priority_date>
2017-11-16
</priority_date>

<ipc_classes>
G06F40/30,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
PARK, JAE HYUN
CHANG, TAE KWON
CHOI, IN KWON
</inventors>

<docdb_family_id>
66539586
</docdb_family_id>

<title>
APPARATUS RELATED TO METRIC-LEARNING-BASED DATA CLASSIFICATION AND METHOD THEREOF
</title>

<abstract>
The present invention provides artificial intelligence technology which has machine-learning-based information understanding capability, including metric learning providing improved classification performance, classification of an object considering a semantic relationship, understanding of the meaning of a scene based on the metric learning and the classification, and the like. An electronic device according to one embodiment of the present invention comprises a memory in which at least one instruction is stored, and a processor for executing the stored instruction. Here, the processor extracts feature data from training data of a first class, obtains a feature point by mapping the extracted feature data to an embedding space, and makes an artificial neural network learn in a direction for reducing a distance between the obtained feature point and an anchor point.
</abstract>

<claims>
1. An electronic apparatus comprising: a memory configured to store at least one instruction; and a processor configured to execute the stored instruction, wherein the processor further configured to: extract feature data from training data of a first class, obtain a feature point by mapping the extracted feature data to an embedding space, and train an artificial neural network in a direction for reducing a distance between the obtained feature point and an anchor point, and wherein the anchor point is the feature data extracted from representative data of the first class mapped to the embedding space.
2. The electronic apparatus as claimed in claim 1, wherein the training the artificial neural network comprises training the artificial neural network by using a loss function which defines that the closer the feature point of training data of the first class to the anchor point, the less the loss, and the closer the feature point of training data of a second class, different from the first class, to the anchor point, the greater the loss.
3. The electronic apparatus as claimed in claim 1, wherein the training the artificial neural network comprises training a convolutional neural network (CNN) layer for extracting the feature data of training data of the first class, and a metric learning layer for obtaining a distance between the feature point obtained by receiving data output from the CNN layer and the anchor point collectively.
4. The electronic apparatus as claimed in claim 1, wherein the training the artificial neural network comprises separating, from the CNN layer, only the metric learning layer for obtaining a distance between the feature point obtained by receiving data output from the CNN layer for extracting the feature data of training data of the first class and the anchor point and training the separated metric learning layer.
5. The electronic apparatus as claimed in claim 1, wherein the artificial neural network comprises a metric learning layer which outputs cluster feature data formed on the embedding space, and wherein the training the artificial neural network comprises training an object classification layer composed of a single layer that receives data output from the metric learning layer and outputs a confidence level by each class.
6. The electronic apparatus as claimed in claim 1, wherein the training the artificial neural network comprises training the artificial neural network in a direction that the feature point of the training data of the first class is closer to the anchor point of the first class, and at the same time the feature point of the training data of the second class is closer to the anchor point of the second class on the embedding space, and wherein a position of the anchor point of the first class and a position of the anchor point of the second class are determined by reflecting semantic relationship information between the first class and the second class.
7. The electronic apparatus as claimed in claim 6, wherein the semantic relationship information comprises a distance in a semantic tree between a keyword of the first class and a keyword of the second class, and wherein the semantic tree reflects semantic hierarchical relationships between each keyword, and the distance in the semantic tree between the keyword of the first class and the keyword of the second class is set as the greater the number of nodes between a first node corresponding to the keyword of the first class and a second node corresponding to the keyword of the second class, the farther the distance gets.
8. The electronic apparatus as claimed in claim 6, wherein the training the artificial neural network comprises reflecting the semantic relationship information between the first class and the second class and updating a position on the embedding space of at least one of a first class cluster and a second class cluster, wherein the first class cluster is composed of the feature point of the first class and the anchor point of the first class, and wherein the second class cluster is composed of the feature point of the second class and the anchor point of the second class.
9. The electronic apparatus as claimed in claim 1, wherein the training the artificial neural network comprises updating the position of the anchor point on the embedding space by reflecting the feature point of the first class, and training the artificial neural network in a direction to reduce the distance between the feature point of the first class and the updated anchor point.
10. The electronic apparatus as claimed in claim 9, wherein the updating the position of the anchor point on the embedding space comprises not performing position update of the anchor point in an initial training composed of an iteration of first time from the training start point, but performing position update of the anchor point in an iteration after the initial training.
11. The electronic apparatus as claimed in claim 10, wherein the performing position update of the anchor point in the iteration after the initial training comprises performing position update of the anchor point once every two or more iterations of second time.
12. The electronic apparatus as claimed in claim 10, wherein the first time is set to a first value in response to a type of the training data being a first type, and is set to a second value when the type of the training data is a second type.
13. The electronic apparatus comprises: a memory configured to store at least one instruction; and a processor configured to execute the stored instruction, wherein the processor further configured to: obtain feature points on the embedding space of each of a plurality of objects extracted from an image by using an object recognition model which outputs data related to feature points on the embedding space, and understands a scene of the image by using a keyword of an anchor point closest to at least some of the feature points, wherein the anchor point is a representative image for each class mapped onto the embedding space, and wherein the embedding space is a feature space in which a distance between the anchor points is calculated by reflecting the semantic relationship between the anchor points.
14. The electronic apparatus as claimed in claim 13, wherein the understanding the scene of the image comprises selecting a lower level anchor point closest to each of the mapped feature points, selecting at least some upper node from among nodes of a semantic tree corresponding to each of the selected lower level anchor points, and understanding the scene of the image by using a keyword corresponding to the selected upper node.
15. The electronic apparatus as claimed in claim 13, wherein the understanding the scene of the image comprises selecting an upper level anchor point closest to at least some of the mapped feature points, and understanding the scene of the image by using a keyword corresponding to the selected the upper level anchor point.
16. The electronic apparatus as claimed in claim 13, wherein the processor is configured to select the object recognition model based on a type of the image.
17. The electronic apparatus as claimed in claim 13, wherein the processor is configured to select the object recognition model based on profile information of the electronic apparatus's user.
18. The electronic apparatus as claimed in claim 13, wherein the processor is configured to select the object recognition model based on an application service type.
19. The electronic apparatus as claimed in claim 13, wherein the processor is configured to output additional contents corresponding to the understood scene.
20. A method performed by the electronic apparatus comprising: obtaining feature points on the embedding space of each of a plurality of objects extracted from an image by using an object recognition model that outputs data related to feature points on an embedding space; and understanding a scene of the image using a keyword of an anchor point closest to at least some of the feature points from among the feature points, wherein the anchor point is that a representative image for each class is mapped on the embedding space, and wherein the embedding space is a feature space in which a distance between the anchor points is calculated by reflecting a semantic relationship between the anchor points.
</claims>
</document>
