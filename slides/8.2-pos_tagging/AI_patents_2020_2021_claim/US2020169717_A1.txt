<document>

<filing_date>
2018-11-27
</filing_date>

<publication_date>
2020-05-28
</publication_date>

<priority_date>
2018-11-27
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06T15/04,G06T17/00,G06T19/20,G06T7/70,G11B27/036,H04N13/117,H04N13/156
</ipc_classes>

<assignee>
AT&T INTELLECTUAL PROPERTY I (AMERICAN TELEPHONE AND TELEGRAPH COMPANY INTELLECTUAL PROPERTY I)
</assignee>

<inventors>
GIBBON, DAVID CRAWFORD
LIU ZHU
SHAHRARAY, BEHZAD
ZAVESKY, ERIC
XU, TAN
</inventors>

<docdb_family_id>
70771031
</docdb_family_id>

<title>
Volumetric video-based augmentation with user-generated content
</title>

<abstract>
A processing system having at least one processor may obtain a two-dimensional source video, select a volumetric video associated with at least one feature of the source video from a library of volumetric videos, identify a first object in the source video, and determine a location of the first object within a space of the volumetric video. The processing system may further obtain a three-dimensional object model of the first object, texture map the first object to the three-dimensional object model of the first object to generate an enhanced three-dimensional object model of the first object, and modify the volumetric video to include the enhanced three-dimensional object model of the first object in the location of the first object within the space of the volumetric video.
</abstract>

<claims>
1. A method comprising: obtaining, by a processing system including at least one processor, a source video, wherein the source video is a two-dimensional video; selecting, by the processing system, a volumetric video associated with at least one feature of the source video from a library of volumetric videos; identifying, by the processing system, a first object in the source video; determining, by the processing system, a location of the first object within a space of the volumetric video; obtaining, by the processing system, a three-dimensional object model of the first object; texture mapping, by the processing system, the first object to the three-dimensional object model of the first object to generate an enhanced three-dimensional object model of the first object; and modifying, by the processing system, the volumetric video to include the enhanced three-dimensional object model of the first object in the location of the first object within the space of the volumetric video.
2. The method of claim 1, further comprising: performing an alignment of the source video to the volumetric video, wherein the determining the location of the first object within the space of the volumetric video is in accordance with the alignment.
3. The method of claim 2, wherein the alignment comprises a spatial alignment, wherein the spatial alignment comprises: detecting key points in both the source video and the volumetric video; and calculating a plurality of vectors between the first object and the key points.
4. The method of claim 2, wherein the alignment further comprises a time alignment of the source video and the volumetric video.
5. The method of claim 1, wherein the obtaining the source video further comprises: obtaining the at least one feature of the source video, wherein the at least one feature comprises at least one of: location information; time information; an event tag; or a keyword.
6. The method of claim 5, wherein the selecting comprises: determining that the volumetric video matches the at least one feature of the source video.
7. The method of claim 5, wherein the selecting is in accordance with a ranked list of volumetric videos from the library of volumetric videos based upon a level of matching to the at least one feature of the source video.
8. The method of claim 1, further comprising: detecting a second object in the source video, wherein the at least one feature of the source video comprises the second object.
9. The method of claim 8, wherein the selecting the volumetric video associated with the at least one feature of the source video comprises: detecting the second object in the volumetric video.
10. The method of claim 1, further comprising: presenting, via an endpoint device, the volumetric video that is modified.
11. The method of claim 1, further comprising: generating an output video comprising a two dimensional traversal of the volumetric video that is modified.
12. The method of claim 11, wherein the output video is generated in accordance with a selection by a user of at least one viewing perspective within the space of the volumetric video.
13. The method of claim 11, further comprising: presenting, via an endpoint device, the output video.
14. The method of claim 13, wherein the source video is obtained from the endpoint device.
15. The method of claim 1, wherein the at least one feature is specified by a user associated with the source video.
16. The method of claim 1, wherein the obtaining the three-dimensional object model of the first object is in accordance with a catalog of two-dimensional objects and three-dimensional object models that are matched to the two-dimensional objects.
17. The method of claim 16, wherein the obtaining the three-dimensional object model comprises: matching the first object to one of the two-dimensional objects in the catalog; and obtaining, from the catalog, the three-dimensional object model that is matched to the one two-dimensional object.
18. The method of claim 17, wherein the matching is in accordance with a machine learning-based image detection model.
19. A non-transitory computer-readable medium storing instructions which, when executed by a processing system including at least one processor, cause the processing system to perform operations, the operations comprising: obtaining a source video, wherein the source video is a two-dimensional video; selecting a volumetric video associated with at least one feature of the source video from a library of volumetric videos; identifying a first object in the source video; determining a location of the first object within a space of the volumetric video; obtaining a three-dimensional object model of the first object; texture mapping the first object to the three-dimensional object model of the first object to generate an enhanced three-dimensional object model of the first object; and modifying the volumetric video to include the enhanced three-dimensional object model of the first object in the location of the first object within the space of the volumetric video.
20. A device comprising: a processing system including at least one processor; and a computer-readable medium storing instructions which, when executed by the processing system, cause the processing system to perform operations, the operations comprising: obtaining a source video, wherein the source video is a two-dimensional video; selecting a volumetric video associated with at least one feature of the source video from a library of volumetric videos; identifying a first object in the source video; determining a location of the first object within a space of the volumetric video; obtaining a three-dimensional object model of the first object; texture mapping the first object to the three-dimensional object model of the first object to generate an enhanced three-dimensional object model of the first object; and modifying the volumetric video to include the enhanced three-dimensional object model of the first object in the location of the first object within the space of the volumetric video.
</claims>
</document>
