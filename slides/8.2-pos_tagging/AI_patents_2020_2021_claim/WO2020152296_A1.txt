<document>

<filing_date>
2020-01-23
</filing_date>

<publication_date>
2020-07-30
</publication_date>

<priority_date>
2019-01-23
</priority_date>

<ipc_classes>
G06N3/04
</ipc_classes>

<assignee>
DEEPMIND TECHNOLOGIES
DUAN, SUNNY YUNCHEN
</assignee>

<inventors>
HIGGINS, IRINA
DUAN, SUNNY YUNCHEN
</inventors>

<docdb_family_id>
69192079
</docdb_family_id>

<title>
IDENTIFYING NEURAL NETWORKS THAT GENERATE DISENTANGLED REPRESENTATIONS
</title>

<abstract>
A method for automatically identifying a computer-implemented neural network which is able to generate a disentangled latent variable representation of an input data item. The method involves obtaining a pool of trained neural networks, encoding a set of evaluation data items using each of the trained neural networks to determine a respective set of latent representations for each of the trained neural networks, and determining a measure of similarity between the sets of latent representations in order to select a trained neural network with a disentangled latent variable representation.
</abstract>

<claims>
1. A method for automatically providing a computer-implemented neural network with a disentangled latent variable representation of an input data item, the method comprising:
obtaining a pool of trained neural networks, wherein each trained neural network is a computer-implemented neural network comprising at least an encoder neural network to encode an input data item as a latent representation of the data item; and
determining an unsupervised selection of one of the trained neural networks, comprising: obtaining an evaluation data set comprising a set of evaluation data items;
encoding the set of evaluation data items using each of the trained neural networks to determine a respective set of latent representations for each of the trained neural networks;
determining a measure of similarity between the sets of latent representations of the trained neural networks; and
selecting one of the trained neural networks using the measure of similarity to provide a computer-implemented neural network with a disentangled latent representation of an input data item.
2. A method as claimed in claim 1 comprising obtaining the pool of trained neural networks by training the neural networks in parallel on a distributed computing system, and wherein determining the measure of similarity between the sets of latent representations of the trained neural networks is performed between pairs or groups of the trained neural networks as a set of parallel tasks on the distributed computing system.
3. A method as claimed in claim 1 or 2 wherein the latent representation comprises a vector of latent values.
4. A method as claimed in claim 3 comprising determining a multivariate posterior distribution for the latent representation of the input data item and determining the latent representation from the multivariate posterior distribution.
5. A method as claimed in claim 3 or 4 wherein the measure of similarity is invariant to one or more of: i) permutation of an order of the latent values, ii) a sign of the latent values, and iii) whether the latent representation of one of the trained neural networks is a subset of the latent representation of another of the trained neural networks.
6. A method as claimed in any one of claims 1-5 wherein determining the measure of similarity between the sets of latent representations of the trained neural networks comprises, for each of the trained neural networks, making a pairwise comparison between the trained neural network and each of P other trained neural networks in the pool and determining a
disentanglement score for the trained neural network from the pairwise comparisons.
7. A method as claimed in claim 6 wherein selecting one of the trained neural networks comprises determining a ranking of the trained neural networks using the disentanglement score and selecting a highest ranking trained neural network.
8. A method as claimed in claim 6 or 7 wherein the latent representation comprises a vector of latent values, and wherein determining the disentanglement score for the pairwise comparison comprises comparing a first set of vectors of latent values produced by encoding the set of evaluation data items using a first of the compared trained neural networks and a second set of vectors of latent values produced by encoding the set of evaluation data items using second of the compared trained neural networks.
9. A method as claimed in claim 8 wherein each latent value is defined by a component of the vector of latent values, wherein comparing the first and second sets of vectors of latent values comprises determining a similarity matrix, wherein each entry in the similarity matrix represents a similarity between a set of first components of the first set of vectors and a set of second components of the second set of vectors; and wherein determining the disentanglement score comprises determining the disentanglement score from the similarity matrix.
10. A method as claimed in claim 9 comprising determining a similarity between the set of first components of the first set of vectors and the set of second components of the second set of vectors by determining a rank correlation between the set of first components and the set of second components.
11. A method as claimed in claim 9 comprising determining a row of values for the similarity matrix by regressing the set of first components of the first set of vectors on each of the components of the second set of vectors to determine a weight of each of the components of the second set of vectors for the row of values of the similarity matrix.
12. A method as claimed in claim 9, 10 or 11 wherein comparing the first and second sets of vectors of latent values further comprises taking the absolute value of each entry in the similarity matrix.
13. A method as claimed in any one of claims 9-12 wherein determining the disentanglement score from the similarity matrix comprises determining the disentanglement score from a largest entry in each row and/or column of the similarity matrix.
14. A method as claimed in any one of claims 1-13 wherein each trained neural network comprises a trained variational autoencoder neural network.
15. A method as claimed in any one of claims 1-14 wherein the latent representation of each trained neural network comprises a vector with the same number of latent values, and wherein each trained neural network has one or both of i) a different set of hyperparameter values, and ii) a different set of weight initialization values.
16. A method as claimed in any one of claims 1-15 wherein the data item comprises a still or moving image or an audio signal.
17. A method as claimed in any one of claims 1-16 further comprising using the provided computer-implemented neural network with the disentangled latent variable representation in i) a classification neural network system; ii) a reinforcement learning neural network system; or iii) a data storage and/or transmission system.
18. A system comprising one or more computers and one or more storage devices storing instructions that when executed by the one or more computers cause the one or more computers to perform the operations of the respective method of any one of claims 1-17.
19. One or more computer storage media storing instructions that when executed by one or more computers cause the one or more computers to implement the method of any one of claims 1-17 or the system of claim 18.
</claims>
</document>
