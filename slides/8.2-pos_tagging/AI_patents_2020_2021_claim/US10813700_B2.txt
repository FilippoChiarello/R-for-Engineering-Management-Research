<document>

<filing_date>
2019-01-02
</filing_date>

<publication_date>
2020-10-27
</publication_date>

<priority_date>
2016-04-27
</priority_date>

<ipc_classes>
A61B17/15,A61B34/10,A61F2/46,G02B27/01,G06T19/00,G06T19/20,G09B23/28
</ipc_classes>

<assignee>
ARTHROLOGY CONSULTING
</assignee>

<inventors>
AMANATULLAH, DEREK
</inventors>

<docdb_family_id>
67393009
</docdb_family_id>

<title>
Methods for augmenting a surgical field with virtual guidance and tracking and adapting to deviation from a surgical plan
</title>

<abstract>
One variation of a method includes: accessing a virtual patient model defining a target resected contour of a hard tissue of interest; after resection of the hard tissue of interest during a surgical operation, accessing an optical scan recorded by an optical sensor facing a surgical field occupied by a patient, detecting a set of features representing the patient in the optical scan, registering the virtual patient model to the hard tissue of interest in the surgical field based on the set of features, and detecting an actual resected contour of the hard tissue of interest in the optical scan; and calculating a spatial difference between the actual resected contour of the hard tissue of interest and the target resected contour of the hard tissue of interest represented in the virtual patient model registered to the hard tissue of interest in the surgical field.
</abstract>

<claims>
I claim:
1. A method for registering features of a patient in a surgical field comprising: accessing a virtual patient model representing a hard tissue of interest of the patient, the virtual patient model generated from a pre-operative scan of the hard tissue of interest of the patient; during a first period of time within a surgical operation and preceding incision of the patient proximal the hard tissue of interest: accessing a first sequence of optical scans recorded by an optical sensor facing the surgical field occupied by the patient; detecting a constellation of visible soft tissue features on the patient, proximal to the hard tissue of interest, and below a surgical site of the surgical operation; registering a three-dimensional field model of the constellation of visible soft tissue features within the virtual patient model, the three-dimensional field model comprising: a first set of spatial relationships between visible soft tissue features in the constellation of visible soft tissue features; and a set of motional relationships between visible soft tissue features relative to adjacent visible soft tissue features; and a soft tissue gravity model characterizing deformation of the constellation of visible soft tissue features based on orientation of the hard tissue of interest relative to gravity; and deriving a mechanical axis of the hard tissue of interest based on detected movement of the constellation of visible soft tissue features within the first sequence of optical scans and the three-dimensional field model of the constellation of visible soft tissue features; during a second period of time succeeding incision of the patient proximal the hard tissue of interest and prior to resection of the hard tissue of interest: accessing a second sequence of optical scans recorded by the optical sensor; detecting a first contour of the hard tissue of interest in the second sequence of optical scans; aligning the virtual patient model with the first contour of the hard tissue of interest based on the mechanical axis of the hard tissue of interest; registering virtual hard tissue features defined in the virtual patient model to the first contour of the hard tissue of interest; locating visible soft tissue features, in the constellation of visible soft tissue features, in the second sequence of optical scans; and deriving a second set of spatial relationships between the constellation of visible soft tissue features and virtual hard tissue features defined in the virtual patient model based on registration of the virtual patient model to the hard tissue of interest and the three-dimensional field model of the constellation of visible soft tissue features; during a third period of time concurrent with resection of the hard tissue of interest: accessing a third sequence of optical scans recorded by the optical sensor; locating the constellation of visible soft tissue features in each optical scan in the third sequence of optical scans; aligning the virtual patient model to the hard tissue of interest throughout the third period of time based on three-dimensional positions of visible soft tissue features detected in the third sequence of optical scans, the three-dimensional field model of the constellation of visible soft tissue features, and the second set of spatial relationships between the constellation of visible soft tissue features and virtual hard tissue features; registering the virtual patient model to the hard tissue of interest; and detecting a second contour of the hard tissue of interest in the third sequence of optical scans; and at a fourth time succeeding the third period of time, detecting a spatial difference between virtual hard tissue features, defined in the virtual patient model, and the second contour of the hard tissue of interest detected in the third sequence of optical scans.
2. The method of claim 1: further comprising, during the first period of time within the surgical operation: accessing an initial sequence of optical scans recorded by the optical sensor; detecting a head in the initial sequence of optical scans; detecting a foot in the initial sequence of optical scans; deriving an orientation of the patient relative to the optical sensor based on a location of the head and a location of the foot in the initial sequence of optical scans; predicting a region of the surgical field occupied by the hard tissue of interest based on the orientation of the patient; scanning the region in the surgical field depicted in the initial sequence of optical scans for a soft tissue proximal the hard tissue of interest; and coarsely registering the virtual patient model to the soft tissue proximal the hard tissue of interest; and wherein registering virtual hard tissue features defined in the virtual patient model to the first contour of the hard tissue of interest comprises refining coarse registration of the virtual patient model to the hard tissue of interest based on alignment of virtual hard tissue features defined in the virtual patient model and the first contour of the hard tissue of interest detected in the second sequence of optical scans.
3. The method of claim 2, further comprising, during a fourth period of time succeeding the first period of time and succeeding incision of the patient proximal the hard tissue of interest: accessing a fourth sequence of optical scans recorded by the optical sensor; detecting presence of a red surface in the third sequence of optical scans; interpreting the red surface as an incision wound on the patient; and confirming registration of the virtual patient model to the soft tissue proximal the hard tissue of interest in response to a location of the incision wound overlapping locations of virtual hard tissue features in the virtual patient model.
4. The method of claim 1: wherein registering virtual hard tissue features defined in the virtual patient model to the first contour of the hard tissue of interest comprises calculating a best-fit location of the virtual patient model, relative to the hard tissue of interest, that minimizes error between virtual hard tissue features defined in the virtual patient model and the first contour of the hard tissue of interest detected in the second sequence of optical scans; and further comprising displacing virtual hard tissue features defined in the virtual patient model into alignment with the first contour of the hard tissue of interest detected in the second sequence of optical scans.
5. The method of claim 1, further comprising: serving a prompt to a surgeon in the surgical field to manipulate a portion of the patient proximal the hard tissue of interest through a range of motion during the second period of time; and serving confirmation of registration of the virtual patient model to the hard tissue of interest to the surgeon.
6. The method of claim 1: wherein accessing the first sequence of optical scans comprises: accessing a first sequence of color images from a fixed stereo camera arranged over and facing an operating table within the surgical field; and transforming the first sequence of color images into a first set of three-dimensional color point clouds; further comprising combining the first set of three-dimensional color point clouds into a composite three-dimensional color point cloud depicting hard tissue and soft tissue of the patient; and wherein detecting the constellation of visible soft tissue features comprises selecting the constellation of visible soft tissue features from the composite three-dimensional color point cloud.
7. The method of claim 1: wherein accessing the virtual patient model comprises accessing the virtual patient model comprising a virtual unresected femur of the patient representing the hard tissue of interest; wherein detecting the first contour of the hard tissue of interest in the second sequence of optical scans comprises detecting an unresected contour of a femoral condyle of the patient, prior to resection, in the second sequence of optical scans; wherein registering virtual hard tissue features defined in the virtual patient model to the first contour of the hard tissue of interest comprises registering virtual unresected femoral condyle features defined in the virtual patient model to the unresected contour of the femoral condyle detected in the second sequence of optical scans; wherein detecting the second contour of the hard tissue of interest in the third sequence of optical scans comprises detecting a resected contour of the femoral condyle in the third sequence of optical scans; and wherein detecting the spatial difference comprises detecting the spatial difference between virtual unresected femoral condyle features defined in the virtual patient model and the resected contour of the femoral condyle detected in the third sequence of optical scans.
8. The method of claim 7, further comprising: calculating a magnitude of resection of the femoral condyle based on the spatial difference; calculating an orientation of resection of the femoral condyle based on the spatial difference; characterizing a surface profile of the second contour detected in the third sequence of optical scans, the second contour comprising a resected contour of the femoral condyle; and rendering the magnitude of resection, the orientation of resection, and the surface profile on a display present near the surgical field.
9. The method of claim 8, wherein rendering the magnitude of resection, the orientation of resection, and the surface profile on the display comprises, during the third period of time: detecting a position of an augmented reality headset, worn by a surgeon and comprising the display, proximal the surgical field; estimating a perspective of the surgeon viewing the surgical field based on the position of the augmented reality headset; generating an augmented reality frame comprising a projection of the virtual unresected femur of the patient from the perspective of the surgeon; inserting the magnitude of resection, the orientation of resection, and the surface profile into the augmented reality frame; and at the augmented reality headset, rendering the augmented reality frame.
10. The method of claim 7: wherein accessing the virtual patient model comprises accessing the virtual patient model further comprising a virtual unresected tibia of the patient; further comprising, during the second period of time: detecting a second hard tissue of interest of the patient, prior to resection, in the first sequence of optical scans, the second hard tissue of interest comprising an unresected contour of a tibial plateau of the patient; and registering the virtual unresected tibia defined in the virtual patient model to the second hard tissue of interest detected in the first sequence of optical scans; further comprising deriving a third set of spatial relationships between the constellation of visible soft tissue features and the virtual unresected tibia in the virtual patient model based on registration of the virtual unresected tibia to the second hard tissue of interest and the three-dimensional field representation of the constellation of visible skin features; further comprising, during the third period of time: detecting the constellation of visible soft tissue features in the third sequence of optical scans; registering the virtual unresected tibia in the virtual patient model to the second hard tissue of interest based on the third set of spatial relationships and the constellation of visible soft tissue features detected in the third sequence of optical scans; and detecting a resected contour of the tibial plateau in the third sequence of optical scans; and further comprising, at approximately the fourth time, detecting a second spatial difference between virtual unresected tibial plateau features defined in the virtual patient model and the resected contour of the tibial plateau detected in the third sequence of optical scans.
11. The method of claim 1, further comprising, during the first period of time: detecting a first orientation of the hard tissue of interest relative to gravity; and deforming the constellation of visible soft tissue features according to the soft tissue gravity model based on the first orientation of the hard tissue of interest relative to gravity.
12. The method of claim 1, further comprising: accessing a definition of a target resection of the hard tissue of interest of the patient; calculating an actual resection of the hard tissue of interest of the patient based on the second contour of the hard tissue of interest in the third sequence of optical scans; calculating a second spatial difference between the actual resection of the hard tissue of interest and the target resection of the hard tissue of interest; and during the third period of time, rendering the second spatial difference on a display present near the surgical field.
13. The method of claim 12, further comprising: serving a prompt to a surgeon present near the surgical field to provide a reason for the second spatial difference; labeling the second spatial difference as an intentional deviation from a surgical plan associated with the target resection of the hard tissue of interest based on the reason for the second spatial difference presented by the surgeon; and recording the spatial difference, the second spatial difference, and the reason provided by the surgeon in a database and in association with the surgical operation.
14. The method of claim 12, further comprising: accessing a definition of a target position of a surgical implant relative to the hard tissue of interest of the patient; during a fourth period of time succeeding the third period of time: accessing a fourth sequence of optical scans recorded by the optical sensor; detecting the constellation of visible soft tissue features in the fourth sequence of optical scans; registering the virtual patient model to the hard tissue of interest based on the second set of spatial relationships and the constellation of visible soft tissue features detected in the fourth sequence of optical scans; detecting the surgical implant in the fourth sequence of optical scans; calculating an actual position of the surgical implant relative to the virtual patient model registered to the hard tissue of interest based on the second set of spatial relationships and the constellation of visible soft tissue features detected in the fourth sequence of optical scans; calculating a third spatial difference between the actual position of the surgical implant and the target position of the surgical implant relative to the hard tissue of interest; and rendering the third spatial difference on the display.
15. A method for registering features of a patient in a surgical field comprising: accessing a virtual patient model representing a hard tissue of interest of the patient, the virtual patient model generated from a pre-operative scan of the hard tissue of interest; during a first period of time within a surgical operation and preceding incision of the patient proximal the hard tissue of interest: accessing a first sequence of optical scans recorded by an optical sensor facing the surgical field occupied by the patient; detecting a constellation of visible soft tissue features on the patient and proximal to the hard tissue of interest; and registering a three-dimensional field representation of the constellation of visible soft tissue features in the virtual patient model, comprising: a first set of spatial relationships between visible soft tissue features in the constellation of visible soft tissue features; and a set of motional relationships between visible soft tissue features relative to adjacent visible soft tissue features; and a soft tissue gravity model characterizing deformation of the constellation of visible soft tissue features based on orientation of the hard tissue of interest relative to gravity; during a second period of time succeeding incision of the patient proximal the hard tissue of interest and prior to resection of the hard tissue of interest: accessing a second sequence of optical scans recorded by the optical sensor; detecting a first contour of the hard tissue of interest in the second sequence of optical scans; and registering virtual hard tissue features defined in the virtual patient model to the first contour of the tissue of interest; detecting the constellation of visible soft tissue features, on the patient and proximal the tissue of interest, in the first sequence of optical scans; deriving a set of spatial relationships between the constellation of visible soft tissue features and virtual hard tissue features defined in the virtual patient model; accessing a third sequence of optical scans recorded by the optical sensor during a third period of time succeeding the second period of time; detecting a second contour of the hard tissue of interest in the third sequence of optical scans; detecting resection of the hard tissue of interest based on a difference between the second contour of the hard tissue of interest and the first contour of the hard tissue of interest; in response to detecting resection of the hard tissue of interest: locating the constellation of visible soft tissue features in the third sequence of optical scans; aligning the virtual patient model with the hard tissue of interest based on the set of spatial relationships and the constellation of visible soft tissue features detected in the third sequence of optical scans; and registering the virtual patient model to the hard tissue of interest based on the three-dimensional field representation of the constellation of visible soft tissue features registered in the virtual patient model; and at a fourth time, succeeding the third period of time, detecting a spatial difference between virtual hard tissue features defined in the virtual patient model and the second contour of the hard tissue of interest detected in the third sequence of optical scans.
16. The method of claim 15: wherein accessing the virtual patient model comprises accessing the virtual patient model comprising a generic representation of the hard tissue of interest; and wherein registering virtual tissue features defined in the virtual anatomical model to the first contour of the tissue of interest comprises: calculating a best-fit location of the virtual patient model, relative to the tissue of interest, that minimizes error between virtual tissue features defined in the virtual patient model and the first contour of the tissue of interest detected in the second sequence of optical scans; and morphing the generic representation of the hard tissue of interest into conformity with unique anatomy of the patient by displacing virtual tissue features defined in the virtual anatomical model into alignment with the first contour of the tissue of interest detected in the second sequence of optical scans.
</claims>
</document>
