<document>

<filing_date>
2019-09-26
</filing_date>

<publication_date>
2020-07-02
</publication_date>

<priority_date>
2018-12-28
</priority_date>

<ipc_classes>
G06N3/08,G10L13/04,G10L15/04,G10L15/16,G10L15/22,G10L15/24,G10L15/30,G10L25/90
</ipc_classes>

<assignee>
RINGCENTRAL
</assignee>

<inventors>
MIKHAILOV, ILYA VLADIMIROVISH
</inventors>

<docdb_family_id>
71123204
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR RECOGNIZING A SPEECH OF A SPEAKER
</title>

<abstract>
Systems, methods, and computer readable media comprising instructions executable by a processor, for recognizing speech within a received audio signal segment the audio signal to isolate the speech based on a speaker audio profile, determine from the audio signal a command, a first score reflecting confidence in determining the command, and a second score reflecting a potential error in determining the command, and cause the command to be executed if the first score is above a first threshold value and the second score is below a second threshold value.
</abstract>

<claims>
1. A method for recognizing speech within a received audio signal, the method comprising: segmenting the audio signal to isolate a speech based on a speaker audio profile; determining from the audio signal: a command, a first score reflecting confidence in determining the command, and a second score reflecting a potential error in determining the command; and causing the command to be executed if the first score is above a first threshold value and the second score is below a second threshold value.
2. The method of claim 1, wherein the segmentation of the audio signal is performed by a computer-based neural network model.
3. The method of claim 1, wherein the segmentation of the audio signal is based on one of an audio waveform, a cadence of the speech, a pitch of the speech, loudness of the speech, or vocabulary of the speech.
4. The method of claim 1, further comprising: receiving video data of the speaker producing the audio signal; and performing a segmentation of the audio signal based on a correlation of the audio signal and the video data.
5. The method of claim 1, further comprising: receiving vibration data of the speaker producing the audio signal; and performing a segmentation of the audio signal based on a correlation of the audio signal and the vibration data.
6. The method of claim 5, wherein the vibration data is recorded by a wearable device.
7. The method of claim 1, wherein the audio data is recorded by at least one microphone.
8. The method of claim 1, further comprising interacting with the speaker via a synthesized speech.
9. The method of claim 8, wherein the interacting includes prompting the speaker for a follow-up audio signal containing a command.
10. A system for recognizing a speech of a speaker comprising: at least one memory device storing instructions; and at least one processor configured to execute the instructions to perform operations comprising: receiving an audio signal; performing a segmentation of the audio signal to isolate the speech of the speaker based on a speaker audio profile; determining from the audio signal: a command, a first score reflecting confidence in determining the command, and a second score reflecting a potential error in determining the command; and causing the command to be executed if the first score is above a first threshold value and the second score is below a second threshold value.
11. The system of claim 10, wherein the operations further comprise: transmitting the audio signal to a remote server of a remote computing platform via a network; and storing the audio signal in a remote database associated with the remote computing platform.
12. The system of claim 11, wherein transmitting the audio signal is performed in a continuously operating mode.
13. The system of claim 10, wherein the memory device and the processor may be parts of a mobile computing device comprising one of a wearable electronic device, a smartphone, a tablet, a camera, a laptop or a gaming console.
14. The system of claim 10, wherein the operations further comprise generating a profile for the speaker at a remote computing platform, the profile comprising speaker related meta-data, audio signals associated with the speaker, and at least one computer-based model for performing the segmentation of the audio signal.
15. The system of claim 14, wherein the profile further comprises a speech recognition model.
16. The system of claim 10, wherein the operations further comprise interacting with the speaker via a synthesized speech.
17. A computing platform for recognizing speech comprising: a server for receiving audio data via a network; a database configured to store a profile for the speaker, the profile comprising speaker related meta-data, audio signals associated with the speaker, and at least one computer-based model for recognizing the speech of the speaker configured to: receive an audio signal; segment the audio signal to isolate a speech based on a speaker audio profile; determine from the audio signal: a command, a first score reflecting confidence in determining the command, and a second score reflecting a potential error in determining the command; and cause the command to be executed if the first score is above a first threshold value and the second score is below a second threshold value.
18. The computing platform of claim 17, configured to: receive a request from a computing device for a speaker whose speech requires recognition; upload the at least one computer-based model to the computing device for recognizing the speech of the speaker if the speaker has the speaker profile stored in the database of the computing system;
19. The computing platform of claim 17, configured to: receive a request from a mobile device for selecting a plurality of speakers whose speech requires recognition; select speakers that have the speaker profiles stored in the database of the computing system, resulting in selected speakers; upload a plurality of computer-based models corresponding to the selected speakers to a computing device for recognizing the speech of the selected speakers; and perform a segmentation of the audio signal to isolate at least one speech of at least one of the selected speakers resulting in at least one isolated speech.
20. The computer platform of claim 19 for facilitating an audio conference for a plurality of speakers, the speakers being participants of the audio conference, further comprising an interface for a participant to select at least one isolated speech of at least one speakers.
</claims>
</document>
