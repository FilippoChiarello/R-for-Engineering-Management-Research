<document>

<filing_date>
2019-09-23
</filing_date>

<publication_date>
2020-06-04
</publication_date>

<priority_date>
2011-05-13
</priority_date>

<ipc_classes>
G06F9/46,G06F9/50,G06F9/54,G06K9/00,G06K9/62,G06K9/68,G06N20/00,G06N5/04,G06Q10/10
</ipc_classes>

<assignee>
ORIONS DIGITAL SYSTEMS
</assignee>

<inventors>
LAHR NILS B.
</inventors>

<docdb_family_id>
51532872
</docdb_family_id>

<title>
GENERATING EVENT DEFINITIONS BASED ON SPATIAL AND RELATIONAL RELATIONSHIPS
</title>

<abstract>
Data from one or more sensors is input to a workflow and fragmented to produce HyperFragments. The HyperFragments of input data are processed by a plurality of Distributed Experts, who make decisions about what is included in the HyperFragments or add details relating to elements included therein, producing tagged HyperFragments, which are maintained as tuples in a Semantic Database. Algorithms are applied to process the HyperFragments to create an event definition corresponding to a specific activity. Based on related activity included in historical data and on ground truth data, the event definition is refined to produce a more accurate event definition. The resulting refined event definition can then be used with the current input data to more accurately detect when the specific activity is being carried out.
</abstract>

<claims>
1. A system for transforming a video signal into an organized data structure comprising: an image sensor; one or more memory storage devices; a first set of computer-readable instructions stored on the one or more memory storage devices that, when executed by a processor, cause the system to: receive the video signal from the image sensor; convert the video signal into a plurality of discrete video fragments; apply a tagging plug-in to a discrete video fragment of the plurality of discrete video fragments; associate, based at least in part on applying the tagging plug-in, one or more semantic tags with the discrete video fragment to generate a tagged discrete video fragment; apply one or more ontological models from a semantic database to the tagged discrete video fragment; determine, based at least in part on applying the one or more ontological models, whether to send the tagged discrete video fragment to a second set of computer-readable instructions or a third set of computer-readable instructions; and send, based on determining whether to send the tagged discrete video fragment to a second set of computer-readable instructions or a third set of computer-readable instructions, the tagged discrete video fragment to the second set of computer-readable instructions or the third set of computer-readable instructions; the second set of computer-readable instructions stored in the one or more memory storage devices that, if the first set of computer-readable instructions determines to send the tagged discrete video fragment to the second set of computer-readable instructions, execute to: receive the tagged discrete video fragment; cause the tagged discrete video fragment to be presented on a display for analysis by a human; and receive, from the human, an input to generate a first additional tag associated with the tagged discrete video fragment; and the third set of computer-readable instructions stored in the one or more memory storage devices that, if the first set of computer-readable instructions determines to send the tagged discrete video fragment to the third set of computer-readable instructions, execute to: receive the tagged discrete video fragment; apply a machine learning algorithm to the tagged discrete video fragment; and generate, via the machine learning algorithm, a second additional tag associated with the tagged discrete video fragment.
2. The system of claim 1, wherein the first set of computer-readable, when executed by the processor, further cause the system to store the tagged discrete video fragment including the first additional tag or the second additional tag in the semantic database.
3. The system of claim 1, wherein the one or more ontological models comprise one or more data structure definitions that are based on a specified task.
4. The system of claim 1, wherein converting the video signal into a plurality of discrete video fragments comprises extracting the plurality of discrete video fragments in about five second intervals from a real-time video feed.
5. The system of claim 1, wherein the discrete video fragment comprises an initial frame and one or more successive frames that define a change relative to the initial frame.
6. The system of claim 1, wherein determining whether to send the tagged discrete video fragment to a second set of computer-readable instructions or a third set of computer-readable instructions is based, at least in part, on detecting a first availability of the second set of computer-readable instructions for execution, or a second availability of the third set of computer-readable instructions for execution.
7. The system of claim 1, wherein the image sensor comprises a camera attached to an airplane or an unmanned aerial vehicle.
8. A method comprising: receiving, from a camera, a video signal; converting the video signal into a discrete video fragment; applying a tagging plug-in to the discrete video fragment to associate one or more tags with the discrete video fragment to create a tagged discrete video fragment; applying one or more ontological models to the tagged discrete video fragment; determining, based on applying the one or more ontological rules, whether to send the tagged discrete video fragment to a first analysis system or a second analysis system; sending, based on determining whether to send the tagged discrete video fragment to a first analysis system or a second analysis system, the tagged discrete video fragment to the first analysis system or the second analysis system; if the tagged discrete video fragment is sent to the first analysis system: receiving, by the first analysis system, the tagged discrete video fragment; presenting, by the first analysis system, the tagged discrete video fragment on a display for analysis by a human; and receiving, by the first analysis system, an input from the human to associate first additional information with the tagged discrete video fragment; if the tagged discrete video fragment is sent to the second analysis system: receiving, by the second analysis system, the tagged discrete video fragment; applying, by the second analysis system, a machine learning algorithm to the tagged discrete video fragment; and generating, via the machine learning algorithm, second additional information associated with the tagged discrete video fragment.
9. The method of claim 8, wherein the tagging plug-in comprises a motion detection plug-in that detects a motion of an object identified in the discrete video fragment.
10. The method of claim 9, wherein the object comprises a vehicle and the one more tags comprise an indication that the vehicle is in motion.
11. The method of claim 10, wherein the first additional information comprises an indication that the vehicle has performed a U-turn.
12. The method of claim 8, wherein the tagging plug-in determines an absence of data and requests the data from an external source.
13. The method of claim 12, wherein the data comprises a global positioning system (GPS) coordinate corresponding to a location identified in the discrete video fragment.
14. The method of claim 8, wherein the machine learning algorithm comprises an image recognition algorithm.
15. The method of claim 8, wherein the one or more ontological models include one or more rules generated from one or more stored videos of a person cheating in a casino.
16. The method of claim 8, wherein the discrete video fragment comprises information associated with at least one of an airplane altitude, an airplane speed, an airplane pilot identity, or an airplane pilot heart rate.
17. A system comprising: a camera; one or more memory storage devices; a set of computer-readable instructions stored on the one or more memory storage devices that, when executed by a processor, cause the system to: receive a video signal from the camera; convert the video signal into a plurality of discrete video fragments; apply a tagging plug-in to a discrete video fragment of the plurality of discrete video fragments; associate, based on applying the tagging plug-in, one or more semantic tags with the discrete video fragment to generate a tagged discrete video fragment; apply one or more ontological models of a semantic database to the tagged discrete video fragment; send, based at least in part on applying the one or more ontological models, the tagged discrete video fragment to a first analysis system; generate, by the first analysis system, an additional tag associated with the tagged discrete video fragment; send, based at least in part on applying the one or more ontological models, the tagged discrete video fragment and the additional tag to a second analysis system; receive, by the second analysis system, an acceptance or a rejection of the additional tag.
18. The system of claim 17, wherein the first analysis system comprises a machine learning algorithm and the additional tag indicates a presence or an absence of a data point outside a predetermined range.
19. The system of claim 17, wherein the second analysis system comprises a display for presenting the tagged discrete video fragment and the additional tag to a human, and a graphical user interface for receiving an input from the human, the acceptance or the rejection corresponding to the input.
20. The system of claim 17, wherein the machine learning algorithm comprises a first machine learning algorithm, and the second analysis system comprises a second machine learning algorithm that accesses a training data set to generate the acceptance or the rejection.
</claims>
</document>
