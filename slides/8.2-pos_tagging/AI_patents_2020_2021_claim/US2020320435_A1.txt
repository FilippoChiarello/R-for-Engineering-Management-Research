<document>

<filing_date>
2020-04-07
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-08
</priority_date>

<ipc_classes>
G06N20/00,G06N5/04
</ipc_classes>

<assignee>
SRI INTERNATIONAL
</assignee>

<inventors>
GERVASIO, MELINDA T.
YEH, CHIH-HUNG
Sequeira, Pedro Daniel Barbosa
</inventors>

<docdb_family_id>
72663142
</docdb_family_id>

<title>
MULTI-LEVEL INTROSPECTION FRAMEWORK FOR EXPLAINABLE REINFORCEMENT LEARNING AGENTS
</title>

<abstract>
Techniques are disclosed for applying a multi-level introspection framework to interaction data characterizing a history of interaction of a reinforcement learning agent with an environment. The framework may apply statistical analysis and machine learning methods to interaction data collected during the RL agent's interaction with the environment. The framework may include a first ("environment") level that analyzes characteristics of one or more tasks to be solved by the RL agent to generate elements, a second ("interaction") level that analyzes actions of the RL agent when interacting with the environment to generate elements, and a third ("meta-analysis") level that generates elements by analyzing combinations of elements generated by the first level and elements generated by the second level.
</abstract>

<claims>
1. A computing system comprising: a computation engine comprising processing circuitry, wherein the computation engine is configured to obtain interaction data generated by a reinforcement learning agent, the interaction data characterizing one or more tasks in an environment and characterizing one or more interactions of the reinforcement learning agent with the environment, the one or more interactions performed according to trained policies for the reinforcement learning agent, wherein the computation engine is configured to process the interaction data to apply a first analysis function to the one or more tasks to generate first elements, wherein the computation engine is configured to process the interaction data to apply a second analysis function to the one or more interactions to generate second elements, the first analysis function different than the second analysis function, wherein the computation engine is configured to process at least one of the first elements and the second elements to generate third elements denoting one or more characteristics of the one or more interactions, and wherein the computation engine is configured to output an indication of the third elements to a user to provide an explanation of the one or more interactions of the reinforcement learning agent with the environment.
2. The computing system of claim 1, wherein the computation engine is configured to output a request for a decision for one or more actions to perform by the reinforcement learning agent within the environment, wherein the computation engine is configured to receive, from the user, decision data indicating a decision of the user responsive to the request for the decision, and wherein the computation engine is configured to process the decision data to modify the trained policies for the reinforcement learning agent, retrain the reinforcement learning agent, or provide control to the reinforcement learning agent.
3. The computing system of claim 1, wherein the computation engine is configured to execute the reinforcement learning agent to perform the one or more tasks to generate the trained policies.
4. The computing system of claim 1, wherein the first analysis function comprises a transition analysis function, wherein to generate the first elements, the computation engine applies the transition analysis function to the one or more interactions to identify a reinforcement learning agent transition having a certainty level that meets a threshold, and wherein the first elements comprise an indication of the identified reinforcement learning agent transition.
5. The computing system of claim 1, wherein the first analysis function comprises a reward analysis function, wherein to generate the first elements, the computation engine applies the reward analysis function to rewards of the one or more interactions to identify an interaction having a reward value that meets a distribution threshold, and wherein the first elements comprise an indication of the identified interaction.
6. The computing system of claim 1, wherein the second analysis function comprises an interaction analysis function, wherein the second elements comprise at least one of observation frequency data, outlier data, or certainty data.
7. The computing system of claim 1, wherein the first analysis function is a function included in an environmental analysis level of a multi-level introspection framework, wherein the second analysis function is a function included in an interaction analysis level of the multi-level introspection framework, and wherein to process the first elements and the second elements the computation engine is configured to apply a meta-analysis function of a meta-analysis level of the multi-level introspection framework.
8. The computing system of claim 1, wherein the first analysis function comprises a value function, wherein the first elements comprise respective values indicating expected respective rewards for one or more state of the environment, wherein the second analysis function comprises a transition probability function, wherein the second elements comprise transition probability values each indicating a probability of a transition to a new state of the environment given a state of the environment and an action, wherein to process the first elements and the second elements the computation engine is configured to compute at least one of local minima or maxima, absolute minima or maxima, observation variance outliers, or strict-difference variance outliers based on the values and the transition probability values.
9. The computing system of claim 1, wherein the interaction data comprises counter data indicating respective numbers for at least: one or more states of the environment interacted with by the reinforcement learning agent, one or more actions performed for states of the environment, or one or more transitions of the reinforcement learning agent within the environment, wherein the first analysis function comprises a value function, wherein the first elements comprise respective values indicating expected respective rewards for one or more state of the environment, wherein the second analysis function comprises a transition probability function, wherein the second elements comprise transition probability values each indicating a probability of a transition to a new state of the environment given a state of the environment and an action, wherein to process the first elements and the second elements the computation engine is configured to: compute local maxima based on the values; generate a transition graph based on the transition probability values; and process the transition graph to identify most likely sequences of transitions of the reinforcement learning agent within the environment, wherein the third elements comprise the most likely sequences.
10. The computing system of claim 1, wherein the first analysis function comprises a reward analysis function, wherein to generate the first elements, the computation engine applies the reward analysis function to rewards of the one or more interactions to identify an interaction having a reward value that meets a distribution threshold, and wherein the first elements comprise an indication of the identified interaction, wherein the second analysis function comprises a value analysis function, wherein the interaction data comprises at least one: value data for one or more actions performed for states of the environment, or prediction error for one or more actions performed for the one or more states of the environment, and wherein to generate the second elements, the computation engine applies the value analysis function to at least one of the value data or prediction error to generate outlier data, wherein the second elements comprise the outlier data, wherein the interaction data comprises counter data indicating respective numbers for at least: one or more states of the environment interacted with by the reinforcement learning agent, one or more actions performed for states of the environment, or one or more transitions of the reinforcement learning agent within the environment, wherein to process the first elements and the second elements the computation engine is configured to identify contradiction data comprising at least one of contradictory-value observations, contradictory-count observations, or contradictory-goal observations, and wherein the third elements comprise the contradiction data.
11. The computing system of claim 1, wherein to output the indication of the third elements the computation engine is configured to: compute, based on the third elements, summary data for a plurality of analysis functions, the summary data comprising one or more of: a maxima state, a minima state, a state-action pair with associated certainty, a state with associated frequency value, a most likely sequence from a minima state to a maxima state, or a most likely sequence from a maxima state to a minima state; and output, to a display device, the summary data.
12. The computing system of claim 1, wherein the computation engine is configured to generate, based on the third elements, one or more training scenarios.
13. The computing system of claim 1, wherein the interaction data is for one of: an autonomous vehicle, a conversational assistant, a medical system, a network automation system, a home automation system, or an industrial control system.
14. The computing system of claim 1, wherein the computation engine is configured to receive a query for a most likely sequence for the reinforcement learning agent, wherein the third elements comprise the most likely sequence.
15. A method of explainable reinforcement learning, the method comprising: obtaining, by a computing system, interaction data generated by a reinforcement learning agent, the interaction data characterizing one or more tasks in an environment and characterizing one or more interactions of the reinforcement learning agent with the environment, the one or more interactions performed according to trained policies for the reinforcement learning agent; processing, by the computing system, the interaction data to apply a first analysis function to the one or more tasks to generate first elements; processing, by the computing system, the interaction data to apply a second analysis function to the one or more interactions to generate second elements, the first analysis different than the second analysis; processing, by the computing system, at least one of the first elements and the second elements to generate third elements denoting one or more characteristics of the one or more interactions; and outputting, by the computing system, an indication of the third elements to a user to provide an explanation of the one or more interactions of the reinforcement learning agent.
16. The method of claim 15, wherein the first analysis comprises one of a transition analysis function or a reward analysis function.
17. The method of claim 15, wherein the second analysis function comprises an interaction analysis function.
18. The method of claim 15, wherein the second analysis function comprise one of an observation frequency analysis function, an observation-action frequency analysis function, or a value analysis function, and wherein the second elements comprise at least one of observation frequency data, outlier data, or certainty data.
19. The method of claim 15, wherein processing the first elements and the second elements comprises applying a meta-analysis function.
20. A non-transitory computer-readable medium comprising instructions for causing one or more programmable processors to: obtain interaction data generated by a reinforcement learning agent, the interaction data characterizing one or more tasks in an environment and characterizing one or more interactions of the reinforcement learning agent with the environment, the one or more interactions performed according to trained policies for the reinforcement learning agent; process the interaction data to apply a first analysis function to the one or more tasks to generate first elements; process the interaction data to apply a second analysis function to the one or more interactions to generate second elements, the first analysis different than the second analysis; process at least one of the first elements and the second elements to generate third elements denoting one or more characteristics of the one or more interactions; and output an indication of the third elements to a user to provide an explanation of the one or more interactions of the reinforcement learning agent.
</claims>
</document>
