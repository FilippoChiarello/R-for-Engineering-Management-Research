<document>

<filing_date>
2020-04-09
</filing_date>

<publication_date>
2020-07-23
</publication_date>

<priority_date>
2018-01-25
</priority_date>

<ipc_classes>
G06K9/62,G06K9/66,G06N3/08
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
GEORGIADIS, GEORGIOS
DENG, WEIRAN
</inventors>

<docdb_family_id>
67298737
</docdb_family_id>

<title>
ACCELERATING LONG SHORT-TERM MEMORY NETWORKS VIA SELECTIVE PRUNING
</title>

<abstract>
A system and method for pruning. A neural network includes a plurality of long short-term memory cells, each of which includes an input having a weight matrix Wc, an input gate having a weight matrix Wi, a forget gate having a weight matrix Wf, and an output gate having a weight matrix Wo. In some embodiments, after initial training, one or more of the weight matrices Wi, Wf, and Wo are pruned, and the weight matrix Wc is left unchanged. The neural network is then retrained, the pruned weights being constrained to remain zero during retraining.
</abstract>

<claims>
1. A method for performing machine learning in a first neural network comprising one or more long short-term memory cells, a first long short-term memory cell of the one or more long short-term memory cells comprising: an input having a first weight matrix Wc; an input gate having a first weight matrix Wi; a forget gate having a first weight matrix Wf; and an output gate having a first weight matrix Wo, the method comprising: maintaining the first weight matrix Wc unchanged; and pruning the first weight matrix Wf, the pruning of the first weight matrix Wf comprising: determining that a first element, at a first position in the first weight matrix Wf, fails to meet a first threshold, the first threshold being based on a second threshold; and setting to zero the first element, at the first position in the first weight matrix Wf, based on determining that the first element, at the first position in the first weight matrix Wf, fails to meet the first threshold.
2. The method of claim 1, further comprising: calculating a standard deviation over a subset of elements of the first weight matrix Wf, wherein the first threshold is further based on the standard deviation; determining that a second element, at a second position in the first weight matrix Wf, meets the first threshold; and maintaining the second element unchanged, based on determining that the second element, at the second position in the first weight matrix Wf, meets the first threshold, wherein a second long short-term memory cell of the one or more long short-term memory cells comprises an input gate having a second weight matrix Wf and wherein the calculating of the standard deviation comprises calculating a standard deviation over all elements of the first and second weight matrices Wf.
3. The method of claim 2, wherein the subset of elements of the first weight matrix Wf includes all elements of the first weight matrix Wf.
4. The method of claim 2, wherein a second long short-term memory cell of the one or more long short-term memory cells comprises a second weight matrix Wf and wherein the calculating of the standard deviation comprises calculating a standard deviation over all elements at the first position in the first and second weight matrices Wf.
5. The method of claim 1, further comprising pruning the first weight matrix Wi.
6. The method of claim 1, further comprising pruning the first weight matrix Wo.
7. The method of claim 1, wherein the first neural network further comprises a plurality of artificial neurons and a plurality of connections between the artificial neurons, each of the connections having a weight, and the method further comprises: calculating a standard deviation over the weights of the connections; setting to zero the weight of a connection of the plurality of connections when a magnitude of the weight is smaller than a product of a threshold and the standard deviation; and leaving the weight of the connection unchanged, otherwise.
8. The method of claim 1, further comprising retraining the first neural network, the retraining comprising maintaining the first element equal to zero.
9. The method of claim 8, further comprising operating a second neural network, the second neural network having a weight matrix Wf equal to the weight matrix Wf of the first neural network, the operating comprising: classifying an image with the second neural network, and controlling a vehicle based on the classifying of the image.
10. A system for performing machine learning, the system comprising a first processing circuit, the first processing circuit being configured to: instantiate a first neural network comprising one or more long short-term memory cells, a first long short-term memory cell of the one or more long short-term memory cells comprising: an input having a first weight matrix Wc; an input gate having a first weight matrix Wi; a forget gate having a first weight matrix Wf; and an output gate having a first weight matrix Wo, maintain the first weight matrix Wc unchanged; and prune the first weight matrix Wf, the pruning of the first weight matrix Wf comprising: determining that a first element, at a first position in the first weight matrix Wf, fails to meet a first threshold, the first threshold being based on a second threshold; setting to zero the first element, at the first position in the first weight matrix Wf, based on determining that the first element, at the first position in the first weight matrix Wf, fails to meet the first threshold.
11. The system of claim 10, the pruning of the first weight matrix Wf further comprising: calculating a standard deviation over a subset of elements of the plurality of weight matrices Wf, wherein the first threshold is further based on the standard deviation; determining that a second element, at a second position in the first weight matrix Wf, meets the first threshold; and maintaining the second element unchanged, based on determining that the second element, at the second position in the first weight matrix Wf, meets the first threshold, wherein a second long short-term memory cell of the one or more long short-term memory cells comprises an input gate having a second weight matrix Wf and wherein the calculating of the standard deviation comprises calculating a standard deviation over all elements of the first and second weight matrices Wf.
12. The system of claim 11, wherein the subset of elements of the first weight matrix Wf includes all elements of the first weight matrix Wf.
13. The system of claim 11, wherein a second long short-term memory cell of the one or more long short-term memory cells comprises a second weight matrix Wf and wherein the calculating of the standard deviation comprises calculating a standard deviation over all elements at the first position in the first and second weight matrices Wf.
14. The system of claim 10, wherein the first processing circuit is further configured to prune the first weight matrix Wi.
15. The system of claim 10, wherein the first processing circuit is further configured to prune the first weight matrix Wo.
16. The system of claim 10, wherein the system further comprises a plurality of artificial neurons and a plurality of connections between the artificial neurons, each of the connections having a weight, and the first processing circuit is further configured to: calculate a standard deviation over the weights of the connections; set to zero the weight of a connection of the plurality of connections when a magnitude of the weight is smaller than a product of a threshold and the standard deviation; and leave the weight of the connection unchanged, otherwise.
17. The system of claim 10, wherein the first processing circuit is further configured to retrain the first neural network, the retraining comprising leaving the first element equal to zero.
18. The system of claim 17, further comprising a second processing circuit configured to instantiate a second neural network, the second neural network having a weight matrix Wf equal to the weight matrix Wf of the first neural network, and to: classify images with the second neural network, and control a vehicle based on the classifying of the images.
19. A method for performing machine learning in a first neural network comprising one or more long short-term memory cells, a first long short-term memory cell of the one or more long short-term memory cells comprising: an input having a first weight matrix Wc; and a forget gate having a first weight matrix Wf; the method comprising: maintaining the first weight matrix Wc unchanged; and performing a step for pruning the first weight matrix Wf.
20. The method of claim 19, wherein the first long short-term memory cell further comprises: an input gate having a first weight matrix Wi; and an output gate having a first weight matrix Wo, wherein the step for pruning comprises: calculating a standard deviation over a subset of elements of the first weight matrix Wf; determining that a first element, at a first position in the first weight matrix Wf, fails to meet a first threshold, the first threshold being based on a second threshold and the standard deviation; setting to zero the first element, at the first position in the first weight matrix Wf, based on determining that the first element, at the first position in the first weight matrix Wf, fails to meet the first threshold; determining that a second element, at a second position in the first weight matrix Wf, meets the first threshold; and maintaining the second element unchanged, based on determining that the second element, at the second position in the first weight matrix Wf, meets the first threshold.
</claims>
</document>
