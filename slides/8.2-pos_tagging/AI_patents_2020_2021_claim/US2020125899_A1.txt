<document>

<filing_date>
2019-03-28
</filing_date>

<publication_date>
2020-04-23
</publication_date>

<priority_date>
2018-10-17
</priority_date>

<ipc_classes>
G06K9/62
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
CHANG, HYUN SUNG
JUNG, KYUNGBOO
LEE, WON HEE
SON, MINJUNG
</inventors>

<docdb_family_id>
66751948
</docdb_family_id>

<title>
METHOD AND APPARATUS TO TRAIN IMAGE RECOGNITION MODEL, AND IMAGE RECOGNITION METHOD AND APPARATUS
</title>

<abstract>
An apparatus and method to train an image recognition model to accurately estimate a location of a reference point for each class of landmark is disclosed. The apparatus and method use the image recognition model, which is trained based on calculating a class loss and a class-dependent localization loss from training data based on an image recognition model and training the image recognition model using a total loss comprising the class loss and the localization loss.
</abstract>

<claims>
1. A method of training an image recognition model, comprising: calculating a class loss and a class-dependent localization loss from training data based on an image recognition model; and training the image recognition model using a total loss comprising the class loss and the localization loss.
2. The method of claim 1, wherein the calculating of the class loss and the class-dependent localization loss comprises: calculating temporary class information and temporary reference point information from an input training image based on the image recognition model; calculating the class loss based on the temporary class information and ground truth class information; and calculating the localization loss based on the temporary reference point information and ground truth reference point information.
3. The method of claim 2, wherein the calculating of the temporary class information and the temporary reference point information comprises: calculating temporary class information and temporary reference point information for each of subregions of the input training image.
4. The method of claim 3, wherein the calculating of the class loss comprises: calculating a partial class loss between the ground truth class information and the temporary class information calculated for the each of the subregions of the input training image; and determining a sum of partial class losses calculated for the each of the subregions of the input training image to be the class loss.
5. The method of claim 3, wherein the calculating of the class loss comprises: selecting subregions corresponding to a ground truth landmark portion from among the subregions of the input training image; calculating a partial class loss between the ground truth class information and temporary class information calculated for each of the selected subregions; and determining a sum of partial class losses calculated for the selected subregions to be the class loss.
6. The method of claim 5, wherein the selecting of the subregions comprises: further selecting a subregion corresponding a ground truth background portion from among the subregions of the input training image.
7. The method of claim 3, wherein the calculating of the localization loss comprises: calculating, for each of the subregions of the input training image, a partial localization loss between the ground truth reference point information and temporary reference point information calculated for the each of the subregions of the input training image; and determining a sum of partial localization losses calculated for the each of the subregions to be the localization loss.
8. The method of claim 3, wherein the calculating of the localization loss comprises: selecting subregions corresponding to a ground truth landmark portion from among the subregions of the input training image; calculating a partial localization loss between the ground truth reference point information and temporary reference point information of each of the selected subregions; and determining a sum of partial localization losses calculated for the selected subregions to be the localization loss.
9. The method of claim 8, wherein the calculating of the partial localization loss comprises: excluding a subregion with a ground truth background portion from the selected subregions.
10. The method of claim 3, wherein the calculating of the temporary class information and the temporary reference point information for the each of the subregions of the input training image comprises: calculating temporary class information and temporary reference point information for each of anchor nodes set for the each of the subregions.
11. The method of claim 10, wherein the calculating of the temporary class information and the temporary reference point information for the each of the anchor nodes comprises: calculating temporary class information and temporary reference point information for an anchor node having a highest confidence level from among confidence levels calculated for each of the anchor nodes.
12. The method of claim 10, wherein the calculating of the temporary class information and the temporary reference point information for each of the anchor nodes comprises: excluding an anchor node having a confidence level less than a threshold from among confidence levels calculated for each of the anchor nodes.
13. The method of claim 1, wherein the calculating of the class loss and the class-dependent localization loss comprises: calculating a class-based weight based on temporary class information; and determining the class-dependent localization loss based on the class-based weight, temporary reference point information, and ground truth reference point information.
14. The method of claim 13, wherein the determining of the class-dependent localization loss comprises: determining the class-dependent localization loss by applying the class-based weight to a difference between the temporary reference point information and the ground truth reference point information.
15. The method of claim 1, wherein the training comprises: updating a parameter of the image recognition model to minimize the total loss.
16. The method of claim 15, wherein the updating of the parameter comprises: repeating the updating of the parameter of the image recognition model to converge the total loss.
17. The method of claim 15, wherein the updating of the parameter comprises: updating the parameter such that the class loss is minimized before the localization loss is minimized.
18. A non-transitory computer-readable storage medium storing instructions that, when executed by a processor, cause the processor to perform the method of claim 1.
19. A training apparatus comprising: a memory configured to store an image recognition model; and a processor configured to calculate a class loss and a class-dependent localization loss from training data based on the image recognition model, and train the image recognition model using a total loss comprising the class loss and the localization loss.
20. An image recognition method comprising: obtaining an input image; and estimating, from the input image, a class of a landmark in the input image and a reference point of the landmark, based on an image recognition model.
</claims>
</document>
