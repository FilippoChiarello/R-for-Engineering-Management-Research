<document>

<filing_date>
2019-09-10
</filing_date>

<publication_date>
2020-03-19
</publication_date>

<priority_date>
2018-09-12
</priority_date>

<ipc_classes>
G06N20/00,G06N3/063,G06N3/08
</ipc_classes>

<assignee>
MATELABS INNOVATIONS PVT.
</assignee>

<inventors>
AHIRWAR, KAILASH
VISHWAKARMA, RAHUL
</inventors>

<docdb_family_id>
69776846
</docdb_family_id>

<title>
SYSTEM FOR DECENTRALIZED AND DISTRIBUTED DEEP LEARNING
</title>

<abstract>
The embodiments herein disclose a system (100) comprising a requester node (101) and a master node (102). The requester node (101) interacts directly with a user or through a computing device. The master node (102) integrates a data received from and transmitted to a plurality of sources. The master node (101) comprises a request pooler (103), a data collection node (104), a data repository (107), and a deep learning training distribution (DLTD) node (109). The request pooler (103) is connected to the requester node (101) through a unidirectional channel. The data collection node (104) is connected to a data source node (105) and a data annotator (106). The data repository (107) comprises a plurality of data sets collected from the data collection node (108). The DLTD node (109) is connected to plurality of computer nodes (110) and the data repository (107).
</abstract>

<claims>
1. A system (100) for deep learning in a decentralized and distributed network, the system comprises:
a requester node (101), wherein the requester node interacts with a user;
a master node (102), wherein the master node integrates a data received from and transmitted to a plurality of sources, wherein the master node comprises:
a request pooler (103), wherein the request pooler is connected to the requester node through a unidirectional channel;
a data collection node (104), wherein the data collection node is connected to a data source node (105) and a data annotator (106);
a data repository (107), wherein the data repository comprises a plurality of data sets collected from the data collection node (108);
a deep learning training distribution (DLTD) node (109), wherein the DLTD node is connected to a plurality of computer nodes (110) and the data repository.
2. The system as claimed in claim 1, wherein the data source node collects data from a plurality of data banks for pre-processing and storing in the data collection node in a standard format, wherein the collected data is annotated by the data annotator.
3. The system as claimed in claim 1, wherein the DLTD node distributes the plurality of data sets among the plurality of computer nodes for computation to perform a training of a deep learning network.
4. The system as claimed in claim 3, wherein the DLTD node is further connected to a distribution server, wherein the distribution server is further connected to the computer nodes through a gradient collector and a collection queue.
5. The system as claimed in claim 4, wherein the distribution server prepares a list of matrix calculation to calculate a plurality of gradients.
6. The system as claimed in claim 4, wherein the gradient collector receives calculations from the plurality of computer nodes and orderly accumulates in the distribution server.
7. The system as claimed in claim 4, wherein the distribution server calls for a plurality of batches of the plurality of dataset through the calculation queue.
8. The system as claimed in claim 4, wherein a calculation is assigned to each computer nodes through the calculation queue.
9. The system as claimed in claim 1 implements dynamic graph computation for distribution of a data and gradient.
</claims>
</document>
