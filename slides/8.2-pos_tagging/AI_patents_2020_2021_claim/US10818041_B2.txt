<document>

<filing_date>
2019-10-22
</filing_date>

<publication_date>
2020-10-27
</publication_date>

<priority_date>
2017-04-21
</priority_date>

<ipc_classes>
G06T1/20,G06T9/00
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
KOKER, ALTUG
RAY, JOYDEEP
RANGANATHAN VASANTH
APPU, ABHISHEK R.
</inventors>

<docdb_family_id>
63852337
</docdb_family_id>

<title>
Fabric-based compression/decompression for internal data transfer
</title>

<abstract>
A mechanism is described for facilitating fabric-based compression and/or decompression of data at computing devices. A method of embodiments, as described herein, includes compressing contents of a data stream traveling through an internal fabric between a source component and a destination component, wherein the contents are compressed on the internal fabric.
</abstract>

<claims>
1. An apparatus comprising: one or more processors including a graphics processor; an internal fabric to carry data including data for machine learning; and one or more compressors and one or more decompressors associated with the internal fabric; wherein the apparatus is to provide compression of contents of a data stream, the data stream including data for machine learning, transmitted through the internal fabric between a source component and a destination component, wherein one of the source component or the destination component comprises the graphics processor, the apparatus including: a first compressor of the one or more compressors to compress the contents of the data stream and to assign one or more compression tags to the compressed contents prior to transmission of the compressed contents on the internal fabric, and a first decompressor of the one or more decompressors to identify the compressed contents using the one or more compression tags and to decompress the compressed contents subsequent to transmission of the compressed contents on the internal fabric.
2. The apparatus of claim 1, wherein the one or more processors further include a central processing unit (CPU), and wherein the other of the source component or the destination component comprises the CPU.
3. The apparatus of claim 1, wherein the one or more compression tags are further to define whether the contents of the data stream are compressed by at least a first number of bits to generate the compressed contents.
4. The apparatus of claim 3, wherein, for a compression of at least the first number of bits, the apparatus is to use the first number of bits of the internal fabric for encoding of compression information for the compressed contents.
5. The apparatus of claim 1, wherein the data stream includes sparse matrix data for machine learning.
6. The apparatus of claim 1, wherein the destination component is to receive the contents of the data stream, originated at or sent from the source component, subsequent to decompression of the data stream by the first decompressor.
7. The apparatus of claim 1, wherein the one or more processors are to clock gate the internal fabric at byte-level granularity to ensure clock gate controls throughout the internal fabric.
8. The apparatus of claim 1, wherein the graphics processor includes a plurality of streaming multiprocessors (SMs), and wherein one or more of the plurality of SMs generates or receives the data stream.
9. The apparatus of claim 1, wherein the source component comprises an application processor, and wherein the destination component comprises the graphics processor.
10. The apparatus of claim 9, wherein the graphics processor is co-located with the application processor on a common semiconductor package.
11. A method comprising: compressing, by a first compressor of one or more compressors associated with an internal fabric of an apparatus, contents of a data stream from a source component for a destination component, wherein: the data stream includes data for machine learning, and the apparatus includes one or more processors including a graphics processor, one of the source component or the destination component comprising the graphics processor; assigning one or more compression tags to the compressed contents by the first compressor; transmitting the compressed contents and the one or more compression tags through the internal fabric; identifying, by a first decompressor of one or more decompressors associated with the internal fabric, the compressed contents using the one or more compression tags; and decompressing the compressed contents by the first decompressor subsequent to transmission of the compressed contents on the internal fabric.
12. The method of claim 11, further comprising: defining, utilizing the one or more compression tags, whether the contents of the data stream are compressed by at least a first number of bits to generate the compressed contents.
13. The method of claim 12, further comprising: for a compression of at least the first number of bits, using the first number of bits of the internal fabric for encoding of compression information for the compressed contents.
14. The method of claim 11, wherein the data stream includes sparse matrix data for machine learning.
15. The method of claim 11, further comprising: receiving, at the destination component, the contents of the data stream, originated at or sent from the source component, subsequent to decompression of the data stream by the first decompressor.
16. The method of claim 11, further comprising: clock gating, by the one or more processors, the internal fabric at byte-level granularity to ensure clock gate controls throughout the internal fabric.
17. The method of claim 11, wherein the graphics processor includes a plurality of streaming multiprocessors (SMs), and wherein one or more of the plurality of SMs generates or receives the data stream.
18. At least one non-transitory machine-readable medium comprising instructions that when executed by a computing device, cause the computing device to perform operations comprising: compressing, by a first compressor of one or more compressors associated with an internal fabric of an apparatus, contents of a data stream from a source component for a destination component, wherein: the data stream includes data for machine learning, and the apparatus includes one or more processors including a graphics processor, one of the source component or the destination component comprising the graphics processor; assigning one or more compression tags to the compressed contents by the first compressor; transmitting the compressed contents and the one or more compression tags through the internal fabric; identifying, by a first decompressor of one or more decompressors associated with the internal fabric, the compressed contents using the one or more compression tags; and decompressing the compressed contents by the first decompressor subsequent to transmission of the compressed contents on the internal fabric.
19. The machine-readable medium of claim 18, wherein the instructions further include instructions for: defining, utilizing the one or more compression tags, whether the contents of the data stream are compressed by at least a first number of bits to generate the compressed contents.
20. The machine-readable medium of claim 19, wherein the instructions further include instructions for: for a compression of at least the first number of bits, using the first number of bits of the internal fabric for encoding of compression information for the compressed contents.
21. The machine-readable medium of claim 18, wherein the data stream includes sparse matrix data for machine learning.
22. The machine-readable medium of claim 18, wherein the instructions further include instructions for: receiving, at the destination component, the contents of the data stream, originated at or sent from the source component, subsequent to decompression of the data stream by the first decompressor.
23. The machine-readable medium of claim 18, wherein the instructions further include instructions for: clock gating, by the one or more processors, the internal fabric at byte-level granularity to ensure clock gate controls throughout the internal fabric.
</claims>
</document>
