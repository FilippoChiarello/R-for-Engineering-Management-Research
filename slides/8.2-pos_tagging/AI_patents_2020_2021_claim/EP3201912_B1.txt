<document>

<filing_date>
2015-10-01
</filing_date>

<publication_date>
2020-08-12
</publication_date>

<priority_date>
2014-10-02
</priority_date>

<ipc_classes>
G10L15/02,G10L17/02,G10L17/18
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
SLANEY, MALCOLM
STOLCKE, ANDREAS
YELLA, SREE HARSHA
</inventors>

<docdb_family_id>
54330054
</docdb_family_id>

<title>
NEURAL NETWORK-BASED SPEECH PROCESSING
</title>

<abstract>
Pairs of feature vectors are obtained that represent speech. Some pairs represent two samples of speech from the same speakers, and other pairs represent two samples of speech from different speakers. A neural network feeds each feature vector in a sample pair into a separate bottleneck layer, with a weight matrix on the input of both vectors tied to one another. The neural network is trained using the feature vectors and an objective function that induces the network to classify whether the speech samples come from the same speaker. The weights from the tied weight matrix are extracted for use in generating derived features for a speech processing system that can benefit from features that are thus transformed to better reflect speaker identity.
</abstract>

<claims>
1. A computing system, comprising: a feature extraction system configured to extract a set of training features from audio training data and generate pairs of feature vectors from a same audio source and pairs of feature vectors from different audio sources; and a neural network training system configured to receive the pairs of feature vectors and train a neural network by applying the pairs of feature vectors through a weight matrix, to an input node layer of the neural network, modify the weight matrix based on an objective function of network outputs that indicate whether the pairs of feature vectors are from the same audio source or different audio sources, and to extract weights from the weight matrix and provide the weights to an audio processing system; wherein the feature extraction system is configured to extract the pairs of feature vectors as feature vectors from speech of known speakers; the feature extraction system is configured to generate the pairs of feature vectors as pairs of feature vectors from the same speaker and pairs of feature vectors from different speakers; the input node layer of the neural network comprises: a first bottleneck layer having a set of nodes; and a second bottleneck layer having a set of nodes; the weight matrix ties weights on inputs to corresponding nodes of the first and second bottleneck layers together; and the neural network training system comprises: a training component that feeds the pairs of feature vectors into the neural network by feeding a first feature vector of each of the pairs of feature vectors through the weight matrix into the nodes of the first bottleneck layer and feeding a second feature vector of each of the pairs of feature vectors through the weight matrix into the nodes of the second bottleneck layer.
2. The computing system of claim 1 wherein the training component is configured to train the neural network by forcing an output layer of the neural network to indicate whether the pairs of feature vectors are drawn from speech of the same speaker or different speakers, based on the objective function.
3. The computing system of claim 2 and further comprising:
a feature generation system configured to apply the extracted weights to a set of features extracted from speech data to obtain a set of derived features.
4. The computing system of claim 3 and further comprising:
a speech processing system configured to use the set of derived features in generating a speech processing result corresponding to the speech data.
5. A computer readable storage system that stores computer executable instructions which, when executed by the computer, cause the computer to perform a method, comprising: extracting a set of training feature vectors from speech training data that represents speech from a plurality of different, known speakers; generating pairs of feature vectors from a same speaker and pairs of feature vectors from different speakers; training a neural network by applying the set of training features, through a weight matrix, to an input node layer of the neural network, and modifying network weights in the weight matrix based on an objective function of network outputs; extracting the network weights from the weight matrix of the trained neural network; and providing the weights to a speech processing system; wherein the pairs of feature vectors are extracted as feature vectors from speech of known speakers, as pairs of feature vectors from the same speaker and pairs of feature vectors from different speakers; the input node layer of the neural network comprises: a first bottleneck layer having a set of nodes; and a second bottleneck layer having a set of nodes; the weight matrix ties weights on inputs to corresponding nodes of the first and second bottleneck layers together; and the training the neural network comprises:
feeding the pairs of feature vectors into the neural network by feeding a first feature vector of each of the pairs of feature vectors through the weight matrix into the nodes of the first bottleneck layer and feeding a second feature vector of each of the pairs of feature vectors through the weight matrix into the nodes of the second bottleneck layer.
</claims>
</document>
