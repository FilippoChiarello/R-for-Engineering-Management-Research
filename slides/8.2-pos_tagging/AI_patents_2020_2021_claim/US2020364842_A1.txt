<document>

<filing_date>
2020-03-31
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-13
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08,G06T7/00,G06T7/70
</ipc_classes>

<assignee>
FUJITSU
</assignee>

<inventors>
CHATON, Thomas
</inventors>

<docdb_family_id>
66542047
</docdb_family_id>

<title>
SURFACE DEFECT IDENTIFICATION METHOD AND APPARATUS
</title>

<abstract>
Embodiments include a computer implemented method of processing images of material surfaces to identify defects on the imaged material surface, the method including training a neural network to generate reduced-defect versions of training images of material surfaces; acquiring an image of a subject material surface; inputting the acquired image to the neural network to generate a reduced-defect version of the acquired image; and comparing the reduced-defect version of the acquired image with the acquired image to identify differences. Defects on the subject material surface at locations of the identified differences are identifiable.
</abstract>

<claims>
1. A computer-implemented method of processing images of material surfaces to identify defects on the imaged material surface, the method comprising: training a first neural network to generate reduced-defect versions of training images of material surfaces; acquiring an image of a subject material surface; inputting the acquired image to the first neural network to generate a reduced-defect version of the acquired image; comparing the reduced-defect version of the acquired image with locations in the acquired image to identify respective differences between the reduced-defect version of the acquired image and the acquired image; identifying defects on the subject material surface at the locations of the identified respective differences.
2. The method according to claim 1, wherein each training image of the training images is input to the first neural network as a plurality of training image portions to generate reduced-defect versions of the training image portions, each training image portion of the training image portions representing a spatial subdivision of the training image, and the method further comprises aggregating the reduced-defect versions of the training image portions into a reduced-defect version of the training image; and the acquired image is input to the first neural network as a plurality of acquired image portions, each acquired image portion of the acquired image portions representing a spatial subdivision of the acquired image to cause the first neural network to generate reduced-defect versions of the acquired image portions, and the method further comprises aggregating the reduced-defect versions of the acquired image portions to generate the reduced-defect version of the acquired image.
3. The method according to claim 1, wherein the comparing includes locating a respective location among the locations at which a difference is identified between the reduced-defect version of the acquired image and the acquired image, and outputting the location.
4. The method according to claim 3, further comprising: extracting from the acquired image an extracted image portion bounding the respective location at which the difference is identified between the reduced-defect version of the acquired image and the acquired image; inputting the extracted image portion to a second neural network, the second neural network being an encoding neural network trained to output an encoded characterisation of a material surface defect by processing the input extracted image portion to show the defects on the subject material surface; outputting the extracted image portion with a label based on the encoded characterisation.
5. The method according to claim 4, wherein the extracting from the acquired image of the extracted image comprises: extracting a plurality of image portions from the acquired image, each extracted image portion of the plurality of extracted image portions bound to a respective location at which a difference is identified between the reduced-defect version of the acquired image and the acquired image; adding the plurality of extracted image portions to a stored population of image portion members from historically acquired images bounding respective locations at which differences have been identified between the historically acquired images and respective reduced-defect versions of the historically acquired images, wherein each image portion member of the stored population of image portion member is stored along with a respective encoded characterisation obtained by processing the image portion member with the encoding neural network; and executing a clustering algorithm on respective encoded characterisations of image portion members of the stored population of image members corresponding to the extracted image portions to divide the extracted image portions into groups, each extracted image portion of the plurality of extracted image portions being a member of a group among the groups, wherein the outputting of the label for the extracted image portion member in the group includes outputting a label selected from historical assignment of labels to respective image portion members of the stored population of image portion members in the group, based on a comparison of an encoded characterisation of the extracted image portion member with the respective encoded characterization of the image portion members of the population of stored image portion members in the group.
6. The method according to claim 5, wherein the labels assigned to the population of stored image portions in the group are labels previously assigned to the population of stored image portions by a user via a user interface.
7. The method according to claim 5, wherein the outputting of the label for the extract image portion member in the group comprises: outputting, via a user interface, a plurality of candidate labels for the extracted image portion member, wherein each candidate label of the candidate labels is selected from labels assigned to the historically acquired images based on comparison of the encoded characterisation of the extracted image portion member with the respective encoded characterization of the image portion members of the population of stored image portions in the group; and the method further comprises accepting, via a user interface, a selection of a label from among the output candidate labels, and assigning the selected label to the extracted image portion member in the group.
8. The method according to claim 5, wherein the label output for the extract image portion member in the group, or the output candidate labels, is a recommended label selected by a machine learning algorithm based on the historical assignments of labels to the image portion members in the group from the stored population of image portion members.
9. The method according to claim 1, wherein the first neural network is a generative adversarial network, and the training includes training the first neural network to generate image data of the training images satisfying a discriminator network that the generated image data belongs to a training dataset, and training the discriminator network to distinguish between image data belonging to the training dataset and the generated image data.
10. The method according to claim 1, wherein the first neural network includes an inpainter model to generate the reduced-defect versions of the training images of material surfaces, and a cleaning model to remove noise from the generated reduced-defect versions of training images.
11. The method according to claim 1, wherein the first neural network includes a convolutional denoising neural network.
12. A non-transitory computer-readable medium storing a computer program which, when executed by a computing system comprising processor hardware and memory hardware, causes the processor hardware to perform a method comprising: training a first neural network to generate reduced-defect versions of input training images of material surfaces; acquiring an image of a subject material surface; inputting the acquired image to the first neural network to generate a reduced-defect version of the acquired image; comparing the reduced-defect version of the acquired image with locations in the acquired image to identify respective differences between the reduced-defect version of the acquired image and the acquired image; identifying defects on the subject material surface at the locations of the identified respective differences.
13. An apparatus comprising processor hardware and memory hardware, the memory hardware storing processing instructions which, when executed by the processor hardware, cause the processor hardware to perform: training a first neural network to generate reduced-defect versions of training images of material surfaces; acquiring an image of a subject material surface; inputting the acquired image to the first neural network to generate a reduced-defect version of the acquired image; comparing the reduced-defect version of the acquired image with locations in the acquired image to identify respective differences between the reduced-defect version of the acquired image and the acquired image; identifying defects on the subject material surface at the locations of the identified respective differences.
14. The apparatus according to claim 13, wherein the processor hardware includes a GPU.
</claims>
</document>
