<document>

<filing_date>
2017-10-23
</filing_date>

<publication_date>
2020-09-15
</publication_date>

<priority_date>
2017-10-23
</priority_date>

<ipc_classes>
B25J9/16,G05B11/32,G06N20/00,G06T11/60,G06T13/40,G06T19/00
</ipc_classes>

<assignee>
SONY INTERACTIVE ENTERTAINMENT
</assignee>

<inventors>
BASHKIROV, SERGEY
MATSUKAWA, TAKEO
</inventors>

<docdb_family_id>
66171083
</docdb_family_id>

<title>
VR body tracking without external sensors
</title>

<abstract>
Plural individual sensor assemblies are engaged with respective parts of a person's body. Each assembly may include accelerometers, magnetometers, and gyroscopes. Sensor data is fused together to get the orientation at each body location. To simplify, the body is assumed to consist of rigid bars of known length connected with ball joints so that once the relative orientations of all bars are given by the respective assemblies, body pose can be computed. Then the body pose is translated as a virtual body into a virtual world either by a ray cast method that anchors a foot of the virtual body to the ground assuming infinite gravity and infinite friction and then translating the other body parts to make the ground contact point fixed, or by implementing an approximate dynamics physics engine on the virtual body. The technique may be used in VR location-based entertainment and for motion capture.
</abstract>

<claims>
1. A method comprising: engaging plural motion sensor assemblies (MSA) to respective body parts, the MSA outputting pose information related to the respective body parts; providing the pose information to a display apparatus for presenting an image of the body parts having respective poses according to the pose information and rendering the image using ray cast in which a foot of the image is constrained to remain on virtual ground in virtual space.
2. The method of claim 1, comprising rendering the image using ray cast in which the foot of the image is constrained to remain on virtual ground with infinite gravity and infinite friction.
3. The method of claim 1, comprising rendering the image using a modeled dynamics physics engine.
4. The method of claim 1, comprising providing the pose information to a robot to cause the robot to move according to the pose information.
5. The method of claim 4, comprising implementing machine learning on the robot to obey movement commands by generating pose sequences in such a way that robot does not tip over.
6. The method of claim 1, comprising: processing the pose information using a machine learning-based robot controller; and moving a robot according to an output of the controller.
7. An assembly comprising: at least one apparatus; plural motion sensor assemblies (MSA) outputting pose information related to poses of respective real-world body parts; and at least one processor associated with the apparatus and configured with instructions for: receiving the pose information; and rendering an image using ray cast in which a foot of the image is constrained to remain on virtual ground in virtual space.
8. The assembly of claim 7, wherein the processor is configured with instructions for: rendering the image using a modeled dynamics involving physics engine.
9. The assembly of claim 7, wherein three respective MSA are attached to each respective arm of the body parts, two MSA are attached to each respective leg of the body parts, and at least one MSA is attached to a torso of the body parts.
10. An assembly comprising: at least one virtual reality (VR) apparatus; plural motion sensor assemblies (MSA) outputting pose information related to poses of respective real-world body parts; at least one transmitter sending the pose information to the VR apparatus; and at least one processor associated with the VR apparatus and configured with instructions for: receiving the pose information; presenting on the VR apparatus at least one image in a VR space that moves in the VR space according to the pose information; rendering the image using ray cast in which a foot of the image is constrained to remain on virtual ground in the virtual space.
11. An assembly comprising: at least one virtual reality (VR) apparatus; plural motion sensor assemblies (MSA) outputting pose information related to poses of respective real-world body parts; at least one transmitter sending the pose information to the VR apparatus; and at least one processor associated with the VR apparatus and configured with instructions for: receiving the pose information; presenting on the VR apparatus at least one image in a VR space that moves in the VR space according to the pose information; and rendering the image using ray cast in which a foot of the image is constrained to remain on virtual ground with infinite gravity and infinite friction.
12. An assembly comprising: at least one apparatus; plural motion sensor assemblies (MSA) outputting pose information related to poses of respective real-world body parts; and at least one processor associated with the apparatus and configured with instructions for: receiving the pose information; and presenting on the apparatus at least one image using ray cast technique in which a foot of the image remains on virtual ground in virtual space.
13. An assembly comprising: at least one virtual reality (VR) apparatus; and at least one processor associated with the VR apparatus and configured with instructions for: receiving pose information; and presenting at least one image in a VR space that moves in the VR space according to the pose information using a ray cast technique in which a portion of the image remains on virtual ground in the virtual space.
14. An assembly comprising: at least one virtual reality (VR) apparatus; at least one processor associated with the VR apparatus and configured with instructions for: receiving pose information; presenting on the VR apparatus at least one image in a VR space that moves in the VR space according to the pose information using a technique in which a portion of the image is constrained to remain on virtual ground with infinite gravity and infinite friction.
</claims>
</document>
