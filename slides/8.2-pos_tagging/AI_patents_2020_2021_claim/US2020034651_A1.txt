<document>

<filing_date>
2019-10-04
</filing_date>

<publication_date>
2020-01-30
</publication_date>

<priority_date>
2016-12-27
</priority_date>

<ipc_classes>
G06K9/00,G06K9/03,G06K9/62,G06K9/66,G06T5/00,G06T7/00,G06T7/11,G06T7/136
</ipc_classes>

<assignee>
DEFINIENS
</assignee>

<inventors>
LESNIAK, JAN MARTIN
</inventors>

<docdb_family_id>
60923259
</docdb_family_id>

<title>
Identifying and Excluding Blurred Areas of Images of Stained Tissue To Improve Cancer Scoring
</title>

<abstract>
A method for identifying blurred areas in digital images of stained tissue involves artificially blurring a learning tile and then training a pixel classifier to correctly classify each pixel as belonging either to the learning tile or to a blurred copy. A learning tile is first selected from a digital image of stained tissue. The learning tile is copied and blurred by applying a filter to each pixel. The pixel classifier is trained to correctly classify each pixel as belonging either to the learning tile or to the blurred, copied learning tile. The pixel classifier then classifies each pixel of the entire digital image as most likely resembling either the learning tile or the blurred learning tile. The digital image is segmented into blurred and unblurred areas based on the pixel classification. The blurred areas and the unblurred areas of the digital image are identified on a graphical user interface.
</abstract>

<claims>
1. 1-17. (canceled)
18. A method comprising: selecting a learning region of a digital image of a slice of tissue from a cancer patient that has been stained using a biomarker, wherein the digital image comprises pixels, wherein each of the pixels has a color defined by pixel values, wherein a portion of the pixels exhibits the color stained using the biomarker, and wherein the learning region includes a first subregion and a second subregion; distorting the second subregion of the learning region by applying a filter to the pixel values of each pixel of the second subregion so as artificially to blur the second subregion; generating a pixelwise descriptor by analyzing and comparing the pixel values of each pixel of the learning region with the pixel values of neighboring pixels at predetermined offsets from each analyzed pixel, wherein the pixelwise descriptor is trained to indicate based on the comparing with neighboring pixels that each pixel of the learning region most likely belongs either to an unblurred class of pixels such as those in the first subregion or to a blurred class of pixels such as those in the second subregion; characterizing each pixel of the digital image as most likely belonging either to the unblurred class of pixels or to the blurred class of pixels using the pixelwise descriptor by classifying each characterized pixel based on the pixel values of neighboring pixels at predetermined offsets from each characterized pixel; and identifying blurred areas of the digital image based on the classifying of pixels as belonging to the blurred class of pixels.
19. The method of claim 18, further comprising: dividing the digital image into tiles, wherein the learning region is one of the tiles, and wherein for each pixel the color stained using the biomarker and defined by the pixel values has a magnitude derived from the pixel values; and identifying the learning region as the tile whose pixel values represent a mean magnitude of the color stained using the biomarker.
20. The method of claim 18, further comprising: performing object-oriented image analysis on the digital image except for in the identified blurred areas.
21. The method of claim 18, further comprising: generating image objects by segmenting the digital image except in the identified blurred areas; determining a score using the image objects, wherein the score is indicative of a level of cancer malignancy of the slice of tissue from the cancer patient.
22. The method of claim 18, wherein each of the pixels has a color that is a shade of gray.
23. 23-24. (canceled)
25. The method of claim 18, wherein the pixelwise descriptor is a set of random forest pixelwise descriptors.
26. The method of claim 18, further comprising: determining a histopathological score based on tissue stained using the biomarker in areas of the digital image that are outside the blurred areas.
27. The method of claim 18, wherein the biomarker is used to immunohistochemically stain for the Ki-67 protein.
28. The method of claim 18, wherein the pixelwise descriptor is a binary classifier that is trained using supervised learning.
29. A method comprising: selecting a region of a digital image of cancer tissue that has been stained using a biomarker, wherein the digital image comprises pixels, wherein each of the pixels has a color defined by pixel values, wherein a portion of the pixels exhibits the color stained using the biomarker, and wherein the region includes a first subregion and a second subregion; distorting the second subregion by modifying the pixel values of each pixel of the second subregion so as artificially to blur the second subregion; generating a pixelwise descriptor by comparing the pixel values of each pixel of the region with the pixel values of neighboring pixels at predetermined offsets from each analyzed pixel, wherein the pixelwise descriptor is trained to indicate based on the comparing that each pixel of the region most likely belongs either to an unblurred class of pixels such as those in the first subregion or to a blurred class of pixels such as those in the second subregion; characterizing each pixel of the digital image as most likely belonging either to the unblurred class of pixels or to the blurred class of pixels using the pixelwise descriptor by classifying each characterized pixel based on the pixel values of neighboring pixels at predetermined offsets from each characterized pixel; and identifying blurred areas of the digital image based on the classifying of pixels as belonging to the blurred class of pixels.
30. The method of claim 29, further comprising: dividing the digital image into tiles, wherein the region is one of the tiles, and wherein for each pixel the color stained using the biomarker and defined by the pixel values has a magnitude derived from the pixel values; and identifying the region as the tile whose pixel values represent a mean magnitude of the color stained using the biomarker.
31. The method of claim 29, further comprising: performing object-oriented image analysis on the digital image except for in the identified blurred areas.
32. The method of claim 29, further comprising: generating image objects by segmenting the digital image except in the identified blurred areas; and determining a score using the image objects, wherein the score is indicative of a level of cancer malignancy of the cancer tissue.
33. The method of claim 29, wherein each of the pixels has a color that is a shade of gray.
34. The method of claim 29, wherein the pixelwise descriptor is a set of random forest pixelwise descriptors.
35. The method of claim 29, further comprising: determining a histopathological score based on cancer tissue stained using the biomarker in areas of the digital image that are outside the identified blurred areas.
36. The method of claim 29, wherein the biomarker is used to immunohistochemically stain for the Ki-67 protein.
37. The method of claim 29, wherein the pixelwise descriptor is a binary classifier that is trained using supervised learning.
</claims>
</document>
