<document>

<filing_date>
2019-09-10
</filing_date>

<publication_date>
2020-03-19
</publication_date>

<priority_date>
2018-09-14
</priority_date>

<ipc_classes>
B25J11/00,B25J9/16,G06T7/20,H04L12/58,H04N7/14,H04N7/15
</ipc_classes>

<assignee>
LG ELECTRONICS
</assignee>

<inventors>
SHIN, YONG KYOUNG
</inventors>

<docdb_family_id>
67956553
</docdb_family_id>

<title>
ROBOT, METHOD FOR OPERATING THE SAME, AND SERVER CONNECTED THERETO
</title>

<abstract>
A method of operating a robot includes detecting movement of a video call counterpart using a video call counterpart robot included in image data received from the video call counterpart robot; canceling movement of a user from detected movement of the video call counterpart; and determining motion corresponding to the canceled movement of the video call counterpart.
</abstract>

<claims>
1. A method of operating a robot, the method comprising: receiving image data from a video call counterpart robot, the image data including information of a video call counterpart that uses the video call counterpart robot; detecting movement of the video call counterpart based on the received image data; removing, from the detected movement of the video call counterpart, information corresponding to movement of a user; and determining motion of the robot corresponding to the detected movement of the video call counterpart having the removed information corresponding to movement of the user.
2. The method of claim 1, further comprising: receiving, from the video call counterpart robot, the information corresponding to movement of the user detected by the video call counterpart robot; and storing the received information corresponding to movement of the user.
3. The method of claim 2, wherein the determining the motion comprises determining that the video call counterpart has not moved, when there is no movement of the video call counterpart that is equal to or greater than a reference value, as a result of removing the information corresponding to movement of the user from the detected movement of the video call counterpart.
4. The method of claim 1, further comprising: performing the determined motion of the robot; and transmitting, to the video call counterpart robot, information on the detected movement of the video call counterpart.
5. The method of claim 1, further comprising: detecting movement of the user by using a camera; and storing information on the detected movement of the user.
6. The method of claim 5, wherein the determining the motion comprises determining that the video call counterpart has not moved, when the detected movement of the video call counterpart corresponds to the detected movement of the user.
7. The method of claim 5, further comprising: storing timing information on the detected movement of the user.
8. The method of claim 7, wherein the determining the motion comprises determining that the video call counterpart has not moved, when the detected movement of the video call counterpart and timing information of the detected movement of the video call counterpart correspond to the detected movement of the user and the timing information of the detected movement of the user.
9. The method of claim 1, further comprising displaying at least one of an image photographed by a camera or an image received from the video call counterpart robot.
10. The method of claim 1, further comprising: transmitting image data and speech data received from the video call counterpart robot to an emotion recognition server learned by a plurality of unimodal inputs and a multi-modal input based on the plurality of unimodal inputs; and receiving, from the emotion recognition server, an emotion recognition result of the video call counterpart for each of the plurality of unimodal inputs and an emotion recognition result of the video call counterpart for the multimodal input.
11. A robot comprising: a communication device configured to transmit and receive data with a video call counterpart robot, the received data includes image data of a video call counterpart that uses the video call counterpart robot; a display configured to display an image based on the received data; and a controller configured to: detect movement of the video call counterpart based on the received image data, remove, from the detected movement of the video call counterpart, information corresponding to movement of a user, and determine motion of the robot for responding to the detected movement of the video call counterpart having the removed information corresponding to movement of the user.
12. The robot of claim 11, wherein the controller determines that the video call counterpart has not moved, when there is no movement that is equal to or greater than a reference value, as a result of removing the information corresponding to movement of the user from the detected movement of the video call counterpart.
13. The robot of claim 11, further comprising a storage device configured to store the information corresponding to movement of the user and timing information based on movement of the user, wherein the controller determines that the video call counterpart has not moved, when the detected movement of the video call counterpart and timing information of the detected movement of the video call counterpart correspond to the movement of the user and the timing information of the movement of the user.
14. The robot of claim 11, further comprising a driving device to control the robot to have the determined motion.
15. The robot of claim 11, wherein the controller controls the communication device to transmit the detected movement of the video call counterpart to the video call counterpart robot.
16. The robot of claim 11, wherein the controller detects movement of the user by using a camera, and determines that the video call counterpart has not moved, when the detected movement of the video call counterpart corresponds to the detected movement of the user.
17. A server comprising: a communication device configured to wirelessly connect to a first robot and a second robot for a voice call; and a processor configured to: receive, through the communication device, first image data from the first robot, detect movement of a first user of the first robot from the first image data, determine a first motion corresponding to the detected movement of the first user, control the communication device to transmit, to the second robot, first motion data corresponding to the determined first motion, receive, through the communication device, second image data from the second robot, determine a second motion corresponding to movement of a second user of the second robot based on the received second image data and the detected movement of the first user, and control the communication device to transmit, to the first robot, second motion data corresponding to the determined second motion.
18. The server of claim 17, wherein the processor is configured to: detect movement of the second user based on the received second image data, remove, from the detected movement of the second user, information corresponding to the detected movement of the first user, and determine the second motion based on the detected movement of the second user having the removed information corresponding to the detected movement of the first user.
19. The server of claim 18, wherein the processor is configured to: detect that there is no movement of the second user when the detected movement of the second user corresponds to movement less than a reference value.
20. The server of claim 17, wherein the second image data is image data obtained by the second robot while performing the first motion based on the first motion data.
</claims>
</document>
