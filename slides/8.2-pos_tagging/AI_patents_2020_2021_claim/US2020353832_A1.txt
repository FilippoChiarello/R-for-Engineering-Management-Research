<document>

<filing_date>
2019-05-08
</filing_date>

<publication_date>
2020-11-12
</publication_date>

<priority_date>
2019-05-08
</priority_date>

<ipc_classes>
B60L53/12,B60L53/36,B62D15/02,G05D1/00,G05D1/02,G06N3/04
</ipc_classes>

<assignee>
BYTON NORTH AMERICA CORPORATION
</assignee>

<inventors>
SHAO, WESLEY
XIAO, XINHUA
</inventors>

<docdb_family_id>
73047031
</docdb_family_id>

<title>
DEEP NEURAL NETWORK BASED DRIVING ASSISTANCE SYSTEM
</title>

<abstract>
Deep neural network (DNN) based driving assistance system is disclosed. For one example, a vehicle data processing system includes one or more sensors and a driving assistance system. The one or more sensors obtain data describing an environment around a vehicle. The driving assistance system is coupled to the one or more sensors and configured to detect continuously a designated object in the environment around the vehicle based on the captured data from the one or more sensors using a deep neural network (DNN). The driving assistance system is also configured to output commands from the DNN used to autonomously steer the vehicle to the designated object in the environment to enable coupling of the vehicle with the designated object, e.g., a charging pad for wireless charging.
</abstract>

<claims>
1. A vehicle data processing system comprising: one or more sensors to obtain data describing an environment around a vehicle; and a driving assistance system coupled to the one or more sensors and configured to detect and track a designated object in the environment around the vehicle based on the captured data from the one or more sensors using a deep neural network (DNN), and output commands based on the detected and tracked designated object from the DNN used to autonomously steer or maneuver the vehicle to the designated object in the environment to enable coupling of the vehicle with the designated object.
2. The vehicle data processing system of claim 1, wherein the designated object includes a charging pad of a wireless charging system.
3. The vehicle data processing system of claim 1, wherein the designated object includes a trailer hitch component, cable charging component, gas filling component or other device or component for coupling with vehicle.
4. The vehicle data processing of claim 1, wherein the DNN includes a convolutional neural network (CNN) to detect the designated object in the data from the one or more sensors and a recurrent neural network (RNN) coupled to the CNN to track the designated object and output commands including steering commands, braking commands, transmission commands, switching-off motor commands, or other commands to subsystems of the vehicle.
5. The vehicle data processing system of claim 4, further comprising: a steering control system coupled to the driving assistance system and configured to receive steering commands from the RNN, and output steering signals based on the steering commands such as forward, backward, stop, velocity, yaw direction, yaw velocity, or other steering signals to respective subsystems of the vehicle to autonomously steer or maneuver the vehicle to the designated object in the environment and enable coupling of the vehicle with the designated object.
6. The vehicle data processing system of claim 4, wherein the DNN further includes a sub-network to detect one or more obstacles or other objects in the environment based on the data from the one or more sensors.
7. The vehicle data processing system of claim 6, wherein the driving assistance system is further configured to a provide a warning on a display of the vehicle.
8. The vehicle data processing system of claim 1, wherein the one or more sensors include at least one vision sensor having a camera, a light detection and ranging device (LIDAR), ultrasonic device, inertia measurement unit (IMU), and/or global positioning device (GPS) device.
9. The vehicle data processing system of claim 5, wherein the camera is to capture image data surrounding the vehicle including the designated object, the LIDAR is to measure distance to the designated object by illuminating the designated object with a laser, the ultrasonic device is to detect objects and distances using ultrasound waves, the IMU is to collect angular velocity and linear acceleration data, and the GPS device is obtain GPS data and calculate geographical positioning of the vehicle.
10. The vehicle processing system of claim 1, wherein the driving assistance system is to receive initialization information regarding location of the designated object from a database in a cloud-based system.
11. The vehicle processing system of claim 9, wherein information regarding the designated object is updated in the database.
12. A vehicle data processing system comprising: one or more sensors to obtain data describing an environment around a vehicle; and a plurality of subsystems including a driving assistance subsystem and steering control subsystem, and wherein the driving assistance system is coupled to the one or more sensors and configured to detect and track a designated object in the environment around the vehicle based on the captured data from the one or more sensors using a deep neural network (DNN), and output commands to a plurality of subsystems including the steering control system based on the detected and tracked designated object from the DNN, the steering control system receives commands from the DNN and outputs steering signals to subsystems of the vehicle to autonomously steer or maneuver the vehicle to the designated object in the environment and enable coupling of the vehicle with the designated object.
13. The vehicle of claim 12, wherein the designated object includes a charging pad of a wireless charging system.
14. The vehicle of claim 12, wherein the designated object includes a trailer hitch component, cable charging component, gas filling component or other device or component for coupling with vehicle.
15. The vehicle of claim 12, wherein the DNN includes a convolutional neural network (CNN) to detect the designated object in the data from the one or more sensors and a recurrent neural network (RNN) to track the designated object and output commands including steering commands, braking commands, transmission commands, switching-off motor commands, or other commands to subsystems of the vehicle.
16. The vehicle of claim 15, wherein the DNN further includes a sub-network to detect one or more obstacles or other objects in the environment based on the data from the one or more sensors.
17. The vehicle of claim 16, wherein the driving assistance system is further configured to a provide a warning on a display of the vehicle based on one or more detected obstacles.
18. The vehicle of claim 12, wherein the steering control system outputs steering signals such as forward, backward, stop, velocity, yaw direction, yaw velocity, or other steering signals to respective subsystems of the vehicle to autonomously steer or maneuver the vehicle to the designated object in the environment and enable coupling of the vehicle with the designated object.
19. The vehicle of claim 12, wherein the one or more sensors include at least one vision sensor having a camera, a light detection and ranging device (LIDAR), ultrasonic device, inertia measurement unit (IMU), and/or global positioning device (GPS) device.
20. The vehicle of claim 19, wherein the camera is to capture image data surrounding the vehicle including the designated object, the LIDAR is to measure distance to the designated object by illuminating the designated object with a laser, the ultrasonic device is to detect objects and distances using ultrasound waves, the IMU is to collect angular velocity and linear acceleration data, and the GPS device is to obtain GPS data and calculate geographical positioning of the vehicle.
21. The vehicle of claim 12, wherein the driving assistance system is to receive initialization information regarding location of the designated object from a database.
22. The vehicle of claim 21, wherein information regarding the designated object is updated in the database.
</claims>
</document>
