<document>

<filing_date>
2020-06-05
</filing_date>

<publication_date>
2021-01-14
</publication_date>

<priority_date>
2019-07-08
</priority_date>

<ipc_classes>
G01N21/88,G01N21/90,G06T7/00
</ipc_classes>

<assignee>
KRONES
</assignee>

<inventors>
PIANA, STEFAN
NIEDERMEIER, ANTON
SCHOBER, STEFAN
HEWICKER, ALEXANDER
</inventors>

<docdb_family_id>
71016554
</docdb_family_id>

<title>
METHOD AND DEVICE FOR INSPECTING CONTAINERS IN A CONTAINER MASS FLOW
</title>

<abstract>
The invention relates to a method (100) for inspecting containers (2) in a container mass flow. The containers (2) of the container mass flow are transported (101) by means of a conveyor (3), wherein the container mass flow is detected (102) as an image data stream by at least one camera (5), and the image data stream is evaluated (103) for faults (21) and/or foreign bodies (22) on the containers (2) by an image processing unit (7). The image data stream is evaluated by the image processing unit (7) using a deep neural network (10) in order to detect and/or localize (104) the faults (21) and/or foreign bodies (22).
</abstract>

<claims>
Ansprüche
1. Verfahren (100) zur Inspektion von Behältern (2) in einem Behältermassenstrom, wobei die Behälter (2) des Behältermassenstroms mit einem Transporteur (3) transportiert wer den (101), wobei der Behältermassenstrom mit wenigstens einer Kamera (5) als Bildda tenstrom erfasst wird (102), und wobei der Bilddatenstrom von einer Bildverarbeitungs einheit (7) auf Fehler (21) und/oder auf Fremdkörper (22) an den Behältern (2) hin aus gewertet wird (103), dadurch gekennzeichnet, dass der Bilddatenstrom von der Bildverarbeitungseinheit (7) mit einem tiefen neuronalen Netzwerk (10) ausgewertet wird, um die Fehler (21) und/oder Fremdkörper (22) zu er kennen und/oder zu lokalisieren (104).
2. Verfahren (100) nach Anspruch 1 , wobei das tiefe neuronale Netzwerk (10) eine Einga beschicht (11), eine Ausgabesicht (17) und wenigstens zwei dazwischenliegende, ver deckte Schichten (12 - 16) umfasst, und wobei der Bilddatenstrom oder vom Bilddaten strom abgeleitete Daten zunächst über die Eingabeschicht (11), dann über die wenigs tens zwei verdeckte Schichten (12 - 16) und dann über die Ausgabeschicht (17) zu Aus gabeinformationen (17.1 , 17.2) dahingehend verarbeitet werden, die Fehler (21) und/o der Fremdkörper (22) zu erkennen und/oder zu lokalisieren.
3. Verfahren (100) nach Anspruch 1 oder 2, wobei das tiefe neuronale Netzwerk (10) ein tiefes, faltendes neuronales Netzwerk mit wenigstens einer faltenden Schicht (12, 14) umfasst, insbesondere wobei die wenigstens eine faltende Schicht (12, 14) als eine ver deckte Schicht ausgebildet ist, und wobei der Bilddatenstrom, vom Bilddatenstrom abge leitete Daten und/oder bereits mit dem tiefen neuronalen Netzwerk teilweise verarbeitete Daten durch eine oder mehrere Faltungsoperation (C1 , C2) der wenigstens einen falten den Schicht (12, 14) zu gefalteten Daten verarbeitete werden.
4. Verfahren (100) nach Anspruch 3, wobei das tiefe, faltende neuronale Netzwerk (10) eine Pooling-Schicht (13, 15) umfasst, mit der für die Erkennung und/oder die Lokalisierung der Fehler und/oder Fremdkörper relevante Daten aus den gefalteten Daten ausgewählt werden. 5. Verfahren (100) nach einem der vorangegangenen Ansprüche, wobei das tiefe neuronale Netzwerk (10) mit einem Trainingsdatensatz mit Bildern von Behältern mit Trainingsfeh lern und/oder mit Trainingsfremdkörpern trainiert wird (200), so dass das tiefe neuronale Netzwerk (10) anhand des Trainingsdatensatzes ein Modell entwickelt, um die Fehler (21) und/oder Fremdkörper (22) an den Behältern (2) zu erkennen und/oder zu lokalisie ren.
6. Verfahren (100) nach Anspruch 5, wobei in den Bildern des Trainingsdatensatz die Trai ningsfehler und/oder die Trainingsfremdkörper automatisiert von der Bildverarbeitungs einheit (7), von einer weiteren Bildverarbeitungseinheit und/oder manuell von einer Bedi enperson erkannt und als Fehlermarkierungen in dem Trainingsdatensatz abgelegt wer den (204).
7. Verfahren (100) nach Anspruch 5 oder 6, wobei mit einer weiteren Bildverarbeitungsein heit einer Behälterinspektionsvorrichtung wenigstens ein Teil der Bilder für den Trainings datensatz erfasst wird (201).
8. Verfahren (100) nach einem der Ansprüche 5 - 7, wobei synthetische Fehlerund/oder Fremdkörpermuster erzeugt werden, und wobei mit den synthetischen Fehlerund/oder Fremdkörpermustern wenigstens ein Teil der Bilder des Trainingsdatensatzes erzeugt werden (202).
9. Verfahren (100) nach einem der Ansprüche 5 - 8, wobei von einem Hersteller und/oder von einem Betreiber einer Behälterverarbeitungsanlage wenigstens ein Teil der Bilder für den Trainingsdatensatz und/oder ein Fehlerkatalog erstellt wird (203).
10. Verfahren (100) nach einem der Ansprüche 5 - 9, wobei der Trainingsdatensatz Bilder von fehlerund/oder fremdkörperfreien Behältern (2) umfasst.
11. Verfahren (100) nach einem der Ansprüche 5 - 10, wobei die Bilder des T rainingsdatensatzes automatisiert vervielfältigt werden, um weitere Bilder für den Trainingsdatensatz mit Varianten der T rainingsfehler und/oder der T rainingsfremdkörper zu erstellen (205).
12. Verfahren (100) nach einem der Ansprüche 5 - 11 , wobei mit einem ersten Teil der Bilder des Trainingsdatensatzes das tiefe neuronale Netzwerk trainiert wird (206), und wobei mit einem zweiten Teil der Bilder des Trainingsdatensatzes das tiefe neuronale Netzwerk verifiziert wird (207). 13. Vorrichtung (1) zur Inspektion von Behältern (2) in einem Behältermassenstrom, insbe sondere zur Durchführung des Verfahrens (100) nach einem der Ansprüche 1 - 12, mit einem Transporteur (3) zum Transport der Behälter (2) des Behältermassen stroms, wenigstens einer Kamera (5), um den Behältermassenstrom als Bilddatenstrom zu erfassen, und mit einer Bildverarbeitungseinheit (7), um den Bilddatenstrom auf Fehler (21) und/oder auf Fremdkörper (22) an den Behältern hin auszuwerten, dadurch gekennzeichnet, dass die Bildverarbeitungseinheit (7) ein tiefes neuronales Netzwerk (10) zur Auswertung des Bilddatenstroms umfasst, um die Fehler (21) und/oder Fremdkörper (22) zu erkennen und/oder zu lokalisieren.
14. Vorrichtung (1) nach Anspruch 13, wobei die Bildverarbeitungseinheit (7) einen Signal prozessor, eine CPU, eine GPU (8), einen FPGA und/oder einen Vektorprozessor zur Durchführung von Verfahrensschritten des tiefen neuronalen Netzwerks (10) umfasst.
</claims>
</document>
