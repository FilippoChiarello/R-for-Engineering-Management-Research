<document>

<filing_date>
2018-06-29
</filing_date>

<publication_date>
2020-10-06
</publication_date>

<priority_date>
2017-12-28
</priority_date>

<ipc_classes>
G06F16/951,G06F21/44,G06F21/45,G06F21/53,G06F21/64,G06K9/00,G06K9/36,G06K9/46,G06K9/62,G06K9/64,G06K9/72,G06N3/04,G06N3/08,G06N5/02,G06T7/223,G06T7/70,H04L29/08,H04L9/06,H04L9/32,H04N19/42,H04N19/46,H04N19/625,H04N19/63,H04N19/80,H04W12/02,H04W4/70
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
CHEN YEN-KUANG
LIAO, YI-TING
NDIOUR, IBRAHIMA J.
SOMAYAZULU, VALLABHAJOSYULA, S.
TICKOO, OMESH
VARADARAJAN, SRENIVAS
YANG SHAOWEN
</inventors>

<docdb_family_id>
65230711
</docdb_family_id>

<title>
Multi-domain cascade convolutional neural network
</title>

<abstract>
In one embodiment, an apparatus comprises a communication interface and a processor. The communication interface is to communicate with a plurality of devices. The processor is to: receive compressed data from a first device, wherein the compressed data is associated with visual data captured by sensor(s); perform a current stage of processing on the compressed data using a current CNN, wherein the current stage of processing corresponds to one of a plurality of processing stages associated with the visual data, and wherein the current CNN corresponds to one of a plurality of CNNs associated with the plurality of processing stages; obtain an output associated with the current stage of processing; determine, based on the output, whether processing associated with the visual data is complete; if the processing is complete, output a result associated with the visual data; if the processing is incomplete, transmit the compressed data to a second device.
</abstract>

<claims>
1. An apparatus, comprising: a communication interface to communicate with a plurality of devices over a network; and a processor to: receive compressed data from a first device of the plurality of devices, wherein the compressed data is associated with visual data captured by one or more sensors; perform a current stage of processing on the compressed data using a current convolutional neural network (CNN), wherein the current stage of processing corresponds to one of a plurality of processing stages associated with the visual data, and wherein the current CNN corresponds to one of a plurality of convolutional neural networks (CNNs) associated with the plurality of processing stages; obtain an output associated with the current stage of processing, wherein the output is obtained from the current CNN; determine, based on the output associated with the current stage of processing, whether processing associated with the visual data is complete; upon a determination that the processing associated with the visual data is complete, output a result associated with the visual data; and upon a determination that the processing associated with the visual data is not complete, transmit the compressed data to a second device of the plurality of devices, wherein the second device is to perform a subsequent processing stage of the plurality of processing stages.
2. The apparatus of claim 1, wherein the plurality of CNNs comprise: a first convolutional neural network (CNN) trained to process one or more first types of compressed features; a second convolutional neural network (CNN) trained to process one or more second types of compressed features; and a third convolutional neural network (CNN) trained to process uncompressed visual data.
3. The apparatus of claim 2, wherein the current CNN is one of the first CNN, the second CNN, and the third CNN.
4. The apparatus of claim 2, wherein the one or more first types of compressed features comprises one or more of the following types of compressed features: motion vectors; prediction residuals; transform coefficients; quantization parameters; or macroblock coding modes.
5. The apparatus of claim 4, wherein the one or more second types of compressed features are different than the one or more first types of compressed features.
6. The apparatus of claim 5, wherein the one or more second types of compressed features and the one or more first types of compressed features are generated by different sources.
7. The apparatus of claim 1, wherein each convolutional neural network (CNN) of the plurality of CNNs is associated with a particular processing stage of the plurality of processing stages.
8. The apparatus of claim 1, wherein each processing stage of the plurality of processing stages is performed by a particular device of the plurality of devices.
9. The apparatus of claim 1, wherein the result associated with the visual data comprises a processing decision.
10. At least one non-transitory machine accessible storage medium having instructions stored thereon, wherein the instructions, when executed on a machine, cause the machine to: receive compressed data from a first device of a plurality of devices, wherein the compressed data is associated with visual data captured by one or more sensors; perform a current stage of processing on the compressed data using a current convolutional neural network (CNN), wherein the current stage of processing corresponds to one of a plurality of processing stages associated with the visual data, and wherein the current CNN corresponds to one of a plurality of convolutional neural networks (CNNs) associated with the plurality of processing stages; obtain an output associated with the current stage of processing, wherein the output is obtained from the current CNN; determine, based on the output associated with the current stage of processing, whether processing associated with the visual data is complete; upon a determination that the processing associated with the visual data is complete, output a result associated with the visual data; and upon a determination that the processing associated with the visual data is not complete, transmit the compressed data to a second device of the plurality of devices, wherein the second device is to perform a subsequent processing stage of the plurality of processing stages.
11. The storage medium of claim 10, wherein: the plurality of CNNs comprise: a first convolutional neural network (CNN) trained to process one or more first types of compressed features; a second convolutional neural network (CNN) trained to process one or more second types of compressed features, wherein the one or more second types of compressed features are different from the one or more first types of compressed features; and a third convolutional neural network (CNN) trained to process uncompressed visual data; and the current CNN is one of the first CNN, the second CNN, and the third CNN.
12. The storage medium of claim 11, wherein the one or more first types of compressed features comprises one or more of the following types of compressed features: motion vectors; prediction residuals; transform coefficients; quantization parameters; or macroblock coding modes.
13. The storage medium of claim 10, wherein each convolutional neural network (CNN) of the plurality of CNNs is associated with a particular processing stage of the plurality of processing stages.
14. A method, comprising: receiving compressed data from a first device of a plurality of devices, wherein the compressed data is associated with visual data captured by one or more sensors; performing a current stage of processing on the compressed data using a current convolutional neural network (CNN), wherein the current stage of processing corresponds to one of a plurality of processing stages associated with the visual data, and wherein the current CNN corresponds to one of a plurality of convolutional neural networks (CNNs) associated with the plurality of processing stages; obtaining an output associated with the current stage of processing, wherein the output is obtained from the current CNN; determining, based on the output associated with the current stage of processing, whether processing associated with the visual data is complete; upon a determination that the processing associated with the visual data is complete, outputting a result associated with the visual data; and upon a determination that the processing associated with the visual data is not complete, transmitting the compressed data to a second device of the plurality of devices, wherein the second device is to perform a subsequent processing stage of the plurality of processing stages.
15. The method of claim 14, wherein: the plurality of CNNs comprise: a first convolutional neural network (CNN) trained to process one or more first types of compressed features; a second convolutional neural network (CNN) trained to process one or more second types of compressed features, wherein the one or more second types of compressed features are different from the one or more first types of compressed features; and a third convolutional neural network (CNN) trained to process uncompressed visual data; and the current CNN is one of the first CNN, the second CNN, and the third CNN.
16. The method of claim 15, wherein the one or more first types of compressed features comprises one or more of the following types of compressed features: motion vectors; prediction residuals; transform coefficients; quantization parameters; or macroblock coding modes.
17. A system, comprising: one or more sensors to capture visual data; and a plurality of processing devices to: obtain compressed data corresponding to the visual data captured by the one or more sensors; extract a first set of compressed features from the compressed data; process the first set of compressed features using a first convolutional neural network (CNN), wherein the first CNN is trained to process one or more first types of compressed features; extract a second set of compressed features from the compressed data; process the second set of compressed features using a second convolutional neural network (CNN), wherein the second CNN is trained to process one or more second types of compressed features different from the one or more first types of compressed features; extract the visual data from the compressed data, wherein the visual data is extracted by decompressing the compressed data; and process the visual data using a third convolutional neural network (CNN), wherein the third CNN is trained to process raw visual data.
18. The system of claim 17, wherein the one or more first types of compressed features comprises one or more of the following types of compressed features: motion vectors; prediction residuals; transform coefficients; quantization parameters; or macroblock coding modes.
19. The system of claim 17, wherein the plurality of processing devices comprises: one or more first processing devices to process the first set of compressed features using the first CNN; one or more second processing devices to process the second set of compressed features using the second CNN; and one or more third processing devices to process the visual data using the third CNN.
20. The system of claim 19, wherein the one or more first processing devices comprises one or more edge processing devices.
21. The system of claim 19, wherein the one or more second processing devices comprises one or more fog processing devices.
22. The system of claim 19, wherein the one or more third processing devices comprises one or more cloud processing devices.
23. The system of claim 17, wherein the one or more sensors comprise one or more vision sensors, wherein the one or more vision sensors comprise at least one camera.
</claims>
</document>
