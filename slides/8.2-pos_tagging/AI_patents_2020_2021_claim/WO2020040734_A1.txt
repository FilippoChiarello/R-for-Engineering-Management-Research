<document>

<filing_date>
2018-08-21
</filing_date>

<publication_date>
2020-02-27
</publication_date>

<priority_date>
2018-08-21
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06K9/66
</ipc_classes>

<assignee>
SIEMENS
</assignee>

<inventors>
ERNST, JAN
INNANJE, ARUN
PENG, KUAN-CHUAN
WU, ZIYAN
</inventors>

<docdb_family_id>
63762952
</docdb_family_id>

<title>
ORIENTATION DETECTION IN OVERHEAD LINE INSULATORS
</title>

<abstract>
Systems, methods, and computer-readable media are described for determining the orientation of a target object in an image and iteratively reorienting the target object until an orientation of the target object is within an acceptable threshold of a target orientation. Also described herein are systems, methods, and computer-readable media for verifying that an image contains a target object.
</abstract>

<claims>
What is claimed is:
1. A computer-implemented method for detecting and correcting an orientation of a target object in an image, the method comprising: training a deep neural network using a set of training images; providing the image as input to the deep neural network, wherein the image is a segmented image; utilizing the deep neural network to determine an initial orientation prediction for the target object; and utilizing the deep neural network to obtain a rectified image from the segmented image based at least in part on the initial orientation prediction, wherein an orientation of the target object in the rectified image is within a threshold value of a target orientation.
2. The computer-implemented method of claim 1, wherein utilizing the deep neural network to obtain the rectified image comprises: determining that the initial orientation prediction deviates from the target orientation by more than the threshold value; and generating an aligned image from the segmented image.
3. The computerimplemented method of claim 2, wherein generating the aligned image comprises rotating the target object in the segmented image to the target orientation based at least in part on the initial orientation prediction to obtain the aligned image.
4. The computer-implemented method of claim 3, further comprising: determining a classification bin having a highest classification score in connection with the initial orientation prediction; determining a first neighboring bin and a second neighboring bin of the classification bin having the highest classification score; determining a first orientation associated with the first neighboring bin and a second orientation associated with the second neighboring bin; determining a first classification score of the first neighboring bin and a second classification score of the second neighboring bin; determining that the first classification score is greater than the second classification score; and determining a rotation angle by which to rotate the target object in the segmented image based at least in part on a difference between the first orientation and the target orientation and a difference between the second orientation and the target orientation.
5. The computer-implemented method of claim 4, wherein determining the rotation angle further comprises: determining that the difference between the first orientation and the target orientation is less than the difference between the second orientation and the target orientation; and determining that the rotation angle is less than the difference between the initial orientation prediction and the target orientation.
6. The computer-implemented method of claim 2, further comprising: providing the aligned image as input to the deep neural network; utilizing the deep neural network to determine a refined orientation prediction for the target object; determining that the refined orientation prediction for the target object is within the threshold value of the target orientation; and outputting the aligned image as the rectified image.
7. The computer-implemented method of claim 1, further comprising utilizing the trained deep neural network to verify that the target object is present in the segmented image.
8. A system for detecting and correcting an orientation of a target object in an image, the system comprising: at least one memory storing computer-executable instructions; and at least one processor, wherein the at least one processor is configured to access the at least one memory and execute the computer-executable instructions to: train a deep neural network using a set of training images; provide the image as input to the deep neural network, wherein the image is a segmented image; utilize the deep neural network to determine an initial orientation prediction for the target object; and utilize the deep neural network to obtain a rectified image from the segmented image based at least in part on the initial orientation prediction, wherein an orientation of the target object in the rectified image is within a threshold value of a target orientation.
9. The system of claim 8, wherein the at least one processor is configured to utilize the deep neural network to obtain the rectified image by executing the computerexecutable instructions to: determine that the initial orientation prediction deviates from the target orientation by more than the threshold value; and generate an aligned image from the segmented image.
10. The system of claim 9, wherein the at least one processor is configured to generate the aligned image by executing the computer-executable instructions to rotate the target object in the segmented image to the target orientation based at least in part on the initial orientation prediction to obtain the aligned image.
11. The system of claim 10, wherein the at least one processor is further configured to execute the computer-executable instructions to: determine a classification bin having a highest classification score in connection with the initial orientation prediction; determine a first neighboring bin and a second neighboring bin of the
classification bin having the highest classification score; determine a first orientation associated with the first neighboring bin and a second orientation associated with the second neighboring bin; determine a first classification score of the first neighboring bin and a second classification score of the second neighboring bin; determine that the first classification score is greater than the second classification score; and determine a rotation angle by which to rotate the target object in the segmented image based at least in part on a difference between the first orientation and the target orientation and a difference between the second orientation and the target orientation.
12. The system of claim 11, wherein the at least one processor is configured to determine the rotation angle by executing the computer-executable instructions to: determine that the difference between the first orientation and the target orientation is less than the difference between the second orientation and the target orientation; and determine that the rotation angle is less than the difference between the initial orientation prediction and the target orientation.
13. The system of claim 9, wherein the at least one processor is further configured to execute the computer-executable instructions to: provide the aligned image as input to the deep neural network; utilize the deep neural network to determine a refined orientation prediction for the target object; determine that the refined orientation prediction for the target object is within the threshold value of the target orientation; and output the aligned image as the rectified image.
14. The system of claim 8, wherein the at least one processor is further configured to execute the computer-executable instructions to utilize the trained deep neural network to verify that the target object is present in the segmented image.
15. A computer program product for detecting and correcting an orientation of a target object in an image comprising a storage medium readable by a processing circuit, the storage medium storing instructions executable by the processing circuit to cause a method to be performed, the method comprising: training a deep neural network using a set of training images; providing the image as input to the deep neural network, wherein the image is a segmented image; utilizing the deep neural network to determine an initial orientation prediction for the target object; and utilizing the deep neural network to obtain a rectified image from the segmented image based at least in part on the initial orientation prediction, wherein an orientation of the target object in the rectified image is within a threshold value of a target orientation.
16. The computer program product of claim 15, wherein utilizing the deep neural network to obtain the rectified image comprises: determining that the initial orientation prediction deviates from the target orientation by more than the threshold value; and generating an aligned image from the segmented image.
17. The computer program product of claim 16, wherein generating the aligned image comprises rotating the target object in the segmented image to the target orientation based at least in part on the initial orientation prediction to obtain the aligned image.
18. The computer program product of claim 17, the method further comprising: determining a classification bin having a highest classification score in connection with the initial orientation prediction; determining a first neighboring bin and a second neighboring bin of the classification bin having the highest classification score; determining a first orientation associated with the first neighboring bin and a second orientation associated with the second neighboring bin; determining a first classification score of the first neighboring bin and a second classification score of the second neighboring bin; determining that the first classification score is greater than the second classification score; and determining a rotation angle by which to rotate the target object in the segmented image based at least in part on a difference between the first orientation and the target orientation and a difference between the second orientation and the target orientation.
19. The computer program product of claim 18, wherein determining the rotation angle further comprises: determining that the difference between the first orientation and the target orientation is less than the difference between the second orientation and the target orientation; and determining that the rotation angle is less than the difference between the initial orientation prediction and the target orientation.
20. The computer program product of claim 16, further comprising: providing the aligned image as input to the deep neural network; utilizing the deep neural network to determine a refined orientation prediction for the target object; determining that the refined orientation prediction for the target object is within the threshold value of the target orientation; and
outputting the aligned image as the rectified image.
</claims>
</document>
