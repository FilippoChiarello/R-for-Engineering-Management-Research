<document>

<filing_date>
2019-03-06
</filing_date>

<publication_date>
2020-09-10
</publication_date>

<priority_date>
2019-03-06
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
PADHI, INKIT
POTDAR, SALONI
WANG, HAOYU
WANG, RUIJIAN
</inventors>

<docdb_family_id>
72334612
</docdb_family_id>

<title>
OUT-OF-DOMAIN SENTENCE DETECTION
</title>

<abstract>
A computer-implemented method includes obtaining a training data set including text data indicating one or more phrases or sentences. The computer-implemented method includes training a classifier using supervised machine learning based on the training data set and additional text data indicating one or more out-of-domain phrases or sentences. The computer-implemented method includes training an autoencoder using unsupervised machine learning based on the training data. The computer-implemented method further includes combining the classifier and the autoencoder to generate the out-of-domain sentence detector configured to generate an output indicating a classification of whether input text data corresponds to an out-of-domain sentence. The output is based on a combination of a first output of the classifier and a second output of the autoencoder.
</abstract>

<claims>
1. A computer-implemented method of training an out-of-domain sentence detector, the computer-implemented method comprising: obtaining a training data set including text data indicating one or more phrases or sentences; training a classifier using supervised machine learning based on the training data set and additional text data indicating one or more out-of-domain phrases or sentences; training an autoencoder using unsupervised machine learning based on the training data; and combining the classifier and the autoencoder to generate the out-of-domain sentence detector configured to generate an output indicating a classification of whether input text data corresponds to an out-of-domain sentence, wherein the output is based on a combination of a first output of the classifier and a second output of the autoencoder.
2. The computer-implemented method of claim 1, wherein the training data set and at least a portion of the additional text data are obtained from a customer.
3. The computer-implemented method of claim 1, wherein at least a portion of the additional text data is obtained from a pool of example sentences.
4. The computer-implemented method of claim 3, further comprising: clustering the example sentences of the pool into clusters in a feature space, wherein a distance between clusters in the feature space indicates a similarity between sentence examples in the clusters.
5. The computer-implemented method of claim 4, further comprising: obtaining an out-of-domain example sentence; mapping the out-of-domain example sentence into the feature space; and including a particular example sentence from the pool in the portion of the additional text data based on a distance in the feature space between the out-of-domain example sentence and the particular example sentence failing to satisfy a first threshold.
6. The computer-implemented method of claim 5, wherein the distance comprises a cosine distance.
7. The computer-implemented method of claim 5, wherein the distance comprises an L2 distance.
8. The computer-implemented method of claim 4, further comprising: mapping an example sentence from the training data set into the feature space; and including a particular example sentence from the pool in the portion of the additional text data based on a distance in the feature space between the example sentence and the particular example sentence satisfying a second threshold.
9. The computer-implemented method of claim 1, wherein the training data set includes a first number of training examples, wherein the additional text data includes a second number of training examples, and wherein the first number and the second number are the same.
10. The computer-implemented method of claim 1, wherein the autoencoder is configured to output a reconstruction error, and wherein the second output is based on application of a forcing function to the reconstruction error.
11. The computer-implemented method of claim 1, wherein providing the training data set to the autoencoder comprises generating one or more embedding vectors based on the training data set and providing the one or more embedding vectors to the autoencoder.
12. The computer-implemented method of claim 11, wherein the one or more embedding vectors are generated using a long short-term memory (LSTM) network, a universal sentence encoder (USE), or embeddings for language models (ELMo).
13. The computer-implemented method of claim 1, wherein the output comprises an average of the first output and a value based on the second output.
14. The computer-implemented method of claim 1, wherein the output comprises a weighted average of the first output and a value based on the second output.
15. An apparatus comprising: a processor; and a memory coupled to the processor and storing instructions that, when executed by the processor, cause the processor to perform operations comprising: obtaining a training data set including text data indicating one or more phrases or sentences; training a classifier using supervised machine learning based on the training data set and additional text data indicating one or more out-of-domain phrases or sentences; training an autoencoder using unsupervised machine learning based on the training data; and combining the classifier and the autoencoder to generate an out-of-domain sentence detector configured to generate an output indicating a classification of whether input text data corresponds to an out-of-domain sentence, wherein the output is based on a combination of a first output of the classifier and a second output of the autoencoder.
16. The apparatus of claim 15, wherein the memory is further configured to store a pool of example sentences, and wherein at least a portion of the additional text data includes one or more example sentences from the pool.
17. The apparatus of claim 15, further comprising a transmitter configured to transmit the out-of-domain sentence detector to a device for execution at the device.
18. A computer program product for training an out-of-domain sentence detector, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processor to cause the processor to perform operations comprising: obtaining, at the processor, a training data set including text data indicating one or more phrases or sentences; training, at the processor, a classifier using supervised machine learning based on the training data set and additional text data indicating one or more out-of-domain phrases or sentences; training, at the processor, an autoencoder using unsupervised machine learning based on the training data; and combining the classifier and the autoencoder to generate the out-of-domain sentence detector configured to generate an output indicating a classification of whether input text data corresponds to an out-of-domain sentence, wherein the output is based on a combination of a first output of the classifier and a second output of the autoencoder.
19. The computer program product of claim 18, wherein the operations further comprise: obtaining, at the processor, an out-of-domain example sentence; mapping, at the processor, the out-of-domain example sentence into a feature space; and including, at the processor, a particular example sentence from a pool of example sentences in the additional text data based on a distance in the feature space between the out-of-domain example sentence and the particular example sentence failing to satisfy a first threshold.
20. The computer program product of claim 18, wherein the operations further comprise: mapping, at the processor, an example sentence from a training data set into a feature space; and including, at the processor, a particular example sentence from a pool of example sentences in the additional text data based on a distance in the feature space between the example sentence and the particular example sentence satisfying a second threshold.
</claims>
</document>
