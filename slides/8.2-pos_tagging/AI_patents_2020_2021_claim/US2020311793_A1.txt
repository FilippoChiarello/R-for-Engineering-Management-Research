<document>

<filing_date>
2019-03-26
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-26
</priority_date>

<ipc_classes>
G06K9/00,G06N5/02,G06Q30/02,G06Q30/06
</ipc_classes>

<assignee>
TOSHIBA GLOBAL COMMERCE SOLUTIONS HOLDINGS CORPORATION
</assignee>

<inventors>
BROSNAN, SUSAN W.
Hawk, James
</inventors>

<docdb_family_id>
72606022
</docdb_family_id>

<title>
Method of Evaluating Body Language Using Video Analytics, Virtual Store Areas, and Machine Learning
</title>

<abstract>
A behavioral model defining a current behavior of a consumer in a retail store is generated by a computer based on digital images of the consumer captured in the retail store. The computer then analyzes the generated behavioral model relative to one or more baseline behavioral models, which consider the consumer's specific location within the store, and, based on the results of that analysis, predicts whether the consumer requires assistance. Additionally, the computer implements a learning process that allows it to determine whether the prediction was incorrect, and if so, to update the associated baseline behavioral models.
</abstract>

<claims>
1. A method for predicting whether a consumer in a retail store needs assistance, the method comprising: generating a behavioral model of a consumer in a retail store based on an image analysis of one or more digital images of the consumer at a location in the retail store, wherein the behavioral model defines a current behavior of the consumer at the location; predicting that the consumer needs assistance based on a comparison of the behavioral model to one or more baseline behavioral models stored in a memory, wherein each baseline behavioral model defines a baseline consumer behavior at corresponding locations in the retail store; and sending an alert message to an operator associated with the retail store indicating that the consumer needs assistance, wherein the alert message identifies the consumer and the location of the consumer in the retail store.
2. The method of claim 1 wherein the behavioral model is generated to comprise data indicating a body language profile of the consumer at the location of the consumer within the retail store.
3. The method of claim 2 wherein the data indicating the body language profile of the consumer indicates one or both of: a gesture made by the consumer; and a facial expression made by the consumer.
4. The method of claim 2 wherein each baseline behavioral model comprises a baseline body language profile for consumers at the location in the retail store with each baseline body language profile comprising data indicating one or both of: a baseline gesture; and a baseline facial expression.
5. The method of claim 4 further comprising: receiving feedback indicating whether the consumer needed the assistance; and updating the one or more baseline behavioral models based on the feedback.
6. The method of claim 5 wherein updating the one or more baseline behavioral models based on the feedback comprises one of: updating a negative feedback counter associated with the baseline behavioral model that was compared to the generated behavioral model if the feedback is negative feedback; and updating a positive feedback counter associated with the baseline behavioral model that was compared to the generated behavioral model if the feedback is positive feedback.
7. The method of claim 1 wherein the retail store is virtually partitioned into a plurality of sections, and wherein each section is associated with one or more baseline behavioral models, each defining a different baseline consumer behavior in that section.
8. The method of claim 1 wherein generating a behavioral model of the consumer further comprises: identifying one or more contextual indicators in the one or more digital images based on the image analysis, wherein each contextual indicator identifies an object at the location of the consumer in the retail store; and generating the behavioral model to comprise data identifying the one or more contextual indicators.
9. The method of claim 1 further comprising timestamping the behavioral model to indicate when the current behavior of the consumer was detected.
10. The method of claim 1 further comprising obtaining the one or more digital images of the consumer at the location in the retail store.
11. A computing device configured to predict whether a consumer in a retail store needs assistance, the computing device comprising: a communications interface circuit configured to communicatively connect the computing device to a communications network; and processing circuitry configured to: generate a behavioral model of a consumer in a retail store based on an image analysis of one or more digital images of the consumer at a location in the retail store, wherein the behavioral model defines a current behavior of the consumer at the location; predict that the consumer needs assistance based on a comparison of the behavioral model to one or more baseline behavioral models stored in a memory, wherein each baseline behavioral model defines a baseline consumer behavior at corresponding locations in the retail store; and send an alert message to an operator associated with the retail store indicating that the consumer needs assistance, wherein the alert message identifies the consumer and the location of the consumer in the retail store.
12. The computing device of claim 11 wherein the processing circuitry is configured to generate the behavioral model to comprise data indicating a body language profile of the consumer at the location of the consumer within the retail store.
13. The computing device of claim 12 wherein the data indicating the body language profile of the consumer indicates one or both of: a gesture made by the consumer; and a facial expression made by the consumer.
14. The computing device of claim 11 wherein the retail store is virtually partitioned into a plurality of sections, and wherein each section is associated with one or more baseline behavioral models, each defining a different baseline consumer behavior in that section.
15. The computing device of claim 11 wherein to generate a behavioral model of the consumer, the processing circuit is further configured to: identify one or more contextual indicators in the one or more digital images based on the image analysis, wherein each contextual indicator identifies an object at the location of the consumer in the retail store; and generate the behavioral model to comprise data identifying the one or more contextual indicators.
16. The computing device of claim 11 wherein the processing circuitry is further configured to timestamp the behavioral model to indicate when the current behavior of the consumer was detected.
17. The computing device of claim 11 wherein each baseline behavioral model comprises a baseline body language profile for consumers at the location in the retail store with each baseline body language profile comprising data indicating one or both of: a baseline gesture; and a baseline facial expression.
18. The computing device of claim 17 wherein the processing circuitry is further configured to: receive feedback indicating whether the consumer needed the assistance; and update the one or more baseline behavioral models based on the feedback.
19. The computing device of claim 18 wherein to update the one or more baseline behavioral models based on the feedback, the processing circuitry is further configured to: update a negative feedback counter associated with the baseline behavioral model that was compared to the generated behavioral model if the feedback is negative feedback; and update a positive feedback counter associated with the baseline behavioral model that was compared to the generated behavioral model if the feedback is positive feedback.
20. A non-transitory computer readable medium comprising executable program code that, when executed by a processing circuit in a computing device, causes the computing device to: generate a behavioral model of a consumer in a retail store based on an image analysis of one or more digital images of the consumer at a location in the retail store, wherein the behavioral model defines a current behavior of the consumer at the location; predict that the consumer needs assistance based on a comparison of the behavioral model to one or more baseline behavioral models stored in a memory, wherein each baseline behavioral model defines a baseline consumer behavior at corresponding locations in the retail store; and send an alert message to an operator associated with the retail store indicating that the consumer needs assistance, wherein the alert message identifies the consumer and the location of the consumer in the retail store.
</claims>
</document>
