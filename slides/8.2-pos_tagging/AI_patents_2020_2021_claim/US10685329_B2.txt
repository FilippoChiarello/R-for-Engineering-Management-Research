<document>

<filing_date>
2017-04-03
</filing_date>

<publication_date>
2020-06-16
</publication_date>

<priority_date>
2014-06-20
</priority_date>

<ipc_classes>
G06K9/00,G06Q10/06,G06Q10/10,G09B7/02
</ipc_classes>

<assignee>
HIREVUE
</assignee>

<inventors>
LARSEN, LOREN
TAYLOR, BENJAMIN
</inventors>

<docdb_family_id>
54870007
</docdb_family_id>

<title>
Model-driven evaluator bias detection
</title>

<abstract>
A method for detecting bias in an evaluation process is provided. The method includes operations of receiving evaluation data from a candidate evaluation system. The evaluation data is provided by a set of evaluators based on digital interview data collected from evaluation candidates. The operations of the method further include extracting indicators of characteristics of the evaluation candidates from the digital interview data, classifying the evaluation candidates based on the indicators extracted from the digital interview data, and determining whether the evaluation data indicates a bias of one or more evaluators with respect to a classification of the evaluation candidates.
</abstract>

<claims>
1. A method comprising: retrieving, by a human bias detection tool executed by a computing device of a digital interviewing platform, evaluation data from a data storage device, the evaluation data generated with respect to a set of evaluators who evaluated recorded video responses of first candidates to questions asked during a hiring process; extracting, by the human bias detection tool performing video analysis on video frames of the video responses, visual indicators of faces of the first candidates, wherein the visual indicators comprise one or more facial features; extracting, by the human bias detection tool performing spectral analysis on audio signals of the video responses, an audio indicator that further characterizes respective first candidates; generating a combined vector representation of the first candidates by combining, by the human bias detection tool, the visual indicators with the audio, wherein generating the combined vector representation comprises correlating the visual indicators with the audio indicator within a data structure for each of the respective first candidates; performing, by the human bias detection tool, supervised learning of the combined vector representation of the first candidates with respect to one or more classifications of the first candidates, to train a classification model; classifying second candidates according to a protected class by applying, by the human bias detection tool, the classification model to second indicators captured of the second candidates, wherein the second indicators comprise one or more of a second visual indicator combined with one or more of a second audio indicator of respective second candidates; determining, by the human bias detection tool, that evaluation data for the second candidates indicates a disparate impact of one or more evaluators of the set of evaluators with respect to classifications of the second candidates according to the protected class; generating, by the human bias detection tool, first data including a notification of determination of the disparate impact of the one or more evaluators; and transmitting the first data to a second computing device of a supervisor, the first data to cause a user interface of the second computing device to display a first graphical user interface (GUI) element containing the notification.
2. The method of claim 1, wherein the visual indicators further comprise relative spacing between identified features of the faces of the first candidates.
3. The method of claim 1, wherein the determining whether the evaluation data indicates the disparate impact comprises performing a relative selection rate analysis with respect to the classifications to obtain a metric of disparate impact reflected in the evaluation data for the second candidates, the method further comprising: determining, by the human bias detection tool, that the metric of the disparate impact exceeds a specified limit of relative selection rate to other groups in the hiring process, the specified limit being less than 80% of a normal selection rate, which is a limit enforced for the protected class; and generating, by the human bias detection tool, the first data to contain information regarding the determination that the metric of disparate impact exceeds the specified limit in the hiring process, wherein the information regarding the determination indicates a potential violation of an anti-discrimination law.
4. The method of claim 3, further comprising: transmitting, by the computing device, second data to the second computing device, the second data causing the second computing device to display a second GUI element that, when activated, causes the second computing device to display a prompt for additional information associated with the determination that the metric of disparate impact exceeds the specified limit in the hiring process, wherein the additional information comprises at least one of a confirmation of the determination, a rejection of the determination, or a list of actions to be taken to address the determination; and receiving, at the computing device, from the user interface of the second computing device, the additional information associated with the determination.
5. The method of claim 3, wherein generating the notification further comprises generating the information to indicate a deviation from a modeled outcome, wherein the modeled outcome represents a second set of evaluators having a metric of disparate impact that does not exceed the specified limit.
6. The method of claim 1, wherein performing the supervised learning of the combined vector representation of the first candidates comprises supplying a matrix having a column per classification of the first candidates.
7. The method of claim 1, wherein the performing the video analysis further comprises: extracting, from the video responses, additional visual indicators of human characteristics of the first candidates; and combining the additional visual indicators with the audio indicator.
8. A digital evaluation platform comprising: a data storage device to store evaluation data provided by a set of evaluators in response to evaluation of recorded video of responses of first candidates to questions asked during a hiring process; and a server device, coupled to the data storage device, to execute a human bias detection tool to: retrieve the evaluation data from the data storage device; extract visual indicators of faces of the first candidates via video analysis on video frames of the video responses, wherein the visual indicators comprise one or more facial features; extract an audio indicator for each respective first candidate via spectral analysis on audio signals of the video responses, wherein each audio indicator further characterizes respective first candidates; generate a combined vector representation of the first candidates by combining the visual indicators with the audio indicator that includes a correlation, within a data structure, between the visual indicators with the audio indicator; perform supervised learning of the combined vector representation of the first candidates with respect to one or more classifications of the first candidates, to train a classification model; classify second candidates according to a protected class by applying the classification model to second indicators captured of the second candidates, wherein the second indicators comprise one or more of a second visual indicator combined with one or more of a second audio indicator of respective second candidates; determine that evaluation data for the second candidates indicates a disparate impact of one or more evaluators of the set of evaluators with respect to classifications of the second candidates according to the protected class, to facilitate notification of a supervisor of the disparate impact; generate, first data including a notification of determination of the disparate impact of the one or more evaluators; and transmit the first data to a second computing device of a supervisor, the first data to cause a user interface of the second computing device to display a first graphical user interface (GUI) element containing the notification.
9. The digital evaluation platform of claim 8, wherein the visual indicators further comprise relative spacing between identified features of the faces of the first candidates.
10. The digital evaluation platform of claim 8, wherein to determine whether the evaluation data indicates the disparate impact comprises to perform a relative selection rate analysis with respect to the classifications to obtain a metric of disparate impact reflected in the evaluation data for the second candidates, and wherein the human bias detection tool further to: determine that the metric of the disparate impact exceeds a specified limit of relative selection rate to other groups in the hiring process, the specified limit being less than 80% of a normal selection rate, which is a limit enforced for the protected class; and generate the first data to contain information regarding the determination that the metric of disparate impact exceeds the specified limit in the hiring process, wherein the information regarding the determination indicates a potential violation of an anti-discrimination law.
11. The digital evaluation platform of claim 10, wherein the information regarding the determination indicates a deviation from a modeled outcome, the modeled outcome to represent a second set of evaluators having a metric of disparate impact that does not exceed the specified limit.
12. The digital evaluation platform of claim 10, wherein the server device is further to: transmit second data to the second computing device, the second data causing the second computing device to display a second GUI element that, when activated, causes the second computing device to display a prompt for additional information associated with the determination that the metric of disparate impact exceeds the specified limit in the hiring process, wherein the additional information comprises at least one of a confirmation of the determination, a rejection of the determination, or a list of actions to be taken to address the determination; and receive from the user interface of the second computing device the additional information associated with the determination.
13. The digital evaluation platform of claim 8, wherein to perform the supervised learning of the combined vector representation of the first candidates comprises to supply a matrix having a column per classification of the first candidates.
14. The digital evaluation platform of claim 8, wherein the human bias detection tool is further to: extract, from the video responses, additional visual indicators of human characteristics of the first candidates; and combine the additional visual indicators with the audio indicator.
15. A non-transitory computer-readable storage medium storing instructions that, when executed by a processing device, cause the processing device to perform operations comprising: retrieving, by a human bias detection tool executed by a computing device of a digital interviewing platform, evaluation data from a data storage device, the evaluation data generated with respect to a set of evaluators who evaluated recorded video responses of first candidates to questions asked during a hiring process; extracting, by the human bias detection tool performing video analysis on video frames of the video responses, visual indicators of faces of the first candidates, wherein the visual indicators comprise one or more facial features; extracting, by the human bias detection tool performing spectral analysis on audio signals of the video responses, an audio indicator that further characterizes respective first candidates; generating a combined vector representation of the first candidates by combining, by the human bias detection tool, the visual indicators with the audio, wherein generating the combined vector representation comprises correlating the visual indicators with the audio indicator within a data structure for each of the respective first candidates; performing, by the human bias detection tool, supervised learning of the combined vector representation of the first candidates with respect to one or more classifications of the first candidates, to train a classification model; classifying second candidates according to a protected class by applying, by the human bias detection tool, the classification model to second indicators captured of the second candidates, wherein the second indicators comprise one or more of a second visual indicator combined with one or more of a second audio indicator of respective second candidates; determining, by the human bias detection tool, that evaluation data for the second candidates indicates a disparate impact of one or more evaluators of the set of evaluators with respect to classifications of the second candidates according to the protected class; generating, by the human bias detection tool, first data including a notification of determination of the disparate impact of the one or more evaluators; and transmitting the first data to a second computing device of a supervisor, the first data to cause a user interface of the second computing device to display a first graphical user interface (GUI) element containing the notification.
16. The non-transitory computer-readable storage medium of claim 15, wherein the visual indicators further comprise relative spacing between identified features of the faces of the first candidates.
17. The non-transitory computer-readable storage medium of claim 15, wherein the determining whether the evaluation data indicates the disparate impact comprises performing a relative selection rate analysis with respect to the classifications to obtain a metric of disparate impact reflected in the evaluation data for the second candidates, wherein the operations further comprise: determining, by the human bias detection tool, that the metric of the disparate impact exceeds a specified limit of relative selection rate to other groups in the hiring process, the specified limit being less than 80% of a normal selection rate, which is a limit enforced for the protected class; and generating, by the human bias detection tool, the first data to contain information regarding the determination that the metric of disparate impact exceeds the specified limit in the hiring process, wherein the information regarding the determination indicates a potential violation of an anti-discrimination law.
18. The non-transitory computer-readable storage medium of claim 17, wherein the operations further comprise: transmitting, by the processing device, second data to the second computing device, the second data causing the second computing device to display a second GUI element that when activated causes the second computing device to display a prompt for additional information associated with the determination that the metric of disparate impact exceeds the specified limit in the hiring process, wherein the additional information comprises at least one of a confirmation of the determination, a rejection of the determination, or a list of actions to be taken to address the determination; and receiving, at the processing device from the user interface of the second computing device, the additional information associated with the determination.
19. The non-transitory computer-readable storage medium of claim 17, wherein the information regarding the determination indicates a deviation from a modeled outcome, wherein the modeled outcome represents a second set of evaluators having a metric of disparate impact that does not exceed the specified limit.
20. The non-transitory computer-readable storage medium of claim 15, wherein performing the supervised learning of the combined vector representation of the first candidates comprises supplying a matrix having a column per classification of the first candidates.
21. The non-transitory computer-readable storage medium of claim 15, wherein the performing the video analysis further comprises extracting, from the video responses, additional visual indicators of human characteristics of the candidates and combining the additional visual indicators with the audio indicator.
</claims>
</document>
