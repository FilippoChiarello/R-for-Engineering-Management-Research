<document>

<filing_date>
2015-12-28
</filing_date>

<publication_date>
2020-03-24
</publication_date>

<priority_date>
2015-12-28
</priority_date>

<ipc_classes>
G06F16/438,G06F3/048,G06F3/0482,G06F3/16
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
DURHAM, BRANDON SCOTT
BRAHMBHATT, KINTAN DILIPKUMAR
PAL, RICKESH
HANSON, KRISTINE ANNE
THETFORD, TED WILLIAM
</inventors>

<docdb_family_id>
69902373
</docdb_family_id>

<title>
Methods and systems for providing multi-user recommendations
</title>

<abstract>
Techniques described herein can be used to provide recommendations for multiple users. In particular, one or more users may interact with an interactive device to stream media content or utilize other services provided by a service provider. The users may provide commands to the interactive device to request content from a service provider. Contextual data associated with the request may be used to determine that an audience of the interactive device comprises more than one user. Based on this determination, content recommendations can be provided so that the recommendations are more likely to be suitable for the audience.
</abstract>

<claims>
1. A computer-implemented method, comprising: maintaining, with respect to each of a plurality of known group contexts, a contextual profile comprising a set of profile parameters for each known group context and an indication of an activity of a plurality of activities in which one or more users may be engaged; receiving, from a voice-activated device, a voice command of a first user requesting media content to be played by the voice-activated device as well as a contextual audio data corresponding to ambient sound within an environment in which the voice-activated device is located, wherein the ambient sound includes user voices as well as other sound data that is independent of media content played by the voice-activated device, and wherein the contextual audio data corresponding to the ambient sound is utilizable to determine a known group context of the plurality of known group contexts; identifying, based on a first voice associated with the voice command, the first user; determining, based on a second voice associated with the contextual audio data, a presence of a second user different from the first user within a proximity of the voice-activated device; identifying, based on the second voice associated with the contextual audio data, the second user; determining, based on the first user and the second user, the known group context of the plurality of known group contexts associated with the environment at least in part by comparing an audio feature extracted from the contextual audio data with an audio feature associated with a profile parameter of the known group context, the known group context indicating the activity of the plurality of activities in which multiple people are engaged; determining a first list of recommended media content for the first user based on a first set of attributes stored in relation to the first user and the known group context, the first list of recommended media content determined based on the activity; determining a second list of recommended media content for the second user based on a second set of attributes stored in relation to the second user and the known group context, the second list of recommended media content determined based on the activity; determining a third list of recommended media content based at least in part on the first list and the second list; and providing the third list of recommend media content to the voice-activated device.
2. The computer-implemented method of claim 1, wherein the third list of recommended media content comprises an intersection of the first list and the second list.
3. The computer-implemented method of claim 1, wherein determining the presence of the second user further comprises determining that a mobile device associated with the second user is within a predetermined distance from a predetermined location.
4. A computer-implemented method, comprising: maintaining, with respect to each of a plurality of known group contexts, a contextual profile comprising profile parameters and an indication of an activity of a plurality of activities associated with a known group context of the plurality of known group contexts; receiving a request, from a device, for media content to be played by the device; determining, based on contextual audio data corresponding to ambient sound within an environment in which the device is located, that an audience of the device comprises more than one user, wherein the ambient sound includes user voices as well as other sound data that is independent of media content played by the device, and wherein the contextual audio data corresponding to the ambient sound is utilizable to determine the known group context of the plurality of known group contexts; identifying, based on a first voice in the contextual audio data, a first set of attributes associated with a first user; identifying, based on a second voice in the contextual audio data, a second set of attributes associated with a second user; determining the known group context of the plurality of known group contexts associated with the environment by comparing audio features from the contextual audio data with audio features associated with profile parameters of the known group context, the known group context indicating the activity of the plurality of activities in which the first user and the second user are engaged; generating a recommended media content based on the first set of attributes, the second set of attributes, and the known group context, the recommended media content being selected based on one or more preferences stored in relation to the activity; and providing the recommended media content to the device.
5. The computer-implemented method of claim 4, wherein the request from the device is generated in response to a voice command.
6. The computer-implemented method of claim 4, wherein determining that the audience of the device comprises more than one user comprises detecting a presence of more than one user near the device.
7. The computer-implemented method of claim 6, wherein detecting the presence of more than one user near the device comprises identifying at least the first voice and the second voice near the device.
8. The computer-implemented method of claim 6, wherein detecting the presence of more than one user near the device comprises determining that more than one mobile devices respectively associated with at least the first user and the second user are located near the device.
9. The computer-implemented method of claim 4, wherein generating the recommended media content comprises: determining a first list of recommended media content for the first user of the audience based on preferences of the first user; determining a second list of recommended media content for the second user of the audience based on preferences of the second user; and determining the recommended media content for the device based at least in part on the first list of recommended media content and the second list of recommended media content.
10. The computer-implemented method of claim 4, wherein generating the recommended media content is further based on a type of the device.
11. The computer-implemented method of claim 4, further comprising: detecting an updated audience for the device, wherein the updated audience includes a different set of users; generating an updated recommended media content based at least in part on preferences associated with the updated audience; and providing the updated recommended media content to the device.
12. A computer system, comprising: a memory that stores computer-executable instructions; and a processor configured to access the memory and execute the computer-executable instructions to implement a method comprising: maintaining, with respect to each of a plurality of known group contexts, a contextual profile comprising a set of profile parameters for each known group context and an indication of an activity of a plurality of activities in which one or more users may be engaged; receiving a request, from a device, for media content to be played by the device; determining, based on contextual audio data corresponding to ambient sound within an environment in which the device is located, that an audience of the device comprises more than one user, wherein the ambient sound includes user voices as well as other sound data that is independent of media content played by the device, and wherein the contextual audio data corresponding to the ambient sound is utilizable to determine the known group context of the plurality of known group contexts; identifying, based on a first voice in the contextual audio data, a first set of attributes associated with a first user; identifying, based on a second voice in the contextual audio data, a second set of attributes associated with a second user; determining the known group context of the plurality of known group contexts associated with the environment by comparing audio features from the contextual audio data with audio features associated with profile parameters of the known group context, the known group context indicating the activity of the plurality of activities in which the first user and the second user are engaged; generating a recommended media content based on the first set of attributes, the second set of attributes, and the known group context, the recommended media content being selected based on preferences stored in relation to the activity; and providing the recommended media content to the device.
13. The computer system of claim 12, wherein the request from the device comprises a voice command.
14. The computer system of claim 12, wherein determining that the audience of the device comprises more than one user comprises determining that the device is under a group mode.
15. The computer system of claim 12, wherein determining the audience of the device comprises: identifying the first user of the audience; and determining a group account associated with the first user.
16. The computer system of claim 12, wherein generating the recommended media content comprises: determining a first list of recommended media content for the first user of the audience based on preferences of the first user; determining a second list of recommended media content for the second user of the audience based on preferences of the second user; and determining the recommended media content for the device based at least in part on the first list of recommended media content and the second list of recommended media content.
17. The computer system of claim 16, wherein determining the recommended media content for the device comprises selecting the recommended media content from an intersection of the first list and the second list.
18. The computer system of claim 16, wherein the preferences of the first user and preferences of the second user are determined based at least in part on feedbacks of the first user and the second user with respect to media content played by the device.
19. The computer system of claim 16, wherein generating the recommended media content is further based on demographics associated with the audience.
</claims>
</document>
