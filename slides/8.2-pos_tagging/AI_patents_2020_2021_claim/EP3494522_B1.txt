<document>

<filing_date>
2017-09-07
</filing_date>

<publication_date>
2020-01-08
</publication_date>

<priority_date>
2016-09-26
</priority_date>

<ipc_classes>
G06N20/00,G06N7/00,G06N99/00
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
BACON, DAVID MORRIS
KONECNY, JAKUB
MCMAHAN, HUGH BRENDAN
YU, XINNAN
</inventors>

<docdb_family_id>
59982468
</docdb_family_id>

<title>
COMMUNICATION EFFICIENT FEDERATED LEARNING
</title>

<claims>
1. A computer-implemented method for communication efficient machine learning, the method comprising: obtaining (402), by a client computing device, global values for a set of parameters of a machine-learned model; training (404), by the client computing device, the machine-learned model based at least in part on a local dataset to obtain an update matrix that is descriptive of updated values for the set of parameters of the machine-learned model, wherein the update matrix is restricted to be a low-rank matrix, and wherein the local dataset is stored locally by the client computing device; and communicating (406), by the client computing device, information descriptive of the update matrix to a server computing device, wherein: training, by the client computing device, the machine-learned model based at least in part on the local dataset to obtain the update matrix comprises: defining, by the client computing device, the update matrix as a product of a first matrix and a second matrix, wherein the first matrix comprises fixed values and the second matrix comprises optimizable variables; and training, by the client computing device, machine-learned model based at least in part on the local dataset to obtain the second matrix; and communicating, by the client computing device, information descriptive of the update matrix to the server computing device comprises communicating, by the client computing device, information descriptive of the second matrix to the server computing device without sending the first matrix from the client computing device to the server computing device.
2. The computer-implemented method of claim 1, further comprising, prior to training, by the client computing device, the machine-learned model:
generating, by the client computing device, the first matrix based at least in part on a seed and a pseudo-random number generator, wherein both the client computing device and the server computing device have knowledge of the seed such that the first matrix is reproducible by the server computing device.
3. The computer-implemented method of any one of the preceding claims, wherein the update matrix is restricted to be a sparse matrix.
4. The computer-implemented method of any one of the preceding claims, wherein training, by the client computing device, the machine-learned model based at least in part on the local dataset comprises training, by the client computing device, the machine-learned model based at least in part on the local dataset such that updated values are determined only for a pre-selected portion of the set of parameters, the update matrix descriptive of only the updated values for the pre-selected portion of the set of parameters.
5. The computer-implemented method of claim 4, further comprising, prior to training, by the client computing device, the machine-learned model:
generating, by the client computing device, a parameter mask that specifies which of the set of parameters are included in the pre-selected portion of the set of parameters.
6. The computer-implemented method of claim 5, wherein generating, by the client computing device, the parameter mask comprises generating, by the client computing device, the parameter mask based at least in part on a seed and a pseudo-random number generator, wherein both the client computing device and the server computing device have knowledge of the seed such that the parameter mask is reproducible by the server computing device.
7. The computer-implemented method of any one of the preceding claims, wherein the update matrix describes the updated values for the set of parameters or respective differences between the updated values and the global values.
8. A client computing device, comprising: at least one processor; and at least one non-transitory computer-readable medium that stores instructions that, when executed by the at least one processor, cause the client computing device to perform the method of any one of the preceding claims.
9. At least one non-transitory computer-readable medium that stores instructions that, when executed by a client computing device, cause the client computing device to perform the method of any one of claims 1 to 7.
</claims>
</document>
