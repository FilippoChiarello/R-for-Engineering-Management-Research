<document>

<filing_date>
2019-01-11
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2019-01-11
</priority_date>

<ipc_classes>
G01S17/06,G01S17/58,G01S17/89,G05D1/00,G05D1/02,G06N20/00
</ipc_classes>

<assignee>
ZOOX
</assignee>

<inventors>
SILVA, WILLIAM ANTHONY
WANG, CHUANG
</inventors>

<docdb_family_id>
69467780
</docdb_family_id>

<title>
Occlusion Prediction and Trajectory Evaluation
</title>

<abstract>
Techniques are discussed for controlling a vehicle, such as an autonomous vehicle, based on predicted occluded areas in an environment. An occluded area can represent areas where sensors of the vehicle are unable to sense portions of the environment due to obstruction by another object. A first occluded region for an object is determined at a first time based on a location of the object. A predicted location for the object can be used to determine a predicted occluded region caused by the object at a second time after the first time. Predicted occluded regions can be determined for multiple trajectories for the vehicle to follow and/or at multiple points along such trajectories, and a trajectory can be selected based on associated occlusion scores and/or trajectory scores associated therewith. The vehicle can be controlled to traverse the environment based on the selected trajectory.
</abstract>

<claims>
1. A system comprising: one or more processors; and one or more computer-readable media storing instructions executable by the one or more processors, wherein the instructions, when executed, cause the system to perform operations comprising: capturing sensor data of an environment using a sensor of an autonomous vehicle; determining a first trajectory for the autonomous vehicle to traverse in the environment; determining a second trajectory for the autonomous vehicle to traverse in the environment; detecting, based at least in part in the sensor data, a current position of an object in the environment; determining, based at least in part on the sensor data, a predicted location of the object; determining, based at least in part on the first trajectory and the predicted location of the object, a first occluded region associated with the object; determining, based at least in part on the second trajectory and the predicted location of the object, a second occluded region associated with the object; selecting, as a selected trajectory, the first trajectory or the second trajectory based at least in part on a first cost associated with the first occluded region or a second cost associated with the second occluded region; and controlling the autonomous vehicle based at least in part on the selected trajectory.
2. The system of claim 1, wherein the predicted location is a first predicted location associated with a first time, and wherein the operations further comprise: determining, based at least in part on the sensor data, a second predicted location of the object in the environment, the second predicted location associated with a second time after the first time; and determining, based at least in part on the first trajectory and the second predicted location, a third occluded region associated with the object; wherein selecting the first trajectory or the second trajectory is further based at least in part on a third cost associated with the third occluded region.
3. The system of claim 2, wherein: the object is a stationary object and the first predicted location corresponds to the second predicted location; or the object is a dynamic object and the first predicted location is different than the second predicted location.
4. The system of claim 1, the operations further comprising: determining an occlusion score for the first occluded region based at least in part on map data associated with the environment, wherein selecting the selected trajectory is further based on the occlusion score.
5. The system of claim 1, the operations further comprising determining, based at least in part on the predicted location of the object, multiple predicted trajectories for the object, wherein determining one or more of the multiple predicted trajectories is based at least in part on at least one of: a heat map received from a machine learning model trained to generate the heat map representing the object; a probability map based at least in part on a classification of the object, an initial position of the object, a velocity of the object; or a physics-based model associated with the object.
6. A method comprising: receiving a trajectory for a vehicle to follow in an environment; determining a predicted location for an object in the environment, the predicted location associated with a future time; determining, based at least in part on the predicted location and the trajectory, an occluded region associated with the object at the future time; and controlling the vehicle based at least in part on the occluded region.
7. The method of claim 6, further comprising: determining an occlusion score associated with the occluded region, wherein the occlusion score is based at least in part on map data.
8. The method of claim 7, further comprising determining an occlusion state and an occupancy state of an occlusion field of the occlusion grid at the future time.
9. The method of claim 6, further comprising determining an occlusion score for the occluded region based on an attribute associated with the occluded region, wherein controlling the vehicle is further based on the occlusion score for the occluded region.
10. The method of claim 6, wherein the object is a first object, the predicted location is a first predicted location, and the occluded region is a first occluded region, the method further comprising: determining a second predicted location for a second object in the environment, the second predicted location associated with the future time; and determining, based at least in part on the second predicted location and the trajectory, a second occluded region associated with the second object at the future time, wherein controlling the vehicle is further based on the second occluded region.
11. The method of claim 10, further comprising: determining a first occlusion score for the first occluded region based on a first attribute associated with the first occluded region; determining a second occlusion score for the second occluded region based on a second attribute associated with the second occluded region; and determining a trajectory score for the trajectory based at least in part on the first occlusion score and the second occlusion score, wherein controlling the vehicle is further based on the trajectory score for the trajectory.
12. The method of claim 11, wherein the trajectory is a first trajectory and the trajectory score is a first trajectory score, the method further comprising: determining a second trajectory score for a second trajectory; and selecting, as a selected trajectory, the first trajectory or the second trajectory based at least in part on the first trajectory score or the second trajectory score, wherein controlling the vehicle is further based at least in part on the selected trajectory.
13. The method of claim 11, wherein the first attribute is associated with one or more of: map data associated with the first occluded region; one or more objects in the first occluded region; a distance between a point associated with the trajectory and the first occluded region; a size of the first occluded region; a time period associated with the first occluded region; or a direction of travel associated with the vehicle;
14. The method of claim 6, wherein the predicted location of the object in the environment is based at least in part on sensor data received from one or more of a lidar sensor, a radar sensor, an image sensor, or a time of flight sensor.
15. A non-transitory computer-readable medium storing instructions that, when executed, cause one or more processors to perform operations comprising: receiving a first trajectory for a vehicle to follow in an environment; receiving a second trajectory for the vehicle to follow in the environment; determining a predicted location of an object in the environment at a future time; determining, based at least in part on the first trajectory and the predicted location of the object, a first occluded region associated with the object; determining, based at least in part on the second trajectory and the predicted location of the object, a second occluded region associated with the object; and controlling the vehicle based at least in part on the first occluded region and the second occluded region.
16. The non-transitory computer-readable medium of claim 15, wherein the predicted location is a first predicted location, the future time is a first time, and wherein the operations further comprise: determining a second predicted location of the object in the environment, the second predicted location associated with a second time after the first time; and determining, based at least in part on the first trajectory and the second predicted location, a third occluded region associated with the object; wherein controlling the vehicle is further based at least in part on the third occluded region.
17. The non-transitory computer-readable medium of claim 16, wherein: the object is a stationary object and the first predicted location corresponds to the second predicted location; or the object is a dynamic object and the first predicted location is different than the second predicted location.
18. The non-transitory computer-readable medium of claim 15, wherein the operations further comprise: determining an occlusion score for the first occluded region based at least in part on map data associated with the environment, wherein controlling the vehicle is further based on the occlusion score.
19. The non-transitory computer-readable medium of claim 15, wherein determining the predicted location of the object in the environment is based at least in part on at least one of: a heat map received from a machine learning model trained to generate the heat map representing the object; a probability map based at least in part on a classification of the object, an initial position of the object, a velocity of the object; or a physics-based model associated with the object.
20. The non-transitory computer-readable medium of claim 15, wherein determining the predicted location of the object is based at least in part on sensor data received from one or more of a lidar sensor, a radar sensor, an image sensor, or a time of flight sensor.
</claims>
</document>
