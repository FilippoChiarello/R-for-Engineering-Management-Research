<document>

<filing_date>
2020-04-03
</filing_date>

<publication_date>
2020-10-15
</publication_date>

<priority_date>
2019-04-12
</priority_date>

<ipc_classes>
G01C21/30,G01C21/36,G05D1/02,G06K9/00,G06N3/08
</ipc_classes>

<assignee>
NVIDIA CORPORATION
</assignee>

<inventors>
MULLER, URS
AKBARZADEH, AMIR
BOJARSKI, MARIUSZ
FIRNER, BERNHARD
</inventors>

<docdb_family_id>
72748809
</docdb_family_id>

<title>
NEURAL NETWORK TRAINING USING GROUND TRUTH DATA AUGMENTED WITH MAP INFORMATION FOR AUTONOMOUS MACHINE APPLICATIONS
</title>

<abstract>
In various examples, training sensor data generated by one or more sensors of autonomous machines may be localized to high definition (HD) map data to augment and/or generate ground truth data – e.g., automatically, in embodiments. The ground truth data may be associated with the training sensor data for training one or more deep neural networks (DNNs) to compute outputs corresponding to autonomous machine operations – such as object or feature detection, road feature detection and classification, wait condition identification and classification, etc. As a result, the HD map data may be leveraged during training such that the DNNs – in deployment – may aid autonomous machines in navigating environments safely without relying on HD map data to do so.
</abstract>

<claims>
What is claimed is:
1. A method comprising: receiving map data corresponding to a region including a location of a dynamic actor at a time; localizing the dynamic actor with respect to the map data; receiving sensor data generated by a sensor of the dynamic actor at the time; generating, based at least in part on the map data and the localizing, ground truth data corresponding to the sensor data; and training a neural network using the sensor data and the ground truth data.
2. The method of claim 1, wherein the generating the ground truth data includes: transforming the map data to a coordinate system of the dynamic actor; determining one or more features represented by the map data; and generating, within the coordinate system, labels or annotations corresponding to the one or more features, wherein the ground truth data is representative of the labels or the annotations.
3. The method of claim 1, further comprising determining the region including the location based at least in part on at least one of global navigation satellite system (GNSS) data, global positioning system (GPS) data, or differential GPS (DGPS) data generated by one or more location-based sensors of the dynamic actor.
4. The method of claim 1, wherein the training the neural network comprises training the neural network to perform inferencing for at least one of: object detection, feature detection, road feature detection, wait condition detection or classification, or future trajectory generation.
5. The method of claim 1, further comprising: receiving data representative of a trajectory of the dynamic actor through at least a portion of a field of view represented by the sensor data, wherein the generating the ground truth data includes adjusting the trajectory based at least in part on the HD map data.
6. The method of claim 5, wherein the adjusting the trajectory includes shifting the trajectory toward a rail of a lane of travel of the dynamic actor. 7. The method of claim 1, wherein the sensor data includes at least one of image data, LIDAR data, RADAR data, SONAR data, or ultrasonic data.
8. The method of claim 1, wherein the generating the ground truth data includes: transforming the map data from a first coordinate system of the map data to a second coordinate system of the sensor data, wherein the ground truth data corresponds to the second coordinate system.
9. The method of claim 8, wherein the first coordinate system is a threedimensional (3D) world-space coordinate system and the second coordinate system is a twodimensional (2D) image-space coordinate system. 10. A method comprising: receiving map data representative of a high definition (HD) map; receiving first sensor data generated by at least one first sensor of a dynamic actor; localizing the dynamic actor with respect to the HD map based at least in part on the first sensor data; receiving second sensor data generated by a second sensor of the dynamic actor; correlating the map data with the second sensor data based at least in part on the localizing; and generating, based at least in part on the correlating, ground truth data corresponding to the second sensor data for training a neural network.
11. The method of claim 10, wherein the correlating includes transforming the map data to a coordinate space oriented with respect to the dynamic actor.
12. The method of claim 11, wherein the correlating further includes, after the transforming, converting the map data from world-space coordinates to sensor-space coordinates corresponding to the second sensor data.
13. The method of claim 10, wherein the first sensor data is representative of one or more features within a field of view of the one or more first sensors, and the localizing the dynamic actor includes correlating the one or more features with one or more corresponding features represented by the HD map. 14. The method of claim 10, further comprising: receiving third sensor data generated by one or more third sensors of the dynamic actor and representative of a trajectory of the dynamic actor through at least a portion of a field of view represented by the second sensor data, wherein the generating the ground truth data includes adjusting the trajectory based at least in part on the map data.
15. The method of claim 10, wherein the ground truth data and outputs of the neural network are generated in three-dimensional (3D) world-space coordinates.
16. A system comprising: a sensor to generate sensor data representative of a sensor data representation; a computing device including one or more processing devices and one or more memory devices communicatively coupled to the one or more processing devices storing programmed instructions thereon, which when executed by the processor causes the instantiation of: a map manager to localize a dynamic actor with respect to a high definition (HD) map; a feature determiner to determine or more features represented by the HD map; a ground truth generator to: correlate first locations of the one or more features with second locations of the one or more features within the sensor data representation; and generate, based at least in part on the correlating, ground truth data corresponding to the second locations of the one or more features; and a training engine to train a neural network using the sensor data and the ground truth data.
17. The system of claim 16, wherein the one or more features include objects, road features, or wait conditions.
18. The system of claim 16, further comprising: a trajectory generator to generate a trajectory corresponding to a field of view of the sensor as represented by the sensor data, wherein generating the ground truth data includes adjusting the trajectory based at least in part on the one or more features. 19. The system of claim 18, wherein the one or more features includes a rail of a lane of travel of the dynamic actor.
20. The system of claim 16, wherein the map manager is further to orient the HD map with respect a location and orientation of the dynamic actor.
</claims>
</document>
