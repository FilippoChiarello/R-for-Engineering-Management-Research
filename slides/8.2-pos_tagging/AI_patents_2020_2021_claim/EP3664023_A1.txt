<document>

<filing_date>
2019-12-03
</filing_date>

<publication_date>
2020-06-10
</publication_date>

<priority_date>
2018-12-04
</priority_date>

<ipc_classes>
G06T7/00
</ipc_classes>

<assignee>
GE (GENERAL ELECTRIC COMPANY)
</assignee>

<inventors>
CHOINIERE, JEAN-PHILIPPE
HAREL, STEPHANE
BOUCHARD, STEEVES
MAROIS, MARC-ANDRE
DIWINSKY, DAVID SCOTT
KARIGIANNIS, JOHN
JAIN, ARPIT
BEWLAY, BERNARD PATRICK
BIAN, XIAO
</inventors>

<docdb_family_id>
68766614
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR WORK PIECE INSPECTION
</title>

<abstract>
An inspection system (100) includes one or more imaging devices (108) and one or more processors (104). The imaging devices generate a first set (304) of images (302) of a work piece (120) at a first position (202) relative to the work piece and a second set (306) of images of the work piece at a second position (204) relative to the work piece. At least some of the images in the first and second sets are acquired using different light settings. The processors analyze the first set of images to generate a first prediction image (504) associated with the first position, and analyze the second set of images to generate a second prediction image (704) associated with the second position. The first and second prediction images include respective candidate regions (506, 706). The processors merge the first and second prediction images to detect at least one predicted defect in the work piece depicted in at least one of the candidate regions.
</abstract>

<claims>
1. An inspection system (100) comprising: one or more imaging devices (108) configured to generate a first set (304) of images (302) of a work piece (120) at a first position (202) of the one or more imaging devices relative to the work piece and to generate a second set (306) of images of the work piece at a second position (204) relative to the work piece, wherein at least some of the images in the first set are acquired using different light settings and at least some of the images in the second set are acquired using the different light settings; and one or more processors (104) configured to obtain the first set of images and analyze the first set to generate a first prediction image (504) associated with the first position of the one or more imaging devices, the one or more processors also configured to obtain the second set of images and analyze the second set to generate a second prediction image (704) associated with the second position of the one or more imaging devices, the first and second prediction images including respective candidate regions (506, 706) that depict a potential defect in a surface (134) of the work piece, wherein the one or more processors are configured to merge the first prediction image and the second prediction image to detect at least one predicted defect in the surface of the work piece, wherein the at least one predicted defect is depicted in at least one of the candidate regions of the first and second prediction images.
2. The inspection system (100) of claim 1, further comprising multiple light sources (110) operably connected to the one or more processors (104) and configured to generate illumination light towards the surface (134) of the work piece (120), wherein the one or more processors are configured to control the light sources to provide the different light settings by one or more of changing a wavelength of the illumination light, changing an intensity of the illumination light, activating a first light source (110A) of the light sources to generate the illumination light, deactivating the first light source of the light sources to cease generating the illumination light, or changing a position of at least one of the light sources.
3. The inspection system (100) of claim 1 or 2, wherein the one or more imaging devices (108) in the second position (204) have at least one of a different location or a different angle relative to the work piece (120) than the one or more imaging devices in the first position (202).
4. The inspection system (100) of any of claims 1 to 3, wherein the one or more processors (104) are configured to analyze the first set (304) of images (302) by examining the images one at a time as inputs (302) in a forward propagation direction through layers (404) of artificial neurons in an artificial neural network (402) to generate a set (408) of defect masks (406), each defect mask in the set based on a different one of the images in the first set, wherein the one or more processors generate the first prediction image (504) by merging the defect masks in the set.
5. The inspection system (100) of claim 4, wherein the one or more processors (104) are configured to merge the defect masks (406) to generate the first prediction image (504) via a linear combination of pixels of the defect masks.
6. The inspection system (100) of any of claims 1 to 5, wherein the one or more processors (104) are configured to analyze the first set (304) of images (302) by examining the images one at a time as inputs (302) in a forward propagation direction through layers (404) of artificial neurons in an artificial neural network (402), wherein the layers include at least one long term short term memory layer (606) configured to weight features depicted in the images and to fuse information extracted from the images to generate the first prediction image (504).
7. The inspection system (100) of any of claims 1 to 6, wherein, responsive to detecting the at least one predicted defect in the surface (134) of the work piece (120), the one or more processors (104) are configured to generate a control signal configured to segregate the work piece from other work pieces that lack at least one predicted defect.
8. The inspection system (100) of any of claims 1 to 7, wherein the one or more processors (104) are configured to merge the first prediction image (504) and the second prediction image (704) by mapping the first prediction image and the second prediction image to a computer design model (708) that simulates the work piece (120), wherein the one or more processors map the first and second prediction images to the computer design model based on the first and second positions (202, 204) of the one or more imaging devices (108) relative to the work piece.
9. The inspection system (100) of any of claims 1 to 8, wherein the one or more processors (104) are configured to detect the at least one predicted defect in the surface (134) of the work piece (120) after merging the first and second prediction images (504, 704) by determining an amount of overlap between the respective candidate regions (506, 706) of the first prediction image and the respective candidate regions of the second prediction image.
10. The inspection system (100) of any of claims 1 to 9, wherein the one or more processors (104) are configured to merge the first prediction image (504) and the second prediction image (704) by examining the first and second prediction images as inputs (302) in a forward propagation direction through layers (404) of artificial neurons in an artificial neural network (402) that generates an output probability that at least one of the first and second prediction images depict a defect, wherein the one or more processors detect the at least one predicted defect in the surface (134) of the work piece (120) responsive to the output probability exceeding a designated probability threshold.
11. A method (900) for inspecting a work piece (120) for defects, the method comprising: obtaining a first set (304) of images (302) of the work piece generated by one or more imaging devices (108) at a first position (202) of the one or more imaging devices relative to the work piece, wherein at least some of the images in the first set are acquired using different light settings; obtaining a second set (306) of images of the work piece generated by the one or more imaging devices at a second position (204) of the one or more imaging devices relative to the work piece, wherein at least some of the images in the second set are acquired using the different light settings; analyzing the first set of images via one or more processors (104) to generate a first prediction image (504) associated with the first position of the one or more imaging devices, the first prediction image including a candidate region (506) that depicts a potential defect in a surface (134) of the work piece; analyzing the second set of images via the one or more processors to generate a second prediction image (704) associated with the second position of the one or more imaging devices, the second prediction image including a candidate region (706) that depicts a potential defect in the surface of the work piece; and merging the first prediction image and the second prediction image via the one or more processors to detect at least one predicted defect in the surface of the work piece, wherein the at least one predicted defect is depicted in at least one of the candidate regions of the first and second prediction images.
12. The method (900) of claim 11, further comprising modifying the light settings during the acquisition of the images (302) in the first set (304) and during the acquisition of the images in the second set (306) by one or more of changing a wavelength of illumination light directed towards the surface (134) of the work piece (120), changing an intensity of illumination light directed towards the surface of the work piece, changing a type of light source (110) that is activated, changing a position of a light source that is activated, or changing a number of light sources that are activated.
13. The method (900) of claim 11 or 12, wherein the first set (304) of images (302) is analyzed by examining the images one at a time as inputs (302) in a forward propagation direction through layers (404) of artificial neurons in an artificial neural network (402) to generate a set (408) of defect masks (406), each defect mask in the set based on a different one of the images in the first set, wherein the first prediction image (504) is generated by merging the defect masks in the set.
14. The method (900) of claim 13, wherein the defect masks (406) that are based on the images (302) in the first set (304) are merged together via a linear combination of pixels of the defect masks to generate the first prediction image (504).
15. The method (900) of any of claims 11 to 14, wherein the first set (304) of images (302) is analyzed by examining the images one at a time as inputs (302) in a forward propagation direction through layers (404) of artificial neurons in an artificial neural network (402), wherein the layers include at least one long term short term memory layer (606) configured to weight features depicted in the images and to fuse information extracted from the images to generate the first prediction image (504).
</claims>
</document>
