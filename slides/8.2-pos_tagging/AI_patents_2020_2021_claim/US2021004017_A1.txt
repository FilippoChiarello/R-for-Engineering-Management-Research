<document>

<filing_date>
2020-07-02
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2019-07-05
</priority_date>

<ipc_classes>
G01C21/34,G05D1/02,G06K9/62
</ipc_classes>

<assignee>
DEEPMAP
</assignee>

<inventors>
ZHANG, RONGHUA
COLGATE, GIL
</inventors>

<docdb_family_id>
74066741
</docdb_family_id>

<title>
USING HIGH DEFINITION MAPS FOR GENERATING SYNTHETIC SENSOR DATA FOR AUTONOMOUS VEHICLES
</title>

<abstract>
According to an aspect of an embodiment, operations may comprise accessing high definition (HD) map data of a region, presenting, via a user interface, information describing the HD map data, receiving instructions, via the user interface, for modifying the HD map data by adding one or more synthetic objects to locations in the HD map data, modifying the HD map data based on the received instructions, and generating a synthetic track in the modified HD map data comprising, for each of one or more vehicle poses, generated synthetic sensor data based on the one or more synthetic objects in the modified HD map data.
</abstract>

<claims>
1. A computer-implemented method, comprising: accessing high definition (HD) map data of a region; presenting, via a user interface, information describing the HD map data; receiving instructions, via the user interface, for modifying the HD map data by adding one or more synthetic objects to locations in the HD map data; modifying the HD map data based on the received instructions; and generating a synthetic track in the modified HD map data comprising, for each of one or more vehicle poses, generated synthetic sensor data based on the one or more synthetic objects in the modified HD map data.
2. The computer-implemented method of claim 1, wherein the synthetic track is configured to simulate a lane closure without an actual lane closure in the real world to enable testing of navigation of an autonomous vehicle along the synthetic track.
3. The computer-implemented method of claim 1, wherein the receiving of instructions, via the user interface, for modifying the HD map data further comprises receiving instructions, via the user interface, for modifying the HD map data by removing a synthetic object from a location in the HD map data.
4. The computer-implemented method of claim 1, wherein the receiving of instructions, via the user interface, for modifying the HD map data further comprises receiving instructions, via the user interface, for modifying the HD map data by moving a synthetic object from a first locations in the HD map data to a second location in the HD map data.
5. The computer-implemented method of claim 1, further comprising training a deep learning model based on synthetic track, the deep learning model configured to be used by an autonomous vehicle for navigation along a route.
6. The computer-implemented method of claim 1, wherein each of the one or more synthetic objects comprises a synthetic traffic sign, a synthetic traffic cone, a synthetic traffic light, a synthetic lane line, a synthetic curb, a synthetic barrier, or a synthetic dynamic object.
7. The computer-implemented method of claim 1, wherein the generated synthetic sensor data comprises generated synthetic LIDAR data and/or generated synthetic camera data.
8. One or more non-transitory computer-readable storage media storing instructions that in response to being executed by one or more processors, cause a computer system to perform operations, the operations comprising: accessing high definition (HD) map data of a region; presenting, via a user interface, information describing the HD map data; receiving instructions, via the user interface, for modifying the HD map data by adding one or more synthetic objects to locations in the HD map data; modifying the HD map data based on the received instructions; and generating a synthetic track in the modified HD map data comprising, for each of one or more vehicle poses, generated synthetic sensor data based on the one or more synthetic objects in the modified HD map data.
9. The one or more non-transitory computer-readable storage media of claim 8, wherein the synthetic track is configured to simulate a lane closure without an actual lane closure in the real world to enable testing of navigation of an autonomous vehicle along the synthetic track.
10. The one or more non-transitory computer-readable storage media of claim 8, wherein the receiving of instructions, via the user interface, for modifying the HD map data further comprises receiving instructions, via the user interface, for modifying the HD map data by removing a synthetic object from a location in the HD map data.
11. The one or more non-transitory computer-readable storage media of claim 8, wherein the receiving of instructions, via the user interface, for modifying the HD map data further comprises receiving instructions, via the user interface, for modifying the HD map data by moving a synthetic object from a first locations in the HD map data to a second location in the HD map data.
12. The one or more non-transitory computer-readable storage media of claim 8, further comprising training a deep learning model based on synthetic track, the deep learning model configured to be used by an autonomous vehicle for navigation along a route.
13. The one or more non-transitory computer-readable storage media of claim 8, wherein each of the one or more synthetic objects comprises a synthetic traffic sign, a synthetic traffic cone, a synthetic traffic light, a synthetic lane line, a synthetic curb, a synthetic barrier, or a synthetic dynamic object.
14. The one or more non-transitory computer-readable storage media of claim 8, wherein the generated synthetic sensor data comprises generated synthetic LIDAR data and/or generated synthetic camera data.
15. A computer system comprising: one or more processors; and one or more non-transitory computer readable media storing instructions that in response to being executed by the one or more processors, cause the computer system to perform operations, the operations comprising: accessing high definition (HD) map data of a region; presenting, via a user interface, information describing the HD map data; receiving instructions, via the user interface, for modifying the HD map data by adding one or more synthetic objects to locations in the HD map data; modifying the HD map data based on the received instructions; and generating a synthetic track in the modified HD map data comprising, for each of one or more vehicle poses, generated synthetic sensor data based on the one or more synthetic objects in the modified HD map data.
16. The computer system of claim 15, wherein the synthetic track is configured to simulate a lane closure without an actual lane closure in the real world to enable testing of navigation of an autonomous vehicle along the synthetic track.
17. The computer system of claim 15, wherein the receiving of instructions, via the user interface, for modifying the HD map data further comprises receiving instructions, via the user interface, for modifying the HD map data by removing a synthetic object from a location in the HD map data.
18. The computer system of claim 15, wherein the receiving of instructions, via the user interface, for modifying the HD map data further comprises receiving instructions, via the user interface, for modifying the HD map data by moving a synthetic object from a first locations in the HD map data to a second location in the HD map data.
19. The computer system of claim 15, further comprising training a deep learning model based on synthetic track, the deep learning model configured to be used by an autonomous vehicle for navigation along a route.
20. The computer system of claim 15, wherein each of the one or more synthetic objects comprises a synthetic traffic sign, a synthetic traffic cone, a synthetic traffic light, a synthetic lane line, a synthetic curb, a synthetic barrier, or a synthetic dynamic object.
21. The computer system of claim 15, wherein the generated synthetic sensor data comprises generated synthetic LIDAR data and/or generated synthetic camera data.
</claims>
</document>
