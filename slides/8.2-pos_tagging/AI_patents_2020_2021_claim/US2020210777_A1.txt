<document>

<filing_date>
2020-03-12
</filing_date>

<publication_date>
2020-07-02
</publication_date>

<priority_date>
2018-11-02
</priority_date>

<ipc_classes>
B60W60/00,G05D1/00,G06K9/00,G06K9/62,G06N3/08
</ipc_classes>

<assignee>
AURORA INNOVATION
</assignee>

<inventors>
VALOIS, JEAN SEBASTIEN
PILARSKI, THOMAS
MUNOZ, DANIEL
</inventors>

<docdb_family_id>
71122215
</docdb_family_id>

<title>
Generating Labeled Training Instances for Autonomous Vehicles
</title>

<abstract>
In techniques disclosed herein, machine learning models can be utilized in the control of autonomous vehicle(s), where the machine learning models are trained using automatically generated training instances. In some such implementations, a label corresponding to an object in a labeled instance of training data can be mapped to the corresponding instance of unlabeled training data. For example, an instance of sensor data can be captured using one or more sensors of a first sensor suite of a first vehicle can be labeled. The label(s) can be mapped to an instance of data captured using one or more sensors of a second sensor suite of a second vehicle.
</abstract>

<claims>
1. A method of training a machine learning model to be used in autonomous control of an autonomous vehicle, the method implemented by one or more processors and comprising: generating a plurality of training instances, wherein generating the at least one instance of the training instances comprises: receiving a first instance of sensor data captured using a first sensor suite of a first vehicle, wherein one or more objects are captured in the first instance of sensor data; receiving a second instance of sensor data collected using a second sensor suite of a second vehicle, wherein the one or more objects captured in the first instance of sensor data are captured in the second instance of sensor data, and wherein the second instance of sensor data includes one or more object labels, wherein each object label corresponds to a distinct object of the one or more objects; generating one or more object labels for the first instance of sensor data by mapping the one or more object labels included in the second instance of sensor data to one or more corresponding locations of the one or more objects in the first instance of sensor data; using the plurality of training instances, training the machine learning model by: processing the first instance of sensor data using the machine learning model to generate predicted output indicating one or more predicted object labels for one or more objects captured in the first instance of sensor data; determining a difference between the predicted output and the one or more automatically generated object labels for the first instance of sensor data; and updating one or more weights used for the machine learning model based on the determined difference.
2. The method of claim 1, wherein the machine learning model is a neural network model and wherein updating the one or more weights in the machine learning model based on the determine difference comprises: updating, using backpropagation, one or more weights in the neural network model using the determined difference.
3. The method of claim 1, wherein the one or more objects are distinct from the first vehicle and are distinct from the second vehicle.
4. The method of claim 1, wherein the first instance of sensor data collected using a first sensor suite of a first vehicle includes a corresponding first time stamp, and wherein at least one of the sensors in the sensor suite detects the second vehicle.
5. The method of claim 4, wherein the second instance of sensor data includes a corresponding second time stamp.
6. The method of claim 5, wherein the second instance of sensor data collected using the second sensor suite of the second vehicle is temporally correlated with the first instance of sensor data collected using the first sensor suite of the first vehicle by temporally correlating the first time stamp of the first instance of sensor data with the second time stamp of the second instance of sensor data.
7. The method of claim 1, wherein automatically generating the one or more object labels for the first instance of sensor data by mapping the one or more object labels included in the second instance of sensor data to one or more locations of the corresponding one or more objects in the first instance of sensor data comprises: for each object corresponding to the one or more object labels in the second instance of sensor data: determining a location of the object in the second instance of sensor data; determining a corresponding location of the object in the first instance of sensor data; and generating the object label for the first instance of sensor data by mapping the label of the object to the location of the object in the first instance of sensor data.
8. The method of claim 7, wherein determining the location of the object in the second instance of sensor data and determining the corresponding location of the object in the first instance of sensor data comprises: determining the location of the object in the second instance of sensor data with respect to a common coordinate system; and determining the corresponding location of the object in the first instance of sensor data with respect to the common coordinate system.
9. The method of claim 7, wherein determining the location of the object in the second instance of sensor data and determining the corresponding location of the object in the first instance of sensor data comprises: determining the location of the object in the second instance of sensor data with respect to a coordinate system of the second vehicle; and determining the corresponding location of the object in the first instance of sensor data with respect to the coordinate system of the second vehicle.
10. The method of claim 1, wherein the first vehicle is a first autonomous vehicle, wherein the first sensor suite of the first vehicle is a first autonomous vehicle sensor suite, and wherein the first autonomous vehicle sensor suite comprises at least a Global Positioning System (GPS) unit, a radio direction and ranging (RADAR) unit, a light detection and ranging (LIDAR) unit, one or more cameras, or an inertial measurement unit (IMU).
11. The method of claim 10, wherein the first instance of sensor data collected using the first sensor suite of the first autonomous vehicle comprises at least GPS data, RADAR data, LIDAR data, one or more images from one or more cameras, and IMU data.
12. The method of claim 10, wherein the second vehicle is a second autonomous vehicle, wherein the second sensor suite of the second vehicle is a second autonomous vehicle sensor suite.
13. The method of claim 10, wherein the second vehicle is a non-autonomous vehicle and the second sensor suite of the second vehicle is a removable hardware pod.
14. The method of claim 13, wherein the removable hardware pod is mounted onto the second vehicle.
15. The method of claim 13, wherein the removable hardware pod includes at least a GPS unit, LIDAR unit, or one or more cameras.
16. The method of claim 1, wherein generating each of the plurality of training instances further comprises: receiving a third instance of sensor data using a third sensor suite of a third vehicle, wherein the third instance of sensor data is temporally correlated with the first instance of sensor data and is temporally correlated with the second instance of sensor data, and wherein the third instance of sensor data includes one or more additional object labels corresponding to the one or more objects captured in the third instance of sensor data; and automatically generating the one or more object labels for the first instance of sensor data by mapping the one or more object labels included in the second instance of sensor data to the one or more locations of the corresponding one or more objects in the first instance of sensor data, and mapping the one or more additional object labels included in the third instance of sensor data to the one or more locations of the corresponding one or more objects in the first instance of sensor data.
17. The method of claim 16, wherein the third vehicle is a third autonomous vehicle.
18. The method of claim 16, wherein the third vehicle is an additional non-autonomous vehicle and the third sensor suite of the third vehicle is a removable hardware pod.
19. A system comprising one or more processors and memory operably coupled with the one or more processors, wherein the memory stores instructions that, in response to the execution of the instructions by one or more processors, cause the one or more processors to perform the following operations: utilizing a machine learning model in controlling an autonomous vehicle, wherein training the machine learning model comprises: generating a plurality of training instances, wherein generating at least one instance of the training instances comprises: receiving a first instance of sensor data collected using a first sensor suite of a first vehicle; receiving a second instance of sensor data collected using a second suite of a second vehicle, wherein the second instance of sensor data collected using the second sensor suite of the second vehicle is temporally correlated with the first instance of sensor data collected using the first sensor suite of the first vehicle, and wherein the second instance of sensor data includes one or more object labels corresponding to one or more objects captured in the second instance of sensor data; automatically generating one or more object labels for the first instance of sensor data by mapping the one or more object labels included in the second instance of sensor data to one or more locations of the corresponding one or more objects in the first instance of sensor data; using the plurality of training instances, training the machine learning model by: processing the first instance of sensor data collected using the first sensor suite of the first vehicle using the machine learning model to generate predicted output; determining a difference between the predicted output and the one or more automatically generated object labels for the first instance of sensor data; and updating one or more weights used for the machine learning model based on the determined difference.
20. At least one non-transitory computer-readable medium comprising instructions that, in response to execution of the instructions by one or more processors, cause one or more processors to perform the following operations: utilizing a machine learning model in controlling an autonomous vehicle, wherein training the machine learning model comprises: generating a plurality of training instances, wherein generating at least one instance of the plurality of training instances comprises: receiving a first instance of sensor data collected using a first sensor suite of a first vehicle; receiving a second instance of sensor data collected using a second suite of a second vehicle, wherein the second instance of sensor data collected using the second sensor suite of the second vehicle is temporally correlated with the first instance of sensor data collected using the first sensor suite of the first vehicle, and wherein the second instance of sensor data includes one or more object labels corresponding to one or more objects captured in the second instance of sensor data; automatically generating one or more object labels for the first instance of sensor data by mapping the one or more object labels included in the second instance of sensor data to one or more locations of the corresponding one or more objects in the first instance of sensor data; for each training instance in the plurality of training instances, training the machine learning model by: processing the first instance of sensor data collected using the first sensor suite of the first vehicle using the machine learning model to generate predicted output; determining a difference between the predicted output and the one or more automatically generated object labels for the first instance of sensor data; and updating one or more weights in the machine learning model based on the determined difference.
21. A method of training a machine learning model with targeted training instances to be used in autonomous control of at least one autonomous vehicle, the method comprising: generating a plurality of targeted training instances, wherein generating each of the targeted training instances includes: generating autonomous vehicle training input of the targeted training instances based on an instance of autonomous vehicle data wherein at least one of the sensors of an autonomous vehicle sensor suite detects an additional vehicle; generating a label of the autonomous vehicle training input indicating a current state of at least one attribute of the additional vehicle using a determined corresponding instance of additional vehicle data which temporally corresponds with the instance of autonomous vehicle data detecting the additional vehicle, wherein at least one of the sensors in an additional vehicle sensor suite detects the at least one attribute of the additional vehicle and is related to the mobility of the additional vehicle; generating the trained machine learning model by: applying the autonomous vehicle data portion of the targeted training instances as training input to the machine learning model to generate predicted output of the machine learning model; and updating one or more weights in the machine learning model by determining a difference between the predicted output and the label of the targeted training instances.
</claims>
</document>
