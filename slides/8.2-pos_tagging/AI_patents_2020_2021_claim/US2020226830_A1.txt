<document>

<filing_date>
2019-12-19
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2016-11-11
</priority_date>

<ipc_classes>
G02B27/00,G02B27/01,G06K9/00,G06T13/40,G06T17/20,G10L21/10
</ipc_classes>

<assignee>
MAGIC LEAP
</assignee>

<inventors>
KAEHLER, ADRIAN
</inventors>

<docdb_family_id>
62108639
</docdb_family_id>

<title>
PERIOCULAR AND AUDIO SYNTHESIS OF A FULL FACE IMAGE
</title>

<abstract>
Systems and methods for synthesizing an image of the face by a head-mounted device (HMD) are disclosed. The HMD may not be able to observe a portion of the face. The systems and methods described herein can generate a mapping from a conformation of the portion of the face that is not imaged to a conformation of the portion of the face observed. The HMD can receive an image of a portion of the face and use the mapping to determine a conformation of the portion of the face that is not observed. The HMD can combine the observed and unobserved portions to synthesize a full face image.
</abstract>

<claims>
1. (canceled)
2. (canceled)
3. (canceled)
4. (canceled)
5. (canceled)
6. (canceled)
7. (canceled)
8. (canceled)
9. (canceled)
10. (canceled)
11. (canceled)
12. (canceled)
13. (canceled)
14. (canceled)
15. (canceled)
16. (canceled)
17. (canceled)
18. (canceled)
19. (canceled)
20. (canceled)
21. A computerized method, performed by a computing system having one or more hardware computer processors and one or more non-transitory computer readable storage device storing software instructions executable by the computing system to perform the computerized method comprising: accessing a first plurality of images each associated with first conformations of a first region of a corresponding user of a plurality of users, wherein each of the first plurality of images do not include a second region of the faces of the plurality of users; accessing a second plurality of images associated with second conformations of a second region of a corresponding user of the plurality of users, wherein each of the first conformations of the first region is associated with at least one of the second conformations of the second region; and training a machine learning derived model using the first plurality of images and the second plurality of images to generate a mapping from a first conformation of the first region to a second conformation of the second region, wherein the mapping is configured to receive, as an input, an image of the first region of a face of a person that does not include the second region of the face of the person.
22. The method of claim 21, wherein the first region is a periocular region and the second region is a full face or a lower face region.
23. The method of claim 21, wherein the first region is a lower face region and the second region is a full face or a periocular region.
24. The method of claim 23, wherein the image of the first region of the face of the person comprises an image of the lower face region acquired by at least one of: an outward-facing imaging system of a head-mounted device or a camera external to the outward-facing imaging system.
25. The method of claim 22, wherein the image of the first region of the face of the person comprises an image acquired by an inward-facing imaging system of a head-mounted device.
26. The method of claim 21, wherein the first conformation and the second conformation are encoded by face parameters.
27. The method of claim 26, wherein the face parameters are part of a three-dimensional (3D) face model.
28. The method of claim 21, wherein the machine learning derived model comprises a likelihood that the first conformation of the first region matches the second conformation of the second region.
29. The method of claim 21, wherein the machine learning derived model is further trained using at least one of: an audio stream associated with the first plurality of images and the second plurality of images, or eye specific information.
30. The method of claim 21, wherein the mapping comprises an input comprising conformation of a lower face of the person and an output comprising conformations of the periocular region.
31. The method of claim 21, further comprising communicating the mapping to a wearable device to generate an image of the periocular region based on an image of the lower face of the person.
32. A computing system comprising: a hardware computer processor; a non-transitory computer readable medium having software instructions stored thereon, the software instructions executable by the hardware computer processor to cause the computing system to perform operations comprising: access a first plurality of images each associated with first conformations of a first region of a corresponding user of a plurality of users, wherein each of the first plurality of images do not include a second region of the faces of the plurality of users; access a second plurality of images associated with second conformations of a second region of a corresponding user of the plurality of users, wherein each of the first conformations of the first region is associated with at least one of the second conformations of the second region; and train a machine learning derived model using the first plurality of images and the second plurality of images to generate a mapping from a first conformation of the first region to a second conformation of the second region, wherein the mapping is configured to receive, as an input, an image of the first region of a face of a person that does not include the second region of the face of the person.
33. The system of claim 32, wherein the first region is a periocular region and the second region is a full face or a lower face region.
34. The system of claim 32, wherein the first region is a lower face region and the second region is a full face or a periocular region.
35. The system of claim 34, wherein the image of the first region of the face of the person comprises an image of the lower face region acquired by at least one of: an outward-facing imaging system of a head-mounted device or a camera external to the outward-facing imaging system.
36. The system of claim 33, wherein the image of the first region of the face of the person comprises an image acquired by an inward-facing imaging system of a head-mounted device.
37. The system of claim 32, wherein the first conformation and the second conformation are encoded by face parameters.
38. The system of claim 37, wherein the face parameters are part of a three-dimensional (3D) face model.
39. The system of claim 32, wherein the machine learning derived model comprises a likelihood that the first conformation of the first region matches the second conformation of the second region.
40. The system of claim 32, wherein the machine learning derived model is further trained using at least one of: an audio stream associated with the first plurality of images and the second plurality of images, or eye specific information.
41. The system of claim 32, wherein the mapping comprises an input comprising conformation of a lower face of the person and an output comprising conformations of the periocular region.
42. The system of claim 32, wherein the software instructions are further configure to communicate the mapping to a wearable device to generate an image of the periocular region based on an image of the lower face of the person.
</claims>
</document>
