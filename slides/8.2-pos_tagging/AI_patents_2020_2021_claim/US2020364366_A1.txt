<document>

<filing_date>
2019-05-15
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-15
</priority_date>

<ipc_classes>
G06F21/62,G06N3/04,G06Q50/26
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
NATARAJAN, ARJUN
KUNDU, ASHISH
SINGH, KAPIL KUMAR
PAYNE, JOSHUA F.
</inventors>

<docdb_family_id>
73231199
</docdb_family_id>

<title>
DEEP LEARNING-BASED IDENTITY FRAUD DETECTION
</title>

<abstract>
A method provides a security action based on identity profile scores. One or more processors represent an identity profile as a knowledge graph. The processor(s) associate a set of changes of the identity profile across a plurality of identity networks with a fraud score. The processor(s) then implement a security action based on the fraud score.
</abstract>

<claims>
1. A method comprising: representing, by one or more processors, an identity profile as a knowledge graph; associate, by one or more processors, a set of changes of the identity profile across a plurality of identity networks with a fraud score; and implementing, by one or more processors, a security action based on the fraud score.
2. The method of claim 1, wherein the knowledge graph is a graph neural network.
3. The method of claim 1, wherein each node in the knowledge graph is represented as a node vector, and wherein the method further comprises: representing, by one or more processors, a neighborhood of said each node in the knowledge graph as a neighborhood vector, wherein changes to the identity profile are determined by detecting changes in the neighborhood vector over time; and determining, by one or more processors, that the identity profile is fraudulent based on the changes in the neighborhood vector over time.
4. The method of claim 1, further comprising: calculating, by one or more processors, a similarity score for multiple nodes in the knowledge graph; determining, by one or more processors, a correlation between two nodes in the knowledge graph as having a same similarity score; and determining, by one or more processors, that the identity profile is fraudulent based on the two nodes in the knowledge graph having the same similarity score.
5. The method of claim 4, further comprising: aggregating, by one or more processors, the fraud score, the similarity score, and a base score for each node; and further determining, by one or more processors, that the identity profile is fraudulent based on an aggregation of the fraud score, the similarity score, and the base score for each node.
6. The method of claim 1, wherein the fraud score exceeds a predefined value, and wherein the security action is blocking a release of the identity profile to a requester of the identity profile.
7. A computer program product comprising a computer readable storage medium having program code embodied therewith, wherein the computer readable storage medium is not a transitory signal per se, and wherein the program code is readable and executable by a processor to perform a method comprising: representing an identity profile as a knowledge graph; associating a set of changes of the identity profile across a plurality of identity networks with a fraud score; and implementing a security action based on the fraud score.
8. The computer program product of claim 7, wherein the knowledge graph is a graph neural network.
9. The computer program product of claim 7, wherein each node in the knowledge graph is represented as a node vector, and wherein the method further comprises: representing a neighborhood of said each node in the knowledge graph as a neighborhood vector, wherein changes to the identity profile are determined by detecting changes in the neighborhood vector over time; and determining that the identity profile is fraudulent based on the changes in the neighborhood vector over time.
10. The computer program product of claim 7, wherein the method further comprises: calculating a similarity score for multiple nodes in the knowledge graph; determining a correlation between two nodes in the knowledge graph as having a same similarity score; and determining that the identity profile is fraudulent based on the two nodes in the knowledge graph having the same similarity score.
11. The computer program product of claim 10, wherein the method further comprises: aggregating the fraud score, the similarity score, and a base score for each node; and further determining that the identity profile is fraudulent based on an aggregation of the fraud score, the similarity score, and the base score for each node.
12. The computer program product of claim 7, wherein the fraud score exceeds a predefined value, and wherein the security action is blocking a release of the identity profile to a requester of the identity profile.
13. The computer program product of claim 7, wherein the program code is provided as a service in a cloud environment.
14. A computer system comprising one or more processors, one or more computer readable memories, and one or more computer readable non-transitory storage mediums, and program instructions stored on at least one of the one or more computer readable non-transitory storage mediums for execution by at least one of the one or more processors via at least one of the one or more computer readable memories, the stored program instructions executed to perform a method comprising: representing an identity profile as a knowledge graph; associating a set of changes of the identity profile across a plurality of identity networks with a fraud score; and implementing a security action based on the fraud score.
15. The computer system of claim 14, wherein the knowledge graph is a graph neural network.
16. The computer system of claim 14, wherein each node in the knowledge graph is represented as a node vector, and wherein the method further comprises: representing a neighborhood of said each node in the knowledge graph as a neighborhood vector, wherein changes to the identity profile are determined by detecting changes in the neighborhood vector over time; and determining that the identity profile is fraudulent based on the changes in the neighborhood vector over time.
17. The computer system of claim 14, wherein the method further comprises: calculating a similarity score for multiple nodes in the knowledge graph; determining a correlation between two nodes in the knowledge graph as having a same similarity score; and determining that the identity profile is fraudulent based on the two nodes in the knowledge graph having the same similarity score.
18. The computer system of claim 17, wherein the method further comprises: aggregating the fraud score, the similarity score, and a base score for each node; and further determining that the identity profile is fraudulent based on an aggregation of the fraud score, the similarity score, and the base score for each node.
19. The computer system of claim 14, wherein the fraud score exceeds a predefined value, and wherein the security action is blocking a release of the identity profile to a requester of the identity profile.
20. The computer system of claim 14, wherein the stored program instructions are provided as a service in a cloud environment.
</claims>
</document>
