<document>

<filing_date>
2020-01-13
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2019-01-14
</priority_date>

<ipc_classes>
F03D17/00,G01H1/00,G01J5/00,G06K9/00,G06N20/00,G06N5/04,H04N7/18
</ipc_classes>

<assignee>
OREGON STATE UNIVERSITY
</assignee>

<inventors>
ALBERTANI, ROBERT
JOHNSTON, MATTHEW
HU, CONGCONG
CLOCKER, KYLE
MAURER, WILLIAM GAGE
</inventors>

<docdb_family_id>
71516699
</docdb_family_id>

<title>
APPARATUS AND AMENDMENT OF WIND TURBINE BLADE IMPACT DETECTION AND ANALYSIS
</title>

<abstract>
A multisensory system provides both temporal and spatial coverage capacities for auto-detection of bird collision events. The system includes an apparatus having a first circuitry to capture and store a series of images or video of a blade of a wind turbine; and a memory to store the images from the first circuitry. The apparatus also has one or more sensors to continuously sense vibration of the blade or for acoustic recordings; and a second circuitry to analyze the sensor data stream and/or the series of images or video to identify a cause of the vibration and to trigger the camera(s). A communication interface transmits data from the second circuitry to another device, wherein the second circuitry applies artificial intelligence or machine learning to control sensitivity of the one or more sensors.
</abstract>

<claims>
1. A first apparatus comprising: a first circuitry to capture and store a series of images or video of a blade of a wind turbine; a memory to store the series of images of video from the first circuitry; one or more sensors to continuously sense vibration of the blade or for acoustic recordings; a second circuitry to analyze a data stream from the one or more sensors and/or the stored series of images of video, and to apply machine-learning or statistical analysis to the data stream from the one or more sensors; and a communication interface to transmit data from the second circuitry to a second apparatus.
2. The first apparatus of claim 1, wherein the second circuitry is to determine when an object likely struck the blade.
3. The first apparatus of claim 2, wherein the second circuitry is to save a portion of the data stream that indicates when the object likely struck the blade.
4. The first apparatus of claim 3, wherein the second circuitry is to discard another portion of the data stream that does not indicate when the object likely struck the blade.
5. The first apparatus of claim 1, wherein the first circuitry includes one or more of: a visual camera, or an infrared camera, and wherein the visual camera or the infrared camera are installed on the blade of the wind turbine.
6. The first apparatus of claim 1, wherein the first circuitry is to reuse memory space to store the series of images or video of the blade.
7. The first apparatus of claim 1 comprises a battery to power the first circuitry, the second circuitry, the memory, the one or more sensors, and the communication interface.
8. The first apparatus of claim 1 comprises a power supply connected with a power system in a hub of the wind turbine.
9. The first apparatus of claim 1, wherein the one or more sensors include one or more of: a 3-axis accelerometer, a piezoelectric contact microphone, gyroscope, or one or more sensors for acoustic recordings.
10. The first apparatus of claim 1, wherein the communication interface includes one of Bluetooth, Wi-Fi, 5G, or LTE.
11. The first apparatus of claim 1, wherein the one or more sensors includes a vibration sensor, which is to trigger the first circuitry to capture the image.
12. The first apparatus of claim 1, wherein the second apparatus is in a cloud, and wherein the second circuitry is to: pre-process the data stream with continuous wavelet transform (CWT); generate a time marginal integration (TMI) graph by calculating the energy distribution in the CWT with respect to time; and extract features from the TMI graph.
13. A non-tangible machine-readable storage medium having machine-readable storage instructions that, when executed, cause one or more machines to perform a method comprising: capturing a series of images or video of a blade of a wind turbine; storing the series of images or video in a memory; continuously sensing, by one or more sensors, vibration of the blade or for acoustic recordings; analyzing a data stream from the one or more sensors and/or the stored images or video by applying machine-learning or statistical analysis to the data stream from the one or more sensors; identifying from the analyzed data stream and the applied machine-learning or statistical analysis when an object struck the blade; saving a portion of the data stream indicative of when the object struck the blade; and transmitting the portion of the data stream to a device.
14. The non-tangible machine-readable storage medium of claim 13 having machine-readable storage instructions that, when executed, cause the one or more machines to perform the method comprising: discarding another portion of the data stream that does not indicate when the object likely struck the blade; and reusing memory space to store the series of images or video of the blade.
15. The non-tangible machine-readable storage medium of claim 13, wherein analyzing the data stream from the one or more sensors by applying machine-learning to control sensitivity of the one or more sensors, comprises: pre-processing the data stream with continuous wavelet transform (CWT); generating a time marginal integration (TMI) graph by calculating the energy distribution in the CWT with respect to time; and extracting features from the TMI graph.
16. The non-tangible machine-readable storage medium of claim 13, wherein transmitting the portion of the data stream to the device is via one of Bluetooth, Wi-Fi, 5G, or LTE.
17. A method comprising: capturing a series of images or video of a blade of a wind turbine; storing the series of images or video in a memory; continuously sensing, by one or more sensors, vibration of the blade or for acoustic recordings; analyzing a data stream from the one or more sensors and/or the stored images or video by applying machine-learning or statistical analysis to the data stream from the one or more sensors; identifying from the analyzed data stream and the applied machine-learning when an object struck the blade; saving a portion of the data stream indicative of when the object struck the blade; and transmitting the portion of the data stream to a device.
18. The method of claim 17 comprising discarding another portion of the data stream that does not indicate when the object likely struck the blade.
19. The method of claim 17, wherein the one or more sensors include one or more of: a 3-axis accelerometer, a piezoelectric contact microphone, gyroscope, one or more sensors for acoustic recordings, or a vibration sensor, which is to trigger the first circuitry to capture the image.
20. The method of claim 17, wherein analyzing the data stream from the one or more sensors by applying machine-learning to control sensitivity of the one or more sensors, comprises: pre-processing the data stream with continuous wavelet transform (CWT); generating a time marginal integration (TMI) graph by calculating the energy distribution in the CWT with respect to time; and extracting features from the TMI graph.
</claims>
</document>
