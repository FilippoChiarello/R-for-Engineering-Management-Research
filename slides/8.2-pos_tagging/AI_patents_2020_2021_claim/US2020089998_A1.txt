<document>

<filing_date>
2018-09-21
</filing_date>

<publication_date>
2020-03-19
</publication_date>

<priority_date>
2018-09-19
</priority_date>

<ipc_classes>
G06K9/54,G06K9/62,G06N3/04,G06N3/08,G06T11/60,G06T3/40,G06T5/00,G06T5/30,G06T5/50
</ipc_classes>

<assignee>
ABBYY PRODUCTION
</assignee>

<inventors>
ZAGAYNOV, IVAN GERMANOVICH
BORIN, PAVEL VALERYEVICH
</inventors>

<docdb_family_id>
69007082
</docdb_family_id>

<title>
Training image-processing neural networks by synthetic photorealistic indicia-bearing images
</title>

<abstract>
Systems and methods for training image processing neural networks by synthetic photorealistic indicia-bearing images. An example method comprises: generating an initial set of images, wherein each image of the initial set of images comprises a rendering of a text string; producing an augmented set of images by processing the initial set of images to introduce, into each image of the initial set of image, at least one simulated image defect; generating a training dataset comprising a plurality of pairs of images, wherein each pair of images comprises a first image selected from the initial set of images and a second image selected from the augmented set of images; and training, using the training dataset, a convolutional neural network for image processing.
</abstract>

<claims>
1. A method, comprising: generating, by a computer system, an initial set of images, wherein each image of the initial set of images comprises a rendering of a text string; producing an augmented set of images by processing the initial set of images to introduce, into each image of the initial set of image, at least one simulated image defect; generating a training dataset comprising a plurality of pairs of images, wherein each pair of images comprises a first image selected from the initial set of images and a second image selected from the augmented set of images; and training, using the training dataset, a convolutional neural network for image processing.
2. The method of claim 1, wherein processing the initial set of images further comprises: superimposing, on a generated image, a transparent image of a pre-defined or randomly generated text.
3. The method of claim 1, wherein processing the initial set of images further comprises: de-contrasting a generated image to reduce a maximum difference in luminance of pixels of the generated image by a pre-defined value.
4. The method of claim 1, wherein processing the initial set of images further comprises: simulating an additional light source in a scene of a generated image by additively applying, to at least a subset of pixels of the generated image, low frequency Gaussian noise of a low amplitude.
5. The method of claim 1, wherein processing the initial set of images further comprises: de-focusing a generated image by applying, to at least a subset of pixels of a generated image, Gaussian blur.
6. The method of claim 1, wherein processing the initial set of images further comprises: simulating movement of imaged objects in a generated image by superimposing a motion blur on the generated image.
7. The method of claim 1, wherein processing the initial set of images further comprises: applying, to at least a subset of pixels of a generated image, a simulated digital noise.
8. The method of claim 1, wherein processing the initial set of images further comprises: simulating camera pre-processing of a generated image by applying a filter to at least a subset of pixels of the generated image.
9. The method of claim 1, wherein processing the initial set of images further comprises: simulating de-mosaicing of a generated image by applying Gaussian blur to at least a subset of pixels of the generated image.
10. The method of claim 1, wherein the convolutional neural network comprises: a preprocessing branch including a set of convolution filters performing local transformations of an input image, and a context branch including multiple convolution layers which reduce the input image by a scaling factor and multiple trans-convolution layers for enlarging the image by the scaling factor.
11. The method of claim 10, wherein training the convolutional neural network is performed using a hinge loss function.
12. The method of claim 1, wherein the convolutional neural network comprises multiple convolution layers which implement dilated convolution operators with various dilation parameter values.
13. The method of claim 12, wherein training the convolutional neural network further comprises: determining a per-parameter training rate by calculating an exponential moving average of a gradient and a squared gradient of an input signal.
14. The method of claim 1, further comprising: utilizing the convolution neural network for image pre-processing for an optical character recognition (OCR) application.
15. The method of claim 1, further comprising: generating a classification convolutional neural network for classifying a set of input images into a first class comprising synthetic images and a second class comprising real photo images.
16. The method of claim 15, wherein generating a classification convolutional neural network comprises modifying a convolution neural network utilized for image pre-processing.
17. The method of claim 15, further comprising: utilizing the classification convolutional neural network for filtering the training data set.
18. A system, comprising: a memory; a processor, coupled to the memory, the processor configured to: generate an initial set of images, wherein each image of the initial set of images comprises a rendering of a text string; produce an augmented set of images by processing the initial set of images to introduce, into each image of the initial set of image, at least one simulated image defect; generate a training dataset comprising a plurality of pairs of images, wherein each pair of images comprises a first image selected from the initial set of images and a second image selected from the augmented set of images; and train, using the training dataset, a convolutional neural network for image processing.
19. A computer-readable non-transitory storage medium comprising executable instructions that, when executed by a processing device, cause the processing device to: generate an initial set of images, wherein each image of the initial set of images comprises a rendering of a text string; produce an augmented set of images by processing the initial set of images to introduce, into each image of the initial set of image, at least one simulated image defect; generate a training dataset comprising a plurality of pairs of images, wherein each pair of images comprises a first image selected from the initial set of images and a second image selected from the augmented set of images; and train, using the training dataset, a convolutional neural network for image processing.
20. The computer-readable non-transitory storage medium of claim 19, further comprising executable instructions causing the processing device to: generate a classification convolutional neural network for classifying a set of input images into a first class comprising synthetic images and a second class comprising real photo images.
</claims>
</document>
