<document>

<filing_date>
2017-09-28
</filing_date>

<publication_date>
2020-06-09
</publication_date>

<priority_date>
2017-09-28
</priority_date>

<ipc_classes>
G06K9/00,G06K9/34,G06K9/40,G06K9/46,G06K9/62,G06N20/00,G06N99/00,G06Q20/18,G06Q20/40
</ipc_classes>

<assignee>
NCR CORPORATION
</assignee>

<inventors>
LICHT, YEHOSHUA ZVI
VELTMAN, NIR
HECKER, WESTON LEE
</inventors>

<docdb_family_id>
63642915
</docdb_family_id>

<title>
Self-Service Terminal (SST) facial authentication processing
</title>

<abstract>
Real-time facial recognition is augmented with a machine-learning process that samples pixels from images captured for the physical environmental background of a device, which captures an image of a user's face for facial authentication. The background pixel points that are present in a captured image of a user's face from a camera of the device are authenticated with the image of the user's face. The value of the background pixel points are compared against the expected values for the background pixel points provided by the on-going machine-learning process for the background.
</abstract>

<claims>
1. A method, comprising: sampling pixels of an image that is captured of a user, the pixels comprising image representations of both a background and a face of the user; identifying from background pixels selected from the pixels that are associated with background environmental objects and obtaining background conditions, wherein identifying further includes separating permanent objects associated with the background from non-permanent objects associated with the background based on applying the background conditions to the background pixels; authenticating the user for access to a resource based on face pixels that are selected from the pixels and based on the permanent objects separated from the non-permanent objects in the background pixels: 1) when face pixel values for the face pixels_are within a threshold of expected face pixel values for the face of the user and 2) when permanent object pixel values associated with the permanent objects are determined to be expected permanent object pixel values that are expected to be present for the background, wherein authenticating further includes obtaining the expected permanent object pixel values based on: a time of day, calendar day, and current weather conditions for a physical location where the image was captured; and maintaining select ones of the expected permanent object pixel values as sets of the background pixels for the background, each set associated with: a different time of day, a different calendar day, different weather conditions for a physical location where the image was captured, or different combinations of: times of day, calendar days, and weather conditions for the physical location.
2. The method of claim 1 further comprising, sampling second pixels representing the background when the user is not present.
3. The method of claim 2, wherein sampling the second pixels further includes iterating the sampling of the second pixels at a predefined interval of time when the user is not present.
4. The method of claim 3, wherein iterating further includes dynamically updating the expected permanent object pixel values that are associated with permanent objects based on the sampling of the second pixels.
5. The method of claim 1, wherein sampling further includes identifying light attribute values for select ones of the pixels associated with the background.
6. The method of claim 5, wherein identifying further includes determining the light attribute values as: light intensity values, light brightness values, and color values.
7. The method of claim 1, wherein authenticating further includes processing depth analysis on the image for determining whether the image is being presented to a camera that captured the image as one of: a printed image of the user, a displayed image displayed on a display of a mobile device, and a video played on display of the mobile device.
8. The method of claim 7, wherein processing further includes preventing authentication of the user when the depth analysis detects abnormalities with the image indicating that a depth is missing from the image.
9. The method of claim 1, wherein authenticating further includes performing facial recognition on the face pixels and performing background object recognition on the background pixels.
10. The method of claim 9, wherein performing the facial recognition further includes providing the face pixels to a network service for facial recognition processing against registered face pixels registered for the user, wherein the registered face pixels comprise the expected face pixels values.
</claims>
</document>
