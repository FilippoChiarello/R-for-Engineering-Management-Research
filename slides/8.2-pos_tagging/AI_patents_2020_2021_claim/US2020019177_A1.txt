<document>

<filing_date>
2019-09-24
</filing_date>

<publication_date>
2020-01-16
</publication_date>

<priority_date>
2019-09-24
</priority_date>

<ipc_classes>
B25J9/16,B60W30/09,G05D1/02
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
MOUSTAFA, HASSNAA
TATOURIAN, IGOR
ZAGE, DAVID
</inventors>

<docdb_family_id>
69139336
</docdb_family_id>

<title>
COGNITIVE ROBOTIC SYSTEMS AND METHODS WITH FEAR BASED ACTION/REACTION
</title>

<abstract>
Apparatuses, storage media and methods associated with cognitive robot systems, such as ADAS for CAD vehicles, are disclosed herein. In some embodiments, an apparatus includes emotional circuitry to receive stimuli for a robot integrally having the robotic system, process the received stimuli to identify potential adversities, and output information describing the identified potential adversities; and thinking circuitry to receive the information describing the identified potential adversities, process the received information describing the identified potential adversities to determine respective fear levels for the identified potential adversities in view of a current context of the robot, and generate commands to the robot to respond to the identified potential adversities, based at least in part on the determined fear levels for the identified potential adversities. Other embodiments are also described and claimed.
</abstract>

<claims>
1. A robotic system, comprising: emotional circuitry to receive a plurality of stimuli for a robot integrally having the robotic system, process the received stimuli to identify one or more potential adversities, and output information describing the identified one or more potential adversities; and thinking circuitry coupled to the emotional circuitry to receive the information describing the identified one or more potential adversities, process the received information describing the identified one or more potential adversities to determine respective fear levels for the identified one or more potential adversities in view of a current context of the robot, and generate commands to the robot to respond to the identified one or more potential adversities, based at least in part on the determined fear levels for the identified one or more potential adversities.
2. The robotic system of claim 1, further comprising one or more contextual machines integrally disposed on the robot, and coupled to the thinking circuitry, to receive one or fear and fear-based action or reaction data for a plurality of adversities associated with a plurality of other proximally located robots, process the one of fear and fear-based action or reaction data for the plurality of adversities associated with the plurality of other proximally located robots to generate context determining data, and output the generated context determining data for the thinking circuitry to identify the current context of the robot
3. The robotic system of claim 2, wherein the one or more contextual machines include an information sharing machine coupled with the thinking circuitry and arranged to receive messages from the other proximally located robots on potential adversities currently perceived and having raised fear levels determined by the other proximally located robots, pre-process the received messages into a subset of the plurality of context determining data, and output the subset of the plurality of context determining data for use by the thinking circuitry in identifying the current context of the robot.
4. The robotic system of claim 2, wherein the one or more contextual machines include a social learning machine coupled with the thinking circuitry and arranged to receive data associated with observed behaviors of other proximally located robots, process the received data associated with observed behaviors of other proximally located robots into a subset of the plurality of context determining data, and output the subset of the plurality of context determining data for use by the thinking circuitry in identifying the current context of the robot.
5. The robotic system of claim 2, wherein the one or more contextual machines include an environment learning machine coupled with the thinking circuitry and arranged to receive data associated with observed errors of other proximally located robots, process the received data associated with observed errors of other proximally located robots into a subset of the plurality of context determining data, and output the subset of the plurality of context determining data for use by the thinking circuitry in identifying the current context of the robot.
6. The robotic system of claim 1, further comprising a fear communication machine, integrally disposed with the robot, and coupled with the thinking circuitry; wherein the thinking circuitry is arranged to further generate and output the determined fear levels for the identified one or more potential adversities for the fear communication machine; and wherein the fear communication machine is arranged to process the fear levels for the identified one or more potential adversities, and generate and output notifications of the fear levels for the identified one or more potential adversities for an operator interacting with the robot.
7. A driving assistance system (DAS), comprising: threat perceiving circuitry to receive a plurality of stimuli associated with potential threats against safe operation of a computer-assisted driving (CAD) vehicle integrally having the DAS, process the received stimuli to identify the potential threats, and output information describing the identified potential threats; threat responding circuitry coupled to the threat perceiving circuitry to receive the information describing the identified potential threats, process the received information describing the identified potential threats to determine respective fear levels for the identified potential threats in view of a current context of the CAD vehicle, and output the determined respective fear levels for the identified potential threats; and a fear communication machine coupled with the threat responding circuitry to process the fear levels for the identified potential threats, and generate and output notifications of the fear levels of the identified potential threats for a driver of the CAD vehicle.
8. The DAS of claim 7, wherein the plurality of stimuli include one or more of a current motion vector of the CAD vehicle, a current inertia vector of the CAD vehicle, a current speed of the CAD vehicle, a current speed limit, an amount of safe distance from another vehicle, a description of a proximally located road hazard, or state data about a driver of the CAD vehicle.
9. The DAS of claim 7, wherein the threat perceiving circuitry is arranged to process the plurality of stimuli to predict a likelihood of collision with another vehicle or object.
10. The DAS of claim 9, wherein to predict a likelihood of collision with another vehicle or object comprises to predict a likelihood of trajectory of the other vehicle or object.
11. The DAS of claim 7, wherein the threat perceiving circuitry is arranged to process at least a subset of the plurality of stimuli to determine lateral dynamics of the CAD vehicle or tire-road interaction of the CAD vehicle.
12. The DAS of claim 11, wherein to determine tire-road interaction of the CAD vehicle comprises to determine a yaw rate of the CAD vehicle, a sideslip angle of the CAD vehicle, or current road friction.
13. The DAS of claim 7, wherein the threat responding circuitry is further arranged to generate commands to the CAD vehicle to respond to the identified potential threats, based at least in part on the determined fear levels for the identified potential threats.
14. The DAS of claim 7, further comprising one or more contextual machines integrally disposed on the CAD vehicle, and coupled to the threat responding circuitry, to receive fear or fear-based action or reaction data of a plurality of threats, associated with a plurality of other proximally located vehicles, process the fear or fear-based action or reaction data of the plurality of threats associated with the plurality of other proximally located vehicles to generate a plurality of context determining data, and to output the context determining data for the thinking circuitry to identify the current context of the CAD vehicle.
15. The DAS of claim 14, wherein the one or more contextual machines include an information sharing machine coupled with the threat responding circuitry and arranged to receive messages from other proximally located vehicles on potential threats currently perceived and having raised fear levels determined by the other proximally located vehicles, pre-process the received messages into a subset of the plurality of context determining data, and output the subset of the plurality of context determining data for use by the threat responding circuitry in identifying the current context of the CAD vehicle.
16. The DAS of claim 15, wherein the messages comprise one or more messages from the other proximally located vehicles on adverse weather impact, road hazards, speed bumps, or steep terrain perceived by the other proximally located vehicles and having raised fear levels determined by the other proximally located vehicles.
17. The DAS of claim 14, wherein the one or more contextual machines include a social learning machine coupled with the threat responding circuitry and arranged to receive data associated with observed behaviors of other proximally located CAD vehicles, process the received data associated with observed behaviors of other proximally located vehicles into a subset of the plurality of context determining data, and output the subset of the plurality of context determining data for use by the threat responding circuitry in identifying the current context of the CAD vehicle.
18. The DAS of claim 17, wherein the data associated with observed behaviors of other proximally located CAD vehicles comprise data associated with observed slippage of the other proximally located CAD vehicles.
19. The DAS of claim 14, wherein the one or more contextual machines include an environment learning machine coupled with the threat responding circuitry and arranged to receive data associated with observed errors of other proximally located CAD vehicle, process the received data associated with observed errors of other proximally located CAD vehicle into a subset of the plurality of context determining data, and output the subset of the plurality of context determining data for use by the threat responding circuitry in identifying the current context of the CAD vehicle.
20. A method for computer-assisted driving, comprising: perceiving, by a driving assistance subsystem (DAS) of a vehicle, with first circuitry of the DAS, one or more potential threats to safe operation of the vehicle, based at least in part on a plurality of received stimuli; and responding, by the DAS, with second circuitry of DAS, differ and coupled with the first circuitry, to the perceived one or more potential threats, including determining fear levels for the perceived one or more potential threats, based at least in part on a current context of the vehicle, and generating one or more commands to maintain safe operation of the vehicle, based at least in part on the determined fear levels for the perceived one or more potential threats.
21. The method of claim 20, further comprising accepting, by the DAS, with third circuitry, differ and coupled with the second circuitry, information sharing from first one or more other proximally located vehicles on fear determined for the first one or more potential threats, by the one or more other proximally located vehicles; learning, by the DAS, with the third circuitry, operational experiences of second one or more proximally located vehicles from observations of the second one or more other proximally located vehicles; and learning, by the DAS, with the third circuitry, about environmental conditions of an area currently immediately surrounding the vehicle; wherein interpreting with the second circuitry further includes determining, with the second circuitry, the current context, based at least in part on the information sharing accepted, the operational experiences learned, and the environmental conditions learned.
22. The method of claim 21, further comprising outputting, by the DAS, with fourth circuitry, differ and coupled with the second circuitry, notifications of the fear levels determined for a driver of the vehicle.
23. At least one computer-readable medium (CRM) having instructions stored therein, to cause a driver assistance system (DAS) of a vehicle, in response to execution of the instruction by the DAS, to: accept information sharing from first one or more other proximally located vehicles on fear determined for first one or more potential threats to safe operation of vehicles, by the one or more proximally located vehicles; learn operational experiences of second one or more other proximally located vehicles from observations of the second one or more other proximally located vehicles; and learn about environmental conditions of an area currently immediately surrounding the vehicle; wherein the information sharing accepted, the operational experiences learned, and the environmental conditions learned are used to determine a current context for determining fear levels of perceived potential threats to safe operation of the vehicle.
24. The CRM of claim 23, wherein the DAS is further caused to determine the current context using the information sharing accepted, the operational experiences learned, and the environmental conditions learned.
25. The CRM of claim 23, wherein the DAS is further caused to perceive the potential threats to safe operation of the vehicle, based on a plurality of stimuli; and to interpret the perceived one or more potential threats, including to determine fear levels for the perceived one or more potential threats, based at least in part on the determined current context of the vehicle, and to generate one or more commands to maintain safe operation of the vehicle, based at least in part on the determined fear levels for the perceived one or more potential threats.
</claims>
</document>
