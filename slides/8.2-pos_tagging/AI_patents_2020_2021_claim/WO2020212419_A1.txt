<document>

<filing_date>
2020-04-15
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2019-04-16
</priority_date>

<ipc_classes>
G10L21/0272,G10L25/30
</ipc_classes>

<assignee>
FRAUNHOFER
FRIEDRICH-ALEXANDER-UNIVERSITAET ERLANGEN-NUERNBERG
</assignee>

<inventors>
HABETS, EMANUEL
MACK, WOLFGANG
</inventors>

<docdb_family_id>
66217806
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR DETERMINING A DEEP FILTER
</title>

<abstract>
A method for determining a deep filter comprises the following steps: • receiving a mixture; • estimating using a deep neural network the deep filter, wherein the estimating is performed, such that the deep filter, when applying to elements of the mixture, obtains estimates of respective elements of the desired representation; wherein the deep filter of at least one dimension comprises a tensor with elements.
</abstract>

<claims>
1. A method for filtering a mixture comprising the following steps: determining (100) a deep filter (10x) of at least one-dimension, comprising: receiving (1 10) a mixture (10); estimating (120) using a deep neural network the deep filter (10x), wherein the estimating (120) is performed, such that the deep filter (10x), when applying to elements of the mixture (10), obtains estimates of respective elements of a desired representation (1 1 ), wherein the deep filter (10x) of at least one dimension comprises a tensor with elements (sx,y); and applying the deep filter (10x) to the mixture (10).
2. The method (100) according to claim 1 , wherein the mixture (10) comprises a realor complex-valued time-frequency presentation or a feature representation of it; and wherein the desired representation (1 1 ) comprises a desired realor complex-valued time-frequency presentation or a feature representation of it.
3. The method (100) according to one of the previous claims, wherein the deep filter (10x) comprises a realor complex-valued time-frequency filter; and/or wherein the deep filter (10x) of at least one dimension is described in the short-time Fourier transform domain.
4. The method (100) according to one of the previous claims, wherein the step of estimating (120) is performed for each element of the mixture (10) or for a predetermined portion of the elements of the mixture (10).
5. The method (100) according to one of the previous claims, wherein the estimating (120) is performed for at least two sources.
6. The method (100) according to one of the previous claims, further comprising the step of defining a filter structure with its filter variables for the deep filter (10x) of at least one dimension.
7. The method (100) according to one of the previous claims, wherein the deep neural network comprises a number of output parameters equal to the number of filter values of a filter function of the deep filter (10x). 8. The method (100) according to one of the previous claims, wherein the at least one dimension are out of a group comprising time, frequency and sensor, or wherein the at least one of the dimensions is across time or frequency. 9. The method (100) according to one of the previous claims, wherein the deep neural network comprises a batch-normalization layer, a bidirectional long short-term memory layer, a feed-forward output layer with a tanh activation and/or one or more additional layer. 10. The method (100) according to one of the previous claims, further comprising the step of training the deep neural network.
1 1. The method (100) according to claim 10, wherein the deep neural network is trained by optimizing of the mean squared error between a ground truth of the desired representation (11) and an estimate of the desired representation (1 1) ; or wherein the deep neural network is trained by reducing the reconstruction error between the desired representation (11 ) and an estimate of the desired representation (1 1) ; or wherein the training is performed by a magnitude reconstruction.
12. The method (100) according to one of the previous claims, wherein the estimating (120) is performed by use of the formula: wherein 2 . L + 1 is a filter dimension in the time-frame direction and 2 . / + 1 is a filter dimension in a frequency direction and is the complex conjugated 1 D or
2D filter; and where the estimated desired representation (11), where n is the time-frame and k is the frequency index.
13. The method (100) according to claim 10, 11 or 12, wherein the training is performed by use of the following formula: , wherein Xd(n, k ) is the desired representation (11) and the estimated desired representation (11) where N is the total number of time-frames and K the number of frequency bins per timeframe, or by use of the following formula: wherein Xd[n, k ) is the desired representation (11) and Xd[n, k ) is the estimated desired representation (11), where N is the total number of time-frames and K the number of frequency bins per time-frame .
14. The method (100) according to one of the previous claims, wherein the tensor elements (Sx y) of the deep filter (10x) are bounded in magnitude or bounded in magnitude by use of the following formula: , wherein is a complex
conjugated 2D filter.
15. The method (100) according to claim one of the previous claims, wherein the step of applying is performed element-wise.
16. The method (100) according to one of the previous claims, wherein the applying is performed by summing up to obtain an estimate of the desired representation (11 ) in a respective tensor element (sx,y).
17. The use of the method (100) according to one of the previous claims for signal extraction or for signal separation of at least two sources.
18. The use of the method (100) according to one of the previous claims for signal reconstruction.
19. Computer program for performing, when running on a computer, one of the methods according to one of claims 1 to 18.
20. An apparatus for determining a deep filter (10x), the apparatus comprising an input for receiving (110) a mixture (10); a deep neural network for estimating (120) the deep filter (10x) such that the deep filter (10x), when applying to elements of the mixture (10), obtains estimates of respective elements of a desired representation (11); wherein the deep filter (10x) of at least one dimension comprises a tensor with elements (Sx,y).
21. An apparatus filtering a mixture, the apparatus comprises a deep filter as determined by the apparatus of claim 20 and means for applying the deep filter to the mixture.
</claims>
</document>
