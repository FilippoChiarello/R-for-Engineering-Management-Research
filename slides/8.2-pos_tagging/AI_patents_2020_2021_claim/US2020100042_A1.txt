<document>

<filing_date>
2019-11-25
</filing_date>

<publication_date>
2020-03-26
</publication_date>

<priority_date>
2015-12-27
</priority_date>

<ipc_classes>
G10L19/16,G10L19/22,H04R5/04,H04S1/00,H04S7/00
</ipc_classes>

<assignee>
LYREN, PHILIP SCOTT
NORRIS, GLEN A.
</assignee>

<inventors>
LYREN, PHILIP SCOTT
NORRIS, GLEN A.
</inventors>

<docdb_family_id>
59086798
</docdb_family_id>

<title>
Switching binaural sound
</title>

<abstract>
A method provides binaural sound to a person through electronic earphones. The binaural sound localizes to a sound localization point (SLP) in empty space that is away from but proximate to the person. When an event occurs, the binaural sound switches or changes to stereo sound, to mono sound, or to altered binaural sound.
</abstract>

<claims>
1. 1.-20. (canceled)
21. Headphones, comprising: a power supply that powers the headphones that a listener wears; microphones that capture environmental sound; a network chip that wirelessly receives sound from a smartphone; a sound chip that raises a volume of the environmental sound captured with the microphones and passes through the environmental sound with raised volume as mic-thru sound with the volume raised; speakers that play the sound from the smartphone along with the mic-thru sound with the volume raised; and a sensor, on a housing of the headphones, that senses a touch of a hand of the listener to turn on and to turn off the mic-thru sound with the volume raised.
22. The headphones of claim 21, wherein the sensor senses touches of the hand of the listener to switch between modes of operation that include a pass-thru mode that plays the environmental sound through the speakers to the listener, a silent mode that blocks the environmental sound from passing through to the listener, and a mix-mode that plays both the environmental sound and the sound from the smartphone through the speakers to the listener.
23. The headphones of claim 21, wherein the sensor senses the touch of the hand of the listener to activate capturing, by the microphones, a voice command from the listener to an intelligent personal assistant (IPA), and the network chip wirelessly transmits the voice command to the smartphone.
24. The headphones of claim 21, wherein the network chip wirelessly communicates with the smartphone that provides a user interface (UI) to adjust a volume of the mic-thru sound played to the listener through the speakers.
25. The headphones of claim 21 further comprising: headtracking that tracks head movements of the listener with respect to the smartphone, wherein binaural sound provided through the speakers continues to externally localize to a location of the smartphone while the head movements of the listener change with respect to the location of the smartphone.
26. The headphones of claim 21 further comprising: headtracking that tracks head movements of the listener with respect to a fixed location of a screen, wherein binaural sound provided through the speakers continues to externally localize to the fixed location of the screen while the head movements of the listener change with respect to the fixed location of the screen.
27. The headphones of claim 21, wherein voice recognition detects a voice of the listener and the headphones automatically stop playing the sound from the smartphone through the speakers and automatically switch to a pass-thru mode that allows the environmental sound to pass through to the listener in response to detecting the voice of the listener.
28. Headphones, comprising: a power supply that powers the headphones that a listener wears; microphones that capture environmental sound; a network chip that wirelessly receives music from a smartphone; speakers that play the music and the environmental sound to the listener; and a sound chip that automatically switches, based on a physical activity of the listener that includes walking and running, the headphones from a silent mode to a mix mode, wherein while in the silent mode the headphones play the music but mute the environmental sound from passing through to the listener, and wherein while in the mix mode the headphones play both the music and voices in the environment sound but mute non-voices in the environmental sound from passing through to the listener.
29. The headphones of claim 28, wherein the headphones automatically switch from the silent mode to the mix mode upon determining the listener is on an airplane.
30. The headphones of claim 28, wherein the headphones automatically switch from the silent mode to the mix mode based on a global positioning system (GPS) location of the listener wearing the headphones.
31. The headphones of claim 28 further comprising: head tracking that tracks head movements of the listener, wherein the head movements command the headphones to lower a volume of the music, and the headphones lower the volume of the music in response to the head movements.
32. The headphones of claim 28 further comprising: head tracking that tracks head movements of the listener, wherein the head movements command the headphones to answer an incoming telephone call, and the headphones answer the incoming telephone call in response to the head movements.
33. The headphones of claim 28 further comprising: a sensor that senses a hand of the listener and automatically switches from the silent mode to the mix mode in response to sensing the hand of the listener.
34. The headphones of claim 28 further comprising: a button, wherein the headphones automatically capture, at the microphones and in response to activation of the button, a voice command to an intelligent personal assistant (IPA), and wherein the network chip wirelessly transmits the voice command to the smartphone.
35. Headphones, comprising: a power supply that powers the headphones that a listener wears; one or more microphones that capture environmental sound; a network chip that wirelessly communicates with and receives music from a smartphone; a sound chip that processes the environmental sound captured by the one or more microphones and increases the environmental sound captured by the one or more microphones; speakers that play the music from the smartphone mixed with the environmental sound increased by the sound chip; and a sensor that senses a touch of a hand of the listener on a housing of the headphones to activate and to deactivate mixing of the environmental sound increased by the sound chip with the music from the smartphone.
36. The headphones of claim 35, wherein the sensor senses touches of the hand of the listener to change between modes of operation that include a silent mode that plays the music from the smartphone but blocks the environmental sound from passing through to the listener, and a mix-mode that plays both the environmental sound and the music from the smartphone through the speakers to the listener.
37. The headphones of claim 35, wherein the sensor senses the touch of the hand of the listener to capture a voice command from the listener to an intelligent personal assistant (IPA), and the network chip wirelessly transmits the voice command to the smartphone.
38. The headphones of claim 35 further comprising: headtracking that tracks head movements of the listener with respect to the smartphone, wherein three-dimensional (3D) sound provided through the speakers continues to externally localize to a location of the smartphone while the head movements of the listener change with respect to the location of the smartphone.
39. The headphones of claim 35 further comprising: headtracking that tracks head movements of the listener with respect to a fixed location of a screen of an electronic device, wherein three-dimensional (3D) sound provided through the speakers continues to externally localize to the fixed location of the screen while the head movements of the listener change with respect to the fixed location of the screen.
40. The headphones of claim 35 further comprising: headtracking that tracks head movements of the listener with respect to different fixed locations where sounds of instruments in the music externally localize to the listener, wherein the sounds of the instruments continue to externally localize to the different fixed locations while the head movements of the listener change with respect to the different fixed locations.
</claims>
</document>
