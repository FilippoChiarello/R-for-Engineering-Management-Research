<document>

<filing_date>
2018-06-25
</filing_date>

<publication_date>
2020-11-03
</publication_date>

<priority_date>
2018-06-25
</priority_date>

<ipc_classes>
G10L15/06,G10L15/08,G10L15/183,G10L17/00
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
GRAY, JOHN
PRABHAKARA, AJITH
YAVAGAL, DEEPAK
</inventors>

<docdb_family_id>
73019618
</docdb_family_id>

<title>
Wakeword detection
</title>

<abstract>
Techniques for implementing multiple wakeword detectors on a single device are described. A digital signal processor (DSP) of the device may initially include an untrained wakeword detection component. The wakeword detection component of the DSP may be trained by engaging a user to speak particular utterances. Once a companion application is configured to implement a wakeword detection component, the companion application's wakeword detection component may be trained specific to the user of the device. Once the companion application's wakeword detection component is trained, the DSP wakeword detection component may be deactivated or its accuracy adjusted.
</abstract>

<claims>
1. A method for detecting wakewords using different components, the method comprising: receiving first audio corresponding to first speech; determining, using a digital signal processor (DSP) of a first device, first audio data, representing the first audio, includes a spoken wakeword; after determining the first audio data includes the spoken wakeword, determining, by a first application executed by the first device, a first likelihood that at least a portion of the first audio data corresponds to a first audio signature corresponding to a first wakeword associated with a first speech processing system; after determining the first audio data includes the spoken wakeword, determining, by the first application, a second likelihood that the at least a portion of the first audio data corresponds to a second audio signature corresponding to a second wakeword associated with a second speech processing system; determining the first likelihood is greater than the second likelihood; and sending the first audio data to a second application associated with the first wakeword, the second application enabling the first device to communicate with the first speech processing system.
2. The method of claim 1, further comprising: training the second application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; after sending the first audio data, receiving second audio data representing third speech; determining audio characteristics of the second audio data are substantially different from stored audio characteristics associated with the first user; and based at least in part on the audio characteristics being substantially different from the stored audio characteristics, preventing the second audio data from being sent to the first speech processing system.
3. The method of claim 1, further comprising: training the second application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; and determining, by the wakeword detection component, a third likelihood that the at least a portion of the first audio data corresponds to stored audio characteristics associated with the first user.
4. The method of claim 1, further comprising: training the second application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; determining, by the wakeword detection component, audio characteristics of the first audio data are substantially different from stored audio characteristics associated with the first user; sending the first audio data to the first speech processing system; and based at least in part on the audio characteristics being substantially different from the stored audio characteristics, sending, to the first speech processing system, an indicator that the first audio data was spoken by a user unassociated with the first device.
5. A method, comprising: receiving, by a first device, first audio data representing first speech; determining, using a processor of the first device, that the first audio data includes a spoken wakeword; determining, by the first device, a first likelihood that at least a portion of the first audio data corresponds to a first audio signature corresponding to a first wakeword associated with a first speech processing system; determining, by the first device, a second likelihood that the at least a portion of the first audio data corresponds to a second audio signature corresponding to a second wakeword associated with a second speech processing system; determining the first likelihood is greater than the second likelihood; and sending the first audio data to a first application executed by the first device, the first application being associated with the first wakeword and enabling the first device to communicate with the first speech processing system.
6. The method of claim 5, wherein the processor is a digital signal processor (DSP) and wherein the method further comprises: configuring the DSP to detect a plurality of wakewords.
7. The method of claim 5, further comprising: training the first application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; and determining, by the wakeword detection component, a third likelihood that the at least a portion of the first audio data corresponds to stored audio characteristics associated with the first user.
8. The method of claim 5, further comprising: training the first application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; determining, by the wakeword detection component, audio characteristics of the first audio data are substantially different from stored audio characteristics associated with the first user; sending the first audio data to the first speech processing system; and based at least in part on the audio characteristics being substantially different from the stored audio characteristics, sending, to the first speech processing system, an indicator that the first audio data was spoken by a user unassociated with the first device.
9. The method of claim 5, further comprising: training the first application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; after sending the first audio data, receiving second audio data representing third speech; determining audio characteristics of the second audio data are substantially different from stored audio characteristics associated with the first user; and based at least in part on the audio characteristics being substantially different from the stored audio characteristics, preventing the second audio data from being sent to the first speech processing system.
10. The method of claim 5, further comprising: training the first application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; after training the first application, receiving second audio data representing third speech; detecting, using the wakeword detection component, a representation of the first wakeword in the second audio data; and using the second audio data to further train the wakeword detection component.
11. The method of claim 10, wherein the second audio data corresponds to either: the first wakeword; or the first wakeword with a user command.
12. The method of claim 10, further comprising: sending, to the first speech processing system, a model trained using at least the second audio data.
13. A system, comprising: at least one processor; and at least one memory comprising instructions that, when executed by the at least one processor, cause the system to: receive, by a first device, first audio data representing first speech; determine, using a processor of the first device, that the first audio data includes a spoken wakeword; determine, by the first device, a first likelihood that at least a portion of the first audio data corresponds to a first audio signature corresponding to a first wakeword associated with a first speech processing system; determine, by the first device, a second likelihood that the at least a portion of the first audio data corresponds to a second audio signature corresponding to a second wakeword associated with a second speech processing system; determine the first likelihood is greater than the second likelihood; and send the first audio data to a first application executed by the first device, the first application being associated with the first wakeword and enabling the first device to communicate with the first speech processing system.
14. The system of claim 13, wherein the processor is a digital signal processor (DSP) and wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: configure the DSP to detect a plurality of wakewords.
15. The system of claim 13, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: train the first application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; and determine, by the wakeword detection component, a third likelihood that the at least a portion of the first audio data corresponds to stored audio characteristics associated with the first user.
16. The system of claim 13, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: train the first application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; determine, by the wakeword detection component, audio characteristics of the first audio data are substantially different from stored audio characteristics associated with the first user; send the first audio data to the first speech processing system; and based at least in part on the audio characteristics being substantially different from the stored audio characteristics, send, to the first speech processing system, an indicator that the first audio data was spoken by a user unassociated with the first device.
17. The system of claim 13, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: train the first application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; after sending the first audio data, receive second audio data representing third speech; determine audio characteristics of the second audio data are substantially different from stored audio characteristics associated with the first user; and based at least in part on the audio characteristics being substantially different from the stored audio characteristics, prevent the second audio data from being sent to the first speech processing system.
18. The system of claim 13, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: train the first application to implement a wakeword detection component, the wakeword detection component being trained using at least second audio data representing second speech of a first user; after training the first application, receive second audio data representing third speech; detect, using the wakeword detection component, a representation of the first wakeword in the second audio data; and use the second audio data to further train the wakeword detection component.
19. The system of claim 18, wherein the second audio data corresponds to either: the first wakeword; or the first wakeword with a user command.
20. The system of claim 18, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: send, to the first speech processing system, a model trained using at least the second audio data.
</claims>
</document>
