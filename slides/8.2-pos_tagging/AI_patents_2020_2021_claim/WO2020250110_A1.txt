<document>

<filing_date>
2020-06-08
</filing_date>

<publication_date>
2020-12-17
</publication_date>

<priority_date>
2019-06-08
</priority_date>

<ipc_classes>
G06F3/01,G06F3/0346,G06T17/00,G06T19/00
</ipc_classes>

<assignee>
PATIL, ABHIJIT
RAUT, PANKAJ
TOMAR, ABHISHEK
</assignee>

<inventors>
PATIL, ABHIJIT
RAUT, PANKAJ
TOMAR, ABHISHEK
</inventors>

<docdb_family_id>
73782062
</docdb_family_id>

<title>
A SYSTEM AND A METHOD FOR GENERATING A 3D VISUALIZATION USING MIXED REALITY-BASED HMD
</title>

<abstract>
A method (200) for generating a 3D visualization (316) using information from a document (302) in a chronological order of pages, using a Mixed Reality (MR) based Head Mounted Device (HMD (102)) is provided. The method (200) comprises receiving one or more images of one or more pages of a document (302) using an image acquisition device of the HMD (102); processing the one or more images for text recognition and extracting information from the recognised text in a form of a plurality of excerpts; identifying a plurality of 2-Dimensional (2D) sketches for the corresponding plurality of excerpts; converting the plurality of 2D sketches and the extracted information into a corresponding plurality of 3D models (314); processing and merging the plurality of 3D models (314) to generate a 3D visualization (316) and displaying the generated 3D visualization (316) in a mixed reality space (312) of the HMD (102).
</abstract>

<claims>
1. A method (200) for generating a 3D visualization (316) using information from a document (302) in a chronological order of pages, using a Mixed Reality (MR) based Head Mounted Device (HMD (102)), the method (200) comprising the steps of:
receiving one or more images of one or more pages of a document (302) in a chronological order, one by one using an image acquisition device of the HMD (102);
processing the one or more images for text recognition and extracting information from the recognised text in a form of a plurality of excerpts;
identifying a plurality of 2-Dimensional (2D) sketches for the corresponding plurality of excerpts in the chronological order of the one or more pages using a first prestored dataset;
converting the plurality of 2D sketches and the extracted information into a corresponding plurality of 3D models (314) using a second prestored dataset; processing and merging the plurality of 3-Dimensionsal (3D) models to generate a 3D visualization (316) depicting the information on the one or more pages; and
displaying the generated 3D visualization (316) having a predetermined duration in the chronological order of one or more pages, in a mixed reality space (312) of the HMD (102), thereby enabling a user (322) to understand the document (302) even without knowing the language of the document (302);
wherein the 3D visualizations (316) are generated page by page, starting from a first page of the one or more pages in a chronological order and the 3D visualization (316) of a subsequent page continues from a chronology of information from a previous page.
2. The method (200) as claimed in claims 1 , further comprising:
sketching & adding new plurality of 2D sketches and/or 3D sketches based on gestures and/or voice inputs from the user (322) in the mixed reality space (312), using a handheld electronic controller (106) connected with HMD (102); editing & modelling with the previously generated plurality of 2D sketches and/or 3D sketches and/or the plurality of 3D models (314) in the mixed reality space (312), using the handheld electronic controller (106).
3. The method (200) as claimed in claims 1 , wherein the document (302) is selected from a group comprising e-books, printed text books, hand written texts, info-graphic books, user (322) manuals, novels, e-files, manuscripts or inscriptions.
4. The method (200) as claimed in claims 1 , wherein extracting information from the recognised text includes extracting terms indicative of a corresponding plurality of objects and segmenting the recognised text into the plurality of excerpts based on the context in which the terms are being used.
5. The method (200) as claimed in claims 4, wherein the first prestored dataset includes a plurality of 2D sketches corresponding to a respective plurality of objects.
6. The method (200) as claimed in claims 5, wherein the plurality of objects include all the living and non-living objects selected from a group comprising humans of multiple age groups, animals, plants, furniture, vehicles, natural resources, eatables, crops, infrastructure, stationery, sign boards, wearables, musical instruments, sports equipment, mechanical tools, electrical equipment and electronic equipment.
7. The method (200) as claimed in claims 6, wherein the second prestored dataset includes a plurality of 3D models (314) corresponding to a respective plurality of 2D sketches, the plurality of objects and the 3D sketches.
8. The method (200) as claimed in claims 1 , wherein processing and merging the plurality of 3-Dimensionsal (3D) models to generate a 3D visualization (316) comprises a step of adding organic gestures and motion to the generated plurality of 3D models (314) using prestored gestures and motion profiles based on the generated plurality of 3D models (314) and the information extracted from the page.
9. A computer system (104) for generating a 3D visualization (316) using information from a document (302) in a chronological order of pages, using a Mixed Reality (MR) based Head Mounted Device (HMD (102)), the computer system (104) comprising:
a memory unit (1042) configured to store machine-readable instructions; and
a processor (1044) operably connected with the memory unit (1042), the processor (1044) obtaining the machine-readable instructions from the memory unit (1042), and being configured by the machine-readable instructions to:
receive one or more images of one or more pages of a document (302) in a chronological order, one by one using an image acquisition device of the HMD (102);
process the one or more images for text recognition and extracting information from the recognised text in a form of a plurality of excerpts; identify a plurality of 2-Dimensional (2D) sketches for the corresponding plurality of excerpts in the chronological order of the one or more pages using a first prestored dataset;
convert the plurality of 2D sketches and the extracted information into a corresponding plurality of 3D models (314) using a second prestored dataset;
process and merge the plurality of 3-Dimensionsal (3D) models to generate a 3D visualization (316) depicting the information on the one or more pages; and
display the generated 3D visualization (316) having a predetermined duration in the chronological order of one or more pages, in a mixed a reality space of the HMD (102), thereby enabling a user (322) to understand the document (302) even without knowing the language of the book;
wherein the 3D visualizations (316) are generated page by page, starting from a first page of the one or more pages in a chronological order and the 3D visualization (316) of a subsequent page continues from a chronology of information from a previous page.
10. The computer system (104) as claimed in claims 9, further comprising a handheld electronic controller (106) connected with the HMD (102); wherein the handheld electronic controller (106) is configured to: sketch & add new plurality of 2D sketches and/or 3D sketches based on gestures and/or voice inputs from the user (322), in the mixed reality space (312); and edit & model with the previously generated plurality of 2D sketches and/or 3D sketches and/or the plurality of 3D models (314) in the mixed reality space (312).
1 1. The computer system (104) as claimed in claims 9, wherein the document (302) is selected from a group comprising e-books, printed text books, hand written texts, info-graphic books, user (322) manuals, novels, e-files, manuscripts or inscriptions.
12. The computer system (104) as claimed in claims 9, wherein the processor (1044) is configured to extract information from the recognised text by extracting terms indicative of a corresponding plurality of objects and segmenting the recognised text into the plurality of excerpts based on the context in which the terms are being used.
13. The computer system (104) as claimed in claims 12, wherein the first prestored dataset includes a plurality of 2D sketches corresponding to a respective plurality of objects.
14. The computer system (104) as claimed in claims 13, wherein the plurality of objects include all the living and non-living objects selected from a group comprising humans of multiple age groups, animals, plants, furniture, vehicles, natural resources, eatables, crops, infrastructure, stationery, sign boards, wearables, musical instruments, sports equipment, mechanical tools, electrical equipment and electronic equipment.
15. The computer system (104) as claimed in claims 14, wherein the second prestored dataset includes a plurality of 3D models (314) corresponding to a respective plurality of 2D sketches, the plurality of objects and the 3D sketches.
16. The computer system (104) as claimed in claims 9, wherein the processor (1044) is configured to process and merge the plurality of 3-Dimensionsal (3D) models by adding organic gestures and motion to the generated plurality of 3D models (314) using prestored gestures and motion profiles based on the generated plurality of 3D models (314) and the information extracted from the page
17. A system (400) for generating a 3D visualization (316) using information from a document (302) in a chronological order of pages, using a Mixed Reality (MR) based Head Mounted Device (HMD (102)), the system (400) comprising:
a control module (402) connected with the HMD (102); and
an interface module (404);
wherein the interface module (404) is configured to receive one or more images of one or more pages of a document (302) in a chronological order, one by one using an image acquisition device of the HMD (102);
wherein the control module (402) is configured to:
process the one or more images for text recognition and extracting information from the recognised text in a form of a plurality of excerpts; identify a plurality of 2-Dimensional (2D) sketches for the corresponding plurality of excerpts in the chronological order of the one or more pages using a first prestored dataset;
convert the plurality of 2D sketches and the extracted information into a corresponding plurality of 3D models (314) using a second prestored dataset;
process and merge the plurality of 3-Dimensionsal (3D) models to generate a 3D visualization (316) depicting the information on the one or more pages;
wherein the interface module (404) is further configured to display the generated 3D visualization (316) having a predetermined duration in the chronological order of one or more pages, in a mixed a reality space of the HMD (102), thereby enabling a user (322) to understand the document (302) even without knowing the language of the document (302); and wherein the 3D visualizations (316) are generated page by page, starting from a first page of the one or more pages in a chronological order and the 3D visualization (316) of a subsequent page continues from a chronology of information from a previous page. 18. The system (400) as claimed in claims 17, further comprising a handheld electronic controller (106) connected with the HMD (102);
wherein the handheld electronic controller (106) is configured to: sketch & adding new plurality of 2D sketches and/or 3D sketches based on gestures and/or voice inputs from the user (322) in the mixed reality space (312); edit & model with the previously generated plurality of 2D sketches and/or 3D sketches and/or the plurality of 3D models (314) in the mixed reality space (312).
19. The system (400) as claimed in claims 17, wherein the document (302) is selected from a group comprising e-books, printed text books, hand written texts, info-graphic books, user (322) manuals, novels, e-files, manuscripts or inscriptions.
20. The system (400) as claimed in claims 17, wherein the control module (402) is configured to extract information from the recognised text by extracting terms indicative of a corresponding plurality of objects and segmenting the recognised text into the plurality of excerpts based on the context in which the terms are being used.
21. The system (400) as claimed in claims 20, wherein the first prestored dataset includes a plurality of 2D sketches corresponding to a respective plurality of objects.
22. The system (400) as claimed in claims 21 , wherein the plurality of objects include all the living and non-living objects selected from a group comprising humans of multiple age groups, animals, plants, furniture, vehicles, natural resources, eatables, crops, infrastructure, stationery, sign boards, wearables, musical instruments, sports equipment, mechanical tools, electrical equipment and electronic equipment.
23. The system (400) as claimed in claims 22, wherein the second prestored dataset includes a plurality of 3D models (314) corresponding to a respective plurality of 2D sketches, the plurality of objects and the 3D sketches. 24. The system (400) as claimed in claims 17, wherein the control module (402) is configured to process and merge the plurality of 3-Dimensionsal (3D) models by adding organic gestures and motion to the generated plurality of 3D models (314) using prestored gestures and motion profiles based on the generated plurality of 3D models (314) and the information extracted from the page.
25. A handheld electronic controller (106) connected with a Mixed Reality (MR) based Head Mounted Device (HMD (102)) comprising atleast a magnetic coil, a tactile sensor, haptic feedback device, a biometric sensor, a microprocessor and a power source;
wherein the handheld electronic controller (106) is configured to: sketch & add new plurality of 2D sketches and/or 3D sketches based on gestures and/or voice inputs from the user (322) in the mixed reality space (312); edit & model with the previously generated plurality of 2D sketches and/or the 3D sketches and/or the plurality of 3D models (314) in the mixed reality space (312).
26. The handheld electronic controller (106) as claimed in claim 25, wherein the handheld electronic controller (106) is configured to be used as a tool in one or more modes based on manual selection and/or a manner of holding the handheld electronic controller (106);
wherein the tool is selected from selection tools, sketching tools such as pencil, pen and paint brush and hardware tools such as hammer, chisel, screw driver, plier, axe and wrench;
wherein the handheld electronic controller (106) is further configured to provide a dynamic haptic feedback using the haptic feedback sensors and spatial sound effect according to a selected virtual tool, a pressure applied by the user (322) and a material being modelled, while interacting in the mixed reality space (312); wherein the tactile sensor senses the force exerted by the user to simulate click and drag actions; wherein the one or more modes are selected from sketching mode, painting mode, sculpting mode and modelling mode, each mode comprising a customised tool pallets (344) showing different tools required for the respective mode; and wherein the biometric sensor is configured to identify and save profiles for multiple users so as to change the one or more modes automatically as preferred by the user.
27. The handheld electronic controller (106) as claimed in claim 25, wherein sketching & adding new plurality of 2D sketches and/or 3D sketches further includes:
copying 2D or 3D images from visible real-world sources such as a physical magazine or an electronic file by creating a boundary to enclose a required 2D or 3D image using the electronic controller (106);
pasting the selected 2D or 3D image in the mixed reality space (312) of the HMD (102) and converting the 2D or 3D image into a 3D model.
</claims>
</document>
