<document>

<filing_date>
2016-07-27
</filing_date>

<publication_date>
2020-03-11
</publication_date>

<priority_date>
2015-09-04
</priority_date>

<ipc_classes>
G07C9/00,G10L17/02,G10L17/04,G10L17/18,G10L17/22,H04M1/725
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
BENGIO, SAMY
HEIGOLD, GEORG
MORENO, IGNACIO LOPEZ
</inventors>

<docdb_family_id>
56853791
</docdb_family_id>

<title>
NEURAL NETWORKS FOR SPEAKER VERIFICATION
</title>

<abstract>
This document generally describes systems, methods, devices, and other techniques related to speaker verification, including (i) training a neural network for a speaker verification model, (ii) enrolling users at a client device, and (iii) verifying identities of users based on characteristics of the users' voices. Some implementations include a computer-implemented method. The method can include receiving, at a computing device, data that characterizes an utterance of a user of the computing device. A speaker representation can be generated, at the computing device, for the utterance using a neural network on the computing device. The neural network can be trained based on a plurality of training samples that each: (i) include data that characterizes a first utterance and data that characterizes one or more second utterances, and (ii) are labeled as a matching speakers sample or a non-matching speakers sample.
</abstract>

<claims>
1. A method comprising: receiving, at data processing hardware of a user device, data that characterizes a first utterance; generating, by the data processing hardware, a speaker representation for the utterance using a trained neural network, the speaker representation indicating distinctive features of a voice of a speaker of the first utterance; obtaining, by the data processing hardware, a speaker model for an enrolled user of the user device, the speaker model previously determined during an enrollment phase and characterizing distinctive features of a voice of the enrolled user based on one or more second utterances spoken by the enrolled user;
determining, by the data processing hardware, whether a similarity score between the speaker representation for the first utterance and the speaker model for the enrolled user satisfies a similarity score threshold; and when the similarity score satisfies the similarity score threshold: authenticating, by the data processing hardware, the speaker of the first utterance as the enrolled user of the user device; and updating, by the data processing hardware, the speaker model for the enrolled user of the user device based on the first utterance.
2. The method of claim 1, further comprising, in response to authenticating the speaker of the first utterance as the enrolled user of the user device, transitioning, by the data processing hardware, operation of the user device from a low-power state to a more fully-featured state.
3. The method of claim 1 or 2, further comprising, in response to authenticating the speaker of the first utterance as the enrolled user of the user device: processing, by the data processing hardware, one or more terms in the first utterance; and performing, by the data processing hardware, an action based on the one or more terms in the first utterance.
4. The method of any of claims 1-3, wherein the first utterance and each of the one or more enrollment utterances comprise a same pre-determined phrase.
5. The method of any of claims 1-4, wherein the similarity score between the speaker representation and the speaker model comprises a cosine distance between a vector of values for the speaker representation and a vector of values for the speaker model.
6. The method of any of claims 1-5, wherein obtaining the speaker model for the enrolled user of the user device comprises retrieving the speaker model from memory hardware of the user device.
7. The method of any of claims 1-6, further comprising, determining the speaker model for the enrolled user during the enrollment phase by: receiving, at the data processing hardware, the one or more enrollment utterances spoken by the enrolled user; inputting, by the data processing hardware, data characterizing each of the one or more enrollment utterances into the neural network to generate a respective enrolled speaker representation for each of the one or more enrollment utterances; and generating, by the data processing hardware, the speaker model for the enrolled user of the user device based on the respective enrolled speaker representation for each of the one or more enrollment utterances.
8. The method of any of claims 1-7, wherein receiving the data that characterizes the first utterance comprises: receiving a raw audio signal of the first utterance; and converting the raw audio signal of the first utterance into audio features characterizing the first utterance.
9. The method of any of claims 1-8, wherein the trained neural network comprises a long-short-term memory recurrent neural network that is trained on data that characterizes utterances having variable lengths.
10. The method of any of claims 1-9, wherein the trained neural network comprises a deep neural network that is trained on data that characterizes utterances all having a fixed-length.
11. The method of claim 10, wherein the deep neural network comprises a locally-connected hidden layer followed by a plurality of fully-connected hidden layers.
12. The method of claim 10, wherein the deep neural network does not have a Softmax output layer.
13. The method of any of claims 1-12, further comprising, prior to generating the speaker representation for the utterance using the trained neural network, receiving, by the data processing hardware, the trained neural network over a network from a remote computing device.
14. A system comprising: data processing hardware of a user device; and memory hardware of the user device and in communication with the data processing hardware, the memory hardware storing instructions that when executed by the data processing hardware cause the data processing hardware to perform operations comprising the method of any preceding claim.
</claims>
</document>
