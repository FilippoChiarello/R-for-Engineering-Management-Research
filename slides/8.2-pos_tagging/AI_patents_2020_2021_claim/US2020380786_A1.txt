<document>

<filing_date>
2019-05-31
</filing_date>

<publication_date>
2020-12-03
</publication_date>

<priority_date>
2019-05-31
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06T19/00,G06T7/00,G06T7/246,G06T7/73,H04N13/243,H04N13/261,H04N13/282
</ipc_classes>

<assignee>
AT&T INTELLECTUAL PROPERTY I (AMERICAN TELEPHONE AND TELEGRAPH COMPANY INTELLECTUAL PROPERTY I)
</assignee>

<inventors>
ZAVESKY, ERIC
HUTSLER, MOLLY
Henderson, Timothy
</inventors>

<docdb_family_id>
73550321
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR ANALYZING AND DISTRIBUTING VOLUMETRIC VIDEO
</title>

<abstract>
Aspects of the subject disclosure may include, for example, a device that includes a processing system and a memory that stores executable instructions that causes the device to perform operations including acquiring audiovisual data from a plurality of cameras focused on an event; recognizing an object in the audiovisual data; identifying key points on the object; determining a type of analytical information concerning movement of the key points; and providing a point-of-view (PoV) rendering from the audiovisual data to a viewer at a display interface, wherein the PoV rendering includes the analytical information. Other embodiments are disclosed.
</abstract>

<claims>
1. A device, comprising: a processing system including a processor; and a memory that stores executable instructions that, when executed by the processing system, facilitate performance of operations, the operations comprising: acquiring audiovisual data from a plurality of cameras focused on an event; generating live volumetric video (VV) data from the audiovisual data acquired from the plurality of cameras; recognizing an object in the live VV data; identifying key points on the object from the live VV data; determining a type of analytical information concerning movement of the key points; and providing, to a display interface according to the live VV data, a point-of-view (PoV) rendering viewable by a viewer, wherein the PoV rendering includes the analytical information.
2. The device of claim 1, wherein the operations further comprise analyzing motion of the object from the live VV data to identify the key points in real-time without markers.
3. The device of claim 1, wherein the type of analytical information includes position, a distance between two key points, speed, trajectory, velocity, acceleration, or a combination thereof.
4. The device of claim 1, wherein the type of analytical information includes an estimate of mass, force, momentum, work, kinetic energy, impact, power, or a combination thereof.
5. The device of claim 1, wherein the type of analytical information includes angular position, angular velocity, angular acceleration, moment of inertia, centripetal force, torque, or a combination thereof.
6. The device of claim 1, wherein the operations further comprise receiving an indication from the display interface identifying relevant key points.
7. The device of claim 6, wherein the indication further comprises identifying the type of analytical information to determine the relevant key points.
8. The device of claim 1, wherein the processing system comprises a plurality of processors operating in a distributed processing environment, and wherein the PoV rendering is provided in real-time.
9. The device of claim 8, wherein the PoV rendering of a current trial of the event is overlaid on a previous trial of the event.
10. The device of claim 9, wherein the PoV rendering includes a comparison of the analytical information from the previous trial of the event and the current trial of the event.
11. The device of claim 10, wherein the operations further comprise aggregating a plurality of trials of the event and developing a model for motion of the object.
12. The device of claim 11, wherein development of the model includes user-generated feedback from the display interface of the viewer associated with one or more trials of the plurality of trials of the event.
13. A machine-readable medium, comprising executable instructions that, when executed by a processing system including a processor, facilitate performance of operations, the operations comprising: generating volumetric video (VV) data from image data recorded by a plurality of digital cameras, wherein each digital camera in the plurality of digital cameras comprises a different point-of-view (PoV) of an event; recognizing an object in the live VV data; identifying key points on the object from the live VV data; determining analytical information associated with movement of the object; rendering a presentation of the live VV data on a display interface, wherein the rendering includes the analytical information; and generating automated feedback based on application of an idealized model for movement of the object.
14. The machine-readable medium of claim 13, wherein the operations further comprise receiving a PoV from the display interface, and rendering the presentation based on the PoV received.
15. The machine-readable medium of claim 14, wherein the idealized model is developed from movement of previously identified objects.
16. The machine-readable medium of claim 15, wherein the automated feedback comprises haptic feedback.
17. The machine-readable medium of claim 16, wherein the processing system comprises a plurality of processors operating in a distributed processing environment.
18. A method, comprising: recognizing, by a processing system including a processor, an object in volumetric video (VV) data generated from images recorded by a plurality of digital cameras focused on an event, wherein each digital camera in the plurality of digital cameras comprises a different point-of-view (PoV) of the event; identifying, by the processing system, key points on the object from the VV data; determining, by the processing system, analytical information concerning movement of the object; and providing, by the processing system, automated feedback concerning movement of the object, movement of the key points, or a combination thereof, based on the analytical information and application of an idealized model for motion of the object.
19. The method of claim 18, further comprising: rendering, by the processing system, a current trial of the event overlaid on a previous trial of the event.
20. The method of claim 19, further comprising: comparing, by the processing system, the analytical information from the previous trial of the event and the current trial of the event, wherein the automated feedback is further based on the comparison.
</claims>
</document>
