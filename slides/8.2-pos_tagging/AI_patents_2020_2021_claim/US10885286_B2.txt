<document>

<filing_date>
2018-10-12
</filing_date>

<publication_date>
2021-01-05
</publication_date>

<priority_date>
2018-10-12
</priority_date>

<ipc_classes>
G06F16/48,G06F40/45,G06F40/58,G10L13/00,G10L13/04,G10L13/10
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
SIMONNET, GUILLAUME
THOLFSEN, MICHAEL
RAY, PAUL RONALD
</inventors>

<docdb_family_id>
68165896
</docdb_family_id>

<title>
Simultaneous and real time translation and language switching across a set of features
</title>

<abstract>
A computer-implemented method that may be carried out by a reader device or other computing device includes identifying boundaries of words and sentences of displayed content and receiving a language selection of a language for translating a selected unit of text in the displayed content; translating the unit of text to the selected language; retrieving from a picture dictionary, a pictogram associated with a tag applied to the word or at least one word from the sentence of the selected unit of text; generating pronunciation files for both an original language of the unit of text and the selected language; and displaying, in context with the displayed content, the unit of text in the original language and the selected language, the pictogram, and icons for requesting to play the pronunciation files. The selected unit of text can be a word or a sentence.
</abstract>

<claims>
1. A reader device comprising: a display; one or more processors; a storage system; and instructions stored on the storage system that when executed by the one or more processors direct the reader device to at least: identify boundaries of words and sentences of displayed content by at least: performing syntaxic analysis of at least a portion of the displayed content to at least identify spaces and periods; categorizing words identified by the spaces and periods into categories comprising word and number; performing language detection to determine a character set for the words; and performing language-specific semantic analysis of the words; receive a language selection of a language for translating a selected unit of text in the displayed content, wherein the selected unit of text is a word or a sentence; translate the selected unit of text to the selected language; retrieve from a picture dictionary, a pictogram associated with a tag applied to the word or at least one word from the sentence of the selected unit of text; generate pronunciation files for both an original language of the selected unit of text and the selected language; and display, in context with the displayed content, the selected unit of text in the original language and the selected language, the pictogram, and an icons for requesting to play the pronunciation files via a call-out window.
2. The reader device of claim 1, wherein the displayed content comprises text in at least two languages.
3. The reader device of claim 1, further comprising instructions that direct the reader device to: apply a same feature to the translated unit of text as currently applied to the selected unit of text in the original language.
4. The reader device of claim 3, wherein the feature comprises one or both of: indicating part of speech; and indicating syllables.
5. The reader device of claim 1, further comprising instructions that direct the reader device to: identify parts of speech and syllables of each word; and tag words with their part of speech and entity identifier.
6. The reader device of claim 5, further comprising instructions that direct the reader device to: receive a command to display a learning tool feature for the displayed content; and display the part of speech or syllables of the displayed content.
7. A method comprising: receiving content; identifying boundaries of words and sentences of at least a portion of the content, wherein the identifying the boundaries of words and sentences of the at least the portion of the content comprises: performing syntaxic analysis of the at least the portion of the content to at least identify spaces and periods; categorizing words identified by the spaces and periods into categories comprising word and number; performing language detection to determine a character set for the words; and performing language-specific semantic analysis of the words; receiving a selection of a language for translating a selected unit of text from a displayed portion of the content; translating the selected unit of text to the selected language, wherein the selected unit of text is a word or a sentence; retrieving from a picture dictionary, a pictogram associated with a tag applied to the word forming the selected unit of text or at least one word from the sentence forming the selected unit of text; generating pronunciation files for both an original language of the selected unit of text and the selected language; and displaying, in context with the displayed portion of the content, the selected unit of text in the original language and the selected language, the pictogram, and icons for requesting to play the pronunciation files via a call-out window.
8. The method of claim 7, further comprising: applying at least one feature to at least the portion of the content; and applying a same at least one feature to the translated unit of text.
9. The method of claim 8, wherein the feature comprises one or both of: indicating part of speech; and indicating syllables.
10. The method of claim 7, further comprising: identifying the parts of speech and syllables of each word; and tagging words with their part of speech and entity identifier.
11. The method of claim 7, wherein translating the selected unit of text to the selected language comprises: communicating with a translation service to obtain a translation of the selected unit of text to the selected language.
12. The method of claim 7, wherein the content comprises text in at least two languages.
13. A computer-readable storage medium having instructions stored thereon that when executed by a processor, direct the processor to at least: receive content comprising at least one original language; identify boundaries of words and sentences of at least a portion of the content by at least: performing syntaxic analysis of the at least the portion of the content to at least identify spaces and periods; categorizing words identified by the spaces and periods into categories comprising word and number; performing language detection to determine a character set for the words; and performing language-specific semantic analysis of the words; receive a selection of a language for translating a selected unit of text from a displayed portion of the content; receive a selection of a learning feature; apply the learning feature to the displayed portion of the content at least with respect to the selected unit of text in the original language; translate the selected unit of text to the selected language; apply the learning feature to the selected unit of text in the selected language; and wherein when the selected unit of text is a word: retrieve from a picture dictionary, a pictogram associated with a tag applied to the word; generate pronunciation files for both an original language of the word and the selected language; and display, in context with the displayed portion of the content, the word in the original language and the selected language, the pictogram, and icons for requesting to play the pronunciation files via a call-out window.
14. The medium of claim 13, wherein when the selected unit of text is a sentence: display the selected unit of text in the selected language in place of the selected unit of text in the original language.
15. The medium of claim 13, wherein the instructions further direct the processor to, when the selected unit of text is the sentence: retrieve from the picture dictionary, a pictogram associated with a tag applied at least one word from the sentence forming the selected unit of text; generate pronunciation files for both an original language of the selected unit of text and the selected language; and display, in context with the displayed portion of the content, the selected unit of text in the original language and the selected language, the pictogram, and icons for requesting to play the pronunciation files.
16. The medium of claim 13, wherein the content comprises text in at least two languages.
17. The medium of claim 13, wherein the learning feature comprises one or both of: indicating part of speech; and indicating syllables.
18. The medium of claim 17, further comprising instructions that direct the processor to: identify the part of speech and syllables of each word; and tag words with their part of speech and entity identifier.
</claims>
</document>
