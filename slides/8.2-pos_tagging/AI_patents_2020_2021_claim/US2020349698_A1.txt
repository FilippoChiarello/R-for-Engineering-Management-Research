<document>

<filing_date>
2020-05-01
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2019-05-02
</priority_date>

<ipc_classes>
A61C13/34,A61C9/00,G06K9/62,G06N3/04,G06N3/08,G06T17/00,G06T19/20,G06T7/00
</ipc_classes>

<assignee>
ALIGN TECHNOLOGY
</assignee>

<inventors>
KATZ, RAN
BROWN, CHAD CLAYTON
Coslovsky, Jonathan
Agniashvili, Pavel
Minchenkov, Mikhail
</inventors>

<docdb_family_id>
73016540
</docdb_family_id>

<title>
EXCESS MATERIAL REMOVAL USING MACHINE LEARNING
</title>

<abstract>
A method includes processing an input comprising data from an intraoral image using a trained machine learning model that has been trained to classify regions of dental sites, wherein the trained machine learning model outputs a probability map comprising, for each pixel in the intraoral image, a first probability that the pixel belongs to a first dental class and a second probability that the pixel belongs to a second dental class, wherein the first dental class represents excess material, the excess material comprising material other than teeth or gums. The method further includes determining, based on the probability map, one or more pixels in the intraoral image that are classified as excess material. The method further includes hiding or removing from the intraoral image data for the one or more pixels that are classified as excess material.
</abstract>

<claims>
1. A method comprising: receiving an intraoral image of a dental site, the intraoral image comprising a height map; processing an input comprising data from the intraoral image using a trained machine learning model that has been trained to classify regions of dental sites, wherein the trained machine learning model outputs a probability map comprising, for each pixel in the intraoral image, a first probability that the pixel belongs to a first dental class and a second probability that the pixel belongs to a second dental class, wherein the first dental class represents excess material, the excess material comprising material other than teeth or gums; determining, based on the probability map, one or more pixels in the intraoral image that are classified as excess material; and hiding or removing from the intraoral image data for the one or more pixels that are classified as excess material.
2. The method of claim 1, further comprising: receiving a plurality of additional intraoral images of the dental site; processing a plurality of additional inputs using the trained machine learning model, wherein each additional input comprises data from one of the plurality of additional intraoral images, wherein for each additional input the trained machine learning model outputs an additional probability map comprising, for each pixel in an additional intraoral image associated with the additional input, an additional first probability that the pixel belongs to the first dental class and an additional second probability that the pixel belongs to the second dental class; for each additional intraoral image, determining zero or more pixels in the additional intraoral image that are classified as excess material based on the additional probability map associated with the additional intraoral image; for each additional intraoral image comprising one or more pixels that are classified as excess material, hiding or removing from the additional intraoral image data for the one or more pixels in the additional intraoral image that are classified as excess material; and generating a three-dimensional model of the dental site from the intraoral image and a plurality of additional intraoral images.
3. The method of claim 1, wherein the intraoral image is received from an intraoral scanner during an intraoral scanning session, and wherein the processing of the intraoral image is performed during the intraoral scanning session while another intraoral image is generated by the intraoral scanner.
4. The method of claim 1, wherein the intraoral image is a blended image comprising data from a sequence of raw intraoral images, the method further comprising: combining the data from the sequence of raw intraoral images to generate the blended image.
5. The method of claim 1, further comprising: receiving an additional image of the dental site that was generated prior to the intraoral image, wherein the input comprises the data from the intraoral image and additional data from the additional image.
6. The method of claim 5, further comprising: generating a three-dimensional model of the dental site from a plurality of previously received intraoral images; determining a plane associated with the intraoral image; and projecting the three-dimensional model of the dental site onto the plane to generate the additional image.
7. The method of claim 1, further comprising: receiving a color image of the dental site that is associated with the intraoral image of the dental site, wherein the input comprises the data from the intraoral image and additional data from the color image.
8. The method of claim 7, further comprising: determining an alignment between the color image and the intraoral image.
9. The method of claim 1, wherein the trained machine learning model comprises a recurrent neural network, and wherein the input further comprises a previous output of the recurrent neural network associated with a previous intraoral image of the dental site.
10. The method of claim 1, further comprising: receiving an additional image of the dental site generated under specific lighting conditions, wherein the input comprises the data from the intraoral image and additional data from the additional image, and wherein the specific lighting conditions comprise infrared illumination or ultraviolet illumination.
11. The method of claim 1, wherein each pixel in the intraoral image comprises a first value representing height and a second value representing intensity, and wherein the data from the intraoral image that is included in the input comprises the first value and the second value for each pixel.
12. The method of claim 1, wherein the probability map comprises, for each pixel in the intraoral image, the first probability that the pixel belongs to the first dental class, the second probability that the pixel belongs to the second dental class, and a third probability that the pixel belongs to a third dental class, wherein the second dental class represents teeth, and wherein the third dental class represents gums.
13. The method of claim 12, wherein: the probability map comprises an RGB image; R values of the RGB image are associated with a first one of the first dental class, the second dental class or the third dental class; G values in the RGB image are associated with a second one of the first dental class, the second dental class or the third dental class; and B values in the RGB image are associated with a third one of the first dental class, the second dental class or the third dental class.
14. The method of claim 1, wherein determining that a pixel is classified as excess material comprises: determining that the first probability that the pixel belongs to the first dental class that represents excess material exceeds a probability threshold.
15. The method of claim 1, wherein determining that a pixel is classified as excess material comprises: determining that the first probability that the pixel belongs to the first dental class that represents excess material exceeds the second probability that the pixel belongs to the second dental class.
16. The method of claim 1, wherein the probability map comprises, for each pixel in the intraoral image, the first probability that the pixel belongs to the first dental class, the second probability that the pixel belongs to the second dental class, a third probability that the pixel belongs to a third dental class, and a fourth probability that the pixel belongs to a fourth dental class, wherein the first dental class represents excess material not adjacent to teeth, wherein the second dental class represents teeth, wherein the third dental class represents gums, and wherein the fourth dental class represents excess material adjacent to teeth.
17. The method of claim 1, wherein the probability map comprises, for each pixel in the intraoral image, the first probability that the pixel belongs to the first dental class, the second probability that the pixel belongs to the second dental class, a third probability that the pixel belongs to a third dental class, and a fourth probability that the pixel belongs to a fourth dental class, wherein the second dental class represents teeth, wherein the third dental class represents gums, and wherein the fourth dental class represents one of an upper palate, a gingival line, a scan body, a finger, or a preparation tooth.
18. The method of claim 1, further comprising: generating a virtual three-dimensional (3D) model of the dental site using the intraoral image; and manufacturing a physical 3D model of the dental site from the virtual 3D model of the dental site, wherein the physical 3D model of the dental site lacks excess material.
19. A method comprising: receiving a plurality of intraoral images of a dental site, wherein each intraoral image of the plurality of intraoral images comprises a height map; processing a plurality of inputs using a trained machine learning model that has been trained to classify regions of dental sites, each of the plurality of inputs comprising data from one of the plurality of intraoral images; wherein for each intraoral image of the plurality of intraoral images, the trained machine learning model outputs a probability map comprising, for each pixel in the intraoral image, a first probability that the pixel belongs to a first dental class and a second probability that the pixel belongs to a second dental class, wherein the first dental class represents excess material, the excess material comprising material other than teeth or gums; and wherein as a result of the processing, a plurality of probability maps are generated, each probability map of the plurality of probability maps being associated with a respective intraoral image of the plurality of intraoral images; generating a three-dimensional model of the dental site from the plurality of intraoral images, wherein each point in the three-dimensional model is associated with one or more first probabilities that the point belongs to the first dental class and one or more second probabilities that the point belongs to the second dental class, wherein the one or more first probabilities and the one or more second probabilities are aggregated from the plurality of probability maps; for each point in the three-dimensional model, determining whether the point is classified as excess material based on at least one of a) the one or more first probabilities or b) the one or more second probabilities; and modifying the three-dimensional model by hiding or removing from the three-dimensional model those points that are classified as excess material.
20. The method of claim 19, wherein determining that a point in the three-dimensional model is classified as excess material comprises: for each intraoral image comprising a pixel that maps to the point, performing the following comprising: determining the first probability and the second probability for the pixel in the intraoral image; and determining whether the pixel is classified as excess material based on at least one of the first probability or the second probability; and determining a first number of intraoral images comprising a pixel that maps to the point for which the pixel is classified as excess material; determining a second number of intraoral images comprising a pixel that maps to the point for which the pixel is not classified as excess material; and determining that the first number is greater than the second number.
21. The method of claim 19, wherein each of the plurality of intraoral images is a blended image comprising data from a sequence of raw intraoral images.
22. The method of claim 19, wherein each of the plurality of inputs comprises data from at least two sequential intraoral images from the plurality of intraoral images.
23. The method of claim 19, further comprising: receiving a plurality of color images of the dental site, wherein each color image of the plurality of color images is associated with a corresponding intraoral image of the plurality of intraoral images, and wherein each of the plurality of inputs comprises data from an intraoral image of the plurality of intraoral images and additional data from a corresponding color image of the plurality of color images.
24. The method of claim 19, wherein the trained machine learning model comprises a recurrent neural network, and wherein each input other than a first input of the plurality of inputs further comprises a previous output of the recurrent neural network associated with a previous intraoral image of the plurality of intraoral images.
25. The method of claim 19, further comprising: receiving a plurality of additional images of the dental site generated under specific lighting conditions, wherein each additional image of the plurality of additional images is associated with a corresponding intraoral image of the plurality of intraoral images, and wherein each of the plurality of inputs comprises data from an intraoral image of the plurality of intraoral images and additional data from a corresponding additional image of the plurality of additional images, and wherein the specific lighting conditions comprise infrared illumination or ultraviolet illumination.
26. The method of claim 19, wherein each pixel in each intraoral image comprises a first value representing height and a second value representing intensity, and wherein for each input of the plurality of inputs the data from the intraoral image comprises the first value and the second value for each pixel in the intraoral image.
27. The method of claim 19, wherein each probability map of the plurality of probability maps comprises, for each pixel in the intraoral image associated with the probability map, the first probability that the pixel belongs to the first dental class, the second probability that the pixel belongs to the second dental class, and a third probability that the pixel belongs to a third dental class, wherein the second dental class represents teeth, and wherein the third dental class represents gums.
</claims>
</document>
