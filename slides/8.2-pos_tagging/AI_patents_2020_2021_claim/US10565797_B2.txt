<document>

<filing_date>
2018-02-17
</filing_date>

<publication_date>
2020-02-18
</publication_date>

<priority_date>
2018-02-17
</priority_date>

<ipc_classes>
G02B27/01,G06F3/01,G06T19/00,G06T7/00
</ipc_classes>

<assignee>
VARJO TECHNOLOGIES
</assignee>

<inventors>
OLLILA, MIKKO
NISSINEN, JOONAS
</inventors>

<docdb_family_id>
65433688
</docdb_family_id>

<title>
System and method of enhancing user's immersion in mixed reality mode of display apparatus
</title>

<abstract>
A system and a method for enhancing a user's immersion in a mixed reality mode of head-mounted display apparatus, the system being at least communicably coupled to the aforesaid display apparatus. The system includes at least one camera communicably coupled to a processor. The processor controls said camera to capture sequence of images of real-world environment; analyse sequence of images to identify spatial geometry of real objects in real-world environment and material categories to which real objects belong; process sequence of images to generate sequence of mixed-reality images, based upon spatial geometry and material category of at least one real object that is represented by at least one virtual object in sequence of mixed-reality images, wherein visual behaviour of at least one virtual object emulates at least one material property associated with material category of the at least one real object; and render the sequence of mixed-reality images.
</abstract>

<claims>
1. A system for enhancing a user's immersion in a mixed reality mode of a head-mounted display apparatus, the system being at least communicably coupled to the head-mounted display apparatus, the system comprising: at least one camera; and a processor communicably coupled to the at least one camera, wherein the processor is configured to: (i) control the at least one camera to capture a sequence of images of a given real-world environment; (ii) analyze the sequence of images to identify a spatial geometry of real objects present in the given real-world environment; (iii) analyze the sequence of images to identify material categories to which the real objects or their portions belong, wherein each real object or its portion belongs to its corresponding material category; (iv) process the sequence of images to generate a sequence of mixed-reality images, based upon the spatial geometry and the material category of at least one real object from amongst the real objects, wherein the at least one real object is to be represented by at least one virtual object in the sequence of mixed-reality images, the sequence of mixed-reality images is to be generated in a manner that a visual behaviour of the at least one virtual object in the sequence of mixed-reality images emulates at least one material property associated with the material category of the at least one real object; (v) render, at the head-mounted display apparatus, the sequence of mixed-reality images; (vi) generate an audio signal that is representative of an acoustic behaviour of the at least one virtual object, based upon the spatial geometry and the material category of the at least one real object, wherein the acoustic behaviour of the at least one virtual object is to emulate at least one material property associated with the material category of the at least one real object; and (vii) play the audio signal, at the head-mounted display apparatus, substantially simultaneously with the rendering of the sequence of mixed-reality images.
2. The system of claim 1, wherein the visual behaviour of the at least one virtual object is to be indicative of at least one of: an expected physical interaction between the at least one virtual object and at least one other virtual object, a lighting effect expected from a surface of the at least one real object.
3. The system of claim 1, wherein the system is at least communicably coupled to a haptic feedback device, wherein the processor is configured to: (viii) generate a haptic signal that is representative of a haptic behaviour of the at least one virtual object, based upon the spatial geometry and the material category of the at least one real object, wherein the haptic behaviour of the at least one virtual object is to emulate at least one material property associated with the material category of the at least one real object; and (ix) play the haptic signal, at the haptic feedback device, substantially simultaneously with the rendering of the sequence of mixed-reality images at the head-mounted display apparatus.
4. The system of claim 1, wherein the processor is configured to generate and store a three-dimensional model representing the spatial geometry and the material categories of the real objects in the given real-world environment, and to utilize the three-dimensional model to generate the sequence of mixed-reality images at (iv).
5. The system of claim 4, wherein the processor is configured to determine whether or not the given real-world environment maps to an existing three-dimensional model, and to utilize the existing three-dimensional model if it is determined that the given real-world environment maps to the existing three-dimensional model.
6. The system of claim 1, wherein the processor is configured to process the sequence of images at (iv) based upon the user's input regarding at least one of: a type of the given real-world environment, the user's preferences.
7. The system of claim 1, wherein the head-mounted display apparatus comprises means for detecting a gaze direction of the user, wherein the processor is configured to receive, from said means, information indicative of the detected gaze direction of the user, and to determine a region of interest in the given real-world environment based upon the detected gaze direction, further wherein, when processing the sequence of images at (iv), the processor is configured to select the at least one real object, from amongst the real objects, based upon the region of interest in the given real-world environment.
8. The system of claim 1, further comprising means for adjusting an orientation of the at least one camera, the head-mounted display apparatus comprising means for tracking a head orientation of the user, wherein the processor is configured to receive, from said means, information indicative of the head orientation of the user, and to control the means for adjusting the orientation of the at least one camera, based upon the head orientation of the user.
9. A method of enhancing a user's immersion in a mixed reality mode of a head-mounted display apparatus, the method comprising: (i) capturing, via at least one camera, a sequence of images of a given real-world environment; (ii) analyzing the sequence of images to identify a spatial geometry of real objects present in the given real-world environment; (iii) analyzing the sequence of images to identify material categories to which the real objects or their portions belong, wherein each real object or its portion belongs to its corresponding material category; (iv) processing the sequence of images to generate a sequence of mixed-reality images, based upon the spatial geometry and the material category of at least one real object from amongst the real objects, wherein the at least one real object is represented by at least one virtual object in the sequence of mixed-reality images, the sequence of mixed-reality images is generated in a manner that a visual behaviour of the at least one virtual object in the sequence of mixed-reality images emulates at least one material property associated with the material category of the at least one real object; (v) rendering, at the head-mounted display apparatus, the sequence of mixed-reality images; (vi) generating an audio signal that is representative of an acoustic behaviour of the at least one virtual object, based upon the spatial geometry and the material category of the at least one real object, wherein the acoustic behaviour of the at least one virtual object emulates at least one material property associated with the material category of the at least one real object; and (vii) playing the audio signal, at the head-mounted display apparatus, substantially simultaneously with the rendering of the sequence of mixed-reality images.
10. The method of claim 9, further comprising: (viii) generating a haptic signal that is representative of a haptic behaviour of the at least one virtual object, based upon the spatial geometry and the material category of the at least one real object, wherein the haptic behaviour of the at least one virtual object emulates at least one material property associated with the material category of the at least one real object; and (ix) playing the haptic signal, at a haptic feedback device, substantially simultaneously with the rendering of the sequence of mixed-reality images at the head-mounted display apparatus.
11. The method of claim 9, further comprising generating and storing a three-dimensional model representing the spatial geometry and the material categories of the real objects in the given real-world environment; and utilizing the three-dimensional model to generate the sequence of mixed-reality images at the step (iv).
12. The method of claim 11, further comprising determining whether or not the given real-world environment maps to an existing three-dimensional model; and utilizing the existing three-dimensional model if it is determined that the given real-world environment maps to the existing three-dimensional model.
13. The method of claim 9, wherein the processing of the sequence of images at the step (iv) is performed based upon the user's input regarding at least one of: a type of the given real-world environment, the user's preferences.
14. The method of claim 9, further comprising receiving, from the head-mounted display apparatus, information indicative of a gaze direction of the user; and determining a region of interest in the given real-world environment based upon the gaze direction of the user, wherein the processing of the sequence of images at the step (iv) comprises selecting the at least one real object, from amongst the real objects, based upon the region of interest in the given real-world environment.
15. The method of claim 9, further comprising receiving, from the head-mounted display apparatus, information indicative of a head orientation of the user; and adjusting an orientation of the at least one camera, based upon the head orientation of the user.
16. A computer program product comprising a non-transitory machine-readable data storage medium having stored thereon program instructions that, when accessed by a processing device, cause the processing device to: (i) receive, from at least one camera, a sequence of images of a given real-world environment, the at least one camera being communicably coupled to the processing device; (ii) analyze the sequence of images to identify a spatial geometry of real objects present in the given real-world environment; (iii) analyze the sequence of images to identify material categories to which the real objects or their portions belong, wherein each real object or its portion belongs to its corresponding material category; (iv) process the sequence of images to generate a sequence of mixed-reality images, based upon the spatial geometry and the material category of at least one real object from amongst the real objects, wherein the at least one real object is to be represented by at least one virtual object in the sequence of mixed-reality images, the sequence of mixed-reality images is to be generated in a manner that a visual behaviour of the at least one virtual object in the sequence of mixed-reality images emulates at least one material property associated with the material category of the at least one real object; (v) render, at a head-mounted display apparatus, the sequence of mixed-reality images, the head-mounted display apparatus being communicably coupled to the processing device; (vi) generate an audio signal that is representative of an acoustic behaviour of the at least one virtual object, based upon the spatial geometry and the material category of the at least one real object, wherein the acoustic behaviour of the at least one virtual object is to emulate at least one material property associated with the material category of the at least one real object; and (vii) play the audio signal, at the head-mounted display apparatus, substantially simultaneously with the rendering of the sequence of mixed-reality images.
17. The computer program product of claim 16, wherein, when accessed by the processing device, the program instructions cause the processing device to: (viii) generate a haptic signal that is representative of a haptic behaviour of the at least one virtual object, based upon the spatial geometry and the material category of the at least one real object, wherein the haptic behaviour of the at least one virtual object is to emulate at least one material property associated with the material category of the at least one real object; and (ix) play the haptic signal, at a haptic feedback device, substantially simultaneously with the rendering of the sequence of mixed-reality images at the head-mounted display apparatus, the haptic feedback device being communicably coupled to the processing device.
</claims>
</document>
