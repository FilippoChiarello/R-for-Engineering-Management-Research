<document>

<filing_date>
2019-09-26
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-26
</priority_date>

<ipc_classes>
G06F1/16,G06F3/01,G06F3/03,G06F3/16,G06T19/00,H04L29/08
</ipc_classes>

<assignee>
CTRL-LABS CORPORATION
</assignee>

<inventors>
BARTOV, NITZAN
BERENZWEIG, ADAM
BROWN, NAOR
COCHRAN, ROBERT
DIMAIOLO, ROBERT
DUYAN, JOSHUA
KAIFOSH, PATRICK
MAO, QIUSHI
REISMAN, JASON
STONE, JASMINE
WETMORE, DANIEL
</inventors>

<docdb_family_id>
69884253
</docdb_family_id>

<title>
NEUROMUSCULAR CONTROL OF PHYSICAL OBJECTS IN AN ENVIRONMENT
</title>

<abstract>
Methods and apparatus for controlling a physical object in an environment based, at least in part, on neuromuscular signals. The method comprises recording a plurality of neuromuscular signals from a plurality of neuromuscular sensors arranged on one or more wearable devices worn by a user, receiving a selection of a physical object within the environment, and controlling, based at least in part on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, an operation of the selected object within the environment.
</abstract>

<claims>
What is claimed is:
1. A computerized system for controlling a physical object in an environment based, at least in part, on neuromuscular signals, the system comprising:
a plurality of neuromuscular sensors configured to record a plurality of neuromuscular signals from a user, wherein the plurality of neuromuscular sensors are arranged on one or more wearable devices; and
at least one computer processor programmed to:
receive a selection of a physical object within the environment; and control, based at least in part on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, an operation of the selected physical object within the environment.
2. The computerized system of claim 1, wherein receiving the selection of the physical object within the environment comprises determining the selection of the physical object based, at least in part, on the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals.
3. The computerized system of claim 1, further comprising:
at least one storage device configured to store information describing an association between the plurality of neuromuscular signals and one or more selectable physical objects in the environment,
wherein determining the selection of the physical object is based, at least in part, on the stored information describing an association between the plurality of
neuromuscular signals and the one or more selectable physical objects in the
environment.
4. The computerized system of claim 3, wherein at least some of the one or more selectable physical objects in the environment are connected in the environment using at least one short range communication protocol.
5. The computerized system of claim 3, wherein the stored information describing an association between the plurality of neuromuscular signals and the one or more selectable objects in the environment comprises at least one inference model configured to map the plurality of neuromuscular signals to the one or more selectable physical objects in the environment.
6. The computerized system of claim 1, wherein the at least one computer processor is further programmed to:
identify a muscular activation state, based on the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals, and wherein receiving the selection of the physical object within the environment is based, at least in part, on the identified muscular activation state.
7. The computerized system of claim 6, wherein receiving the selection of the physical object within the environment based, at least in part, on the identified muscular activation state comprises using the muscular activation state to interact with a user interface to select from among one of a plurality of selectable physical objects.
8. The computerized system of claim 6, wherein the muscular activation state comprises a gesture, a pose, or a sub-muscular activation state.
9. The computerized system of claim 1, wherein receiving the selection of the physical object within the environment comprises automatically selecting the physical object based, at least in part, on user context and/or user behavior.
10. The computerized system of claim 1, wherein receiving the selection of the physical object within the environment is based, at least in part, on a proximity of the physical object to the user in the environment.
11. The computerized system of claim 10, wherein the at least one computer processor is further programmed to:
detect that the computerized system is within a particular range of a selectable physical object in the environment; and
establish a near field communication between the computerized system and the selectable physical object in response to the detection, wherein receiving a selection of the physical object within the environment is based, at least in part, on the established near field communication.
12. The computerized system of claim 1, further comprising:
an infrared receiver configured to receive infrared signals from one or more physical objects, and
wherein receiving the selection of the physical object within the environment is based, at least in part, on an infrared signal received by the infrared receiver.
13. The computerized system of claim 12, further comprising:
an infrared transmitter configured to transmit a broadcast infrared signal to the one or more physical objects, wherein the infrared signals received by the infrared receiver is received in response to transmitting the broadcast infrared signal.
14. The computerized system of claim 1, wherein the environment is an augmented reality environment generated by an augmented reality system.
15. The computerized system of claim 14, wherein the augmented reality system is configured to display a user interface within the augmented reality environment, and wherein receiving a selection of the object comprises receiving the selection of the object via the user interface.
16. The computerized system of claim 14, wherein receiving a selection of the physical object comprises determining the selection of the physical object based, at least in part, by the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals.
17. The computerized system of claim 16, wherein the at least one computer processor is further programmed to:
generate a control signal based, at least in part, on the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals; and
provide the control signal to the augmented reality system, wherein receiving the selection of the physical object in the environment is based, at least in part, on the control signal provided to the augmented reality system.
18. The computerized system of claim 17, wherein the augmented reality system is configured to display a cursor in the augmented reality environment,
wherein the control signal is for controlling a display position of the cursor in the augmented reality environment, and
wherein receiving the selection of the physical object in the environment is based, at least in part, on the display position of the cursor in the augmented reality
environment.
19. The computerized system of claim 14, wherein
the augmented reality system includes at least one camera and/or eye tracking system, and
receiving the selection of the physical object in the environment is based, at least in part, on information captured by the at least one camera and/or eye tracking system.
20. The computerized system of claim 19, wherein receiving the selection of the physical object in the environment is further based, at least in part, on the plurality of neuromuscular signals and/or the information derived from the plurality of
neuromuscular signals.
21. The computerized system of claim 1, wherein receiving a selection of the physical object within the environment comprises:
dividing the environment into a plurality of spatial areas;
determining based, at least in part, on an orientation of an inertial measurement unit which of the plurality of spatial areas the user is pointing to; and
selecting the physical object within the spatial area to which the user is pointing.
22. The computerized system of claim 1, further comprising a simultaneous location and mapping system, wherein receiving the selection of the physical object in the environment is based, at least in part, on information determined by the simultaneous location and mapping system.
23. The computerized system of claim 1, wherein receiving the selection of the physical object in the environment is based, at least in part, on information captured by at least one microphone.
24. The computerized system of claim 1, wherein the computerized system is configured to provide an indication to the user that the physical object has been selected.
25. The computerized system of claim 24, wherein the selected physical object is configured to provide the indication to the user upon selection.
26. The computerized system of claim 24, wherein the at least one computer processor is further programmed to provide the indication to the user upon selection of the physical object.
27. The computerized system of claim 24, wherein
the environment is an augmented reality environment generated by an augmented reality system,
the physical object is a physical object viewed in the augmented reality environment, and
the augmented reality system is configured to provide the indication to the user upon selection of the physical object viewed in the augmented reality environment.
28. The computerized system of claim 27, wherein providing an indication that the physical object has been selected comprises presenting a visual indication within the augmented reality environment.
29. The computerized system of claim 1, further comprising:
at least one storage device configured to store information describing an association between the plurality of neuromuscular signals and at least one control action for each of one or more selectable physical objects in the environment,
wherein controlling an operation of the selected object comprises determining the operation to control based, at least in part, on the stored information describing an association between the plurality of neuromuscular signals and the at least one control action for the selected physical object.
30. The computerized system of claim 29, wherein the stored information describing an association between the plurality of neuromuscular signals and the at least one control action for each of the one or more selectable physical objects in the environment comprises at least one inference model trained to map the plurality of neuromuscular signals to the at least one control action for each of the one or more selectable physical objects in the environment.
31. The computerized system of claim 1, wherein the at least one computer processor is further programmed to:
identify a muscular activation state, based on the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals, and wherein controlling an operation of the selected physical object is performed based, at least in part, on the identified muscular activation state.
32. The computerized system of claim 1, wherein the muscular activation state comprises a gesture, a pose, or a sub-muscular activation state.
33. The computerized system of claim 1, wherein the environment is an augmented reality environment generated by an augmented reality system, and
wherein controlling the operation of the selected physical object within the environment comprises controlling the operation of the selected physical object via input provided to the augmented reality system.
34. The computerized system of claim 33, wherein the augmented reality system is configured to display a control interface within the augmented reality environment, and wherein controlling the operation of the selected physical object comprises controlling the operation of the object via a user interaction with the control interface.
35. The computerized system of claim 34, wherein controlling the operation of the selected physical object comprises: generating a control signal based, at least in part, on the plurality of
neuromuscular signals and/or the information derived from the plurality of
neuromuscular signals; and
providing the control signal to the augmented reality system to interact with the control interface displayed in the augmented reality environment.
36. The computerized system of claim 32, wherein
the augmented reality system is configured to display the control interface at a first location in the augmented reality environment,
the selected physical object viewed in the augmented reality environment is located at a second location in the augmented reality environment, and
the first location is closer to the user than the second location in the augmented reality environment.
37. The computerized system of claim 33, wherein the augmented reality system is configured to provide feedback to the user in response to the interaction with the control interface.
38. The computerized system of claim 37, wherein the feedback comprises visual feedback, auditory feedback, and/or haptic feedback.
39. The computerized system of claim 36, wherein the augmented reality system is configured to display a first control interface for a first object and a second control interface for a second object in the augmented reality environment.
40. The computerized system of claim 39, wherein the augmented reality system is configured to display the first control interface when the first object is selected and the second control interface when the second object is selected.
41. The computerized system of claim 1, wherein the at least one computer processor is further programmed to: detect, based at least in part on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, a first muscular activation state indicating a desire to control an operation of the selected physical object.
42. The computerized system of claim 41, wherein the first muscular activation state is a wake-up muscular activation state for the selected physical object.
43. The computerized system of claim 41, wherein the at least one computer processor is further programmed to:
send an instruction to the selected physical object to enable or disable a user interface of the selected physical object in response to detecting the first muscular activation state.
44. The computerized system of claim 43, wherein sending an instruction to the selected physical object comprises sending an instruction to enable the user interface, and wherein the at least one computer processor is further programmed to:
detect, based at least in part on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, a second muscular activation state,
wherein controlling an operation of the selected physical object comprises controlling an operation of the selected physical object based, at least in part, on the second muscular activation state.
45. A method performed by a computerized system for controlling a physical object in an environment based, at least in part, on neuromuscular signals, the method comprising:
recording a plurality of neuromuscular signals from a plurality of neuromuscular sensors arranged on one or more wearable devices worn by a user;
receiving a selection of a physical object within the environment; and
controlling, based at least in part on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, an operation of the selected physical object within the environment.
46. The method of claim 45, wherein receiving the selection of the physical object within the environment comprises determining the selection of the physical object based, at least in part, on the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals.
47. The method of claim 45, wherein determining the selection of the physical object is based, at least in part, on stored information describing an association between the plurality of neuromuscular signals and one or more selectable physical objects in the environment.
48. The method of claim 45, further comprising:
identifying a muscular activation state, based on the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals, and wherein receiving the selection of the physical object within the environment is based, at least in part, on the identified muscular activation state.
49. The method of claim 48, wherein receiving the selection of the physical object within the environment based, at least in part, on the identified muscular activation state comprises using the muscular activation state to interact with a user interface to select from among one of a plurality of selectable physical objects.
50. The method of claim 48, wherein receiving the selection of the physical object within the environment comprises automatically selecting the physical object based, at least in part, on user context and/or user behavior.
51. The method of claim 48, wherein receiving the selection of the physical object within the environment is based, at least in part, on a proximity of the physical object to the user in the environment.
52. The method of claim 51, further comprising:
detecting that the computerized system is within a particular range of a selectable physical object in the environment; and establishing a near field communication between the computerized system and the selectable physical object in response to the detection,
wherein receiving a selection of the physical object within the environment is based, at least in part, on the established near field communication.
53. The method of claim 45, further comprising receiving an infrared signal,
wherein receiving the selection of the physical object within the environment is based, at least in part, on the received infrared signal.
54. The method of claim 53, further comprising transmitting a broadcast infrared signal to the one or more physical objects,
wherein the infrared signals received by the infrared receiver is received in response to transmitting the broadcast infrared signal.
55. The method of claim 45, wherein
the environment is an augmented reality environment generated by an augmented reality system,
the augmented reality system is configured to display a user interface within the augmented reality environment, and
receiving a selection of the object comprises receiving the selection of the object via the user interface.
56. The method of claim 55, wherein receiving a selection of the physical object comprises determining the selection of the physical object based, at least in part, by the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals.
57. The method of claim 56, further comprising:
generating a control signal based, at least in part, on the plurality of
neuromuscular signals and/or the information derived from the plurality of
neuromuscular signals; and
providing the control signal to the augmented reality system, wherein receiving the selection of the physical object in the environment is based, at least in part, on the control signal provided to the augmented reality system.
58. The method of claim 45, wherein receiving a selection of the physical object within the environment comprises:
dividing the environment into a plurality of spatial areas;
determining based, at least in part, on an orientation of an inertial measurement unit which of the plurality of spatial areas the user is pointing to; and
selecting the physical object within the spatial area to which the user is pointing.
59. The method of claim 45, further comprising providing an indication to the user that the physical object has been selected.
60. The method of claim 59, wherein
the environment is an augmented reality environment generated by an augmented reality system,
the physical object is a physical object viewed in the augmented reality environment, and
the augmented reality system is configured to provide the indication to the user upon selection of the physical object viewed in the augmented reality environment.
61. The method of claim 45, further comprising:
storing, on at least one storage device, information describing an association between the plurality of neuromuscular signals and at least one control action for each of one or more selectable physical objects in the environment,
wherein controlling an operation of the selected object comprises determining the operation to control based, at least in part, on the stored information describing an association between the plurality of neuromuscular signals and the at least one control action for the selected physical object.
62. The method of claim 45, further comprising:
identifying a muscular activation state, based on the plurality of neuromuscular signals and/or the information derived from the plurality of neuromuscular signals, and wherein controlling an operation of the selected physical object is performed based, at least in part, on the identified muscular activation state.
63. The method of claim 45, wherein the environment is an augmented reality environment generated by an augmented reality system, and
wherein controlling the operation of the selected physical object within the environment comprises controlling the operation of the selected physical object via input provided to the augmented reality system.
64. The method of claim 45, further comprising:
detecting, based at least in part on the plurality of neuromuscular signals and/or information based on the neuromuscular signals, a first muscular activation state indicating a desire to control an operation of the selected physical object.
65. The method of claim 64, wherein the first muscular activation state is a wake-up muscular activation state for the selected physical object.
66. The method of claim 65, further comprising:
sending an instruction to the selected physical object to enable or disable a user interface of the selected physical object in response to detecting the first muscular activation state.
67. The method of claim 66, wherein sending an instruction to the selected physical object comprises sending an instruction to enable the user interface, and wherein the method further comprises:
detecting, based at least in part on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, a second muscular activation state,
wherein controlling an operation of the selected physical object comprises controlling an operation of the selected physical object based, at least in part, on the second muscular activation state.
68. At least one non-transitory computer-readable storage medium storing
instructions that, when executed by at least one computer processor, causes the at least one computer processor to perform a method according to any of claims 45-67.
69. A computerized system for controlling a physical object in an environment based, at least in part, on neuromuscular signals, the system comprising:
a plurality of neuromuscular sensors configured to record a plurality of neuromuscular signals from a user, wherein the plurality of neuromuscular sensors are arranged on one or more wearable devices; and
at least one computer processor programmed to:
select a physical object within an environment of the user; provide feedback to the user indicating that the physical object has been selected;
determine a first muscular activation state, based, at least in part, on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals; and
control an operation of the selected physical object based, at least in part, on the determined first muscular activation state.
70. The computerized system of claim 69, further comprising:
at least one storage device configured to store information describing an association between one or more selectable physical objects in the environment and a plurality of muscular activation states,
wherein selecting the physical object within the environment is based, at least in part, on the stored information.
71. The computerized system of claim 69, wherein
the plurality of neuromuscular signals used, at least in part, to determine the first muscular activation state are recorded during a first time period,
the at least one computer processor is further programmed to determine a second muscular activation state based, at least in part, on a plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals recorded during a second time period, and selecting the physical object within the environment of the user is based, at least in part, on the determined second muscular activation state.
72. The computerized system of claim 69, wherein selecting the physical object is based, at least in part, on user context and/or user behavior.
73. The computerized system of claim 69, wherein
the at least one computer processor is further programmed to receive speech input from the user, and
selecting the physical object is based, at least in part, on the received speech input.
74. The computerized system of claim 69, wherein selecting the physical object is based, at least in part, on a proximity of the user to the physical object.
75. The computerized system of claim 74, wherein selecting the physical object is based, at least in part, on a proximity of the user to the physical object relative to other selectable physical objects in the environment of the user.
76. The computerized system of claim 69, wherein providing feedback to the user indicating that the physical object has been selected comprises instructing the selected physical object to provide the feedback.
77. The computerized system of claim 69, wherein providing feedback to the user indicating that the physical object has been selected comprises providing one or more of auditory feedback and vibratory feedback.
78. The computerized system of claim 69, further comprising:
at least one storage device configured to store information describing an association between at least one control action for each of one or more selectable physical objects in the environment and a corresponding muscular activation state including the first muscular activation state, wherein controlling an operation of the selected physical object is based, at least in part, on the stored information describing an association between the at least one control action for the selected physical object and the first muscular activation state.
79. The computerized system of claim 69, wherein the at least one computer processor is further programmed to:
detect, based at least in part on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, a second muscular activation state indicating a desire to control an operation of the selected physical object.
80. The computerized system of claim 79, wherein the at least one computer processor is further programmed to:
send an instruction to the selected physical object to enable or disable a user interface of the selected physical object in response to detecting the second muscular activation state, wherein sending an instruction to the selected physical object comprises sending an instruction to enable the user interface; and
control an operation of the selected physical object based, at least in part, on the first muscular activation state after the user interface has been enabled.
81. A method performed by a computerized system for controlling a physical object in an environment based, at least in part, on neuromuscular signals, the method comprising:
recording a plurality of neuromuscular signals from a plurality of neuromuscular sensors arranged on one or more wearable devices;
selecting a physical object within an environment of the user;
providing feedback to the user indicating that the physical object has been selected;
determining a first muscular activation state, based, at least in part, on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals; and
controlling an operation of the selected physical object based, at least in part, on the determined first muscular activation state.
82. The method of claim 81, further comprising:
storing, on at least one storage device, information describing an association between one or more selectable physical objects in the environment and a plurality of muscular activation states,
wherein selecting the physical object within the environment is based, at least in part, on the stored information.
83. The method of claim 81, wherein selecting the physical is further based, at least in part, on user context and/or user behavior.
84. The method of claim 81, further comprising:
receiving speech input from the user,
wherein selecting the physical object is based, at least in part, on the received speech input.
85. The method of claim 81, wherein selecting the physical object is based, at least in part, on a proximity of the user to the physical object.
86. The method of claim 81, wherein providing feedback to the user indicating that the physical object has been selected comprises instructing the selected physical object to provide the feedback.
87. The method of claim 81, further comprising:
storing, by at least one storage device, information describing an association between at least one control action for each of one or more selectable physical objects in the environment and a corresponding muscular activation state including the first muscular activation state,
wherein controlling an operation of the selected physical object is based, at least in part, on the stored information describing an association between the at least one control action for the selected physical object and the first muscular activation state.
88. The method of claim 81, further comprising: detecting, based at least in part on the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals, a second muscular activation state indicating a desire to control an operation of the selected physical object; and
sending an instruction to the selected physical object to enable or disable a user interface of the selected physical object in response to detecting the second muscular activation state.
89. The method of claim 88, wherein sending an instruction to the selected physical object comprises sending an instruction to enable the user interface, and wherein the method further comprises:
controlling an operation of the selected physical object based, at least in part, on the first muscular activation state after the user interface has been enabled.
90. The method of claim 88, wherein
the plurality of neuromuscular signals used, at least in part, to determine the first muscular activation state are recorded during a first time period,
the method further comprises determining a second muscular activation state based, at least in part, on a plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals recorded during a second time period, and
selecting the physical object within the environment of the user is based, at least in part, on the determined second muscular activation state.
91. At least one non-transitory computer-readable storage medium storing instructions that, when executed by at least one computer processor, causes the at least one computer processor to perform a method according to any of claims 81-90.
</claims>
</document>
