<document>

<filing_date>
2019-11-13
</filing_date>

<publication_date>
2020-05-14
</publication_date>

<priority_date>
2018-11-13
</priority_date>

<ipc_classes>
G05B13/02,G05D1/00,G05D1/02,G06N3/04
</ipc_classes>

<assignee>
QUALCOMM
</assignee>

<inventors>
NAGHSHVAR, MOHAMMAD
SADEK, AHMED KAMEL
WIGGERS, AUKE JORIS
</inventors>

<docdb_family_id>
70551448
</docdb_family_id>

<title>
HYBRID REINFORCEMENT LEARNING FOR AUTONOMOUS DRIVING
</title>

<abstract>
A method includes determining a current state of an environment of an autonomous agent, such as a vehicle. The method also includes determining, via a first neural network, a set of actions based on the current state. The method further includes determining whether further analysis of the set of actions is desired. The method selects an action from the set of actions using a model-based solution based on a reward and a risk of the action when further analysis is desired. The method also includes selecting the action from the set of actions according to a metric when further analysis is not desired. The method controls the autonomous agent to perform the selected action.
</abstract>

<claims>
1. A method, comprising: determining a current state of an environment of an autonomous agent; determining, via a first neural network, a set of actions based on the current state; determining whether further analysis of the set of actions is desired; selecting an action from the set of actions using a model-based solution based on a reward and a risk of the action when further analysis is desired; selecting the action from the set of actions according to a metric when further analysis is not desired; and controlling the autonomous agent to perform the selected action.
2. The method of claim 1, in which the first neural network is a model-free neural network.
3. The method of claim 1, further comprising determining whether further analysis of the set of actions is desired based on a solution implemented by a decision making system.
4. The method of claim 1, further comprising: determining a utility function for each action in the set of actions; and determining whether further analysis is desired based on the utility function for each action in the set of actions and a variance.
5. The method of claim 2, further comprising: processing the set of actions with a second model-free neural network; processing the set of actions with the model-based solution; and selecting the action from a combination of outputs of the second model-free neural network and the model-based solution.
6. The method of claim 1, in which: the action comprises a default action when a difference between outputs of the model-based solution and the first neural network is greater than a threshold value; and the difference is computed by a utility function.
7. The method of claim 1, further comprising: processing the set of actions with a set of model-free neural networks; processing the set of actions with a set of model-based solutions; and selecting the action from a combination of outputs of the set of model-free neural networks and the set of model-based solutions.
8. The method of claim 7, in which the combination of outputs is based on voting.
9. The method of claim 1, further comprising determining the current state of the environment based on at least one of a camera, a radio detection and ranging (RADAR) sensor, a light detection and ranging (LIDAR) sensor, or a combination thereof.
10. An apparatus comprising: a memory; and at least one processor coupled to the memory, the at least one processor configured: to determine a current state of an environment of an autonomous agent; to determine, via a first neural network, a set of actions based on the current state; to determine whether further analysis of the set of actions is desired; to select an action from the set of actions using a model-based solution based on a reward and a risk of the action when further analysis is desired; to select the action from the set of actions according to a metric when further analysis is not desired; and to control the autonomous agent to perform the action.
11. The apparatus of claim 10, in which the first neural network is a model-free neural network.
12. The apparatus of claim 10, in which the at least one processor is further configured to determine whether further analysis of the set of actions is desired based on a solution implemented by a decision making system.
13. The apparatus of claim 10, in which the at least one processor is further configured: to determine a utility function for each action in the set of actions; and to determine whether further analysis is desired based on the utility function for each action in the set of actions and a variance.
14. The apparatus of claim 11, in which the at least one processor is further configured: to process the set of actions with a second model-free neural network; to process the set of actions with the model-based solution; and to select the action from a combination of outputs of the second model-free neural network and the model-based solution.
15. The apparatus of claim 10, in which: the action comprises a default action when a difference between outputs of the model-based solution and the first neural network is greater than a threshold value; and the difference is computed by a utility function.
16. The apparatus of claim 10, in which the at least one processor is further configured: to process the set of actions with a set of model-free neural networks; to process the set of actions with a set of model-based solutions; and to select the action from a combination of outputs of the set of model-free neural networks and the set of model-based solutions.
17. The apparatus of claim 16, in which the combination of outputs is based on voting.
18. The apparatus of claim 10, in which the at least one processor is further configured to determine the current state of the environment based on at least one of a camera, a radio detection and ranging (RADAR) sensor, a light detection and ranging (LIDAR) sensor, or a combination thereof.
19. A non-transitory computer-readable medium having program code recorded thereon, the program code executed by a processor and comprising: program code to determine a current state of an environment of an autonomous agent; program code to determine, via a first neural network, a set of actions based on the current state; program code to determine whether further analysis of the set of actions is desired; program code to select an action from the set of actions using a model-based solution based on a reward and a risk of the action when further analysis is desired; program code to select the action from the set of actions according to a metric when further analysis is not desired; and program code to control the autonomous agent to perform the action.
20. The non-transitory computer-readable medium of claim 19, in which the program code further comprises: program code to determine a utility function for each action in the set of actions; and program code to determine whether further analysis is desired based on the utility function for each action in the set of actions and a variance.
21. The non-transitory computer-readable medium of claim 19, in which the program code further comprises: program code to process the set of actions with a second model-free neural network, when the first neural network comprises a first model-free neural network; program code to process the set of actions with the model-based solution; and program code to select the action from a combination of outputs of the second model-free neural network and the model-based solution.
22. The non-transitory computer-readable medium of claim 19, in which: the action comprises a default action when a difference between outputs of the model-based solution and the first neural network is greater than a threshold value; and the difference is computed by a utility function.
23. The non-transitory computer-readable medium of claim 19, in which the program code further comprises: program code to process the set of actions with a set of model-free neural networks; program code to process the set of actions with a set of model-based solutions; and program code to select the action from a combination of outputs of the set of model-free neural networks and the set of model-based solutions.
24. The non-transitory computer-readable medium of claim 23, in which the combination of outputs is based on voting.
25. The non-transitory computer-readable medium of claim 19, in which the program code further comprises program code to determine the current state of the environment based on at least one of a camera, a radio detection and ranging (RADAR) sensor, a light detection and ranging (LIDAR) sensor, or a combination thereof.
26. An apparatus comprising: means for determining a current state of an environment of an autonomous agent; means for determining, via a first neural network, a set of actions based on the current state; means for determining whether further analysis of the set of actions is desired; means for selecting an action from the set of actions using a model-based solution based on a reward and a risk of the action when further analysis is desired; means for selecting the action from the set of actions according to a metric when further analysis is not desired; and means for controlling the autonomous agent to perform the action.
27. The apparatus of claim 26, further comprising: means for determining a utility function for each action in the set of actions; and means for determining whether further analysis is desired based on the utility function for each action in the set of actions and a variance.
28. The apparatus of claim 26, further comprising: means for processing the set of actions with a second model-free neural network, when the first neural network comprises a first model-free neural network; means for processing the set of actions with the model-based solution; and means for selecting the action from a combination of outputs of the second model-free neural network and the model-based solution.
29. The apparatus of claim 26, in which: the action comprises a default action when a difference between outputs of the model-based solution and the first neural network is greater than a threshold value; and the difference is computed by a utility function.
30. The apparatus of claim 26, further comprising: means for processing the set of actions with a set of model-free neural networks; means for processing the set of actions with a set of model-based solutions; and means for selecting the action from a combination of outputs of the set of model-free neural networks and the set of model-based solutions.
</claims>
</document>
