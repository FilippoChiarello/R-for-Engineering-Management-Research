<document>

<filing_date>
2019-11-26
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-05
</priority_date>

<ipc_classes>
G06K9/46,G06K9/62,G06K9/66,G06N3/04,G06N3/08,G06T7/11
</ipc_classes>

<assignee>
SEOUL NATIONAL UNIVERSITY
</assignee>

<inventors>
ZHANG, BYOUNG TAK
KIM, TAEHYEONG
SON, SEON IL
PARK, KYUNG-WHA
HEO, MIN-OH
</inventors>

<docdb_family_id>
70971078
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR GENERATING STORY FROM PLURALITY OF IMAGES BY USING DEEP LEARNING NETWORK
</title>

<abstract>
Disclosed herein are a visual story generation method and apparatus for generating a story from a plurality of images by using a deep learning network. The visual story generation method includes: extracting features from a plurality of respective images by using the first extraction unit of a deep learning network; generating the structure of a story based on the overall feature of the plurality of images by using the second extraction unit of the deep learning network; and generating the story by using outputs of the first and second extraction units.
</abstract>

<claims>
1. A visual story generation method for generating a story from a plurality of images by using a deep learning network, the visual story generation method comprising: extracting features from a plurality of respective images by using a first extraction unit of a deep learning network; generating a structure of a story based on an overall feature of the plurality of images by using a second extraction unit of the deep learning network; and generating the story by using outputs of the first and second extraction units.
2. The visual story generation method of claim 1, wherein generating the structure of the story comprises: inputting the extracted features of the plurality of respective images to the second extraction unit including bidirectional long short-term memory (LSTM) of two or more layers; extracting, by the second extraction unit, the overall feature of the plurality of images; understanding, by the second extraction unit, context based on the overall feature; and generating, by the second extraction unit, the structure of the story based on the understood context.
3. The visual story generation method of claim 1, wherein generating the story comprises generating the story based on the generated structure of the story and generating sentences by connecting pieces of information between sentences included in the story.
4. The visual story generation method of claim 3, wherein generating the story is performed by applying a cascading mechanism such that a hidden value output by each sentence generator included in a story generation module configured to generate the sentences is input to a subsequent sentence generator.
5. The visual story generation method of claim 1, wherein extracting the features from the plurality of respective images comprises extracting features from the plurality of respective images by using a convolution neural network.
6. A non-transitory computer-readable storage medium having stored thereon a program that performs the method set forth in claim 1.
7. A visual story generation apparatus for generating a story from a plurality of images by using a deep learning network, the visual story generation apparatus comprising: an input/output unit configured to receive a plurality of images from an outside, and to output a story generated from the plurality of images; a storage unit configured to store a program for generating a story from a plurality of images; and a control unit configured to include at least one processor; wherein a deep learning network that is implemented by executing the program by the control unit comprises: a first extraction unit configured to extract features of the plurality of respective images; a second extraction unit configured to generate a structure of the story based an overall feature of the plurality of images; and a story generation module configured to generate the story by using outputs of the first extraction unit and the second extraction unit.
8. The visual story generation apparatus of claim 7, wherein: the second extraction unit includes bidirectional LSTM of two or more layers; and the second extraction unit receives the features of the plurality of respective images extracted by the first extraction unit, extracts the overall feature of the plurality of images, understands context based on the overall feature, and generates the structure of the story based on the understood context.
9. The visual story generation apparatus of claim 7, wherein the story generation module generates the story based on the generated structure of the story and generates sentences by connecting pieces of information between sentences included in the story.
10. The visual story generation apparatus of claim 9, wherein: the story generation module comprises a plurality of sentence generators; and a cascading mechanism is applied to the story generation module such that a hidden value output by each of the plurality of sentence generators is input to a subsequent sentence generator.
11. The visual story generation apparatus of claim 7, wherein the first extraction unit is implemented using a convolution neural network.
</claims>
</document>
