<document>

<filing_date>
2020-01-23
</filing_date>

<publication_date>
2020-08-11
</publication_date>

<priority_date>
2019-01-23
</priority_date>

<ipc_classes>
G06F40/44,G06N3/04,G06N3/08,G06N5/04
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
CHAN, WILLIAM
USZKOREIT, JAKOB D.
KIROS, JAMIE RYAN
STERN, MITCHELL THOMAS
</inventors>

<docdb_family_id>
69743906
</docdb_family_id>

<title>
Generating neural network outputs using insertion operations
</title>

<abstract>
Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating network outputs using insertion operations.
</abstract>

<claims>
1. A method performed by one or more computers, the method comprising: receiving a network input; and generating a network output from the network input, wherein the network output comprises a plurality of outputs from a vocabulary of outputs arranged according to an output order, the generating comprising, at each of a plurality of generation time steps: identifying a current partial network output that has already been generated as of the generation time step, the current partial network output comprising zero or more outputs from the vocabulary of outputs arranged according to a partial output order; generating, using a decoder neural network conditioned on (i) at least a portion of the network input and (ii) any outputs in the current partial network output, a decoder output that defines, for each of a plurality of insertion locations, a respective score distribution over the vocabulary of outputs, wherein each insertion location is a different new location in the partial output order at which there is no output in the current partial network output, wherein the decoder neural network is an attention-based neural network that is configured to generate the decoder output by applying an attention mechanism over an encoded representation of the network input and a self-attention mechanism over the outputs in the current partial network output; selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary; and generating a new partial network output that comprises (i) the zero or more outputs in the current partial network output and (ii) for each selected insertion location, the inserted output from the vocabulary inserted at the corresponding new location in the partial output order.
2. The method of claim 1, wherein generating the decoder output using the decoder neural network comprises: generating a decoder input that includes the encoded representation of the network input and the outputs in the current partial network output arranged according to the partial output order.
3. The method of claim 2, wherein generating the decoder input further comprises adding two marker outputs to the current partial network output, wherein the decoder neural network is configured to generate a respective representation vector for each location in the partial output order after the two marker outputs have been added, and wherein generating the decoder output comprises: generating a respective slot representation for each insertion location by concatenating the representation vectors for each adjacent pair of locations in the partial output order; and generating a score distribution for each insertion location from at least the slot representation for the insertion location.
4. The method of claim 1, wherein the vocabulary includes an end-of-sequence token.
5. The method of claim 4, wherein selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary comprises: determining that an insertion location-output combination with a highest score across all insertion location-output combinations does not include the end-of-sequence token; and in response, selecting only the insertion location-output combination with a highest score across all insertion location-output combinations.
6. The method of claim 4, wherein selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary comprises: determining that there is at least one insertion location for which the output with the highest score is not the end-of-sequence token; and in response, selecting only an insertion location-output combination with a highest score across all insertion location-output combinations that include an insertion location for which the output with the highest score is not the end-of-sequence token.
7. The method of claim 4, wherein selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary comprises: identifying, from the decoder output and for each insertion location, an output that has a highest score for the insertion location; determining that there is at least one insertion location for which the output with the highest score is not the end-of-sequence token; and in response, selecting each insertion location for which the output with the highest score is not the end-of-sequence token and the corresponding output that has the highest score for the insertion location.
8. The method of claim 1, wherein the decoder neural network is configured to generate a respective slot representation for each insertion location.
9. The method of claim 8, wherein generating the decoder output comprises: projecting a decoder hidden state matrix generated from the slot representations using a projection matrix to generate a content-location logit matrix; flattening the content-location logit matrix into a content-location logit vector; and applying a softmax over the content-location logit vector to generate a probability distribution over all insertion location-output combinations.
10. The method of claim 8, wherein generating the decoder output comprises: generating a respective probability for each location by applying a softmax to a product of a decoder hidden state matrix generated from the slot representations and a learned query vector; for each location: projecting the slot representation for the location into a score vector that includes a respective score for each output in the vocabulary using a projection matrix; applying a softmax over the score vector to generate an initial probability for each output in the vocabulary; and multiplying each initial probability by the probability for the location to generate a final probability for each output in the vocabulary.
11. The method of claim 8, wherein generating the decoder output comprises: generating a context vector by applying max pooling over the slot representations; generating a bias vector from the context vector that includes a respective bias value for each output in the vocabulary; and generating the decoder output from the bias vector and the slot representations.
12. One or more non-transitory computer-readable storage media storing instructions that when executed by one or more computers cause the one or more computers to perform operations comprising: receiving a network input; and generating a network output from the network input, wherein the network output comprises a plurality of outputs from a vocabulary of outputs arranged according to an output order, the generating comprising, at each of a plurality of generation time steps: identifying a current partial network output that has already been generated as of the generation time step, the current partial network output comprising zero or more outputs from the vocabulary of outputs arranged according to a partial output order; generating, using a decoder neural network conditioned on (i) at least a portion of the network input and (ii) any outputs in the current partial network output, a decoder output that defines, for each of a plurality of insertion locations, a respective score distribution over the vocabulary of outputs, wherein each insertion location is a different new location in the partial output order at which there is no output in the current partial network output, wherein the decoder neural network is an attention-based neural network that is configured to generate the decoder output by applying an attention mechanism over an encoded representation of the network input and a self-attention mechanism over the outputs in the current partial network output; selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary; and generating a new partial network output that comprises (i) the zero or more outputs in the current partial network output and (ii) for each selected insertion location, the inserted output from the vocabulary inserted at the corresponding new location in the partial output order.
13. A system comprising one or more computers and one or more storage devices storing instructions that when executed by one or more computers cause the one or more computers to perform operations comprising: receiving a network input; and generating a network output from the network input, wherein the network output comprises a plurality of outputs from a vocabulary of outputs arranged according to an output order, the generating comprising, at each of a plurality of generation time steps: identifying a current partial network output that has already been generated as of the generation time step, the current partial network output comprising zero or more outputs from the vocabulary of outputs arranged according to a partial output order; generating, using a decoder neural network conditioned on (i) at least a portion of the network input and (ii) any outputs in the current partial network output, a decoder output that defines, for each of a plurality of insertion locations, a respective score distribution over the vocabulary of outputs, wherein each insertion location is a different new location in the partial output order at which there is no output in the current partial network output, wherein the decoder neural network is an attention-based neural network that is configured to generate the decoder output by applying an attention mechanism over an encoded representation of the network input and a self-attention mechanism over the outputs in the current partial network output; selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary; and generating a new partial network output that comprises (i) the zero or more outputs in the current partial network output and (ii) for each selected insertion location, the inserted output from the vocabulary inserted at the corresponding new location in the partial output order.
14. The system of claim 13, wherein generating the decoder output using the decoder neural network comprises: generating a decoder input that includes the encoded representation of the network input and the outputs in the current partial network output arranged according to the partial output order.
15. The system of claim 14, wherein generating the decoder input further comprises adding two marker outputs to the current partial network output, wherein the decoder neural network is configured to generate a respective representation vector for each location in the partial output order after the two marker outputs have been added, and wherein generating the decoder output comprises: generating a respective slot representation for each insertion location by concatenating the representation vectors for each adjacent pair of locations in the partial output order; and generating a score distribution for each insertion location from at least the slot representation for the insertion location.
16. The system of claim 14, wherein the vocabulary includes an end-of-sequence token.
17. The system of claim 16, wherein selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary comprises: determining that an insertion location-output combination with a highest score across all insertion location-output combinations does not include the end-of-sequence token; and in response, selecting only the insertion location-output combination with a highest score across all insertion location-output combinations.
18. The system of claim 16, wherein selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary comprises: determining that there is at least one insertion location for which the output with the highest score is not the end-of-sequence token; and in response, selecting only an insertion location-output combination with a highest score across all insertion location-output combinations that include an insertion location for which the output with the highest score is not the end-of-sequence token.
19. The system of claim 16, wherein selecting, using the decoder output, one or more of the insertion locations and, for each selected insertion location, an inserted output from the vocabulary comprises: identifying, from the decoder output and for each insertion location, an output that has a highest score for the insertion location; determining that there is at least one insertion location for which the output with the highest score is not the end-of-sequence token; and in response, selecting each insertion location for which the output with the highest score is not the end-of-sequence token and the corresponding output that has the highest score for the insertion location.
20. The system of claim 16, wherein the decoder neural network is configured to generate a respective slot representation for each insertion location, and wherein generating the decoder output comprises: projecting a decoder hidden state matrix generated from the slot representations using a projection matrix to generate a content-location logit matrix; flattening the content-location logit matrix into a content-location logit vector; and applying a softmax over the content-location logit vector to generate a probability distribution over all insertion location-output combinations.
</claims>
</document>
