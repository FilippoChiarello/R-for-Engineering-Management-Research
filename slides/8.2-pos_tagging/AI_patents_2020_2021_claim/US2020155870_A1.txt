<document>

<filing_date>
2017-12-27
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2017-06-30
</priority_date>

<ipc_classes>
A61B6/12,A61N5/10
</ipc_classes>

<assignee>
SHIMADZU CORPORATION
</assignee>

<inventors>
TAKAHASHI WATARU
OSHIKAWA, SHOTA
</inventors>

<docdb_family_id>
64740519
</docdb_family_id>

<title>
TRACKING DEVICE FOR RADIATION TREATMENT, POSITION DETECTION DEVICE, AND METHOD FOR TRACKING MOVING BODY
</title>

<abstract>
A control part 30 includes: a DRR image creation part 31 that creates a DRR image including a specific site; a specific site projection part 32 that creates a projection region image representing the region of the specific site; a discriminator learning part 33 that learns a discriminator for recognizing the region of the specific site by performing machine learning with use of the DRR image and the projection region image as a training label image; a specific site region detection part 34 that detects the region of the specific site by performing discrimination using the discriminator learned by the discriminator learning part 33 on an X-ray fluoroscopic image including the specific site; and a radiation signal generation part 35 that transmits a treatment beam radiation signal to an irradiation device 90 when the region of the specific site detected by the specific site region detection part 34 is included in the radiation region of a treatment beam.
</abstract>

<claims>
1. A tracking device for radiation treatment, the tracking device collecting an X-ray fluoroscopic image including a specific site of a subject, detecting a position of the specific site, and tracking a movement of the specific site in order to radiate a treatment beam to the specific site, the tracking device comprising: a DRR image creation part that creates a DRR image including the specific site by performing virtual fluoroscopic projection simulating geometrical fluoroscopic conditions between an X-ray tube and an X-ray detector with respect to the subject on CT image data on a region including the specific site, the CT image data being created at a time of treatment planning; a discriminator learning part that learns a discriminator for recognizing the region of the specific site by performing machine learning with use of the DRR image created by the DRR image creation part and a training label image indicating the region of the specific site; and a specific site region detection part that detects the region of the specific site by performing discrimination using the discriminator learned by the discriminator learning part on an X-ray fluoroscopic image including the specific site.
2. The tracking device for radiation treatment according to claim 1, the tracking device further comprising a specific site projection part that creates a projection region image representing the region of the specific site by performing the virtual fluoroscopic projection simulating the geometrical fluoroscopic conditions between the X-ray tube and the X-ray detector with respect to the subject on the region of the specific site registered on the CT image data on the region including the specific site at the time of the treatment planning, wherein the discriminator learning part learns the discriminator with the projection region image representing the region of the specific site as the training label image, the projection region image being created by the specific site projection part.
3. The tracking device for radiation treatment according to claim 2, wherein the DRR image creation part creates the DRR image with parameters including at least one of a projection coordinate and an angle among the geometrical fluoroscopic conditions changed or image processing including at least one of rotation, deformation, and scaling of an image performed, the specific site projection part creates the projection region image representing the region of the specific site parameters including at least one of a projection coordinate and an angle among the geometrical fluoroscopic conditions changed or image processing including at least one of rotation, deformation, and scaling of an image performed, and the DRR image creation part and the specific site projection part change parameters including at least one of a projection coordinate and an angle among the geometrical fluoroscopic conditions under a same condition, or perform image processing including at least one of rotation, deformation, and scaling of an image under a same condition.
4. The tracking device for radiation treatment according to claim 2, wherein the DRR image creation part performs at least one of contrast change, noise addition, and edge enhancement on the created DRR image.
5. The tracking device for radiation treatment according to claim 2, wherein the discriminator learning part learns a discriminator that is a neural network configured of a convolution layer with the DRR image as an input layer and a label image representing the region of the specific site as an output image.
6. The tracking device for radiation treatment according to claim 2, wherein when calculating a loss function for performing the machine learning, the discriminator learning part performs the calculation after increasing weight of a specific site label on a basis of areas of the specific site label and a background label in the training label image, and then performs the calculation while sequentially decreasing the weight of the specific site label as the learning progresses.
7. The tracking device for radiation treatment according to claim 2, wherein when calculating a loss function for performing the machine learning, the discriminator learning part weights a loss function for an image obtained by trimming a periphery of the specific site and adds a resulting loss function to a loss function for an entire image.
8. The tracking device for radiation treatment according to claim 2, the tracking device further comprising an image processing part that performs image processing of the DRR image and the X-ray fluoroscopic image, wherein the discriminator learning part performs the machine learning with use of the DRR image and a DRR image after the image processing by the image processing part, and the specific site region detection part performs the discrimination using the discriminator learned by the discriminator learning part on the X-ray fluoroscopic image including the specific site and an X-ray fluoroscopic image that includes the specific site and was subjected to the image processing by the image processing part under a same condition as for the DRR image.
9. A position detection device that detects a position of a specific site on a basis of an X-ray fluoroscopic image including the specific site of a subject, the position detection device comprising: a DRR image creation part that creates a DRR image including the specific site by performing virtual projection simulating geometrical fluoroscopic conditions between an X-ray tube and an X-ray detector with respect to the subject on CT image data on a region including the specific site; a discriminator learning part that learns a discriminator for recognizing the region of the specific site by performing machine learning with use of the DRR image created by the DRR image creation part and a training label image indicating the region of the specific site; and a specific site region detection part that detects the region of the specific site by performing discrimination using the discriminator learned by the discriminator learning part on an X-ray image including the specific site.
10. The position detection device according to claim 9, further comprising a specific site projection part that creates a projection region image representing the region of the specific site by performing the virtual fluoroscopic projection simulating the geometrical fluoroscopic conditions between the X-ray tube and the X-ray detector with respect to the subject on the region of the specific site registered on the CT image data on the region including the specific site at a time of treatment planning, wherein the discriminator learning part learns the discriminator with the projection region image representing the region of the specific site as the training label image, the projection region image being created by the specific site projection part.
11. The position detection device according to claim 10, wherein the DRR image creation part creates the DRR image with parameters including at least one of a projection coordinate and an angle among the geometrical fluoroscopic conditions changed or image processing including at least one of rotation, deformation, and scaling of an image performed, the specific site projection part creates the projection region image representing the region of the specific site with parameters including at least one of a projection coordinate and an angle among the geometrical fluoroscopic conditions changed or image processing including at least one of rotation, deformation, and scaling of an image performed, and the DRR image creation part and the specific site projection part change parameters including at least one of a projection coordinate and an angle among the geometrical fluoroscopic conditions under a same condition, or perform image processing including at least one of rotation, deformation, and scaling of an image under a same condition.
12. The position detection device according to claim 10, wherein the DRR image creation part performs at least one of contrast change, noise addition, and edge enhancement on the created DRR image.
13. The position detection device according to claim 10, wherein the discriminator learning part learns a discriminator that is a neural network configured of a convolution layer with the DRR image as an input layer and a label image representing the region of the specific site as an output image.
14. The position detection device according to claim 10, wherein when calculating a loss function for performing the machine learning, the discriminator learning part performs the calculation after increasing weight of a specific site label on a basis areas of the specific site label and a background label in the training label image, and then performs the calculation while sequentially decreasing the weight of the specific site label as the learning progresses.
15. The position detection device according to claim 10, wherein when calculating a loss function for performing the machine learning, the discriminator learning part weights a loss function for an image obtained by trimming a periphery of the specific site and adds a resulting loss function to a loss function for an entire image.
16. The position detection device according to claim 10, further comprising an image processing part that performs image processing of the DRR image and the X-ray fluoroscopic image, wherein the discriminator learning part performs the machine learning with use of the DRR image and a DRR image after the image processing by the image processing part, and the specific site region detection part performs the discrimination using the discriminator learned by the discriminator learning part on the X-ray fluoroscopic image including the specific site and an X-ray fluoroscopic image that includes the specific site and was subjected to the image processing by the image processing part under a same condition as for the DRR image.
17. A method for tracking a moving body, the method collecting an X-ray fluoroscopic image including a specific site of a subject, detecting a position of the specific site, and tracking a movement of the specific site in order to radiate a treatment beam to the specific site, the method comprising: a DRR image creation step of creating a DRR image including the specific site by performing virtual fluoroscopic projection simulating geometrical fluoroscopic conditions between an X-ray tube and an X-ray detector with respect to the subject on CT image data on a region including the specific site, the CT image data being created at a time of treatment planning; a specific site projection step of creating a projection region image representing the region of the specific site by performing the virtual fluoroscopic projection simulating the geometrical fluoroscopic conditions between the X-ray tube and the X-ray detector with respect to the subject on the region of the specific site registered on the CT image data on the region including the specific site at the time of the treatment planning; a discriminator learning step of learning a discriminator for recognizing a position of the specific site by performing machine learning with use of the DRR image created in the DRR image creation step and the projection region image created in the specific site projection step; and a specific site region detection step of detecting the region of the specific site by performing discrimination using the discriminator learned in the discriminator learning step on an X-ray fluoroscopic image including the specific site, the X-ray fluoroscopic image being obtained by detecting an X-ray passing through the subject after radiation from the X-ray tube with use of the X-ray detector.
</claims>
</document>
