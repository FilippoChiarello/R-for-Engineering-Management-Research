<document>

<filing_date>
2020-06-05
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2019-07-04
</priority_date>

<ipc_classes>
G06K9/32,G06K9/62
</ipc_classes>

<assignee>
NATIONAL CHIAO TUNG UNIVERSITY
</assignee>

<inventors>
GUO, JIUN-IN
WU, Tai-En
</inventors>

<docdb_family_id>
74065742
</docdb_family_id>

<title>
METHOD AND SYSTEM FOR IDENTIFYING A PEDESTRIAN
</title>

<abstract>
A method and system for identifying a pedestrian is disclosed. The method comprises: capturing a original image and detecting a pedestrian in the original image so as to obtain a 2D pedestrian feature image; obtaining a 3D information and identifying the 3D information so as to obtain a 3D pedestrian feature map; projecting the 3D pedestrian feature map to a 2D pedestrian feature plane image; and matching the 2D pedestrian feature imager and the 2D pedestrian feature plane image to obtain a matched image; wherein the original image and the 3D information are obtained simultaneously.
</abstract>

<claims>
1. A method for identifying a pedestrian, comprising: capturing an original image, detecting a pedestrian in the original image, and obtaining a 2D (two-dimensional) pedestrian feature image from the original image; obtaining a 3D (three-dimensional) data, and performing a 3D identification process for the 3D data to obtain a 3D pedestrian feature map with the pedestrian feature; projecting the 3D pedestrian feature map onto a 2D pedestrian feature plane image; and matching the 2D pedestrian feature image and the 2D pedestrian feature plane image to obtain a matching image; wherein the original image and the 3D data are simultaneity obtained.
2. The method according to claim 1, wherein when the 2D pedestrian feature image is not obtained, the obtained original image is processed for a second 3D identification to obtain a first interest area.
3. The method according to claim 2, wherein the first interest area is identified to obtain the 2D pedestrian feature image.
4. The method according to claim 1, wherein the 3D pedestrian feature map is not obtained, the obtained 3D data is processed for a second detection to obtain a second interest area.
5. The method according to claim 4, wherein the second interest area is identified to obtain the 3D pedestrian feature map.
6. The method according to claim 1, wherein the pedestrian in the original image is detected by a depth learning technology, and the 3D data is processed for a second detection.
7. The method according to claim 1, wherein when the 3D pedestrian feature map is projected to the 2D pedestrian plane image, the 3D pedestrian feature map is changed from a spherical coordinate to a Cartesian coordinate.
8. The method according to claim 7, wherein when the 3D pedestrian feature map is projected to the 2D pedestrian feature plane image, detection points are projected onto a multi-layer grid map, each object in the multi-layer grid map is identified as the highest and lowest points of the each object for adjustment, the object is cut from the multi-layer grid map to determine which one grid belong to the object through continuous grid values, and however, if the continuous grids have different heights from each other, the object will be cut and adjusted if the lowest point of the grid around the adjacent continuous grid is higher than the highest point of the continuous grid.
9. The method according to claim 8, wherein in a multi-layer grid map, whether the values in the continuous grid are all 1 (meaning there is a value) to determine whether an object under test, and if the highest point of some of the continuous grids in the continuous grid in the object to be tested is smaller than the lowest point of the surrounding grid, the object grid will be adjusted for cutting, and the object to be tested will be post-processed to select the object to be tested that matches the pedestrian range
10. A system for identifying a pedestrian, comprising: an image capturing device, capturing an original image, detecting a pedestrian in the original image, and obtaining a 2D (two-dimensional) pedestrian feature image from the original image; a depth sensing device, obtaining a 3D (three-dimensional) information, and performing a 3D identification process for the 3D information to obtain a 3D pedestrian feature map with the pedestrian feature; and a matching device, matching the 2D pedestrian feature image and the 2D pedestrian feature plane image to obtain a matching image; wherein the image capturing device and the depth sensing device respectively and simultaneity obtain the original image and the 3D data.
11. The system according to claim 10, wherein the image capturing device does not obtain the 2D pedestrian feature image, the obtained original image is transmitted to the depth sensing device to perform the second identification process to obtain a first interest area.
12. The system according to claim 11, wherein the depth sensing device identifies the first interest area to obtain the 2D pedestrian feature image.
13. The system according to claim 10, wherein when the depth sensing device does not obtain the 3D pedestrian feature image, the 3D data is transmitted to the image capturing device for a second detection to obtain a second interest area.
14. The system according to claim 13, wherein the image capturing device identifies the second interest area to obtain the 3D pedestrian feature map.
15. The system according to claim 10, wherein the image capturing device detects the pedestrian in the original image by a depth learn technology.
16. The system according to claim 10, wherein when the match device projects the 3D pedestrian feature map to the 2D pedestrian plane image, the 3D pedestrian feature map is changed from a spherical coordinate to a Cartesian coordinate.
17. The system according to claim 16, wherein when the 3D pedestrian feature map is projected to the 2D pedestrian feature plane image, detection points are projected onto a multi-layer grid map, each object in the multi-layer grid map is identified as the highest and lowest points of the each object for adjustment, the object is cut from the multi-layer grid map to determine which one grid belong to the object through continuous grid values, and however, if the continuous grids have different heights from each other, the object will be cut and adjusted if the lowest point of the grid around the adjacent continuous grid is higher than the highest point of the continuous grid.
18. The system according to claim 17, wherein in a multi-layer grid map, whether the values in the continuous grid are all 1 (meaning there is a value) to determine whether an object under test, and if the highest point of some of the continuous grids in the continuous grid in the object to be tested is smaller than the lowest point of the surrounding grid, the object grid will be adjusted for cutting, and the object to be tested will be post-processed to select the object to be tested that matches the pedestrian range.
</claims>
</document>
