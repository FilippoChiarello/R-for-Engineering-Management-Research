<document>

<filing_date>
2018-08-07
</filing_date>

<publication_date>
2020-05-19
</publication_date>

<priority_date>
2017-08-07
</priority_date>

<ipc_classes>
G06F3/0484,G06F3/0488,G06T13/20,G06T13/40,G06T13/80,G06T7/20
</ipc_classes>

<assignee>
FINEGOLD, MICHAL
</assignee>

<inventors>
FINEGOLD, MICHAL
</inventors>

<docdb_family_id>
65229767
</docdb_family_id>

<title>
Method for the computer animation of captured images
</title>

<abstract>
A method for the computer animation of captured images is provided. The computer animation of the captured image may be operatively rigged via touchscreen input or synchronized with video and audio input. During the rigging stage, the user may locate joints and pivot points and/or isolated body parts via a touchscreen. Animation may be based on, in part, motion capture from video input devices, and by using computer vision and machine learning to predict the location of the pivot points and associated body parts.
</abstract>

<claims>
1. A method of computer animating captured images, comprising: obtaining a first set of rules that define one or more first nodes as a function of two or more first body parts of one or more animatable captured images; obtaining a timed data file of a moving body having one or more tracked coordinates of two or more second body parts of said moving body; evaluating the one or more tracked coordinates against the first set of rules to determine a respective tracked coordinate for each first node; and applying synchronized movement to each first node by mirroring each respective tracked coordinate to produce animation control of the one or more animatable captured images; the first set of rules comprise defining a relationship between two adjacent first nodes as a vector, wherein each vector establishes a relative directional orientation of the two adjacent first nodes when applying synchronized movement.
2. The method of claim 1, wherein the timed data file of a moving body is a video output of a user.
3. The method of claim 1, wherein the first set of rules comprises one or more touchscreen gestures defining each first node.
4. A method of computer animating captured images, comprising: obtaining a first set of rules that define one or more first nodes as a function of two or more first body parts of one or more animatable captured images; obtaining a timed data file of a moving body having one or more tracked coordinates of two or more second body parts of said moving body; evaluating the one or more tracked coordinates against the first set of rules to determine a respective tracked coordinate for each first node; and applying synchronized movement to each first node by mirroring each respective tracked coordinate to produce animation control of the one or more animatable captured images, wherein the first set of rules further comprises defining a root first node, wherein a vector is defined by the root first node and the one or more first nodes when applying synchronized movement.
5. The method of claim 4, wherein the first set of rules further comprises defining a hierarchically connection between the root first node and the one or more first nodes, wherein the synchronized movement of the one or more first nodes depends from the root first node.
6. A method of computer animating captured images, comprising: obtaining a first set of rules that define one or more first nodes as a function of two or more first body parts of one or more animatable captured images; the first set of rules comprising: defining one or more first body parts of the animatable captured image by one or more bounding boxes defined by the one or more first nodes; obtaining a timed data file of a moving body having one or more tracked coordinates of two or more second body parts of said moving body, wherein the timed data file of a moving body is a video output of a user; evaluating the one or more tracked coordinates against the first set of rules to determine a respective tracked coordinate for each first node; and applying synchronized movement to each first node by mirroring each respective tracked coordinate to produce animation control of the one or more animatable captured images.
7. The method of claim 6, wherein the inverse kinematic logic functionality infers a continued motion at a continuous velocity.
8. The method of claim 6, wherein the first set of rules further comprises defining a root first node, wherein a vector is defined by the root first node and the one or more first nodes when applying synchronized movement.
9. The method of claim 8, wherein the first set of rules further comprises defining a hierarchically connection between the root first node and the one or more first nodes, wherein the synchronized movement of the one or more first nodes depends from the root first node.
10. The method of claim 6, wherein the first set of rules further comprises defining a first body part of the animatable captured image, wherein the first body part is defined by a bounding box, and wherein a center of the bounding box is calculated as the one or more first nodes.
11. A method of computer animating captured images, comprising: obtaining a first set of rules that define a first body part of the animatable captured image, wherein the first body part is defined by a bounding box, and wherein a center of the bounding box is a first node; obtaining a timed data file of a moving body having one or more tracked coordinates of two or more second body parts of said moving body, wherein the timed data file of a moving body is a video output of a user; evaluating the one or more tracked coordinates against the first set of rules to determine a respective tracked coordinate for the first node; and applying synchronized movement to the first node by mirroring each respective tracked coordinate to produce animation control of the one or more animatable captured images, wherein the evaluation of the one or more tracked coordinates against the first set of rules comprises inverse kinematic logic functionality is configured to predict motion of the first nodes even if their respective tracked coordinate is not directly tracked.
</claims>
</document>
