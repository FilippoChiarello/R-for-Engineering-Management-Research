<document>

<filing_date>
2019-01-07
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2018-01-25
</priority_date>

<ipc_classes>
G06K9/52,G06K9/62,G06K9/66,G06N5/04
</ipc_classes>

<assignee>
APPLE
WEBB, RUSSELL Y.
Ramapuram, Jason
</assignee>

<inventors>
WEBB, RUSSELL Y.
Ramapuram, Jason
</inventors>

<docdb_family_id>
73554860
</docdb_family_id>

<title>
Neural network architecture
</title>

<abstract>
A method includes processing an input image using convolution layers to define image features and processing the image features to define feature statistics. Processing the image features includes applying an activation function in a feature dimension of the image features. The method also includes processing the feature statistics using fully connected layers to produce a binary output regarding a characteristic of the input image.
</abstract>

<claims>
1. A method, comprising: processing an input image using convolution layers to define image features; processing the image features by applying an activation function in a feature dimension of the image features to define feature statistics and summing the feature statistics in a first spatial dimension and a second spatial dimension to define a spatially-summed feature vector; and processing the spatially-summed feature vector using fully connected layers to produce a binary output regarding a characteristic of the input image.
2. The method of claim 1, wherein processing the image features further includes applying a 1×1 convolution prior to applying the activation function in the feature dimension.
3. The method of claim 2, wherein processing the image features is performed by applying the 1×1 convolution and applying the activation function in the feature dimension two or more times in parallel branches.
4. The method of claim 3, wherein values obtained from the parallel branches are combined by superposition.
5. The method of claim 1, wherein processing the image features further includes applying pooling to the feature statistics subsequent to applying the activation function in the feature dimension.
6. The method of claim 5, wherein summing the feature statistics in the first spatial dimension and the second spatial dimension is performed subsequent to applying pooling.
7. A method, comprising: processing an input image using convolution layers to define image features; processing the image features to define feature statistics, wherein processing the image features includes applying an activation function in a feature dimension of the image features; and processing the feature statistics using fully connected layers to produce a binary output regarding a characteristic of the input image, wherein processing the image features further includes summing the feature statistics in a first spatial dimension and a second spatial dimension subsequent to applying pooling to the feature statistics, such that the feature statistics include a spatially-summed vector that represents the image features, and wherein processing the image features is performed by applying pooling and summing to the feature statistics two or more times in parallel branches, wherein pooling is applied using a different pooling size for each of the parallel branches.
8. The method of claim 7, wherein values obtained from the parallel branches are combined by concatenation.
9. The method of claim 1, wherein the image features include values representing presence or absence of features in the input image with respect to each of a first spatial dimension, a second spatial dimension, and the feature dimension.
10. The method of claim 1, wherein the activation function is a softmax activation function.
11. The method of claim 1, wherein the activation function is a scaled exponential linear unit activation function.
12. A neural network for processing an input image, comprising: convolution layers that accept the input image as an input and produce a feature matrix including values for image features representing presence or absence of the image features in the input image with respect to a first spatial dimension, a second spatial dimension, and a feature dimension; a feature analyzer that accepts the feature matrix as an input, applies an activation function in the feature dimension, and produces a spatially-summed feature vector by summing the image features in a first spatial dimension and a second spatial dimension; and fully connected layers that accept the spatially-summed feature vector as an input and produce a binary output regarding a characteristic of the input image.
13. The neural network of claim 12, wherein the feature analyzer applies a 1×1 convolution prior to applying the activation function in the feature dimension.
14. The neural network of claim 13, wherein the feature analyzer utilizes two or more parallel branches to apply the 1×1 convolution and to apply the activation function in the feature dimension, and values obtained from the parallel branches are combined by superposition.
15. The neural network of claim 12, wherein the feature analyzer applies pooling subsequent to application of the activation function in the feature dimension.
16. The neural network of claim 15, wherein the feature analyzer sums the image features in the first spatial dimension and the second spatial dimension subsequent to application of pooling.
17. A neural network for processing an input image, comprising: convolution layers that accept the input image as an input and produce a feature matrix including values for image features representing presence or absence of the image features in the input image with respect to a first spatial dimension, a second spatial dimension, and a feature dimension; a feature analyzer that accepts the feature matrix as an input, applies an activation function in the feature dimension, and produces a spatially-summed feature vector; and fully connected layers that accept the spatially-summed feature vector as an input and produce a binary output regarding a characteristic of the input image, wherein the feature analyzer applies pooling subsequent to application of the activation function in the feature dimension, wherein the feature analyzer sums the image features in a first spatial dimension and a second spatial dimension subsequent to application of pooling to define the spatially-summed feature vector, and wherein the feature analyzer applies pooling and summing to the image features two or more times in parallel branches, wherein pooling is applied using a different pooling size for each of the parallel branches, and values obtained from the parallel branches are combined by concatenation.
18. A method for training a neural network, comprising: processing an input image using convolution layers to define image features; processing the image features using feature analysis layers to define feature statistics, wherein processing the image features includes applying a 1×1 convolution to the image features and applying an activation function in a feature dimension of the image features; processing the feature statistics using fully connected layers to produce a binary output regarding a characteristic of the input image; and adjusting at least one of the convolution layers, the feature analysis layers, and the fully connected layers based on a comparison of the binary output to a weak supervision signal that corresponds to the input image.
19. The method of claim 18, wherein processing the image features further includes applying pooling subsequent to applying the activation function in the feature dimension.
20. The method of claim 19, wherein processing the image features further includes summing the image features in a first spatial dimension and a second spatial dimension subsequent to applying pooling, such that the feature statistics include a spatially-summed vector that represents the image features.
</claims>
</document>
