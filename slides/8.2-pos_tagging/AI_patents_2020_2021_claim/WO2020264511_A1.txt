<document>

<filing_date>
2020-06-29
</filing_date>

<publication_date>
2020-12-30
</publication_date>

<priority_date>
2019-06-27
</priority_date>

<ipc_classes>
H04N21/442,H04N21/466,H04N21/482
</ipc_classes>

<assignee>
ROVI GUIDES
</assignee>

<inventors>
MILLER, KYLE
</inventors>

<docdb_family_id>
71738293
</docdb_family_id>

<title>
METHODS AND SYSTEMS FOR PERSONALIZED SCREEN CONTENT OPTIMIZATION
</title>

<abstract>
Systems and associated methods are described for providing content recommendations. The system selects, using a multi-armed bandit solution model, a first plurality of content categories based on a reward score of each content category. The categories are displayed. When a user selects an item from the displayed categories, the system finds all categories that include the selected item, but rewards only the category with the highest score. The system selects, using the multi-armed bandit solution model, the second plurality of content categories based on the updated reward score of each content category. The categories are then displayed. The system may also repeat the steps to refine the multi-armed bandit solution model.
</abstract>

<claims>
1. A method for selecting content item identifiers for display, the method comprising:
(a) selecting, using a multi-armed bandit solution model, a first plurality of content categories based on a reward score of each content category;
(b) selecting a first set of recommended content items for the first plurality of content categories;
(c) generating for display identifiers for recommended content items of the first set of recommended content items;
(d) receiving a request for a requested content item associated with one of the displayed identifiers;
(e) identifying all content categories of the first plurality of content categories that include the requested content item;
(f) increasing reward score of the content category of the identified content categories that has the highest reward score;
(g) selecting, using the multi-armed bandit solution model, a second plurality of content categories based on the reward score of each content category;
(h) selecting a second set of recommended content items for the second plurality of content categories; and
(i) generating for display identifiers for recommended content items of the second set of recommended content items.
2. The method of claim 1, further comprising repeating the steps (d)-(i).
3. The method of claim 2, wherein selecting, using the multi-armed bandit solution model, a second plurality of content categories based on the reward score of each content category comprises:
selecting the second plurality of content categories using a random technique during an exploration stage of the multi-armed bandit solution model; and
selecting the second plurality of content categories based on which content categories have the highest reward scores during an exploitation stage of the armed bandit solution model.
4. The method of claim 3, further comprising switching the multi-armed bandit solution model to the exploitation stage based on the number of times steps (d)-(i) have been repeated.
5. The method of claim 3, further comprising switching the multi-armed bandit solution model to the exploitation stage based on determining that sum of reward scores of the second plurality of content categories stopped improving.
6. The method of claim 3, wherein the multi-armed bandit solution model is specific to a single user, and wherein all requests for a requested content item are received from the single user.
7. The method of claim 3, wherein the multi-armed bandit solution model is specific to a user group, and wherein all requests for a requested content item are received from a user of the user group.
8. The method of claim 1, further comprising:
prior to step (a), assigning a reward score to all content categories based on content preference data of a plurality of users.
9. The method of claim 1, further comprising:
prior to step (a), assigning a random reward score to all content categories.
10. The method of claim 1, wherein increasing the reward score of the identified content category with the highest reward score comprises:
calculating a recall value for the requested content item, wherein the reward scores is proportional to the number of times the requested content item was requested and inversely proportional the number of times the identifier of the requested content item was generated for display; and
and increasing the reward score based on the recall value.
11. A system comprising control circuitry configured for implementing the steps of the method of any of claims 1 to 10.
12. A non-transitory computer-readable medium having instructions encoded thereon that when executed by control circuitry enable the control circuitry to execute the steps of the method of any of claims 1 to 10.
</claims>
</document>
