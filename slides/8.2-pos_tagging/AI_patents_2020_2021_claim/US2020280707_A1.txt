<document>

<filing_date>
2020-05-18
</filing_date>

<publication_date>
2020-09-03
</publication_date>

<priority_date>
2018-12-14
</priority_date>

<ipc_classes>
G02B27/28,G02B5/30,G06K9/66,G06N20/20,G06T5/20,G06T7/55,H04N13/111,H04N13/271,H04N5/341
</ipc_classes>

<assignee>
LYFT
</assignee>

<inventors>
BRIGGS, FORREST SAMUEL
CLÃ‰MENT, ROMAIN
ZHOU, YI
</inventors>

<docdb_family_id>
70736151
</docdb_family_id>

<title>
MULTICHANNEL, MULTI-POLARIZATION IMAGING FOR IMPROVED PERCEPTION
</title>

<abstract>
In one embodiment, a method includes accessing first image data generated by a first image sensor having a first filter array that has a first filter pattern. The first filter pattern includes a number of first filter types. The method also includes accessing second image data generated by a second image sensor having a second filter array that has a second filter pattern different from the first filter pattern. The second filter pattern includes a number of second filter types, the number of second filter types and the number of first filter types have at least one filter type in common. The method also includes determining a correspondence between one or more first pixels of the first image data and one or more second pixels of the second image data based on a portion of the first image data associated with the filter type in common.
</abstract>

<claims>
1. A method comprising: receiving first image data captured by a first image sensor including a first filter array having a first set of filter types; receiving second image data captured by a second image sensor including a second filter array having a second set of filter types, wherein the first set of filter types and the second set of filter types have at least one filter type in common; computing depth information of one or more first pixels of the first image data and one or more second pixels of the second image data corresponding to the one or more first pixels based at least in part on the at least one filter type in common; and determining spatial information between a pixel of the one or more first pixels and a corresponding pixel of the one or more second pixels based on the depth information.
2. The method of claim 1, wherein the at least one filter type in common comprises a clear filter type, a color filter type, a polarization filter type or an infrared (IR) filter type.
3. The method of claim 1, wherein the spatial information is further based on the one or more first pixels and the one or more second pixels associated with the at least one filter type in common.
4. The method of claim 1, wherein the first filter array has a first filter pattern and the second filter array has a second filter pattern different from the first filter pattern.
5. The method of claim 1, wherein computing the depth information of the one or more first pixels of the first image data and the one or more second pixels of the second image data comprises calculating a cost volume associated with the one or more first pixels and the one or more second pixels.
6. The method of claim 5, wherein the cost volume is a look-up table with cost values for each pixel of the first and second pixels of the first and second image data.
7. The method of claim 1, wherein determining the spatial information comprises determining one or more disparity values indicating a spatial correspondence between the pixel of the one or more first pixels and the corresponding pixel of the one or more second pixels.
8. The method of claim 1, wherein, prior to computing the depth information, the method further comprises: determining the spatial correspondence between the one or more first pixels of the first image data and the one or more second pixels of the second image data.
9. The method of claim 1, wherein determining the spatial information comprises determining one or more disparity values indicating a spatial correspondence between the pixel of the one or more first pixels and the corresponding pixel of the one or more second pixels.
10. The method of claim 1, wherein, prior to computing the depth information, the method further comprises: identifying one or more objects included within the first image data and the second image data using the depth information and the spatial information.
11. A system comprising: one or more non-transitory computer-readable storage media including instructions; and one or more processors coupled to the storage media, the one or more processors configured to execute the instructions to: receive first image data captured by a first image sensor including a first filter array having a first set of filter types; receive second image data captured by a second image sensor including a second filter array having a second set of filter types, wherein the first set of filter types and the second set of filter types have at least one filter type in common; compute depth information of one or more first pixels of the first image data and one or more second pixels of the second image data corresponding to the one or more first pixels based at least in part on the at least one filter type in common; and determine spatial information between a pixel of the one or more first pixels and a corresponding pixel of the one or more second pixels based on the depth information.
12. The system of claim 11, wherein the at least one filter type in common comprises a clear filter type, a color filter type, a polarization filter type or an infrared (IR) filter type.
13. The system of claim 11, wherein the spatial information is further based on the one or more first pixels and the one or more second pixels associated with the at least one filter type in common.
14. The system of claim 11, wherein the first filter array has a first filter pattern and the second filter array has a second filter pattern different from the first filter pattern.
15. The system of claim 11, wherein the one or more processors are further configured to execute the instructions to determine the depth information based on a calculation of a cost volume associated with the one or more first pixels and the one or more second pixels.
16. The system of claim 11, wherein the one or more processors are further configured to execute the instructions to determine the spatial information by determining on one or more disparity values indicating a spatial correspondence between the pixel of the one or more first pixels and the corresponding pixel of the one or more second pixels.
17. The system of claim 11, wherein, prior to computing the depth information, the one or more processors are further configured to execute the instructions to determine the spatial correspondence between the one or more first pixels of the first image data and the one or more second pixels of the second image data.
18. The system of claim 11, wherein the one or more processors are further configured to execute the instructions to determine the spatial information by determining one or more disparity values indicating a spatial correspondence between the pixel of the one or more first pixels and the corresponding pixel of the one or more second pixels.
19. The system of claim 11, wherein, prior to computing the depth information, the one or more processors are further configured to execute the instructions to identify one or more objects included within the first image data and the second image data using the depth information and the spatial information.
20. A non-transitory computer-readable medium comprising instructions that, when executed by one or more processors of a computing system, cause the one or more processors to: receive first image data captured by a first image sensor including a first filter array having a first set of filter types; receive second image data captured by a second image sensor including a second filter array having a second set of filter types, wherein the first set of filter types and the second set of filter types have at least one filter type in common; compute depth information of one or more first pixels of the first image data and one or more second pixels of the second image data corresponding to the one or more first pixels based at least in part on the at least one filter type in common; and determine spatial information between a pixel of the one or more first pixels and a corresponding pixel of the one or more second pixels based on the depth information.
</claims>
</document>
