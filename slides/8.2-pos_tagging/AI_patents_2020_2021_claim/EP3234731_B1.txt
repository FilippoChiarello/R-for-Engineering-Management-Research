<document>

<filing_date>
2015-12-15
</filing_date>

<publication_date>
2020-07-01
</publication_date>

<priority_date>
2014-12-16
</priority_date>

<ipc_classes>
A24F47/00,A61B5/00,A61B5/11,G06F3/00,G06F3/01
</ipc_classes>

<assignee>
SOMATIX
</assignee>

<inventors>
SCHATZBERG, URI
OFIR, ERAN
</inventors>

<docdb_family_id>
56127477
</docdb_family_id>

<title>
METHODS AND SYSTEMS FOR MONITORING AND INFLUENCING GESTURE-BASED BEHAVIORS
</title>

<abstract>
Methods and systems are provided herein for analyzing, monitoring, and/or influencing a user's behavioral gesture in real-time. A gesture recognition method may be provided. The method may comprise: obtaining sensor data collected using at least one sensor located on a wearable device, wherein said wearable device is configured to be worn by a user; and analyzing the sensor data to determine a probability of the user performing a predefined gesture, wherein the probability is determined based in part on a magnitude of a motion vector in the sensor data, and without comparing the motion vector to one or more physical motion profiles.
</abstract>

<claims>
1. A system (100) for implementing gesture recognition, comprising: a memory for storing sensor data collected by a plurality of sensors located on a wearable device (104), wherein the plurality of sensors comprises an accelerometer (105-1) and a gyroscope (105-2), and wherein said wearable device (104) is configured to be worn by a user; and one or more processors configured to: analyze the sensor data by comparing magnitudes of two or more motion vectors comprising a magnitude of an acceleration vector obtained from the accelerometer (105-1) and a magnitude of an angular velocity vector obtained from the gyroscope (105-2), without comparing the motion vectors to a plurality of physical motion profiles, to determine a likelihood of the user performing a predefined gesture; and determine whether the likelihood that the user is performing the predefined gesture is below or above a threshold value.
2. The system (100) of claim 1, wherein the one or more processors are located onboard the wearable device (104).
3. The system (100) of claim 1, wherein the one or more processors are located onboard a user device (102) or a remote server (106) in communication with the wearable device (104), wherein the user device (102) and the remote server (106) are provided separate from the wearable device (104).
4. The system (100) of claim 1, wherein the predefined gesture is selected from a group of different gestures associated with different activities including the user smoking or about to smoke a cigarette, eating or drinking.
5. The system (100) of claim 1, where the one or more processors are configured to calculate a pitch angle, roll angle, and/or yaw angle of the wearable device based on at least the acceleration vector or the angular velocity vector, and determine the likelihood of the user performing the predefined gesture based on the calculated angle(s).
6. The system (100) of claim 1, wherein the plurality of sensors further comprises one or more of the following: a magnetometer, a heart rate monitor, a global positioning system (GPS) receiver, a barometer, an external temperature sensor, a microphone, a skin temperature sensor, a capacitive sensor, or a sensor configured to detect a galvanic skin response.
7. The system (100) of claim 1, wherein the one or more processors are configured to analyze the sensor data by calculating a multi-dimensional distribution function, wherein said multi-dimensional distribution function comprises a plurality of features associated with various aspects of the predefined gesture, and wherein the plurality of features are extracted from the sensor data.
8. The system (100) of claim 1, wherein the one or more processors are configured to apply a data compression step to the sensor data, wherein the data compression step is configured to at least reduce a bandwidth required to transmit the sensor data or reduce a power consumption of the wearable device (104) during the transmission of the sensor data.
9. The system (100) of claim 8, wherein the plurality of sensors are configured to collect the sensor data at a plurality of different frequencies.
10. The system (100) of claim 1, wherein the plurality of sensors are arranged to (1) start collecting the sensor data at a first predetermined frequency when the likelihood that the user is performing the predefined gesture is below the threshold value, or (2) start collecting the sensor data at a second predetermined frequency different from the first predetermined frequency when the likelihood that the user is performing the predefined gesture is above the threshold value.
11. The system (100) of claim 1, wherein the plurality of sensors comprises a first group of sensors and a second group of sensors, and wherein the first group of sensors and the second group of sensors are configured so that they are selectively activated so as to reduce power consumption of the wearable device (104).
12. The system (100) of claim 11, wherein the second group of sensors is inactive when the likelihood that the user is performing the predefined gesture is below a threshold value, wherein the second group of sensors are collectively activated (1) when the wearable device (104) is powered on and the likelihood that the user is performing the predefined gesture is above the threshold value, or (2) upon determining that the user is performing the predefined gesture.
13. The system (100) of claim 1, wherein the wearable device (104) is configured to operate in a plurality of modes comprising a low power mode and an accuracy mode, wherein an accuracy of detecting whether the user is performing the predefined gesture is improved when the wearable device (104) is in the accuracy mode compared to the low power mode.
14. A gesture recognition method comprising: obtaining sensor data collected by a plurality of sensors located on a wearable device (104), wherein the plurality of sensors comprises an accelerometer (105-1) and a gyroscope (105-2), and wherein said wearable device (104) is configured to be worn by a user; analyzing the sensor data by comparing magnitudes of two or more motion vectors comprising a magnitude of an acceleration vector obtained from the accelerometer (105-1) and a magnitude of an angular velocity vector obtained from the gyroscope (105-2), without comparing the motion vectors to a plurality of physical motion profiles, to determine a likelihood of the user performing a predefined gesture; and determining whether the likelihood that the user is performing the predefined gesture is below or above a threshold value.
</claims>
</document>
