<document>

<filing_date>
2019-12-17
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2018-12-19
</priority_date>

<ipc_classes>
G01S13/86,G01S13/931,G01S17/86,G01S17/87,G01S17/89,G01S17/931,G06K9/00
</ipc_classes>

<assignee>
VALEO SCHALTER UND SENSOREN
</assignee>

<inventors>
CHACON-ALAM, ASHLEY
PICRON, VANESSA
VEJARANO, CAMILO
</inventors>

<docdb_family_id>
69061331
</docdb_family_id>

<title>
METHOD FOR IMPROVED OBJECT DETECTION
</title>

<abstract>
The invention provides a method for improved object (22) detection based on two types of environment sensors (14, 16) applied in a driving support system (12) of a vehicle (10), whereas the first type of environment sensor is an image type sensor (14) having an image-field-of-view (18) and the second type of environment sensor is a range type sensor (16) having a range-field-of-view (20) that at least partially overlaps the image- field-of-view (18), comprising the steps of providing a 2-dimensional array of data points (26) representing the surrounding of the vehicle (10) in the image-field-of-view (18) by at least one image type sensor (14), identifying one or more troublemakers (24) in the 2- dimensional array of data points (26), providing a 3-dimensional array of data points (28) representing the surrounding of the vehicle (10) in the range-field-of-view (20) by at least one range-type-sensor (16), mapping the 3-dimensional array of data points (28) into the 2-dimensional array of data points (26), selecting one or more 3D-sub-sets of data points (27) in the 3-dimensional array of data points (28) matching the one or more troublemakers (24), providing a revised 3-dimensional array of data points (34), considering the 3-dimensional array of data points (28) and the one or more 3D-sub-sets of data points (27), and detecting position, size, velocity, and/or orientation of objects (22), considering the revised 3-dimensional array of data points (34).
</abstract>

<claims>
Patent claims
1. Method for improved object (22) detection based on two types of environment sensors (14, 16) applied in a driving support system (12) of a vehicle (10), whereas the first type of environment sensor is an image type sensor (14) having an image-field-of-view (18) and the second type of environment sensor is a range type sensor (16) having a range-field-of-view (20) that at least partially overlaps the image-field-of-view (18), comprising the steps of
providing a 2-dimensional array of data points (26) representing the surrounding of the vehicle (10) in the image-field-of-view (18) by at least one image type sensor (14),
identifying one or more troublemakers (24) in the 2-dimensional array of data points (26),
providing a 3-dimensional array of data points (28) representing the surrounding of the vehicle (10) in the range-field-of-view (20) by at least one range-type-sensor (16),
mapping the 3-dimensional array of data points (28) into the 2-dimensional array of data points (26),
selecting one or more 3D-sub-sets of data points (27) in the 3-dimensional array of data points (28) matching the one or more troublemakers (24),
providing a revised 3-dimensional array of data points (34), considering the 3-dimensional array of data points (28) and the one or more 3D-sub-sets of data points (27), and
detecting position, size, velocity, and/or orientation of objects (22), considering the revised 3-dimensional array of data points (34).
2. Method according to any preceding claim, characterized in that
the step of identifying one or more troublemakers (24) in the 2-dimensional array of data points (28) comprises
determining an area (32) in the 2-dimensional array of data points (26) belonging to the one or more troublemakers (24), and the step of selecting one or more 3D-sub-sets of data points (27) in the 3-dimensional array of data points (28) matching the one or more troublemakers (24) comprises
selecting one or more 3D-sub-set of data points (27) in the 3-dimensional array of data points (28) that are mapped inside the area (32) belonging to the one or more troublemakers (24).
3. Method according to any preceding claim, characterized in that
the step of identifying one or more troublemakers (24) in the 2-dimensional array of data points (28), comprises
discovering one or more troublemakers (24) coupled with segmenting the 2-dimensional array of data points (28).
4. Method according to any preceding claim, characterized in that
the step of providing a revised 3-dimensional array of data points (34), considering the 3-dimensional array of data points (28) and the one or more 3Dsub-sets of data points (27) comprises
removing the one or more 3D-sub-sets of data points (27) from the 3- dimensional array of data points (28).
5. Method according to any preceding claim, characterized in that
the step of identifying one or more troublemakers (24) in the 2-dimensional array of data points (26) comprises
identifying one or more objects (22) having an inconsistent reflection surface and/or one or more objects (22) having a discontinuous reflection surface.
6. Method according to any preceding claim, characterized in that
the step of identifying one or more troublemakers (24) in the 2-dimensional array of data points (26) comprises
identifying one or more objects (22) of the category tree, bush, hedge, vegetation, grid and/or wire fence.
7. Method according to any preceding claim, characterized in that the step of providing a 2-dimensional array of data points (26) representing the surrounding of the vehicle (10) in the image-field-of-view (18) by at least one image type sensor (14) comprises
providing a 2-dimensional array of data points (26) by at least one camera
(14).
8. Method according to any preceding claim, characterized in that
the step of providing a 3-dimensional array of data points (28) representing the surrounding of the vehicle (10) in the range-field-of-view (20) by at least one range type sensor (16) comprises
providing a 3-dimensional array of data points (28) by at least one LiDAR sensor (16) and/or by at least one radar sensor.
9. Method according to any preceding claim, characterized in that
the step of identifying one or more troublemakers (24) in the 2-dimensional array of data points (26)
comprises identifying one or more troublemakers (24) in the 2-dimensional array of data points (26) by an image recognition algorithm and/or by a neural network.
10. Driving support system (12) for performing the method according to any of
preceding claims 1 to 9,
comprising at least one image type sensor (14) for providing a 2-dimensional array of data points (26) representing the surrounding of the vehicle (10) in an image-field-of-view (18) and one range type sensor (16) for providing a 3- dimensional array of data points (28) representing the surrounding of the vehicle (10) in a range-field-of-view (20).
1 1. Driving support system (12) according to claim 10, characterized in that
the image type sensor (14) for providing a 2-dimensional array of data points (26) is a camera (14) and the range type sensor (16) for providing a 3-dimensional array of data points (28) is a LiDAR sensor (16) and/or a radar sensor.
12. Driving support system (12) according to claim 10 or 1 1 , characterized in that the at least one image type sensor (14) for providing a 2-dimensional array of data points (26) has an image-field-of-view (18) of 360 degrees of the surrounding of the vehicle (10).
13. Driving support system (12) according to any of claims 10 to 12, characterized in that the at least one range type sensor (16) for providing a 3-dimensional array of data points (28) has a range-field-of-view (20) of 360 degrees of the surrounding of the vehicle (10).
</claims>
</document>
