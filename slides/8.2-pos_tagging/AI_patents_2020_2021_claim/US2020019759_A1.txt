<document>

<filing_date>
2019-07-08
</filing_date>

<publication_date>
2020-01-16
</publication_date>

<priority_date>
2018-07-11
</priority_date>

<ipc_classes>
G06F16/45,G06K9/00,G06N3/08
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
SAVCHENKO, ANDREY VLADIMIROVICH
</inventors>

<docdb_family_id>
69139495
</docdb_family_id>

<title>
SIMULTANEOUS RECOGNITION OF FACIAL ATTRIBUTES AND IDENTITY IN ORGANIZING PHOTO ALBUMS
</title>

<abstract>
A method is provided for simultaneously recognizing facial attributes and identity to organize photo and/or video albums, based on modifying an efficient convolutional neural network (CNN) which extracts facial representations suitable for face identification and attribute (age, gender, ethnicity, emotion, etc.) recognition tasks. The method enables to process all the tasks simultaneously, without a need for additional CNNs. As a result, a very fast facial analytic system is provided, and the system can be installed onto mobile devices.
</abstract>

<claims>
1. A controlling method of an electronic apparatus, the method comprising: obtaining at least one identity feature regarding an image, by inputting the image to a convolutional neural network (CNN) that is trained to extract an identity feature for identifying a face included in at least one image based on training data including a plurality of images; inputting the obtained identity feature to at least one hidden layer to which dropout regularization is applied; and recognizing a facial attribute included in the input image through one or more independent fully-connected layers based on an output of the hidden layer according to an input of the identity feature.
2. The method as claimed in claim 1, wherein the attribute is at least one of age, gender, race, ethnicity or emotion.
3. The method as claimed in claim 1, further comprising: training each of the one or more independent fully-connected layers based on different training data, wherein the each of the one or more independent fully-connected layers corresponds to a different attribute.
4. The method as claimed in claim 1, further comprising: detecting a region associated with a face from one or more input images; and extracting the identity feature, through the trained CNN, from the detected region.
5. The method as claimed in claim 4, wherein the detecting of the region is performed by a multi-view cascade classifier or a multi-task cascaded convolutional neural network (MTCNN) detector.
6. The method as claimed in claim 1, further comprising: detecting regions associated with faces from a plurality of images; extracting a plurality of identity features from the detected regions; obtaining clusters corresponding to each person by clustering the plurality of identity features; and recognizing an attribute of a face of a person corresponding to each of the obtained clusters.
7. The method as claimed in claim 1, further comprising: detecting regions associated with faces from a plurality of images; extracting a plurality of identity features and attributes of faces from the detected regions; obtaining clusters corresponding to each person by clustering the plurality of identity features and the attributes; and calculating an average value of each of the attributes of the faces with respect to each of the obtained clusters.
8. The method as claimed in claim 6, wherein the obtaining of the clusters comprises obtaining the clusters using a hierarchical agglomerative clustering (HAS).
9. The method as claimed in claim 7, wherein the calculating of the average value of each of the attributes of the faces is performed through simple voting or by maximizing average posterior probabilities in outputs of the CNN.
10. The method as claimed in claim 1, further comprising: selecting a plurality of frames in each of a plurality of video clips; detecting regions associated with faces from the selected plurality of frames; extracting a plurality of identity features and attributes of faces from the detected regions; obtaining first clusters corresponding to each person by clustering the plurality of identity features and the attributes; calculating an average value of each of the plurality of identity features and the attributes of faces with respect to each of the first clusters; detecting regions associated with faces from a plurality of images; extracting a plurality of identity features and attributes of faces from the detected regions; obtaining second clusters corresponding to each person by jointly clustering the calculated average value of each of the plurality of identity features and the plurality of identity features extracted from the plurality of images; and calculating an average value of each of the attributes of faces with respect to each of the second clusters.
11. The method as claimed in claim 10, wherein the selecting of the plurality of frames comprises selecting different frames of a video clip of a fixed frame rate.
12. An electronic apparatus comprising: a memory to store a convolutional neural network (CNN) trained to extract an identity feature for identifying a face included in at least one image based on training data including a plurality of images; and at least one processor configured to: obtain at least one identity feature regarding an image by inputting the image to the CNN, input the obtained identity feature to at least one hidden layer to which dropout regularization is applied, and recognize a facial attribute included in the input image through one or more independent fully-connected layers based on an output of the hidden layer according to an input of the identity feature
13. The apparatus as claimed in claim 12, wherein each of the one or more independent fully-connected layer is trained based on different training data corresponding to each of different attributes.
14. The apparatus as claimed in claim 12, wherein the at least one processor is further configured to: detect a region associated with a face from one or more input images, and extract the identity feature, through the trained CNN, from the detected region.
15. The apparatus as claimed in claim 14, wherein the at least one processor is further configured to detect the region through a multi-view cascade classifier or a multi-task cascaded convolutional neural network (MTCNN) detector.
16. The apparatus as claimed in claim 12, wherein the at least one processor is further configured to: detect regions associated with faces from a plurality of images, extracts a plurality of identity features from the detected regions, obtain clusters corresponding to each person by clustering the plurality of identity features, and recognize an attribute of a face of a person corresponding to each of the obtained clusters.
17. The apparatus as claimed in claim 12, wherein the at least one processor is further configured to: detect regions associated with faces from a plurality of images, extract a plurality of identity features and attributes of faces from the detected regions, obtain clusters corresponding to each person by clustering the plurality of identity features and the attributes, and calculate an average value of each of the attributes of the faces with respect to each of the obtained clusters
18. The apparatus as claimed in claim 16, wherein the at least one processor is further configured to obtain the clusters using a hierarchical agglomerative clustering (HAS).
19. The apparatus as claimed in claim 17, wherein the at least one processor is further configured to calculate an average value of each of the attributes of the faces through simple voting or by maximizing average posterior probabilities in outputs of the CNN.
20. The apparatus as claimed in claim 12, wherein the at least one processor is further configured to: select a plurality of frames in each of a plurality of video clips, detect regions associated with faces from the selected plurality of frames, extract a plurality of identity features and attributes of faces from the detected regions, obtain first clusters corresponding to each person by clustering the plurality of identity features and the attributes, calculate an average value of each of the plurality of identity features and the attributes of faces with respect to each of the first clusters, detect regions associated with faces from a plurality of images, extract a plurality of identity features and attributes of faces from the detected regions, obtain second clusters corresponding to each person by jointly clustering the calculated average value of each of the plurality of identity features and the plurality of identity features extracted from the plurality of images, and calculate an average value of each of the attributes of faces with respect to each of the second clusters.
</claims>
</document>
