<document>

<filing_date>
2018-07-27
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2017-08-04
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N20/00,G06N3/04,G06N3/08,G06N5/00,G06T7/246,G06T7/269,H04N21/4402
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
ABDELHAK, SHERINE
PANDIT, NEELAY
</inventors>

<docdb_family_id>
65275477
</docdb_family_id>

<title>
Methods and apparatus to generate temporal representations for action recognition systems
</title>

<abstract>
Methods, apparatus, systems and articles of manufacture to generate temporal representations for action recognition systems are disclosed. An example apparatus includes an optical flow computer to compute a first optical flow based on first and second video frames separated by a first amount of time and compute a second optical flow based on third and fourth video frames separated by a second amount of time, the second amount of time different than the first amount of time, and an aggregator to combine the first optical flow and the second optical flow to form an image representing action in a video.
</abstract>

<claims>
1. An apparatus comprising: an optical flow computer to: compute a first optical flow based on first and second video frames separated by a first amount of time, the first amount of time to illustrate a small amount of difference between the first and second video frames, the small amount of difference corresponding to a low level of motion in a video; and compute a second optical flow based on third and fourth video frames separated by a second amount of time greater than the first amount of time, the second amount of time to illustrate a higher amount of difference between the third and fourth video frames relative to the small amount of difference, the higher amount of difference corresponding to a high level of motion in the video; and an aggregator to combine the first optical flow and the second optical flow to form an image representing action in the video, the image to include a scaled level of motion based on the low and high levels of motion for identifying the action in the video.
2. The apparatus of claim 1, further including a scaler to normalize the first optical flow based on the first amount of time, and the second optical flow based on the second amount of time.
3. The apparatus of claim 1, further including a convolutional neural network to identify an action in the video based on the image representing action in the video.
4. The apparatus of claim 1, wherein the optical flow computer is a first optical flow computer, and further including: a second optical flow computer to: compute a third optical flow based on fifth and sixth video frames separated by a third amount of time, and compute a fourth optical flow based on seventh and eighth video frames separated by the third amount of time; a first convolutional neural network to identify a first action in the video based on the image representing action in the video; a second convolutional neural network to identify a second action in the video based on the third and fourth optical flows; and a fuser to identify a third action in the video based on the first action and the second action.
5. The apparatus of claim 1, wherein the aggregator is to combine the first optical flow and the second optical flow by computing a sum of the first optical flow and the second optical flow.
6. The apparatus of claim 5, wherein the aggregator is to compute the sum of the first optical flow and the second optical flow by computing a weighted sum of the first optical flow and the second optical flow.
7. The apparatus of claim 1, further including a frame skipper to determine whether an amount of motion associated with fifth and sixth video frames satisfies a threshold, wherein the optical flow computer is to skip computing a third optical flow based on the fifth and sixth video frames when the amount of motion does not satisfy the threshold.
8. The apparatus of claim 7, wherein the frame skipper is to determine the amount of motion by computing a joint entropy for the fifth and sixth frames.
9. The apparatus of claim 7, wherein the frame skipper is to determine the threshold by computing a mean similarity for the video.
10. A method comprising: computing a first optical flow based on first and second video frames separated by a first amount of time, the first amount of time to illustrate a small amount of difference between the first and second video frames, the small amount of difference corresponding to a low level of motion in a video; computing a second optical flow based on third and fourth video frames separated by a second amount of time, the second amount of time greater than the first amount of time, the second amount of time to illustrate a higher amount of difference between the third and fourth video frames relative to the small amount of difference, the higher amount of difference corresponding to a high level of motion in the video; combining the first optical flow and the second optical flow to form an image representing action in the video, the image to include a scaled level of motion based on the low and high levels of motion for identifying the action in the video.
11. The method of claim 10, further including: determining whether an amount of motion associated with fifth and sixth video frames satisfies a threshold; and skipping computing a third optical flow based on the fifth and sixth video frames when the amount of motion does not satisfy the threshold.
12. The method of claim 10, further including: normalizing the first optical flow based on the first amount of time; and normalizing the second optical flow based on the second amount of time.
13. The method of claim 10, further including applying machine learning to the image representing action in the video to identify an action in the video.
14. The method of claim 10, wherein combining the first optical flow and the second optical flow includes computing a sum of the first optical flow and the second optical flow.
15. The method of claim 14, wherein computing the sum of the first optical flow and the second optical flow includes computing a weighted sum of the first optical flow and the second optical flow.
16. A non-transitory computer-readable storage medium comprising instructions that, when executed, cause a machine to: compute a first optical flow based on first and second video frames separated by a first amount of time, the first amount of time to illustrate a small amount of difference between the first and second video frames, the small amount of difference corresponding to a low level of motion in a video; compute a second optical flow based on third and fourth video frames separated by a second amount of time, the second amount of time greater than the first amount of time, the second amount of time to illustrate a higher amount of difference between the third and fourth video frames relative to the small amount of difference, the higher amount of difference corresponding to a high level of motion in the video; and combine the first optical flow and the second optical flow to form an image representing action in the video, the image to include a scaled level of motion based on the low and high levels of motion for identifying the action in the video.
17. The non-transitory computer-readable storage medium of claim 16, wherein the instructions, when executed, cause the machine to combine the first optical flow and the second optical flow by computing a sum of the first optical flow and the second optical flow.
18. The non-transitory computer-readable storage medium of claim 16, wherein the instructions, when executed, cause the machine to: determine whether an amount of motion associated with fifth and sixth video frames satisfies a threshold; and skip computing a third optical flow based on the fifth and sixth video frames when the amount of motion does not satisfy the threshold.
19. The non-transitory computer-readable storage medium of claim 16, wherein the instructions, when executed, cause the machine to: normalize the first optical flow based on the first amount of time; and normalize the second optical flow based on the second amount of time.
20. The non-transitory computer-readable storage medium of claim 16, wherein the instructions, when executed, cause the machine to pass the image representing action in the video through a convolutional neural network to identify an action in the video.
21. An apparatus comprising: a first optical flow computer to: compute a first optical flow based on first and second video frames separated by a first amount of time, and compute a second optical flow based on third and fourth video frames separated by a second amount of time, the second amount of time different than the first amount of time; an aggregator to combine the first optical flow and the second optical flow to form an image representing action in a video; a second optical flow computer to: compute a third optical flow based on fifth and sixth video frames separated by a third amount of time, and compute a fourth optical flow based on seventh and eighth video frames separated by the third amount of time; a first convolutional neural network to identify a first action in the video based on the image representing action in the video; a second convolutional neural network to identify a second action in the video based on the third and fourth optical flows; and a fuser to identify a third action in the video based on the first action and the second action.
</claims>
</document>
