<document>

<filing_date>
2019-10-21
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2015-12-08
</priority_date>

<ipc_classes>
A61B5/00,A61B5/107,A61B7/00,A61B8/08,G16H20/30,G16H50/30
</ipc_classes>

<assignee>
KNEEVOICE
</assignee>

<inventors>
DE GREIFF, GUSTAVO
RIGBY, FELIPE
LEAL, CARLOS
</inventors>

<docdb_family_id>
59013519
</docdb_family_id>

<title>
ASSESSING JOINT CONDITION USING ACOUSTIC SENSORS
</title>

<abstract>
A new non-invasive tool for cartilage assessment, exercise and sports management, and prevention of osteoarthritis is provided. In various embodiments, cartilage condition is assessed using audible signals from joints. Assessment test results are used to provide feedback regarding joint stress and friction that is related to physiological or pathological loads. Data obtained from audible signals are processed to provide an index that can be interpreted by a user or third parties. The index is useful as a baseline for exercise practices, training routines, wellness programs, or rehabilitation protocols.
</abstract>

<claims>
1. A system comprising: a contact microphone; a position sensor; a processor operatively connected to the contact microphone and the position sensor; a computer readable storage medium having program instructions embodied therewith, the program instructions executable by the processor to cause the processor to perform a method comprising: receiving from the contact microphone audio comprising sounds emanating from a human joint during flexion; receiving, from the position sensor, motion data of the human joint; synchronizing the motion data with the audio; extracting a plurality of features from the audio; providing the plurality of features and the motion data to a trained classifier; obtaining from the trained classifier a first score indicative of joint health; and displaying the first score with an indication to perform follow-up when the score is below a predetermined threshold.
2. The system of claim 1, the method further comprising: capturing the audio via the contact microphone in contact with an exterior of a human knee.
3. The system of claim 2, wherein the contact microphone is in contact with an anterior patellar surface.
4. The system of claim 1, the method further comprising: canceling noise from the audio prior to extracting the plurality of features.
5. The system of claim 4, wherein canceling noise comprises: capturing an ambient audio signal by a second microphone; removing the ambient audio signal from the audio.
6. The system of claim 4, wherein canceling the noise comprises: applying a bandpass filter to the audio.
7. The system of claim 1, wherein the plurality of features comprises signal frequency, amplitude, zero-crossing rate, entropy of energy, spectral centroid, spectral spread, mel-frequency cepstral coefficients, or chroma vector.
8. The system of claim 1, wherein the trained classifier comprises a random decision forest.
9. The system of claim 1, wherein the trained classifier comprises a neural network.
10. The system of claim 1, wherein the trained classifier comprises a support vector machine.
11. The system of claim 1, the method further comprising: computing a second score indicative of joint health from the first score.
12. The system of claim 11, wherein computing the second score comprises weighting the first score according to a reported pain value.
13. The system of claim 11, wherein computing the second score comprises weighting the first score according to a characteristic of a subject.
14. The system of claim 13, wherein the characteristic comprises body mass index, age, gender, existing medical condition, or frequency of physical activity.
15. The system of claim 1, the method further comprising outputting the first score or the second score to a user.
16. A method comprising: receiving audio from a contact microphone, the audio comprising sounds emanating from a human joint during flexion; receiving, from a position sensor, motion data of the human joint; synchronizing the motion data with the audio; extracting a plurality of features from the audio; providing the plurality of features and the motion data to a trained classifier; obtaining from the trained classifier a first score indicative of joint health; and displaying the score with an indication to perform follow-up when the score is below a predetermined threshold.
17. The system of claim 1, wherein the position sensor is in contact with an exterior of a human knee.
18. The system of claim 17, wherein the position sensor is in contact with an anterior patellar surface.
19. The system of claim 4, wherein canceling noise is performed using the motion data.
20. The system of claim 19, wherein cancelling noise comprises determining periodicity of the motion data.
21. The system of claim 1, the method further comprising: obtaining from the trained classifier a location of joint noise within the human joint; displaying the location of joint noise.
22. The method of claim 16, further comprising: obtaining from the trained classifier a location of joint noise within the human joint; displaying the location of joint noise.
</claims>
</document>
