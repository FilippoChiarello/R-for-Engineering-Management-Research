<document>

<filing_date>
2016-06-24
</filing_date>

<publication_date>
2020-04-07
</publication_date>

<priority_date>
2016-06-24
</priority_date>

<ipc_classes>
G06F11/30,H04L12/26
</ipc_classes>

<assignee>
AMD (ADVANCED MICRO DEVICES)
</assignee>

<inventors>
PAUL, INDRANI
PIGA, LEONARDO
HUANG WEI
KOCOLOSKI, BRIAN J.
</inventors>

<docdb_family_id>
60678015
</docdb_family_id>

<title>
Achieving balanced execution through runtime detection of performance variation
</title>

<abstract>
Systems, apparatuses, and methods for achieving balanced execution in a multi-node cluster through runtime detection of performance variation are described. During a training phase, performance counters and an amount of time spent waiting for synchronization is monitored for a plurality of tasks for each node of the multi-node cluster. These values are utilized to generate a model which correlates the values of the performance counters to the amount of time spent waiting for synchronization. Once the model is built, the values of the performance counters are monitored for a period of time at the start of each task, and these values are input into the model. The model generates a prediction of whether a given node is on the critical path. If the given node is predicted to be on the critical path, the power allocation of the given node is increased.
</abstract>

<claims>
1. A system comprising: a computing cluster comprising plurality of nodes; and a cluster agent configured to map each task of a plurality of tasks of a workload to a different node of the plurality of the nodes, each of the plurality of tasks ending with a barrier configured to wait for all nodes of the cluster executing a task of the plurality of tasks to reach the barrier before starting a new task; wherein each node of the plurality of nodes comprises circuitry configured to: create a run-time prediction model independently of models created by other nodes of the plurality of nodes while performing a given task, wherein the model provides a prediction of an amount of time to complete the given task based on an amount of time waiting for synchronization of the given task and run-time values of one or more of a plurality of performance parameters of a node; and identify, using the model, a subset of performance parameters of the plurality of performance parameters which are predicted to correlate to an amount of time waiting for synchronization of the given task; wherein while the cluster has not reached a synchronization point, each node of the plurality of nodes comprises circuitry configured to: track the subset of performance parameters during an initial period of time while performing a current task of the workload; generate, independently of other nodes, a prediction while performing the current task, of how long the node will take to complete the current task, wherein the prediction is generated by the model using the subset of performance parameters; increase an amount of power allocated to the node subsequent to the initial period of time responsive to predicting, during performance of the current task, that the node will take longer than a programmable threshold amount of time to complete the current task; decrease, during run-time, the amount of power allocated to the node subsequent to the initial period of time responsive to predicting, during performance of the current task, that the node will take less than the programmable threshold amount of time to complete the current task; and determine if the cluster has reached the synchronization point.
2. The system as recited in claim 1, wherein each node is further configured to identify, during a training phase, which subset of parameters of the plurality of parameters most closely correlate to time waiting for said synchronization, wherein each node identifies the subset of parameters independently of other nodes.
3. The system as recited in claim 1, wherein the cluster agent is further configured to send to each node one or more performance counter thresholds and a likelihood outcome that a corresponding task will be on a critical path, and wherein each node is configured to determine whether performance counters exceed the performance counter thresholds during execution of a corresponding task.
4. The system as recited in claim 1, wherein each node is configured to: track one or more performance counter values for an initial period of time at a beginning of a given task; provide the one or more performance counter values as inputs to the model while executing the given task; generate, with the model, a criticality probability based on the one or more performance counter values; and characterize the given task as being on a critical path if the criticality probability is greater than a criticality threshold.
5. The system as recited in claim 1, wherein creating the model comprises correlating values of the subset of performance parameters with the amount of time spent waiting for synchronization.
6. The system as recited in claim 1, wherein the model is configured to generate a likelihood that a given task will be on a critical path, and wherein each node is configured to generate frequency and voltage settings based on the likelihood.
7. The system as recited in claim 1, wherein the subset of performance parameters includes at least one or more of: a translation lookaside buffer (TLB) hit rate, a percentage of time spent in kernel mode versus user mode, a number of cycles from instruction completion to retirement, and a number of cycles from instruction tagging to retirement.
8. A method comprising: mapping, by a cluster agent, each task of a plurality of tasks of a workload to a different node of a computing cluster comprising a plurality of nodes comprising circuitry, each of the plurality of tasks ending with a barrier configured to wait for all nodes of the cluster executing a task of the plurality of tasks to reach the barrier before starting a new task; creating, by each node of the plurality of nodes, a run-time prediction model independently of models created by other nodes of the plurality of nodes while performing a given task, wherein the model provides a prediction of an amount of time to complete the given task based on an amount of time waiting for synchronization of the given task and run-time values of one or more of a plurality of performance parameters of a node; identifying, by each node of the plurality of nodes using the model, a subset of performance parameters of the plurality of performance parameters which are predicted to correlate to an amount of time waiting for synchronization of the given task; while the cluster has not reached a synchronization point: tracking, by each node of the plurality of nodes, the subset of performance parameters during an initial period of time while performing a current task of the workload; generating, independently of other nodes, a prediction while performing the current task of how long the node will take to complete the current task, wherein the prediction is generated by the model using the subset of performance parameters; increasing an amount of power allocated to the node subsequent to the initial period of time responsive to predicting, during performance of the current task, that the node will take longer than a programmable threshold amount of time to complete the current task; decreasing, during run-time, the amount of power allocated to the node subsequent to the initial period of time responsive to predicting, during performance of the current task, that the node will take less than the programmable threshold amount of time to complete the current task; and determining if the cluster has reached the synchronization point.
9. The method as recited in claim 8, wherein the method further comprises each node identifying, during a training phase, which subset of parameters of the plurality of parameters most closely correlate to time waiting for said synchronization, wherein each node identifies the subset of parameters independently of other nodes.
10. The method as recited in claim 8, further comprising: sending, by the cluster agent to each node, one or more performance counter thresholds and a likelihood outcome that a corresponding task will be on the critical path; and determining, by each node, whether one or more performance counters exceed the one or more performance counter thresholds during execution of a corresponding task.
11. The method as recited in claim 8, further comprising: tracking one or more performance counter values for an initial period of time at a beginning of a given task; providing the one or more performance counter values as inputs to the model while executing the given task; generating, with the model, a criticality probability based on the one or more performance counter values; and characterizing the given task as being on a critical path if the criticality probability is greater than a criticality threshold.
12. The method as recited in claim 8, wherein creating the model comprises correlating values of the subset of performance parameters with the amount of time spent waiting for synchronization.
13. The method as recited in claim 8, further comprising generating a likelihood that a given task will be on a critical path and generating frequency and voltage settings based on the likelihood.
14. The method as recited in claim 8, wherein the subset of performance parameters includes at least one or more of: a translation lookaside buffer (TLB) hit rate, a percentage of time spent in kernel mode versus user mode, a number of cycles from instruction completion to retirement, and a number of cycles from instruction tagging to retirement.
15. A non-transitory computer readable storage medium comprising program instructions, wherein the program instructions are executable to: map, by a cluster agent, each task of a plurality of tasks of a workload to a different node of computing cluster comprising a plurality of nodes comprising circuitry, each of the plurality of tasks ending with a barrier configured to wait for all nodes of the cluster executing a task of the plurality of tasks to reach the barrier before starting a new task; create, by each node of the plurality of nodes, a run-time prediction model independently of models created by other nodes of the plurality of nodes while performing a given task, wherein the model provides a prediction of an amount of time to complete the given task based on an amount of time waiting for synchronization of the given task and run-time values of one or more of a plurality of performance parameters of a node; identify, by each node of the plurality of nodes using the model, a subset of performance parameters of the plurality of performance parameters which are predicted to correlate to an amount of time waiting for synchronization of the given task; while the cluster has not reached a synchronization point: track, by each node of the plurality of nodes, the subset of performance parameters during an initial period of time while performing a current task of the workload; generate, independently of other nodes, a prediction while performing the current task of how long the node will take to complete the current task, wherein the prediction is generated by the model using the subset of performance parameters; increase an amount of power allocated to the node subsequent to the initial period of time responsive to predicting, during performance of the current task, that the node will take longer than a programmable threshold amount of time to complete the current task; decrease, during run-time, the amount of power allocated to the node subsequent to the initial period of time responsive to predicting, during performance of the current task, that the node will take less than the programmable threshold amount of time to complete the current task; and determine if the cluster has reached the synchronization point.
16. The non-transitory computer readable storage medium as recited in claim 15, wherein the initial period of time is less than a total amount of time utilized by the node for performing the task, and the program instructions are further executable to, for each node identify, during a training phase, which subset of parameters of the plurality of parameters most closely correlate to time waiting for said synchronization, wherein each node identifies the subset of parameters independently of other nodes.
17. The non-transitory computer readable storage medium as recited in claim 15, wherein the program instructions are further executable to: send, by the cluster agent to each node, one or more performance counter thresholds and a likelihood outcome that a corresponding task will be on the critical path; and determine, by each node, whether one or more performance counters exceed the one or more performance counter thresholds during execution of a corresponding task.
18. The non-transitory computer readable storage medium as recited in claim 15, wherein the program instructions are further executable to: track one or more performance counter values for an initial period of time at a beginning of a given task; provide the one or more performance counter values as inputs to the model while executing the given task; generate, with the model, a criticality probability based on the one or more performance counter values; and characterize the given task as being on a critical path if the criticality probability is greater than a criticality threshold.
19. The non-transitory computer readable storage medium as recited in claim 15, wherein creating the model comprises correlating values of the subset of performance parameters with the amount of time spent waiting for synchronization.
20. The non-transitory computer readable storage medium as recited in claim 15, wherein the program instructions are further executable to generate a likelihood that a given task will be on a critical path and generate frequency and voltage settings based on the likelihood.
</claims>
</document>
