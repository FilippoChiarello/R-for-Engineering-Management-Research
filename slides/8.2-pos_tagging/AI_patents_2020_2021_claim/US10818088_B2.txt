<document>

<filing_date>
2018-07-10
</filing_date>

<publication_date>
2020-10-27
</publication_date>

<priority_date>
2018-07-10
</priority_date>

<ipc_classes>
G06T15/00,G06T19/00
</ipc_classes>

<assignee>
CURIOUS
</assignee>

<inventors>
JONES, ANTHONY MARK
JONES, JESSICA A. F.
YOUNG BRUCE A.
</inventors>

<docdb_family_id>
69138464
</docdb_family_id>

<title>
Virtual barrier objects
</title>

<abstract>
A computer system presents a virtual object on a display of the computer system which represents an action at a location in space. If a user of the computer system approaches the location, the computer system presents one or more stimuli to encourage movement away from that location. The appearance of the object may vary as the user of the computer system moves. The appearance of the object may include information and may vary with a change of state. Multiple such virtual objects may be used to indicate a path.
</abstract>

<claims>
1. A method to provide directional guidance to a user wearing a head-mounted display (HMD), the method comprising: establishing a three-dimensional (3D) real-world position for a virtual barrier object, the virtual barrier object not in a real-world environment around the user; rendering an image of the virtual barrier object at a position corresponding to the 3D real-world position on the HMD; and presenting an additional sensory stimulus, directed to the user's sense of sound, touch, smell, or taste, in addition to the rendered image of the virtual barrier object, to the user to encourage the user to avoid the 3D real-world position of the virtual barrier object.
2. The method of claim 1, further comprising: capturing an image of a portion of the real-world around the user with a camera mounted on the HMD; and displaying, to the user on the HMD, the rendered image of the virtual barrier object overlaid on the captured image of the portion of the real-world around the user.
3. The method of claim 1, further comprising: creating a synthetic image of a portion of the real-world around the user based on data about the real-world around the user; and displaying, to the user on the HMD, the rendered image of the virtual barrier object overlaid on the synthetic image of the portion of the real-world around the user.
4. The method of claim 3, further comprising by rendering images of one or more real-world objects identified in the data about the real-world around the user to create the synthetic image.
5. The method of claim 1, further comprising: transmitting a view of a portion of the real-world around the user through a transparent portion of the HMD; and displaying the rendered image of the virtual barrier object to occlude a portion of the view of the portion of the real-world around the user.
6. The method of claim 1, further comprising: determining a distance between the user and the 3D real-world position of the virtual object; and selecting the additional sensory stimulus based on the distance.
7. The method of claim 1, further comprising: determining a closing velocity between the user and the 3D real-world position of the virtual object; and selecting the additional sensory stimulus based on the closing velocity.
8. The method of claim 1, wherein the additional sensory stimulus comprises a haptic push delivered by a haptic subsystem of the HMD.
9. The method of claim 1, further comprising: calculating a direction for the user to move to avoid the 3D real-world position of the virtual object; and communicating information related to the direction to an article of haptic clothing worn by the user; wherein the additional sensory stimulus comprises a haptic push applied by the article of haptic clothing worn by the user to encourage the user to move in the direction to avoid the 3D real-world position of the virtual object.
10. The method of claim 1, wherein the additional sensory stimulus encourages the user to move in a specific direction.
11. The method of claim 10, wherein the additional sensory stimulus comprises an unnatural sound presented to the user as originating in the specific direction.
12. The method of claim 1, wherein the 3D real-world position of the virtual barrier object corresponds to a gap between two real-world objects.
13. The method of claim 12, wherein the virtual barrier object is rendered in a correct orientation of the user according to a 3D real-world position of the two real-world objects.
14. An article of manufacture comprising a tangible medium, that is not a transitory propagating signal, encoding computer-readable instructions that, when applied to a computer system, instruct the computer system to perform a method comprising: establishing a three-dimensional (3D) real-world position for a virtual barrier object, the virtual barrier object not in a real-world environment around the user; rendering an image of the virtual barrier object at a position corresponding to the 3D real-world position on the HMD; and presenting an additional sensory stimulus, directed to the user's sense of sound, touch, smell, or taste, in addition to the rendered image of the virtual barrier object, to the user to encourage the user to avoid the 3D real-world position of the virtual barrier object.
15. A head-mounted display (HMD) comprising: a display; a structure, coupled to the display and adapted to position the display in a field-of-view (FOV) of the user; a processor, coupled to the display, the processor configured to: establish a three-dimensional (3D) real-world position for a virtual barrier object, the virtual barrier object not in a real-world environment around the user; render an image of the virtual barrier object at a position corresponding to the 3D real-world position on the HMD; and present an additional sensory stimulus, directed to the user's sense of sound, touch, smell, or taste, in addition to the rendered image of the virtual barrier object, to the user to encourage the user to avoid the 3D real-world position of the virtual barrier object.
</claims>
</document>
