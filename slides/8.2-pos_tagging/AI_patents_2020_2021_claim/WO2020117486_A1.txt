<document>

<filing_date>
2019-11-21
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-05
</priority_date>

<ipc_classes>
A61B5/00,A61B8/08
</ipc_classes>

<assignee>
VERATHON
</assignee>

<inventors>
CHOI, JOON HWAN
PADWAL, MONALI
WATERS, KENDALL R.
YANG FUXING
</inventors>

<docdb_family_id>
68965984
</docdb_family_id>

<title>
IMPLANT ASSESSMENT USING ULTRASOUND AND OPTICAL IMAGING
</title>

<abstract>
A system may include an ultrasound probe and a controller unit configured to obtain a baseline ultrasound image of a patient's breast area using the ultrasound probe and to obtain a follow-up ultrasound image of the patient's breast area using the ultrasound probe. The controller unit may further be configured to use one or more machine learning models to compare the baseline ultrasound image with the follow-up ultrasound image; detect a change in a morphology or integrity of the patient's breast area based on the comparison of the baseline ultrasound image with the follow-up ultrasound image; and generate a recommendation for a medical intervention based on the detected change.
</abstract>

<claims>
1. A method performed by a computing device, the method comprising:
obtaining, by the computing device, a baseline ultrasound image of a patient's breast area;
obtaining, by the computing device, a follow-up ultrasound image of the patient's breast area;
using, by the computing device, one or more machine learning models to compare the baseline ultrasound image with the follow-up ultrasound image;
detecting, by the computing device, a change in a morphology or integrity of the patient's breast area based on the comparison of the baseline ultrasound image with the follow-up ultrasound image; and
generating, by the computing device, a recommendation for a medical intervention based on the detected change.
2. The method of claim 1, further comprising:
obtaining a baseline optical image of the patient's breast area;
obtaining a follow-up optical image of the patient's breast area;
using the one or more machine learning models to compare the baseline optical image with the follow-up optical image; and
wherein detecting the change in the morphology or integrity of the patient's breast area is further based on the comparison of the baseline optical image with the follow-up optical image.
3. The method of claim 1, further comprising:
obtaining a baseline three-dimensional (3D) scan image of the patient's breast area; obtaining a follow-up 3D scan image of the patient's breast area;
using the one or more machine learning models to compare the baseline 3D scan image with the follow-up 3D scan image; and
wherein detecting the change in the morphology or integrity of the patient's breast area is further based on the comparison of the baseline 3D scan image with the follow-up 3D scan image.
4. The method of claim 1, further comprising:
obtaining a baseline thermal camera image of the patient's breast area; obtaining a follow-up thermal camera image of the patient's breast area;
using the one or more machine learning models to compare the baseline thermal camera image with the follow-up thermal camera image; and
detecting a change in a morphology, integrity or temperature variation of the patient's breast area based on the comparison of the baseline thermal camera image with the follow-up thermal camera image.
5. The method of claim 1, further comprising:
obtaining a baseline elastography image of the patient's breast area;
obtaining a follow-up elastography image of the patient's breast area;
using the one or more machine learning models to compare the baseline elastography image with the follow-up elastography image; and
detecting a change in a morphology, integrity, or stiffness of the patient's breast area based on the comparison of the baseline elastography image with the follow-up elastography image.
6. The method of claim 3, further comprising:
obtaining a three-dimensional (3D) scan image of the patient's breast area using one or more depth cameras;
generating a 3D geometrical feature plot using the obtained 3D scan image; and using the generated 3D geometrical feature plot as an input into the one or more machine learning models.
7. The method of claim 1, wherein using the one or more machine learning models to compare the baseline ultrasound image with the follow-up ultrasound image includes:
using the one or more machine learning models to determine a quantitative clinical grading value for the morphology or integrity of the patient's breast area.
8. The method of claim 1, further comprising:
using the one or more machine learning models to perform a segmentation of an implant capsule, a rupture area, or a fluid collection in an ultrasound image of the patient's breast area.
9. The method of claim 8, further comprising:
using a plurality of ultrasound images that include the segmentation of the implant capsule, the rupture area, or the fluid collection to generate a three-dimensional (3D) shape of the implant capsule, the rupture area, or the fluid collection.
10. The method of claim 1, further comprising:
using the one or more machine learning models to determine whether the patient's breast area is associated with at least one of:
an extracapsular rupture,
an intracapsular rupture,
a capsular contracture, or
a fluid collection.
11. The method of claim 1, wherein obtaining the baseline ultrasound image of the patient's breast area and obtaining the follow-up ultrasound image of the patient's breast area include:
dividing a breast area into a plurality of sectors;
scanning particular ones of the plurality of sectors using an ultrasound probe;
indicating, on a user interface, which ones of the plurality of sectors has been scanned;
receiving, via the user interface, a selection of a scanned sector of the plurality of sectors; and
displaying, in the user interface, one or more ultrasound images associated with the selected scanned sector.
12. The method of claim 1, wherein at least one of the baseline ultrasound image and follow-up ultrasound image includes a B-mode ultrasound image, a Power Doppler ultrasound image, a Continuous Wave Doppler ultrasound image, a Pulsed Wave Doppler ultrasound image, a Probability Mode ultrasound image, or a motion mode ultrasound image.
13. A system comprising:
an ultrasound probe; and
a controller unit configured to: obtain a baseline ultrasound image of a patient's breast area using the ultrasound probe;
obtain a follow-up ultrasound image of the patient's breast area using the ultrasound probe;
use one or more machine learning models to compare the baseline ultrasound image with the follow-up ultrasound image;
detect a change in a morphology or integrity of the patient's breast area based on the comparison of the baseline ultrasound image with the follow-up ultrasound image; and
generate a recommendation for a medical intervention based on the detected change.
14. The system of claim 13, further comprising:
a depth camera; and
wherein the controller unit is further configured to:
obtain a baseline optical or three-dimensional (3D) scan image of the patient's breast area using the depth camera;
obtain a follow-up optical or 3D scan image of the patient's breast area using the depth camera;
use the one or more machine learning models to compare the baseline optical or 3D scan image with the follow-up optical or 3D scan image; and
wherein the controller unit is further configured to detect the change in the morphology or integrity of the patient's breast area based on the comparison of the baseline optical or 3D scan image with the follow-up optical or 3D scan image.
15. The system of claim 14, wherein the controller unit is further configured to:
obtain a 3D scan image of the patient's breast area using the depth camera;
generate a 3D geometrical feature plot using the obtained 3D scan image; and use the generated 3D geometrical feature plot as an input into the one or more machine learning models.
16. The system of claim 13, wherein the controller unit is further configured to:
obtain a baseline elastography image of the patient's breast area using the ultrasound probe; obtain a follow-up elastography image of the patient's breast area using the ultrasound probe;
use the one or more machine learning models to compare the baseline elastography image with the follow-up elastography image; and
wherein the controller unit is further configured to detect the change in the morphology or integrity of the patient's breast area based on the comparison of the baseline elastography image with the follow-up elastography image.
17. The system of claim 13, wherein, when using the one or more machine learning models to compare the baseline ultrasound image with the follow-up ultrasound image, the controller unit is further configured to:
use the one or more machine learning models to determine a quantitative clinical grading value for the morphology or integrity of the patient's breast area.
18. The system of claim 13, wherein the controller unit is further configured to:
use the one or more machine learning models to perform a segmentation of an implant capsule, a rupture area, or a fluid collection in an ultrasound image of the patient's breast area; and
use a plurality of ultrasound images that include the segmentation of the implant capsule, the rupture area, or the fluid collection to generate a three-dimensional (3D) shape of the implant capsule, the rupture area, or the fluid collection.
19. The system of claim 13, wherein the controller unit is further configured to:
use the one or more machine learning models to determine whether the patient's breast area is associated with at least one of:
an extracapsular rupture,
an intracapsular rupture,
capsular contracture, or
a fluid collection.
20. A device comprising:
logic configured to:
obtain a baseline ultrasound image of a patient's breast area using an ultrasound probe; obtain a follow-up ultrasound image of the patient's breast area using the ultrasound probe;
obtain a baseline optical or three-dimensional (3D) scan image of the patient's breast area using the depth camera;
obtain a follow-up optical or 3D scan image of the patient's breast area using the depth camera;
use one or more machine learning models to compare the baseline ultrasound image with the follow-up ultrasound image and the baseline optical or 3D scan image with the follow-up optical or 3D scan image;
detect a change in a morphology or integrity of the patient's breast area based on the comparison of the baseline ultrasound image with the follow-up ultrasound image and the baseline optical or 3D scan image with the follow-up optical or 3D scan image; and
generate a recommendation for a medical intervention based on the detected change.
21. A method performed by a computing device, the method comprising:
obtaining, by the computing device, an ultrasound image of a patient's breast area; obtaining, by the computer device, at least one of an optical image of the patient's breast area, a three-dimensional (3D) scan image of the patient's breast area, or a thermal camera image of the patient's breast area;
using, by the computing device, one or more machine learning models to compare the ultrasound image with the at least one of the optical image of the patient's breast area, the 3D scan image of the patient's breast area, or the thermal camera image of the patient's breast area;
detecting, by the computing device, a change in a morphology or integrity of the patient's breast area based on the comparison; and
generating, by the computing device, a recommendation for a medical intervention based on the detected change.
</claims>
</document>
