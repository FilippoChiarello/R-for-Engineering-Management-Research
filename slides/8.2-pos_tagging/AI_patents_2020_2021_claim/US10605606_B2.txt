<document>

<filing_date>
2018-07-11
</filing_date>

<publication_date>
2020-03-31
</publication_date>

<priority_date>
2016-05-16
</priority_date>

<ipc_classes>
B64C39/02,B64D47/08,G01C21/00,G01C21/16,G06K9/00,G06K9/34,G06K9/62
</ipc_classes>

<assignee>
MA, YUNQIAN
NORTHROP GRUMMAN SYSTEMS CORPORATION
</assignee>

<inventors>
MA, YUNQIAN
</inventors>

<docdb_family_id>
60294615
</docdb_family_id>

<title>
Vision-aided aerial navigation
</title>

<abstract>
An aerial vehicle is navigated using hierarchical vision-aided navigation that classifies regions of acquired still image frames as featureless or feature-rich, and thereby avoids expending time and computational resources attempting to extract and match false features from the featureless regions. Pattern recognition registers an acquired image to a general area of a map database before performing feature matching to a finer map region. This hierarchical position determination is more efficient than attempting to ascertain a fine-resolution position without knowledge of coarse-resolution position. Resultant matched feature observations can be data-fused with other sensor data to correct a navigation solution based on GPS and/or IMU data.
</abstract>

<claims>
1. A hierarchical position determination based method of navigation of an aerial vehicle, the method comprising: determining that the navigation solution covariances computed during flight exceed a predetermined distance threshold; acquiring an aerial image frame from a camera on the aerial vehicle; partitioning the acquired aerial image frame into a plurality of regions; determining that at least one partitioned region of the image frame is not featureless; matching the acquired aerial image frame to a coarse global map region using a pattern recognition method; limiting a region of search of a map feature database to features in the database geo-registered to spatial coordinates within the matched coarse global map region; generating matched feature observations by matching features extracted from at least one of the partitioned image regions to corresponding features in the map feature database; navigating the aerial vehicle based at least in part on the matched feature observations.
2. The method of claim 1, wherein the generating matched feature observations comprises: classifying one or more of the plurality of regions as featureless or feature-rich by: computing an autocorrelation function to determine at least one peak width, and testing the at least one peak width against a width threshold, and/or by using a model that has been trained using a machine learning method applied to a training dataset comprising a plurality of training images of featureless regions and a plurality of training images of feature-rich regions; extracting features for those regions classified as feature-rich and not for those regions classified as featureless.
3. The method of claim 2, wherein the classifying of the regions is conducted in parallel, with each region classified in an independent software thread.
4. The method of claim 2, wherein the generating matched feature observations further comprises matching features following the extracting features, wherein matched feature observations are generated by matching features extracted from the regions to corresponding features in a map feature database.
5. The method of claim 4, further comprising performing data fusion following the matching features and prior to the navigating the aerial vehicle, wherein the matched feature observations are combined with inertial measurement unit (IMU) sensor readings using a Kalman filter to arrive at a corrected navigation solution suitable for input into an inertial navigation system (INS).
6. The method of claim 5, wherein the Kalman filter fuses readings from a barometric sensor in addition to the matched feature observations and the IMU sensor readings to arrive at the corrected navigation solution.
7. The method of claim 2, further comprising performing perspective warping following the classifying and prior to the extracting features, wherein the perspective of a region is ortho-rectified.
8. The method of claim 2, wherein one or more of the plurality of regions is classified as featureless or feature-rich by computing the autocorrelation function to determine the at least one peak width, and by testing the at least one peak width against the width threshold, wherein the width threshold is dynamically computed as an Otsu threshold statistically derived from a set of peak widths determined from the plurality of regions, the set of peak widths having a bimodal distribution.
9. The method of claim 1, wherein the partitioning the acquired aerial image frame comprises partitioning the acquired aerial image frame into regions using a watershed segmentation method.
10. The method of claim 1, wherein the partitioning the acquired aerial image frame comprises partitioning the acquired aerial image frame into regions using a grid partition method.
11. The method of claim 1, wherein the size of the coarse global map region to which the acquired aerial image frame is matched is smaller than the globe surface area of each of the partitioned acquired aerial image frame regions.
12. The method of claim 1, wherein the area of the coarse global map region to which the acquired aerial image frame is matched corresponds to one ten-thousandth of the globe or larger.
13. The method of claim 1, wherein the distance threshold is on the order of thousands of miles.
14. The method of claim 1, wherein the pattern recognition method is based on or more of: a generalized Fourier transform, Bayesian sequential hypothesis testing, artificial neural networks, and/or genetic algorithms.
15. A system for navigation of an aerial vehicle using hierarchical position determination, the system comprising: a camera configured to acquire an aerial image frame; a fusion engine configured to provide navigation solution covariances indicative of accumulated error in a determination of the position of the aerial vehicle during GNSS-denied flight; an image processor comprising: a partitioner configured to partition an acquired aerial image frame into a plurality of regions; a classifier configured to classify each one of the regions as only one of featureless or feature-rich; a pattern recognizer configured to match the acquired aerial image frame to a coarse global map region using a pattern recognition method based on determining that: at least one partitioned region of the image frame is not featureless, and the navigation solution covariances computed during flight exceed a predetermined distance threshold; and a feature matcher configured to generate matched feature observations by matching features extracted from at least one of the partitioned image regions classified as feature-rich to corresponding features in one or more selected search regions of a map feature database having a number of search regions, wherein the one or more selected search regions of the map feature database are limited to those geo-registered to spatial coordinates within the matched coarse global map region; and navigation controls configured to navigate the aerial vehicle based at least in part on the matched feature observations.
16. The system of claim 15, wherein the classifier is configured to classify the one or more of the plurality of regions as featureless or feature-rich by computing an autocorrelation function to determine at least one peak width, and testing the at least one peak width against a width threshold.
17. The system of claim 15, wherein the classifier is configured to classify the one or more of the plurality of regions as featureless or feature-rich by using a model that has been trained using a machine learning method applied to a training dataset comprising a plurality of training images of featureless regions and a plurality of training images of feature-rich regions.
18. The system of claim 15, wherein the size of the coarse global map region to which the acquired aerial image frame is matched is smaller than the globe surface area of each of the partitioned acquired aerial image frame regions.
19. The system of claim 15, wherein the area of the coarse global map region to which the acquired aerial image frame is matched corresponds to one ten-thousandth of the globe or larger.
20. The system of claim 15, wherein the distance threshold is on the order of thousands of miles.
</claims>
</document>
