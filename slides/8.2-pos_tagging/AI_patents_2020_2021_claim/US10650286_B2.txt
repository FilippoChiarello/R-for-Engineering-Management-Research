<document>

<filing_date>
2017-09-07
</filing_date>

<publication_date>
2020-05-12
</publication_date>

<priority_date>
2017-09-07
</priority_date>

<ipc_classes>
A61B5/00,A61B5/055,A61B6/00,G06K9/00,G06K9/46,G06K9/62,G06N3/04,G06N3/08,G16H30/40,G16H50/20,G16H50/70
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
KISILEV, PAVEL
BEN-ARI, RAMI
SULAM, JEREMIAS
</inventors>

<docdb_family_id>
65517280
</docdb_family_id>

<title>
Classifying medical images using deep convolution neural network (CNN) architecture
</title>

<abstract>
Embodiments of the present systems and methods may provide the capability to classify medical images, such as mammograms, in an automated manner using existing annotation information. In embodiments, only the global, image level tag may be needed to classify a mammogram into certain types, without fine annotation of the findings in the image. In an embodiment, a computer-implemented method for classifying medical images may comprise receiving a plurality of image tiles, each image tile including a portion of a whole view, processed by a trained or a pre-trained model and outputting a one-dimensional feature vector for each tile to generate a three-dimensional feature volume and classifying the larger image by a trained model based on the generated three-dimensional feature volume to form a classification of the image.
</abstract>

<claims>
1. A computer-implemented method for classifying medical images comprising: receiving a plurality of image tiles from a whole medical image, the whole medical image having a global image-level tag and without local annotations that reveal a position and a shape of findings within the image, each image tile including a portion of the whole image, processed by a trained or a pre-trained model and outputting a one-dimensional feature vector for each tile to generate a three-dimensional feature volume; and classifying the whole image by a trained model based on the generated three-dimensional feature volume to form a classification of the image, the trained model comprising a plurality of layers to decrease spatial dimensions of the generated three-dimensional feature volume to a singular output.
2. The method of claim 1, wherein the whole image is one of a mammogram image or a breast Magnetic Resonance Imaging image.
3. The method of claim 2, wherein the singular output is a classification that is a binary classification that classifies the images into malignant or benign.
4. The method of claim 3, wherein the class populations are highly imbalanced.
5. The method of claim 3, wherein the three-dimensional feature volume is generated using a plurality of layers of convolutional network processing in a deep convolutional neural network, wherein the deep convolutional neural network uses a deep neural network loss function that directly maximizes an area under the curve (AUC) performance measure.
6. The method of claim 5, wherein the deep convolutional neural network combines a tile based approach with pre-trained encoding and trained convolutional neural network layers.
7. The method of claim 1, wherein sizes of the tiles are determined based on an expected size of findings in the images.
8. A system for classifying medical images, the system comprising a processor, memory accessible by the processor, and computer program instructions stored in the memory and executable by the processor to perform: receiving a plurality of image tiles from a whole medical image, the whole medical image having a global image-level tag and without local annotations that reveal a position and a shape of findings within the image, each image tile including a portion of the whole image, processed by a trained or a pre-trained model and outputting a one-dimensional feature vector for each tile to generate a three-dimensional feature volume; and classifying the whole image by a trained model based on the generated three-dimensional feature volume to form a classification of the image, the trained model comprising a plurality of layers to decrease spatial dimensions of the generated three-dimensional feature volume to a singular output.
9. The system of claim 8, wherein the whole image is one of a mammogram image or a breast Magnetic Resonance Imaging image.
10. The system of claim 9, wherein the singular output is a classification that is a binary classification that classifies the images into malignant or benign.
11. The system of claim 10, wherein the class populations are highly imbalanced.
12. The system of claim 10, wherein the three-dimensional feature volume is generated using a plurality of layers of convolutional network processing in a deep convolutional neural network, wherein the deep convolutional neural network uses a deep neural network loss function that directly maximizes an area under the curve (AUC) performance measure.
13. The system of claim 12, wherein the deep convolutional neural network combines a tile based approach with pre-trained encoding and trained convolutional neural network layers.
14. The system of claim 8, wherein sizes of the tiles are determined based on an expected size of findings in the images.
15. A computer program product for classifying medical images, the computer program product comprising a non-transitory computer readable storage having program instructions embodied therewith, the program instructions executable by a computer, to cause the computer to perform a method comprising: receiving a plurality of image tiles from a whole medical image, the whole medical image having a global image-level tag and without local annotations that reveal a position and a shape of findings within the image, each image tile including a portion of the whole image, processed by a trained or a pre-trained model and outputting a one-dimensional feature vector for each tile to generate a three-dimensional feature volume; and classifying the whole image by a trained model based on the generated three-dimensional feature volume to form a classification of the image, the trained model comprising a plurality of layers to decrease spatial dimensions of the generated three-dimensional feature volume to a singular output.
16. The computer program product of claim 15, wherein the whole image is one of a mammogram image or a breast Magnetic Resonance Imaging image.
17. The computer program product of claim 16, wherein the singular output is a classification that is a binary classification that classifies the images into malignant or benign.
18. The computer program product of claim 17, wherein the class populations are highly imbalanced.
19. The computer program product of claim 17, wherein the three-dimensional feature volume is generated using a plurality of layers of convolutional network processing in a deep convolutional neural network, wherein the deep convolutional neural network uses a deep neural network loss function that directly maximizes an area under the curve (AUC) performance measure.
20. The computer program product of claim 19, wherein the deep convolutional neural network combines a tile based approach with pre-trained encoding and trained convolutional neural network layers.
</claims>
</document>
