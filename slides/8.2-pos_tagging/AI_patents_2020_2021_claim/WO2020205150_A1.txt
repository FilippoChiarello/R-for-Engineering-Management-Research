<document>

<filing_date>
2020-03-05
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-02
</priority_date>

<ipc_classes>
G06Q10/06
</ipc_classes>

<assignee>
ASPEN TECHNOLOGY
</assignee>

<inventors>
JANAK, STACY
VARVAREZOS, DIMITRIOS
TERRAZAS-MORENO, Sebastian
</inventors>

<docdb_family_id>
70190091
</docdb_family_id>

<title>
VALIDATION OF OPERATING PLANS AND SCHEDULES USING MACHINE LEARNING
</title>

<abstract>
Disclosed are methods and systems that help identify critical variables for more efficient and robust plan validation process. An example embodiment is a computer implemented method of industrial process control. The example method includes receiving in computer memory a dataset including initial process parameters representing operational data of a subject industrial process, and, using filtering operations and grouping operations on the dataset, identifying a subset of the process parameters indicative of control data for controlling the subject industrial process. The example method further includes automatically applying the identified subset of process parameters controlling the subject industrial process.
</abstract>

<claims>
What is claimed is:
1. A computer implemented method of industrial process control, comprising:
receiving in computer memory a dataset including initial process parameters representing operational data of a subject industrial process;
using filtering operations and grouping operations on the dataset, identifying a subset of the process parameters indicative of control data for controlling the subject industrial process, said using filtering operations and grouping operations including:
(i) applying a filter to the dataset that filters as a function of relative importance among the process parameters and that results in a filtered dataset having process parameters of threshold importance;
(ii) grouping into one or more clusters the process parameters of the filtered dataset based on correlation among the process parameters of the filtered dataset; and
(iii) for each cluster resulting from the grouping, extracting from the filtered dataset process parameters based on any one or combination of (a) a priority rating, (b) a measure of collinearity between the grouped process parameters within each given cluster of the determined clusters, (c) a measure of importance associated with the grouped process parameters, and (d) randomly or pseudo-randomly; and
automatically applying the identified subset of process parameters controlling the subject industrial process.
2. The method of Claim 1, wherein the industrial process includes at least one of an optimized operational planning process, a scheduling process, a simulated chemical plant process, and an actual chemical plant process.
3. The method of Claim 1, wherein the operational data includes at least one of
operating plan data and scheduling data.
4. The method of Claim 1, wherein the process parameters include at least one of a primal variable and a dual variable.
5. The method of Claim 1, wherein the process parameters include at least one of a
process variable and a process constraint.
6. The method of Claim 1, further comprising constructing a principal component
analysis (PCA) model that reduces dimensionality of the operational data of the dataset.
7. The method of Claim 1, wherein the extracting is based proportionally on at least one of (a) relative hyper-volumes of the grouped clusters, (b) relative numbers of the grouped process parameters of the grouped clusters, and (c) a uniform distribution between a plurality of the grouped clusters.
8. The method of Claim 1, wherein the applying a filter to the dataset includes filtering the dataset based on a hypervolume constructed around an origin of a projected space associated with the dataset.
9. The method of Claim 1, wherein at least one of:
the priority rating is based on information indicative of subject matter expertise, the information comprising at least one of (a) metadata and (b) embedded information;
the priority rating is determined based on domain knowledge; the measure of correlation is a measure of linear correlation of the remaining process parameters within the projected space; and
the measure of linear correlation increases as proximity between the remaining process parameters increases, and the measure of collinearity decreases as the grouped process parameters approach one or more edges of the cluster.
10. A computer system for industrial process control, the system comprising:
a processor operatively coupled to a data storage system, the processor configured to: receive in computer memory a dataset including initial process parameters representing operational data of a subject industrial process;
identify, using filtering operations and grouping operations on the dataset, a subset of the process parameters indicative of control data for controlling the subject industrial process, said using filtering operations and grouping operations including:
(i) applying a filter to the dataset that filters as a function of relative importance among the process parameters and that results in a filtered dataset having process parameters of threshold importance;
(ii) grouping into one or more clusters the process parameters of the filtered dataset based on correlation among the process parameters of the filtered dataset; and
(iii) for each cluster resulting from the grouping, extracting from the filtered dataset process parameters based on any one or combination of (a) a priority rating, (b) a measure of collinearity between the grouped process parameters within each given cluster of the determined clusters, (c) a measure of importance associated with the grouped process parameters, and (d) randomly or pseudorandomly; and
automatically apply the identified subset of process parameters controlling the subject industrial process.
11. The computer system of Claim 10, wherein the industrial process includes at least one of an optimized operational planning process, a scheduling process, a simulated chemical plant process, and an actual chemical plant process.
12. The computer system of Claim 10, wherein the operational data includes at least one of operating plan data and scheduling data.
13. The computer system of Claim 10, wherein the process parameters include at least one of a primal variable and a dual variable.
14. The computer system of Claim 10, wherein the process parameters include at least one of a process variable and a process constraint.
15. The computer system of Claim 10, wherein the processor is further configured to construct a principal component analysis (PCA) model that reduces dimensionality of the operational data of the dataset.
16. The computer system of Claim 10, wherein the processor is further configured to extract process parameters based proportionally on at least one of (a) relative hyper volumes of the grouped clusters, (b) relative numbers of the grouped process parameters of the grouped clusters, and (c) a uniform distribution between a plurality of the grouped clusters.
17. The computer system of Claim 10, wherein the processor is further configured to apply a filter to the dataset by filtering the dataset based on a hypervolume constructed around an origin of a projected space associated with the dataset.
18. The computer system of Claim 10, wherein at least one of:
the priority rating is based on information indicative of subject matter expertise, the information comprising at least one of (a) metadata and (b) embedded information;
the priority rating is determined based on domain knowledge; the measure of correlation is a measure of linear correlation of the remaining process parameters within the projected space; and
the measure of linear correlation increases as proximity between the remaining process parameters increases, and the measure of collinearity decreases as the grouped process parameters approach one or more edges of the cluster.
19. A non-transitory computer-readable data storage medium comprising instructions causing a computer to:
receive in computer memory a dataset including initial process parameters representing operational data of a subject industrial process; identify, using filtering operations and grouping operations on the dataset, a subset of the process parameters indicative of control data for controlling the subject industrial process, said using filtering operations and grouping operations including:
(i) applying a filter to the dataset that filters as a function of relative importance among the process parameters and that results in a filtered dataset having process parameters of threshold importance;
(ii) grouping into one or more clusters the process parameters of the filtered dataset based on correlation among the process parameters of the filtered dataset; and
(iii) for each cluster resulting from the grouping, extracting from the filtered dataset process parameters based on any one or combination of (a) a priority rating, (b) a measure of collinearity between the grouped process parameters within each given cluster of the determined clusters, (c) a measure of importance associated with the grouped process parameters, and (d) randomly or pseudo-randomly; and
automatically apply the identified subset of process parameters controlling the subject industrial process.
20. The non-transitory computer-readable data storage medium of Claim 19 wherein the instructions cause the computer to:
(i) construct a principal component analysis (PCA) model that reduces dimensionality of the operational data of the dataset;
(ii) extract process parameters based proportionally on at least one of (a) relative hyper-volumes of the grouped clusters, (b) relative numbers of the grouped process parameters of the grouped clusters, and (c) a uniform distribution between a plurality of the grouped clusters; and
(iii) apply a filter to the dataset by filtering the dataset based on a hypervolume constructed around an origin of a projected space associated with the dataset.
</claims>
</document>
