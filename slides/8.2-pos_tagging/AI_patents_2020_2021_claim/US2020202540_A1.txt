<document>

<filing_date>
2018-12-19
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2018-12-19
</priority_date>

<ipc_classes>
B60W30/09,G06K9/00,G06T7/246,G06T7/277,G06T7/73
</ipc_classes>

<assignee>
WANG ZIJIAN
ROMAN IVAN
LI DALONG
</assignee>

<inventors>
WANG ZIJIAN
ROMAN IVAN
LI DALONG
</inventors>

<docdb_family_id>
71097714
</docdb_family_id>

<title>
TECHNIQUES FOR USING A SIMPLE NEURAL NETWORK MODEL AND STANDARD CAMERA FOR IMAGE DETECTION IN AUTONOMOUS DRIVING
</title>

<abstract>
An advanced driver assistance system (ADAS) and corresponding method for a vehicle utilize a camera system configured to capture an image and a controller configured to receive the captured image, detect an object in the captured image using a simple neural network model, track the detected object using a tracking technique to obtain a tracked position, project a trajectory of the detected object using a trajectory projection technique to obtain a predicted position, determine a most likely position of the detected object based on at least one of the tracked and predicted positions, generate a two-dimensional (2D) birdview projection illustrating the detected object according to its determined most likely position, and control at least one ADAS feature of the vehicle using the generated 2D birdview projection.
</abstract>

<claims>
1. An advanced driver assistance system (ADAS) for a vehicle, the ADAS comprising: a camera system configured to capture an image; and a controller configured to: receive the captured image; detect an object in the captured image using a simple neural network model; track the detected object using a tracking technique to obtain a tracked position; project a trajectory of the detected object using a trajectory projection technique to obtain a predicted position; determine a most likely position of the detected object based on at least one of the tracked and predicted positions; generate a two-dimensional (2D) birdview projection illustrating the detected object according to its determined most likely position; and control at least one ADAS feature of the vehicle using the generated 2D birdview projection.
2. The ADAS of claim 1, wherein the simple neural network model is based on a TensorFlow single shot multi-box detector (SSD) algorithm.
3. The ADAS of claim 2, wherein the detected object is labeled and the simple neural network model is trained using vehicle-to-vehicle transfer learning.
4. The ADAS of claim 1, wherein the tracking technique is based on the Hungarian method and includes applying a deep-sort single hypothesis tracking methodology with recursive Kalman filtering and frame-by-frame data association.
5. The ADAS of claim 4, wherein the recursive Kalman filtering comprises a standard Kalman filter with constant velocity motion and a linear observation model
6. The ADAS of claim 1, wherein the trajectory projection technique comprises using the squared Mahalanobis distance between predicted Kalman states and newly-arrived measurements to build a matching cascade.
7. The ADAS of claim 6, wherein the building of the matching cascade as part of the trajectory projection technique overcomes at least one of object occlusion, hiding, and reformation.
8. The ADAS of claim 1, wherein the controller determines the most likely position of the detected object using a Softmax hub module that calculates a maximum likelihood position based on these tracked and predicted positions
9. The ADAS of claim 1, wherein the controller is configured to generate the 2D birdview projection by determining matrix and distortion parameters of the camera system using a calibration routine, finding a chessboard on a ground plane view for the vehicle and obtaining at least four points at sub-pixel accuracy, using the at least four points to compute a homography matrix for the ground plane view, and using a perspective function to obtain the 2D birdview projection of the ground plane view.
10. The ADAS of claim 1, wherein the at least one ADAS feature comprises collision avoidance during an autonomous driving mode of the vehicle.
11. A method of controlling at least one advanced driver assistance system (ADAS) feature of a vehicle, the method comprising: receiving, by a controller and from a camera system of the vehicle, a captured image; detecting, by the controller, an object in the captured image using a simple neural network model; tracking, by the controller, the detected object using a tracking technique to obtain a tracked position; projecting, by the controller, a trajectory of the detected object using a trajectory projection technique to obtain a predicted position; determining, by the controller, a most likely position of the detected object based on at least one of the tracked and predicted positions; generating, by the controller, a two-dimensional (2D) birdview projection illustrating the detected object according to its determined most likely position; and controlling, by the controller, the at least one ADAS feature of the vehicle using the generated 2D birdview projection.
12. The method of claim 11, wherein the simple neural network model is based on a TensorFlow single shot multi-box detector (SSD) algorithm.
13. The method of claim 12, further comprising labeling the detected object and training the simple neural network model using vehicle-to-vehicle transfer learning.
14. The method of claim 11, wherein the tracking technique is based on the Hungarian method and includes applying a deep-sort single hypothesis tracking methodology with recursive Kalman filtering and frame-by-frame data association.
15. The method of claim 14, wherein the recursive Kalman filtering comprises a standard Kalman filter with constant velocity motion and a linear observation model
16. The method of claim 11, wherein the trajectory projection technique comprises using the squared Mahalanobis distance between predicted Kalman states and newly-arrived measurements to build a matching cascade.
17. The method of claim 16, wherein the building of the matching cascade as part of the trajectory projection technique overcomes at least one of object occlusion, hiding, and reformation.
18. The method of claim 11, wherein the most likely position of the detected object is determined using a Softmax hub module that calculates a maximum likelihood position based on these tracked and predicted positions
19. The method of claim 11, wherein the 2D birdview projection is generated by determining matrix and distortion parameters of the camera system using a calibration routine, finding a chessboard on a ground plane view for the vehicle and obtaining at least four points at sub-pixel accuracy, using the at least four points to compute a homography matrix for the ground plane view, and using a perspective function to obtain the 2D birdview projection of the ground plane view.
20. The method of claim 11, wherein the at least one ADAS feature comprises collision avoidance during an autonomous driving mode of the vehicle.
</claims>
</document>
