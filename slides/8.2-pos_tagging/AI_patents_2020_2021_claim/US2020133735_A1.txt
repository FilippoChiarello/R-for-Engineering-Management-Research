<document>

<filing_date>
2019-05-17
</filing_date>

<publication_date>
2020-04-30
</publication_date>

<priority_date>
2018-10-31
</priority_date>

<ipc_classes>
G06F16/22,G06F16/245,G06F9/48,G06F9/50,G06N20/00
</ipc_classes>

<assignee>
EMC IP HOLDING COMPANY
</assignee>

<inventors>
LIU, JINPENG
WANG KUN
ZHAO JUNPING
</inventors>

<docdb_family_id>
70326738
</docdb_family_id>

<title>
METHOD, DEVICE, AND COMPUTER PROGRAM PRODUCT FOR ASSIGNING TASKS TO DEDICATED PROCESSING RESOURCES
</title>

<abstract>
A method comprises obtaining hardware information of a plurality of dedicated processing resources, wherein the plurality of dedicated processing resources comprises a first dedicated processing resource and a second dedicated processing resource, and the hardware information comprises first hardware information of the first dedicated processing resource and second hardware information of the second dedicated processing resource. The method further comprises generating a first task based on the first hardware information and a second task based on the second hardware information, and allocating the first task to the first dedicated processing resource and the second task to the second dedicated processing resource. For task scheduling in heterogeneous dedicated processing resources (for example, accelerator devices) scenario, the method generates corresponding kernel codes according to different hardware capabilities. Thus, dynamic optimization for the heterogeneous dedicated processing resources is implemented, thereby improving resource utilization rate and execution efficiency.
</abstract>

<claims>
1. A method of assigning tasks to dedicated processing resources, comprising: obtaining hardware information of a plurality of dedicated processing resources, the plurality of dedicated processing resources comprising a first dedicated processing resource and a second dedicated processing resource, and the hardware information comprising first hardware information of the first dedicated processing resource and second hardware information of the second dedicated processing resource; generating a first task based on the first hardware information and a second task based on the second hardware information; and allocating the first task to the first dedicated processing resource and the second task to the second dedicated processing resource.
2. The method according to claim 1, wherein the obtaining hardware information of a plurality of dedicated processing resources comprises: obtaining high-performance computing tasks; allocating the plurality of dedicated processing resources to the high-performance computing tasks; and obtaining hardware information of each of the plurality of dedicated processing resources in real time.
3. The method according to claim 1, wherein the obtaining hardware information of a plurality of dedicated processing resources comprises: querying hardware information of each of the plurality of dedicated processing resources periodically; storing the queried hardware information into a database, the hardware information comprising an identifier, a type, and a performance parameter of each dedicated processing resource; and obtaining, from the database, the hardware information of the plurality of dedicated processing resources.
4. The method according to claim 1, wherein the generating a first task based on the first hardware information and a second task based on the second hardware information comprises: determining a first compilation rule and a second compilation rule based on the first hardware information and the second hardware information respectively, the first hardware information indicating that the first dedicated processing resource enables a specific function, and the second hardware information indicating the second dedicated processing resource disables the specific function; and generating the first task and the second task using the first compilation rule and the second compilation rule respectively.
5. The method according to claim 4, wherein the generating a first task based on a first hardware information and a second task based on a second hardware information further comprises: associating the first task with a first identifier of the first dedicated processing resource; and associating the second task with a second identifier of the second dedicated processing resource, each identifier comprising an Internet Protocol (IP) address and a local identification of each dedicated processing resource.
6. The method according to claim 1, further comprising: receiving, from the first dedicated processing resource, a first result for the first task; receiving, from the second dedicated processing resource, a second result for the second task; and combining the first result and the second result.
7. The method according to claim 1, wherein the plurality of dedicated processing resources further comprises a third dedicated processing resource of the same type as the second dedicated processing resource, wherein the assigning the second task to the second dedicated processing resource comprises: allocating the second task to the second dedicated processing resource and the third dedicated processing resource.
8. The method according to claim 1, wherein the dedicated processing resources are graphics processing units (GPUs), and the first task and the second task are deep learning tasks, the method further comprising: performing the deep learning tasks on the first dedicated processing resource and the second dedicated processing resource respectively.
9. A device of assigning tasks to dedicated processing resources, comprising: a processing unit; and a memory coupled to the processing unit and storing instructions thereon, the instructions, when executed by the processing unit, executing the acts comprising: obtaining hardware information of a plurality of dedicated processing resources, the plurality of dedicated processing resources comprising a first dedicated processing resource and a second dedicated processing resource, and the hardware information comprising first hardware information of the first dedicated processing resource and second hardware information of the second dedicated processing resource; generating a first task based on the first hardware information and a second task based on the second hardware information; and allocating the first task to the first dedicated processing resource and the second task to the second dedicated processing resource.
10. The device according to claim 9, wherein the obtaining hardware information of a plurality of dedicated processing resources comprises: obtaining high-performance computing tasks; allocating the plurality of dedicated processing resources to the high-performance computing tasks; and obtaining hardware information of each of the plurality of dedicated processing resources in real time.
11. The device according to claim 9, wherein the obtaining hardware information of a plurality of dedicated processing resources comprises: querying hardware information of each of the plurality of dedicated processing resources periodically; storing the queried hardware information into a database, the hardware information comprising an identifier, a type, and a performance parameter of each dedicated processing resource; and obtaining, from the database, the hardware information of the plurality of dedicated processing resources.
12. The device according to claim 9, wherein the generating a first task based on the first hardware information and a second task based on the second hardware information comprises: determining a first compilation rule and a second compilation rule based on the first hardware information and the second hardware information respectively, the first hardware information indicating that the first dedicated processing resource enables a specific function, and the second hardware information indicating the second dedicated processing resource disables the specific function; and generating the first task and the second task using the first compilation rule and the second compilation rule respectively.
13. The device according to claim 12, wherein the generating a first task based on a first hardware information and a second task based on a second hardware information further comprises: associating the first task with a first identifier of the first dedicated processing resource; and associating the second task with a second identifier of the second dedicated processing resource, each identifier comprising an Internet Protocol (IP) address and a local identification of each dedicated processing resource.
14. The device according to claim 9, the acts further comprising: receiving, from the first dedicated processing resource, a first result for the first task; receiving, from the second dedicated processing resource, a second result for the second task; and combining the first result and the second result.
15. The device according to claim 9, wherein the plurality of dedicated processing resources further comprises a third dedicated processing resource of the same type as the second dedicated processing resource, wherein the assigning the second task to the second dedicated processing resource comprises: allocating the second task to the second dedicated processing resource and the third dedicated processing resource.
16. The device according to claim 9, wherein the dedicated processing resources are graphics processing units (GPUs), and the first task and the second task are deep learning tasks, the acts further comprising: performing the deep learning tasks on the first dedicated processing resource and the second dedicated processing resource respectively.
17. A computer program product that is tangibly stored on a non-transient computer readable medium and comprises computer-executable instructions, the computer-executable instructions, when executed, causing a computer to execute a method of assigning tasks to dedicated processing resources, comprising: obtaining hardware information of a plurality of dedicated processing resources, the plurality of dedicated processing resources comprising a first dedicated processing resource and a second dedicated processing resource, and the hardware information comprising first hardware information of the first dedicated processing resource and second hardware information of the second dedicated processing resource; generating a first task based on the first hardware information and a second task based on the second hardware information; and allocating the first task to the first dedicated processing resource and the second task to the second dedicated processing resource.
18. The computer program product according to claim 17, wherein the obtaining hardware information of a plurality of dedicated processing resources comprises: obtaining high-performance computing tasks; allocating the plurality of dedicated processing resources to the high-performance computing tasks; and obtaining hardware information of each of the plurality of dedicated processing resources in real time.
19. The computer program product according to claim 17, wherein the obtaining hardware information of a plurality of dedicated processing resources comprises: querying hardware information of each of the plurality of dedicated processing resources periodically; storing the queried hardware information into a database, the hardware information comprising an identifier, a type, and a performance parameter of each dedicated processing resource; and obtaining, from the database, the hardware information of the plurality of dedicated processing resources.
20. The computer program product according to claim 17, wherein the generating a first task based on the first hardware information and a second task based on the second hardware information comprises: determining a first compilation rule and a second compilation rule based on the first hardware information and the second hardware information respectively, the first hardware information indicating that the first dedicated processing resource enables a specific function, and the second hardware information indicating the second dedicated processing resource disables the specific function; and generating the first task and the second task using the first compilation rule and the second compilation rule respectively.
</claims>
</document>
