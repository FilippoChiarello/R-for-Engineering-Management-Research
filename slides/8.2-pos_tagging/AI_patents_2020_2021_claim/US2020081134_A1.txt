<document>

<filing_date>
2019-09-09
</filing_date>

<publication_date>
2020-03-12
</publication_date>

<priority_date>
2018-09-07
</priority_date>

<ipc_classes>
G01S19/39,G01S19/46,G01S19/47,G01S19/52,G05D1/02
</ipc_classes>

<assignee>
DEEPMAP
</assignee>

<inventors>
CHEN CHEN
COOMBE, GREGORY WILLIAM
ZENG, DI
WHEELER, MARK DAMON
ADACHI, JEFF
</inventors>

<docdb_family_id>
69720708
</docdb_family_id>

<title>
VALIDATION OF GLOBAL NAVIGATION SATELLITE SYSTEM LOCATION DATA WITH OTHER SENSOR DATA
</title>

<abstract>
A vehicle computing system validates location data received from a Global Navigation Satellite System receiver with other sensor data. In one embodiment, the system calculates velocities with the location data and the other sensor data. The system generates a probabilistic model for velocity with a velocity calculated with location data and variance associated with the location data. The system determines a confidence score by applying the probabilistic model to one or more of the velocities calculated with other sensor data. In another embodiment, the system implements a machine learning model that considers features extracted from the sensor data. The system generates a feature vector for the location data and determines a confidence score for the location data by applying the machine learning model to the feature vector. Based on the confidence score, the system can validate the location data. The validated location data is useful for navigation and map updates.
</abstract>

<claims>
1. A computer implemented method comprising: receiving location data from a Global Navigation Satellite System (GNSS) receiver located on an autonomous vehicle; receiving acceleration data from an inertial measurement unit (IMU) located on the autonomous vehicle; receiving image data of an environment surrounding the autonomous vehicle from a camera located on the autonomous vehicle; receiving light detection and ranging (LIDAR) data from a LIDAR located on the autonomous vehicle; generating a feature vector comprising features based on the location data, the acceleration data, the image data, and the LIDAR data; determining a confidence score for the location data for the vehicle by applying a trained machine learning model to the feature vector, wherein the trained machine learning model is trained on training data of past trips taken by one or more vehicles with sensor data associated with the past trips, and wherein the trained machine learning model receives as input, an input feature vector based on the location data, the acceleration data, the image data, and the LIDAR data, and outputs a confidence score for each set of global coordinates in the location data; validating the location data based on the confidence score; and navigating the autonomous vehicle according to the validated location data.
2. The computer implemented method of claim 1, wherein the location data comprises a first set of global coordinates determined at a first point in time, wherein the features include the first set of global coordinates at the first point in time.
3. The computer implemented method of claim 2, wherein the first set of global coordinates are calculated with a first satellite signal at a first radio frequency, a second satellite signal at a second radio frequency, and a third satellite signal at a third radio frequency, wherein the features include the first satellite signal, the first radio frequency, the second satellite signal, the second radio frequency, the third satellite signal, and the third radio frequency.
4. The computer implemented method of claim 2, wherein the location data further comprises a second set of global coordinates determined at a second point in time, wherein the features include the second set of global coordinates at the second point in time.
5. The computer implemented method of claim 1, further comprising: classifying a location type of the environment where the autonomous vehicle is located based on one or more of: the image data and LIDAR data, wherein the features include the location type of the environment.
6. The computer implemented method of claim 1, further comprising: receiving sound detection and ranging (SONAR) data from a SONAR located on the autonomous vehicle, wherein the features include the SONAR data, and wherein the machine learning model inputs the feature vector including the SONAR data.
7. The computer implemented method of claim 1, further comprising: receiving radio detection and ranging (RADAR) data from a RADAR located on the autonomous vehicle, wherein the features include the RADAR data, and wherein the machine learning model inputs the feature vector including the SONAR data.
8. The computer implemented method of claim 1, further comprising: receiving wheel odometry data from a wheel odometer located on a wheel of the autonomous vehicle, wherein the features include the wheel odometry data, and wherein the machine learning model inputs the feature vector including the SONAR data.
9. A computer implemented method comprising: receiving location data including a first set of global coordinates for the autonomous vehicle at a first point in time and a second set of global coordinates for the autonomous vehicle at a second point in time from a Global Navigation Satellite System (GNSS) receiver located on an autonomous vehicle, the first set of global coordinates determined by a plurality of satellite signals and associated with a variance of the plurality of satellite signals; determining a first velocity of the autonomous vehicle at the first time point based on the first set of global coordinates and the second set of global coordinates; generating a probabilistic model of velocity at the first point in time based on the first velocity and the variance, wherein the probabilistic model inputs a velocity at the first time point and outputs a confidence score; receiving additional sensor data including one or more of: acceleration data, image data of an environment surrounding the autonomous vehicle, light detection and ranging (LIDAR) data, radar detection and ranging (RADAR) data, sound detection and ranging (SONAR) data, and wheel odometry data; determining a second velocity of the autonomous vehicle at the first time point based on the additional sensor data; calculating a confidence score for the second velocity by applying the probabilistic model to the second velocity; validating the location data based on the confidence score; and navigating the autonomous vehicle using the validated location data.
10. The computer implemented method of claim 9, wherein the first velocity is calculated by: measuring a Euclidean distance between the first set of global coordinates and the second set of global coordinates; and dividing the distance by a time differential between the first point in time and the second point in time.
11. The computer implemented method of claim 9, wherein the plurality of satellite signals includes a first satellite signal received at a first radio frequency, wherein the first velocity is calculated by measuring a Doppler shift of the first satellite signal based on the first radio frequency.
12. The computer implemented method of claim 9, wherein the second velocity is determined based on integrating the acceleration data.
13. The computer implemented method of claim 9, further comprising applying a Kalman filter to the acceleration data to remove IMU bias in the acceleration data.
14. The computer implemented method of claim 9, wherein the second velocity is determined by applying a trained machine learning model to the image data of the environment, wherein the trained machine learning model is trained with training data comprising video captured by a camera moving at a known velocity, wherein image data is input into the machine learning model and a predicted velocity is output according to the input image data.
15. The computer implemented method of claim 9, wherein the second velocity is determined by applying a trained machine learning model to the LIDAR data, wherein the trained machine learning model is trained with training data comprising LIDAR scans captured by a LIDAR moving at a known velocity, wherein LIDAR data is input into the machine learning model and a predicted velocity is output according to the input LIDAR data.
16. The computer implemented method of claim 9, wherein the second velocity is determined by applying a trained machine learning model to the RADAR data, wherein the trained machine learning model is trained with training data comprising RADAR scans captured by a RADAR moving at a known velocity, wherein RADAR data is input into the machine learning model and a predicted velocity is output according to the input RADAR data.
17. The computer-implemented method of claim 9, wherein the second velocity is determined by applying a trained machine learning model to the SONAR data, wherein the trained machine learning model is trained with training data comprising SONAR scans captured by a SONAR moving at a known velocity, wherein SONAR data is input into the machine learning model and a predicted velocity is output according to the input SONAR data
18. The computer implemented method of claim 9, further comprising: determining a second velocity of the autonomous vehicle at the first time point based on the additional sensor data; and calculating a second confidence score for the third velocity by applying the probabilistic model to the third velocity, wherein validating the location data is further based on the second confidence score.
19. The computer implemented method of claim 9, further comprising: in response to validating the location data, determining a difference between high-definition (HD) map data and the additional sensor data; and updating the HD map data with the additional sensor data.
20. A computer implemented method comprising: receiving location data including a first set of global coordinates for an autonomous vehicle at a first point in time and a second set of global coordinates for the autonomous vehicle at a second point in time from a Global Navigation Satellite System (GNSS) receiver located on the autonomous vehicle, the first set of global coordinates is determined by a plurality of satellite signals and is associated with a variance of the plurality of satellite signals; determining a first velocity of the autonomous vehicle at the first point in time based on the first set of global coordinates and the second set of global coordinates; generating a probabilistic model of velocity at the first time point based on the first velocity and the variance, wherein the probabilistic model inputs a velocity at the first time point and outputs a confidence score; receiving image data of an environment surrounding the autonomous vehicle from a camera located on the vehicle; determining a second velocity of the autonomous vehicle at the first time point by: identifying a plurality of features in a first frame of the image data, identifying the plurality of features in a second frame of the image data, establishing an image correspondence between the first frame and the second frame based on identification of the plurality of features in the first frame and the identification of the plurality of features in the second frame, and calculating the second velocity based on a comparison of the plurality of features in the first frame and the plurality of features in the second frame; calculating a confidence score for the second velocity by applying the probabilistic model to the second velocity; validating the location data based on the confidence score; and navigating the autonomous vehicle according to the validated location data.
21. The computer implemented method of claim 20, wherein the first velocity is calculated by: measuring a Euclidean distance between the first set of global coordinates and the second set of global coordinates; and dividing the distance by a time differential between the first point in time and the second point in time.
22. The computer implemented method of claim 20, wherein the first set of global coordinates is determined by the GNSS receiver receiving at least a first satellite signal from a first satellite at a first radio frequency, wherein the first velocity is calculated by measuring a Doppler shift of the first satellite signal based on the first radio frequency.
23. The computer implemented method of claim 20, wherein the plurality of satellite signals includes a first satellite signal from a first satellite, a second satellite signal from a second satellite, and a third satellite signal, wherein a HD map of an environment where the vehicle is located comprises occupancy grid data describing spatial position of a road, and wherein the first set of global coordinates is determined by calculating trilateration of the first satellite signal, the second satellite signal, and the third satellite signal on the road.
24. The computer implemented method of claim 20, wherein calculating the second velocity based on the comparison of the plurality of features in the first frame and the plurality of features in the second frame comprises: calculating an optical flow by determining a difference in position of each feature of the plurality of features between the first frame and the second frame, wherein the optical flow describes a relative velocity of each pixel in the image data between the first frame and the second frame; calculating a displacement of the camera from the first point in time to the second point in time based on the optical flow; and calculating the second velocity by dividing the displacement of the camera from the first point in time to the second point in time over a time differential of the first point in time and the second point in time.
25. The computer implemented method of claim 20, wherein identifying the first feature at the first position in the first frame of the image data comprises applying one or more image kernels to the first frame; and wherein identifying the first feature at a second position in a second frame of the image data comprises applying the one or more image kernels to the second frame.
26. A computer implemented method comprising: receiving location data including a plurality of sets of global coordinates for an autonomous vehicle at a plurality of points in time from a Global Navigation Satellite System (GNSS) receiver located on the autonomous vehicle, each global coordinate determined by a plurality of satellite signals and associated with a variance of the plurality of satellite signals; receiving sensor data including one or more of: acceleration data, image data of an environment surrounding the autonomous vehicle, light detection and ranging (LIDAR) data, radar detection and ranging (RADAR) data, sound detection and ranging (SONAR) data, and wheel odometry data; generating a high-definition (HD) map with the location data and the sensor data, the HD map comprising occupancy grid data describing spatial positions of one or more objects; generating an uncertainty map parallel to the HD map, the uncertainty map storing the variance of each set of global coordinates over a spatial volume; receiving new sensor data including one or more of: new acceleration data, new image data of a new environment surrounding the autonomous vehicle, new light detection and ranging (LIDAR) data, new radar detection and ranging (RADAR) data, new sound detection and ranging (SONAR) data, and new wheel odometry data; determining a location of the autonomous vehicle in the HD map according to the new sensor data; retrieving a variance for the location of the autonomous vehicle from the uncertainty map; receiving new location data including a first set of global coordinates for the autonomous vehicle from the GNSS receiver; validating the first set of global coordinates according to the retrieved variance; and navigating the autonomous vehicle with the validated first set of global coordinates.
</claims>
</document>
