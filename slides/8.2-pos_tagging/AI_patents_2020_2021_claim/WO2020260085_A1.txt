<document>

<filing_date>
2020-06-17
</filing_date>

<publication_date>
2020-12-30
</publication_date>

<priority_date>
2019-06-28
</priority_date>

<ipc_classes>
G02B27/01,G06F3/01,G06F3/0484
</ipc_classes>

<assignee>
SONY CORPORATION
SONY EUROPE
</assignee>

<inventors>
TORFS, DIMITRI
SERBANATI, Alexandru
MEYVIS, Francis
SAELENS, Pierre
</inventors>

<docdb_family_id>
67137560
</docdb_family_id>

<title>
METHOD, COMPUTER PROGRAM AND HEAD-MOUNTED DEVICE FOR TRIGGERING AN ACTION, METHOD AND COMPUTER PROGRAM FOR A COMPUTING DEVICE AND COMPUTING DEVICE
</title>

<abstract>
Examples relate to a method and a head-mounted device for triggering an action with relation to a selected object in a field of view of a user, to a computing device and a method for a computing device, a system comprising the computing device and the head-mounted device, and to corresponding computer programs. The method for triggering an action with relation to a selected object in a field of view of a user comprises detecting a pre-defined brain activity pattern of the user using a brain activity sensor of a head-mounted device worn by the user. The pre-defined brain activity pattern expresses a user command to select an object on which a gaze of the user is focused. The method comprises determining a direction of the gaze of the user at a time of the detection of the pre-defined brain activity pattern. The method comprises capturing an image of the field of view of the user at the time of the detection of the pre-defined brain activity pattern. The method comprises providing at least a part of the image to a computing entity, to cause the computing entity to trigger the action with relation to the selected object.
</abstract>

<claims>
What is claimed is:
1. A method for triggering an action with relation to a selected object in a field of view of a user, the method comprising:
Detecting a pre-defmed brain activity pattern of the user using a brain activity sensor of a head-mounted device worn by the user, the pre-defmed brain activity pattern ex pressing a user command to select an object on which a gaze of the user is focused;
Determining a direction of the gaze of the user at a time of the detection of the predefmed brain activity pattern;
Capturing an image of the field of view of the user at the time of the detection of the pre-defmed brain activity pattern; and
Providing at least a part of the image to a computing entity, to cause the computing entity to trigger the action with relation to the selected object.
2. The method according to claim 1, comprising selecting the object by determining the object on which the gaze of the user is focused in the captured image based on the direction of the gaze of the user.
3. The method according to claim 1, further comprising cropping the image based on the direction of the gaze of the user, and providing the cropped image to the compu ting entity.
4. The method according to claim 1, wherein the image is provided to the computing entity with information on the direction of the gaze of the user.
5. The method according to claim 1, wherein the pre-defmed activity pattern is detected using a processor of the head-mounted device, and/or wherein the direction of the gaze is determined using a processor of the head-mounted device.
6. The method according to claim 1, wherein the computing entity is either a) a
backend server, the image being transmitted to the backend server via the internet, or b) a mobile device, the image being transmitted to the mobile device via a wireless connection.
7. The method according to claim 1, wherein the direction of the gaze is determined us ing either a) at least one inward-oriented visual or infrared sensor of the headmounted device or b) by measuring the electro-magnetic field generated by the con traction of the muscles of the eye.
8. The method according to claim 1, wherein the image is captured using at least one outward-oriented visual sensor of the head-mounted device,
9. The method according to claim 8, wherein the image comprises a wide-angle field of view, the at least one outward-oriented visual sensor being equipped with a wide-an gle lens,
and/or wherein the image comprises a close-angle field of view, the at least one outward-oriented visual sensor being equipped with a telephoto lens.
10. The method according to claim 1, further comprising receiving information on the selected object from the computing entity, and displaying the information on the se lected object using a visual display of the head-mounted device.
11. The method according to claim 1, wherein the method further comprises capturing a context of the user, the action to be triggered being based on the context of the user, or wherein the action to be triggered is determined by the user before or after the de tection of the pre-defmed brain activity pattern,
or wherein the action to be triggered depends on the selected object.
12. The method according to claim 1, wherein the action to be triggered is the headmounted display displaying information on the selected object using a visual display of the head-mounted device,
or wherein the action to be triggered is a selection of an element of a graphical user interface, the element being the selected object.
13. The method according to claim 1, wherein the pre-defmed brain activity pattern is a user-specific brain activity pattern, the method comprising recording the pre-defmed brain activity pattern using the brain activity sensor of the head-mounted device.
14. The method according to claim 1, wherein the pre-defmed brain activity pattern is a non-user-specific brain activity pattern, the method comprising providing a user training to train the user to produce the pre-defmed brain activity pattern.
15. A head-mounted device for triggering an action with relation to a selected object in a field of view of a user, the head-mounted device comprising: a brain activity sensor for detecting brain activity patterns of a user wearing the headmounted device;
at least one sensor for determining a direction of a gaze of the user;
at least one outward-oriented visual sensor for capturing an image of a field of view of the user;
an interface for communicating with a computing entity; and
a processor configured to:
Detect a pre-defmed brain activity pattern of the user using the brain activity sensor, the pre-defmed brain activity pattern expressing a user command to select an object on which a gaze of the user is focused,
Determine a direction of the gaze of the user at a time of the detection of the predefmed brain activity pattern,
Capture an image of a field of view of the user at the time of the detection of the predefmed brain activity pattern, and
Provide at least a part of the image to a computing entity, to cause the computing entity to trigger the action with relation to the selected object.
16. A method for a computing device, the method comprising:
Receiving an image from a head-mounted device, the image being based on a direction of a gaze of a user at a time of a detection of a pre-defmed brain activity pattern of a user wearing the head-mounted device, the pre-defmed brain activity pattern express ing a user command to select an object on which a gaze of the user is focused;
Determining information on the selected object within the image; and
Triggering the action with relation to the selected object based on the information on the selected object.
17. The method according to claim 16, wherein the action to be triggered is the headmounted display displaying the information on the selected object using a visual dis play of the head-mounted device, the method comprising providing the information on the selected object to the head-mounted device,
or wherein the action to be triggered is a selection of an element of a graphical user interface, the element being the selected object, the triggering of the action compris ing providing a control signal to the graphical user interface, to cause the graphical user interface to select the element.
18. A computing device comprising: an interface for communicating with a head-mounted device; and a processor configured to:
Receive an image from the head-mounted device via the interface, the image being based on a direction of a gaze of a user at a time of a detection of a pre-defmed brain activity pattern of a user wearing the head-mounted device, the pre-defmed brain ac tivity pattern expressing a user command to select an object on which a gaze of the user is focused,
Determine information on the selected object within the image,
Trigger the action with relation to the selected object based on the information on the selected object.
19. A computer program having a program code for performing the method according to claim 1, when the computer program is executed on a computer, a processor, or a programmable hardware component.
20. A computer program having a program code for performing the method according to claim 16, when the computer program is executed on a computer, a processor, or a programmable hardware component.
</claims>
</document>
