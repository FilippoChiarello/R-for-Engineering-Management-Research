<document>

<filing_date>
2019-03-25
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-25
</priority_date>

<ipc_classes>
G06F3/0484,G06F9/30,G06K9/00,G06T19/00
</ipc_classes>

<assignee>
VERIZON PATENT AND LICENSING
</assignee>

<inventors>
MANCUSO, STEVEN
RUTLEDGE, CHRISTOPHER LEE
VEMURI, BHARADWAJ
Corniel, Kelvin
Terlizzi, Pamela
</inventors>

<docdb_family_id>
72605875
</docdb_family_id>

<title>
Proximity-Based Content Sharing as an Augmentation for Imagery Captured by a Camera of a Device
</title>

<abstract>
An exemplary augmentation system accesses imagery captured by a sensor of a first device, identifies a user depicted in the imagery, determines that the user is associated with a second device, determines that the second device is located within a predefined proximity range of the first device, accesses, based on the user being depicted in the imagery and the second device being located within the predefined proximity range of the first device, shared content associated with the identified user, and provides the shared content for display as an augmentation for the imagery captured by the sensor of the first device. Corresponding methods and systems are also disclosed.
</abstract>

<claims>
1. A method comprising: accessing, by an augmentation system, imagery captured by a sensor of a first device; identifying, by the augmentation system, a user depicted in the imagery; determining, by the augmentation system, that the user is associated with a second device; determining, by the augmentation system, that the second device is located within a predefined proximity range of the first device; providing, by the augmentation system based on the user being depicted in the imagery and the second device being located within the predefined proximity range of the first device, shared content associated with the identified user for display as an augmentation for the imagery captured by the sensor of the first device.
2. The method of claim 1, wherein the determining that the second device is located within the predefined proximity range of the first device comprises: determining, by the augmentation system and based on data from a location data store, a location of the first device and a location of the second device; and determining, by the augmentation system, that a distance between the location of the first device and the location of the second device is within the predefined proximity range.
3. The method of claim 1, wherein the determining that the second device is located within the predefined proximity range of the first device comprises: determining, by the augmentation system and based on depth data associated with the imagery, a distance between the first device and the second device; and determining, by the augmentation system, that the distance is within the predefined proximity range of the first device.
4. The method of claim 1, wherein the shared content associated with the identified user is provided by the identified user and stored in a data store prior to the second device being located within the predefined proximity range of the first device.
5. The method of claim 1, further comprising accessing, by the augmentation system, the shared content associated with the identified user, wherein the accessing of the shared content associated with the identified user comprises receiving, via the augmentation system, the shared content associated with the identified user from the second device.
6. The method of claim 1, wherein the shared content indicates a status of the identified user based on a state of use of an application installed on the second device.
7. The method of claim 1, wherein the providing, by the augmentation system, of the shared content associated with the identified user for display is performed in response to determining that a user associated with the first device is authorized to receive the shared content associated with the identified user.
8. The method of claim 1, further comprising: determining, by the augmentation system, that the first device is located within a particular geographic location; and generating, by the augmentation system and based on the imagery captured by the camera of the first device and on the first device being located within the particular geographic location, an augmented environment view for display by the first device, the augmented environment view including a plurality of markers representing current locations of users of the augmentation system within the particular geographic location.
9. The method of claim 1, further comprising: providing, by the augmentation system, in response to detecting a user interaction with the displayed augmentation, a feature, on the first device, configured to facilitate a communication between a user of the first device and the user of second device.
10. A system comprising: at least one memory storing instructions; and at least one processor communicatively coupled to the at least one memory and configured to execute the instructions to: access imagery captured by a camera of a first device; identify a user depicted in the imagery; determine that the user is associated with a second device; determine that the second device is located within a predefined proximity range of the first device; and provide, based on the user being depicted in the imagery and the second device being located within the predefined proximity range of the first device, shared content associated with the identified user for display as an augmentation for the imagery captured by the camera of the first device.
11. The system of claim 10, wherein the determining that the second device is located within the predefined proximity range of the first device comprises: determining, based on data from a location data store, a location of the first device and a location of the second device; and determining that a distance between the location of the first device and the location of the second device is within the predefined proximity range.
12. The system of claim 10, wherein the determining that the second device is located within the predefined proximity range of the first device comprises: determining, based on depth data associated with the imagery, a distance between the first device and the second device; and determining that the distance is within the predefined proximity range of the first device.
13. The system of claim 10, wherein the shared content associated with the identified user is provided by the identified user and stored in a data store prior to the second device being located within the predefined proximity range of the first device.
14. The system of claim 10, wherein: the at least one processor is further configured to execute the instructions to access the shared content associated with the identified user; and the accessing of the shared content associated with the identified user comprises requesting and receiving the shared content associated with the identified user from the second device.
15. The system of claim 10, wherein the shared content indicates a status of the identified user based on a state of use of an application installed on the second device.
16. The system of claim 10, wherein the at least one processor is further configured to execute the instructions to determine whether a user associated with the first device is authorized to receive the shared content associated with the identified user.
17. The system of claim 10, wherein the at least one processor is further configured to execute the instructions to: access second imagery captured by a second camera of the first device; identify a user of the first device as being depicted in the second imagery; access, based on the user of the first device being depicted in the second imagery, shared content associated with the user of the first device; and provide the shared content associated with the user of the first device for display as an augmentation for the second imagery captured by the second camera of the first device.
18. The system of claim 10, wherein the at least one processor is further configured to execute the instructions to: detect a user interaction with the displayed augmentation; and provide, in response to the detecting of the user interaction with the displayed augmentation, a feature configured to facilitate an interaction between the user depicted in the imagery captured by the camera of the first device and a user of the first device.
19. A non-transitory computer-readable medium storing instructions that, when executed, direct at least one processor of a computing device to: access imagery captured by a camera of a first device; identify a user depicted in the imagery; determine that the user is associated with a second device; determine that the second device is within a predefined proximity range of the first device; and provide, based on the user being depicted in the imagery and the second device being within the predefined proximity range of the first device, shared content associated with the identified user for display as an augmentation for the imagery captured by the camera of the first device.
20. The computer-readable medium of claim 19, wherein the instructions, when executed, further direct the at least one processor of the computing device to: detect a user interaction with the displayed augmentation; and provide, in response to the detecting of the user interaction with the displayed augmentation, a feature configured to facilitate an interaction between the user depicted in the imagery captured by the camera of the first device and a user of the first device.
</claims>
</document>
