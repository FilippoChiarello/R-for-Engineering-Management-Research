<document>

<filing_date>
2017-11-16
</filing_date>

<publication_date>
2020-10-15
</publication_date>

<priority_date>
2017-11-16
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
KAIST (KOREA ADVANCED INSTITUTE OF SCIENCE AND TECHNOLOGY)
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
KIM, KYUNG-SU
KIM, SUNG JIN
KWEON, IN SO
CHO, Donghyeon
KIM, Dahun
</inventors>

<docdb_family_id>
66539061
</docdb_family_id>

<title>
METHOD AND DEVICE FOR HIERARCHICAL LEARNING OF NEURAL NETWORK, BASED ON WEAKLY SUPERVISED LEARNING
</title>

<abstract>
The present disclosure relates to an artificial intelligence (AI) system for simulating functions of the human brain, such as cognition and determination, by using a machine learning algorithm, such as deep learning, and to an application of the AI system. Particularly, the present disclosure relates to a method for hierarchical learning of a neural network according to an AI system and an application thereof, whereby a first activation map may be generated by applying a source learning image to a first learning network model configured to generate semantic segmentation, a second activation map may be generated by applying the source learning image to a second learning network model configured to generate semantic segmentation, a loss may be calculated from labeled data of the source learning image based on the first activation map and the second activation map, and a weight for a plurality of network nodes constituting the first learning network model and the second learning network model may be updated based on the loss.
</abstract>

<claims>
1. A method for hierarchical learning of a neural network, the method comprising: generating a first activation map by applying a source learning image to a first learning network model configured to learn semantic segmentation; generating a second activation map by applying the source learning image to a second learning network model configured to learn semantic segmentation; calculating a loss from labeled data of the source learning image based on the first activation map and the second activation map; and updating, based on the loss, a weight for a plurality of network nodes constituting the first learning network model and the second learning network model.
2. The method of claim 1, wherein the second learning network model is configured to learn a remaining region from the source learning image excluding an image region inferred from the first learning network model.
3. The method of claim 1, wherein the updating of the weight for the plurality of network nodes is performed when the loss is less than a predetermined threshold, and the method further comprises applying the source learning image to a third learning network model configured to perform semantic segmentation when the loss is not less than the predetermined threshold.
4. The method of claim 1, wherein the labeled data comprises an image-level annotation for the source learning image.
5. The method of claim 1, wherein the semantic segmentation corresponds to a result obtained by estimating, in pixel units, objects in the source learning image.
6. The method of claim 1, further comprising generating semantic segmentation for the source learning image by combining the first activation map and the second activation map.
7. The method of claim 1, wherein the first learning network model and the second learning network model each comprise a fully convolutional network (FCN).
8. A device for hierarchical learning of a neural network, the device comprising: a memory storing one or more instructions; and at least one processor configured to execute the one or more instructions stored in the memory to generate a first activation map by applying a source learning image to a first learning network model configured to learn semantic segmentation, generate a second activation map by applying the source learning image to a second learning network model configured to learn semantic segmentation, calculate a loss from labeled data of the source learning image based on the first activation map and the second activation map, and update, based on the loss, a weight for a plurality of network nodes constituting the first learning network model and the second learning network model.
9. The device of claim 8, wherein the second learning network model is configured to learn a remaining region from the source learning image excluding an image region inferred from the first learning network model.
10. The device of claim 8, wherein the update of the weight for the plurality of network nodes is performed when the loss is less than a predetermined threshold, and the at least one processor is further configured to apply the source learning image to a third learning network model configured to perform semantic segmentation when the loss is not less than the predetermined threshold.
11. The device of claim 8, wherein the labeled data comprises an image-level annotation for the source learning image.
12. The device of claim 8, wherein the semantic segmentation corresponds to a result obtained by estimating, in pixel units, objects in the source learning image.
13. The device of claim 8, wherein the at least one processor is further configured to generate semantic segmentation for the source learning image by combining the first activation map and the second activation map.
14. The device of claim 8, wherein the first learning network model and the second learning network model each comprise a fully convolutional network (FCN).
15. A computer-readable recording medium having recorded thereon a program configured to execute, in a computer, the method of claim 1.
</claims>
</document>
