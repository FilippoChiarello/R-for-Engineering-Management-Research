<document>

<filing_date>
2018-08-10
</filing_date>

<publication_date>
2021-01-19
</publication_date>

<priority_date>
2017-08-10
</priority_date>

<ipc_classes>
G06F16/61,G06F3/16,G10L13/033,G10L13/047,G10L13/08,G10L15/05,G10L15/18,G10L15/22,G10L15/30,H04L12/58
</ipc_classes>

<assignee>
FACET LABS
</assignee>

<inventors>
OGAWA, STUART
SO, WILFRED P.
NISHIMURA, KOICHI
Sparks, Lindsay Alexander
</inventors>

<docdb_family_id>
65271267
</docdb_family_id>

<title>
Oral communication device and computing systems for processing data and outputting oral feedback, and related methods
</title>

<abstract>
Typical graphical user interfaces and predefined data fields limit the interaction between a person and a computing system. An oral communication device and a data enablement platform are provided for ingesting oral conversational data from people, and using machine learning to provide intelligence. At the front end, an oral conversational bot, or chatbot, interacts with a user. On the backend, the data enablement platform has a computing architecture that ingests data from various external data sources as well as data from internal applications and databases. These data and algorithms are applied to surface new data, identify trends, provide recommendations, infer new understanding, predict actions and events, and automatically act on this computed information. The chatbot then provides audio data that reflects the information computed by the data enablement platform. The system and the devices, for example, are adaptable to various industries.
</abstract>

<claims>
1. A speech computing device comprising a housing that holds at least: a memory device that stores thereon at least a data enablement application that comprises multiple modules that correspond to different modes, a conversational bot and one or more synthesized voice libraries, wherein each of the one or more synthesized voice libraries comprise voice parameter features of one or more corresponding people; an input sensor that is configured to record a user's input as speech data; a processor configured to use the conversational bot to identify contextual data associated with the speech data, the contextual data including a current mode corresponding to a currently activated module of the data enablement application; a data communication device configured to transmit the audio data and the contextual data via a data network and, in response, receive response data, wherein the response data comprises an indication of a given synthesized voice library, text data, and the current mode; the processor further configured to use the conversational bot to generate an audio response from the given synthesized voice library and the text data, and to propagate the text data to one or more other modules that are currently inactive; and an audio speaker that is controlled by the processor to output the audio response.
2. The computing device of claim 1 wherein the currently activated module is a meeting notes module; the speech data comprises a topic; and the text data comprises data in relation to the topic.
3. The computing device of claim 2 wherein the computing device detects at least one of a pause or an end of a sentence in the speech data and then outputs the audio response.
4. The computing device of claim 2 wherein the speech data and the text data is added to a meeting notes file.
5. The computing device of claim 2 wherein the data communication device is communication with at least one other user device, and the computing device further transmits additional data about the topic to the other user device within a same given time period as outputting the audio response.
6. The computing device of claim 2 wherein the input sensor obtains public speech data, the computing device further receives private meeting notes, and the computing device further generates meeting notes that comprise the privates meeting notes and public notes derived from the public speech data and the text data in the response data.
7. The computing device of claim 6 wherein the private notes and the public notes are organized by time of creation.
8. The computing device of claim 6 wherein the data communication device is in communication with at least a silent communication device to obtain private speech data; and the computing device further generates the private meeting notes from the private speech data.
9. The computing device of claim 1 further comprising a visual display device, and the response data further includes visual data that is outputted with the audio response.
10. The computing device of claim 9 wherein the visual display device is a projector.
11. The computing device of claim 1 wherein the speech data comprises a topic; and the text data comprises a summarization of multiple news articles in relation to the topic.
12. The computing device of claim 1 wherein the currently activated module is an introductions module associated with a social network platform of the user; the speech data comprises a topic or an entity; and the text data comprises a list of names obtained from the social network platform that are related to the topic or the entity.
13. The computing device of claim 1 wherein the multiple modules comprise a to-do list module, an opportunities module, an introductions module, a meeting notes module and a new module; and wherein the currently activated of the multiple modules propagates the text data to at least two or more of the other ones of the multiple modules.
14. The computing device of claim 1 wherein the memory device further stores conversation libraries that include one or more parameters that are used by the conversational bot to affect the audio response; and the parameters comprise one or more of: tone; frequency; loudness; rate at which a word or phrase is said; phonetic pronunciation; lexicon; syntax; articulation; rhythm; melody; phrases; and questions.
15. The computing device of claim 1 wherein the speech data comprises a topic; and the indication of the given synthesized voice library is associated with a person that is an authority or an expert of the topic.
16. The computing device of claim 1 wherein the speech data comprises a topic and a name of a person; the indication of the given synthesized voice library is associated with the person; and the text data is in relation to both the topic and the person.
17. The computing device of claim 1 further comprising a graphics processing unit (GPU) that exchanges data with the processor, the GPU configured to pre-process the audio data using parallel threaded computations to extract data features, and the data communication device transmits the extracted data features in association with the contextual data and the audio data.
</claims>
</document>
