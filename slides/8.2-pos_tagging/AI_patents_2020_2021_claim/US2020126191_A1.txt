<document>

<filing_date>
2019-12-17
</filing_date>

<publication_date>
2020-04-23
</publication_date>

<priority_date>
2017-07-27
</priority_date>

<ipc_classes>
G06T5/00,G06T7/246,G06T7/50
</ipc_classes>

<assignee>
NVIDIA CORPORATION
</assignee>

<inventors>
MUNKBERG, CARL JACOB
LEFOHN, AARON ELIOT
SALVI, MARCO
PATNEY, ANJUL
HASSELGREN, JON NIKLAS THEODOR
BRITTAIN, DONALD LEE
</inventors>

<docdb_family_id>
70280992
</docdb_family_id>

<title>
NEURAL NETWORK SYSTEM WITH TEMPORAL FEEDBACK FOR ADAPTIVE SAMPLING AND DENOISING OF RENDERED SEQUENCES
</title>

<abstract>
A neural network-based rendering technique increases temporal stability and image fidelity of low sample count path tracing by optimizing a distribution of samples for rendering each image in a sequence. A sample predictor neural network learns spatio-temporal sampling strategies such as placing more samples in dis-occluded regions and tracking specular highlights. Temporal feedback enables a denoiser neural network to boost the effective input sample count and increases temporal stability. The initial uniform sampling step typically present in adaptive sampling algorithms is not needed. The sample predictor and denoiser operate at interactive rates to achieve significantly improved image quality and temporal stability compared with conventional adaptive sampling techniques.
</abstract>

<claims>
1. A computer-implemented method, comprising: receiving guide data for a rendered image frame in a sequence of rendered image frames, the sequence including a previous rendered image frame and the rendered image frame; receiving external state including a reconstructed previous rendered image frame with fewer artifacts compared with the previous rendered image frame, wherein the external state is warped, using difference data corresponding to changes between the previous rendered image frame and the rendered image frame, to produce warped external state; and processing the guide data for the rendered image frame using layers of a neural network model to produce a sample map that indicates a number of samples to be computed for each pixel in the rendered image frame, wherein the warped external state is input to one or more of the layers of the neural network.
2. The computer-implemented method of claim 1, further comprising rendering the rendered image frame according to the sample map.
3. The computer-implemented method of claim 2, wherein the rendered image frame includes artifacts including at least a loss of high-frequency detail or residual noise.
4. The computer-implemented method of claim 1, further comprising processing the guide data for the previous rendered image frame using layers of the neural network model to produce a first sample map that indicates a number of samples to be computed for each pixel in the previous rendered image frame, wherein an initial warped external state is input to one or more of the layers of the neural network.
5. The computer-implemented method of claim 1, further comprising processing the previous rendered image frame using layers of a reconstruction neural network model to produce the external state.
6. The computer-implemented method of claim 1, further comprising processing the rendered image frame using layers of a reconstruction neural network model to produce second external state including a reconstructed rendered image frame with fewer artifacts compared with the rendered image frame.
7. The computer-implemented method of claim 6, wherein processing the rendered image frame to produce the reconstructed data frame is based on the warped external state.
8. The computer-implemented method of claim 6, wherein processing the rendered image frame to produce the reconstructed image frame is based on the guide data for the rendered image frame.
9. The computer-implemented method of claim 6, further comprising adjusting parameters of the neural network model and the reconstruction neural network model based on differences between the reconstructed image frame and the rendered image frame without artifacts.
10. The computer-implemented method of claim 1, wherein the guide data comprises normal vectors, depth, or albedo.
11. The computer-implemented method of claim 1, wherein the difference data is motion vectors.
12. A system, comprising: a processing unit configured as a neural network model to: receive guide data for a rendered image frame in a sequence of rendered image frames, the sequence including a previous rendered image frame and the rendered image frame; receive external state including a reconstructed previous rendered image frame with fewer artifacts compared with the previous rendered image frame, wherein the external state is warped, using difference data corresponding to changes between the previous rendered image frame and the rendered image frame, to produce warped external state; and process the guide data for the rendered image frame using layers of the neural network model to produce a sample map that indicates a number of samples to be computed for each pixel in the rendered image frame, wherein the warped external state is input to one or more of the layers of the neural network.
13. The system of claim 12, further comprising a renderer that is coupled to the neural network model and configured to render the rendered image frame according to the sample map.
14. The system of claim 13, wherein the rendered image frame includes artifacts including at least a loss of high-frequency detail or residual noise.
15. The system of claim 12, wherein the neural network model is further configured to process the guide data for the previous rendered image frame using layers to produce a first sample map that indicates a number of samples to be computed for each pixel in the previous rendered image frame.
16. The system of claim 12, further comprising a reconstruction neural network model configured to process the previous rendered image frame using layers of the reconstruction neural network model to produce the external state.
17. The system of claim 12, further comprising a reconstruction neural network model configured to process the rendered image frame using layers of the reconstruction neural network model to produce second external state including a reconstructed rendered image frame with fewer artifacts compared with the rendered image frame.
18. The system of claim 17, wherein processing the rendered image frame to produce the reconstructed data frame is based on the warped external state.
19. The system of claim 12, wherein the guide data comprises normal vectors, depth, or albedo.
20. A non-transitory, computer-readable storage medium storing instructions that, when executed by a processing unit, cause the processing unit to: receive guide data for a rendered image frame in a sequence of rendered image frames, the sequence including a previous rendered image frame and the rendered image frame; receive external state including a reconstructed previous rendered image frame with fewer artifacts compared with the previous rendered image frame, wherein the external state is warped, using difference data corresponding to changes between the previous rendered image frame and the rendered image frame, to produce warped external state; and process the guide data for the rendered image frame using layers of a neural network model to produce a sample map that indicates a number of samples to be computed for each pixel in the rendered image frame, wherein the warped external state is input to one or more of the layers of the neural network.
</claims>
</document>
