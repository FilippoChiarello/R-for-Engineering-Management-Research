<document>

<filing_date>
2018-09-17
</filing_date>

<publication_date>
2020-09-03
</publication_date>

<priority_date>
2017-09-28
</priority_date>

<ipc_classes>
G06N20/00,G06N7/00
</ipc_classes>

<assignee>
D5AI
</assignee>

<inventors>
BAKER, JAMES, K.
BAKER, BRADLEY J.
</inventors>

<docdb_family_id>
65807592
</docdb_family_id>

<title>
ESTIMATING THE AMOUNT OF DEGRADATION WITH A REGRESSION OBJECTIVE IN DEEP LEARNING
</title>

<abstract>
Computer systems and computer-implemented methods train a machine-learning regression system. The method comprises the step of generating, with a machine-learning generator, output patterns; distorting the output patterns of the generator by a scale factor to generate distorted output patterns; and training the machine-learning regression system to predict the scaling factor, where the regression system receives the distorted output patterns as input and learns and the scaling factor is a target value for the regression system. The method may further comprise, after training the machine-learning regression system, training a second machine-learning generator by back propagating partial derivatives of an error cost function from the regression system to the second machine-learning generator and training the second machine-learning generator using stochastic gradient descent.
</abstract>

<claims>
1. A computer-implemented method comprising: generating, with a machine-learning generator, output patterns, wherein the machine-learning generator is implemented by a computer system comprising a set of processor cores; distorting, by the computer system, the output patterns of the generator to generate distorted output patterns, wherein a scale of distortion of the output patterns is controlled by a scaling factor; and training, by the computer system, a machine-learning regression system to predict the scaling factor, wherein the regression system receives the distorted output patterns as input and learns and the scaling factor is a target value for the regression system.
2. The method of claim 1, wherein distorting the output patterns of the generator comprises applying the distortion to an output of the generator.
3. The method of claim 1, wherein: the generator comprises a network with multiple layers, including an internal layer; and distorting the output patterns comprises applying the distortion to the internal layer of the generator to thereby generate the distorted output patterns.
4. The method of claim 1, wherein: the distortion comprises noise applied to the output patterns; and the scaling factor controls an amount of noise applied to the output patterns.
5. The method of claim 1, wherein: the distortion comprises a degradation of the output patterns; and the scaling factor controls an amount of degradation to the output patterns.
6. The method of claim 1, wherein: the distortion comprises a transformation of the output patterns; and the scaling factor controls an amount of transformation of the output patterns.
7. The method of claim 1, wherein the generator comprising an autoencoder.
8. The method of claim 7, wherein the autoencoder comprises an autoencoder selected from the group consisting of a variational autoencoder and a stochastic categorical autoencoder network.
9. The method of claim 1, wherein the generator comprises a generative adversarial network.
10. The method of claim 1, wherein the generator comprises a stochastic generator that produces parameters for probability distributions of the output patterns.
11. The method of claim 10, further comprising controlling a degree of dispersion for the probability distributions.
12. The method of claim 1, further comprising, after training the machine-learning regression system, training, with the computer system, a second machine-learning generator, wherein: an output of the second machine-learning generator is fed into the machine-learning regression system; and training the second machine-learning generator comprises: back propagating partial derivatives of an error cost function from the regression system to the second machine-learning generator; and training the second machine-learning generator using stochastic gradient descent.
13. The method of claim 12, wherein a target regression value for the machine-learning regression system in training the second machine-learning generator is zero.
14. The method of claim 12, wherein training the second machine-learning generator comprises back-propagating a second objective from a second network to the second machine-learning generator.
15. The method of claim 14, wherein the second network comprises a classifier.
16. The method of claim 14, wherein the second network comprises a real-vs-generated discriminator.
17. The method of claim 13, wherein the second machine-learning generator comprises a machine-learning decoder that generates output patterns from random input.
18. The method of claim 13, wherein the second machine-learning generator comprises a stochastic autoencoder.
19. The method of claim 18, wherein the stochastic autoencoder comprises a variational autoencoder.
20. The method of claim 18, wherein the stochastic autoencoder comprises a stochastic categorical autoencoder.
21. The method of claim 18, further comprising, by the computer system, implementing a machine-learning denoising network for denoising output from the second machine-learning generator.
22. The method of claim 21, further comprising, by the computer system, training the machine-learning denoising network prior to training the second machine-learning generator.
23. The method of claim 21, wherein training the second machine-learning generator comprises back-propagating a second objective from a second network to the second machine-learning generator.
24. The method of claim 23, wherein the second network comprises a classifier.
25. The method of claim 23, wherein the second network comprises a real-vs-generated discriminator.
26. The method of claim 13, further comprising, by the computer system, implementing a machine-learning denoising network for denoising output from the second machine-learning generator.
27. The method of claim 26, wherein training the second machine-learning generator comprises back-propagating a second objective from a second network to the second machine-learning generator.
28. A computer-implemented method of training a machine-learning generator, the method comprising: back propagating, by a computer system comprising a set of processor cores, partial derivatives of an error cost function from a regression system to the machine-learning generator, wherein: an output of the second machine-learning generator is fed into the machine-learning regression system; the machine-learning regression system is trained to predict a scaling factor of distortion applied to training examples provided to the machine-learning regression system; the scaling factor is a target value for the regression system during training of the regression system; and a target regression value for the machine-learning regression system in training the machine-learning generator is zero; and training, by the computer system, the machine-learning generator using stochastic gradient descent.
29. The method of claim 28, wherein a target regression value for the machine-learning regression system in training the machine-learning generator is zero.
30. The method of claim 29, wherein training the machine-learning generator comprises back-propagating a second objective from a second network to the machine-learning generator.
31. The method of claim 30, wherein the second network comprises a classifier.
32. The method of claim 30, wherein the second network comprises a real-vs-generated discriminator.
33. The method of claim 29, wherein the machine-learning generator comprises a machine-learning decoder that generates output patterns from random input.
34. The method of claim 29, wherein the machine-learning generator comprises a stochastic autoencoder.
35. The method of claim 34, wherein the stochastic autoencoder comprises a variational autoencoder.
36. The method of claim 34, wherein the stochastic autoencoder comprises a stochastic categorical autoencoder.
37. The method of claim 34, further comprising, by the computer system, implementing a machine-learning denoising network for denoising output from the machine-learning generator.
38. The method of claim 37, further comprising, by the computer system, training the machine-learning denoising network prior to training the machine-learning generator.
39. The method of claim 37, wherein training the machine-learning generator comprises back-propagating a second objective from a second network to the machine-learning generator.
40. The method of claim 39, wherein the second network comprises a classifier.
41. The method of claim 39, wherein the second network comprises a real-vs-generated discriminator.
42. The method of claim 29, further comprising, by the computer system, implementing a machine-learning denoising network for denoising output from the machine-learning generator.
43. The method of claim 42, wherein training the machine-learning generator comprises back-propagating a second objective from a second network to the machine-learning generator.
44. A machine-learning computer system comprising: a set of processor cores; and computer memory that stores software that, when executed by the set of processor cores, causes the set of processor cores to: generate, with a machine-learning generator, output patterns; distort the output patterns of the generator to generate distorted output patterns, wherein a scale of distortion of the output patterns is controlled by a scaling factor; and train a machine-learning regression system to predict the scaling factor, wherein the regression system receives the distorted output patterns as input and learns and the scaling factor is a target value for the regression system.
45. 45-54. (canceled)
55. The machine-learning computer system of claim 44, wherein the software further causes the set of processor cores to, after training the machine-learning regression system, train a second machine-learning generator, wherein: an output of the second machine-learning generator is fed into the machine-learning regression system; and the software further causes the set of processor cores to train the second machine-learning generator by: back propagating partial derivatives of an error cost function from the regression system to the second machine-learning generator; and training the second machine-learning generator using stochastic gradient descent.
56. 56-70. (canceled)
71. A machine-learning computer system comprising: a set of processor cores; and computer memory that stores software that, when executed by the set of processor cores, causes the set of processor cores to training a machine-learning generator by: back propagating partial derivatives of an error cost function from a regression system to the machine-learning generator, wherein: an output of the second machine-learning generator is fed into the machine-learning regression system; the machine-learning regression system is trained to predict a scaling factor of distortion applied to training examples provided to the machine-learning regression system; the scaling factor is a target value for the regression system during training of the regression system; and a target regression value for the machine-learning regression system in training the machine-learning generator is zero; and training the machine-learning generator using stochastic gradient descent.
72. 72-86. (canceled)
</claims>
</document>
