<document>

<filing_date>
2019-04-25
</filing_date>

<publication_date>
2020-10-29
</publication_date>

<priority_date>
2019-04-25
</priority_date>

<ipc_classes>
G06Q30/06,G06T19/00,H04N7/18
</ipc_classes>

<assignee>
CAPITAL ONE SERVICES
</assignee>

<inventors>
HOOVER, JASON
TANG, QIAOCHU
DAGLEY, GEOFFREY
WYLIE, STEPHEN
PRICE, MICAH
DUCKWORTH, STAEVAN
AWOYEMI, OLALEKAN
</inventors>

<docdb_family_id>
72917205
</docdb_family_id>

<title>
UTILIZING MACHINE LEARNING TO GENERATE AUGMENTED REALITY VEHICLE INFORMATION FOR A VEHICLE CAPTURED BY CAMERAS IN A VEHICLE LOT
</title>

<abstract>
A device receives, from multiple cameras, streaming video data associated with multiple vehicles and provides the streaming video data to a user device associated with a user. The device receives, from the user device, a request to control a first camera and provides, to the user device, first streaming video data associated with the first camera. The device receives, from the user device, a camera control command for the first camera and causes the first camera to perform an action. The device receives updated first streaming video data from the first camera and provides, to the user device, the updated first streaming video data. The device receives, from the user device, information identifying a first vehicle in the updated first streaming video data and identifies first augmented reality vehicle information associated with the first vehicle. The device provides the first augmented reality vehicle information to the user device.
</abstract>

<claims>
1. A method, comprising: determining, by a device, an inventory of a plurality of vehicles in a vehicle lot based on first streaming video data received from a plurality of cameras associated with the vehicle lot; determining, by the device and using the first streaming video data, a physical condition of each vehicle of the plurality of vehicles; receiving, by the device and from the plurality of cameras, second streaming video data associated with the plurality of vehicles, the plurality of cameras providing respective portions of the second streaming video data; providing, by the device, the second streaming video data to a user device associated with a user; receiving, by the device and from the user device, a request to control a first camera, of the plurality of cameras, based on a user interaction with the second streaming video data; providing, by the device, to the user device, and based on the request, third streaming video data associated with the first camera, wherein the third streaming video data includes a respective portion of the second streaming video data captured by the first camera; receiving, by the device and from the user device, a camera control command for the first camera; causing, by the device, the first camera to perform an action based on the camera control command, the action including moving the first camera; receiving, by the device, updated third streaming video data from the first camera based on the first camera performing the action, wherein the updated third streaming video data includes the respective portion of the second streaming video data captured by the first camera after performance of the action; providing, by the device and to the user device, the updated third streaming video data; receiving, by the device and from the user device, information identifying a first vehicle, of the plurality of vehicles, in the updated third streaming video data; identifying, by the device, first augmented reality vehicle information associated with the first vehicle based on the information identifying the first vehicle, the first augmented reality vehicle information including data identifying the physical condition of the first vehicle; and providing, by the device, the first augmented reality vehicle information to the user device to enable the user device to overlay the first augmented reality vehicle information on the updated third streaming video data.
2. The method of claim 1, further comprising: utilizing information indicating the inventory of the plurality of vehicles to determine augmented reality vehicle information for each of the plurality of vehicles.
3. The method of claim 1, wherein identifying the first augmented reality vehicle information comprises: processing the information identifying the first vehicle, with a machine learning model, to match the information identifying the first vehicle and a portion of augmented reality vehicle information associated with the plurality of vehicles; and identifying the first augmented reality vehicle information based on matching the information identifying the first vehicle and the portion of the augmented reality vehicle information associated with the plurality of vehicles.
4. The method of claim 1, further comprising: receiving, from the user device, information requesting a communication with a sales person at the vehicle lot; and causing the communication to be established between the user device associated with the user and a user device associated with the sales person.
5. The method of claim 1, further comprising: receiving, from the user device, another request to control a second camera, of the plurality of cameras, based on another user interaction with the second streaming video data; and providing, to the user device and based on the other request, fourth streaming video data associated with the second camera, wherein the fourth streaming video data includes a respective portion of the second streaming video data captured by the second camera.
6. The method of claim 5, further comprising: receiving, from the user device, another camera control command for the second camera; causing the second camera to perform another action based on the other camera control command, the other action including moving the second camera; receiving updated fourth streaming video data from the second camera based on the second camera performing the other action, wherein the updated fourth streaming video data includes the respective portion of the second streaming video data captured by the second camera after performance of the other action; and providing, to the user device, the updated fourth streaming video data.
7. The method of claim 6, further comprising: receiving, from the user device, information identifying a second vehicle, of the plurality of vehicles, in the updated fourth streaming video data; identifying second augmented reality vehicle information associated with the second vehicle based on the information identifying the second vehicle; and providing the second augmented reality vehicle information to the user device to enable the user device to associate the second augmented reality vehicle information with the updated fourth streaming video data.
8. A device, comprising: one or more memories; and one or more processors, communicatively coupled to the one or more memories, configured to: determine an inventory of a plurality of vehicles in a vehicle lot based on first streaming video data received from a plurality of cameras associated with the vehicle lot; receive, from the plurality of cameras, second streaming video data associated with the plurality of vehicles in a vehicle lot, the plurality of cameras providing respective portions of the second streaming video data; receive, from a user device associated with a user, user input indicating a particular vehicle, of the plurality of vehicles; provide, based on the user input, the second streaming video data to the user device, the second streaming video data depicting the particular vehicle; receive, from the user device, a request to control a particular camera, of the plurality of cameras, based on a user interaction with the second streaming video data; provide, to the user device and based on the request, particular streaming video data associated with the particular camera, wherein the particular streaming video data includes a respective portion of the second streaming video data captured by the particular camera, and wherein the particular streaming video data includes information identifying the particular vehicle; receive, from the user device, a camera control command for the particular camera, wherein the camera control command includes a command to cause the particular camera to one or more of tilt, rotate, pan, or zoom; cause the particular camera to one or more of tilt, rotate, pan, or zoom based on the camera control command; receive updated particular streaming video data from the particular camera based on the particular camera one or more of tilting, rotating, panning, or zooming, wherein the updated particular streaming video data includes the respective portion of the second streaming video data captured by the particular camera after the particular camera one or more of tilts, rotates, pans, or zooms; provide, to the user device, the updated particular streaming video data; identify augmented reality vehicle information associated with the particular vehicle based on the information identifying the particular vehicle, the augmented reality vehicle information including data identifying the particular vehicle; and provide the augmented reality vehicle information to the user device to enable the user device to overlay the augmented reality vehicle information on the updated particular streaming video data.
9. The device of claim 8, wherein the augmented reality vehicle information further includes information indicating one or more of: a make of the particular vehicle, a model of the particular vehicle, a year of the particular vehicle, mileage of the particular vehicle, miles per gallon of the particular vehicle, a cost of the particular vehicle, financing options for the particular vehicle, or an accident history associated with the particular vehicle.
10. The device of claim 8, wherein the one or more processors are further configured to: determine, using the first streaming video data, a physical condition and location of each vehicle of the plurality of vehicles; determine whether the physical condition and the location match historical inventory information regarding the plurality of vehicles, wherein the historical inventory information is maintained by an inventory management system associated with the vehicle lot; and generate a notification based on determining that the physical condition and the location do not match the historical inventory information.
11. The device of claim 8, wherein, when identifying the augmented reality vehicle information, the one or more processors are configured to: process the information identifying the particular vehicle, with a machine learning model, to match the information identifying the particular vehicle and a portion of augmented reality vehicle information associated with the plurality of vehicles; and identify the augmented reality vehicle information based on matching the information identifying the particular vehicle and the portion of the augmented reality vehicle information associated with the plurality of vehicles.
12. The device of claim 8, wherein the one or more processors are further configured to: receive information requesting a communication with a sales person at the vehicle lot; and cause the communication to be established between the user device associated with the user and a user device associated with the sales person.
13. The device of claim 8, wherein the one or more processors are further configured to: receive, from the user device, another camera control command for the particular camera; cause the particular camera to perform an action based on the other camera control command, the action including moving the particular camera; receive further updated particular streaming video data from the particular camera based on the particular camera performing the action, wherein the further updated particular streaming video data includes the respective portion of the second streaming video data captured by the particular camera after performance of the action; and provide, to the user device, the further updated particular streaming video data.
14. The device of claim 13, wherein the plurality of cameras includes one or more of: a camera, a three-hundred and sixty degrees camera, a robot equipped with a camera, another user device equipped with a camera, or an unmanned aerial vehicle (UAV) equipped with a camera.
15. A non-transitory computer-readable medium storing instructions, the instructions comprising: one or more instructions that, when executed by one or more processors of a device, cause the one or more processors to: determine an inventory of a plurality of vehicles in a vehicle lot based on first streaming video data received from a plurality of cameras associated with the vehicle lot; determine, using the first streaming video data, a physical condition of each vehicle of the plurality of vehicles; receive, from the plurality of cameras, second streaming video data associated with the plurality of vehicles, the plurality of cameras providing respective portions of the second streaming video data; receive, from a user device associated with a user, user input indicating a particular vehicle, of the plurality of vehicles; provide, based on the user input, the second streaming video data to the user device, the second streaming video data depicting the particular vehicle; receive, from the user device, a selection of a first camera of the plurality of cameras; provide, to the user device and based on the selection, third streaming video data captured by the first camera, wherein the third streaming video data includes a respective portion of the second streaming video data captured by the first camera; receive, from the user device, a camera control command for the first camera; cause the first camera to perform an action based on the camera control command, the action including moving the first camera; receive updated third streaming video data from the first camera based on the first camera performing the action, wherein the updated third streaming video data includes the respective portion of the second streaming video data captured by the first camera after performance of the action, and the updated third streaming video data includes information identifying the particular vehicle; provide, to the user device, the updated third streaming video data; identify augmented reality vehicle information associated with the vehicle based on the information identifying the vehicle, wherein the augmented reality vehicle information includes: data identifying a location of the vehicle, the physical condition of the vehicle, and information indicating one or more of: a make of the vehicle, a model of the vehicle, a year of the vehicle, mileage of the vehicle, miles per gallon of the vehicle, a cost of the vehicle, financing options for the vehicle, or an accident history associated with the vehicle; and provide the augmented reality vehicle information to the user device to enable the user device to overlay the augmented reality vehicle information on the updated third streaming video data.
16. The non-transitory computer-readable medium of claim 15, wherein the instructions further comprise: one or more instructions that, when executed by the one or more processors, cause the one or more processors to: utilize information indicating the inventory of the plurality of vehicles to determine augmented reality vehicle information for each of the plurality of vehicles.
17. The non-transitory computer-readable medium of claim 15, wherein the one or more instructions, that cause the one or more processors to identify the augmented reality vehicle information, cause the one or more processors to: process the information identifying the vehicle, with a machine learning model, to match the information identifying the vehicle and a portion of augmented reality vehicle information associated with the plurality of vehicles; and identify the augmented reality vehicle information based on matching the information identifying the vehicle and the portion of the augmented reality vehicle information associated with the plurality of vehicles.
18. The non-transitory computer-readable medium of claim 15, wherein the instructions further comprise: one or more instructions that, when executed by the one or more processors, cause the one or more processors to: receive, from the user device, information requesting a communication with a sales person at the vehicle lot; and cause the communication to be established between the user device associated with the user and a user device associated with the sales person.
19. The non-transitory computer-readable medium of claim 15, wherein the instructions further comprise: one or more instructions that, when executed by the one or more processors, cause the one or more processors to: receive, from the user device, another selection of a second camera of the plurality of cameras; and provide, to the user device and based on the other selection, fourth streaming video data captured by the second camera, wherein the fourth streaming video data includes a respective portion of the second streaming video data captured by the second camera.
20. The non-transitory computer-readable medium of claim 19, wherein the instructions further comprise: one or more instructions that, when executed by the one or more processors, cause the one or more processors to: receive, from the user device, another camera control command for the second camera; cause the second camera to perform another action based on the other camera control command, the other action including moving the second camera; receive updated fourth streaming video data from the second camera based on the second camera performing the other action, wherein the updated fourth streaming video data includes the respective portion of the second streaming video data captured by the second camera after performance of the other action; and provide, to the user device, the updated fourth streaming video data.
</claims>
</document>
