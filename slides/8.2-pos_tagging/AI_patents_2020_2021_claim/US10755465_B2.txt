<document>

<filing_date>
2018-11-29
</filing_date>

<publication_date>
2020-08-25
</publication_date>

<priority_date>
2013-08-02
</priority_date>

<ipc_classes>
G06N3/00,G06T13/40
</ipc_classes>

<assignee>
SOUL MACHINES
</assignee>

<inventors>
SAGAR, MARK ANDREW
ROBERTSON, PAUL BURTON
BULLIVANT, DAVID PETER
</inventors>

<docdb_family_id>
52432139
</docdb_family_id>

<title>
System for neurobehaviorual animation
</title>

<abstract>
The present invention relates to a computer implemented system for animating a virtual object or digital entity. It has particular relevance to animation using biologically based models, or behavioural models particularly neurobehavioural models. There is provided a plurality of modules having a computational element and a graphical element. The modules are arranged in a required structure and have at least one variable and being associated with at least one connector. The connectors link variables between modules across the structure, and the modules together provide a neurobehavioural model. There is also provided a method of controlling a digital entity in response to an external stimulus.
</abstract>

<claims>
What we claim is:
1. A computer implemented system for generating interactive behavior of an embodied virtual character or digital entity, the system comprising: a plurality of interconnected modules together representative of a neurobehavioral model, at least one of the plurality of interconnected modules receiving data characterizing a real-world input stimulus; wherein the neurobehavioral model is time-stepped such that the plurality of interconnected modules operate in a time-step to provide an external output defining a response of the virtual character or digital entity to the external stimulus and wherein time-stepping within modules occurs at a rate providing multiple computational time-steps before a response is provided.
2. The system of claim 1, including an external output defining an audible response of the virtual character or digital entity to the external stimulus.
3. The system of claim 1, including an external output defining a physical response of the virtual character or digital entity to the external stimulus and wherein the physical response is any of: change of orientation, a change of emotional expression, a change in body language, or mirroring the external input.
4. The system of claim 1, wherein each module has at least one variable and is associated with at least one connector, wherein the connectors communicate information on variable values between modules in a time-stepped manner.
5. A computer implemented system for generating interactive behavior of an embodied virtual character or digital entity, the system comprising: a plurality of interconnected modules together representative of a neurobehavioral model, at least one of the plurality of interconnected modules receiving data characterizing a real-world input stimulus; wherein the neurobehavioral model is time-stepped such that the plurality of interconnected modules operate in a time-step to provide an external output defining a response of the virtual character or digital entity to the external stimulus and wherein the plurality of the modules have coupled computational and graphical elements, each module representing a biological process and having a computational element relating to and simulating the biological process and a graphical element visualizing the biological process.
6. A computer implemented system for generating interactive behavior of an embodied virtual character or digital entity, the system comprising: a plurality of interconnected modules together representative of a neurobehavioral model, at least one of the plurality of interconnected modules receiving data characterizing a real-world input stimulus; wherein the neurobehavioral model is time-stepped such that the plurality of interconnected modules operate in a time-step to provide an external output defining a response of the virtual character or digital entity to the external stimulus and wherein the plurality of interconnected modules together representative of a neurobehavioral model simulate multiple parallel systems for generating behavior, and at least one module is configured to resolve competing inputs from a plurality of other inputs from the interconnected module to provide the external output defining a response of the virtual character or digital entity to the external stimulus.
7. A facial graphics rendering system, comprising: a plurality of layers, the plurality of layers comprising: a graphics rendering layer which receives muscle actuation/position data defining degrees of actuation of a set of facial animation muscles and which generates graphics image data; a muscle actuation/integration layer receiving nerve actuation data defining a degrees of nerve activation for a set of animation nerves and generating muscle actuation data for a set of activation muscles defined for the muscle actuation layer; and a nerve activation layer receiving expression data defining an expression and generating nerve activation data defining a combination of animation nerves to be activated and defining a degree of activation for each nerve.
8. The system of claim 7, wherein each of the plurality of layers receives stimulus data and generates feedback data.
9. The system of claim 5, wherein at least one of the plurality of interconnected modules receives data characterizing an internal stimulus from another one of the plurality of interconnected modules, wherein the internal stimulus also affects the external output defining the response of the virtual character or digital entity to the external stimulus.
10. The system of claim 5, wherein the real-world stimulus is received from one or more of the group consisting of a camera, an electromagnetic transducer, an audio transducer, a keyboard, and a graphical user interface.
11. The system of claim 5, wherein the interconnected modules are configured to exhibit chaotic behavior, depending in a nonlinear way on a past state as characterized by module variable values.
12. The system of claim 5, wherein the output is at least one of: graphical output or actuation of a physical robot.
13. The system of claim 5, wherein at least one of the plurality of interconnected modules creates an association between the external stimulus and the external output.
14. The system of claim 5, including an external output defining an audible response of the virtual character or digital entity to the external stimulus.
15. The system of claim 5, including an external output defining a physical response of the virtual character or digital entity to the external stimulus and wherein the physical response is any of: change of orientation, a change of emotional expression, a change in body language, or mirroring the external input.
16. The system of claim 5, wherein the external stimulus affects the operation of the neurobehavioral model over time.
17. The system of claim 5, wherein each module has at least one variable and is associated with at least one connector, wherein the connectors communicate information on variable values between modules in a time-stepped manner.
18. The system of claim 6, wherein at least one of the plurality of interconnected modules receives data characterizing an internal stimulus from another one of the plurality of interconnected modules, wherein the internal stimulus also affects the external output defining the response of the virtual character or digital entity to the external stimulus.
19. The system of claim 6, wherein the real-world stimulus is received from one or more of the group consisting of a camera, an electromagnetic transducer, an audio transducer, a keyboard, and a graphical user interface.
20. The system of claim 6, wherein the interconnected modules are configured to exhibit chaotic behavior, depending in a nonlinear way on a past state as characterized by module variable values.
21. The system of claim 6, wherein the output is at least one of: graphical output or actuation of a physical robot.
22. The system of claim 6, wherein at least one of the plurality of interconnected modules creates an association between the external stimulus and the external output.
23. The system of claim 6, including an external output defining an audible response of the virtual character or digital entity to the external stimulus.
24. The system of claim 6, including an external output defining an physical response of the virtual character or digital entity to the external stimulus and wherein the physical response is any of: change of orientation, a change of emotional expression, a change in body language, or mirroring the external input.
25. The system of claim 6, wherein the external stimulus affects the operation of the neurobehavioral model over time.
26. The system of claim 6, wherein each module has at least one variable and is associated with at least one connector, wherein the connectors communicate information on variable values between modules in a time-stepped manner.
</claims>
</document>
