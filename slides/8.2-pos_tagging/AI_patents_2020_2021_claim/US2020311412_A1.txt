<document>

<filing_date>
2019-03-29
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-29
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N3/02,G06N5/04
</ipc_classes>

<assignee>
KONICA MINOLTA LABORATORY U.S.A.
</assignee>

<inventors>
PREBBLE, TIM
</inventors>

<docdb_family_id>
72605970
</docdb_family_id>

<title>
INFERRING TITLES AND SECTIONS IN DOCUMENTS
</title>

<abstract>
A method for processing an electronic document (ED) to infer titles and sections in the ED includes: applying visual analysis to the ED and identifying candidate titles and candidate sections of the ED; filtering the candidate titles based on the candidate sections; filtering the candidate sections based on the filtered candidate titles; applying semantic analysis to the ED and identifying topics and portions of the ED; refining, based on the identified topics and the portions, the filtered candidate titles and the filtered candidate sections; and generating a marked-up version of the ED that identifies the refined candidate titles and the refined candidate sections.
</abstract>

<claims>
1. A method for processing an electronic document (ED) to infer titles and sections in the ED, the method comprising: applying visual analysis to the ED and identifying candidate titles and candidate sections of the ED; filtering the candidate titles based on the candidate sections; filtering the candidate sections based on the filtered candidate titles; applying semantic analysis to the ED and identifying topics and portions of the ED; refining, based on the identified topics and the portions, the filtered candidate titles and the filtered candidate sections; and generating a marked-up version of the ED that identifies the refined candidate titles and the refined candidate sections.
2. The method of claim 1, further comprising: refining, based on the refined candidate titles and the refined candidate sections, the topics and portions; further refining, based on the refined topics and the refined portions, the refined candidate titles and the refined candidate sections; and generating a marked-up version of the ED that identifies the further refined candidate titles and the further refined candidate sections.
3. The method of claim 1, wherein the refining of the candidate titles and the candidate sections further comprises: re-applying the visual analysis to only a first portion among the portions, wherein the first portion is associated with a first topic among the topics; comparing the filtered candidate titles and the filtered candidate sections identified within the first portion to the first topic, wherein the filtered candidate titles and the filtered candidate sections within the first portion are associated with a second topic among the topics; and determining, based on the first topic matching the second topic, that the filtered candidate titles and the filtered candidate sections within the first portion are associated with the first portion.
4. The method of claim 3, wherein the method further comprises: identifying, based on executing the visual analysis and the semantic analysis on an entirety of the ED, a possible inconsistency between the first topic and the second topic; and selecting the first portion based on the possible inconsistency.
5. The method of claim 1, wherein each of the candidate sections is associated with at least one of the candidate titles, and the refining of the filtered candidate titles and the filtered candidate sections further comprises: identifying a first filtered candidate section among the filtered candidate sections that is not associated with any of the filtered candidate titles; re-applying the visual analysis to only the first filtered candidate section; determining that the first filtered candidate section includes a non-text object; searching, using the visual analysis, for any of the filtered candidate titles within a predetermined area of the non-text object; determining, based on identifying a first filtered candidate title among the filtered candidate titles within the predetermined area, that the first filtered candidate title is a title of the second filtered candidate section.
6. The method of claim 1, wherein the ED comprises multiple pages, and the refining of the filtered candidate titles and the filtered candidate sections further comprises: dividing, based on the topics or the portions, the ED into a first subset of the pages and a second subset of the pages that do not overlap; and separately re-applying the visual analysis to the first subset and the second subset to identify any missed candidate titles and sections within the first subset and the second subset.
7. The method of claim 1, wherein the refining of the filtered candidate titles and the filtered candidate sections further comprises: dividing, based on the topics or the portions, the ED into a first part and a second part that do not overlap, wherein the second part is masked; and re-applying the visual analysis to only the first part to identify any missed candidate titles and sections within the first area.
8. The method of claim 1, wherein the titles and the sections of the ED do not include tags.
9. The method of claim 1, wherein the visual analysis is applied using a Convolution Neural Network (CNN) in combination with a Recurrent Neural Network (RNN).
10. The method of claim 1, wherein the semantic analysis is applied using Natural Language Processing (NLP).
11. A non-transitory computer readable medium (CRM) storing computer readable program code for processing an electronic document (ED) to infer titles and sections in a parsed version of the ED embodied therein, the computer readable program code causes a computer to: apply visual analysis to the ED and identify candidate titles and candidate sections of the ED; filter the candidate titles based on the candidate sections; filter the candidate sections based on the filtered candidate titles; apply semantic analysis to the ED and identify topics and portions of the ED; refine, based on the identified topics and the portions, the filtered candidate titles and the filtered candidate sections; and generate a marked-up version of the ED that identifies the refined candidate titles and the refined candidate sections.
12. The CRM of claim 11, wherein the computer readable program code further causes a computer to: refine, based on the refined candidate titles and the refined candidate sections, the topics and portions; further refine, based on the refined topics and the refined portions, the refined candidate titles and the refined candidate sections; and generate a marked-up version of the ED that identifies the further refined candidate titles and the further refined candidate sections.
13. The CRM of claim 11, wherein the refining of the candidate titles and the candidate sections further comprises: re-applying the visual analysis to only a first portion among the portions, wherein the first portion is associated with a first topic among the topics; comparing the filtered candidate titles and the filtered candidate sections identified within the first portion to the first topic, wherein the filtered candidate titles and the filtered candidate sections within the first portion are associated with a second topic among the topics; and determining, based on the first topic matching the second topic, that the filtered candidate titles and the filtered candidate sections within the first portion are associated with the first portion.
14. The CRM of claim 13, wherein the computer readable program code further causes a computer to: identifying, based on executing the visual analysis and the semantic analysis on an entirety of the ED, a possible inconsistency between the first topic and the second topic; and selecting the first portion based on the possible inconsistency.
15. The CRM of claim 11, wherein each of the candidate sections is associated with at least one of the candidate titles, and the refining of the filtered candidate titles and the filtered candidate sections further comprises: identifying a first filtered candidate section among the filtered candidate sections that is not associated with any of the filtered candidate titles; re-applying the visual analysis to only the first filtered candidate section; determining that the first filtered candidate section includes a non-text object; searching, using the visual analysis, for any of the filtered candidate titles within a predetermined area of the non-text object; determining, based on identifying a first filtered candidate title among the filtered candidate titles within the predetermined area, that the first filtered candidate title is a title of the second filtered candidate section.
16. A system for processing an electronic document (ED) to infer titles and sections in a parsed version of the ED, the system comprising: a memory; and a processor coupled to the memory, wherein the processor: applies visual analysis to the ED and identifies candidate titles and candidate sections of the ED; filters the candidate titles based on the candidate sections; filters the candidate sections based on the filtered candidate titles; applies semantic analysis to the ED and identifies topics and portions of the ED; refines, based on the identified topics and the portions, the filtered candidate titles and the filtered candidate sections; and generates a marked-up version of the ED that identifies the refined candidate titles and the refined candidate sections.
17. The system of claim 16, wherein the processor further: refines, based on the refined candidate titles and the refined candidate sections, the topics and portions; further refines, based on the refined topics and the refined portions, the refined candidate titles and the refined candidate sections; and generates a marked-up version of the ED that identifies the further refined candidate titles and the further refined candidate sections.
18. The system of claim 16, wherein the refining of the candidate titles and the candidate sections further comprises: re-applying the visual analysis to only a first portion among the portions, wherein the first portion is associated with a first topic among the topics; comparing the filtered candidate titles and the filtered candidate sections identified within the first portion to the first topic, wherein the filtered candidate titles and the filtered candidate sections within the first portion are associated with a second topic among the topics; and determining, based on the first topic matching the second topic, that the filtered candidate titles and the filtered candidate sections within the first portion are associated with the first portion.
19. The system of claim 18, wherein the processor further: identifies, based on executing the visual analysis and the semantic analysis on an entirety of the ED, a possible inconsistency between the first topic and the second topic; and selects the first portion based on the possible inconsistency.
20. The system of claim 16, wherein each of the candidate sections is associated with at least one of the candidate titles, and the refining of the filtered candidate titles and the filtered candidate sections further comprises: identifying a first filtered candidate section among the filtered candidate sections that is not associated with any of the filtered candidate titles; re-applying the visual analysis to only the first filtered candidate section; determining that the first filtered candidate section includes a non-text object; searching, using the visual analysis, for any of the filtered candidate titles within a predetermined area of the non-text object; determining, based on identifying a first filtered candidate title among the filtered candidate titles within the predetermined area, that the first filtered candidate title is a title of the second filtered candidate section.
</claims>
</document>
