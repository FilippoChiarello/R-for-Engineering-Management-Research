<document>

<filing_date>
2019-10-21
</filing_date>

<publication_date>
2021-01-19
</publication_date>

<priority_date>
2018-07-06
</priority_date>

<ipc_classes>
G06F11/36,G06F16/22,G06F16/242,G06F16/2455,G06F16/248,G06F16/25,G06F16/28,G06F16/335,G06F16/903,G06F16/9032,G06F16/9038,G06F16/906,G06F16/93,G06F17/15,G06F17/16,G06F17/18,G06F21/55,G06F21/60,G06F21/62,G06F30/20,G06F40/117,G06F40/166,G06F40/20,G06F8/71,G06F9/54,G06K9/00,G06K9/03,G06K9/62,G06K9/66,G06K9/68,G06K9/72,G06N20/00,G06N3/04,G06N3/08,G06N5/04,G06N7/00,G06Q10/04,G06T11/00,G06T7/194,G06T7/246,G06T7/254,H04L29/06,H04L29/08,H04N21/234,H04N21/81
</ipc_classes>

<assignee>
CAPITAL ONE SERVICES
</assignee>

<inventors>
GOODSITT, JEREMY
WALTER S. AUSTIN
</inventors>

<docdb_family_id>
67543579
</docdb_family_id>

<title>
Systems and methods for motion correction in synthetic images
</title>

<abstract>
Systems and methods for generating synthetic video are disclosed. For example, the system may include one or more memory units storing instructions and one or more processors configured to execute the instructions to perform operations. The operations may include generating a static background image and determining the location of a reference edge. The operations may include determining a perspective of an observation point. The operations may include generating synthetic difference images that include respective synthetic object movement edges. The operations may include determining a location of the respective synthetic object movement edge and generating adjusted difference images corresponding to the individual synthetic difference images. Adjusted difference images may be based on synthetic difference images, locations of the respective synthetic object movement edges, the perspective of the observation point, and the location of the reference edge. The operations may include generating texturized images based on the adjusted difference images.
</abstract>

<claims>
1. A system for generating synthetic video comprising: one or more memory units storing instructions; and one or more processors configured to execute the instructions to perform operations comprising: generating background difference images from a sequence of images; generating synthetic difference images using an image sequence generator model; determining, for individual synthetic difference images, a location of a respective synthetic object movement edge; generating a sequence of adjusted difference images based on the synthetic difference images and the locations of the respective synthetic object movement edges; generating merged difference images based on the adjusted difference images and the background difference images; and generating texturized images based on the merged difference images.
2. The system of claim 1, wherein generating background difference images is based on a method of image subtraction.
3. The system of claim 1, wherein: the operations further comprise determining, for individual background difference images, a location of a respective background movement object edge; and the generating of merged difference images is further based on the locations of the background movement edges.
4. The system of claim 3, wherein: the operations further comprise generating a sequence of normalized images based on the sequence of images; and the generating of the background difference images comprises applying a method of image subtraction to the normalized sequence of images.
5. The system of claim 1, wherein: the operations further comprise generating a static background image based on the sequence of images; determining the location of a reference edge in the static background image; and the generating of the adjusted difference images is further based on the location of the reference edge.
6. The system of claim 5, wherein determining the location of the reference edges comprises using at least one of an edge detecting method, an object detection method, a homography method, or a pose estimation method.
7. The system of claim 1, the operations further comprising: generating a static background image based on the sequence of images; determining the location of a reference edge in the static background image; and the generating of merged difference images is further based on the location of the reference edge.
8. The system of claim 1, the operations further comprising training the image sequence generator model to generate synthetic difference images based on training difference images.
9. The system of claim 1, wherein the image sequence generator model comprises at least one of a recurrent neural network (RNN) model, a generative adversarial model (GAN), an RNN-GAN model, a convolutional neural network model, or a long short-term memory model.
10. The system of claim 1, wherein generating synthetic difference images comprises iteratively using the image sequence generator model to accept a previous synthetic difference image as an input and return a subsequent synthetic difference image as an output, starting from a first difference image.
11. The system of claim 1, wherein generating at least one of the adjusted difference images comprises scaling the respective synthetic object movement edge of the corresponding synthetic difference image.
12. The system of claim 1, wherein: the operations further comprise at least one of receiving or determining a perspective of an observation point; and generating at least one of the adjusted difference images is further based on the perspective of the observation point.
13. The system of claim 1, wherein generating at least one of the adjusted difference images comprises estimating a location and brightness of a light source based on luminance values.
14. The system of claim 1, wherein generating at least one of the adjusted difference images comprises using at least one of a gradient domain method or an image stitching method.
15. The system of claim 1, wherein generating at least one of the merged difference images comprises using at least one of an edge detecting method, an object detection method, a homography method, or a pose estimation method.
16. The system of claim 1, wherein generating at least one of the merged difference images comprises using at least one of a gradient domain method or an image stitching method.
17. The system of claim 1, wherein generating at least one of the texturized images comprises implementing a decoder model to perform at least one of a forward-step decoding or backward-step decoding.
18. The system of claim 1, wherein generating at least one of the texturized images is further based on at least one of edge density or edge direction.
19. A method for generating synthetic video comprising: generating background difference images based on a sequence of images; generating synthetic difference images using an image sequence generator model; determining, for individual synthetic difference images, a location of a respective synthetic object movement edge; generating a sequence of adjusted difference images based on the synthetic difference images and the locations of the respective synthetic object movement edges; generating merged difference images based on the adjusted difference images and the background difference images; and generating texturized images based on the merged difference images.
20. A system for generating synthetic video comprising: one or more memory units storing instructions; and one or more processors configured to execute the instructions to perform operations comprising: training an image sequence generator model to generate synthetic difference images based on training difference images; generating background difference images based on a sequence of images and a method of image subtraction; determining, for individual background difference images, a location of a respective background movement object edge; generating synthetic difference images using the image sequence generator model by iteratively accepting a previous synthetic difference image as an input and returning a subsequent synthetic difference image as an output, starting from a first difference image; determining, for individual synthetic difference images, a location of a respective synthetic object movement edge; generating a static background image based on the sequence of images; determining the location of a reference edge in the static background image using at least one of an edge detecting method, an object detection method, a homography method, or a pose estimation method; generating a sequence of adjusted difference images based on the synthetic difference images, the locations of the respective synthetic object movement edges, and the location of the reference edge; generating merged difference images based on the adjusted difference images, the background difference images, and the locations of the background movement edges; and generating texturized images based on the adjusted difference images, wherein generating at least one of the texturized images comprises implementing a decoder model to perform at least one of a forward-step decoding or backward-step decoding.
</claims>
</document>
