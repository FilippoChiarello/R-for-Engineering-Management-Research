<document>

<filing_date>
2020-06-30
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2018-04-27
</priority_date>

<ipc_classes>
G06F16/903,G06F3/01,G06K9/00
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
ASMI, YASSER B.
ABHISHEK, ABHISHEK
GORACZKO, MICHEL
LIU JIE
LYMBEROPOULOS, DIMITRIOS
AMINPOUR, ROUZBEH
ZHANG, ZHENGYOU
DALLOUL, ALI
LU, YI
ZUBERI, KHAWAR
WANG, DI
CAPONE, TONY
</inventors>

<docdb_family_id>
66770529
</docdb_family_id>

<title>
CONTEXT-AWARENESS
</title>

<abstract>
The discussion relates to context-aware environments. One example can include inwardly-facing cameras positioned around a periphery of an environment that defines a volume. The example can also include sensors positioned relative to the volume and configured to communicate with a user device in the volume. The example can also include an ambient perception component configured to track user locations in the volume and to detect user gestures relative to objects in the volume, and responsive to receiving a query from the user's device, to supplement the query with information derived from the objects.
</abstract>

<claims>
1. 1.-20. (canceled)
21. A system, comprising: cameras positioned to capture portions of an environment; sensors positioned to sense the portions or other portions of the environment and to communicate with user devices in the environment; and, a processor configured to determine locations of users in the environment utilizing data from the cameras, to identify the user devices in the environment utilizing data from the sensors, to co-locate individual users and individual user devices, to detect user gestures from the camera data, to receive a user query from an individual user performing an individual user gesture, to match the user query to an individual object in the environment, to supplement the user query with information about the individual object, to obtain a response for the supplemented user query, and to send the response to an individual user device that is co-located with the individual user.
22. The system of claim 21, wherein the processor is further configured to detect the user gestures from both the camera data and the sensor data.
23. The system of claim 22, wherein the processor is further configured to utilize data from the user devices to detect the user gestures.
24. The system of claim 21, wherein the user gestures include what object the individual user is looking at when the user query is received, and wherein the object the individual user is looking at comprises the individual object.
25. The system of claim 24, wherein the processor is further configured to identify the individual object from the camera data.
26. The system of claim 25, wherein the processor is further configured to obtain information about the individual object from an object database associated with the environment.
27. The system of claim 26, wherein in an instance where the user query contains a pronoun, the supplement the user query with the user gestures comprises supplementing the user query with the information about the individual object.
28. A system, comprising: cameras positioned to capture images of portions of an environment; sensors positioned to sense the portions or other portions of the environment and configured to communicate with a user device in the environment; and, an ambient perception component configured to track locations of a user in the environment and to detect user input relative to objects in the environment, and responsive to receiving a user query from the user, to match the user query to an individual object associated with an individual user input, to supplement the user query with information about the individual object, and to provide a response to the supplemented user query to the user.
29. The system of claim 28, wherein the ambient perception component is further configured to identify that the individual user input comprises a user gesture that is directed to the individual object.
30. The system of claim 29, wherein the ambient perception component is configured to access a database that relates to the objects and obtain the information about the individual object from the database.
31. The system of claim 30, wherein the ambient perception component is configured to supplement the user query with at least some of the information about the individual object from the database.
32. The system of claim 30, wherein the ambient perception component is configured to submit the supplemented user query to a search tool and send the response that includes results from the search tool to the user device for presentation to the user.
33. A smart device, comprising: storage configured to store computer-readable instructions; and, a processor configured to execute the computer-readable instructions: to receive a response to a supplemented user query, the supplemented user query comprising a user query submitted by a user and supplemented with object information relating to an object that was the subject of a user input when the user query was submitted, and to cause the response to the supplemented user query to be presented to the user.
34. The smart device of claim 33, wherein the computer-readable instructions when executed by the processor cause the processor to audibly present the response.
35. The smart device of claim 33, further comprising sensors configured to sense the user input.
36. The smart device of claim 35, wherein the sensors comprise a camera.
37. The smart device of claim 35, wherein the sensors comprise microelectromechanical sensors configured to detect user motions.
38. The smart device of claim 33, wherein the computer-readable instructions when executed by the processor cause the processor to communicate with other devices in an environment containing the object.
39. The smart device of claim 38, wherein the computer-readable instructions when executed by the processor cause the processor to receive the user input and the object information and to generate the supplemented user query from the object information and the user query.
40. The smart device of claim 38, wherein the computer-readable instructions when executed by the processor cause the processor to receive the user query and to receive the response to the supplemented user query.
</claims>
</document>
