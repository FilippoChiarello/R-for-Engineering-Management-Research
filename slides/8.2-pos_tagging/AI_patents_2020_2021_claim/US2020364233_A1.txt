<document>

<filing_date>
2019-08-05
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-15
</priority_date>

<ipc_classes>
G06F16/22,G06F16/2457,G06F16/93,G06N20/00
</ipc_classes>

<assignee>
WeR.AI, Inc.
</assignee>

<inventors>
CHAN, MAN
</inventors>

<docdb_family_id>
73231501
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR A CONTEXT SENSITIVE SEARCH ENGINE USING SEARCH CRITERIA AND IMPLICIT USER FEEDBACK
</title>

<abstract>
An example method comprises receiving documents to generate a corpus, generating an index of the documents, searching the corpus using the index and a search criteria to generate search results, ordering the search results, providing the search results to a user device, receiving a selection of one or more documents considered to be relevant, receiving a selection of one or more documents considered to be irrelevant, updating a machine learning model based on the selection of the one or more documents considered to be relevant and the one or more documents considered to be irrelevant, the machine learning model configured to generate a probability of likelihood of relevancy for at least a subset of the documents, re-ordering the search results based on the probability of likelihood of relevancy for each of the at least a subset of the documents, and providing the ordered search results based on the probability.
</abstract>

<claims>
1. A computing system comprising: one or more processors; and memory storing instructions that, when executed by the one or more processors, cause the computing system to: receive documents from one or more data sources to generate a corpus; generate an index of the documents based on keywords and phrases contained in each of the documents; receive a search criteria including keywords to search the corpus using the index; search the corpus using the index and the search criteria to generate search results; order the search results; provide the search results to a user device; receive a selection of one or more documents considered to be relevant from the user device; update a machine learning model based on the selection of the one or more documents considered to be relevant, the machine learning model configured to generate a probability of likelihood of relevancy for at least a subset of the documents; re-order the search results based on the probability of likelihood of relevancy for each of the at least a subset of the documents; and provide the ordered search results based on the probability to the user device, the search results including an ordered list of documents.
2. The system of claim 1, wherein the documents may include any computer object with text.
3. The system of claim 1, wherein the documents are abstracts and include identifiers of longer documents that the abstracts belong to.
4. The system of claim 1, wherein order the search results comprises ordering the search results based on TF-IDF.
5. The system of claim 1, wherein each document is encoded as a feature vector.
6. The system of claim 1, wherein the machine learning model is a general linear model (GLM) classifier that converts documents into a feature matrix using, at least in part positive features such as labels associated with selected relevant documents and negative features such as labels associated with selected irrelevant documents.
7. The system of claim 1, wherein the instructions further cause the computing system to track each change to the machine learning model and store the information as model information.
8. The system of claim 7, wherein the instructions further cause the computing system to provide a list of pre-existing corpuses based on a request from the user device, receive a selection of a pre-existing corpus from the list of pre-existing corpuses, and provide a list of pre-existing machine learning models including model information for at least a subset for the pre-existing machine learning models.
9. The system of claim 8, wherein the instructions further cause the computing system to receive a request for a particular pre-existing machine learning model from the list of pre-existing corpuses, retrieve the pre-existing corpus, load the particular pre-existing machine learning mode, and provide search results based at least in part on information contained within the model information, the search results being ordered based on the particular pre-existing machine learning model.
10. The system of claim 1, wherein the instructions further cause the computing system to receive a selection of one or more documents considered to be irrelevant from the user device and the machine learning model is updated based on the selection of the one or more documents considered to be relevant.
11. A non-transitory computer readable medium comprising instructions that, when executed, cause one or more processors to perform: receiving documents from one or more data sources to generate a corpus; generating an index of the documents based on keywords and phrases contained in each of the documents; receiving a search criteria including keywords to search the corpus using the index; searching the corpus using the index and the search criteria to generate search results; ordering the search results; providing the search results to a user device; receiving a selection of one or more documents considered to be relevant from the user device; updating a machine learning model based on the selection of the one or more documents considered to be relevant, the machine learning model configured to generate a probability of likelihood of relevancy for at least a subset of the documents; re-ordering the search results based on the probability of likelihood of relevancy for each of the at least a subset of the documents; and providing the ordered search results based on the probability to the user device, the search results including an ordered list of documents.
12. The non-transitory computer readable medium of claim 11, wherein the documents may include any computer object with text.
13. The non-transitory computer readable medium of claim 11, wherein the documents are abstracts and include identifiers of longer documents that the abstracts belong to.
14. The non-transitory computer readable medium of claim 11, wherein order the search results comprises ordering the search results based on TF-IDF.
15. The non-transitory computer readable medium of claim 11, wherein each document is encoded as a feature vector.
16. The non-transitory computer readable medium of claim 11, wherein the machine learning model is a general linear model (GLM) classifier that converts documents into a feature matrix using, at least in part positive features such as labels associated with selected relevant documents and negative features such as labels associated with selected irrelevant documents.
17. The non-transitory computer readable medium of claim 11, wherein the instructions further cause the one or more processors to to track each change to the machine learning model and store the information as model information.
18. The non-transitory computer readable medium of claim 17, wherein the instructions further cause the one or more processors to provide a list of pre-existing corpuses based on a request from the user device, receive a selection of a pre-existing corpus from the list of pre-existing corpuses, and provide a list of pre-existing machine learning models including model information for at least a subset for the pre-existing machine learning models.
19. The non-transitory computer readable medium of claim 18, wherein the instructions further cause the one or more processors to receive a request for a particular pre-existing machine learning model from the list of pre-existing corpuses, retrieve the pre-existing corpus, load the particular pre-existing machine learning mode, and provide search results based at least in part on information contained within the model information, the search results being ordered based on the particular pre-existing machine learning model.
20. The non-transitory computer readable medium of claim 11, wherein the instructions further cause the one or more processors to perform receiving a selection of one or more documents considered to be irrelevant from the user device and wherein updating the machine learning model is based on the selection of the one or more documents considered to be relevant and the one or more documents considered to be irrelevant.
21. A method being implemented by a computing system including one or more physical processors and storage media storing machine-readable instructions, the method comprising: receiving documents from one or more data sources to generate a corpus; generating an index of the documents based on keywords and phrases contained in each of the documents; receiving a search criteria including keywords to search the corpus using the index; searching the corpus using the index and the search criteria to generate search results; ordering the search results; providing the search results to a user device; receiving a selection of one or more documents considered to be relevant from the user device; updating a machine learning model based on the selection of the one or more documents considered to be relevant, the machine learning model configured to generate a probability of likelihood of relevancy for at least a subset of the documents; re-ordering the search results based on the probability of likelihood of relevancy for each of the at least a subset of the documents; and providing the ordered search results based on the probability to the user device, the search results including an ordered list of documents.
</claims>
</document>
