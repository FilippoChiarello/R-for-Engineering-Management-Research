<document>

<filing_date>
2020-03-24
</filing_date>

<publication_date>
2020-07-09
</publication_date>

<priority_date>
2019-12-13
</priority_date>

<ipc_classes>
G06F17/16,H04L29/06
</ipc_classes>

<assignee>
TRIPLEBLIND
</assignee>

<inventors>
STORM, GREG
GILKALAYE, BABAK POOREBRAHIM
DAS, RIDDHIMAN
</inventors>

<docdb_family_id>
71403979
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR EFFICIENT COMPUTATIONS ON SPLIT DATA AND SPLIT ALGORITHMS
</title>

<abstract>
The disclosed concepts achieve privacy for data operated on by an algorithm in an efficient manner A method includes receiving a first algorithm subset, receiving a second algorithm subset, generating two shares of a first mathematical set based on the first algorithm subset and transmitting the two shares of the first mathematical set from a first entity to a second entity. The method can include generating two shares of a second mathematical set based on the second algorithm subset, transmitting the two shares of the second mathematical set from the second entity to the first entity, receiving first split data subset of a full data set and receiving a second split data subset of the full data set. The system, based on these subsets of data, generates a first output subset and a second output subset which are combined for the final output.
</abstract>

<claims>
1. A method comprising: receiving, via at least one processor and at a first entity, a first algorithm subset from an algorithm provider; receiving, via at least one processor and at a second entity, a second algorithm subset from the algorithm provider; generating, via the first entity, two shares of a first mathematical set based on a first parameter associated with the first algorithm subset; transmitting at least a portion of the two shares of the first mathematical set from the first entity to the second entity; generating, via the second entity, two shares of a second mathematical set based on a second parameter associated with the second algorithm subset; transmitting at least a portion of the two shares of the second mathematical set from the second entity to the first entity; receiving, at the first entity, a first split data subset of a full data set; receiving, at the second entity, a second split data subset of the full data set; running the first algorithm subset on the first split data subset based on the two shares of the first mathematical set to yield a first output subset; running the second algorithm subset on the second split data subset based on the two shares of the second mathematical set to yield a second output subset; and combining the first output subset and the second output subset.
2. The method of claim 1, wherein a first algorithm subset from an algorithm that has been divided into a first algorithm subset and a second algorithm subset.
3. The method of claim 1, wherein the first parameter comprises a first characteristic of the first algorithm subset and wherein the second parameter comprises a second characteristic of the second algorithm subset.
4. The method of claim 1, wherein the first parameter relates to a nature of the first algorithm subset and wherein the second parameter both relate to a nature of the second algorithm subset.
5. The method of claim 1, wherein the first split data subset is generated randomly as part of the full data set.
6. The method of claim 1, wherein the second split data subset is generated randomly as part of the full data set.
7. The method of claim 1, wherein the first entity and the second entity comprise one of two physically separate computing device or two separate virtual computing devices.
8. The method of claim 1, wherein each of the first mathematical set and the second mathematical set comprise a beaver set.
9. The method of claim 1, wherein each of the first mathematical set and the second mathematical set comprise an N×M matrix.
10. The method of claim 1, wherein the running of the first algorithm subset on the first split data subset based on the two shares of the first mathematical set to yield the first output subset and the running of the second algorithm subset on the second split data subset based on the two shares of the second mathematical set to yield the second output subset occur using a memoization technique.
11. A system comprising: at least one processor; and a computer-readable storage medium storing instructions which, when executed by the at least one processor, cause the at least one processor to perform operations comprising: receiving, at a first entity, a first algorithm subset from an algorithm provider; receiving, at a second entity, a second algorithm subset from the algorithm provider; generating, via the first entity, two shares of a first mathematical set based on a first parameter associated with the first algorithm subset; transmitting at least a portion of the two shares of the first mathematical set from the first entity to the second entity; generating, via the second entity, two shares of a second mathematical set based on a second parameter associated with the second algorithm subset; transmitting at least a portion of the two shares of the second mathematical set from the second entity to the first entity; receiving, at the first entity, a first split data subset of a full data set; receiving, at the second entity, a second split data subset of the full data set; running the first algorithm subset on the first split data subset based on the two shares of the first mathematical set to yield a first output subset; running the second algorithm subset on the second split data subset based on the two shares of the second mathematical set to yield a second output subset; and combining the first output subset and the second output subset.
12. The system of claim 11, wherein a first algorithm subset from an algorithm that has been divided into a first algorithm subset and a second algorithm subset.
13. The system of claim 11, wherein the first parameter comprises a first characteristic of the first algorithm subset and wherein the second parameter comprises a second characteristic of the second algorithm subset.
14. The system of claim 11, wherein the first parameter relates to a nature of the first algorithm subset and wherein the second parameter both relate to a nature of the second algorithm subset.
15. The system of claim 11, wherein the first split data subset is generated randomly as part of the full data set.
16. The system of claim 11, wherein the second split data subset is generated randomly as part of the full data set.
17. The system of claim 11, wherein the first entity and the second entity comprise one of two physically separate computing device or two separate virtual computing devices.
18. The system of claim 11, wherein each of the first mathematical set and the second mathematical set comprise a beaver set.
19. The system of claim 11, wherein each of the first mathematical set and the second mathematical set comprise an N×M matrix.
20. The system of claim 11, wherein the running of the first algorithm subset on the first split data subset based on the two shares of the first mathematical set to yield a first output subset and the running of the second algorithm subset on the second split data subset based on the two shares of the second mathematical set to yield a second output subset occur using a memoization technique.
</claims>
</document>
