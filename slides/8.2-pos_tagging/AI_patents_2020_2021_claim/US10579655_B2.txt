<document>

<filing_date>
2018-02-07
</filing_date>

<publication_date>
2020-03-03
</publication_date>

<priority_date>
2017-05-11
</priority_date>

<ipc_classes>
G06F16/00,G06F16/31,G06F16/33,G06F17/18,G06F17/21,G06F17/27,G06F17/30,G06F40/10,G06F40/20,G06F40/30,G06N20/00,G06N5/00,G06N7/00
</ipc_classes>

<assignee>
BAIDU INTERNATIONAL TECHNOLOGY (SHENZHEN) COMPANY
</assignee>

<inventors>
JIANG, DI
HE, JINGZHOU
CHEN, ZEYU
BAO, SIQI
</inventors>

<docdb_family_id>
59776907
</docdb_family_id>

<title>
Method and apparatus for compressing topic model
</title>

<abstract>
A method comprises: acquiring a to-be-compressed topic model, wherein each line of the topic model represents a distribution of a word among respective topics; performing a format conversion on the topic model to obtain a first topic model, wherein each line of the first topic model represents a distribution of a topic among respective words; selecting any two topics from the first topic model to form a topic pair, forming a topic pair set using at least one topic pair, and determining a similarity between the two topics in each topic pair in the topic pair set; merging topic pairs having a similarity greater than a similarity threshold to generate a second topic model; and performing a format conversion on the second topic model to obtain a compressed topic model, so that each line of the compressed topic model represents a distribution of a word among the respective topics.
</abstract>

<claims>
1. A method for compressing a topic model, the method comprising: acquiring a to-be-compressed topic model, wherein each line of the topic model represents a distribution of a word among respective topics; performing a format conversion on the topic model to obtain a first topic model, wherein each line of the first topic model represents a distribution of a topic among respective words, and the respective words on the topic are sorted in a descending order according to a number of the words on the topic; selecting any two topics from the first topic model to form a topic pair, forming a topic pair set using at least one topic pair, and determining a similarity between the two topics in each topic pair in the topic pair set; merging topic pairs having a similarity greater than a similarity threshold to generate a second topic model; and performing a format conversion on the second topic model to obtain a compressed topic model, wherein each line of the compressed topic model represents a distribution of a word among the respective topics.
2. The method according to claim 1, wherein the determining a similarity between the two topics in each topic pair in the topic pair set comprises: determining a Jaccard similarity between words in the two topics of the each topic pair in the topic pair set.
3. The method according to claim 1, wherein the determining a similarity between the two topics in each topic pair in the topic pair set comprises: determining the similarity according to a repetition probability of words in the two topics of the each topic pair in the topic pair set.
4. The method according to claim 1, wherein the merging topic pairs having a similarity greater than a similarity threshold to generate a second topic model comprises: determining a disjoint topic set using union-find algorithm; and merging topics in the disjoint topic set to generate a second topic model.
5. The method according to claim 1, wherein before the performing a format conversion on the second topic model to obtain a compressed topic model, the method further comprises: for each topic in the second topic model, determining a probability distribution of each word among the topics; and deleting a word having a probability distribution less than a predetermined probability threshold from the second topic model.
6. An apparatus for compressing a topic model, the apparatus comprising: at least one processor; and a memory storing instructions, the instructions when executed by the at least one processor, cause the at least one processor to perform operations, the operations comprising: acquiring a to-be-compressed topic model, wherein each line of the topic model represents a distribution of a word among respective topics; performing a format conversion on the topic model to obtain a first topic model, wherein each line of the first topic model represents a distribution of a topic among respective words, and the respective words on the topic are sorted in a descending order according to a number of the words on the topic; selecting any two topics from the first topic model to form a topic pair, form a topic pair set using at least one topic pair, and determine a similarity between the two topics in each topic pair in the topic pair set; merging topic pairs having a similarity greater than a similarity threshold to generate a second topic model; and performing a format conversion on the second topic model to obtain a compressed topic model, wherein each line of the compressed topic model represents a distribution of a word among the respective topics.
7. The apparatus according to claim 6, wherein the determining a similarity between the two topics in each topic pair in the topic pair set comprises: determining a Jaccard similarity between words on two topics in each topic pair in the topic pair set.
8. The apparatus according to claim 6, wherein the determining a similarity between the two topics in each topic pair in the topic pair set comprises: determining the similarity according to repetition probability of words on two topics in each topic pair in the topic pair set.
9. The apparatus according to claim 6, wherein the merging topic pairs having a similarity greater than a similarity threshold to generate a second topic model comprises: determining a disjoint topic set using union-find algorithm; and merging topics in the disjoint topic set to generate a second topic model.
10. The apparatus according to claim 6, the operations further comprising: for each topic in the second topic model, determining a probability distribution of each word among the topics; and deleting a word having a probability distribution less than a predetermined probability threshold from the second topic model before performing a format conversion on the second topic model to obtain a compressed topic model.
11. A non-transitory computer readable storage medium storing a computer program, the computer program when executed by one or more processors, causes the one or more processors to perform operations, the operations comprising: acquiring a to-be-compressed topic model, wherein each line of the topic model represents a distribution of a word among respective topics; performing a format conversion on the topic model to obtain a first topic model, wherein each line of the first topic model represents a distribution of a topic among respective words, and the respective words on the topic are sorted in a descending order according to a number of the words on the topic; selecting any two topics from the first topic model to form a topic pair, forming a topic pair set using at least one topic pair, and determining a similarity between the two topics in each topic pair in the topic pair set; merging topic pairs having a similarity greater than a similarity threshold to generate a second topic model; and performing a format conversion on the second topic model to obtain a compressed topic model, wherein each line of the compressed topic model represents a distribution of a word among the respective topics.
</claims>
</document>
