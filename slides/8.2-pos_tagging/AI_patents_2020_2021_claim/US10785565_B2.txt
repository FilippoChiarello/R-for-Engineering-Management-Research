<document>

<filing_date>
2017-11-10
</filing_date>

<publication_date>
2020-09-22
</publication_date>

<priority_date>
2016-11-16
</priority_date>

<ipc_classes>
G01S1/02,G01S19/53,G10L21/0216,H04R1/40,H04R25/00,H04R3/00,H04S7/00
</ipc_classes>

<assignee>
NOKIA TECHNOLOGIES
</assignee>

<inventors>
LEPPANEN, JUSSI
MATE, SUJEET SHYAMSUNDAR
</inventors>

<docdb_family_id>
62043346
</docdb_family_id>

<title>
Distributed audio capture and mixing controlling
</title>

<abstract>
Apparatus including a processor configured to: receive an audio signal from a close microphone, wherein the audio signal is input in a spatial audio mixing, and the close microphone is associated with a first sound source; receive a beam-formed audio signal from a microphone array, wherein the beam-formed audio signal is a result of forming a beam of the microphone array directed from the microphone array towards the close microphone so as to enhance the audio signal; determine a time duration where no further sound source is active within the sound scene the first sound source; and determine a time difference, during the time duration, between the audio signal and the beam-formed audio signal to enable alignment of the audio signal and the beam-formed audio signal.
</abstract>

<claims>
1. Apparatus comprising a processor configured to: receive an audio signal from a close microphone, wherein the audio signal is input in a spatial audio mixing, and where the close microphone is associated with a first sound source of a sound scene; receive a beam-formed audio signal from a microphone array, wherein the beam-formed audio signal is a result of forming a beam of the microphone array directed from the microphone array towards the close microphone so as to enhance the audio signal; determine a time duration where no further sound source is active within the sound scene; and determine a time difference, during the time duration, between the audio signal and the beam-formed audio signal to enable alignment of the audio signal and the beam-formed audio signal.
2. The apparatus as claimed in claim 1, wherein the processor configured to receive the beam-formed audio signal from the microphone array is configured to: determine an orientation angle from the microphone array to the close microphone; and generate the beam-formed audio signal based on the determined orientation angle.
3. The apparatus as claimed in claim 2, wherein the processor is configured to determine the orientation angle from the microphone array to the close microphone based on at least one of: a satellite positioning system estimate of position of the close microphone and/or the microphone array; an inertial positioning system estimate of position of the close microphone and/or the microphone array; a radio frequency beacon system estimate of position of the close microphone and/or the microphone array; a high accuracy indoor positioning (HAIP) system estimate of position of a positioning (HAIP) tag associated with the close microphone and/or the microphone array; or a visual object tracking system estimate of position of an object associated with the close microphone and/or the microphone array.
4. The apparatus as claimed in claim 2, wherein the processor configured to generate the beam-formed audio signal is further configured to adaptively change a beam width for the beam-formed audio signal.
5. The apparatus as claimed in claim 4, wherein the processor, configured to adaptively change the beam width for the beam-formed audio signal, is configured to adaptively change the beam width for the beam-formed audio signal based on at least one of: an amplitude of the close microphone audio signal; an amplitude of the microphone array audio signal; a position of the sound source; or a variance of a position of the close microphone.
6. The apparatus as claimed in claim 1, wherein the processor, configured to determine the time duration where no further sound source is active within the sound scene, is configured to at least one of: determine the time duration where there is an absence of the further sound source within an audio scene comprising the first sound source; determine at least one further sound source within an audio scene comprising the first sound source; determine a position of the at least one further sound source; or determine, for the time duration, the position of the at least one further sound source is not between the microphone array and the first sound source.
7. The apparatus as claimed in claim 1, wherein the processor configured to determine the time difference, during the time duration, between the audio signal and the beam-formed audio signal is further configured to remove segments from the audio signal and/or the beam-formed audio signal based on a determination, for a second time duration of the beam-formed audio signal from microphone array, of a presence of at least one further sound source within the beam-formed audio signal.
8. The apparatus as claimed in claim 7, wherein the processor, configured to selectively remove segments from the audio signal and the beam-formed audio signal, is configured to: determine the second time duration; determine a further sound source time difference between the beam-formed audio signal and the audio signal by identifying within the audio signal the presence of the at least one further sound source matching the presence during the second time duration of the beam-formed audio signal; remove the time segment associated with the second time duration from the beam-formed audio signal; and remove the time segment associated with the second time duration adjusted by the further sound source time difference from the audio signal.
9. The apparatus as claimed in claim 6, wherein the processor, configured to determine the time duration where no further sound source is active within the sound scene, array and the close is configured to perform at least one of: visually determine a presence of the further sound source; determine the presence the further source based on a position estimate from a positioning system associated with the further sound source; or determine the presence of the further sound source by determining an orientation of the close microphone from the microphone array, based on directional analysis of the beam-formed audio signal, differs significantly from an expected orientation of the close microphone from the microphone from an estimate of the position of the close microphone.
10. The apparatus as claimed in claim 1, wherein the processor is further configured to mix and/or process the audio signal based on the time difference to align the audio signal and the beam-formed audio signal.
11. A method comprising: receiving an audio signal from a close microphone, wherein the audio signal is input in a spatial audio mixing, and the close microphone is associated with a first sound source of a sound scene; receiving a beam-formed audio signal from a microphone array, wherein the beam-formed audio signal is a result of forming a beam of the microphone array directed from the microphone array towards the close microphone so as to enhance the audio signal; determining a time duration where no further sound source is active within the sound scene; and determining a time difference, during the time duration, between the audio signal and the beam-formed audio signal to enable alignment of the audio signal and the beam-formed audio signal.
12. The method as claimed in claim 11, wherein receiving the beam-formed audio signal from the microphone array comprises: determining an orientation angle from the microphone array to the close microphone; and generating the beam-formed audio signal based on the determined orientation angle.
13. The method as claimed in claim 12, wherein determining the orientation angle from the microphone array to the close microphone comprises at least one of: determining a satellite positioning system estimate of position of the close microphone and/or the microphone array; determining an inertial positioning system estimate of position of the close microphone and/or the microphone array; determining a radio frequency beacon system estimate of position of the close microphone and/or the microphone array; determining a high accuracy indoor positioning (HAIP) system estimate of position of a positioning (HAIP) tag associated with the close microphone and/or the microphone array; or determining a visual object tracking system estimate of position of an object associated with the close microphone and/or the microphone array.
14. The method as claimed in claim 12, wherein generating the beam-formed audio signal further comprises adaptively changing a beam width for the beam-formed audio signal.
15. The method as claimed in claim 14, wherein adaptively changing the beam width for the beam-formed audio signal comprises adaptively changing the beam width for the beam-formed audio signal based on at least one of: an amplitude of the close microphone audio signal; an amplitude of the microphone array audio signal; a position of the sound source; or a variance of a position of the close microphone.
16. The method as claimed in claim 11, wherein determining the time duration where no further sound source is active within the sound scene array and the close microphone comprises at least one of: determining the time duration where there is an absence of the further sound source within the sound scene comprising the first sound source; determining at least one further sound source within the sound scene comprising the first sound source; determining a position of the at least one further sound source; or determining, for the time duration, that the position of the at least one further sound source is not between the microphone array and the first sound source.
17. The method as claimed in claim 11, wherein determining the time difference, during the time duration, between the audio signal and the beam-formed audio signal comprises removing segments from the audio signal and/or the beam-formed audio signal based on a determination, for a second time duration of the beam-formed audio signal from microphone array, of a presence of at least one further sound source within the beam-formed audio signal.
18. The method as claimed in claim 17, wherein selectively removing segments from the audio signal and the beam-formed audio signal comprises: determining the second time duration; determining a further sound source time difference between the beam-formed audio signal and the audio signal by identifying within the audio signal the presence of the at least one further sound source matching the presence during the second time duration of the beam-formed audio signal; removing the time segment associated with the second time duration from the beam-formed audio signal; and removing the time segment associated with the second time duration adjusted by the further sound source time difference from the audio signal.
19. The method as claimed in claim 16, wherein determining the time duration where no further sound source is active within the sound scene array and the close microphone comprises at least one of: visually determining a presence of the further sound source; determining the presence of the at least one further sound source based on a position estimate from a positioning system associated with the further sound source; or determining the presence of the further sound source by determining an orientation of the close microphone from the microphone array, based on directional analysis of the beam-formed audio signal, differs significantly from an excepted orientation of the close microphone from the microphone array from an estimate of the position of the close microphone.
20. The method as claimed in claim 11, further comprising mixing and/or processing the audio signal based on the time difference to align the audio signal and the beam-formed audio signal.
</claims>
</document>
