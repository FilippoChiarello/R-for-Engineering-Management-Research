<document>

<filing_date>
2020-01-08
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2019-01-08
</priority_date>

<ipc_classes>
B29C64/393,B33Y50/02,G01B9/02,G06N3/02,G06T7/521
</ipc_classes>

<assignee>
LNKBIT
</assignee>

<inventors>
MATUSIK WOJCIECH
CHEN, DESAI
</inventors>

<docdb_family_id>
69423439
</docdb_family_id>

<title>
DEPTH RECONSTRUCTION IN ADDITIVE FABRICATION
</title>

<abstract>
A method for determining estimated depth data for an object includes scanning the object to produce scan data corresponding to a surface region of the object using a first scanning process, configuring an artificial neural network with first configuration data corresponding to the first scanning process, and providing the scan data as an input to the configured artificial neural network to yield the estimated depth data as an output, the estimated depth data representing a location of a part of the object in the surface region.
</abstract>

<claims>
1. A method for determining estimated depth data for an object comprising: scanning the object to produce scan data corresponding to a surface region of the object using a first scanning process; configuring an artificial neural network with first configuration data corresponding to the first scanning process; and providing the scan data as an input to the configured artificial neural network to yield the estimated depth data as an output, the estimated depth data representing a location of a part of the object in the surface region.
2. The method of claim 1 wherein the object comprises an object under 3D additive fabrication according to a first fabrication process.
3. The method of claim 2 wherein the first configuration data corresponds to the first scanning process as well as the first fabrication process.
4. The method of claim 3 wherein configuring an artificial neural network with first configuration data comprising selecting said first configuration data from a set of available configuration data each associated with a different scanning and/or fabrication process.
5. The method of claim 1 further comprising: determining expected depth data for the surface region of the object; and providing the expected depth data with the scan data to the configured artificial neural network.
6. The method of claim 5 wherein the expected depth data includes a range of expected depths.
7. The method of claim 1 wherein scanning the object comprises optically scanning the object at the location on the surface of the object.
8. The method of claim 7 wherein scanning the object comprises optically scanning the object over a plurality of locations on the surface region of the object.
9. The method of method of claim 7 wherein scanning the object comprises scanning the object using optical coherence tomography.
10. The method of claim 1 wherein scanning the object further comprises processing raw scan data according to one or more of (1) a linearization procedure, (2) a spectral analysis procedure, and (3) a phase correction procedure to produce the scan data.
11. The method of claim 1 further comprising transforming the scan data from a time domain representation to a frequency domain representation prior to providing the scan data as input to the artificial neural network.
12. The method of claim 1 wherein the configured artificial neural network further yields a confidence measure associated with the estimated depth data.
13. The method of claim 1 further comprising providing scan data for a spatial neighborhood associated with the surface region of the object as input to the configured artificial neural network.
14. The method of claim 13 wherein the spatial neighborhood includes a plurality of parts of the object in the surface region.
15. A system for determining estimated depth data for an object comprising: a sensor for scanning the object to produce scan data corresponding to a surface region of the object using a first scanning process; an artificial neural network configured with first configuration data corresponding to the first scanning process, the artificial neural network configured to determine the estimated depth data representing a location of a part of the object in the surface region, the artificial neural network having one or more inputs for receiving the scan data, and an output for providing an estimated depth data.
16. A method for determining estimated depth data for an object comprising: scanning the object to produce scan data corresponding to a surface region of the object using a first scanning process; configuring a first artificial neural network with first configuration data corresponding to the first scanning process; configuring a second artificial neural network with second configuration data corresponding to the first scanning process; providing the scan data as an input to the configured first artificial neural network to yield volumetric data representing a location of a part of the object in the surface region; and providing the volumetric data to the configured second neural network to yield the estimated depth data as an output, the estimated depth data representing the location of the part of the object in the surface region.
17. The method of claim 16 further comprising: determining expected depth data for the surface region of the object; and providing the expected depth data with the scan data to the configured second artificial neural network.
18. The method of claim 17 wherein the expected depth data includes a range of expected depths.
19. A method for configuring an artificial neural network for determining estimated depth data for an object, the method comprising: determining training data comprising scan data for a plurality of object and corresponding reference depth data; processing the training data to form configuration data for an artificial neural network; and providing the training data for use in a method for deteimining estimated depth data.
</claims>
</document>
