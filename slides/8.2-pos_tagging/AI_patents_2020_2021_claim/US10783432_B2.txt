<document>

<filing_date>
2017-04-14
</filing_date>

<publication_date>
2020-09-22
</publication_date>

<priority_date>
2017-04-14
</priority_date>

<ipc_classes>
G06F17/16,G06F5/01,G06F7/544,G06N3/04,G06N3/063,G06N3/08
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
GOKMEN, TAYFUN
Ã–NEN, OGUZHAN MURAT
</inventors>

<docdb_family_id>
63790739
</docdb_family_id>

<title>
Update management for RPU array
</title>

<abstract>
A computer-implemented method and computer processing system are provided for update management for a neural network. The method includes performing an isotropic update process on the neural network using a Resistive Processing Unit. The isotropic update process uses a multiplicand and a multiplier from a multiplication operation. The performing step includes scaling the multiplicand and the multiplier to have a same order of magnitude.
</abstract>

<claims>
1. A computer-implemented method for update management for a neural network, the method comprising: performing an isotropic update process on the neural network using a Resistive Processing Unit, the isotropic update process using a multiplicand and a multiplier from a multiplication operation, wherein said performing step comprises scaling the multiplicand and the multiplier to have a same order of magnitude, further comprising translating, by one or more stochastic translators, sets of numbers corresponding to neurons of the neural network into stochastic bitstreams, wherein the scaling factor is applied to an amplification factor of the one or more stochastic translators.
2. The computer implemented method of claim 1, wherein the multiplicand and the multiplier are scaled to maintain a same product before and after the scaling.
3. The computer-implemented method of claim 1, wherein said scaling step is performed in an input conditioning process applied to inputs of the isotropic update process.
4. The computer-implemented method of claim 3, wherein the input conditioning process removes false spatial correlations resulting from a difference between orders of magnitude of the multiplicand and the multiplier.
5. The computer-implemented method of claim 1, wherein the isotropic update process is performed using only a single update cycle.
6. The computer-implemented method of claim 1, wherein the Resistive Processing Unit is configured to perform an analog vector-matrix multiplication.
7. The computer-implemented method of claim 1, wherein the isotropic update process is performed on respective ones of the stochastic bitstreams having a bit length meeting one or more predetermined criterion.
8. The computer-implemented method of claim 7, wherein the one or more predetermined criterion comprise having a smallest bitstream length.
9. The computer-implemented method of claim 1, wherein the one or more stochastic translators comprise a first stochastic translator and a second stochastic translator, and wherein said scaling step comprises multiplying an amplification factor of the first stochastic translator by the scaling factor and dividing an amplification factor of the second stochastic translator by the scaling factor.
10. The computer-implemented method of claim 1, further comprising translating, by one or more deterministic translators, sets of numbers corresponding to neurons of the neural network into deterministic bitstreams.
11. The computer-implemented method of claim 10, wherein the isotropic update process is performed on respective ones of the deterministic bitstreams having a bit length meeting one or more predetermined criterion.
12. The computer-implemented method of claim 11, wherein the one or more predetermined criterion comprise having a smallest bitstream length.
13. The computer-implemented method of claim 10, wherein the scaling factor is applied to an amplification factor of the one or more deterministic translators.
14. The computer-implemented method of claim 10, wherein the one or more deterministic translators comprise a first deterministic translator and a second deterministic translator, and wherein said scaling step comprises multiplying an amplification factor of the first deterministic translator by the scaling factor and dividing an amplification factor of the second deterministic translator by the scaling factor.
</claims>
</document>
