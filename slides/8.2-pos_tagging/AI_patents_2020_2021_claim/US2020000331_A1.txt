<document>

<filing_date>
2019-09-09
</filing_date>

<publication_date>
2020-01-02
</publication_date>

<priority_date>
2015-10-23
</priority_date>

<ipc_classes>
A61B3/00,A61B3/12,A61B3/14,G06K9/00,G06T7/00
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
CHAKRAVORTY, RAJIB
GARNAVI, RAHIL
ROY, PALLAB
</inventors>

<docdb_family_id>
58561547
</docdb_family_id>

<title>
AUTOMATICALLY DETECTING EYE TYPE IN RETINAL FUNDUS IMAGES
</title>

<abstract>
A computer-implemented method includes obtaining an image of a retinal fundus. A plurality of features is extracted from the image of the retinal fundus. The plurality of features includes at least one feature based on anatomical domain knowledge of the retinal fundus and at least one response of a pre-trained deep convolutional neural network to at least a portion of the image of the retinal fundus. The retinal fundus is determined to belong to a left eye or a right eye, based on an analysis of the plurality of features.
</abstract>

<claims>
1. A computer-implemented method, comprising: cropping a region of interest from an image of a retinal fundus; passing the region of interest through a stack of N learned convolutional layers of a pre-trained deep convolutional neural network; discarding a response of an Nth layer of the N learned convolutional layers to the region of interest; applying principal component analysis on responses of an (N-1)th layer of the N learned convolutional layers to the region of interest to generate a set of principal components; extracting an unsupervised feature of the retinal fundus from the set of principal components; and determining whether the retinal fundus belongs to a left eye or a right eye, based on an analysis of a combination of the unsupervised feature and a supervised feature of the retinal fundus.
2. The computer-implemented method of claim 1, wherein the region of interest is centered on an optic disc depicted in the image of the retinal fundus.
3. The computer-implemented method of claim 2, wherein the Nth layer is trained for one thousand classes of a training dataset, and the (N-1)th layer generates more than four thousand responses as potential unsupervised features.
4. The computer-implemented method of claim 1, wherein the determining is performed using a support vector machine that has been trained using a plurality of features including the unsupervised feature and a supervised feature of the retinal fundus.
5. The computer-implemented method of claim 4, wherein the supervised feature comprises a cross-sectional vote-based probability score for the image of the retinal fundus.
6. The computer-implemented method of claim 4, wherein the supervised feature comprises relative blood vessel densities on the left side and the right side of an optic disc depicted in the image of the retinal fundus.
7. The computer-implemented method of claim 4, wherein the supervised feature comprises an orientation of a major retinal blood vessel with respect to an optic disc depicted in the image of the retinal fundus.
8. The computer-implemented method of claim 4, wherein the supervised feature is extracted from an image of retinal blood vessels that has been segmented from the image of the retinal fundus.
9. The computer-implemented method of claim 4, wherein parameters of the support vector machine comprise C, degree, gamma, kernel, and tolerance, and the parameters are computed using a five-fold cross validation accuracy-based grid search over a validation dataset.
10. A non-transitory machine-readable storage medium encoded with instructions executable by a processor, wherein the instructions cause the processor to perform operations comprising: cropping a region of interest from an image of a retinal fundus; passing the region of interest through a stack of N learned convolutional layers of a pre-trained deep convolutional neural network; discarding a response of an Nth layer of the N learned convolutional layers to the region of interest; applying principal component analysis on responses of an (N-1)th layer of the N learned convolutional layers to the region of interest to generate a set of principal components; extracting an unsupervised feature of the retinal fundus from the set of principal components; and determining whether the retinal fundus belongs to a left eye or a right eye, based on an analysis of a combination of the unsupervised feature and a supervised feature of the retinal fundus.
11. The non-transitory machine-readable storage medium of claim 10, wherein the region of interest is centered on an optic disc depicted in the image of the retinal fundus.
12. The non-transitory machine-readable storage medium of claim 11, wherein the Nth layer is trained for one thousand classes of a training dataset, and the (N-1)th layer generates more than four thousand responses as potential unsupervised features.
13. The non-transitory machine-readable storage medium of claim 10, wherein the determining is performed using a support vector machine that has been trained using a plurality of features including the unsupervised feature and a supervised feature of the retinal fundus.
14. The non-transitory machine-readable storage medium of claim 13, wherein the supervised feature comprises a cross-sectional vote-based probability score for the image of the retinal fundus.
15. The non-transitory machine-readable storage medium of claim 13, wherein the supervised feature comprises relative blood vessel densities on the left side and the right side of an optic disc depicted in the image of the retinal fundus.
16. The non-transitory machine-readable storage medium of claim 13, wherein the supervised feature comprises an orientation of a major retinal blood vessel with respect to an optic disc depicted in the image of the retinal fundus.
17. The non-transitory machine-readable storage medium of claim 13, wherein the supervised feature is extracted from an image of retinal blood vessels that has been segmented from the image of the retinal fundus.
18. The non-transitory machine-readable storage medium of claim 13, wherein parameters of the support vector machine comprise C, degree, gamma, kernel, and tolerance, and the parameters are computed using a five-fold cross validation accuracy-based grid search over a validation dataset.
19. A system, comprising: a processor; and a non-transitory machine-readable storage medium encoded with instructions executable by the processor, wherein the instructions cause the processor to perform operations comprising: cropping a region of interest from an image of a retinal fundus; passing the region of interest through a stack of N learned convolutional layers of a pre-trained deep convolutional neural network; discarding a response of an Nth layer of the N learned convolutional layers to the region of interest; applying principal component analysis on responses of an (N-1)th layer of the N learned convolutional layers to the region of interest to generate a set of principal components; extracting an unsupervised feature of the retinal fundus from the set of principal components; and determining whether the retinal fundus belongs to a left eye or a right eye, based on an analysis of a combination of the unsupervised feature and a supervised feature of the retinal fundus.
20. The system of claim 19, wherein the Nth layer is trained for one thousand classes of a training dataset, and the (N-1)th layer generates more than four thousand responses as potential unsupervised features.
</claims>
</document>
