<document>

<filing_date>
2019-09-27
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-27
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
PANG, RUOMING
NGIAM, JIQUAN
VASUDEVAN, VIJAY
LE, QUOC V.
KORNBLITH, SIMON
PENG, DAIYI
</inventors>

<docdb_family_id>
69947474
</docdb_family_id>

<title>
TRAINING MACHINE LEARNING MODELS USING ADAPTIVE TRANSFER LEARNING
</title>

<abstract>
A method for training a target neural network on a target machine learning task is described. The method includes: obtaining a target dataset for training the target neural network on the target machine learning task, the target dataset comprising a plurality of target training examples; obtaining a source dataset for training a source neural network on a source machine learning task, the source dataset comprising a plurality of source training examples; wherein each of the target neural network and the source neural network has the same feature neural network layers having feature layer parameters, the target neural network further comprises one or more target classification layers having target classification parameters, and the source neural network further comprises one or more source classification layers having source classification parameters; generating, from the source training examples in the source dataset, a pre-training dataset using the source dataset and the target dataset so that the pre-training dataset captures features that are relevant to the target dataset; training the source neural network on the source machine learning task using the pre-training dataset to obtain first values of the feature layer parameters and the source classification parameters; initializing the feature layer parameters of the target neural network using the first values of the feature layer parameters from the training of the source neural network; and training the target neural network on the target machine learning task using the target dataset to obtain trained values of the feature layer parameters and the target classification parameters.
</abstract>

<claims>
1. A method for training a target neural network on a target machine learning task, the method comprising: obtaining a target dataset for training the target neural network on the target machine learning task, the target dataset comprising a plurality of target training examples; obtaining a source dataset for training a source neural network on a source machine learning task, the source dataset comprising a plurality of source training examples; wherein each of the target neural network and the source neural network has the same feature neural network layers having feature layer parameters, the target neural network further comprises one or more target classification layers having target classification parameters, and the source neural network further comprises one or more source classification layers having source classification parameters; generating, from the source training examples in the source dataset, a pre-training dataset using the source dataset and the target dataset so that the pre-training dataset captures features that are relevant to the target dataset; training the source neural network on the source machine learning task using the pre-training dataset to obtain first values of the feature layer parameters and the source classification parameters; initializing the feature layer parameters of the target neural network using the first values of the feature layer parameters from the training of the source neural network; and training the target neural network on the target machine learning task using the target dataset to obtain trained values of the feature layer parameters and the target classification parameters.
2. The method of claim 1, wherein each source training example in the source dataset comprises a source training input and a respective ground-truth source output, wherein the respective ground-truth source output belongs to a set of possible source outputs, and wherein each target training example in the target dataset comprises a target training input and a respective ground-truth target output.
3. The method of claim 2, wherein generating the pre-training dataset using the source dataset and the target dataset comprising: generating, for each source output in the set of possible source outputs, a respective importance weight based on the source dataset and the target training inputs, the respective importance weight indicating the importance of the source output in training the target neural network; and generating the pre-training dataset by sampling a set of source training examples from the source dataset based on the importance weights.
4. The method of claim 3, wherein generating, for each source output in the set of possible source outputs, a respective importance weight based on the source dataset and the target training inputs comprising: training a classifier neural network on the source dataset, wherein the classifier neural network is configured to receive an input and to generate for the input a respective output that belongs to the set of possible source outputs.
5. The method of claim 4, wherein generating, for each source output in the set of possible source outputs, a respective importance weight based on the source dataset and the target training inputs comprising: for each target training input in the target dataset, processing the target training input using the trained classifier neural network to generate a respective temporary predicted output for the target training input; determining, for each source output in the set of possible source outputs, a respective first rate of appearance of the source output in a set of the temporary predicted outputs with respective to the target machine learning task; determining, for each source output in the set of possible source outputs, a respective second rate of appearance of the source output in the source dataset with respective to the source machine learning task; and generating, for each source output, the respective importance weight based on the respective first rate of appearance and the respective second rate of appearance.
6. The method of claim 3, wherein the set of source training examples is sampled from the source dataset with replacement.
7. The method of claim 3, wherein the set of source training examples is sampled from the source dataset without replacement.
8. The method of claim 1, wherein training the source neural network on the source machine learning task using the pre-training dataset to obtain the first values of the feature layer parameters and the source classification parameters comprises: adjusting values of the feature layer parameters and the source classification parameters to optimize a source objective function, wherein the source objective function measures an average performance of the source neural network on the source machine learning task given the source training examples in the pre-training dataset.
9. The method of claim 1, wherein training the target neural network on the target machine learning task using the target dataset to obtain trained values of the feature layer parameters and the target classification parameters comprises: adjusting values of the feature layer parameters and the target classification parameters to optimize a target objective function, wherein the target objective function measures an average performance of the target neural network on the target machine learning task given the target training examples in the target dataset.
10. The method of claim 1, wherein the source learning task and the target machine learning task are different image classification tasks.
11. The method of claim 1, further comprising: using the trained target neural network to process a new input to generate a new output.
12. The method of claim 1, further comprising: providing the trained target neural network to a system that uses the trained neural network to process a new input to generate a new output.
13. A system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform operations comprising: obtaining a target dataset for training the target neural network on the target machine learning task, the target dataset comprising a plurality of target training examples; obtaining a source dataset for training a source neural network on a source machine learning task, the source dataset comprising a plurality of source training examples; wherein each of the target neural network and the source neural network has the same feature neural network layers having feature layer parameters, the target neural network further comprises one or more target classification layers having target classification parameters, and the source neural network further comprises one or more source classification layers having source classification parameters; generating, from the source training examples in the source dataset, a pre-training dataset using the source dataset and the target dataset so that the pre-training dataset captures features that are relevant to the target dataset; training the source neural network on the source machine learning task using the pre-training dataset to obtain first values of the feature layer parameters and the source classification parameters; initializing the feature layer parameters of the target neural network using the first values of the feature layer parameters from the training of the source neural network; and training the target neural network on the target machine learning task using the target dataset to obtain trained values of the feature layer parameters and the target classification parameters.
14. The system of claim 13, wherein each source training example in the source dataset comprises a source training input and a respective ground-truth source output, wherein the respective ground-truth source output belongs to a set of possible source outputs, and wherein each target training example in the target dataset comprises a target training input and a respective ground-truth target output.
15. The system of claim 14, wherein generating the pre-training dataset using the source dataset and the target dataset comprising: generating, for each source output in the set of possible source outputs, a respective importance weight based on the source dataset and the target training inputs, the respective importance weight indicating the importance of the source output in training the target neural network; and generating the pre-training dataset by sampling a set of source training examples from the source dataset based on the importance weights.
16. The system of claim 15, wherein generating, for each source output in the set of possible source outputs, a respective importance weight based on the source dataset and the target training inputs comprising: training a classifier neural network on the source dataset, wherein the classifier neural network is configured to receive an input and to generate an output that belongs to the set of possible source outputs.
17. The system of claim 16, wherein generating, for each source output in the set of possible source outputs, a respective importance weight based on the source dataset and the target training inputs comprising: for each target training input in the target dataset, processing the target training input using the trained classifier neural network to generate a respective temporary predicted output for the target training input; determining, for each source output in the set of possible source outputs, a respective first rate of appearance of the source output in the target machine learning task based on the temporary predicted outputs; determining, for each source output in the set of possible source outputs, a respective second rate of appearance of the source output in the source machine learning task based on the source dataset; and generating, for each source output, the respective importance weight based on the respective first rate of appearance and the respective second rate of appearance.
18. The system of claim 15, wherein the set of source training examples is sampled from the source dataset with replacement.
19. The system of claim 15, wherein the set of source training examples is sampled from the source dataset without replacement.
20. One or more non-transitory computer-readable storage media encoded with instructions that, when executed by one or more computers, cause the one or more computers to perform operations comprising: obtaining a target dataset for training the target neural network on the target machine learning task, the target dataset comprising a plurality of target training examples; obtaining a source dataset for training a source neural network on a source machine learning task, the source dataset comprising a plurality of source training examples; wherein each of the target neural network and the source neural network has the same feature neural network layers having feature layer parameters, the target neural network further comprises one or more target classification layers having target classification parameters, and the source neural network further comprises one or more source classification layers having source classification parameters; generating, from the source training examples in the source dataset, a pre-training dataset using the source dataset and the target dataset so that the pre-training dataset captures features that are relevant to the target dataset; training the source neural network on the source machine learning task using the pre-training dataset to obtain first values of the feature layer parameters and the source classification parameters; initializing the feature layer parameters of the target neural network using the first values of the feature layer parameters from the training of the source neural network; and training the target neural network on the target machine learning task using the target dataset to obtain trained values of the feature layer parameters and the target classification parameters.
</claims>
</document>
