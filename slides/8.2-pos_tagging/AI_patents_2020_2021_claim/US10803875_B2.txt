<document>

<filing_date>
2019-02-08
</filing_date>

<publication_date>
2020-10-13
</publication_date>

<priority_date>
2019-02-08
</priority_date>

<ipc_classes>
G10L17/02,G10L17/04,G10L17/06,G10L17/18
</ipc_classes>

<assignee>
NEC CORPORATION
</assignee>

<inventors>
KOSHINAKA, TAKAFUMI
OKABE, KOJI
WANG, QIONGQIONG
</inventors>

<docdb_family_id>
71946223
</docdb_family_id>

<title>
Speaker recognition system and method of using the same
</title>

<abstract>
A speaker recognition system includes a non-transitory computer readable medium configured to store instructions. The speaker recognition system further includes a processor connected to the non-transitory computer readable medium. The processor is configured to execute the instructions for extracting acoustic features from each frame of a plurality of frames in input speech data. The processor is configured to execute the instructions for calculating a saliency value for each frame of the plurality of frames using a first neural network (NN) based on the extracted acoustic features, wherein the first NN is a trained NN using speaker posteriors. The processor is configured to execute the instructions for extracting a speaker feature using the saliency value for each frame of the plurality of frames.
</abstract>

<claims>
1. A speaker recognition system comprising: a non-transitory computer readable medium configured to store instructions; and a processor connected to the non-transitory computer readable medium, wherein the processor is configured to execute the instructions for: extracting acoustic features from each frame of a plurality of frames in input speech data; calculating a saliency value for each frame of the plurality of frames using a first neural network (NN) based on the extracted acoustic features, wherein the first NN is a trained NN using speaker posteriors; and extracting a speaker feature using the saliency value for each frame of the plurality of frames.
2. The speaker recognition system of claim 1, wherein the processor is configured to execute the instructions for extracting the speaker feature using a weighted pooling process implemented using the saliency value for each frame of the plurality of frames.
3. The speaker recognition system of claim 1, wherein the processor is configured to execute the instructions for training the first NN using the speaker posteriors.
4. The speaker recognition system of claim 3, wherein the processor is configured to execute the instructions for generating the speaker posteriors using training data and speaker identification information.
5. The speaker recognition system of claim 1, wherein the processor is configured to execute the instructions for calculating the saliency value for each frame of the plurality of frames based on the a gradient of the speaker posterior for each frame of the plurality of frames based on the extracted acoustic features.
6. The speaker recognition system of claim 1, wherein the processor is configured to execute the instructions for calculating the saliency value for each frame of the plurality of frames using a first node of the first NN and a second node of the first NN, wherein a first frame of the plurality of frames output at the first node indicates the first frame has more useful information than a second frame of the plurality of frames output at the second node.
7. The speaker recognition system of claim 6, wherein the processor is configured to execute the instructions for calculating the saliency value for each frame of the plurality of frames based on the a gradient of the speaker posterior for each frame of the plurality of frames output at the first node of the first NN based on the extracted acoustic features.
8. The speaker recognition system of claim 1, wherein the processor is configured to execute the instructions for outputting an identity of a speaker of the input speech data based on the extracted speaker feature.
9. The speaker recognition system of claim 1, wherein the processor is configured to execute the instructions for matching a speaker of the input speech data to a stored speaker identification based on the extracted speaker feature.
10. The speaker recognition system of claim 1, wherein the processor is configured to execute the instructions for permitting access to a computer system in response to the extracted speaker feature matching an authorized user.
11. A speaker recognition method comprising: receiving input speech data; extracting acoustic features from each frame of a plurality of frames in the input speech data; calculating a saliency value for each frame of the plurality of frames using a first neural network (NN) based on the extracted acoustic features, wherein the first NN is a trained NN using speaker posteriors; and extracting a speaker feature using the saliency value for each frame of the plurality of frames.
12. The speaker recognition method of claim 11, wherein the extracting the speaker feature comprises using a weighted pooling process implemented using the saliency value for each frame of the plurality of frames.
13. The speaker recognition method of claim 11, further comprising training the first NN using the speaker posteriors.
14. The speaker recognition method of claim 13, further comprising generating the speaker posteriors using training data and speaker identification information.
15. The speaker recognition method of claim 11, wherein the calculating the saliency value for each frame of the plurality of frames is based on the a gradient of the speaker posterior for each frame of the plurality of frames based on the extracted acoustic features.
16. The speaker recognition method of claim 11, wherein the calculating the saliency value for each frame of the plurality of frames comprises receiving information from a first node of the first NN and from a second node of the first NN, wherein a first frame of the plurality of frames output at the first node indicates the first frame has more useful information than a second frame of the plurality of frames output at the second node.
17. The speaker recognition method of claim 16, wherein the calculating the saliency value for each frame of the plurality of frames is based on the a gradient of the speaker posterior for each frame of the plurality of frames output at the first node of the first NN based on the extracted acoustic features.
18. The speaker recognition method of claim 11, further comprising outputting an identity of a speaker of the input speech data based on the extracted speaker feature.
19. The speaker recognition method of claim 11, further comprising matching a speaker of the input speech data to a stored speaker identification based on the extracted speaker feature.
20. The speaker recognition method of claim 11, further comprising permitting access to a computer system in response to the extracted speaker feature matching an authorized user.
</claims>
</document>
