<document>

<filing_date>
2020-05-01
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2019-05-01
</priority_date>

<ipc_classes>
G06F3/01,G06F3/14,G06K9/00
</ipc_classes>

<assignee>
ACCENTURE GLOBAL SOLUTIONS
</assignee>

<inventors>
VIALE, EMMANUEL
VIDAL, RICHARD
Kameni, Laetitia
</inventors>

<docdb_family_id>
73017577
</docdb_family_id>

<title>
EMOTION SENSING ARTIFICIAL INTELLIGENCE
</title>

<abstract>
Systems, apparatuses, and methods are directed toward determining emotional states of a subject. For example, the systems, apparatuses, and methods determine one or more previous characteristics of a pupil of an eye based on image data from eye tracking sensors, determine one or more current characteristics of the pupil based on image data from the eye tracking sensors, where the one or more current characteristics include one or more of a current position of the pupil or a current size of the pupil, track movements, based on image data from the eye tracking sensors, in a position of the pupil and changes in a size of the pupil over a time period, automatically predict an emotional state based on a comparison between the one or more previous characteristics and the one or more current characteristics, the tracked movements and the tracked changes in the size and adjust a parameter of one or more hardware devices based on the predicted emotional state.
</abstract>

<claims>
We claim:
1. At least one non-transitory computer readable medium comprising a set of instructions, which when executed by one or more processors of a device, cause the one or more processors to: determine one or more previous characteristics of a pupil of an eye based on image data from eye tracking sensors; determine one or more current characteristics of the pupil based on image data from the eye tracking sensors, wherein the one or more current characteristics include one or more of a current position of the pupil or a current size of the pupil; track movements, based on image data from the eye tracking sensors, in a position of the pupil and changes in a size of the pupil over a time period; automatically predict an emotional state based on a comparison between the one or more previous characteristics and the one or more current characteristics, the tracked movements and the tracked changes in the size; and adjust a parameter of one or more hardware devices based on the predicted emotional state.
2. The at least one non-transitory computer readable medium of claim 1, wherein: the one or more previous characteristics are associated with the emotional state, and the one or more previous characteristics include one or more of a previous position of the pupil or a previous size of the pupil.
3. The at least one non-transitory computer readable medium of claim 1, wherein the set of instructions, which when executed by the one or more processors, cause the one or more processors to: identify an environmental factor; and predict the emotional state based on the environmental factor.
4. The at least one non-transitory computer readable medium of claim 1, wherein the set of instructions, which when executed by the one or more processors, cause the one or more processors to correlate the current position of the pupil and the current size of the pupil to an emotional chart that includes a valence axis and an arousal axis.
5. The at least one non-transitory computer readable medium of claim 1, wherein the adjustment of the parameter of the one or more hardware devices includes a modification to a display.
6. The at least one non-transitory computer readable medium of claim 1, wherein the set of instructions, which when executed by the one or more processors, cause the one or more processors to: calibrate an artificial intelligence model; and automatically predict, with the artificial intelligence model, the emotional state based on the comparison, the tracked movements and the tracked changes in the size.
7. The at least one non-transitory computer readable medium of claim 1, wherein the set of instructions, which when executed by the one or more processors, cause the one or more processors to: store an image in association with the emotional state; present the image to a user; and determine the one or more previous characteristics as the image is presented to a user associated with the eye.
8. A computing system, comprising: a memory; and a processor coupled to the memory, wherein the processor is configured to: determine one or more previous characteristics of a pupil of an eye based on image data from eye tracking sensors; determine one or more current characteristics of the pupil based on image data from the eye tracking sensors, wherein the one or more current characteristics include one or more of a current position of the pupil or a current size of the pupil; track movements, based on image data from the eye tracking sensors, in a position of the pupil and changes in a size of the pupil over a time period; automatically predict an emotional state based on a comparison between the one or more previous characteristics and the one or more current characteristics, the tracked movements and the tracked changes in the size; and adjust a parameter of one or more hardware devices based on the predicted emotional state.
9. The system of claim 8, wherein: the one or more previous characteristics are associated with the emotional state, and the one or more previous characteristics include one or more of a previous position of the pupil or a previous size of the pupil.
10. The system of claim 8, wherein the processor is to: identify an environmental factor; and predict the emotional state based on the environmental factor.
11. The system of claim 8, wherein the processor is to correlate the current position of the pupil and the current size of the pupil to an emotional chart that includes a valence axis and an arousal axis.
12. The system of claim 8, wherein the adjustment of the parameter of the one or more hardware devices includes a modification to a display.
13. The system of claim 8, wherein the processor is to: calibrate an artificial intelligence model; and automatically predict, with the artificial intelligence model, the emotional state based on the comparison, the tracked movements and the tracked changes in the size.
14. The system of claim 8, wherein the processor is to: store an image in association with the emotional state; present the image to a user; and determine the one or more previous characteristics as the image is presented to a user associated with the eye.
15. A method comprising: determining one or more previous characteristics of a pupil of an eye based on image data from eye tracking sensors; determining one or more current characteristics of the pupil based on image data from the eye tracking sensors, wherein the one or more current characteristics include one or more of a current position of the pupil or a current size of the pupil; tracking movements, based on image data from the eye tracking sensors, in a position of the pupil and changes in a size of the pupil over a time period; automatically predicting an emotional state based on a comparison between the one or more previous characteristics and the one or more current characteristics, the tracked movements and the tracked changes in the size; and adjusting a parameter of one or more hardware devices based on the predicted emotional state.
16. The method of claim 15, wherein: the one or more previous characteristics are associated with the emotional state, and the one or more previous characteristics include one or more of a previous position of the pupil or a previous size of the pupil.
17. The method of claim 15, further comprising: identifying an environmental factor; and predicting the emotional state based on the environmental factor.
18. The method of claim 15, further comprising: correlating the current position of the pupil and the current size of the pupil to an emotional chart that includes a valence axis and an arousal axis.
19. The method of claim 15, wherein the adjusting of the parameter of the one or more hardware devices includes modifying the display.
20. The method of claim 15, further comprising: calibrating an artificial intelligence model; and automatically predicting, with the artificial intelligence model, the emotional state based on the comparison, the tracked movements and the tracked changes in the size.
</claims>
</document>
