<document>

<filing_date>
2019-07-10
</filing_date>

<publication_date>
2020-01-16
</publication_date>

<priority_date>
2018-07-10
</priority_date>

<ipc_classes>
B25J19/02,G05D1/02,G06T1/00
</ipc_classes>

<assignee>
EMOTECH
</assignee>

<inventors>
NG, RAYMOND W.M.
MIKSIK, ONDREJ
SWIETOJANSKI, PAWEL
REDDY, SRIKANTH
</inventors>

<docdb_family_id>
63273155
</docdb_family_id>

<title>
ROBOTIC SYSTEMS
</title>

<abstract>
A robotic system is controlled. Audiovisual data representing an environment in which at least part of the robotic system is located is received via at least one camera and at least one microphone. The audiovisual data comprises a visual data component representing a visible part of the environment and an audio data component representing an audible part of the environment. A location of a sound source that emits sound that is represented in the audio data component of the audiovisual data is identified based on the audio data component of the audiovisual data. The sound source is outside the visible part of the environment and is not represented in the visual data component of the audiovisual data. Operation of a controllable element located in the environment is controlled based on the identified location of the sound source.
</abstract>

<claims>
1. A method of controlling a robotic system, the method comprising: receiving, via at least one camera and at least one microphone, audiovisual data representing an environment in which at least part of the robotic system is located, the audiovisual data comprising a visual data component representing a visible part of the environment and an audio data component representing an audible part of the environment; identifying, based on the audio data component of the audiovisual data, a location of a sound source that emits sound that is represented in the audio data component of the audiovisual data, wherein the sound source is outside the visible part of the environment and is not represented in the visual data component of the audiovisual data; and controlling operation of a controllable element located in the environment based on the identified location of the sound source.
2. A method according to claim 1, wherein the at least one microphone comprises an array of microphones comprising at least first and second microphones, wherein the sound emitted by the sound source is received at both the first and second microphones in the microphone array, and wherein the location of the sound source is identified based at least in part on differences in phase and/or intensity of the sound as received at the first and second microphones in the microphone array.
3. A method according to claim 1, wherein the identifying of the location of the sound source comprises determining a direction and/or a distance of the sound source with respect to the at least one microphone.
4. A method according to claim 1, wherein the identifying of the location of the sound source comprises using a spatial model of the environment.
5. A method according to claim 4, wherein the spatial model of the environment represents at least part of the audible part of the environment, wherein the at least part of the audible part of the environment is not also part of the visible part of the environment.
6. A method according to claim 4, comprising generating the spatial model using data received via the at least one camera and/or via the at least one microphone.
7. A method according to claim 1, comprising identifying an activity type of the audible activity.
8. A method according to claim 7, wherein the identifying of the location of the sound source is based at least in part on the identified activity type of the audible activity.
9. A method according to claim 1, wherein the controllable element is comprised in a self-propelling device and wherein the controlling of the operation of the controllable element comprises causing the self-propelling device to avoid the location of the sound source.
10. A method according to claim 1, wherein the controllable element is comprised in a self-propelling device and wherein the controlling of the operation of the controllable element comprises causing the self-propelling device to move towards the location of the sound source.
11. A method according to claim 1, comprising determining a location of at least part of the robotic system using the location of the sound source as a reference location.
12. A method according to claim 1, comprising, in response to determining that the audible activity is outside an initial field of view of the at least one camera, causing the at least one camera to be configured to have a further, different field of view.
13. A method according to claim 1, wherein controlling the operation of the controllable element comprises transmitting a control signal to the controllable element.
14. A method according to claim 1, comprising analysing the visual data component of the audiovisual data for visible activity corresponding to the audible activity.
15. A method according to claim 1, wherein the audible activity is caused by activity of a person located in the environment.
16. A method robotic system according to claim 15, comprising identifying the person.
17. A method according to claim 1, wherein the at least one camera, the at least one microphone and the at least one controllable element are all comprised in the same electronic device as each other.
18. A method according to claim 1, wherein the at least one camera, the at least one microphone and the at least one controllable element are distributed across at least two different electronic devices.
19. A method according to claim 1, wherein the at least one camera, the at least one microphone and/or the at least one controllable element is comprised in: a vacuum cleaner; a lawnmower; a smart home controller; a robotic pet; an appliance; a vehicle; and/or a robotic assistive device.
20. A method according to claim 1, wherein the controllable element is configured to control at least one environmental parameter of the environment.
21. A method according to claim 1, wherein the identified location of the sound source is a first location of the sound source, and wherein method comprises: identifying, based on at least the audio data component of the audiovisual data, a second location of the sound source; and tracking movement of the sound source based on at least the first and second locations of the sound source.
22. A method according to claim 21, wherein the second location of the sound source is within the visible part of the environment.
23. A method according to claim 1, comprising identifying, based on the audiovisual data, at least one attribute of further activity, wherein the further activity involves emission of sound by a further sound source that is within the visible part of the environment and that is represented in the visual data component of the audiovisual data.
24. A robotic system comprising a controller configured to perform a method according to claim 1.
25. A computer program arranged to perform a method according to claim 1.
</claims>
</document>
