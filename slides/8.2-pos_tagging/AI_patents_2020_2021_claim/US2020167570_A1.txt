<document>

<filing_date>
2020-01-31
</filing_date>

<publication_date>
2020-05-28
</publication_date>

<priority_date>
2018-04-26
</priority_date>

<ipc_classes>
G06K9/00,G06T17/30,G06T19/00
</ipc_classes>

<assignee>
FYUSION COMPANY
</assignee>

<inventors>
RUSU, RADU BOGDAN
HOLZER, STEFAN JOHANNES JOSEF
BEALL, CHRIS
HANCHAR, PAVEL
KAR, ABHISHEK
</inventors>

<docdb_family_id>
68290680
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR 3-D AUTO TAGGING
</title>

<abstract>
A multi-view interactive digital media representation (MVIDMR) of an object can be generated from live images of an object captured from a camera. Selectable tags can be placed at locations on the object in the MVIDMR. When the selectable tags are selected, media content can be output which shows details of the object at location where the selectable tag is placed. A machine learning algorithm can be used to automatically recognize landmarks on the object in the frames of the MVIDMR and a structure from motion calculation can be used to determine 3-D positions associated with the landmarks. A 3-D skeleton associated with the object can be assembled from the 3-D positions and projected into the frames associated with the MVIDMR. The 3-D skeleton can be used to determine the selectable tag locations in the frames of the MVIDMR of the object.
</abstract>

<claims>
1. A method comprising: processing a recording, generated using a recording device, of a first plurality of frames captured by a camera of the recording device from a video stream as the recording device moves along a trajectory such that different views of a car are captured in the first plurality of frames; generating a multi-view interactive digital media representation (MVIDMR) of the car including a second plurality of frames from the first plurality of frames wherein the different views of the car are included in each of the second plurality of frames; using a machine learning algorithm on the second plurality of frames to generate heatmaps and part affinity fields associated with 2-D pixel locations of a plurality of landmarks on the car wherein the machine learning algorithm is trained to recognize the plurality of landmarks; determining, using the heatmaps and part affinity fields, a skeleton for the car, the plurality of landmarks forming joints of the skeleton; rendering a first selectable tag into the second plurality of frames to form a third plurality of frames associated with a tagged MVIDMR wherein the first selectable tag is associated with a first landmark positioned at a first joint within the skeleton and wherein the first selectable tag is rendered into the second plurality frames relative to 2-D pixel locations corresponding to the first joint in the second plurality of frames; and causing display of, on a display device of a user, a first frame from the third plurality of frames of the tagged MVIDMR that includes the first selectable tag.
2. The method of claim 1, further comprising: receiving, from the display device, input indicating selection of the first selectable tag by the user; and in response to receiving the input, causing display of, on the display device of the user, media content associated with the first selectable.
3. The method of claim 3, wherein the landmarks are selected from the group consisting of a location on a roof of the car, a location on a side mirror on the car, a location on a tail light of the car, a location on the tires of the car and a location headlights on the car.
4. The method of claim 3, wherein the first selectable tag is associated with a damaged location on the car and wherein the media content shows one or more close-up views of the damaged location.
5. The method of claim 5, wherein the first selectable tag is associated with a damaged location on the car and wherein the media content further shows an assessment of severity of damage to the damaged location.
6. The method of claim 5, wherein the first selectable tag is associated with a damaged location on the car and wherein the media content further shows an estimate of cost of repairing damage to the damaged location.
7. The method of claim 3, wherein the first selectable tag is associated with a component or a region of the car and wherein the media content shows one or more close-up views of the component or the region of the car.
8. The method of claim 3, wherein the MVIDMR shows an interior of the car.
9. The method of claim 1, wherein the displayed tagged MVIDMR comprises a 360 degree view of the car associated with an advertisement to sell the car.
10. The method of claim 1, wherein the skeleton is a 3-D skeleton.
11. The method of claim 10, further comprising based upon a structure from motion calculation, determining 3-D positions of the joints of the 3-D skeleton.
12. The method of claim 11, wherein the structure from motion calculation includes a bundle adjustment calculation.
13. A method comprising: processing a recording, generated using a recording device, of a first plurality of frames captured by a camera of the recording device from a video stream as the recording device moves along a trajectory such that different views of an article of clothing are captured in the first plurality of frames; generating a multi-view interactive digital media representation (MVIDMR) of the article of clothing including a second plurality of frames from the first plurality of frames wherein the different views of the article of clothing are included in each of the second plurality of frames; using a machine learning algorithm on the second plurality of frames to generate heatmaps and part affinity fields associated with 2-D pixel locations of a plurality of landmarks on the article of clothing wherein the machine learning algorithm is trained to recognize the plurality of landmarks; determining, using the heatmaps and part affinity fields, a skeleton for the article of clothing, the plurality of landmarks forming joints of the skeleton; rendering a first selectable tag into the second plurality of frames to form a third plurality of frames associated with a tagged MVIDMR wherein the first selectable tag is associated with a first landmark positioned at a first joint within the skeleton and wherein the first selectable tag is rendered into the second plurality frames relative to 2-D pixel locations corresponding to the first joint in the second plurality of frames; and causing display of, on a display device of a user, a first frame from the third plurality of frames of the tagged MVIDMR that includes the first selectable tag.
14. The method of claim 13, wherein the first selectable tag highlights a portion of the article of clothing.
15. The method of claim 13, wherein the tagged MVIDMR is generated in association with an advertisement for the article of clothing.
16. The method of claim 15, wherein the multi-view interactive digital media representation of the object is displayed in association with a selection allowing the person to purchase the article of clothing.
17. The method of claim 13, wherein the first selectable tag highlights a price of the article of clothing.
18. The method of claim 13, wherein the skeleton is a 3-D skeleton.
19. The method of claim 18, further comprising based upon a structure from motion calculation, determining 3-D positions of the joints of the 3-D skeleton.
20. The method of claim 19, wherein the structure from motion calculation includes a bundle adjustment calculation.
</claims>
</document>
