<document>

<filing_date>
2020-02-04
</filing_date>

<publication_date>
2020-08-13
</publication_date>

<priority_date>
2019-02-04
</priority_date>

<ipc_classes>
G06F9/00,G06N3/00
</ipc_classes>

<assignee>
PATHTRONIC
</assignee>

<inventors>
JYOTHI, VINAYAKA
KUMAR ADDEPALLI, SATEESH
HOOVAYYA POOJARI, ASHIK
</inventors>

<docdb_family_id>
71837521
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR ARTIFICIAL INTELLIGENCE WITH A FLEXIBLE HARDWARE PROCESSING FRAMEWORK
</title>

<abstract>
An artificial intelligence (AI) system is disclosed. The AI system provides an AI system lane processing chain, at least one AI processing block, a local memory, a hardware sequencer, and a lane composer. Each of the at least one AI processing block, the local memory coupled to the AI system lane processing chain, the hardware sequencer coupled to the AI system lane processing chain, and the lane composer is coupled to the AI system lane processing chain. The AI system lane processing chain is dynamically created by the lane composer.
</abstract>

<claims>
What is claimed is:
1. An artificial intelligence (AI) system lane, comprising:
an AI system lane processing chain;
at least one AI processing block;
a local memory;
a hardware sequencer; and
a lane composer;
wherein each of the at least one AI processing block, the local memory coupled to the AI system lane processing chain, the hardware sequencer coupled to the AI system lane processing chain, and the lane composer is coupled to the AI system lane processing chain; and
wherein the AI system lane processing chain is dynamically created by the lane composer.
2. The AI system lane of claim 1, wherein the AI system lane processing chain is dynamically configured by the lane composer in a forward propagation chain to execute an AI solution model inference.
3. The AI system lane of claim 1, wherein the AI system lane processing chain is dynamically configured by the lane composer in a backward propagation chain to execute an AI solution model training.
4. The AI system lane of claim 1, wherein the AI system lane processing chain is dynamically configured by the lane composer in a forward propagation chain and a backward propagation chain to execute AI solution model inference and AI solution model training.
5. The AI system lane of claim 1, further comprising a lane maintamer coupled to the lane composer, wherein the lane composer and the lane maintamer are configured to dynamically update and destroy lanes with a lane hardware framework module through dynamic expansion or contraction of the AI system lane processing chain and parametnzation.
6. The AI system lane of claim 1, further comprising an AI processing hardware orchestrator coupled to the hardware sequencer, wherein the AI processing hardware orchestrator is configured to dynamically trigger the AI system lane composer to enable and trigger the hardware sequencer to execute the AI system lane processing chain in a real-time and continuous manner.
7. The AI system lane of claim 1, wherein the AI processing block comprises at least one of a convolutional neural network (CNN), a fully connected (FC) neural network, a long short term memory (LSTM), a recurrent neural network (RNN), a MaxPool, a AvgPool, a normalization, an activation, a SoftMax, a sorting, a classification, a decision, a rules based decisions, and/or a geo mapping foundational blocks/engines/elements, or any combination thereof.
8. The AI system lane of claim 1, wherein the AI processing block comprises at least one or more AI processing functions based on user inputs.
9. The AI system lane of claim 1, further comprising a security policy engine coupled to the AI system lane processing chain.
10. The AI system lane of claim 9, wherein the security policy engine comprises at least one security programmable logic unit (S-PLU) configured to:
process security related features;
provide security' to the AI system lane; and
enable a range of AI driven security applications.
11. The AI system lane of claim 1, further comprising at least one adaptive intelligent processing logic unit (ADI-PLU) coupled to the AT system lane processing chain.
12. An artificial intelligence (AI) system multilane parallel hardware AI processor, comprising multiple lanes as defined in any one of claims 1-11, wherein the multiple lanes are configured in a parallel and pipelined manner.
13. A virtual artificial intelligence (AI) system multilane, comprising:
a virtual AI system multilane processing chain; at least two A! system lanes;
a local memory;
an Ai processing hardware orchestrator; and
a virtual lane maintainer;
a virtual lane composer;
wherein the virtual AI system multi lane processing chain, the at least one AI system lane, the local memory , the AI processing hardware orchestrator, the virtual lane maintainer, and the virtual lane composer are coupled to the virtual AI system multilane processing chain;
wherein an AI solution model calculation is mapped to the at least two AI system lanes; and
wherein each element of tire virtual AI system multilane processing chain is configured via a virtual lane maintainer and the virtual lane composer.
14. The virtual AI system of claim of claim 13, wherein the virtual lane composer is configured to execute an AI solution model fine grain processing behavior and structure of convolutional neural network (CNN) engine and a fully connected (FC) neural network engine
15. The virtual AI system of claim of claim 13, wherein the AI processing hardware orchestrator is configured to dynamically trigger the virtual lane composer to enable and trigger a hardware sequencer to execute the virtual AI system multilane processing chain in a real-time and continuous manner.
16. The virtual AI system of claim of claim 13, further comprising an uber orchestrator coupled to the AI processing hardware orchestrator, wherein the uber orchestrator is configured to trigger the AI processing hardware orchestrator of at least one of the at least two AI system lanes that participate in executing an AI solution model.
17. The virtual AI system of claim of claim 13, wherein the AI processing hardware orchestrator comprises a hardware execution sequencer to execute the virtual AI system multilane processing chain.
18. The virtual AI system of claim of claim 13, further comprising a data fuser configured to concatenate, hyper map or digest results received from different AI system lanes that are aligned in the frequency, time and space domains.
19. The virtual AI system of claim of claim 13, further comprising at least one AI processing block; coupled to the virtual AI system multilane processing chain.
20. The virtual AI system of claim 19, wherein the Af processing block comprises at least one of a convolutional neural network (CNN), a fully connected (FC) neural network, a long short term memory (LSTM), a recurrent neural network (RNN), a MaxPool, a AvgPool, a normalization, an activation, a SoftMax, a sorting, a classification, a decision, a rules based decisions, and/or a geo mapping foundational blocks/engines/elements, or any combination thereof.
21. The virtual AI system of claim 19, wherein the Af processing block comprises at least one or more AI processing functions based on user inputs.
22. The virtual AI system of claim 13, further comprising a security policy engine coupled to the virtual AI system multilane processing chain.
23. The virtual AI system lane of claim 22, wherein the security policy engine comprises at least one security programmable logic unit (S-PLU) configured to:
process security related features;
provide security to the AI system lane; and
enable a range of AI driven security7 applications.
24. The virtual AI system lane of claim 13, further comprising at least one adaptive intelligent processing logic unit (ADI-PLU) coupled to the AI system lane processing chain.
</claims>
</document>
