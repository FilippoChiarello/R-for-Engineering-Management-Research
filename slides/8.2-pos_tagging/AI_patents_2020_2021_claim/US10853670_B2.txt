<document>

<filing_date>
2018-11-21
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2018-11-21
</priority_date>

<ipc_classes>
G01C22/00,G05D1/00,G05D1/02,G06K9/00,G06K9/62,G06N3/04,G06T7/73
</ipc_classes>

<assignee>
FORD GLOBAL TECHNOLOGIES
</assignee>

<inventors>
DAEHLER, LEDA
JAIN, JINESH J
PUSKORIUS GINTARAS VINCENT
SHOLINGAR, GAUTHAM
</inventors>

<docdb_family_id>
70545919
</docdb_family_id>

<title>
Road surface characterization using pose observations of adjacent vehicles
</title>

<abstract>
A computing system can crop an image based on a width, height and location of a first vehicle in the image. The computing system can estimate a pose of the first vehicle based on inputting the cropped image and the width, height and location of the first vehicle into a deep neural network. The computing system can then operate a second vehicle based on the estimated pose. The computing system may train a model to identify a type and a location of a hazard according to the estimated pose, the hazard being such things as ice, mud, pothole, or other hazard. The model may be used by an autonomous vehicle to identify and avoid hazards or to provide drive assistance alerts.
</abstract>

<claims>
1. A method comprising, by a computer system: receiving training data entries, each entry including a video segment annotated with a vehicle pose and a hazard type; training a first deep neural network (DNN) to output vehicle pose estimates according to the training data entries; training a second DNN using the training data entries to classify a hazard according to the vehicle pose estimates; and training the second DNN using the training data entries to identify a location of the hazard according to the vehicle pose estimates and derivatives of the vehicle pose estimates.
2. The method of claim 1, wherein the vehicle pose estimates each include x, y, z, pitch, yaw, and roll estimates.
3. The method of claim 1, wherein the second DNN is a recurrent neural network.
4. The method of claim 1, wherein training the second DNN using the training data entries to classify the hazard according to the vehicle pose estimates comprises training the second DNN to classify the hazard as at least one of a pothole, ice, mud, gravel, a bump, an uneven road surface, dirt, and a stray object.
5. The method of claim 1, further comprising programming a vehicle controller to use the first DNN and the second DNN fOr hazard detection.
6. A system comprising one or more processing devices and one or more memory devices coupled to the one or more processing devices, the one or more memory devices storing executable code effective to cause the one or more processing devices to: receive training data entries, each entry including a video segment annotated with a vehicle pose and a hazard type; train a first deep neural network (DNN) to output vehicle pose estimates according to the training data entries; and train a second DNN to classify a hazard according to the training data entries and the vehicle pose estimates, wherein the executable code is further effective to cause the one or more processing devices to train the second DNN using the training data entries to identify a location of the hazard according to the vehicle pose estimates, and derivatives of the vehicle pose estimates.
7. The system of claim 6, wherein the vehicle pose estimates each include x, y, z, pitch, yaw, and roll estimates.
8. The system of claim 6, wherein the second DNN is a recurrent neural network.
9. The system of claim 6, wherein the executable code is further effective to cause the one or more processing devices to train the second DNN using the training, data entries to classify the hazard according to the vehicle pose estimates by training the second DNN to classify the hazard as at least one of a pothole, ice, mud, gravel, a bump, an uneven road surface, dirt, and a stray object.
10. The system of claim 6, wherein the executable code is further effective to cause the one or more processing devices to program a vehicle controller to use the first DNN and the second DNN for hazard detection.
11. A method comprising, by a computer system: receiving training data entries, each entry including a video segment captured by a camera mounted to a first vehicle and annotated with a vehicle pose of a second vehicle visible in the video segment and a hazard type being encountered by the second vehicle visible in the video segment; training a first deep neural network (DNN) using the training data entries to output a vehicle pose estimate for a third vehicle visible in video data captured by a camera mounted to a fourth vehicle; and training a second DNN using the training data entries to classify a hazard encountered by the third vehicle according to the vehicle pose estimate for the third vehicle.
12. The method of claim 11, further comprising training the second DNN using the training data entries to identify a location of the hazard encountered by the third vehicle according to the vehicle pose estimates.
13. The method of claim 11, further comprising training the second DNN using the training data entries to identify a location of the hazard according to the vehicle pose estimates and derivatives of the vehicle pose estimates.
14. The method of claim 11, wherein the vehicle pose estimate each include x, y, z, pitch, yaw, and roll estimates.
15. The method of claim 11, wherein the second DNN is a recurrent neural network.
16. The method of claim 11, wherein training the second DNN using the training data entries to classify the hazard according to the training data entries comprises training the second DNN to classify the hazard as at least one of a pothole, ice, mud, gravel, a bump, an uneven road surface, dirt, and a stray object.
17. The method of claim 11, further comprising programming a vehicle controller to use the first DNN and the second DNN for hazard detection.
</claims>
</document>
