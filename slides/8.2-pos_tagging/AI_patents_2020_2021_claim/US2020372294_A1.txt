<document>

<filing_date>
2020-05-21
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2019-05-23
</priority_date>

<ipc_classes>
G06F16/71,G06F16/735,G06K9/00,G06K9/38,G06K9/40,G06K9/46,G06K9/62,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
Webkontrol, Inc.
</assignee>

<inventors>
Koval, Pavel
Valigourskaia, Olga
</inventors>

<docdb_family_id>
73456821
</docdb_family_id>

<title>
Video content indexing and searching
</title>

<abstract>
A method of indexing and searching for video content is provided. For each frame of a first plurality of frames, a first global feature and a first plurality of local features may be identified. The first plurality of local features may be clustered around a first plurality of cluster centers. The first plurality of local features may be converted into a first plurality of binary signatures. An index that maps the first plurality of cluster centers and the first plurality of binary signatures to the first plurality of frames may be generated. A search request associated with a second video may be received and its direct and indirect features may be identified. The identified features of the second video may be compared against the index and a candidate video may be selected as a result of the search request.
</abstract>

<claims>
1. A method comprising: dividing a decoded first video into a first plurality of frames; discarding at least one frame from the first plurality of frames, wherein a first color histogram corresponding to the at least one frame is different from a second color histogram corresponding to a reference frame of the first plurality of frames by at least a threshold value; for each remaining frame of the first plurality of frames in the first video, identifying: a first global feature, and a first plurality of local features; clustering the first plurality of local features around a first plurality of cluster centers; converting, based on the first plurality of cluster centers, the first plurality of local features and into a first plurality of binary signatures; generating an index that maps the first plurality of cluster centers and the first plurality of binary signatures to the first plurality of frames; receiving a search request associated with a second video; identifying, for a frame in the second video, identifying a second global feature and a second plurality of local features; identifying, for the frame in the second video and based on the second plurality of local features, a second cluster center; converting, for the frame in the second video and based on the second cluster center, the second plurality of local features into a second plurality of binary signatures; and selecting, from the index and based on the second cluster center and the second plurality of binary signatures, a candidate video.
2. 2-3. (canceled)
4. The method of claim 1, wherein the dividing the first video into the first plurality of frames comprises applying a filter to the first plurality of frames to suppress noise.
5. The method of claim 4, wherein the filter comprises at least a Gaussian blur filter.
6. The method of claim 4, wherein the dividing the first video into the first plurality of frames comprises rejecting an edge area of a frame in the first plurality of frames, wherein the edge area has a brightness value below a threshold.
7. The method of claim 1, wherein the first global feature, for each remaining frame of the first plurality of frames in the first video, is identified by using a convoluted neural network.
8. The method of claim 1, wherein the first global feature comprises vectors that uniquely identify each frame of the first plurality of frames in the first video.
9. The method of claim 1, wherein the first plurality of local features comprise at least a color feature or a gradient.
10. The method of claim 1, wherein each of the first plurality of local features corresponds to a respective coordinate location in a corresponding frame of the first plurality of frames.
11. The method of claim 1, wherein the index comprises a hybrid structure based on at least two of locality-sensitive hashing, a randomized k-d tree, or a hierarchical k-means tree.
12. The method of claim 1, wherein clustering the first plurality of local features around the first plurality of cluster centers comprises: identifying, among the first plurality of local features, a subset of local features having descriptors that are proximate to each other above a threshold, and identifying a cluster center that is a coordinate-wise mean of the descriptors of the subset of local features.
13. The method of claim 1, wherein converting the first plurality of local features into the first plurality of binary signatures comprises: projecting first descriptors of the first plurality of local features onto second descriptors by using a projection matrix, wherein each of the second descriptors has a smaller dimension than a corresponding descriptor of the first descriptors, selecting a median value of the second descriptors, and performing coordinate-wise binarization of a vector difference between the second descriptors and the median value.
14. The method of claim 1, wherein each of the first plurality of binary signatures comprises a locality-sensitive hash of a position of a corresponding local feature, relative to a corresponding cluster center of the first plurality of cluster centers.
15. The method of claim 1, wherein the frame in the second video is a key frame.
16. The method of claim 1, wherein the second cluster center is identified using a bag-of-words model.
17. The method of claim 1, wherein selecting the candidate video comprises: identifying, from the index and based on the second cluster center and the second plurality of binary signatures, a plurality of candidate videos for the frame in the second video; ranking the plurality of candidate videos in relation to the frame in the second video; removing, from the plurality of candidate videos, at least one candidate video that does not satisfy a threshold condition; assigning votes to the plurality of candidate videos based on histogram cells associated with the plurality of candidate videos in relation to the frame of the second video; and selecting, among the plurality of candidate videos, the candidate video that has a highest vote.
18. The method of claim 17, wherein the plurality of candidate videos are identified using a nearest neighbor search.
19. A system comprising: a processor; and memory storing instructions which, when executed by the processor, cause the system to perform operations comprising: dividing a decoded first video into a first plurality of frames; discarding at least one frame from the first plurality of frames, wherein a first color histogram corresponding to the at least one frame is different from a second color histogram corresponding to a reference frame of the first plurality of frames by at least a threshold value; for each remaining frame of the first plurality of frames in the first video, identifying: a first global feature, and a first plurality of local features; clustering the first plurality of local features around a first plurality of cluster centers; converting, based on the first plurality of cluster centers, the first plurality of local features and into a first plurality of binary signatures; generating an index that maps the first plurality of cluster centers and the first plurality of binary signatures to the first plurality of frames; receiving a search request associated with a second video; identifying, for a frame in the second video, identifying a second global feature and a second plurality of local features; identifying, for the frame in the second video and based on the second plurality of local features, a second cluster center; converting, for the frame in the second video and based on the second cluster center, the second plurality of local features into a second plurality of binary signatures; and selecting, from the index and based on the second cluster center and the second plurality of binary signatures, a candidate video.
20. A non-transitory computer-readable storage medium storing instructions which, when executed by a processor, cause the processor to perform operations comprising: dividing a decoded first video into a first plurality of frames; discarding at least one frame from the first plurality of frames, wherein a first color histogram corresponding to the at least one frame is different from a second color histogram corresponding to a reference frame of the first plurality of frames by at least a threshold value; for each remaining frame of the first plurality of frames in the first video, identifying: a first global feature, and a first plurality of local features; clustering the first plurality of local features around a first plurality of cluster centers; converting, based on the first plurality of cluster centers, the first plurality of local features and into a first plurality of binary signatures; generating an index that maps the first plurality of cluster centers and the first plurality of binary signatures to the first plurality of frames; receiving a search request associated with a second video; identifying, for a frame in the second video, identifying a second global feature and a second plurality of local features; identifying, for the frame in the second video and based on the second plurality of local features, a second cluster center; converting, for the frame in the second video and based on the second cluster center, the second plurality of local features into a second plurality of binary signatures; and selecting, from the index and based on the second cluster center and the second plurality of binary signatures, a candidate video.
21. A method comprising: dividing a decoded first video into a first plurality of frames; applying a filter to the first plurality of frames to reject an edge area of a frame in the first plurality of frames, wherein the edge area has a brightness value below a threshold; for each frame of the first plurality of frames in the first video, identifying: a first global feature, and a first plurality of local features; clustering the first plurality of local features around a first plurality of cluster centers; converting, based on the first plurality of cluster centers, the first plurality of local features and into a first plurality of binary signatures; generating an index that maps the first plurality of cluster centers and the first plurality of binary signatures to the first plurality of frames; receiving a search request associated with a second video; identifying, for a frame in the second video, identifying a second global feature and a second plurality of local features; identifying, for the frame in the second video and based on the second plurality of local features, a second cluster center; converting, for the frame in the second video and based on the second cluster center, the second plurality of local features into a second plurality of binary signatures; and selecting, from the index and based on the second cluster center and the second plurality of binary signatures, a candidate video.
22. A method comprising: for each frame of a first plurality of frames in a first video, identifying: a first global feature, and a first plurality of local features; clustering the first plurality of local features around a first plurality of cluster centers, wherein the clustering comprises: identifying, among the first plurality of local features, a subset of local features having descriptors that are proximate to each other above a threshold, and identifying a cluster center that is a coordinate-wise mean of the descriptors of the subset of local features; converting, based on the first plurality of cluster centers, the first plurality of local features and into a first plurality of binary signatures; generating an index that maps the first plurality of cluster centers and the first plurality of binary signatures to the first plurality of frames; receiving a search request associated with a second video; identifying, for a frame in the second video, identifying a second global feature and a second plurality of local features; identifying, for the frame in the second video and based on the second plurality of local features, a second cluster center; converting, for the frame in the second video and based on the second cluster center, the second plurality of local features into a second plurality of binary signatures; and selecting, from the index and based on the second cluster center and the second plurality of binary signatures, a candidate video.
23. A method comprising: for each frame of a first plurality of frames in a first video, identifying: a first global feature, and a first plurality of local features; clustering the first plurality of local features around a first plurality of cluster centers; converting, based on the first plurality of cluster centers, the first plurality of local features and into a first plurality of binary signatures, wherein the converting comprises: projecting first descriptors of the first plurality of local features onto second descriptors by using a projection matrix, wherein each of the second descriptors has a smaller dimension than a corresponding descriptor of the first descriptors, selecting a median value of the second descriptors, and performing coordinate-wise binarization of a vector difference between the second descriptors and the median value; generating an index that maps the first plurality of cluster centers and the first plurality of binary signatures to the first plurality of frames; receiving a search request associated with a second video; identifying, for a frame in the second video, identifying a second global feature and a second plurality of local features; identifying, for the frame in the second video and based on the second plurality of local features, a second cluster center; converting, for the frame in the second video and based on the second cluster center, the second plurality of local features into a second plurality of binary signatures; and selecting, from the index and based on the second cluster center and the second plurality of binary signatures, a candidate video.
24. A method comprising: for each frame of a first plurality of frames in a first video, identifying: a first global feature, and a first plurality of local features; clustering the first plurality of local features around a first plurality of cluster centers; converting, based on the first plurality of cluster centers, the first plurality of local features and into a first plurality of binary signatures; generating an index that maps the first plurality of cluster centers and the first plurality of binary signatures to the first plurality of frames; receiving a search request associated with a second video; identifying, for a frame in the second video, identifying a second global feature and a second plurality of local features; identifying, for the frame in the second video and based on the second plurality of local features, a second cluster center; converting, for the frame in the second video and based on the second cluster center, the second plurality of local features into a second plurality of binary signatures; and selecting, from the index and based on the second cluster center and the second plurality of binary signatures, a candidate video, wherein the selecting comprises: identifying, from the index and based on the second cluster center and the second plurality of binary signatures, a plurality of candidate videos for the frame in the second video; ranking the plurality of candidate videos in relation to the frame in the second video; removing, from the plurality of candidate videos, at least one candidate video that does not satisfy a threshold condition; assigning votes to the plurality of candidate videos based on histogram cells associated with the plurality of candidate videos in relation to the frame of the second video; and selecting, among the plurality of candidate videos, the candidate video that has a highest vote.
</claims>
</document>
