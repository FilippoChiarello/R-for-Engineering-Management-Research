<document>

<filing_date>
2018-09-28
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-28
</priority_date>

<ipc_classes>
G06F16/2452,G06F16/33,G06F16/901,G06F40/30,G06N3/04
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
SHEININ, VADIM
WU, LINGFEI
XU, KUN
WANG, ZHIGUO
</inventors>

<docdb_family_id>
69945914
</docdb_family_id>

<title>
Personalized interactive semantic parsing using a graph-to-sequence model
</title>

<abstract>
A semantic parsing method using a graph-to-sequence model, system, and computer program product include generating a syntactic graph for a sentence, generating node embeddings for each node based on other nodes the each node is connected to in the syntactic graph, generating a graph embedding over the node embeddings, performing attention-based recurrent neural network (RNN) decoding of the graph embedding and the node embeddings, and providing a logical translation of the sentence based on the decoding.
</abstract>

<claims>
1. A computer-implemented semantic parsing method using a graph-to-sequence model, the method comprising: generating a syntactic graph for a sentence; generating node embeddings for each node based on other nodes the each node is connected to in the syntactic graph; generating a graph embedding over the node embeddings; performing an attention-based recurrent neural network (RNN) decoding of the graph embedding and the node embeddings; and providing a logical translation of the sentence based on the decoding.
2. The computer-implemented method of claim 1, wherein the generating the graph embedding generates the graph embedding by performing max-pooling over the node embeddings.
3. The computer-implemented method of claim 1, wherein the generating the graph embedding generates the graph embedding by creating an additional node and performing node embedding for the additional node as though the additional node is connected to all other nodes of the syntactic graph.
4. The computer-implemented method of claim 1, further comprising querying a user to determine an error for the logical translation of the sentence.
5. The computer-implemented method of claim 4, wherein, if the user returns the error for the logical translation of the sentence, repeating the generating the node embeddings, the generating the graph embedding, and the performing the attention-based recurrent neural network (RNN) decoding to produce a second logical translation.
6. The computer-implemented method of claim 1, wherein the performing the attention-based recurrent neural network (RNN) decoding calculates a context vector to capture an attention the generating the node embeddings and the generating the graph embedding.
7. The computer-implemented method of claim 1, wherein the syntactic graph represents sentence level features, dependency features, and constituency features.
8. The computer-implemented method of claim 1, embodied in a cloud-computing environment.
9. A computer program product for semantic parsing using a graph-to-sequence model, the computer program product comprising a computer-readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform: generating a syntactic graph for a sentence; generating node embeddings for each node based on other nodes the each node is connected to in the syntactic graph; generating a graph embedding over the node embeddings; performing an attention-based recurrent neural network (RNN) decoding of the graph embedding and the node embeddings; and providing a logical translation of the sentence based on the decoding.
10. The computer program product of claim 9, wherein the generating the graph embedding generates the graph embedding by performing max-pooling over the node embeddings.
11. The computer program product of claim 9, wherein the generating the graph embedding generates the graph embedding by creating an additional node and performing node embedding for the additional node as though the additional node is connected to all other odes of the syntactic graph.
12. The computer program product of claim 9, further comprising querying a user to determine an error for the logical translation of the sentence.
13. The computer program product of claim 12, wherein, if the user returns the error for the logical translation of the sentence, repeating the generating the node embeddings, the generating the graph embedding, and the performing the attention-based recurrent neural network (RNN) decoding to produce a second logical translation.
14. The computer program product of claim 9, wherein the performing the attention-based recurrent neural network (RNN) decoding calculates a context vector to capture an attention of the generating the node embeddings and the generating the graph embedding.
15. The computer program product of claim 9, wherein the syntactic graph represents sentence level features, dependency features, and constituency features.
16. A semantic parsing system using a graph-to-sequence model, the system comprising: a processor; and a memory, the memory storing instructions to cause the processor to perform: generating a syntactic graph that represents sentence level features, dependency features, and constituency features for a sentence; generating node embeddings for each node based on other nodes the each node is connected to in the syntactic graph; generating a graph embedding over the node embeddings; performing attention-based recurrent neural network (RNN) decoding of the gaph embedding and the node embeddings; and providing a logical translation of the sentence based on the decoding.
17. The system of claim 16, wherein the generating the graph embedding generates the gaph embedding by performing max-pooling over the node embeddings.
18. The system of claim 16, wherein the generating the graph embedding generates the graph embedding by creating an additional node and performing node embedding for the additional node as though the additional node is connected to all other nodes of the syntactic graph.
19. The system of claim 16, wherein the syntactic graph represents sentence level features, dependency features, and constituency features.
20. The system of claim 14, embodied in a cloud-computing environment.
</claims>
</document>
