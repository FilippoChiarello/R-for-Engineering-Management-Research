<document>

<filing_date>
2019-12-09
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-07
</priority_date>

<ipc_classes>
G06K9/46,G06K9/62,G06N3/08,H04N5/232
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
CHOI, JUNKWON
JUNG, DONGJIN
KANG, SANGKYU
HAN, KYUCHUN
</inventors>

<docdb_family_id>
70972576
</docdb_family_id>

<title>
ELECTRONIC APPARATUS, CONTROLLING METHOD OF ELECTRONIC APPARATUS, AND COMPUTER READABLE MEDIUM
</title>

<abstract>
An electronic apparatus is provided. The electronic apparatus includes: a camera; a processor configured to control the camera; and a memory configured to be electrically connected to the processor and to store a network model trained to determine a degree of matching between an input image frame and predetermined feature information, wherein the memory stores at least one instruction, and wherein the processor is configured, by executing the at least one instruction, to: identify a representative image frame based on a degree of matching obtained by applying image frames, selected from among a plurality of image frames, to the trained network model, while the plurality of image frames are captured through the camera, identify a best image frame based on a degree of matching obtained by applying image frames within a specific section including the identified representative image frame, to the trained network model, from among the plurality of image frames, and provide the identified best image frame.
</abstract>

<claims>
1. An electronic apparatus comprising: a camera; a processor configured to control the camera; and a memory configured to be electrically connected to the processor and to store a network model trained to determine a degree of matching between an input image frame and predetermined feature information, wherein the memory stores at least one instruction, and wherein the processor is configured, by executing the at least one instruction, to: identify a representative image frame based on a degree of matching obtained by applying image frames, selected from among a plurality of image frames, to the trained network model, while the plurality of image frames are captured through the camera, identify a best image frame based on a degree of matching obtained by applying image frames within a specific section including the identified representative image frame, to the trained network model, from among the plurality of image frames, and provide the identified best image frame.
2. The electronic apparatus as claimed in claim 1, wherein: the selected image frames include image frames captured at a constant time interval among the plurality of image frames; and the constant time interval is determined based on a determination speed of the trained network model.
3. The electronic apparatus as claimed in claim 1, wherein the processor is further configured to execute the at least one instruction to: obtain, for each of the selected image frames, a score corresponding to the degree of matching by applying the selected image frames to the trained network model; and identify the representative image frame having a highest score among image frames in which the obtained score is greater than or equal to a predetermined threshold.
4. The electronic apparatus as claimed in claim 1, wherein the processor is further configured to execute the at least one instruction to: obtain, for each of the image frames within the specific section, a score corresponding to the degree of matching by applying the image frames within the specific section to the trained network model; and identify the best image frame as having a highest score among the obtained scores.
5. The electronic apparatus as claimed in claim 1, wherein the processor is further configured to execute the at least one instruction to: obtain a plurality of image frames of low quality by lowering a resolution of the plurality of image frames; identify a representative image frame of low quality by applying image frames, selected from among the plurality of image frames of low quality, to the trained network model; and identify the best image frame by applying the image frames within the specific section including the representative image frame corresponding to the representative image frame of low quality, from among the plurality of image frames, to the trained network model.
6. The electronic apparatus as claimed in claim 1, wherein the processor is further configured to execute the at least one instruction to: delete image frames before a first image frame among the plurality of image frames, based on a score corresponding to the degree of matching of the first image frame among the selected image frames being less than a predetermined threshold; and identify the first image frame as the representative image frame, based on the score of the first image frame being greater than or equal to the predetermined threshold.
7. The electronic apparatus as claimed in claim 6, wherein the processor is further configured to execute the at least one instruction to: delete the image frames before the first image frame among the plurality of image frames, based on the score of the first image frame being greater than or equal to the predetermined threshold, and a score corresponding to a degree of matching of a second image frame following the first image frame among the selected image frames being greater than the score of the first image frame; and identify the second image frame as the representative image frame.
8. The electronic apparatus as claimed in claim 1, wherein the processor is further configured to execute the at least one instruction to: divide the plurality of image frames into a plurality of events based on the degree of matching of the selected image frames; and identify the best image frame for each of the plurality of events.
9. The electronic apparatus as claimed in claim 8, wherein the processor is further configured to execute the at least one instruction to determine that a first image frame and a third image frame correspond to different events, based on a score corresponding to a degree of matching of the first image frame among the selected image frames being greater than or equal to a predetermined threshold, a score corresponding to a degree of matching of a second image frame captured after the first image frame being less than the predetermined threshold, and a score corresponding to a degree of matching of the third image frame captured after the second image frame being greater than or equal to the predetermined threshold.
10. The electronic apparatus as claimed in claim 1, wherein: the trained network model is trained based on a plurality of images matching the feature information and a plurality of images that do not match the feature information; and the feature information is related to at least one of one or more objects included in an image, an action of the one or more objects, an expression of the one or more objects, or a situation corresponding to the image.
11. A controlling method of an electronic apparatus including a memory configured to store a network model trained to determine a degree of matching between an input image frame and predetermined feature information, the controlling method comprising: identifying a representative image frame based on a degree of matching obtained by applying image frames, selected from among a plurality of image frames, to the trained network model, while the plurality of image frames are captured through a camera; identifying a best image frame based on a degree of matching obtained by applying image frames within a specific section including the identified representative image frame, to the trained network model, from among the plurality of image frames; and providing the identified best image frame.
12. The controlling method as claimed in claim 11, wherein the identifying the representative image frame comprises: applying, to the trained network model, the image frames selected from among the plurality of image frames at a constant time interval, wherein the constant time interval is determined based on a determination speed of the trained network model.
13. The controlling method as claimed in claim 11, wherein the identifying the representative image frame comprises: obtaining, for each of the selected image frames, a score corresponding to the degree of matching by applying the selected image frames to the trained network model; and identifying the representative image frame having a highest score among image frames in which the obtained score is greater than or equal to a predetermined threshold.
14. The controlling method as claimed in claim 11, wherein the identifying the best image frame comprises: obtaining, for each of the image frames within the specific section, a score corresponding to the degree of matching by applying the image frames within the specific section to the trained network model; and identifying the best image frame as having a highest score among the obtained scores.
15. The controlling method as claimed in claim 11, further comprising: obtaining a plurality of image frames of low quality by lowering a resolution of the plurality of image frames; and identifying a representative image frame of low quality by applying image frames, selected from among the plurality of image frames of low quality, to the trained network model, wherein the identifying the best image frame comprises applying the image frames within the specific section including the representative image frame corresponding to the representative image frame of low quality, from among the plurality of image frames, to the trained network model.
16. The controlling method as claimed in claim 11, wherein the identifying the representative image frame comprises: deleting image frames before a first image frame among the plurality of image frames, based on a score corresponding to the degree of matching of the first image frame among the selected image frames being less than a predetermined threshold; and identifying the first image frame as the representative image frame, based on the score of the first image frame being greater than or equal to the predetermined threshold.
17. The controlling method as claimed in claim 16, wherein the identifying the representative image frame comprises: deleting the image frames before the first image frame among the plurality of image frames, based on the score of the first image frame being greater than or equal to the predetermined threshold, and a score corresponding to a degree of matching of a second image frame following the first image frame among the selected image frames being greater than the score of the first image frame; and identifying the second image frame as the representative image frame.
18. The controlling method as claimed in claim 11, further comprising: dividing the plurality of image frames into a plurality of events based on the degree of matching of the selected image frames, wherein the identifying the best image frame comprises identifying the best image frame for each of the plurality of events.
19. The controlling method as claimed in claim 18, wherein the dividing the plurality of image frames into the plurality of events comprises: determining that a first image frame and a third image frame correspond to different events, based on a score corresponding to a degree of matching of the first image frame among the selected image frames being greater than or equal to a predetermined threshold, a score corresponding to a degree of matching of a second image frame captured after the first image frame being less than the predetermined threshold, and a score corresponding to a degree of matching of the third image frame captured after the second image frame being greater than or equal to the predetermined threshold.
20. A non-transitory computer readable medium having stored thereon computer instructions executable by a processor of an electronic apparatus to cause the electronic apparatus to perform: identifying a representative image frame based on a degree of matching obtained by applying image frames, selected from among a plurality of image frames, to a trained network model, while the plurality of image frames are captured through a camera; identifying a best image frame based on a degree of matching obtained by applying image frames within a specific section including the identified representative image frame, to the trained network model, from among the plurality of image frames; and providing the identified best image frame, wherein the trained network model is stored in a memory of the electronic apparatus and is trained to determine a degree of matching between an input image frame and predetermined feature information.
</claims>
</document>
