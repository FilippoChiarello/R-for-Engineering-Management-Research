<document>

<filing_date>
2017-04-21
</filing_date>

<publication_date>
2020-11-03
</publication_date>

<priority_date>
2016-01-06
</priority_date>

<ipc_classes>
G05B15/02,G06F1/16,G06F16/22,G06F16/51,G06F16/58,G06F16/583,G06F21/62,G06F3/00,G06F3/01,G06F3/14,G06F3/16,G06K7/10,G06K9/00,G06K9/20,G06K9/46,G06K9/62,G06Q10/10,G06Q30/06,G08B21/18,H04L29/06,H04N1/00,H04N5/225,H04N5/232,H04N5/33,H04N7/14,H04N7/15,H04N7/18,H04W4/02,H04W4/029
</ipc_classes>

<assignee>
ORCAM TECHNOLOGIES
ORCAM TECHNOLOGIES
</assignee>

<inventors>
SHASHUA, AMNON
WEXLER, YONATAN
</inventors>

<docdb_family_id>
59226228
</docdb_family_id>

<title>
Methods and systems for controlling external devices using a wearable apparatus
</title>

<abstract>
A wearable apparatus is provided for capturing and processing images from an environment of a user. In one implementation, a system for controlling one or more controllable devices includes a transceiver and at least one processing device. The processing device is programmed to obtain one or more images captured by an image sensor included in a wearable apparatus, analyze the one or more images to identify a controllable device in an environment of a user of the wearable apparatus, analyze the one or more images to detect a visual trigger associated with the controllable device and, based on the detection of the visual trigger, transmit, via the transceiver, a command. The command may be configured to change at least one aspect of the controllable device.
</abstract>

<claims>
1. A system for controlling one or more controllable devices, the system comprising: a transceiver; and at least one processing device programmed to: obtain a plurality of images captured by an image sensor included in a wearable apparatus; analyze the plurality of images to identify a controllable device in an environment of a user of the wearable apparatus; analyze the plurality of images to detect a visual trigger associated with the controllable device; analyze the plurality of images to identify an activity engaged in by the user, the activity being identified based on detection, in the plurality of images, of an object that the user is interacting with, the object being different from the controllable device; and based on the detection of the visual trigger and the identified activity, transmit, via the transceiver, a command, the command being configured to change at least one aspect of the controllable device.
2. The system of claim 1, wherein the processing device is further programmed to identify a current state of the controllable device based on analysis of the plurality of images.
3. The system of claim 2, wherein the processing device is further programmed to select the command from among a plurality of commands based on the identified current state of the controllable device.
4. The system of claim 1, wherein the processing device is further programmed to identify a context associated with the controllable device based on analysis of the plurality of images.
5. The system of claim 4, wherein the processing device is further programmed to select values for one or more parameters associated with the command based on the identified context associated with the controllable device.
6. The system of claim 5, wherein the identified context is associated with a meal to be prepared held by the user, the controllable device includes a microwave, and the one or more parameters include settings for the microwave based on content of the meal.
7. The system of claim 4, wherein the context is associated with at least one of the visual trigger, an action involving the controllable device, an object held by the user, or a state of the controllable device.
8. The system of claim 1, wherein the processing device is further programmed to: identify a type associated with the visual trigger, wherein the type of the visual trigger includes at least one of a hand gesture, an action involving the user's hand, or an action involving the controllable device; and select the command from among a plurality of commands based on the identified type of the visual trigger.
9. The system of claim 1, wherein the visual trigger includes a hand gesture, wherein the hand gesture includes an upward flick of an index finger, and the upward flick of an index finger is associated with a command for turning on a light switch.
10. The system of claim 1, wherein the system for controlling the one or more controllable devices is included in the wearable apparatus.
11. The system of claim 1, wherein the command is transmitted to a paired device.
12. The system of claim 1, wherein the at least one processing device is further programmed to: obtain audio data captured by at least one audio sensor included in the wearable apparatus; and select the command from among a plurality of available commands based, at least in part, on the audio data.
13. The system of claim 1, wherein the at least one processing device is further programmed to: receive via the transceiver an indication that the command has been received; and provide feedback to the user of the wearable device indicating that the command has been received.
14. The system of claim 1, wherein the at least one processing device is further programmed to: receive via the transceiver an indication that the at least one aspect of the controllable device has changed; and provide feedback to the user of the wearable device indicating that the at least one aspect of the controllable device has changed.
15. The system of claim 1, wherein the at least one processing device is further programmed to: obtain a second group of one or more images captured by the image sensor; analyze the second group of one or more images to identify a change in the at least one aspect of the controllable device; and provide feedback to the user of the wearable device indicative of the change in the at least one aspect of the controllable device.
16. The system of claim 1, wherein the controllable device is associated with at least one of a light source, a locking mechanism, a heating device, a ventilation device, an air conditioning device, an HVAC system, a computer, a printer, a television, a music player, a household appliance, a vehicle, a security system, or a toy, wherein if the controllable device is associated with a locking mechanism, the command is configured to cause the controllable device to lock or unlock the locking mechanism, wherein if the controllable device is associated with a light source, the command is configured to cause the controllable device to change an illumination state of the light source, and wherein if the controllable device is associated with at least one of a heating device, a ventilation device, an air conditioning device, or an HVAC system, the command is configured to change one or more settings of the heating device, the ventilation device, the air conditioning device, or the HVAC system.
17. The system of claim 1, further comprising a memory and, wherein, after analyzing the plurality of images to identify the controllable device in the environment of the user of the wearable apparatus, the at least one processing device is further programmed to: cause the transceiver to transmit an interrogation signal, the interrogation signal being configured to cause a change in at least one aspect of the controllable device; analyze one or more images captured by the image sensor after transmission of the interrogation signal to detect the change in the at least one aspect of the controllable device; and after detection of the change in the at least one aspect of the controllable device, store in the memory information relating to the controllable device.
18. The system of claim 17, wherein the information relating to the controllable device includes a location associated with the controllable device, a type associated with the controllable device, or at least one controllable function associated with the controllable device.
19. The system of claim 17, wherein the change in the at least one aspect of the controllable device includes a change in illumination of at least one light source associated with the controllable device, wherein the at least one light source includes an infrared light source or a visible light source, and wherein the change in illumination includes causing the at least one light source to at least one of: turn off, turn on, blink, dim, or brighten.
20. The system of claim 1, wherein the at least one processing device is further programmed to: analyze one or more images captured by the image sensor to detect at least one recognized gesture made by the user; and cause a control signal to be transmitted to the controllable device, the control signal being configured to control at least one aspect of the controllable device, the at least one aspect of the controllable device to be controlled being associated with the recognized gesture.
21. The system of claim 20, wherein the control signal is configured to cause the controllable device to activate or deactivate.
22. The system of claim 20, wherein the control signal is configured to cause a change in illumination of a light source associated with the controllable device, and the change in illumination includes at least one of: turning on, turning off, dimming, or brightening.
23. A method for controlling one or more controllable devices, the method comprising: obtaining a plurality of images captured by an image sensor included in a wearable apparatus; analyzing the plurality of images to identify a controllable device in an environment of a user of the wearable apparatus; analyzing the plurality of images to detect a visual trigger associated with the controllable device; analyzing the plurality of images to identify an activity engaged in by the user, the activity being identified based on detection, in the plurality of images, of an object that the user is interacting with, the object being different from the controllable device; and based on the detection of the visual trigger and the identified activity, transmitting a command, the command being configured to change at least one aspect of the controllable device.
24. The method of claim 23, further comprising: identifying a current state of the controllable device based on analysis of the one or more images; and selecting the command from among a plurality of commands based on the identified current state of the controllable device.
25. The method of claim 23, further comprising: identifying a context associated with the controllable device based on analysis of the plurality of images; and selecting values for one or more parameters associated with the command based on the identified context associated with the controllable device.
26. The method of claim 23, further comprising: obtaining an indication that the command has been received; and providing feedback to the user of the wearable apparatus indicating that the command has been received.
27. The method of claim 23, further comprising: obtaining an indication that the at least one aspect of the controllable device has changed; and providing feedback to the user of the wearable apparatus indicating that the at least one aspect of the controllable device has changed.
28. The method of claim 23, further comprising: obtaining a second group of one or more images captured by the image sensor; analyzing the second group of one or more images to identify a change in the at least one aspect of the controllable device; and providing feedback to the user of the wearable apparatus indicative of the change in the at least one aspect of the controllable device.
29. The method of claim 23, further comprising: analyzing one or more images captured by the image sensor to detect at least one recognized gesture made by the user; and causing a control signal to be transmitted to the controllable device, the control signal being configured to control at least one aspect of the controllable device, the at least one aspect of the controllable device to be controlled being associated with the recognized gesture.
30. A non-transitory computer storing computer implementable instructions for carrying out the method of claim 23.
31. The system of claim 1, wherein the wearable apparatus has a field of view that substantially coincides with a field of view of the user.
</claims>
</document>
