<document>

<filing_date>
2018-08-17
</filing_date>

<publication_date>
2020-12-08
</publication_date>

<priority_date>
2017-08-17
</priority_date>

<ipc_classes>
G06K9/00,G06K9/40,G06N20/00,G06T7/11,G06T7/254,G08B13/196
</ipc_classes>

<assignee>
BOSSA NOVA ROBOTICS IP
</assignee>

<inventors>
SAVVIDES, MARIOS
VENUGOPALAN, SHREYAS
SINGH, KARANHAAR
ADLER, GAVRIEL
LIN, AN PANG
THANIKKAL, AJMAL
NEBLETT, KYLE
</inventors>

<docdb_family_id>
65360608
</docdb_family_id>

<title>
Robust motion filtering for real-time video surveillance
</title>

<abstract>
A video monitoring method that involves determining motion changes in a set of video frames to find potential objects is described. One or more bounding boxes are defined around the potential objects. These bounding boxes are spatially and temporally filtered to eliminate potential object candidates, with only potential objects in the bounding boxes remaining after filtering being classified or identified.
</abstract>

<claims>
1. A video monitoring method, comprising: determining motion changes in a set of video frames; identifying a plurality of potentially interesting objects in the set of video frames based on the determined motion changes; defining a plurality of bounding boxes, including defining a bounding box around each of the plurality of potentially interesting objects; filtering out at least one bounding box, from among the plurality of bounding boxes, based on spatial and temporal filter settings, including identifying physically unrealistic motion tracks and identifying bounding boxes within predetermined frame regions unlikely to present valid objects, leaving at least one other remaining bounding box; eliminating potentially interesting objects surrounded by any of the at least one filtered out bounding box from further consideration as interesting objects; and classifying potentially interesting objects surrounded by any of the at least one other remaining bounding box.
2. The video monitoring method of claim 1, wherein the video frames are preprocessed to reduce at least one of color depth and resolution.
3. The video monitoring method of claim 1, wherein filtering out at least one bounding box comprises: filtering out a first bounding box, from among the plurality of bounding boxes, based on spatial filter settings, leaving a sub-plurality of bounding boxes; and subsequently filtering out a second bounding box, from among the sub-plurality of bounding boxes, based on temporal filter settings, leaving the at least one other remaining bounding box.
4. The video monitoring method of claim 1, wherein determining motion changes further comprises frame subtraction and morphological processing.
5. The video monitoring method of claim 1, wherein defining a plurality of bounding boxes comprises fitting shape contours, fitting minimum bounding rectangles, and merging adjacent boxes.
6. The video monitoring method of claim 1, wherein filtering out at least one bounding box comprises filtering the plurality of bounding boxes based on: bounding box shape, bounding box size, bounding box aspect ratio, and bounding box spatial location.
7. The video monitoring method of claim 1, wherein filtering out at least one bounding box comprises filtering the plurality of bounding boxes based on: object motion analysis and object tracking.
8. The video monitoring method of claim 1, wherein classifying potentially interesting objects comprises classifying objects using machine learning.
9. The video monitoring method of claim 1, further comprising using a stationary camera to acquire the set of video frames.
10. The video monitoring method of claim 1, further comprising using a movable camera to acquire the set of video frames.
11. The video monitoring method of claim 1, wherein classifying potentially interesting objects comprises classifying a shopping cart in motion.
12. The video monitoring method of claim 1, further comprising using a camera mounted on an autonomous robot to acquire the set of video frames.
13. A video monitoring system, comprising: a processor; and system memory coupled to the processor and storing instructions configured to cause the processor to: determine motion changes in a set of video frames; identify a plurality of potentially interesting objects in the set of video frames based on the determined motion changes; defines a plurality of bounding boxes, including defining a bounding box around each of the plurality of potentially interesting objects; filter out at least one bounding box, from among the plurality of bounding boxes, based on spatial and temporal filter settings, including identifying physically unrealistic motion tracks and identifying bounding boxes within predetermined frame regions unlikely to present valid objects, leaving at least one other remaining bounding box; eliminate potentially interesting objects surrounded by any of the at least one filtered out bounding box from further consideration as interesting objects; and classify potentially interesting objects surrounded by any of the at least one other remaining bounding box.
14. The video monitoring system of claim 13, further comprising instructions configured to preprocess the video frames reducing at least one of color depth and resolution.
15. The video monitoring system of claim 13, wherein instructions configured to filter out at least one bounding box comprise instructions configured to: filter out a first bounding box, from among the plurality of bounding boxes, based on spatial filter settings, leaving a sub-plurality of bounding boxes; and subsequently filter out a second bounding box, from among the sub-plurality of bounding boxes, based on temporal filter settings, leaving the at least one other remaining bounding box.
16. The video monitoring system of claim 13, wherein instructions configured to determine motion changes comprise instructions configured to perform frame subtraction and morphological processing.
17. The video monitoring system of claim 13, wherein instructions configured to define a plurality of bounding boxes comprise instructions configured to perform shape contours fitting, minimum bounding rectangles fitting, and adjacent boxes merging.
18. The video monitoring system of claim 13, wherein instructions configured to filter out at least one bounding box comprise instructions configured to filter the plurality of bounding boxes based on: bounding box shape, bounding box size, bounding box aspect ratio, and bounding box spatial location.
19. The video monitoring system of claim 13, wherein instructions configured to filter out at least one bounding box comprise instructions configured to filter the plurality of bounding boxes based on: object motion analysis and object tracking.
20. A video monitoring system, comprising: a camera system attached to an autonomous robot; a processor; and system memory coupled to the processor and storing instructions configured to cause the processor to: capture a set of video frames at the camera system; determine motion changes in the set of video frames; identify a plurality of potentially interesting objects in the set of video frames based on the determined motion changes; define a plurality of bounding boxes, including defining a bounding box around each of the plurality of potentially interesting objects; filter out at least one bounding box, from among the plurality bounding boxes, based on spatial and temporal filter settings, including identifying physically unrealistic motion tracks and identifying bounding boxes within predetermined frame regions unlikely to present valid objects, leaving at least one other remaining bounding box; eliminate potentially interesting objects surrounded by any of the at least one filtered out bounding box from further consideration as interesting objects; and classify potentially interesting objects surrounded by any of the at least one other remaining bounding box.
</claims>
</document>
