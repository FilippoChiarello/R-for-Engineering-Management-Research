<document>

<filing_date>
2019-11-15
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2018-11-15
</priority_date>

<ipc_classes>
B60R11/04,G05D1/00,G05D1/02,G06K9/00,G06K9/62,G06K9/72,G06N3/04
</ipc_classes>

<assignee>
MOBILEYE VISION TECHNOLOGIES
</assignee>

<inventors>
BENTOLILA, JACOB
GELLER, IDAN
MALACH, ERAN
SHAMBIK, YAAKOV
</inventors>

<docdb_family_id>
69582145
</docdb_family_id>

<title>
FAST CNN CLASSIFICATION OF MULTI-FRAME SEMANTIC SIGNALS
</title>

<abstract>
The present subject matter provides various technical solutions to technical problems facing advanced driver assistance systems (ADAS) and autonomous vehicle (AV) systems. In particular, disclosed embodiments provide systems and methods that may use cameras and other sensors to detect objects and events and identify them as predefined signal classifiers, such as detecting and identifying a red stoplight. These signal classifiers are used within ADAS and AV systems to control the vehicle or alert a vehicle operator based on the type of signal. These ADAS and AV systems may provide full vehicle operation without requiring human input. The embodiments disclosed herein provide systems and methods that can be used as part of or in combination with ADAS and AV systems.
</abstract>

<claims>
1. A system for fast CNN classification of multi-frame semantic signals, the system comprising: processing circuitry; and one or more storage devices comprising instructions, which when executed by the processing circuitry, configure the processing circuitry to: receive a plurality of time sequenced images from an image capture device; transform the plurality of time sequenced images to a plurality of vectors stored in a time-sequenced buffer; generate a temporal image based on the plurality of vectors; and generate a semantic signal based on an application of a convolutional neural network to the temporal image.
2. The system of claim 1, wherein each of a plurality of vectors includes a row vector of the same width as each of the plurality of time sequenced images.
3. The system of claim 2, wherein to transform the plurality of time sequenced images to the plurality of vectors, the processing circuitry is configured to calculate a column value for each of a plurality of columns within each of the plurality of time sequenced images.
4. The system of claim 2, wherein calculating the column value includes at least one of calculating a mean value, a median value, or a maximal value for each of a plurality of columns within each of the plurality of time sequenced images.
5. The system of claim 1, wherein the generation of the temporal image includes concatenating the plurality of vectors to form the temporal image.
6. The system of claim 1, wherein to transform the plurality of time sequenced images to the plurality of vectors, the processing circuitry is configured to use a classifier to obtain each of the plurality of vectors from a respective plurality of images.
7. The system of claim 1, wherein to generate the semantic signal based on the application of the convolutional neural network to the temporal image, the processing circuitry is configured to use a blinking classifier.
8. The system of claim 1, wherein to generate the semantic signal based on the application of the convolutional neural network to the temporal image, the processing circuitry is configured to use a braking classifier.
9. The system of claim 1, wherein to generate the semantic signal based on the application of the convolutional neural network to the temporal image, the processing circuitry is configured to use a braking classifier on a pair of vectors of the plurality of vectors, and to use a blinking classifier on the entire temporal image.
10. The system of claim 1, wherein: the image capture device is mounted on a vehicle; the semantic signal indicates a changed path condition for the vehicle; and the instructions further configure the processing circuitry to: identify a maneuver for the vehicle in response to the changed path condition; and send a vehicle control signal for execution of the maneuver.
11. The system of claim 1, further including a vehicular control device to receive the control signal and execute the vehicular maneuver.
12. An autonomous navigation semantic signal method comprising: receiving a plurality of time sequenced images from an image capture device, each of the plurality of time sequenced images associated with a unique image capture time; mapping each of the plurality of time sequenced images to each of a plurality of vectors; converting the plurality of vectors to temporal image; and identifying a semantic signal based on applying a convolutional neural network to the temporal image.
13. The method of claim 12, further including: capturing the plurality of time sequenced images; and associating the unique image capture time with each of the captured plurality of time sequenced images.
14. The method of claim 12, wherein each of a plurality of vectors includes a row vector of the same width as each of the plurality of time sequenced images.
15. The method of claim 14, wherein mapping each of the plurality of time sequenced images to each of a plurality of vectors includes calculating a column value for each of a plurality of columns within each of the plurality of time sequenced images.
16. The method of claim 14, wherein calculating the column value includes at least one of calculating a mean value, a median value, or a maximal value for each of a plurality of columns within each of the plurality of time sequenced images.
17. The method of claim 12, wherein the generation of the temporal image includes concatenating the plurality of vectors to form the temporal image.
18. The method of claim 12, wherein to transform the plurality of time sequenced images to the plurality of vectors, the processing circuitry is configured to use a classifier to obtain each of the plurality of vectors from a respective plurality of images.
19. The method of claim 12, wherein to generate the semantic signal based on the application of the convolutional neural network to the temporal image, the processing circuitry is configured to use a blinking classifier.
20. The method of claim 12, wherein to generate the semantic signal based on the application of the convolutional neural network to the temporal image, the processing circuitry is configured to use a braking classifier.
21. The method of claim 12, wherein to generate the semantic signal based on the application of the convolutional neural network to the temporal image, the processing circuitry is configured to use a braking classifier on a pair of vectors of the plurality of vectors, and to use a blinking classifier on the entire temporal image.
22. The method of claim 12, further including: identifying a vehicular maneuver based on the semantic signal; and sending a control signal to execute the vehicular maneuver to a vehicular control device.
23. A computer program product that stores instructions that, once executed by a computerized system, cause the computerized system to perform operations comprising: receiving a plurality of time sequenced images from an image capture device, each of the plurality of time sequenced images associated with a unique image capture time; mapping each of the plurality of time sequenced images to each of a plurality of vectors; converting the plurality of vectors to temporal image; and identifying a semantic signal based on applying a convolutional neural network to the temporal image.
24. The computer program product of claim 23, wherein to transform the plurality of time sequenced images to the plurality of vectors, the processing circuitry is configured to use a classifier to obtain each of the plurality of vectors from a respective plurality of images.
25. The computer program product of claim 23, wherein to generate the semantic signal based on the application of the convolutional neural network to the temporal image, the processing circuitry is configured to use a braking classifier on a pair of vectors of the plurality of vectors, and to use a blinking classifier on the entire temporal image.
</claims>
</document>
