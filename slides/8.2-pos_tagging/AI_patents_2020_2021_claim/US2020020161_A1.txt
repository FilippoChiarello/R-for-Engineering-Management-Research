<document>

<filing_date>
2018-07-10
</filing_date>

<publication_date>
2020-01-16
</publication_date>

<priority_date>
2018-07-10
</priority_date>

<ipc_classes>
G06T15/00,G06T19/00
</ipc_classes>

<assignee>
CURIOUS
</assignee>

<inventors>
YOUNG BRUCE A.
JONES, ANTHONY MARK
JONES, JESSICA A. F.
</inventors>

<docdb_family_id>
69138464
</docdb_family_id>

<title>
Virtual barrier objects
</title>

<abstract>
A computer system presents a virtual object on a display of the computer system which represents an action at a location in space. If a user of the computer system approaches the location, the computer system presents one or more stimuli to encourage movement away from that location. The appearance of the object may vary as the user of the computer system moves. The appearance of the object may include information and may vary with a change of state. Multiple such virtual objects may be used to indicate a path.
</abstract>

<claims>
1. A method to provide directional guidance to a user wearing a head-mounted display (HMD), the method comprising: establishing a world position for a virtual barrier object; rendering an image of the virtual barrier object at a position corresponding to the world position on the HMD; and presenting an additional sensory stimulus to the user to encourage the user to avoid the world position of the virtual barrier object.
2. The method of claim 1, wherein the additional sensory stimulus is directed to the sense of vision, sound, touch, smell or taste of user.
3. The method of claim 1, wherein a world rendered on the HMD corresponds to a real-world around the user and the world position corresponds to a real-world position.
4. The method of claim 3, wherein the world position for the virtual barrier object corresponds to a fixed real-world position in space as the user moves.
5. The method of claim 3, wherein the world position for the virtual barrier object corresponds to a real-world position of a moving real-world object, and the virtual barrier object, as rendered on the HMD, moves with the moving real-world object.
6. The method of claim 3, further comprising: capturing an image of a portion of the real-world around the user with a camera mounted on the HMD; and displaying the image of the portion of the real-world around the user on the HMD with the image of the virtual barrier object overlaid on the image of the portion of the real-world around the user.
7. The method of claim 3, further comprising: creating a synthetic image of a portion of the real-world around the user based on data about the real-world around the user; and displaying the synthetic image of the portion of the real-world around the user on the HMD with the image of the virtual barrier object overlaid on the image of the portion of the real-world around the user.
8. The method of claim 3, further comprising: transmitting a view of a portion of the real-world around the user through a transparent portion of the HMD; and displaying the image of the virtual barrier object to occlude a portion of the view of the portion of the real-world around the user.
9. The method of claim 1, wherein world corresponds to a virtual-world around the user and the world position corresponds to a virtual-world position.
10. The method of claim 1, further comprising: determining a distance between the user and the HMD-world position of the virtual object; and selecting the additional sensory stimulus based on the distance.
11. The method of claim 1, further comprising: determining a closing velocity between the user and the HMD-world position of the virtual object; and selecting the additional sensory stimulus based on the closing velocity.
12. The method of claim 1, wherein the additional sensory stimulus comprises a haptic push delivered by a haptic subsystem of the HMD.
13. The method of claim 1, further comprising: calculating a direction for the user to move to avoid the world position of the virtual object; and communicating information related to the direction to an article of haptic clothing worn by the user; wherein the additional sensory stimulus comprises a haptic push applied by the article of haptic clothing worn by the user to encourage the user to move in the direction to avoid the world position of the virtual object.
14. The method of claim 1, further comprising: obtaining a status of a portion of the world occluded by the virtual barrier object; and changing an appearance of the virtual barrier object based on said status.
15. The method of claim 1, wherein the additional sensory stimulus encourages the user to move in a specific direction.
16. The method of claim 15, wherein the additional sensory stimulus comprises an unnatural sound presented to the user as originating in the specific direction.
17. The method of claim 15, wherein the additional sensory stimulus comprises a gradient mask applied to an image of a portion of world space on the HMD.
18. The method of claim 17, wherein the gradient mask changes with time.
19. An article of manufacture comprising a tangible medium, that is not a transitory propagating signal, encoding computer-readable instructions that, when applied to a computer system, instruct the computer system to perform a method comprising: establishing a world position for a virtual barrier object; rendering an image of the virtual barrier object at a position corresponding to the world position on the HMD; and presenting an additional sensory stimulus to the user to encourage the user to avoid the world position of the virtual barrier object.
20. A head-mounted display (HMD) comprising: a display; a structure, coupled to the display and adapted to position the display in a field-of-view (FOV) of the user; a processor, coupled to the display and the sound reproduction device, the processor configured to: establish a real-world position for a virtual barrier object; render an image of the virtual barrier object at a position corresponding to the real-world position on the HMD; and present an additional sensory stimulus to the user to encourage the user to avoid the real-world position of the virtual barrier object.
</claims>
</document>
