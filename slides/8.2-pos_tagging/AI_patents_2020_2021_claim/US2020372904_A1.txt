<document>

<filing_date>
2020-08-11
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2018-05-07
</priority_date>

<ipc_classes>
G10L15/18,G10L15/19,G10L15/22,G10L15/30
</ipc_classes>

<assignee>
APPLE
</assignee>

<inventors>
BERNSTEIN, JEFFREY, TRAER
CIRCLAEYS, ERIC M. G.
KRENN, MATTHAEUS
VESCOVI, MARCOS REGIS
WARREN, RICHARD
</inventors>

<docdb_family_id>
68385417
</docdb_family_id>

<title>
INTELLIGENT AUTOMATED ASSISTANT FOR DELIVERING CONTENT FROM USER EXPERIENCES
</title>

<abstract>
Systems and processes for operating an intelligent automated assistant are provided. In one example process, a speech input is received from a user. In response to determining that the speech input corresponds to a user intent of obtaining information associated with a user experience of the user, one or more parameters referencing a user experience of the user are identified. Metadata associated with the referenced user experience is obtained from an experiential data structure. Based on the metadata, one or more media items associated with the referenced are retrieved based on the metadata. The one or more media items associated with the referenced user experience are output together.
</abstract>

<claims>
1. An electronic device, comprising: one or more processors; a memory; and one or more programs, wherein the one or more programs are stored in the memory and configured to be executed by the one or more processors, the one or more programs including instructions for: receiving, from a user, speech input; determining whether the speech input corresponds to a user intent of obtaining information associated with a user experience of the user; in response to a determination that the speech input corresponds to a user intent of obtaining information associated with a user experience of the user: identifying, from the speech input, one or more parameters referencing a user experience of the user; obtaining, from an experiential data structure, metadata associated with the referenced user experience, wherein the experiential data structure includes a plurality of user experiences determined based on past user activity; retrieving, based on the metadata associated with the referenced user experience, one or more media items associated with the referenced user experience; and outputting together the one or more media items associated with the referenced user experience.
2. The device of claim 1, wherein determining whether the speech input corresponds to a user intent of obtaining information associated with a user experience further comprises: determining whether the speech input corresponds to a user intent of obtaining media associated with the user experience.
3. The device of claim 2, wherein determining whether the speech input corresponds to a user intent of obtaining media associated with the user experience further comprises: determining whether the speech input includes one or more nouns related to images and one or more nouns related to an experience.
4. The device of claim 2, wherein determining whether the speech input corresponds to a user intent of obtaining media associated with the user experience further comprises: determining whether the speech input includes at least one semantic term for an experience, at least one verb for a past activity, and at least one verb for a search.
5. The device of claim 1, wherein identifying, from the speech input, one or more parameters referencing a user experience further comprises: determining whether the speech input includes at least one parameter type corresponding to an event, an activity, a geographical feature, a person, a place, a time, and a location.
6. The device of claim 1, wherein identifying, from the speech input, one or more parameters referencing a user experience further comprises: determining whether the speech input includes at least one parameter sub-type corresponding to at least one parameter type.
7. The device of claim 1, wherein identifying, from the speech input, one or more parameters referencing a user experience further comprises: determining whether the speech input includes at least one descriptor corresponding to at least one parameter type.
8. The device of claim 1, wherein retrieving, based on the metadata associated with the referenced user experience, one or more media items associated with the referenced user experience further comprises: retrieving media items associated with a user profile.
9. The device of claim 1, the one or more programs including instructions for: in accordance with a determination that a predetermined criteria is satisfied, retrieving media items related to the referenced user experience from a remote source.
10. The device of claim 9, wherein the predetermined criteria includes that a number of retrieved media items associated with the referenced user experience is less than a predetermined threshold.
11. The device of claim 1, the one or more programs including instructions for: generating the experiential data structure based on at least one pattern recognition process.
12. The device of claim 1, the one or more programs including instructions for: determining whether a user experience associated with at least one pattern was previously generated; in accordance with a determination that a user experience associated with the at least one pattern was previously generated, updating the previously generated user experience.
13. The device claim 1, the one or more programs including instructions for: generating the experiential data structure based at least on user data obtained from a secondary device.
14. The device of claim 1, the one or more programs including instructions for: generating the experiential data structure based at least on user motion data.
15. The device of claim 1, the one or more programs including instructions for: generating the experiential data structure based at least on user biometric data.
16. The device of claim 1, the one or more programs including instructions for: generating the experiential data structure based at least on facial recognition data.
17. The device of claim 1, the one or more programs including instructions for: generating the experiential data structure based at least on user contact data.
18. The device of claim 1, wherein outputting together the one or more media items associated with the referenced user experience further comprises: generating, using the metadata, information associated with the referenced user experience; and outputting together the one or more media items associated with the referenced user experience and the generated information associated with the referenced user experience.
19. A non-transitory computer-readable storage medium storing one or more programs, the one or more programs comprising instructions, which when executed by one or more processors of an electronic device, cause the electronic device to: receive, from a user, speech input; determine whether the speech input corresponds to a user intent of obtaining information associated with a user experience of the user; in response to a determination that the speech input corresponds to a user intent of obtaining information associated with a user experience of the user: identify, from the speech input, one or more parameters referencing a user experience of the user; obtain, from an experiential data structure, metadata associated with the referenced user experience, wherein the experiential data structure includes a plurality of user experiences determined based on past user activity; retrieve, based on the metadata associated with the referenced user experience, one or more media items associated with the referenced user experience; and output together the one or more media items associated with the referenced user experience.
20. A method, comprising: at an electronic device with one or more processors and memory: receiving, from a user, speech input; determining whether the speech input corresponds to a user intent of obtaining information associated with a user experience of the user; in response to a determination that the speech input corresponds to a user intent of obtaining information associated with a user experience of the user: identifying, from the speech input, one or more parameters referencing a user experience of the user; obtaining, from an experiential data structure, metadata associated with the referenced user experience, wherein the experiential data structure includes a plurality of user experiences determined based on past user activity; retrieving, based on the metadata associated with the referenced user experience, one or more media items associated with the referenced user experience; and outputting together the one or more media items associated with the referenced user experience.
</claims>
</document>
