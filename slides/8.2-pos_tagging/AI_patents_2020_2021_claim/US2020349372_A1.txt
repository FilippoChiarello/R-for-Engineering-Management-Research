<document>

<filing_date>
2020-03-03
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2019-05-02
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N3/08
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
HAN, SEUNG JU
KO, MIN SU
LEE, HANA
BAEK, Jiwon
LEE, Solae
</inventors>

<docdb_family_id>
70289717
</docdb_family_id>

<title>
METHOD AND APPARATUS WITH LIVENESS DETECTION
</title>

<abstract>
A liveness detection method and apparatus, and a facial verification method and apparatus are disclosed. The liveness detection method includes detecting a face region in an input image, measuring characteristic information of the face region, adjusting the measured characteristic information in response to the characteristic information not satisfying a condition, and performing a liveness detection on the face region with the adjusted characteristic information upon the measured characteristic information not satisfying the condition.
</abstract>

<claims>
1. A processor-implemented liveness detection method, comprising: detecting a face region in an input image; measuring characteristic information of the detected face region; in response to the measured characteristic information being determined as not satisfying a condition, generating an adjusted face region by adjusting the characteristic information of the face region; and performing a liveness detection on the adjusted face region.
2. The method of claim 1, wherein the measuring of the characteristic information of the face region comprises measuring a hue value of the face region, wherein the generating of the adjusted face region comprises: in response to a determination that the measured hue value is not included in a preset hue value range, performing the generating of the adjusted face region by adjusting the hue value of the face region to a hue value included in the preset hue value range.
3. The method of claim 2, wherein the adjusting of the hue value of the face region comprises: adjusting the measured hue value of the face region by applying a hue adjustment model to the face region.
4. The method of claim 1, wherein the measuring of the characteristic information of the face region comprises measuring a face tilt value indicating a degree of a tilt of a face included in the face region, wherein the generating of the adjusted face region comprises: in response to a determination that the measured face tilt value is not included in a preset face tilt value range, performing the generating of the adjusted face region by adjusting the face tilt value.
5. The method of claim 4, wherein the measuring of the face tilt value comprises: detecting feature points corresponding to a left eye, a right eye, and both mouth ends in the face region; and measuring the face tilt value based on the detected feature points.
6. The method of claim 4, wherein the adjusting of the face tilt value comprises: adjusting the face tilt value by rotating the face region based on the measured face tilt value.
7. The method of claim 1, wherein the measuring of the characteristic information of the face region comprises measuring a white balance value of the face region, wherein the generating of the face adjusted region comprises: in response to a determination that the measured white balance value is not included in a preset white balance value range, performing the generating of the adjusted face region by adjusting the white balance value of the face region to a white balance value included in the preset white balance value range.
8. The method of claim 1, further comprising: in response to a determination that the measured characteristic information satisfies the condition, performing the liveness detection based on the detected face region without performing the generating of the adjusted face region.
9. The method of claim 1, wherein the performing of the liveness detection comprises: performing the liveness detection using a neural network-based liveness detection model.
10. The method of claim 1, wherein the measuring of the characteristic information of the face region comprises: measuring any one or any combination of any two or more of a hue value, a face tilt value, and a white balance value of the face region; and in response to any one or any combination of any two or more of the measured hue value, the measured face tilt value, and the measured white balance value being respectively determined to be out of range of a preset hue value range, a preset face tilt value range, and a preset white balance value range, generating the adjusted face region by respectively adjusting the hue value, the face tilt value, and the white balance value to respectively fall within the preset hue value range, the preset face tilt value range, and the preset white balance value range.
11. A non-transitory computer-readable storage medium storing instructions that, when executed by one or more processors, configure the one or more processors to perform the method of claim 1.
12. The method of claim 1, wherein a neural network is used to perform a facial verification on the adjusted face region.
13. A processor-implemented facial verification method using a neural network, the facial verification method comprising: extracting a current facial image of a face region from an input image; calculating a current image feature value of the current facial image; comparing the current image feature value to a range of respective image feature values of training facial images; in response to a determination that the current image feature value is out of the range of the respective image feature values, generating an adjusted current facial image by adjusting the current image feature value of the current facial image to be included in the range of the respective image feature values; and inputting of the adjusted current facial image to the neural network.
14. The method of claim 13, wherein the range of the respective image feature values is an absolute range determined based on a minimum image feature value and a maximum image feature value among the image feature values of the training facial images.
15. The method of claim 13, wherein the range of the respective image feature values is a statistical range determined based on a distribution characteristic of the image feature values of the training facial images, and wherein the distribution characteristic includes a mean and a standard deviation of the image feature values.
16. The method of claim 15, wherein the statistical range is one of a range of 1 standard deviation, a range of 2 standard deviations, a range of 3 standard deviations, and a range of 4 standard deviations, on both sides from the mean as a center.
17. The method of claim 13, wherein the neural network is configured to perform a liveness detection on a face object in the input image.
18. The method of claim 13, wherein the neural network is configured to verify a face object in the input image.
19. The method of claim 13, wherein the calculating of the current image feature value comprises: calculating a hue value of the current facial image, wherein the adjusting of the current facial image comprises: in response to a determination that the calculated hue value is out of the range of the respective image feature values, generating the adjusted current facial image by adjusting the hue value of the current facial image to be included in the range of the respective image feature values.
20. The method of claim 13, wherein the calculating of the current image feature value comprises: calculating a face tilt value indicating a degree of a tilt of a face in the current facial image, wherein the adjusting of the current facial image comprises: in response to a determination that the calculated face tilt value is out of the range of the respective image feature values, generating the adjusted current facial image by rotating the face region of the current facial image so a tilt value of the adjusted current facial image to be included in the range of the respective image feature values.
21. The method of claim 13, wherein the calculating of the current image feature value comprises: calculating a white balance value of the face region in the current facial image, wherein the adjusting of the current facial image comprises: in response to a determination that the calculated white balance value is out of the range of the respective image feature values, generating the adjusted current facial image by adjusting the white balance value of the current facial image so a while balance value of the adjusted current facial image to be included in the range of the respective image feature values.
22. An apparatus, comprising: one or more processors configured to: detect a face region in an input image; measure characteristic information of the detected face region; in response to the measured characteristic information being determined as not satisfying a condition, generate an adjusted face region by adjusting the characteristic information of the face region; and perform a liveness detection on the adjusted face region.
23. The apparatus of claim 22, wherein the one or more processors are further configured to: measure a hue value of the face region; and in response to a determination that the measured hue value is not included in a preset hue value range, perform the generating of the adjusted face region by adjusting the hue value of the face region to a hue value included in the preset hue value range.
24. The apparatus of claim 22, wherein the one or more processors are further configured to: measure a face tilt value indicating a degree of a tilt of a face included in the face region; and in response to a determination that the measured face tilt value is not included in a preset face tilt value range, perform the generating of the adjusted face region by adjusting the face tilt value.
25. The apparatus of claim 22, wherein the one or more processors are further configured to: measure a white balance value of the face region; and in response to a determination that the measured white balance value is not included in a preset white balance value range, perform the generating of the adjusted face region by adjusting the white balance value of the face region.
26. The apparatus of claim 22, wherein the one or more processors are further configured to: in response to a determination that the measured characteristic information satisfies the condition, perform the liveness detection based on the detected face region without performing the generating of the adjusted face region.
27. The apparatus of claim 22, wherein the one or more processors are further configured to: perform the liveness detection using a neural network-based liveness detection model.
28. The apparatus of claim 22, wherein the apparatus is any of a smartphone, a wearable device, a tablet computer, a netbook, a laptop computer, a desktop computer, a personal digital assistant (PDA), a set-top box, a home appliance, a biometric door lock, a security device, and a vehicle start device.
29. An apparatus using a neural network, the apparatus comprising: one or more processors configured to: extract a current facial image of a face region from an input image; calculate a current image feature value of the current facial image; compare the current image feature value to a range of respective image feature values of training facial images; in response to a determination that the current image feature value is out of the range of the respective image feature values, generate an adjusted current face region by adjusting the current facial image such that the current image feature value of the current facial image is included in the range of the respective image feature values; and input the adjusted current facial image to the neural network.
30. The apparatus of claim 29, wherein the range of the respective image feature values is an absolute range to be determined based on a minimum image feature value and a maximum image feature value among the image feature values of the facial images used to train the neural network.
31. The apparatus of claim 29, wherein the range of the respective image feature values is a statistical range to be determined based on a distribution characteristic of the image feature values of the facial images used to train the neural network, wherein the distribution characteristic includes a mean and a standard deviation of the image feature values.
32. The apparatus of claim 29, wherein the neural network is used to verify a face object in the input image.
33. The apparatus of claim 29, wherein the one or more processors are configured to: calculate a hue value of the current facial image; and in response to a determination that the calculated hue value is out of the range of the respective image feature values, generate the adjusted current facial image by adjusting the hue value of the current facial image to be included in the range of the respective image feature values.
34. The apparatus of claim 29, wherein the one or more processors are configured to: calculate a face tilt value indicating a degree of a tilt of a face in the current facial image; and in response to a determination that the calculated face tilt value is out of the range of the respective image feature values, generate the adjusted current facial image by rotating the face region of the current facial image so a tilt value of the adjusted current facial image is included in the range of the respective image feature values.
35. The apparatus of claim 29, wherein the one or more processors are configured to: calculate a white balance value of the face region in the current facial image; and in response to a determination that the calculated white balance value is out of the range of the respective image feature values, generate the adjusted current facial image by adjusting the white balance value of the current facial image to be included in the range of the respective image feature values.
36. The apparatus of claim 29, wherein the one or more processors are configured to: calculate any one or any combination of any two or more of a hue value, a face tilt value, and a white balance value of the current facial image; and in response to any one or any combination of any two or more of the calculated hue value, the calculated face tilt value, and the calculated white balance value being respectively determined to be out of the range of respective image feature values, generating the adjusted face region by respectively adjusting the out of range image feature values to be within the respective range of image feature values.
</claims>
</document>
