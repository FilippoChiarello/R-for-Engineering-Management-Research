<document>

<filing_date>
2018-08-29
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2018-08-29
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06T5/00,G06T7/50,G06T7/73
</ipc_classes>

<assignee>
TOYOTA MOTOR CORPORATION
</assignee>

<inventors>
GUO, RUI
OGUCHI KENTARO
SUN, HAO
Ayinde, Babajide
</inventors>

<docdb_family_id>
69641598
</docdb_family_id>

<title>
Distance estimation using machine learning
</title>

<abstract>
A method receives a captured image depicting image content including an object, the captured image being captured by an image sensor located at a sensor position; generates, using a trained first machine learning logic, a lighting-corrected image from an imitative simulation image depicting at least a portion of the image content of the captured image in a simulation style associated with an environment simulator; generates, using a trained second machine learning logic, a depth estimation image from the lighting-corrected image, the depth estimation image indicating a relative distance between the object depicted in the captured image and the sensor position of the image sensor; and determines an object position of the object depicted in the captured image based on the depth estimation image.
</abstract>

<claims>
1. A method comprising: receiving a captured image depicting image content including an object, the captured image being captured by an image sensor located at a sensor position; generating, using a trained first machine learning logic, a lighting-corrected image from an imitative simulation image depicting at least a portion of the image content of the captured image in a simulation style associated with an environment simulator; generating, using a trained second machine learning logic, a depth estimation image from the lighting-corrected image, the depth estimation image indicating a relative distance between the object depicted in the captured image and the sensor position of the image sensor; and determining an object position of the object depicted in the captured image based on the depth estimation image.
2. The method of claim 1, wherein the image content of the captured image depicts a road segment and the object depicted in the captured image is a roadway object associated with the road segment.
3. The method of claim 1, wherein generating the lighting-corrected image from the imitative simulation image includes: detecting, using the trained first machine learning logic, one or more of a shadow region and a glare region in the imitative simulation image; responsive to detecting the shadow region in the imitative simulation image, adjusting, using the trained first machine learning logic, the shadow region to reduce or remove a shadow in the shadow region of the imitative simulation image; and responsive to detecting the glare region in the imitative simulation image, adjusting, using the trained first machine learning logic, the glare region to reduce or remove a glare in the glare region of the imitative simulation image.
4. The method of claim 1, further comprising: generating, using a trained third machine learning logic, the imitative simulation image from the captured image.
5. The method of claim 4, wherein the image content of the captured image depicts a real environment including the object; the simulation style associated with the environment simulator includes a simulated color and a simulated texture generated by the environment simulator; and generating the imitative simulation image from the captured image includes adjusting, using the trained third machine learning logic, one or more of a captured color of the object and a captured texture of the object to one or more of the simulated color and the simulated texture.
6. The method of claim 1, wherein generating the depth estimation image from the lighting-corrected image includes: mapping, using the trained second machine learning logic, one or more image pixels in the lighting-corrected image to one or more grayscale pixels in the depth estimation image.
7. The method of claim 1, wherein the trained first machine learning logic is a conditional-Generative Adversarial Network (GAN) and the trained second machine learning logic is another conditional-GAN; and the method includes generating, using a trained third machine learning logic, the imitative simulation image from the captured image, the trained third machine learning logic being a cycle-GAN.
8. A system comprising: one or more processors; an environment simulator executable by the one or more processors to generate one or more simulation images; a first machine learning logic executable by the one or more processors to receive a captured image depicting image content including an object, the captured image being captured by an image sensor located at a sensor position, and generate an imitative simulation image from the captured image, the imitative simulation image depicting at least a portion of the image content of the captured image in a simulation style associated with the environment simulator; a second machine learning logic executable by the one or more processors to receive the imitative simulation image from the first machine learning logic, and generate a lighting-corrected image from the imitative simulation image; a third machine learning logic executable by the one or more processors to receive the lighting-corrected image from the second machine learning logic, and generate a depth estimation image from the lighting-corrected image, the depth estimation image indicating a relative distance between the object depicted in the captured image and the sensor position of the image sensor; and an object position calculator executable by the one or more processors to determine an object position of the object depicted in the captured image based on the depth estimation image.
9. The system of claim 8, wherein the image content of the captured image depicts a road segment and the object depicted in the captured image is a roadway object associated with the road segment.
10. The system of claim 8, wherein to generate the lighting-corrected image from the imitative simulation image, the second machine learning logic performs one or more operations including: detecting one or more of a shadow region and a glare region in the imitative simulation image; responsive to detecting the shadow region in the imitative simulation image, adjusting the shadow region to reduce or remove a shadow in the shadow region of the imitative simulation image; and responsive to detecting the glare region in the imitative simulation image, adjusting the glare region to reduce or remove a glare in the glare region of the imitative simulation image.
11. The system of claim 8, wherein the image content of the captured image depicts a real environment including the object; the simulation style associated with the environment simulator includes a simulated color and a simulated texture generated by the environment simulator; and to generate the imitative simulation image from the captured image, the first machine learning logic performs one or more operations including adjusting one or more of a captured color of the object and a captured texture of the object to one or more of the simulated color and the simulated texture.
12. The system of claim 8, wherein to generate the depth estimation image from the lighting-corrected image, the third machine learning logic performs one or more operations including: mapping one or more image pixels in the lighting-corrected image to one or more grayscale pixels in the depth estimation image.
13. The system of claim 8, wherein the first machine learning logic is a cycle-Generative Adversarial Network (GAN); and the second machine learning logic is a conditional-GAN and the third machine learning logic is another conditional-GAN.
14. A method for training a machine learning system comprising: generating, using an environment simulator, a simulation image and a target lighting-corrected image corresponding to the simulation image, the simulation image depicting simulated image content and including a lighting effect, the target lighting-corrected image depicting the simulated image content and excluding or reducing the lighting effect; generating, using a first machine learning logic, a synthesized lighting-corrected image from the simulation image, the synthesized lighting-corrected image reducing or removing the lighting effect in the simulation image; determining, using the first machine learning logic, a first discrimination output indicating a level of similarity between the synthesized lighting-corrected image and the target lighting-corrected image; and adjusting one or more parameters of the first machine learning logic based on the first discrimination output.
15. The method of claim 14, wherein the simulated image content of the simulation image depicts a simulated road segment including one or more simulated roadway objects.
16. The method of claim 14, wherein generating the synthesized lighting-corrected image from the simulation image includes: detecting, using the first machine learning logic, one or more of a shadow region and a glare region in the simulation image; responsive to detecting the shadow region in the simulation image, adjusting, using the first machine learning logic, the shadow region to reduce or remove a shadow in the shadow region of the simulation image; and responsive to detecting the glare region in the simulation image, adjusting, using the first machine learning logic, the glare region to reduce or remove a glare in the glare region of the simulation image.
17. The method of claim 14, further comprising: generating, using the environment simulator, a target depth estimation image corresponding to the simulation image, the target depth estimation image indicating a relative distance between an object depicted in the simulation image and a simulated sensor position associated with the simulation image; generating, using a second machine learning logic, a synthesized depth estimation image from the target lighting-corrected image, the target lighting-corrected image depicting the simulated image content of the simulation image and excluding or reducing the lighting effect; determining, using the second machine learning logic, a second discrimination output indicating a level of similarity between the synthesized depth estimation image and the target depth estimation image; and adjusting one or more parameters of the second machine learning logic based on the second discrimination output.
18. The method of claim 17, wherein generating the synthesized depth estimation image from the target lighting-corrected image includes: mapping, using the second machine learning logic, one or more image pixels in the target lighting-corrected image to one or more grayscale pixels in the synthesized depth estimation image.
19. The method of claim 14, further comprising: receiving a captured image depicting image content, the captured image being captured by an image sensor; generating, using a third machine learning logic, an imitative simulation image from the captured image, the imitative simulation image depicting at least a portion of the image content of the captured image in a simulation style associated with the environment simulator; generating, using the third machine learning logic, a synthesized captured image from the imitative simulation image, the synthesized captured image reproducing the captured image; determining, using the third machine learning logic, a third discrimination output indicating a level of similarity between the synthesized captured image and the captured image; and adjusting one or more parameters of the third machine learning logic based on the third discrimination output.
20. The method of claim 19, wherein the image content of the captured image depicts a real environment including an object; the simulation style associated with the environment simulator includes a simulated color and a simulated texture generated by the environment simulator; generating the imitative simulation image from the captured image includes adjusting, using the third machine learning logic, one or more of a captured color of the object and a captured texture of the object to one or more of the simulated color and the simulated texture; and generating the synthesized captured image from the imitative simulation image includes adjusting, using the third machine learning logic, one or more of the simulated color of the object and the simulated texture of the object depicted in the imitative simulation image to one or more of the captured color of the object and the captured texture of the object depicted in the captured image.
21. A system comprising: one or more processors; an environment simulator executable by the one or more processors to generate a simulation image and a target lighting-corrected image corresponding to the simulation image, the simulation image depicting simulated image content and including a lighting effect, the target lighting-corrected image depicting the simulated image content and excluding or reducing the lighting effect; a first machine learning logic executable by the one or more processors to generate a synthesized lighting-corrected image from the simulation image, the synthesized lighting-corrected image reducing or removing the lighting effect in the simulation image, and determine a first discrimination output indicating a level of similarity between the synthesized lighting-corrected image and the target lighting-corrected image; and a training engine executable by the one or more processors to adjust one or more parameters of the first machine learning logic based on the first discrimination output.
22. The system of claim 21, wherein the simulated image content of the simulation image depicts a simulated road segment including one or more simulated roadway objects.
23. The system of claim 21, wherein to generate the synthesized lighting-corrected image from the simulation image, the first machine learning logic performs one or more operations including: detecting one or more of a shadow region and a glare region in the simulation image; responsive to detecting the shadow region in the simulation image, adjusting the shadow region to reduce or remove a shadow in the shadow region of the simulation image; and responsive to detecting the glare region in the simulation image, adjusting the glare region to reduce or remove a glare in the glare region of the simulation image.
24. The system of claim 21, wherein the environment simulator is executable by the one or more processors to generate a target depth estimation image corresponding to the simulation image, the target depth estimation image indicating a relative distance between an object depicted in the simulation image and a simulated sensor position associated with the simulation image; and the system includes a second machine learning logic executable by the one or more processors to generate a synthesized depth estimation image from the target lighting-corrected image, the target lighting-corrected image depicting the simulated image content of the simulation image and excluding or reducing the lighting effect, and determine a second discrimination output indicating a level of similarity between the synthesized depth estimation image and the target depth estimation image; and wherein the training engine is executable by the one or more processors to adjust one or more parameters of the second machine learning logic based on the second discrimination output.
25. The system of claim 24, wherein to generate the synthesized depth estimation image from the target lighting-corrected image, the second machine learning logic performs one or more operations including: mapping one or more image pixels in the target lighting-corrected image to one or more grayscale pixels in the synthesized depth estimation image.
26. The system of claim 21, further comprising a third machine learning logic executable by the one or more processors to receive a captured image depicting image content, the captured image being captured by an image sensor, generate an imitative simulation image from the captured image, the imitative simulation image depicting at least a portion of the image content of the captured image in a simulation style associated with the environment simulator, generate a synthesized captured image from the imitative simulation image, the synthesized captured image reproducing the captured image, and determine a third discrimination output indicating a level of similarity between the synthesized captured image and the captured image; and wherein the training engine is executable by the one or more processors to adjust one or more parameters of the third machine learning logic based on the third discrimination output.
27. The system of claim 26, wherein: the image content of the captured image depicts a real environment including an object; the simulation style associated with the environment simulator includes a simulated color and a simulated texture generated by the environment simulator; to generate the imitative simulation image from the captured image, the third machine learning logic performs one or more operations including adjusting one or more of a captured color of the object and a captured texture of the object to one or more of the simulated color and the simulated texture; and to generate the synthesized captured image from the imitative simulation image, the third machine learning logic performs one or more operations including adjusting one or more of the simulated color of the object and the simulated texture of the object depicted in the imitative simulation image to one or more of the captured color of the object and the captured texture of the object depicted in the captured image.
</claims>
</document>
