<document>

<filing_date>
2015-09-08
</filing_date>

<publication_date>
2020-12-09
</publication_date>

<priority_date>
2015-09-08
</priority_date>

<ipc_classes>
A46B15/00,G06K9/62,G06T7/20
</ipc_classes>

<assignee>
BRAUN
</assignee>

<inventors>
VETTER, INGO
STÜCKRATH, CARL
REICK, HANSJÖRG
ERNST, ANDREAS
BOCKSCH, MARCUS
GARBAS, JENS-UWE
SEITZ, JOCHEN
</inventors>

<docdb_family_id>
54072710
</docdb_family_id>

<title>
DETERMINATION OF A CURRENTLY TREATED BODY PORTION OF A USER
</title>

<abstract>
A pictorial representation of the user while treating his/her body portion using a personal hygienic device combined with sensor data as obtained from at least one inertial sensor residing in the personal hygienic device, is used for determining a currently treated body portion treated using the personal hygienic device. The provision of camera and inertial sensor may be achieved at low cost. The combination of the two sources for determining the user's body portion currently treated complement each other in that one source compensates weaknesses of the other source and vice versa.
</abstract>

<claims>
1. An apparatus for determining a body portion of a user treated by the user using a personal hygienic device (12), comprising a camera (16) configured to capture the user to obtain a pictorial representation of the user while treating the body portion using the personal hygienic device (12), the camera being configured to capture a scene showing the user's face with the user currently treating a certain head portion using the personal hygienic device (12); an interface (18) configured to receive sensor data from at least one inertial sensor (20) residing in the personal hygienic device (12); and an analyzer (26) configured to analyze and to combine the pictorial representation and the sensor data to determine the body portion, wherein the analyzer (26) is arranged to first separately determine the treated body portion on the basis of the pictorial representation on the one hand and the inertial sensor data on the other hand and then to combine both determinations to finally determine the treated body portion.
2. The apparatus in accordance with claim 1, wherein the analyzer (26) is configured to perform the determination by selecting the body portion out of a predetermined set of candidate body portions.
3. The apparatus in accordance with claim 2, wherein the set of candidate body portions at least comprises: a first candidate head portion lying at the user's left hand side; a second candidate head portion lying at the user's left hand side, but being displaced relative to the first candidate head portion along the user's vertical axis; a third candidate head portion lying at the user's right hand side; a fourth candidate head portion lying at the user's right hand side, but being displaced relative to the third candidate head portion along the user's vertical axis.
4. The apparatus in accordance with claim 2, wherein the personal hygienic device (12) is a tooth brush and the set of candidate body portions at least comprises an upper jaw left side portion of the user's dentition, a lower jaw left side portion of the user's dentition, an upper jaw right side portion of the user's dentition, and a lower jaw right side portion of the user's dentition.
5. The apparatus in accordance with any one of claims 1 to 4, wherein the pictorial representation comprises one or more pictures, and the analyzer is configured to associate a time-aligned portion of the sensor data to each of the one or more pictures to obtain a time-aligned mixed pictorial/acceleration data and determine the body portion based on the time-aligned mixed pictorial/acceleration data.
6. The apparatus in accordance with any one of claims 1 to 5, wherein the analyzer (26) is configured to subject the pictorial representation to a first evaluation analysis to obtain a first probability value for each of a first set of candidate body portions indicating how probable the body portion is the respective candidate body portion of the first set of candidate body portions, subject the sensor data to a second evaluation analysis to obtain an second probability value for each candidate body portion of a second set of candidate body portions indicating how probable the body portion is the respective candidate body portion of the second set of candidate body portions, and select the body portion out of a third set of candidate body portions on the basis of the first probability values and the second probability values, wherein the first, second and third sets of candidate body portions represent an identical partitioning, or different partitionings of a portion of a human head.
7. The apparatus in accordance with any one of claims 1 to 6, wherein the body portion is a head portion and the analyzer (26) is configured to locate from a picture of the pictorial representation, and extract from the picture, a mouth region, the mouth region including and surrounding the user's mouth, and warp (58) the mouth region depending on a position of a face of the user in the picture so as to correspond to a predetermined position of the user's face, and determine (94; 96; 98) the body portion on the basis of the warped mouth region.
8. The apparatus in accordance with any one of claims 1 to 7, wherein the analyzer (26) is configured to calculate a roll and pitch of the personal hygienic device on the basis of the sensor data, and determine the body portion on the basis of the roll and pitch.
9. The apparatus in accordance with any one of claims 1 to 8, wherein the pictorial representation comprises a sequence of pictures each associated with a predetermined time stamp and the analyzer is configured to associate a time-aligned portion of the sensor data to each of the sequence of pictures to obtain a sequence of time aligned mixed-pictorial/acceleration data items having a time aligned mixed-pictorial/acceleration data item per time stamp and update a determination of the body portion for each time aligned mixed-pictorial/acceleration data item.
10. The apparatus in accordance with any one of the previous claims, wherein the analyzer (26) is configured to continuously survey a position of the user in a field of view of the camera and to alarm the user in case of running the risk of leaving the field of view of the camera or a predetermined region of interest thereof.
11. The apparatus in accordance with any one of the previous claims, further comprising a visualizer (28) configured to visualize to the user the body portion currently treated.
12. The apparatus in accordance with any one of the previous claims, further comprising a log module (30) configured to log, for each candidate body portion of a set of candidate body portions, a temporal measure of how long the respective candidate body portion has been determined to be the body portion by the analyzer, and a visualizer (28) configured to visualize, for each candidate body portion, the temporal measure or a measure of remaining treatment demand for the respective candidate body portion determined based on the temporal measure, to the user.
13. A system comprising an apparatus (10) according to any of the previous claims and the personal hygienic device (12).
14. A method for determining a body portion of a user treated by the user using a personal hygienic device, comprising capturing the user to obtain a pictorial representation of the user while treating the body portion using the personal hygienic device, the pictorial representation showing the user's face with the user currently treating a certain head portion using the personal hygienic device; receiving sensor data from at least one inertial sensor residing in the personal hygienic device; and analyzing and combining the pictorial representation and the sensor data to determine the body portion, wherein the step of analyzing comprises first separately determining the treated body portion on the basis of the pictorial representation on the one hand and the inertial sensor data on the other hand and then combining both determinations to finally determine the treated body portion.
15. A computer program for performing, when running on an apparatus according to any one of claims 1 to 13, the method of claim 14.
</claims>
</document>
