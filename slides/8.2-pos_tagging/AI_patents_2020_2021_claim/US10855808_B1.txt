<document>

<filing_date>
2019-07-05
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2019-07-05
</priority_date>

<ipc_classes>
H04L12/24,H04L29/08
</ipc_classes>

<assignee>
SERVICENOW
</assignee>

<inventors>
DURVASULA, SREENIVAS
MOHANTY, AMITAV
</inventors>

<docdb_family_id>
71784708
</docdb_family_id>

<title>
Intelligent load balancer
</title>

<abstract>
Techniques for routing requests on a network are described. In accordance with certain aspects, a temporal window is incremented or moved over time to facilitate dynamic routing decisions. The temporal window may be used to project or estimate incoming request traffic based on a suitable probabilistic distribution model, such as a Poisson or Gaussian probability distribution, applied to the window so as to estimate or predict traffic at different times as the window is incremented. Estimated execution times for incoming requests may also be computed so that arrival and completion times of each request or traffic event can be modeled. Processor-implemented routines may be employed to solve the sub-problems defined by the temporal window incoming traffic estimation and the estimated execution times efficiently, allowing the parent or overall routing decision problem to be solved efficiently using dynamic processes, including in real-time contexts.
</abstract>

<claims>
1. A cloud platform, comprising: a data center comprising a plurality of application servers; a client network comprising a plurality of client devices, wherein the plurality of client devices generate requests to be processed by the application servers; a network over which the requests travel between the client network and the data center; and one or more load balancers configured to route the requests among the application servers using a priority tree based on predicted network events, wherein the one or more load balancers generate and use the priority tree by performing acts comprising: generating a temporal window having a width corresponding to a time interval; sliding the temporal window in increments through a series of future times; for each future time in the series, applying a probabilistic model to the temporal window to determine a probable number of expected requests of a respective request type at the respective future time within the time interval encompassed by the temporal window; based upon the probable number of expected requests of the respective request type for each future time in the series, executing a bin packing routine to generate the priority tree comprising nodes corresponding to expected requests and expected request types; assigning requests received over time at the one or more load balancers to a respective node of the priority tree, wherein the expected request and expected request type that correspond to the respective node are matched to the request and a type of the request; based on the assignment of a respective request to the respective node, routing the respective request to a respective application server; and updating the probabilistic model based on a number of nodes corresponding to expected requests and expected request types that were not assigned requests.
2. The cloud platform of claim 1, wherein the probabilistic model comprises one of a Poisson probability distribution or a Gaussian probability distribution.
3. The cloud platform of claim 1, wherein the request types correspond to different types of data or queries associated with requests generated by the client devices.
4. The cloud platform of claim 1, wherein the priority tree comprises a temporally ordered set of nodes based on when requests are expected to arrive.
5. The cloud platform of claim 1, wherein the one or more load balancers further perform acts comprising: updating the priority tree to remove nodes for which a corresponding request was not received and after a time associated with the respective node has passed.
6. The cloud platform of claim 1, wherein the one or more load balancers further perform acts comprising: updating the priority tree to add nodes as the temporal window slides through the series of future times.
7. The cloud platform of claim 1 wherein assigning requests to respective nodes is based on one or both of an arrival time and request type of the respective request.
8. The cloud platform of claim 1, wherein updating the probabilistic model comprises updating the probabilistic model based on a difference between an estimated execution time and an actual execution time of the requests.
9. A method for balancing requests on a network, comprising the acts of: sliding a temporal window forward in time in specified time increments, wherein the temporal window has a width corresponding to a time interval; as the temporal window slides forward in time, determining an expected number of requests for each of one or more request types at each time corresponding to a respective time increment to which the temporal window slides; executing a bin packing routine to generate a priority tree comprising nodes based on the expected number of requests for each of one or more request types at different future times, wherein each node corresponds to an expected request of a respective request type at a future time; as requests are received over time, assigning each request to a respective node of the priority tree, wherein an expected request and expected request type that correspond to the respective node are matched to the request and a type of the request, and wherein assignment of a respective request corresponds to the respective request being routed to a network resource associated with the respective node; and updating the determination of the expected number of requests based on a number of nodes not being assigned requests.
10. The method of claim 9, wherein the network is part of a client instance on a cloud platform.
11. The method of claim 9, wherein determining the expected number of requests for each of one or more request types at each time comprises applying a probabilistic model to the temporal window at each time.
12. The method of claim 11, wherein the probabilistic model comprises one of a Poisson probability distribution or a Gaussian probability distribution.
13. The method of claim 9, wherein the one or more request types comprise requests for different types of data or requests generated by different queries by client devices on the network.
14. The method of claim 9, wherein the priority tree comprises a temporally ordered set of nodes based on when requests are expected to arrive.
15. The method of claim 9, further comprising updating the priority tree as the temporal window is moved forward in time.
16. A load balancer, comprising: a processing component configured to execute stored routines; and a memory component configured to store executable routines, wherein the executable routines, when executed by the processing component, cause the processing component to perform acts comprising: sliding a temporal window forward in time in specified time increments, wherein the temporal window has a width corresponding to a time interval; as the temporal window slides forward in time, determining an expected number of requests for each of one or more request types at each time corresponding to a respective time increment to which the temporal window slides; executing a bin packing routine to generate a priority tree comprising nodes based on the expected number of requests for each of one or more request types at different future times, wherein each node corresponds to an expected request of a respective request type at a future time; as requests are received over time, assigning each request to a respective node of the priority tree, wherein an expected request and expected request type that correspond to the respective node are matched to the request and a type of the request, and wherein assignment of a respective request corresponds to the respective request being routed to a network resource associated with the respective node; and updating the determination of the expected number of requests based on a number of nodes not being assigned requests.
17. The load balancer of claim 16, wherein the load balancer is configured to route requests from a plurality of client devices within a client instance to a plurality of application servers in the client instance.
18. The load balancer of claim 16, wherein determining the expected number of requests for each of one or more request types at each time comprises applying a probabilistic model to the temporal window at each time.
19. The load balancer of claim 18, wherein the probabilistic model comprises one of a Poisson probability distribution or a Gaussian probability distribution.
20. The load balancer of claim 16, wherein the executable routines, when executed by the processing component further cause the processing component to perform acts comprising: updating the priority tree as the temporal window is moved forward in time.
</claims>
</document>
