<document>

<filing_date>
2019-11-14
</filing_date>

<publication_date>
2020-06-03
</publication_date>

<priority_date>
2018-11-30
</priority_date>

<ipc_classes>
G06N3/04,G06N3/063
</ipc_classes>

<assignee>
ROBERT BOSCH
</assignee>

<inventors>
ROCZNIK, THOMAS
PETERS, CHRISTIAN
DUERICHEN, ROBERT
</inventors>

<docdb_family_id>
68581637
</docdb_family_id>

<title>
BIT INTERPRETATION FOR CONVOLUTIONAL NEURAL NETWORK INPUT LAYER
</title>

<abstract>
To efficiently execute deep convolutional neural networks (CNN) on edge devices (e.g., wearable device like an Apple Watch or FitBit) it may be necessary to reduce the bit width of the network parameters down to 1-bit. Binarization at the first layer of a CNN has typically not been performed because it may lead to an increase in the output validation error of the input data. The method and systems provided include a binary input layer (BIL) which accepts binary input data by learning bit specific binary weights. By executing the CNN using binary input data, the present method and system may result in a reduction in the chip area consumed and the energy used in contrast to CNN models executed using floating point input data.
</abstract>

<claims>
1. A method for implementing a convolutional neural network comprising: receiving input data for the convolutional neural network; filtering the input data by applying a bitwise weight algorithm that learns bit specific relevance without a predefined ordinal structure being provided to generate direct binary input data; and providing the direct binary input data to a convolutional layer within the convolutional neural network.
2. The method of claim 1, wherein the direct binary input data is provided to the convolutional layer without having to perform additional normalization to the input data.
3. The method of claim 1, wherein the bitwise weight algorithm operates by summing a product of each individual input data value and a bit specific weight corresponding to each bit of the individual input data value.
4. The method of claim 3, wherein the bit specific weight is trained using a labeled dataset specific to a given use-case.
5. The method of claim 1, wherein the convolutional neural network further comprises one or more fully connected layers and a softmax layer.
6. The method of claim 1, wherein the direct binary input data is further provided to a binary input layer that includes a convolutional kernel (K) filter having a filter size that is at least a 1x1 array.
7. A method for implementing a convolutional neural network comprising: receiving input data for the convolutional neural network; filtering the input data by applying a bitwise weight algorithm that learns bit specific relevance without a predefined ordinal structure being provided to generate direct binary input data; and providing the direct binary input data to a binary input layer that includes a convolutional kernel (K) filter having a filter size that is at least a 1x1 array.
8. The method of claim 7, wherein the bitwise weight algorithm operates by summing a product of each individual input data value and a bit specific weight corresponding to each bit of the individual input data value.
9. The method of claim 8, wherein the bit specific weight is trained using a labeled dataset specific to a given use-case.
10. The method of claim 7, wherein the direct binary input data is provided to a convolutional layer without having to perform additional normalization to the input data.
11. The method of claim 7, wherein one or more convolutional kernel filters are included within the binary input layer.
12. The method of claim 7, wherein the binary input layer factorizes a convolution in a depth-wise and point-wise convolution.
13. The method of claim 7, wherein the convolutional neural network further comprises one or more fully connected layers and a softmax layer.
14. A system for implementing a convolutional neural network comprising: an input for receiving data; and a processor that includes logic for filtering the input data by applying a bitwise weight algorithm that learns bit specific relevance without a predefined ordinal structure being provided to generate direct binary input data; and providing the direct binary input data to a convolutional layer within the convolutional neural network.
15. The system of claim 14, wherein the processor further includes logic that provides the direct binary input data to a binary input layer that includes a convolutional kernel filter having a filter size that is at least a 1x1 array.
16. The system of claim 15, wherein the processor further includes logic that includes the convolutional layer capable of receiving the direct binary input data provided by the binary input layer.
17. The system of claim 15, wherein the binary input layer is designed to include one or more convolutional kernel filters.
18. The system of claim 14, wherein the bitwise weight algorithm operates by summing a product of each individual input data value by a bit specific weight corresponding to each bit of the individual input data value.
19. The system of claim 18, wherein the bit specific weight is trained using a labeled dataset specific to a given use-case.
20. The system of claim 14, wherein the convolutional neural network further comprises one or more fully connected layers and a softmax layer.
</claims>
</document>
