<document>

<filing_date>
2020-07-19
</filing_date>

<publication_date>
2021-01-14
</publication_date>

<priority_date>
2018-06-22
</priority_date>

<ipc_classes>
G06K9/00,G06T17/00,G06T19/20,G06T7/10,G06T7/246
</ipc_classes>

<assignee>
MOTIONVIRTUAL
</assignee>

<inventors>
PARK, JUN HO
</inventors>

<docdb_family_id>
74101959
</docdb_family_id>

<title>
METHOD AND SOFTWARE SYSTEM FOR MODELING, TRACKING AND IDENTIFYING ANIMATE BEINGS AT REST AND IN MOTION AND COMPENSATING FOR SURFACE AND SUBDERMAL CHANGES
</title>

<abstract>
Methods and systems for creating 3D models of biological entities from different types of sensor data are provided. For instance, these methods can track an underlying network of nodes corresponding to blood vessel networks in 3 dimensions. Such methods adapt models to compensate for changes on the surface and in the structure that continuously occur in living entities, such as when blood flows, hands stretch, heads turn, and the like. These 3D models can then be used to perform functions such as motion tracking, biometric authentication, and visualizations in air (such as with Augmented and Virtual Reality) using 3D models as positional references.
</abstract>

<claims>
1. A method for a system to perform 3D model creation and matching, the method comprising: building a model for an object, the model including structure information about the object; generating a first probability unit of the model, wherein the first probability unit includes a first probability distribution of a state of the model and a second probability distribution of a state of the object; comparing the first probability unit with a second probability unit generated through observed data of the object, via a matching path based on the structure information; generating a related probability distribution associated with the matching path; and predicting the state of the object based on the related probability distribution.
2. The method of claim 1, wherein the state of the model includes position, orientation, 6 degrees of freedom (6DoF), velocity, acceleration, color, and/or element types.
3. The method of claim 1, wherein an identified part in the model is associated with the first probability unit, wherein the identified part corresponds to a part in the object with respect to the related probability distribution.
4. The method of claim 1, wherein the comparing is performed via a plurality of matching paths, including the matching path based on the structure information, for comparing the structure state of the model with a plurality of structure states of the object.
5. The method of claim 4, wherein the comparing is performed for a plurality of points of a state of the model by propagating along a network or on a surface of the object.
6. The method of claim 5, wherein a scheme is utilized to predict a state estimate of a next point of the model, and wherein the scheme includes surface geometry, surface tension and/or a surface elasticity system of the object.
7. The method of claim 6, wherein the state estimate of the point is selected based on a maximum likelihood estimation.
8. The method of claim 1, further comprising: calculating a state of a point of the model from the related probability distribution; and updating the state of the point according to the probability distribution changes.
9. The method of claim 1, wherein the observed data of the object represents state data pre-stored in the system or is a data stream generated in real time.
10. The method of claim 1, wherein the related probability distribution is generated by sharing a result of the comparing along the matching path, and wherein the result of the comparing comprises a differential state between the first probability distribution and the second probability distribution.
11. The method of claim 10, further comprising: calculating the differential state from the related probability distribution; and balancing the state of the model by continuously adjusting the differential 6DoF value.
12. The method of claim 3, wherein the identified part is time-sequentially updated by tracking, transformation, or deformation of the model according to a change of the related probability distribution.
13. The method of claim 1, wherein the model is built using one or more sensors, and wherein the sensor comprises one or more of a stereo sensor, a time-of-flight (TOF) sensor, a depth sensor, an RGB sensor, an infrared sensor, or a thermal imaging sensor.
14. The method of claim 1, wherein the model is built using data stored in the system.
15. The method of claim 1, wherein the structure information of the model represents blood vessel, skin, or surface geometry and topology in a body part of a person.
16. The method of claim 1, wherein the method is applied to at least one of a hand segmentation in 2D, a hand segmentation in 3D, a hand collision with other hands in 2D, a hand collision with other hands in 3D, a hand-object interaction, an elemental ID tracking, a motion tracking, a virtual-reality application, an augmented-reality application, a mixed-reality application, or a combination of hands and a virtual object surrounding the hands using a 3D coordinate system.
17. The method of claim 1, wherein the system comprises a sensor, a processor configured to process data, an input/output (I/O) unit, a memory, a communication unit, or a combination thereof.
</claims>
</document>
