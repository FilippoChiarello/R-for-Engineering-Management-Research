<document>

<filing_date>
2019-08-23
</filing_date>

<publication_date>
2020-05-28
</publication_date>

<priority_date>
2018-11-27
</priority_date>

<ipc_classes>
G06K9/00,G06N20/10,G06N3/08,G06T15/60,G06T17/00,G06T9/00
</ipc_classes>

<assignee>
RAYTHEON COMPANY
</assignee>

<inventors>
KIM, PETER
SAND, MICHAEL J.
HOLLENBECK, MATTHEW D.
</inventors>

<docdb_family_id>
67874553
</docdb_family_id>

<title>
COMPUTER ARCHITECTURE FOR ARTIFICIAL IMAGE GENERATION USING AUTO-ENCODER
</title>

<abstract>
A computer architecture for artificial image generation is disclosed. According to some aspects, a computing machine receives a voxel model of a first set of objects different from a target object. The target object is to be recognized using an image recognizer. The computing machine generates, based on the voxel model, a set of TSB (target shadow background-mask) images of the first set of objects. The computing machine receives, at an auto-encoder, a set of real images of the first set of objects. The computing machine generates, using the auto-encoder, one or more artificial images of the target object based on the set of TSB images. The auto-encoder learns differences between the target object and the first set of objects. The computing machine provides, as output, the generated one or more artificial images of the target object.
</abstract>

<claims>
1. An image processing apparatus, the apparatus comprising: processing circuitry and memory; the processing circuitry to: receive a voxel model of a first set of objects different from a target object, wherein the target object is to be recognized using an image recognizer; generate, based on the voxel model, a set of TSB (target shadow background-mask) images of the first set of objects; receive, at an auto-encoder, a set of real images of the first set of objects; generate, using the auto-encoder, one or more artificial images of the target object based on the set of TSB images, wherein the auto encoder encodes, using a sub-encoder, the set of TSB images into a latent vector and decodes, using a sub-decoder, the latent vector to generate the one or more artificial images, wherein the auto-encoder learns differences between the target object and the first set of objects; and provide, as output, the generated one or more artificial images of the target object.
2. The apparatus of claim 1, wherein input received at the auto-encoder lacks real images of the target object.
3. The apparatus of claim 1, wherein the sub-encoder comprises a plurality of convolution layers and a plurality of pooling layers interspersed with the convolution layers, and wherein the sub-encoder is trained, using a machine learning training algorithm, to generate the latent vector based on the set of TSB images.
4. The apparatus of claim 1, wherein the sub-decoder comprises a plurality of deconvolution layers and a plurality of depooling layers interspersed with the deconvolution layers, and wherein the sub-decoder is trained, using a machine learning training algorithm, to generate the one or more artificial images based on the latent vector.
5. The apparatus of claim 1, wherein the processing circuitry is further to: train, using the generated one or more artificial images, the image recognizer to recognize the target object; and provide, as output, an indication that the image recognizer has been trained.
6. The apparatus of claim 5, wherein the processing circuitry is further to: use the trained image recognizer to recognize a new image of the target object.
7. The apparatus of claim 5, wherein the image recognizer comprises a ResNet (residual neural network).
8. The apparatus of claim 1, wherein the sub-encoder comprises a plurality of convolution pools, each convolution pool being followed by a batch normalization, and each batch normalization being followed by a ReLU (rectified linear unit).
9. The apparatus of claim 8, wherein a kernel size of each convolution pool is larger than a kernel size of a previous convolution pool.
10. The apparatus of claim 1, wherein the sub-decoder comprises a plurality of skip connects, each skip connect being followed by a batch normalization, each batch normalization being followed by a ReLU (rectified linear unit), and each ReLU being followed by a decode convolution.
11. The apparatus of claim 10, wherein a kernel size of each decode convolution is smaller than a kernel size of a previous decode convolution.
12. A non-transitory machine-readable medium for image processing, the machine-readable medium storing instructions which, when executed by processing circuitry of one or more machines, cause the processing circuitry to: receive a voxel model of a first set of objects different from a target object, wherein the target object is to be recognized using an image recognizer; generate, based on the voxel model, a set of TSB (target shadow background-mask) images of the first set of objects; receive, at an auto-encoder, a set of real images of the first set of objects; generate, using the auto-encoder, one or more artificial images of the target object based on the set of TSB images, wherein the auto encoder encodes, using a sub-encoder, the set of TSB images into a latent vector and decodes, using a sub-decoder, the latent vector to generate the one or more artificial images, wherein the auto-encoder learns differences between the target object and the first set of objects; and provide, as output, the generated one or more artificial images of the target object.
13. The machine-readable medium of claim 12, wherein input received at the auto-encoder lacks real images of the target object.
14. The machine-readable medium of claim 12, wherein the sub-encoder comprises a plurality of convolution layers and a plurality of pooling layers interspersed with the convolution layers, and wherein the sub-encoder is trained, using a machine learning training algorithm, to generate the latent vector based on the set of TSB images.
15. The machine-readable medium of claim 12, wherein the sub-decoder comprises a plurality of deconvolution layers and a plurality of depooling layers interspersed with the deconvolution layers, and wherein the sub-decoder is trained, using a machine learning training algorithm, to generate the one or more artificial images based on the latent vector.
16. The machine-readable medium of claim 12, wherein the processing circuitry is further to: train, using the generated one or more artificial images, the image recognizer to recognize the target object; and provide, as output, an indication that the image recognizer has been trained.
17. The machine-readable medium of claim 16, wherein the processing circuitry is further to: use the trained image recognizer to recognize a new image of the target object.
18. The machine-readable medium of claim 16, wherein the image recognizer comprises a ResNet (residual neural network).
19. An image processing method comprising: receiving a voxel model of a first set of objects different from a target object, wherein the target object is to be recognized using an image recognizer; generating, based on the voxel model, a set of TSB (target shadow background-mask) images of the first set of objects; receiving, at an auto-encoder, a set of real images of the first set of objects; generate, using the auto-encoder, one or more artificial images of the target object based on the set of TSB images, wherein the auto encoder encodes, using a sub-encoder, the TSB model into a latent vector and decodes, using a sub-decoder, the latent vector to generate the one or more artificial images, wherein the auto-encoder learns differences between the target object and the first set of objects; and providing, as output, the generated one or more artificial images of the target object.
20. The method of claim 19, wherein input received that the auto-encoder lacks real images of the target object.
</claims>
</document>
