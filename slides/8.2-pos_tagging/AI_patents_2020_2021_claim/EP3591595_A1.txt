<document>

<filing_date>
2019-06-28
</filing_date>

<publication_date>
2020-01-08
</publication_date>

<priority_date>
2018-07-02
</priority_date>

<ipc_classes>
G06Q10/06,G11B27/031
</ipc_classes>

<assignee>
AVID TECHNOLOGY
</assignee>

<inventors>
MATHUR, SHAILENDRA
</inventors>

<docdb_family_id>
67137768
</docdb_family_id>

<title>
AUTOMATED MEDIA PUBLISHING
</title>

<abstract>
The described methods, systems, and computer program products enable media composition editors to tag compositional objects with editorial rendition rules that specify how rendering decisions are to be made and how source media assets are to be selected and processed to generate an output rendering of a media composition that adheres to the editor's rendition-related choices. The editorially-specified rendition rules include spatial-type rules, temporal-type rules, and color-type rules, and generally pertain to the spatial, temporal, and color ranges and resolutions to be included within a rendition. When a rendition of a media composition is to be generated, a rendition engine interprets and applies the editorial rendition rules to generate and output the rendition in accordance with rendition parameters supplied to the rendition engine by a rendition profile, and, in some cases, by the media composition and the source media assets.
</abstract>

<claims>
1. A method of generating a rendition of a media composition, the method comprising: receiving the media composition, wherein the media composition includes a compositional object that references a source media asset and wherein the compositional object is associated with an editorial rendition rule specified by an editor of the media composition using a media composition application; receiving a rendition profile that specifies media essence encoding parameters for the rendition of the media composition; and generating from the source media asset the rendition of the media composition in accordance with the editorial rendition rule and the media essence encoding parameters for the rendition of the media composition.
2. The method of claim 1, further comprising enabling an editor using the media composition application running on a media composition host system to: edit the media composition; specify the editorial rendition rule for the compositional object; and associate the editorial rendition rule with the compositional object of the media composition; preferably wherein the steps of receiving the media composition, receiving the rendition profile and generating the rendition are performed by a rendition engine.
3. A method of editing a media composition, the method comprising: enabling an editor using a media composition application running on a media composition host system to: edit the media composition, wherein the media composition includes a compositional object, and the compositional object references a source media asset; specify an editorial rendition rule for the compositional object; and associate the editorial rendition rule with the compositional object of the media composition; and when a rendition of a given media composition is to be generated, a rendition engine: receives the given media composition and an editorial rendition rule that the editor has specified and associated with a compositional object of the given media composition; receives a rendition profile that specifies media essence encoding parameters for the rendition of the given media composition; inputs a source media asset of the given composition; and generates from the source media asset of the given media composition the rendition of the given media composition in accordance with the editorial rendition rule of the given composition and the media essence encoding parameters for the rendition of the given composition.
4. The method of claim 2 or 3, wherein the media composition application includes the rendition engine, or the rendition engine is located remotely from a location from which the media composition is received and/or is hosted on a platform external to the media composition host.
5. The method of any of the preceding claims, wherein the media composition has a plurality of versions, and the rendition profile further specifies a version of the plurality of versions of the media composition that is to be used to generate the rendition of the composition.
6. The method of any of the preceding claims, wherein the editorial rendition rule is a spatial editorial rendition rule and at least one of the media essence encoding parameters specified by the rendition profile is a spatial rendition parameter; preferably wherein the spatial rendition parameter is a framing box that defines a portion of a video frame of the compositional object of the media composition, and wherein a first portion of the source media asset of the composition that lies within the framing box is prioritized for inclusion within the rendition; preferably wherein an aspect ratio of a target display for the rendition is larger than an aspect ratio of the framing box, and wherein a second portion of the source media asset of the composition outside the framing box is also prioritized for inclusion within the rendition, wherein the second portion of the source media asset of the media composition includes media essence data.
7. The method of any of claims 1 to 5, wherein the editorial rendition rule is a temporal editorial rendition rule and at least one of the media essence encoding parameters specified by the rendition profile is a temporal rendition parameter, preferably wherein the temporal rendition parameter includes a temporal framing range that defines a temporal range within the source media asset of the composition, and wherein a temporal portion of the source media asset of the media composition that lies within the temporal framing range is prioritized for inclusion within the rendition.
8. The method of any of claims 1 to 5, wherein the editorial rendition rule is a dynamic range editorial rendition rule and at least one of the media essence encoding parameters specified by the rendition profile is a dynamic range rendition parameter.
9. The method of claim 8, wherein the source media asset of the composition is one of: a video asset, and the dynamic range rendition parameter is a legal dynamic range that defines a range of pixel brightness values within the source media asset of the composition, and wherein pixels of the source media asset of the composition having brightness values that lie within the legal range are prioritized for inclusion within the rendition; and an audio asset, and the dynamic range rendition parameter is a legal dynamic range that defines a range of audio sample intensity values within the source media asset of the composition, and wherein audio samples of the source media asset of the composition having intensity values that lie within the legal range are prioritized for inclusion within the rendition.
10. The method of any of claims 1 to 5, wherein the editorial rendition rule is a color editorial rendition rule and at least one of the media essence encoding parameters specified by the rendition profile is a color gamut rendition parameter; preferably wherein: the source media asset of the composition is one of a graphics asset and a video asset; the color gamut rendition parameter includes a legal color range that defines a multi-dimensional region within a multi-dimensional color space; and pixels of the source media asset of the composition having color values that lie within the legal color range are prioritized for inclusion within the rendition.
11. The method of any of claims 1 to 5, wherein: the editorial rendition rule is a spatial editorial rendition rule for layout of title text on a frame of the rendition; at least one media essence encoding parameter is a spatial framing box; the source media asset of the composition is a text titling effect; and text of the text titling effect is rendered within the framing box on the frame of the rendition.
12. The method of any of claims 1 to 5, wherein: the editorial rendition rule is a compositing editorial rendition rule; at least one media essence encoding parameter is a spatial framing box; the source media asset of the composition is a compositing effect; and a frame of the rendition with a composited image within the framing box is rendered.
13. The method of any of the preceding claims, wherein the generating step includes executing logic that is learned using deep learning methods from captured editorial rendition decisions of a cohort of editors working with a range of media content, source media types, and rendition requirements.
14. A computer program product comprising:
non-transitory computer-readable storage with computer program instructions stored thereon, wherein the computer program instructions, when processed by a computing system, instruct the computing system to perform a method as set out in any of the preceding claims.
15. A media composition rendition engine comprising: a memory for storing computer-readable instructions; and a processor connected to the memory, wherein the processor, when executing the computer-readable instructions, causes the media composition rendition engine to perform a method as set out in any of claims 1 to 13.
</claims>
</document>
