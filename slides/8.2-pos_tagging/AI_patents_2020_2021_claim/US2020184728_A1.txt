<document>

<filing_date>
2019-12-06
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2014-11-16
</priority_date>

<ipc_classes>
G02B27/01,G06F1/16,G06F3/00,G06F3/01,G06F3/03,G06F3/0346,G06T15/04,G06T17/20,G06T19/00
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
PETROVSKAYA, ANNA
VARVAK, PETER
</inventors>

<docdb_family_id>
59313776
</docdb_family_id>

<title>
OPTIMIZING HEAD MOUNTED DISPLAYS FOR AUGMENTED REALITY
</title>

<abstract>
While many augmented reality systems provide "see-through" transparent or translucent displays upon which to project virtual objects, many virtual reality systems instead employ opaque, enclosed screens. Indeed, eliminating the user's perception of the real-world may be integral to some successful virtual reality experiences. Thus, head mounted displays designed exclusively for virtual reality experiences may not be easily repurposed to capture significant portions of the augmented reality market. Various of the disclosed embodiments facilitate the repurposing of a virtual reality device for augmented reality use. Particularly, by anticipating user head motion, embodiments may facilitate scene renderings better aligned with user expectations than na√Øve renderings generated within the enclosed field of view. In some embodiments, the system may use procedural mapping methods to generate a virtual model of the environment. The system may then use this model to supplement the anticipatory rendering.
</abstract>

<claims>
1. (canceled)
2. 2.-20. (canceled)
21. A system comprising: memory including instructions; at least one processor to execute the instructions to, at least: retrieve a first image during a first time; impose a border constraint on a first portion of the first image, the border constraint outside a field of view, the border constraint to cause a second portion of the first image to be within the field of view during the first time; and cause a subset of the first portion of the first image to be within the field of view during a second time in response to receiving inertial measurement unit (IMU) data.
22. The system as defined in claim 21, wherein the at least one processor is to retrieve the IMU data at a rate faster than a camera capture rate of second image data.
23. The system as defined in claim 22, wherein the at least one processor is to determine a predicted pose during the second time, the predicted pose indicative of user head movement.
24. The system as defined in claim 22, wherein the at least one processor is to apply at least one of positional or rotational velocity data to determine a predicted pose during the second time.
25. The system as defined in claim 24, wherein the at least one processor is to apply a Kalman filter to determine the predicted pose.
26. The system as defined in claim 21, wherein the at least one processor is to reduce user nausea by rendering the subset of the first portion of the transformed frame from the border constraint to the field of view of a movable display.
27. The system as defined in claim 21, wherein the at least one processor is to render second image data during a third time as a mesh in response to detecting the IMU data during the second time.
28. A computer readable storage device or storage disk comprising instructions that, when executed, cause the at least one processor to at least: retrieve a first image during a first time; impose a border constraint on a first portion of the first image, the border constraint outside a field of view, the border constraint to cause (a) a second portion of the first image to be within the field of view and (b) the first portion of the first image to be concealed during the first time; and cause a subset of the first portion of the first image to be within the field of view during a second time in response to receiving inertial measurement unit (IMU) data.
29. The storage device or storage disk as defined in claim 28, wherein the instructions, when executed, cause the at least one processor to retrieve the IMU data at a rate faster than a camera capture rate of second image data.
30. The storage device or storage disk as defined in claim 29, wherein the instructions, when executed, cause the at least one processor to determine a predicted pose during the second time, the predicted pose indicative of user head orientation.
31. The storage device or storage disk as defined in claim 29, wherein the instructions, when executed, cause the at least one processor to apply at least one of positional or rotational velocity data to determine a predicted pose during the second time.
32. The storage device or storage disk as defined in claim 31, wherein the instructions, when executed, cause the at least one processor to apply a Kalman filter to determine the predicted pose.
33. The storage device or storage disk as defined in claim 28, wherein the instructions, when executed, cause the at least one processor to reduce user nausea by rendering the subset of the first portion of the first image from the border constraint to the field of view of a movable display.
34. The storage device or storage disk as defined in claim 28, wherein the instructions, when executed, cause the at least one processor to render a second image during a third time as a mesh in response to detecting the IMU data during the second time.
35. A computer implemented method, comprising: retrieving an image during a first time; imposing a border constraint on a first portion of the image, the border constraint outside a field of view, the border constraint to cause a second portion of the image to be within the field of view during the first time; and causing a subset of the first portion of the image to be within the field of view during a second time in response to receiving inertial measurement unit (IMU) data.
36. The method as defined in claim 35, further including retrieving the IMU data at a rate faster than a camera capture rate of a second image.
37. The method as defined in claim 36, further including determining a predicted pose during the second time, the predicted pose indicative of user head movement.
38. The method as defined in claim 36, further including applying at least one of positional or rotational velocity data to determine a predicted pose during the second time.
39. The method as defined in claim 38, further including applying a Kalman filter to determine the predicted pose.
40. The method as defined in claim 35, further including reducing user nausea by rendering the subset of the first portion of the image from the border constraint to the field of view of a movable display.
41. The method as defined in claim 35, further including rendering a second image during a third time as a mesh in response to detecting the IMU data during the second time.
</claims>
</document>
