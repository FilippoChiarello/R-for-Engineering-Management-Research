<document>

<filing_date>
2020-02-03
</filing_date>

<publication_date>
2020-08-13
</publication_date>

<priority_date>
2019-02-11
</priority_date>

<ipc_classes>
G06N3/08,G06Q50/00,H04L29/06
</ipc_classes>

<assignee>
CYABRA STRATEGY
</assignee>

<inventors>
FRANGI, SENDI
SHRAGA, IDO
BRAHMY, DAN
DAAR, YOSSEF
</inventors>

<docdb_family_id>
71944690
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR NEAR REAL TIME DETECTION OF ATTACKS AND INFLUENCE IN SOCIAL NETWORKS
</title>

<abstract>
A system for identifying attacks against a customer in a social network includes a conversation monitor, a user type detector and an attack identifier. The conversation monitor discovers a plurality of users participating in a discourse related to the customer. The user type detector identifies the type of each user that can be real or fake and the attack identifier identifies an attack according to the type of the users. A method for identifying a fake user in a social network includes evaluating an authenticity of a user by applying a set of tests, each test in the set includes one or more rules on one or more parameters associated with the user, each test creating a weighted score. The method also includes calculating a weighted average score from the weighted scores and determining if a user is fake according to the weighted average score compared to a configured threshold.
</abstract>

<claims>
1. A system for identifying attacks against a customer in a social network, the system comprising: a conversation monitor to discover a plurality of users participating in a discourse related to the customer; a user type detector to identify a type of a user, from the plurality of users, as either real or fake; and an attack identifier to identify an attack according to the type of the users.
2. The system of claim 1 wherein an attack is a negative campaign that comprises one or more fake users and is orchestrated by one or more real users.
3. The system of claim 1 also comprising a discourse analyzer to identify one or more key elements in the discourse, the conversation monitor to discover the plurality of users participating in conversations containing one of the key elements.
4. The system of claim 1 wherein the user type detector also comprises an activity analyzer to analyze an activity of each user and to provide indications regarding the type of the user according to the activity.
5. The system of claim 1 wherein the user type detector also comprises a language analyzer to analyze a language of each user and provide indications regarding the type of the user according to the language.
6. The system of claim 1 wherein the user type detector also comprises a link analyzer to analyze a structure of a social network of each user and provide indications regarding the type of the user according to the structure of the social network.
7. The system of claim 1 wherein the user type detector also comprises a visual content analyzer to analyze a category of visual content, related to each user, the category of content is one of: genuine, modified and generated and provide indications regarding the type of the user according to the detected type.
8. The system of claim 7 wherein the visual content analyzer to use a generative adversarial network (GAN) to detect generated visual content.
9. The system of claim 1 wherein the user type detector also comprises a fake user detector to define whether a fake user is a bot or an avatar in a network of fake users.
10. The system of claim 1 wherein the user type detector also comprises a unified entity creator to create for each user a unified entity representing the user in a plurality of networks.
11. The system of claim 1 wherein the attack identifier to identify an attack according to the number of users having a type fake.
12. A method for identifying attacks against a customer in a social network, the method comprising: discovering users participating in a discourse related to the customer; identifying a type of each user; and identifying an attack according to the type of the users.
13. The method of claim 12 wherein an attack is a negative campaign that comprises one or more fake users and is orchestrated by one or more real users.
14. The method of claim 12 also comprising identifying one or more key elements in the discourse and discovering the plurality of users participating in conversations containing one of the key elements.
15. The method of claim 12 wherein the identifying also comprises analyzing an activity of each user and providing indications regarding the type of the user according to the activity.
16. The method of claim 12 wherein the identifying also comprises analyzing a language of each user and providing indications regarding the type of the user according to the language.
17. The method of claim 12 wherein the identifying also comprises analyzing a structure of a network of each user and providing indications regarding the type of the user according to the structure of the network.
18. The method of claim 12 wherein the identifying also comprises: detecting a category of visual content related to each user, the category is one of: genuine, modified and generated; and providing an indication regarding the type of the user according to the detected type.
19. The method of claim 12 wherein the identifying also comprises defining whether a fake user is either a bot or an avatar.
20. The method of claim 12 wherein the identifying also comprises creating for each user a unified entity representing the user in a plurality of networks.
21. The method of claim 20 wherein the identifying also comprising considering characteristics of the unified entity.
22. A method for identifying a fake user in a social network, the method comprising: evaluating an authenticity of a user by applying a set of tests, each test in the set comprising one or more rules on one or more parameters associated with the user, each test creating a weighted score; calculating a weighted average score from the weighted scores; and determining if a user is fake according to the weighted average score compared to a configured threshold.
23. The method of claim 22 wherein a test is an artificial neural network (ANN), the rules are the structure of the ANN and the weighted score is the output of the ANN.
24. The method of claim 22 wherein the set of tests comprises: analyzing the language of the user and extracting a set of characteristics; building an expected profile from the characteristics; comparing the expected profile with an actual profile provided by the user; and creating a language score reflecting the degree of variation between the expected profile and the actual profile.
25. The method of claim 22 wherein the set of tests comprises: detecting a category of visual content related to each user, the category is one of: genuine, modified and generated; and providing an indication regarding the type of the user according to the detected category.
26. The method of claim 22 wherein the detecting a category of visual content comprises using a generative adversarial network (GAN) to detect generated visual content.
</claims>
</document>
