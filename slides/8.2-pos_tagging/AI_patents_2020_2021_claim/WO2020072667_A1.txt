<document>

<filing_date>
2019-10-02
</filing_date>

<publication_date>
2020-04-09
</publication_date>

<priority_date>
2018-10-04
</priority_date>

<ipc_classes>
G01C21/34,G01C21/36,G05D1/02
</ipc_classes>

<assignee>
ZOOX
</assignee>

<inventors>
HONG, XI JOEY
SAPP, BENJAMIN JOHN
</inventors>

<docdb_family_id>
68296776
</docdb_family_id>

<title>
TRAJECTORY PREDICTION ON TOP-DOWN SCENES
</title>

<abstract>
Techniques are discussed for determining predicted trajectories based on a top-down representation of an environment. Sensors of a first vehicle can capture sensor data of an environment, which may include agent(s) separate from the first vehicle, such as a second vehicle or a pedestrian. A multi-channel image representing a top-down view of the agent(s) and the environment and comprising semantic information can be generated based on the sensor data. Semantic information may include a bounding box and velocity information associated with the agent, map data, and other semantic information. Multiple images can be generated representing the environment over time. The image(s) can be input into a prediction system configured to output a heat map comprising prediction probabilities associated with possible locations of the agent in the future. A predicted trajectory can be generated based on the prediction probabilities and output to control an operation of the first vehicle.
</abstract>

<claims>
What is claimed is:
1. A system comprising:
one or more processors; and
one or more computer-readable media storing instructions executable by the one or more processors, wherein the instructions, when executed, cause the system to perform operations comprising:
receiving sensor data of an environment captured by a sensor of a vehicle;
generating, based at least in part on the sensor data, an image representing a top-down view of the environment, the image comprising information associated with an object;
determining, based at least in part on the image, a heat map associated with prediction probabilities of possible locations associated with the object; determining, based at least in part on the heat map, a predicted traj ectory associated with the object; and
determining, based at least in part on the predicted traj ectory, a traj ectory for the vehicle to travel in the environment.
2. The system of claim 1, wherein the information associated with the object comprises one or more of bounding box information or velocity information, and wherein determining the predicted trajectory comprises:
determining a predicted point based at least in part on a highest probability portion associated with a portion of the heat map and a cost associated with determining the predicted trajectory based at least in part on the predicted point.
3. The system of claim 2, wherein:
the predicted point is a first predicted point;
the highest probability portion is a first highest probability portion;
the portion is a first portion;
the cost is a first cost;
+ "— '-"' 'oi is a first predicted trajectory; and the operations further comprise:
masking, as a masked heat map, a second portion of the heat map associated with the first predicted point, wherein the second portion of the heat map comprises at least the first portion;
determining, as a second predicted point, a second highest probability portion associated with a third portion of the masked heat map; and
determining a second predicted trajectory based at least in part on the second predicted point and on a second cost associated with determining the second predicted trajectory based at least in part on the second predicted point.
4. The system of any one of claims 2 to 3, wherein the image comprises:
a first channel associated with the bounding box and semantic information associated with the object; and
a second channel associated with the velocity information associated with the object, and
wherein the operations further comprise inputting the first channel and the second channel into a machine learning model.
5. The system of any one of claims 1 to 4, the operations further comprising inputting the image into a machine learning model to determine the heat map, wherein the machine learning model comprises:
a convolutional neural network (CNN); and
a long short-term memory (LSTM) component coupled to the CNN.
6. A method comprising:
receiving sensor data of an environment;
generating an image representing a top-down view of an object in the environment, wherein the image comprises information associated with the object or the environment;
inputting the image into an algorithm configured to generate a probability distribution associated with a predicted location of the object;
determining, based at least in part on the probability distribution, a predicted Irni prlnrv n¾¾nrifi†fffl u ilh ihe object; and controlling a vehicle based at least in part on the predicted trajectory.
7. The method of claim 6, wherein the probability distribution is represented as a heat map discretizing portions of the environment, wherein a prediction probability of the probability distribution is associated with a portion of the heat map.
8. The method of claim 7, wherein determining the predicted traj ectory comprises : determining a predicted point based at least in part on a highest probability portion of the heat map and a cost associated with the predicted trajectory based at least in part on the predicted point.
9. The method of claim 8, wherein:
the predicted point is a first predicted point;
the highest probability portion is a first highest probability portion;
the portion is a first portion;
the cost is a first cost;
the predicted trajectory is a first predicted trajectory; and
the method further comprises:
masking, as a masked heat map, a second portion of the heat map associated with the first predicted point, wherein the second portion of the heat map comprises at least the first portion; and
determining a second predicted point based at least in part on a second highest probability portion of the heat map and a second cost associated with determining a second predicted trajectory based at least in part on the second predicted point.
10. The method of any one of claims 6 to 9, wherein the image comprises a plurality of channels, a channel of the plurality of channels comprising at least one of:
a location of the object;
an extent of the object;
a bounding box associated with the object;
velocity information associated with the object;
arrftlprafinn information associated with the object; turn indicator status of the object;
map data associated with the environment; or
traffic light information associated with the environment.
11. The method of any one of claims 6 to 10, wherein:
the algorithm is a machine learning model comprising a convolutional neural network trained to generate a heat map representing the probability distribution; and the information comprises one or more of a classification of the object, velocity information associated with the object, or a bounding box associated with the object.
12. The method of any one of claims 6 to 11, wherein the vehicle is an autonomous vehicle, and wherein controlling the autonomous vehicle based at least in part on the predicted trajectory comprises:
generating a trajectory for the autonomous vehicle to follow to traverse the environment; and
controlling the autonomous vehicle based at least in part on the trajectory.
13. The method of any one of claims 6 to 12, further comprising:
capturing, using a sensor on the vehicle, the sensor data of the environment, wherein the sensor comprises one or more of:
a LIDAR sensor;
a RADAR sensor;
an image sensor; or
a time of flight sensor.
14. The method of any one of claims 6 to 13, wherein:
the sensor data represents the environment at a first time;
the probability distribution is a first probability distribution associated with a second time after the first time;
the predicted location is a first predicted location; and
the algorithm is further configured to generate:
a second probability distribution associated with a second predicted 1 nr, ΊI inn nf ihr nhirrt at a third time after the second time.
15. A computer program product comprising coded instructions that, when run on a computer, implement a method as claimed in any of claims 6 to 14.
</claims>
</document>
