<document>

<filing_date>
2018-04-26
</filing_date>

<publication_date>
2020-05-12
</publication_date>

<priority_date>
2018-04-26
</priority_date>

<ipc_classes>
G01S17/89,G05D1/00,G05D1/02,G06K9/00,G06K9/62,G06N3/08,G06T7/181,G06T7/187,G06T7/521
</ipc_classes>

<assignee>
ZOOX
</assignee>

<inventors>
ANGUELOV, DRAGOMIR DIMITROV
DAS, SUBHASIS
PFEIFFER, DAVID
WANG, ZENG
ZELENER, ALLAN
</inventors>

<docdb_family_id>
68292419
</docdb_family_id>

<title>
Data segmentation using masks
</title>

<abstract>
A vehicle can include various sensors to detect objects in an environment. Sensor data can be captured by a perception system in a vehicle and represented in a voxel space. Operations may include analyzing the data from a top-down perspective. From this perspective, techniques can associate and generate masks that represent objects in the voxel space. Through manipulation of the regions of the masks, the sensor data and/or voxels associated with the masks can be clustered or otherwise grouped to segment data associated with the objects.
</abstract>

<claims>
1. A system comprising: one or more processors; and one or more computer-readable media storing instructions executable by the one or more processors, wherein the instructions, when executed, cause the system to perform operations comprising: capturing sensor data using a light detection and ranging (LIDAR) sensor on a vehicle; associating the sensor data with a voxel space, the voxel space comprising at least three dimensions; generating a two-dimensional representation of the voxel space, the two-dimensional representation comprising a number of image channels; inputting the two-dimensional representation into a machine learning algorithm; receiving, from the machine learning algorithm, a first mask representing an object in the voxel space in two dimensions; generating, based at least in part on an expansion of the first mask, a second mask, the expansion based at least in part on a region growing algorithm, a size of the first mask, or an intersection with a third mask associated with another object; and segmenting, based at least in part on the second mask, the sensor data.
2. The system of claim 1, wherein the machine learning algorithm is trained to receive captured LIDAR data representing a detected object having a first width and a first length and to output a mask associated with the detected object, the mask having a second width less than or equal to the first width and a second length less than or equal to the first length.
3. The system of claim 1, wherein a pseudo-pixel is associated with a voxel of the voxel space, the pseudo-pixel representing a column of voxels of the voxel space.
4. The system of claim 3, wherein the pseudo-pixel comprises features associated with the column of voxels.
5. The system of claim 1, wherein segmenting the sensor data comprises using the region growing algorithm to cluster one or more voxels of the voxel space within the second mask.
6. A method comprising: capturing sensor data of an environment using one or more sensors, the sensor data indicative of an object in the environment; associating the sensor data with a voxel space; receiving a first mask associated with a portion of the voxel space, the first mask representing a region smaller in size than the object; generating a second mask by expanding the first mask; and segmenting, based at least in part on the second mask, the sensor data.
7. The method of claim 6, further comprising: generating, based at least in part on segmenting the sensor data, a trajectory for an autonomous vehicle; and controlling, based at least in part on the trajectory, the autonomous vehicle to traverse the environment.
8. The method of claim 6, further comprising: inputting a two-dimensional representation of the voxel space into a machine learning algorithm; and receiving, as the first mask, an output of the machine learning algorithm.
9. The method of claim 8, wherein the two-dimensional representation of the voxel space comprises an image having a number of channels based at least in part on a height of the voxel space and one or more features.
10. The method of claim 9, wherein the one or more features comprise: an average of sensor data, a number of times sensor data is associated with a voxel, a covariance of sensor data, a probability of a voxel belonging to one or more classifications, a ray casting information associated with a voxel; or an occupancy of a voxel.
11. The method of claim 6, wherein the one or more sensors comprises one or more light detection and ranging (LIDAR) sensors.
12. The method of claim 6, wherein the first mask is generated, based at least in part, on classification data associated with the sensor data.
13. The method of claim 12, wherein the classification data is at least one or more of a vehicle, a bicycle, or a pedestrian.
14. The method of claim 6, further comprising: generating the second mask based at least in part on an intersection of an expansion of the first mask and a third mask associated with another object associated with the voxel space.
15. The method of claim 6, wherein segmenting the sensor data comprises associating one or more voxels of the voxel space with the second mask.
16. A non-transitory computer-readable medium storing instructions executable by one or more processors, wherein the instructions, when executed, cause the one or more processors to perform operations comprising: receiving sensor data of an environment from one or more sensors on an autonomous vehicle, the sensor data associated with an object in the environment; associating the sensor data with a voxel space; receiving a first mask associated with a portion of the voxel space, the first mask representing at least a portion of the object using a second perspective; generating a second mask by expanding the first mask; and segmenting, based at least in part on the second mask, the sensor data.
17. The non-transitory computer-readable medium of claim 16, wherein segmenting the sensor data comprises associating one or more voxels of the voxel space with the second mask.
18. The non-transitory computer-readable medium of claim 16, the operations further comprising: generating the second mask based at least in part on an intersection of an expansion of the first mask and a third mask associated with another detected object in the voxel space.
19. The non-transitory computer-readable medium of claim 16, the operations further comprising: inputting, as a two-dimensional representation, the voxel space into a machine learning algorithm; and receiving, as the first mask, an output of the machine learning algorithm, wherein the two-dimensional representation comprises a pseudo-image having a length associated with a first dimension of the voxel space, a width associated with a second dimension of the voxel space, and a number of channels, and further wherein the number of channels is based, at least in part, on a third dimension of the voxel space and one or more features comprising an average of sensor data, a covariance of sensor data, a number of observations of sensor data, an occupancy, or one or more probabilities associated with a semantic classification.
20. The non-transitory computer-readable medium of claim 16, the operations further comprising: generating, based at least in part on segmenting the sensor data, a trajectory for the autonomous vehicle; and controlling, based at least in part on the trajectory, the autonomous vehicle to traverse the environment.
</claims>
</document>
