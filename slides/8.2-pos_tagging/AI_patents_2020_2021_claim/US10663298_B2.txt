<document>

<filing_date>
2017-06-25
</filing_date>

<publication_date>
2020-05-26
</publication_date>

<priority_date>
2017-06-25
</priority_date>

<ipc_classes>
G01C21/16,G06N20/00,G06N99/00,G06T7/20,G06T7/246
</ipc_classes>

<assignee>
INVENSENSE
</assignee>

<inventors>
ALI, ABDELRAHMAN
ELHOUSHI, MOSTAFA
GEORGY, JACQUES
GOODALL, CHRISTOPHER
</inventors>

<docdb_family_id>
64692447
</docdb_family_id>

<title>
Method and apparatus for characterizing platform motion
</title>

<abstract>
An apparatus and method are disclosed for characterizing motion of a platform. Motion sensor data from a portable device having a sensor assembly may be obtained. The portable device may be within the platform and tethered or untethered, and the mobility of the portable device may be constrained or unconstrained within the platform. Following a determination the platform is moving, motion dynamics of the portable device that are independent from motion dynamics of the platform may be identified and motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device may be separated from the obtained motion sensor data. Accordingly, motion sensor data corresponding to motion of the platform that is independent of motion of the portable device may be output. This may be used to derive operator analytics for assessing performance.
</abstract>

<claims>
1. A method for characterizing motion of a platform, the method comprising: obtaining motion sensor data from a portable device having a sensor assembly, wherein the portable device is within the platform and may be tethered or untethered and wherein mobility of the portable device may be constrained or unconstrained within the platform; determining the platform is moving based at least in part on processing the obtained motion sensor data; identifying motion dynamics of the portable device that are independent from motion dynamics of the platform and the lack thereof when it is determined the platform is moving; when independent motion dynamics of the portable device are identified, separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data; and outputting motion sensor data corresponding to motion of the platform that is independent of motion of the portable device.
2. The method of claim 1, further comprising processing the motion sensor data corresponding to motion of the platform that is independent of motion of the portable device to derive operator analytics for an operator of the platform.
3. The method of claim 2, further comprising providing a navigation solution for the platform by using the motion sensor data corresponding to motion of the platform that is independent of motion of the portable device, wherein the operator analytics are based at least in part on the navigation solution.
4. The method of claim 2, wherein the operator analytics are based on at least one of acceleration change, heading change, and speed.
5. The method of claim 4, wherein the operator analytics include adjusting for detection of events comprising at least one of large acceleration, large deceleration, sharp turns, a vehicle swerve, a vehicle sideways slide and vehicle interaction with rumble strips.
6. The method of anyone of claim 4 or 5, further comprising scoring operator performance by comparing the operator analytics to local conditions determined to exist during operation of the platform.
7. The method of claim 1, wherein processing the motion sensor data comprises applying a signal analysis technique.
8. The method of claim 7, wherein the signal analysis technique comprises at least one of: (i) a statistical analysis; (ii) a frequency-domain analysis; and (iii) a time-domain analysis.
9. The method of claim 1, wherein processing the motion sensor data comprises applying a machine learning technique.
10. The method of claim 9, further comprising inputting features extracted from the processed motion sensor data to at least one stored classification model to determine whether the platform is moving.
11. The method of claim 10, wherein the at least one stored classification model comprises extracted features developed during a training phase.
12. The method of claim 1, further comprising providing a source of absolute navigational information, wherein determining the platform is moving is based at least in part on absolute navigational information.
13. The method of claim 1, further comprising obtaining image sensor data from the portable device, wherein determining the platform is moving comprises processing the image sensor data.
14. The method of claim 13, wherein processing the image sensor data comprises comparing similarity between successive samples.
15. The method of claim 1, wherein identifying motion dynamics of the portable device that are independent from motion dynamics of the platform comprises processing the motion sensor data from the portable device.
16. The method of claim 15, wherein processing the motion sensor data comprises at least one of: (i) calculating radius of rotation; (ii) assessing change in orientation of the portable device; (iii) determining heading misalignment between the portable device and the platform; and (iv) fusing extracted features from different sensor types.
17. The method of claim 15, further comprising obtaining motion sensor data from at least one auxiliary portable device, wherein processing the motion sensor data comprises comparing motion sensor data from the portable device with motion sensor data from the auxiliary portable device.
18. The method of claim 1, further comprising providing a source of absolute navigational information, wherein identifying motion dynamics of the portable device that are independent from motion dynamics of the platform is based at least in part on absolute navigational information.
19. The method of claim 15, further comprising obtaining supplemental sensor data from the portable device, wherein identifying motion dynamics of the portable device that are independent from motion dynamics of the platform comprises processing the supplemental sensor data.
20. The method of claim 1, further comprising obtaining image sensor data from the portable device, wherein identifying motion dynamics of the portable device that are independent from motion dynamics of the platform comprises processing the image sensor data.
21. The method of claim 20, wherein the image sensor data comprises a sequence of images and processing the image sensor data comprises calculating a frame related parameter.
22. The method of claim 21, wherein the frame related parameter is derived from at least one of: (i) a comparison of pixels between sequential images; (ii) a comparison of histograms of sequential images; and (iii) a comparison of frame entropy of sequential images.
23. The method of claim 20, wherein the image sensor data comprises a sequence of images and processing the image sensor data comprises performing an optical flow analysis.
24. The method of claim 20, wherein the image sensor data comprises a sequence of images and processing the image sensor data comprises correlating regions between sequential images using at least one of: (i) edge change rate detection; (ii) statistical analysis; (iii) frequency domain analysis; and (iv) multi-resolution analysis.
25. The method of claim 20, further comprising obtaining image sensor data from at least one auxiliary device, wherein processing the image sensor data comprises comparing image sensor data from the portable device with image sensor data from the auxiliary device.
26. The method of claim 20, further comprising obtaining supplemental sensor data from the portable device, wherein identifying motion dynamics of the portable device that are independent from motion dynamics of the platform comprises processing the supplemental sensor data.
27. The method of claim 1, further comprising obtaining ranging sensor data from the portable device, wherein identifying motion dynamics of the portable device that are independent from motion dynamics of the platform comprises processing the ranging sensor data.
28. The method of claim 1, wherein separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data comprises processing the motion sensor data from the portable device.
29. The method of claim 28, wherein processing the motion sensor data comprises at least one of: (i) performing a wavelet analysis; (ii) performing a blind source separation technique; (iii) performing a Fast Fourier Transform (FFT) analysis; (iv) performing a Weighted Frequency Fourier Linear Combiner; and (v) calculating radius of rotation.
30. The method of claim 28, further comprising obtaining motion sensor data from at least one auxiliary portable device, wherein processing the motion sensor data comprises comparing motion sensor data from the portable device with motion sensor data from the auxiliary device.
31. The method of claim 1, further comprising providing a source of absolute navigational information, wherein separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data is based at least in part on the absolute navigational information.
32. The method of claim 1, further comprising obtaining image sensor data from the portable device, wherein separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data comprises processing the image sensor data.
33. The method of claim 32, wherein the image sensor data comprises a sequence of images and processing the image sensor data comprises performing an optical flow analysis.
34. The method of claim 1, further comprising obtaining ranging sensor data from the portable device, wherein separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data comprises processing the ranging sensor data.
35. The method of claim 34, further comprising obtaining image sensor data from the portable device, wherein the image sensor data comprises a sequence of images and wherein processing the image sensor data comprises performing an optical flow analysis, and wherein separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data is based at least in part on the processed ranging sensor data and the optical flow analysis.
36. A portable device for characterizing motion of a platform, wherein the portable device is within the platform and may be tethered or untethered and wherein mobility of the portable device may be constrained or unconstrained within the platform, comprising: a sensor assembly integrated with the portable device, including at least one sensor configured to output data representing motion of the portable device; a processor configured to obtain the motion sensor data; and a motion characterization module implemented with the processor configured to: determine whether the platform is moving based at least in part on processing the obtained motion sensor data; identify motion dynamics of the portable device that are independent from motion dynamics of the platform and the lack thereof when it is determined the platform is moving; when independent motion dynamics of the portable device are identified, separate motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data; and output motion sensor data corresponding to motion of the platform that is independent of motion of the portable device.
37. The portable device of claim 36, wherein the motion characterization module is configured to determine whether the platform is moving, and to perform at least one of: (i) identifying motion dynamics of the portable device that are independent from motion dynamics of the platform; and (ii) separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data using the obtained motion sensor data.
38. The portable device of claim 36, further comprising providing a source of absolute navigational information, wherein the processor is configured to obtain the absolute navigational information and the motion characterization module is configured to perform at least one of: (i) determining whether the platform is moving; (ii) identifying motion dynamics of the portable device that are independent from motion dynamics of the platform; and (iii) separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data using the obtained absolute navigational information.
39. The portable device of claim 38, wherein the source of absolute navigational information is at least one of the following: (i) a global navigation satellite system (GNSS); (ii) cell-based positioning; (iii) WiFi-based positioning; (iv) Bluetooth-based positioning; (v) Bluetooth low energy-based positioning; (vi) other wireless-based positioning; and (vii) visual light communication-based positioning.
40. The portable device of claim 36, further comprising an image sensor, wherein the processor is configured to obtain image sensor data and the motion characterization module is configured to perform at least one of: (i) determining whether the platform is moving; (ii) identifying motion dynamics of the portable device that are independent from motion dynamics of the platform; and (iii) separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data using the obtained image sensor data.
41. The portable device of claim 36, further comprising a supplemental sensor, wherein the processor is configured to obtain supplemental sensor data and the motion characterization module is configured to perform at least one of: (i) identifying motion dynamics of the portable device that are independent from motion dynamics of the platform; and (ii) separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data using the obtained supplemental sensor data.
42. The portable device of claim 40, wherein the supplemental sensor is selected from the group consisting of an ambient light sensor and a proximity sensor.
43. The portable device of claim 36, further comprising a ranging sensor, wherein the processor is configured to obtain ranging sensor data and the motion characterization module is configured to perform at least one of: (i) identifying motion dynamics of the portable device that are independent from motion dynamics of the platform; and (ii) separating motion sensor data corresponding to motion of the platform and motion sensor data corresponding to the identified independent motion of the portable device from the obtained motion sensor data using the obtained ranging sensor data.
44. The portable device of claim 36, wherein the sensor assembly comprises an inertial sensor.
45. The portable device of claim 44, wherein the sensor assembly includes an accelerometer and a gyroscope.
46. The device of claim 44, wherein the inertial sensor is implemented as a Micro Electro Mechanical System (MEMS).
</claims>
</document>
