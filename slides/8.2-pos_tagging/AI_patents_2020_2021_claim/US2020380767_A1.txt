<document>

<filing_date>
2020-08-19
</filing_date>

<publication_date>
2020-12-03
</publication_date>

<priority_date>
2018-05-22
</priority_date>

<ipc_classes>
G06F3/01,G06T15/20,H04N21/218,H04N21/234,H04N21/2343
</ipc_classes>

<assignee>
AT&T INTELLECTUAL PROPERTY I (AMERICAN TELEPHONE AND TELEGRAPH COMPANY INTELLECTUAL PROPERTY I)
</assignee>

<inventors>
GIBBON, DAVID CRAWFORD
SHAHRARAY, BEHZAD
ZAVESKY, ERIC
XU, TAN
</inventors>

<docdb_family_id>
68536110
</docdb_family_id>

<title>
System for Active-Focus Prediction in 360 Video
</title>

<abstract>
Aspects of the subject disclosure may include, for example, predicting a field of view of a viewer to obtain a predicted field of view based on information about the viewer and a scoring of a point of interest in media content. A line of sight is obtained between the viewer and a presentation of the media content to obtain a viewer line of sight, and the scoring of the point of interest in the media content is updated to obtain an updated scoring based on the viewer line of sight, the predicted field of view being updated according to the updated scoring. Other embodiments are disclosed.
</abstract>

<claims>
1. A method comprising: predicting, by a processing system having a processor, a field of view of a viewer to obtain a predicted field of view based on information about the viewer and a scoring of a point of interest in media content; obtaining, by the processing system, a line of sight between the viewer and a presentation of the media content to obtain a viewer line of sight; and updating, by the processing system, the scoring of the point of interest in the media content to obtain an updated scoring based on the viewer line of sight, the predicted field of view being updated according to the updated scoring.
2. The method of claim 1, wherein the media content includes 360 degree video content.
3. The method of claim 2, wherein a portion of the media content sent to equipment of the viewer consists of only the predicted field of view.
4. The method of claim 3, wherein the portion of the media content sent to the equipment of the viewer consists of less than 180 degrees of the media content centered on the predicted field of view.
5. The method of claim 3, wherein the portion of the media content sent to the equipment of the viewer consists of less than 90 degrees of the media content centered on the predicted field of view.
6. The method of claim 1, wherein a portion of the media content sent to equipment of the viewer, consists of less than 135 degrees of the media content centered on the viewer line of sight.
7. The method of claim 1, further comprising: aligning, by the processing system, a camera with the viewer line of sight; and obtaining, by the processing system, the media content from the camera.
8. The method of claim 1, wherein the viewer line of sight is obtained from a tracking of eye movements of the viewer relative to an orientation of the viewer.
9. A non-transitory, machine-readable medium, comprising executable instructions that, when executed by a processing system including a processor, facilitate performance of operations, the operations comprising: identifying a predicted field of view based on first information about a first viewer, and a scoring of a point of interest in video content; monitoring a first line of sight of the first viewer based upon eye movements of the first viewer viewing a first presentation of the video content; and updating the scoring of the point of interest in the video content to obtain an updated scoring based on the first line of sight, the predicted field of view of the first viewer being updated according to the updated scoring.
10. The non-transitory, machine-readable medium of claim 9, wherein the predicted field of view sent to first equipment of the first viewer consists of only the predicted field of view.
11. The non-transitory, machine-readable medium of claim 10, wherein the predicted field of view sent to the first equipment of the first viewer consists of less than 135 degrees of the video content centered on the predicted field of view.
12. The non-transitory, machine-readable medium of claim 9, the operations further comprising sending, to first equipment of the first viewer, less than 135 degrees of the video content centered on the first line of sight.
13. The non-transitory, machine-readable medium of claim 9, the operations further comprising determining a midpoint between the first line of sight and a second line of sight of a second viewer based upon eye movements of the second viewer viewing a second presentation of the video content, and aligning a 360 degree camera system with the midpoint.
14. The non-transitory, machine-readable medium of claim 9, the operations further comprising determining a midpoint between the first line of sight and the predicted field of view, and wherein the predicted field of view comprises less than 180 degrees of the video content centered on the midpoint.
15. The non-transitory, machine-readable medium of claim 14, the operations further comprising aligning a 360-degree camera system with the midpoint.
16. The non-transitory, machine-readable medium of claim 9, the operations further comprising determining a midpoint between the first line of sight and the predicted field of view, and wherein the predicted field of view comprises less than 180 degrees of the video content centered on the midpoint.
17. The non-transitory, machine-readable medium of claim 16, the operations further comprising aligning a 360-degree camera system with the midpoint.
18. An apparatus, comprising: a processing system including a processor; and a memory that stores executable instructions that, when executed by the processing system, facilitates performance of operations, the operations comprising: predicting a field of view of a viewer to obtain a predicted field of view based on information about the viewer and a scoring of a point of interest in video content; monitoring a line of sight of the viewer viewing the video content to obtain a monitored line of sight; and updating a scoring of the point of interest in the video content to obtain an updated scoring based on the monitored line of sight, the predicted field of view being updated according to the updated scoring.
19. The apparatus of claim 18, the operations further comprising determining a midpoint between the monitored line of sight and the predicted field of view, and wherein the predicted field of view comprises less than 135 degrees of the video content centered on the midpoint.
20. The apparatus of claim 19, the operations further comprising aligning a 360-degree camera system with the midpoint.
</claims>
</document>
