<document>

<filing_date>
2019-07-22
</filing_date>

<publication_date>
2020-12-15
</publication_date>

<priority_date>
2018-07-23
</priority_date>

<ipc_classes>
G06T7/521,G06T7/73,G06T7/80,H04N17/00,H04N5/225,H04N5/232,H04N5/247
</ipc_classes>

<assignee>
APPLE
</assignee>

<inventors>
WANG, LEJING
POKRASS, JONATHAN
SETHI, ROHIT
</inventors>

<docdb_family_id>
73746937
</docdb_family_id>

<title>
Estimation of spatial relationships between sensors of a multi-sensor device
</title>

<abstract>
In one implementation, a device has a processor, a projector, a first infrared (IR) sensor, a second IR sensor, and instructions stored on a computer-readable medium that are executed by the processor to estimate the sensor-to-sensor extrinsic parameters. The projector projects IR pattern elements onto an environment surface. The first sensor captures a first image including first IR pattern elements corresponding to the projected IR pattern elements and the device estimates 3D positions for first IR pattern elements. The second IR sensor captures a second image including second IR pattern elements corresponding to the projected IR pattern elements and the device matches the first IR pattern elements and the second IR pattern elements. Based on this matching, the device estimates a second extrinsic parameter corresponding to a spatial relationship between the first IR sensor and the second IR sensor.
</abstract>

<claims>
1. A method comprising: at a device comprising a processor, a projector, a first infrared (IR) sensor, a second IR sensor, and instructions stored on a computer-readable medium, projecting, via the projector, infrared (IR) pattern elements onto an environment surface; capturing, via the first IR sensor, a first image comprising first IR pattern elements corresponding to the projected IR pattern elements; estimating 3D positions for the first IR pattern elements according to a first extrinsic parameter corresponding to a spatial relationship between the projector and the first IR sensor; capturing, via the second IR sensor, a second image comprising second IR pattern elements corresponding to the projected IR pattern elements; matching the first IR pattern elements and the second IR pattern elements; and based on the matching and estimated 3D positions for the first IR pattern elements, estimating a second extrinsic parameter corresponding to a spatial relationship between the first IR sensor and the second IR sensor.
2. The method of claim 1, wherein the device is configured to change the spatial relationship between the first IR sensor and the second IR sensor in response to user manipulation of the device or user input on the device.
3. The method of claim 1, further comprising matching the first image with at least one reference image.
4. The method of claim 1, wherein the device is a head mounted device (HMD) comprising: a first visible spectrum image sensor in a fixed spatial relationship to the first IR sensor and corresponding to a first display on the HMD; and a second visible spectrum image sensor in a fixed spatial relationship to the second IR sensor and corresponding to a second display of the HMD.
5. The method of claim 1, further comprising: identifying a desired inter-pupil distance (IPD) corresponding to a user of the device; and automatically changing the spatial relationship between the first IR sensor and the second IR sensor to correspond to the desired IPD.
6. The method of claim 1 further comprising estimating extrinsic parameters corresponding to the spatial relationship between the first IR sensor and the second IR sensor with respect to six degrees of freedom.
7. The method of claim 6 further comprising calibrating the second IR sensor to the first IR sensor based on the extrinsic parameters.
8. The method of claim 1, wherein the first IR sensor is integrated with the projector in a single unit, wherein the spatial relationship between the projector and the first IR sensor is fixed in the single unit.
9. The method of claim 1, wherein the 3D positions for the first IR pattern elements are estimated based on intrinsic parameters of the projector or the first IR sensor.
10. The method of claim 1, wherein the matching comprises: detecting an object depicted in the first image and the second image; and matching first IR pattern elements according to the object in the first image with second IR pattern elements according to the object in the second image.
11. A system comprising: a non-transitory computer-readable storage medium; a projector; a first IR sensor; a second IR sensor; and a processor coupled to the non-transitory computer-readable storage medium, wherein the non-transitory computer-readable storage medium comprises program instructions that, when executed on the processor, cause the system to perform operations comprising: projecting, via the projector, infrared (IR) pattern elements onto an environment surface; capturing, via the first IR sensor, a first image comprising first IR pattern elements corresponding to the projected IR pattern elements; estimating 3D positions for the first IR pattern elements according to a first extrinsic parameter corresponding to a spatial relationship between the projector and the first IR sensor; capturing, via the second IR sensor, a second image comprising second IR pattern elements corresponding to the projected IR pattern elements; matching the first IR pattern elements and the second IR pattern elements; and based on the matching and estimated 3D positions for the first IR pattern elements, estimating a second extrinsic parameter corresponding to a spatial relationship between the first IR sensor and the second IR sensor.
12. The system of claim 11, wherein the system is configured to change the spatial relationship between the first IR sensor and the second IR sensor in response to user manipulation of the device or user input on the device.
13. The system of claim 11, wherein the operations further comprise matching the first image with at least one reference image.
14. The system of claim 11, wherein the system is a head mounted device (HMD) comprising: a first visible spectrum image sensor in a fixed spatial relationship to the first IR sensor and corresponding to a first display on the HMD; and a second visible spectrum image sensor in a fixed spatial relationship to the second IR sensor and corresponding to a second display of the HMD.
15. The system of claim 11, wherein the operations further comprise: identifying a desired inter-pupil distance (IPD) corresponding to a user of the device; and automatically changing the spatial relationship between the first IR sensor and the second IR sensor to correspond to the desired IPD.
16. The system of claim 11, wherein the operations further comprise estimating extrinsic parameters corresponding to the spatial relationship between the first IR sensor and the second IR sensor with respect to six degrees of freedom.
17. The system of claim 11, wherein the operations further comprise calibrating the second IR sensor to the first IR sensor based on the extrinsic parameters.
18. The system of claim 11, wherein the first IR sensor is integrated with the projector in a single unit, wherein the spatial relationship between the projector and the first IR sensor is fixed in the single unit.
19. The system of claim 11, wherein the 3D positions for the first IR pattern elements are estimated based on intrinsic parameters of the projector or the first IR sensor.
20. The system of claim 11, wherein the matching comprises: detecting an object depicted in the first image and the second image; and matching first IR pattern elements according to the object in the first image with second IR pattern elements according to the object in the second image.
</claims>
</document>
