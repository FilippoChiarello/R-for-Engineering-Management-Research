<document>

<filing_date>
2019-10-03
</filing_date>

<publication_date>
2020-01-30
</publication_date>

<priority_date>
2018-04-04
</priority_date>

<ipc_classes>
H04R5/02,H04R5/04,H04S3/00,H04S7/00
</ipc_classes>

<assignee>
BOSE CORPORATION
</assignee>

<inventors>
BACON, CEDRIK
BERNSTEIN, ERIC RACZKA
JENSEN, CARL
SHANNON, MIKAELA A.
TENGELSEN, DANIEL R.
TORRES, WADE P.
</inventors>

<docdb_family_id>
69177276
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR SOUND SOURCE VIRTUALIZATION
</title>

<abstract>
A system and method for externalizing sound. The system includes a headphone assembly and a localizer configured to collect information related to a location of the user and of an acoustically reflective surface in the environment. A controller is configured to determine a location of at least one virtual sound source, and generate head related transfer functions that simulate characteristics of sound from the virtual sound source directly to the user and to the user via a reflection by the reflective surface. A signal processing assembly is configured to create one or more output signals by filtering the sound signal respectively with the HRTFs. Each speaker of the headphone assembly is configured to produce sound in accordance with the output signal.
</abstract>

<claims>
1. A method for virtualizing sound from a speaker assembly proximate to a user, comprising: receiving an audio signal associated with a first virtual sound source; receiving a virtual sound source location of the first virtual sound source; receiving a virtual sound source orientation of the first virtual sound source; adjusting the audio signal based at least in part on a radiation pattern characteristic of the first virtual sound source; adjusting the audio signal based at least in part on a head related transfer function (HRTF); and providing the adjusted audio signal at an output, the output adjusted audio signal to be provided to the speaker assembly for conversion into acoustic energy delivered to at least one of the user's ears.
2. The method of claim 1, further comprising adjusting the audio signal based at least in part on an acoustically reflective characteristic of an acoustically reflective surface in proximity to the first virtual sound source;
3. The method of claim 2, wherein the acoustically reflective characteristic is frequency dependent.
4. The method of claim 1, wherein the radiation pattern characteristic includes a directional characteristic.
5. The method of claim 2, wherein the radiation pattern characteristic includes a reflected directional characteristic based at least in part on a mirror sound source location selected based at least in part on the first virtual sound source location and a location of the acoustically reflective surface.
6. A method for virtualizing sound from a speaker assembly proximate a user, comprising: associating a first virtual sound source with a first physical location in an environment in which the user is located; identifying one or more acoustically reflective surfaces at a second physical location in the environment; and simulating either a first direct sound from the first virtual audio source or a first primary reflected sound from the first virtual audio source off of a first reflective surface of the one or more reflective surfaces within the environment, wherein the simulated first direct sound or the simulated first primary reflected sound from the first virtual sound source includes a first directional characteristic.
7. The method of claim 6, wherein the first directional characteristic is frequency dependent.
8. The method of claim 6, wherein the step of simulating the first direct sound from the first virtual sound source or simulating the first primary reflected sound off of the first reflective surface of the one or more reflective surfaces further includes: generating a first left Head Related Transfer Function (HRTF) and a first right HRTF, arranged to simulate the first direct sound to the left ear of the user and right ear of the user, respectively, or to simulate the first primary reflected sound to the left ear of the user and the right ear of the user, respectively.
9. The method of claim 6, further comprising the step of: simulating a first secondary reflected sound off of a second reflective surface of the one or more reflective surfaces.
10. The method of claim 9, wherein the step of simulating the first secondary reflected sound off of the second reflective surface of the one or more reflective surfaces includes: generating a second left Head Related Transfer Function (HRTF) and a second right HTRF, arranged to simulate the first secondary reflected sound to the left ear of the user and right ear of the user, respectively.
11. The method of claim 6, further comprising: associating a second virtual sound source with a third physical location in the environment; and simulating either a second direct sound from the second virtual audio source or a second primary reflected sound from the second virtual audio source off of the first reflective surface of the one or more reflective surfaces within the environment, wherein the simulated second direct sound or the simulated second primary reflected sound from the second virtual sound source includes a second directional characteristic.
12. The method of claim 11, wherein the step of simulating the second direct sound from the second virtual sound source or simulating the second primary reflected sound off of the first reflective surface of the one or more reflective surfaces further includes: generating a third left Head Related Transfer Function (HRTF) and a third right HTRF, arranged to simulate the second direct sound to the left ear of the user and right ear of the user, respectively, or to simulate the second primary reflected sound to the left ear of the user and the right ear of the user, respectively.
13. The method of claim 11, further comprising the step of: simulating a second secondary reflected sound off of the second reflective surface of the one or more reflective surfaces.
14. The method of claim 13, wherein the step of simulating the second secondary reflected sound off of the second reflective surface of the one or more reflective surfaces includes: generating a fourth left Head Related Transfer Function (HRTF) and a fourth right HTRF, arranged to simulate the second secondary reflected sound to the left ear of the user and right ear of the user, respectively.
15. A binaural sound virtualization system, comprising: a memory; a processor coupled to the memory and configured to: receive an audio signal, receive location information about a virtual sound source, receive orientation information about the virtual sound source, process the audio signal into a left signal and a right signal, each of the left signal and the right signal configured to cause a user to perceive the audio signal as virtually coming from the virtual sound source located and oriented in accord with the location information and the orientation information, upon acoustically rendering the left signal to the user's left ear and the right signal to the user's right ear; and an output coupled to the processor and configured to provide the left signal and the right signal to an audio rendering device.
16. The binaural sound virtualization system of claim 15, wherein the processing of the audio signal causes a user to perceive the audio signal as virtually coming from the virtual sound source located and oriented in accord with the location information and the orientation information includes applying a radiation pattern associated with the orientation information.
17. The sound externalization system of claim 15, wherein the radiation pattern associated with the orientation information is reflected off one or more acoustically reflective surfaces, wherein the one or more acoustically reflective surfaces are selected from: a wall, a floor, or a ceiling within the environment.
18. The binaural sound virtualization system of claim 15, further comprising a display configured to display an avatar representing the virtual sound source, wherein the display is arranged on a smartphone or other mobile computing device.
19. The binaural sound virtualization system of claim 15 further comprising a motion tracker configured to collect data related to an orientation of the user.
20. A binaural sound virtualization system, comprising: an input to receive an audio signal; a first output to provide a first output signal to be acoustically rendered to a user's left ear; a second output to provide a second output signal to be acoustically rendered to a user's right ear; and a processor coupled to the input, the first output, and the second output, the processor configured to receive the audio signal and adjust the audio signal to generate each of the first output signal and the second output signal to virtualize the audio signal to be perceived as coming from a virtual sound source, the processor further configured to account for a radiation pattern of the virtual sound source in adjusting the audio signal to generate each of the first output signal and the second output signal.
</claims>
</document>
