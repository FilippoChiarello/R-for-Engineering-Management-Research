<document>

<filing_date>
2018-10-08
</filing_date>

<publication_date>
2020-09-15
</publication_date>

<priority_date>
2018-10-08
</priority_date>

<ipc_classes>
G06F3/01,G06F3/16,G06K9/00,G06T7/20,G10L21/0208,H04N7/15
</ipc_classes>

<assignee>
NUANCE COMMUNICATIONS
</assignee>

<inventors>
GANONG, III, WILLIAM F.
LENKE, NILS
Montague, Eric
</inventors>

<docdb_family_id>
70052050
</docdb_family_id>

<title>
System and method for managing a mute button setting for a conference call
</title>

<abstract>
A system, method and computer-readable storage device are disclosed for managing a mute and unmute feature on a device which is used to communicate data in a communication conference. The method includes detecting, when the device is set to mute, whether the user is speaking and whether the speech is meant for the conference. Background noises are distinguished from the speech of the user. If the user is speaking and the device is set to mute, the device will automatically switch to and unmute setting such that people in the indication conference can hear the user speak. Facial recognition, and gaze detection or other data can also be used to determine when to automatically mute or unmute the device and can aid in inferring an intent of the user to speak to the conference participants.
</abstract>

<claims>
We claim:
1. A method comprising: establishing, via a network-based communication server, a communication conference between at least a first user having a first device and a second user having a second device; setting a mute feature for the first device associated with the first user such that the mute feature is on; detecting, via the network-based communication server and while the first device has the mute feature set, whether the first user is speaking and whether, based on data from one or more of a voice detection module, a facial recognition module, a head orientation detection module, a gaze detection module, a background noise module, a motion detection module, an audio volume module or a speaker identification module, the first user intends to communicate with the second user in the communication conference, to yield a determination; and when the determination indicates that the first user is speaking and the determination indicates that the first user intends to speak to the second user in the communication conference, automatically setting, via the network-based communication server, the mute feature to off for the first device to enable the second user to hear the first user in the communication conference.
2. The method of claim 1, wherein the step of detecting whether the first user is speaking further comprises determining an identification of the first user.
3. The method of claim 1, wherein detecting whether the first user is speaking further comprises using a voice activation detection module which also determines whether the speaking by the first user is intended for the communication conference.
4. The method of claim 1, wherein detecting whether the first user is speaking further comprises distinguishing between speech from the first user and a background noise.
5. The method of claim 1, wherein detecting whether the first user is speaking is based at least in part on facial orientation.
6. A method comprising: establishing, via a network-based communication server, a communication conference between at least a first user having a first device and a second user having a second device; setting a mute feature for the first device associated with the first user such that the mute feature is off; detecting, via the network-based communication server, while the first device has the mute feature off and based at least in part on a facial orientation, whether background noise exists in the communication conference at a predetermined threshold to yield a determination; and when the determination indicates that the background noise exists at the predetermined threshold, automatically setting, via the network-based communication server, the mute feature to on for the first device to prevent the second user from hearing sounds from the first device in the communication conference.
7. The method of claim 6, wherein the sounds comprise the background noise and wherein automatically setting the mute feature to on to prevent the second user from hearing sounds from the first device in the communication conference further comprises initiating a filter associated with the background noise.
8. The method of claim 6, wherein the step of detecting whether the background noise exists in the communication conference at the predetermined threshold is performed on one of the first device and a network-based server.
9. The method of claim 6, wherein the step of detecting whether the background noise exists in the communication conference at the predetermined threshold further comprises applying a machine learning model to an environment of the first device.
10. The method of claim 6, wherein the step of detecting whether the background noise exists in the communication conference at the predetermined threshold further comprises distinguishing between speech from the first user and the background noise.
11. A network-based conferencing system comprising: a processor; and a computer-readable storage medium having instructions stored which, when executed by the processor, cause the processor to perform operations comprising: establishing a communication conference between at least a first user having a first device and a second user having a second device; setting a mute feature on the first device associated with the first user such that the mute feature is on; detecting, while the first device has the mute feature set, whether the first user is speaking and whether, based on data from one or more of a voice detection module, a facial recognition module, a head orientation detection module, a gaze detection module, a background noise module, a motion detection module, an audio volume module or a speaker identification module, the first user intends to communicate with the second user in the communication conference, to yield a determination; and when the determination indicates that the first user is speaking and the determination indicates that the first user intends to speak to the second user in the communication conference, automatically setting the mute feature to off to enable the second user to hear the first user in the communication conference.
12. The network-based conferencing system of claim 11, wherein the step of detecting whether the first user is speaking is performed on one or more of the first device and a network-based server.
13. The network-based conferencing system of claim 11, wherein detecting whether the first user is speaking further comprises using a voice activation detection module.
14. The network-based conferencing system of claim 11, wherein detecting whether the first user is speaking further comprises distinguishing between speech from the first user and a background noise.
15. The network-based conferencing system of claim 11, wherein detecting whether the first user is speaking is based at least in part on one or more of facial recognition data, gaze detection data, background noise, motion detection, and audio volume data.
16. The network-based conferencing system of claim 11, wherein automatically setting the mute feature to off to enable the second user to hear the first user in the communication conference further comprises partially, in a timed manner or fully setting the mute feature to off.
17. The network-based conferencing system of claim 16, wherein automatically setting the mute feature to off to enable the second user to hear the first user in the communication conference partially, in the timed manner or fully setting the mute feature to off is based on a confidence level associated with the determination.
</claims>
</document>
