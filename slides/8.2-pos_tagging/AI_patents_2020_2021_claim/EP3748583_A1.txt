<document>

<filing_date>
2019-06-04
</filing_date>

<publication_date>
2020-12-09
</publication_date>

<priority_date>
2019-06-04
</priority_date>

<ipc_classes>
G06T15/04,G06T19/00
</ipc_classes>

<assignee>
MY VIRTUAL REALITY SOFTWARE
</assignee>

<inventors>
BORDING, RASMUS
FJELLVANG, Rune
UMBERA, Stanislav
</inventors>

<docdb_family_id>
66770205
</docdb_family_id>

<title>
SUBSURFACE UTILITY VISUALIZATION
</title>

<abstract>
The invention relates to a method for providing an augmented view of an underground infrastructure in a real world scenery. It comprises a deriving of real time real world images of the real world scenery, deriving a location information for the field of view of those images, deriving a six degree of freedom spatial reference of the real world images and their image content by image processing and an inertial measurement unit. With a deriving of a geospatial information of underground infrastructure in vicinity of the location information from an underground infrastructure database, a calculating of a virtual rendering of the underground infrastructure is done with a same virtual field of view and perspective as the field of view of the real world images. With an augmenting of the virtual rendering in the real world images, a providing of resulting augmented images by a two or three dimensional vision unit is established.According to the invention, the virtual rendering and the augmenting is done with a determining of a ground surface in the real world images and a transforming of the ground surface by a semi-transparent virtual representation of the ground surface, wherein the rendering of the virtual underground infrastructure is visualized below the virtual ground surface in the augmented image.
</abstract>

<claims>
1. A method for providing a real time augmented view (1) of an occluded underground infrastructure (24v) in a real world scenery (8), comprising: ∘ deriving a real time real world image (5) or a video stream of images (5) of the real world scenery (8) by a camera (3), ∘ deriving a location information for the field of view of the real world image (5), ∘ deriving a six degree of freedom spatial reference of the real world image (5) and its image content, comprising image processing and an inertial measurement unit (IMU), ∘ deriving geospatial information of underground infrastructure in vicinity of the location information from an underground infrastructure database, preferably on-line, ∘ calculating a virtual rendering of the underground infrastructure as a virtual underground infrastructure (24v) with a same virtual field of view and perspective as the field of view of the real world image (5), ∘ augmenting the real world image (5) with the virtual rendering (24v) and ∘ providing a resulting augmented image (1) or stream of augmented images (1) by a two dimensional or a stereo vision unit (2), preferably continuously and in real time for a movable field of view of the real world image (5),
characterized in that
the virtual rendering and the augmenting is done with ∘ a determining of a ground surface (9) in the real world image (5), ∘ a deriving of a real world ground texture of the ground surface (9) from the real world image (5) and generating an at least partially semi-transparent virtual representation of the ground surface (9), and ∘ wherein the rendering of the virtual underground infrastructure (24v) is configured to provide the real world ground texture in a see-through rendering atop the virtually rendered underground infrastructure (24v) in the augmented image (1), in particular provided with the rendering of the virtual underground infrastructure (24v) below a virtual ground surface (9v) with a virtually rendered semi-transparent layer or a translucent-glass effect that is visually comprising the real world ground texture in the augmented image (1).
2. Method according to claim 1 characterized in that a visual feature (11,12,13,14s) at and/or above the ground surface is detected in the real world image (5) and augmented by a translucent virtually rendered representation of the visual feature (11v, 12v, 13v, 14v) in the augmented image (1).
3. Method according to any one of claim 1 or 2
characterized in that
features (12) of the underground infrastructure that are visible in the real world image (5) are automatically detected, identified and matched with an according feature from the information of underground infrastructure by a computational unit, wherein the matching provides a spatial reference for an alignment of the virtual rendering (24v) and the features (12) in the real world image (5).
4. Method according to any one of claim 1 to 3,
characterized in that
a texture, color and/or transparency level of the virtual rendering (24v) of the underground infrastructure is automatically adapted dependent on its depth, parallax and a lighting simulation derived from the real world image (5).
5. Method according to any one of claim 1 to 4,
characterized in that
the virtual rendering (24v) comprises a virtual trench (27v) comprising trench walls (26v) and a trench bottom (25v), which is virtual trench (27v) is resizable, and which comprises a view of a virtual excavation of a section of the virtual ground surface (9v).
6. Method according to claim 5, characterized in that the trench walls (26v) and the trench bottom (25v) are rendered with shading effects from the underground infrastructure (24v), in particular calculated according to a lighting simulation derived from the real world image (5), preferably comprising a texture according to a local ground condition derived from the geospatial information of the underground infrastructure.
7. Method according to any one of claim 5 to 6,
characterized in that
the virtual underground infrastructure (24v) is rendered with a comparably higher transparency effect outside of the virtual trench (27v) and without or with a comparably lower transparency effect inside of the virtual trench (27v).
8. Method according to any one of claim 1 to 7,
characterized in that
a virtual indication (22v) of a flow direction, a flow rate (21v) and/or a metadata (21v) related to the underground infrastructure (24v) is virtually rendered according to a meta-information provided with the geospatial information of the underground infrastructure, in particular in a semi-transparent view of the virtual indication (22v) in the augmented image (1).
9. Method according to any one of claim 1 to 8,
characterized by
an automatic detecting of a moving object (11) that comes into a field of view of the real world image (5) and
wherein the virtual rendering comprises a highlighting of the moving object (11) in the augmented image (1), preferably combined with a generating and providing of a security warning (11w) to an operator (4).
10. Method according to any one of claim 1 to 9,
characterized in that
an information on the rendering of the underground infrastructure (24v) is provided to a second, remote augmented reality viewing device (2b) with another field of view of at least partially the same scenery (8), preferably wherein a virtual marking (21v) and/or editing of the virtual renderings is interactively shared in between the at least two augmented reality viewing devices (2,2b) by a communication interface.
11. Method according to any one of claim 1 to 10,
characterized in that
in addition to the virtual rendering of the underground infrastructure (24v), the augmented image (1) comprises a rendering of a corresponding on-ground-level marking (22v) rendered plumb above the virtual underground infrastructure (24v).
12. Method according to any one of claim 1 to 11,
characterized in that
at a remote offsite station display (44), the content (441) of the augmented image (1) of an operator (4) at a site of the scenery (8) is provided plus a calculated virtual view (44b) of the site of the scenery (8), in which calculated virtual view (44b) the operator (4) and his real world image (5) field of view is animated, in particular comprising a position information of the viewing device (2) at the scenery (8) by a reverse-calculating of a position of the camera (3) from the field of view of the real world image (5) and its image content.
13. Method according to any one of claim 1 to 12,
characterized in that
the semi-transparent rendering is done with a color-filtering and/or alpha blending algorithm of a digital image processing software library.
14. A mobile augmented reality viewing device (2,2b) configured execute a method according to any one of claim 1 to 13, in particular configured to provide an augmented image 1 derived according to a method according to any one of claim 1 to 13 to an operator (4) of the AR-viewing device (2,2b), preferably wherein the device comprises at least a computation unit, a camera (3), an inertial measurement unit (IMU), a GPS-receiver, a graphical display, a communication interface and an augmented reality software and/or hardware framework.
15. A computer program product with program code being stored on a machine readable medium or embodied as an electromagnetic wave, the program code being configured for the execution of at least one of the methods according to any one of claims 1 to 13, in particular for rendering a virtual representation of a virtual ground surface (9v) and a virtual underground infrastructure (24v) below this virtual ground surface (9v), and which is configured to apply different levels of semi-transparency for the virtual underground infrastructure (24v) and/or the virtual ground surface (9v) in such a way that at least a fraction of a real world image (5) is shining through those virtual renderings, in particular if the program is carried out on an augmented reality viewing device (2,2b) according to claim 14.
</claims>
</document>
