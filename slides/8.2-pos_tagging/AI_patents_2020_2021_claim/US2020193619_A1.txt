<document>

<filing_date>
2019-11-18
</filing_date>

<publication_date>
2020-06-18
</publication_date>

<priority_date>
2018-12-13
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06T7/246,G06T7/292,G06T7/73,H04N5/247,H04N7/18
</ipc_classes>

<assignee>
AXIS
</assignee>

<inventors>
SKANS, MARKUS
DANIELSSON, NICLAS
</inventors>

<docdb_family_id>
64949030
</docdb_family_id>

<title>
METHOD AND DEVICE FOR TRACKING AN OBJECT
</title>

<abstract>
In a method for tracking an object in video-monitoring scenes, multiple feature vectors are extracted (722) and assembled (724) in point clouds, wherein a point cloud may be assembled for each tracklet, i.e. for each separate part of a track. In order to determine if different tracklets relate to the same or different objects the point clouds of each tracklet is compared (734). Based on the outcome of the comparison it is deduced if the first object and the second object may be considered to be the same object and, if so, the first object is associated (738) with the second object.
</abstract>

<claims>
1. A method for tracking an object in video-monitoring scenes, comprising detecting a first object in a scene, tracking the first object over a first sequence of image frames, extracting data in the form of multiple first feature vectors for the first object, assembling (724) the multiple first feature vectors as a first point cloud in a feature vector space, detecting an occlusion of the first object, detecting a second object subsequently appearing in a scene, tracking the second object over a second sequence of image frames, extracting data in the form of multiple second feature vectors for the second object, assembling the multiple second feature vectors as a second point cloud in the feature vector space, comparing at least a selected portion of the first point cloud to at least a selected portion of the second point cloud in the point cloud space, using the outcome of the comparison to deduce if the first object and the second object may be considered to be the same object and, if so, enabling a track recovery where an object identity of the second object may be set to the object identity of the first object, or vice versa.
2. The method of claim 1, wherein the one or both selections of portion to be used for comparison is based on an occlusion period, i.e. a time between the occlusion of the first object and the appearance of the second object.
3. The method of claim 2, wherein an application of a distribution of weights to each individual feature vector in the selection is also based on the occlusion period.
4. The method of claim 3, wherein shorter occlusion periods shift higher weights to feature vectors extracted closer to the occlusion period, compared to longer occlusion periods.
5. The method of claim 1, wherein the one or both selections of portion to be used for comparison is based, fully or partly, on an estimated pose of the first and/or second tracked object.
6. The method of claim 1, wherein the one or more selections of portion to be used for comparison is made from a parameter selected from the group comprising, in an image area of the first or second object: a level of motion blur, a level of signal to noise ratio, the lighting conditions, and a viewing angle of the tracked object or combinations thereof.
7. The method of claim 1, comprising applying statistical weights to feature vectors in the first and/or second point cloud during the comparison, wherein the statistical weights are fully or partly based on an estimated pose of the first and/or second tracked object, so as to emphasize certain poses.
8. The method of claim 1, further comprising evaluation of the first and/or second point cloud so as to identify a portion of the point cloud having a particularly dense concentration of feature vectors.
9. The method of claim 1, wherein a Euclidian distance is used when comparing the first point cloud to the second point cloud.
10. The method of claim 1, wherein the first point cloud is compared to the second point cloud in a manifold where a major portion of the first point cloud and the second point cloud resides.
11. The method of claim 1, wherein the first point cloud is acquired using a first monitoring camera, whereas the second point cloud is acquired using a second monitoring camera.
12. A device for performing the method of claim 1, wherein the device comprises at least one video-imaging unit for acquiring video image frames of a scene, and a control unit configured to perform the steps of the method.
13. The device of claim 12, wherein the device is a video monitoring camera.
14. A system comprising multiple devices according to claim 12, wherein the control unit is a control unit of one of the video monitoring cameras, or wherein the control unit is a centralized control unit located as a separate device, on a server, or on a client device remote from the video monitoring cameras.
15. A non-transitory computer-readable medium comprising instructions which, when executed by a computer, cause the computer to carry out the method according to claim 1.
</claims>
</document>
