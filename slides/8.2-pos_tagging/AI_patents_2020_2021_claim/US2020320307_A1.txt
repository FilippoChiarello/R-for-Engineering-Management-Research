<document>

<filing_date>
2019-12-04
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-08
</priority_date>

<ipc_classes>
G06K9/00,G10L13/00,G10L13/04,G10L13/08,H04N5/93,H04N9/80
</ipc_classes>

<assignee>
BAIDU USA
BAIDU.COM TIMES TECHNOLOGY (BEIJING) COMPANY
</assignee>

<inventors>
CHEN, XI
WANG, JEFF CHIENYU
TIAN, HAO
Lu, Darning
</inventors>

<docdb_family_id>
72661919
</docdb_family_id>

<title>
Method and apparatus for generating video
</title>

<abstract>
Embodiments of the present disclosure provide a method and apparatus for generating a video. The method may include: determining a commentary of a target news cluster, each piece of news in the target news cluster being specific to a given news event; generating a voice corresponding to each paragraph in the commentary using a speech synthesis technology; determining a candidate material resource set corresponding to the commentary based on a video and an image included in the target news cluster, the candidate material resource being a video or image; determining a candidate material resource sequence corresponding to the each paragraph in the commentary; and generating a video corresponding to the commentary based on the voice corresponding to the each paragraph in the commentary and the candidate material resource sequence.
</abstract>

<claims>
1. A method for generating a video, comprising: determining a commentary of a target news cluster, each piece of news in the target news cluster being specific to a given news event; generating a voice corresponding to each paragraph in the commentary using a speech synthesis technology; determining a candidate material resource set corresponding to the commentary based on a video and an image included in the target news cluster, the candidate material resource being a video or image; determining a candidate material resource sequence corresponding to the each paragraph in the commentary; and generating a video corresponding to the commentary based on the voice corresponding to the each paragraph in the commentary and the candidate material resource sequence.
2. The method according to claim 1, wherein before determining the commentary of the target news cluster, the method further comprises: acquiring at least one news cluster composed of news generated within a recent first preset duration; and determining the target news cluster based on the at least one news cluster.
3. The method according to claim 2, wherein the determining the target news cluster based on the at least one news cluster comprises: determining each news cluster of the at least one news cluster for use as the target news cluster; or ranking each news cluster of the at least one news cluster in descending order of a number of pieces of news generated within a recent second preset duration within the each news cluster; and determining each news cluster ranked within a preset ranking range of the at least one news cluster for use as the target news cluster; or determining each excellent news cluster of the at least one news cluster for use as the target news cluster, wherein a number of images included in news included in the each excellent news cluster is greater than a preset minimum number of images, and a number of videos included in the news included in the each excellent news cluster is greater than a preset minimum number of videos; or determining, for each news cluster of the at least one news cluster, a news event theme corresponding to the news cluster and a current occurrence frequency of the determined news event theme based on each piece of news in the news cluster; determining a frequency difference of the current occurrence frequency of the news event theme corresponding to the each news cluster of the at least one news cluster minus a historical occurrence frequency of the news event theme; and determining a news cluster, with the frequency difference of the news event theme greater than a preset frequency difference threshold, in the at least one news cluster for use as the target news cluster.
4. The method according to claim 1, wherein the determining a commentary of a target news cluster comprises: determining, for each piece of news in the target news cluster, a score of the piece of news suitable for generating a commentary; determining a piece of news with a highest score suitable for generating a commentary in the target news cluster for use as target news; and generating the commentary of the target news cluster based on the target news.
5. The method according to claim 4, wherein the generating the commentary of the target news cluster based on the target news comprises: determining a text included in the target news for use as a target text; deleting a text, unsuitable for commentary, included in the target text, wherein the text unsuitable for commentary is a text in a predetermined text set unsuitable for commentary; replacing a written word included in the target text with a spoken word with a same semantic meaning; and determining a digest text obtained by extracting a digest of the target text for use as the commentary of the target news cluster.
6. The method according to claim 5, wherein the determining a digest text obtained by extracting a digest of the target text for use as the commentary of the target news cluster comprises: determining a maximum number of words of the commentary based on a preset fastest speech rate and a preset longest audio duration; extracting the digest of the target text, a number of words of the extracted digest text being less than the maximum number of words of the commentary; and determining the extracted digest text for use as the commentary of the target news cluster.
7. The method according to claim 4, wherein the determining, for each piece of news in the target news cluster, a score of the each piece of news suitable for generating a commentary comprises: extracting an eigenvalue of the each piece of news based on at least one feature; and determining a score of the each piece of news suitable for generating the commentary based on the extracted at least one eigenvalue; or inputting a text included in the each piece of news into a pre-trained score computing model, to obtain the score of the each piece of news suitable for generating the commentary, wherein the score computing model is used for characterizing a corresponding relationship between the text and a score of the text suitable for generating the commentary.
8. The method according to claim 1, wherein the determining a candidate material resource set corresponding to the commentary based on a video and an image included in the target news cluster comprises: determining the video and the image included in the target news cluster for use as the candidate material resource set corresponding to the commentary; or determining at least one video clip obtained by performing semantic segmentation on each video included in the target news cluster for use as a target video set; determining respective images included in the target news cluster for use as a target image set; and determining the candidate material resource set corresponding to the commentary based on the target video set and the target image set, the candidate material resource being the video or image.
9. The method according to claim 8, wherein the determining the candidate material resource set corresponding to the commentary based on the target video set and the target image set comprises: merging the target video set and the target image set to obtain the candidate material resource set corresponding to the commentary.
10. The method according to claim 8, wherein the determining the candidate material resource set corresponding to the commentary based on the target video set and the target image set comprises: inputting, for each target video in the target video set, the target video into a pre-trained vivid video detection model, to obtain a vivid video detection result corresponding to the target video, wherein the vivid video detection model is used for characterizing a corresponding relationship between a video and a vivid video detection result for characterizing whether the video is a vivid video; deleting a target video with a corresponding vivid video detection result for characterizing a non-vivid video in the target video set; and merging the target video set and the target image set to obtain the candidate material resource set corresponding to the commentary.
11. The method according to claim 10, wherein after the deleting a target video with a corresponding vivid video detection result for characterizing a non-vivid video in the target video set, the method further comprises: deleting a video with a video playing duration less than a preset shortest candidate video duration in the target video set.
12. The method according to claim 1, wherein a playing duration of an image in a video corresponding to the commentary is a preset image playing duration; and the determining a candidate material resource sequence corresponding to the each paragraph in the commentary comprises: determining, for the each paragraph in the commentary, a matching degree between the paragraph and each candidate material resource in the candidate material resource set; and determining a candidate material resource sequence corresponding to the each paragraph in the commentary based on the matching degree between the each paragraph in the commentary and the each candidate material resource, a playing duration of the each candidate material resource and a text length of the each paragraph in the commentary.
13. The method according to claim 12, wherein the determining, for the each paragraph in the commentary, a matching degree between the paragraph and each candidate material resource in the candidate material resource set comprises: determining, for the each paragraph in the commentary, a semantic vector corresponding to the paragraph; determining, for the each candidate material resource in the candidate material resource set, a semantic vector corresponding to the candidate material resource; and determining a similarity between the semantic vector corresponding to the each paragraph in the commentary and the semantic vector corresponding to the each candidate material resource in the candidate material resource set, for use as the matching degree between the corresponding each paragraph and the corresponding each candidate material resource.
14. The method according to claim 13, wherein the determining a similarity between the semantic vector corresponding to the each paragraph in the commentary and the semantic vector corresponding to the each candidate material resource in the candidate material resource set, for use as the matching degree between the corresponding each paragraph and the corresponding each candidate material resource comprises: performing, in response to determining the candidate material resource being an image, semantic segmentation on the image candidate material resource, to obtain at least one semantic annotation result corresponding to the image candidate material resource, and determining a semantic vector corresponding to the candidate material resource based on a semantic vector corresponding to each semantic annotation result of the obtained at least one semantic annotation result; down sampling, in response to determining the candidate material resource being a video, the video candidate material resource, to obtain at least one sample image; performing, for each sample image of the at least one sample image, semantic segmentation on the sample image, to obtain at least one semantic annotation result corresponding to the each sample image, and determining a semantic vector corresponding to the sample image based on the semantic vector corresponding to the each semantic annotation result of the obtained at least one semantic annotation result; and determining the semantic vector corresponding to the candidate material resource based on the semantic vector corresponding to the each sample image.
15. The method according to claim 12, wherein the determining a candidate material resource sequence corresponding to the each paragraph in the commentary based on the matching degree between the each paragraph in the commentary and the each candidate material resource, a playing duration of the each candidate material resource and a text length of the each paragraph in the commentary comprises: determining, for the each paragraph in the commentary, the candidate material resource sequence corresponding to the paragraph using a first preset optimization algorithm, with a playing duration of the candidate material resource sequence corresponding to the paragraph being equal to a playing duration corresponding to the paragraph as a constraint condition, with maximizing a matching degree between the candidate material resource sequence corresponding to the paragraph and the paragraph as an optimization target; or determining the candidate material resource sequence corresponding to the each paragraph in the commentary using a second preset optimization algorithm, with the playing duration of the candidate material resource sequence corresponding to the each paragraph in the commentary being equal to the playing duration corresponding to the each paragraph as a constraint condition, with maximizing a sum of a matching degree between the candidate material resource sequence corresponding to the each paragraph in the commentary and the corresponding each paragraph as an optimization target.
16. The method according to claim 15, wherein candidate material resources in the candidate material resource sequence corresponding to the each paragraph in the commentary are mutually different.
17. The method according to claim 1, wherein the generating a video corresponding to the commentary based on the voice corresponding to the each paragraph in the commentary and the candidate material resource sequence comprises: connecting the voice corresponding to the each paragraph in sequence from front to rear of the each paragraph in the commentary, to obtain a first audio; connecting a video corresponding to the each paragraph in sequence from front to rear of the each paragraph in the commentary, to obtain a first video, wherein the video corresponding to the each paragraph is a video obtained by sequentially connecting the candidate material resources in the candidate material resource sequence corresponding to the each paragraph; and determining the obtained first audio and first video for use as an audio part and a video part in the video corresponding to the commentary respectively; or inputting, for each paragraph in the commentary, the paragraph into a pre-trained video pre-playing time determining model, to obtain a video pre-playing duration corresponding to the paragraph, wherein the video pre-playing duration determining model is used for characterizing a corresponding relationship between a text and a video pre-playing duration corresponding to the text; executing following paragraph video clipping, for each paragraph except for a last paragraph in the commentary, in sequence from front to rear of the paragraph in the commentary: determining a video pre-playing duration corresponding to a paragraph following the paragraph for use as a video clipping duration; sequentially connecting each candidate material resource in the candidate material resource sequence corresponding to the paragraph, to obtain a video corresponding to the paragraph; and clipping a video of the video clipping duration at a tail of the video corresponding to the paragraph; sequentially connecting each candidate material resource in the candidate material resource sequence corresponding to the last paragraph in the commentary, to obtain a video corresponding to the last paragraph; connecting a video corresponding to each paragraph in sequence from front to rear of the each paragraph in the commentary, to obtain a second video; connecting the voice corresponding to each paragraph in sequence from front to rear of the each paragraph in the commentary, to obtain a second audio; and determining the obtained second audio and second video for use as an audio part and a video part in the video corresponding to the commentary respectively.
18. The method according to claim 1, wherein the generating a video corresponding to the commentary based on the voice corresponding to the each paragraph in the commentary and the candidate material resource sequence comprises: inputting, for each paragraph in the commentary, the paragraph into a pre-trained video pre-playing time determining model, to obtain a video pre-playing duration corresponding to the paragraph, wherein the video pre-playing duration determining model is used for characterizing a corresponding relationship between a text and a video pre-playing duration corresponding to the text; executing following paragraph audio extending, for each paragraph except for the last paragraph in the commentary, in sequence from front to rear of the paragraph in the commentary: determining the video pre-playing duration corresponding to a paragraph following the paragraph for use as an audio extending duration; and adding a mute playing duration of the determined audio extending duration to a tail of the voice corresponding to the paragraph; connecting the voice corresponding to each paragraph in sequence from front to rear of the each paragraph in the commentary, to obtain a third audio; connecting a video corresponding to each paragraph in sequence from front to rear of the each paragraph in the commentary, to obtain a third video, wherein the video corresponding to the each paragraph is a video obtained by sequentially connecting the candidate material resources in the candidate material resource sequence corresponding to the each paragraph; and determining the obtained third audio and third video for use as an audio part and a video part in the video corresponding to the commentary respectively.
19. The method according to claim 1, wherein before generating the video corresponding to the commentary based on the voice corresponding to the each paragraph in the commentary and the candidate material resource sequence, the method further comprises: executing following monochromatic material resource detection, for the each paragraph in the commentary: deleting, for each material resource in the candidate material resource sequence corresponding to the paragraph, in response to determining that the material resource is a video and a monochromatic image frame is present in the video material resource, the monochromatic image frame in the material resource; and deleting, in response to determining that the material resource is an image and the image material resource is a monochromatic image, the material resource from the candidate material resource sequence corresponding to the paragraph.
20. The method according to claim 19, wherein before generating the video corresponding to the commentary based on the voice corresponding to the each paragraph in the commentary and the candidate material resource sequence, the method further comprises: executing following alignment detection, for the each paragraph in the commentary: extending, in response to determining a playing duration of the voice corresponding to the paragraph being greater than a playing duration of the candidate material resource sequence corresponding to the paragraph, a playing duration of an image type candidate material resource in the candidate material resource sequence corresponding to the paragraph, or selecting a candidate material resource from the candidate material resource set, and adding the selected candidate material resource to the candidate material resource sequence corresponding the paragraph, such that the playing duration of the voice corresponding to the paragraph is equal to the playing duration of the candidate material resource sequence corresponding to the paragraph.
21. The method according to claim 1, wherein after generating the video corresponding to the commentary based on the voice corresponding to the each paragraph in the commentary and the candidate material resource sequence, the method further comprises: sending the video corresponding to the commentary to a terminal device.
22. The method according to claim 1, wherein the method further comprises: acquiring a current value of at least one parameter in a process from determining the commentary of the target news cluster to generating the video corresponding to the commentary; determining a video evaluation score of the video corresponding to the commentary; performing feature extraction on the current value of the at least one parameter, to obtain feature representation; inputting the feature representation and the determined video evaluation score into a pre-trained evaluation network to obtain a predicted video evaluation score; inputting the feature representation and the predicted video evaluation score into a pre-trained action network to obtain current action information; and adjusting the current value of the at least one parameter based on the current action information.
23. The method according to claim 22, wherein the method further comprises: re-executing the process from determining the commentary of the target news cluster to generating the video corresponding to the commentary based on the current value of the at least one parameter.
24. An apparatus for generating a video, comprising: at least one processor; and a memory storing instructions, wherein the instructions when executed by the at least one processor, cause the at least one processor to perform operations, the operations comprising: determining a commentary of a target news cluster, each piece of news in the target news cluster being specific to a given news event; generating a voice corresponding to each paragraph in the commentary using a speech synthesis technology; determining a candidate material resource set corresponding to the commentary based on a video and an image included in the target news cluster, the candidate material resource being a video or image; determining a candidate material resource sequence corresponding to the each paragraph in the commentary; and generating a video corresponding to the commentary based on the voice corresponding to the each paragraph in the commentary and the candidate material resource sequence.
</claims>
</document>
