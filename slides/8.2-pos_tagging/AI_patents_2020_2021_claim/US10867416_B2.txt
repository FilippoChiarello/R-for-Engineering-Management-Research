<document>

<filing_date>
2017-03-10
</filing_date>

<publication_date>
2020-12-15
</publication_date>

<priority_date>
2017-03-10
</priority_date>

<ipc_classes>
G06K9/46,G06K9/62,G06K9/66,G06T11/00,G06T7/11,G06T7/174,G06T7/194,G06T7/90,H04N1/387
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
LIN ZHE
SHEN, XIAOHUI
SUNKAVALLI, KALYAN K.
TSAI, YI-HSUAN
LU, XIN
</inventors>

<docdb_family_id>
63444908
</docdb_family_id>

<title>
Harmonizing composite images using deep learning
</title>

<abstract>
Methods and systems are provided for generating harmonized images for input composite images. A neural network system can be trained, where the training includes training a neural network that generates harmonized images for input composite images. This training is performed based on a comparison of a training harmonized image and a reference image, where the reference image is modified to generate a training input composite image used to generate the training harmonized image. In addition, a mask of a region can be input to limit the area of the input image that is to be modified. Such a trained neural network system can be used to input a composite image and mask pair for which the trained system will output a harmonized image.
</abstract>

<claims>
1. A computer-implemented method for training a neural network system to harmonize composite images, the method comprising: receiving, by a neural network, a training composite image wherein the training composite image comprises a reference image with a modified region; generating, via the neural network, a training harmonized image from the training composite image received by the neural network, wherein, to generate the training harmonized image, the neural network changes coloration of the modified region of the training composite image to harmonize the modified region with the training composite image; and training the neural network based on a comparison of the generated training harmonized image and the reference image.
2. The computer-implemented method of claim 1, further comprising: receiving a mask of the training composite image, wherein the neural network is trained to modify a foreground region as indicated by the mask.
3. The computer-implemented method of claim 1, further comprising: receiving the reference image; and modifying the reference image, wherein the modification includes editing a selected region of the reference image to generate the training composite image.
4. The computer-implemented method of claim 3, wherein the selected region of the reference image is edited by modifying the selected region to a different coloration from a coloration of the reference image.
5. The computer-implemented method of claim 4, wherein the selected region is modified to the different coloration using color transfer from a reference region of another image, wherein the reference region contains an object with semantic information within a measure of similarity of semantic information of an object contained in the selected region.
6. The computer-implemented method of claim 1, further comprising: adjusting the neural network based on a loss function, wherein the loss function is based on determining reconstruction loss by comparing the reference image and the training harmonized image.
7. The computer-implemented method of claim 6, wherein the loss function is further based on determining pixel-wise cross-entropy loss by comparing pixel semantic labels of the training harmonized image and reference pixel semantic labels.
8. A computer-storage medium having a plurality of executable instructions embodied thereon, which, when executed by one or more processors, cause the one or more processors to perform a method for generating a harmonized image for an input composite image, the method comprising: receiving a composite image comprising a foreground region and a background region; and generating a harmonized image using a neural network of a neural network system, the neural network configured to harmonize coloration of the foreground region and coloration of the background region by modifying the coloration of the foreground region to match the coloration of the background region.
9. The medium of claim 8, the method further comprising: generating the composite image by compositing the foreground region with the background region.
10. The medium of claim 8, the method further comprising: receiving an input image; selecting a region of the input image to extract; and extracting the region as the foreground region; and generating the composite image by compositing the foreground region with the background region.
11. The medium of claim 10, the method further comprising: receiving, by the neural network system, an input mask of the foreground region, indicating for the neural network to harmonize to the coloration of the foreground region.
12. The medium of claim 11, the method further comprising: generating, by the neural network system, a reverse mask of the input mask, the reverse mask indicating for the neural network to harmonize to the coloration of a background region.
13. The medium of claim 8, wherein the neural network comprises a trained neural network, wherein the trained neural network is based on a comparison of a training harmonized image and a reference image with a modified region to generate a training input image, wherein the trained neural network generates the training harmonized image from the training input composite image.
14. The medium of claim 13, the trained neural network further based on: generating the training harmonized image from the training input composite image; and adjusting parameters based on a loss function.
15. The medium of claim 14, wherein the loss function includes determining reconstruction loss from a comparison of the reference image and the training harmonized image.
</claims>
</document>
