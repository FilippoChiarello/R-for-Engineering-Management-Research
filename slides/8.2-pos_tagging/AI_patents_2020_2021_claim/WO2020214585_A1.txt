<document>

<filing_date>
2020-04-14
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2019-04-18
</priority_date>

<ipc_classes>
H04L29/06
</ipc_classes>

<assignee>
ORACLE INTERNATIONAL CORPORATION
</assignee>

<inventors>
FENG, CHAO
KIRTI, GANESH
XU, Brian H.
</inventors>

<docdb_family_id>
72832113
</docdb_family_id>

<title>
DETECTING BEHAVIOR ANOMALIES OF CLOUD USERS
</title>

<abstract>
A method of detecting anomalous user behavior in a cloud environment includes calculating a first vector that is representative of actions taken during a plurality of previous time intervals; calculating a similarity between the first vector and a second vector that comprises counts of actions taken by the user during a current time interval; comparing the similarity to a baseline threshold to determine whether one or more anomalous actions have occurred; and generating an alert based at least in part on a determination that the one or more anomalous actions have occurred in the cloud environment.
</abstract>

<claims>
1. A method of detecting anomalous behavior in a cloud environment, the method comprising:
calculating a first vector that is representative of actions taken during a plurality of previous time intervals in the cloud environment;
calculating a similarity between the first vector and a second vector that comprises counts of actions taken during a current time interval;
comparing the similarity to a baseline threshold to determine whether one or more anomalous actions have occurred; and
generating an alert based at least in part on a determination that the one or more anomalous actions have occurred in the cloud environment
2. The method of claim 1, wherein the similarity is calculated using a cosine similarity.
3. The method of claim 1, wherein each entry in the first vector comprises an average event score during the plurality of previous time intervals.
4. The method of claim 1, wherein each of the plurality of previous time intervals comprises one day.
5. The method of claim 1, wherein the plurality of previous time intervals comprises a window of at least 60 days.
6. The method of claim 1, wherein the plurality of previous time intervals comprises a sliding window of days, wherein the sliding window of days adds the current time interval to the sliding window of days and removes a least-recent time interval from the sliding window of days after each time interval.
7. The method of claim 1, wherein the first vector is representative of actions taken during the plurality of previous time intervals by storing a histogram of event counts for each of the plurality of previous time intervals.
8. A non-transitory computer-readable medium comprising instructions that, when executed by one or more processors, cause the one or more processors to perform operations comprising:
calculating a first vector that is representative of actions taken during a plurality of previous time intervals in the cloud environment;
calculating a similarity between the first vector and a second vector that comprises counts of actions taken during a current time interval;
comparing the similarity to a baseline threshold to determine whether one or more anomalous actions have occurred; and
generating an alert based at least in part on a determination that the one or more anomalous actions have occurred in a cloud environment.
9. The non-transitory computer-readable medium of claim 8, wherein the operations further comprise:
comparing the similarity to an upper threshold to further determine whether one or more anomalous actions have occurred.
10. The non-transitory computer-readable medium of claim 9, wherein the baseline threshold characterizes the similarity as being suspicious, and wherein the upper threshold characterizes the similarity as representing a threat.
11. The non-transitory computer-readable medium of claim 9, wherein the upper threshold is determined based on a predetermined number of standard deviations of an average value calculated in the first vector.
12. The non-transitory computer-readable medium of claim 9, wherein the upper threshold is represented by a neural network that receives the similarity as an input.
13. The non-transitory computer-readable medium of claim 8, wherein the baseline threshold is represented by a neural network that receives the similarity as an input.
14. The non-transitory computer-readable medium of claim 8, wherein the baseline threshold is determined using a peer group analysis for users similar to a current user.
15. A system comprising:
one or more processors; and
one or more memory devices comprising instructions that, when executed by the one or more processors, cause the one or more processors to perform operations comprising:
calculating a first vector that is representative of actions taken during a plurality of previous time intervals in the cloud environment;
calculating a similarity between the first vector and a second vector that comprises counts of actions taken during a current time interval;
comparing the similarity to a baseline threshold to determine whether one or more anomalous actions have occurred; and
generating an alert based at least in part on a determination that the one or more anomalous actions have occurred in the cloud environment.
16. The system of claim 15, wherein the operations further comprise:
comparing one or more values in the second vector to one or more action scores associated with the one or more values.
17. The system of claim 16, wherein each of the one or more action scores represents a likelihood that the action is a malicious action representing a threat.
18. The system of claim 15, wherein the second vector comprises counts of actions taken relative to a particular resource.
19. The system of claim 15, wherein values in the first vector are weighted depending on a day of the week on which an action occurred.
20. The system of claim 15, wherein the second vector comprises counts of actions taken relative to a particular user.
</claims>
</document>
