<document>

<filing_date>
2019-03-25
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-25
</priority_date>

<ipc_classes>
B60W30/09,B60W30/095,G06K9/00,G06N20/00,G06N5/04
</ipc_classes>

<assignee>
ZOOX
</assignee>

<inventors>
GHAFARIANZADEH, MAHSA
Hansen, Luke Martin
</inventors>

<docdb_family_id>
72606571
</docdb_family_id>

<title>
PEDESTRIAN PREDICTION BASED ON ATTRIBUTES
</title>

<abstract>
Techniques are discussed for predicting locations of an object based on attributes of the object and/or attributes of other object(s) proximate to the object. The techniques can predict locations of a pedestrian proximate to a crosswalk as they traverse or prepare to traverse through the crosswalk. The techniques can predict locations of objects as the object traverses an environment. Attributes can comprise information about an object, such as a position, velocity, acceleration, classification, heading, relative distances to regions or other objects, bounding box, etc. Attributes can be determined for an object over time such that, when a series of attributes are input into a prediction component (e.g., a machine learned model), the prediction component can output, for example, predicted locations of the object at times in the future. A vehicle, such as an autonomous vehicle, can be controlled to traverse an environment based on the predicted locations.
</abstract>

<claims>
1. A system comprising: one or more processors; and one or more computer-readable media storing instructions executable by the one or more processors, wherein the instructions, when executed, cause the system to perform operations comprising: capturing sensor data of an environment using a sensor of an autonomous vehicle; determining, based at least in part on the sensor data, that an object is in the environment; determining, based at least in part on map data and the sensor data, that the object is associated with a destination in the environment; determining a first attribute associated with the object, the first attribute associated with a first time; determining a second attribute associated with the object, the second attribute associated with a second time after the first time; inputting the first attribute, the second attribute, and the destination to a machine learned model, wherein the first attribute and the second attribute are represented in a frame of reference based at least in part on the destination; receiving, from the machine learned model, a predicted location of the object at a third time after the second time; and controlling the autonomous vehicle based at least in part on the predicted location of the object in the environment at the third time.
2. The system of claim 1, wherein the object is a pedestrian and the destination is associated with a perimeter of a crosswalk region in the environment and opposite a drivable surface associated with the pedestrian.
3. The system of claim 1, the operations further comprising: determining that the object is associated with the destination based at least in part on inputting the first attribute and the second attribute into a destination prediction component; and receiving, from the destination prediction component, the destination, the destination prediction component comprising another machine learned model.
4. The system of claim 1, the operations further comprising: wherein the predicted location associated with the object at the third time comprises: a lateral offset based at least in part on the frame of reference; and a distance along an axis of the frame of reference representing a difference between a location of the object at the second time and the predicted location.
5. The system of claim 1, the operations further comprising: establishing the frame of reference, wherein: a first location of the object at the second time is associated with an origin of the frame of reference; a first axis is based at least in part on the origin and the destination; and a second axis is perpendicular to the first axis; and wherein the predicted location is based at least in part on the frame of reference.
6. A method comprising: receiving sensor data representing an environment; determining, based at least in part on the sensor data, that an object is in the environment; determining a location in the environment, the location associated with a crosswalk region; determining a first attribute associated with the object, the first attribute associated with a first time; determining a second attribute associated with the object, the second attribute associated with a second time after the first time; inputting the first attribute, the second attribute, and the location to a machine learned model; and receiving, from the machine learned model, a predicted location associated with the object at a third time after the second time.
7. The method of claim 6, further comprising: capturing the sensor data using a sensor on a vehicle; and controlling the vehicle based at least in part on the predicted location of the object in the environment at the third time.
8. The method of claim 6, wherein the location is a first location, the method further comprising: determining the first location based at least in part on at least one of map data or the sensor data representing the environment; determining a threshold region associated with the first location; determining a second location of the object in the environment; determining that the second location of the object is within the threshold region; and selecting, based at least in part on the second location being within the threshold region and at least one of the first attribute or the second attribute, the location as a destination associated with the object.
9. The method of claim 6, wherein the location is a first location, the method further comprising: establishing a frame of reference, wherein: a second location of the object at the second time is associated with an origin of the frame of reference; a first axis is based at least in part on the origin and the first location; and a second axis is perpendicular to the first axis; and wherein the first attribute is based at least in part on the frame of reference.
10. The method of claim 9, further comprising: determining a velocity of the object at the second time; and determining an angle between a velocity vector representing the velocity and the first axis; wherein the second attribute comprises the angle.
11. The method of claim 9, wherein: the location is a first location; and the predicted location associated with the object at the third time comprises a lateral offset with respect to the second axis and a distance along the first axis representing a difference between a second location of the object at the second time and the predicted location.
12. The method of claim 6, further comprising: determining a number of objects entering the crosswalk region within a period of time, wherein the second attribute comprises the number of objects.
13. The method of claim 6, wherein the object is a first object, the method further comprising: determining, based at least in part on the sensor data, that a second object is in the environment; determining, as an object context, at least one of a position, a velocity, or an acceleration associated with the second object; and determining the predicted location associated with the object further based at least in part on the object context.
14. The method of claim 6, further comprising: binning at least a portion of the predicted location to determine a binned predicted location.
15. The method of claim 6, wherein the first attribute comprises at least one of: a position of the object at the first time; a velocity of the object at the first time; a heading of the object at the first time; a first distance between the object at the first time and a first portion of the crosswalk region; a second distance between the object at the first time and a second portion of the crosswalk region; an acceleration of the object at the first time; an indication of whether the object is in a drivable area; a region control indicator state; a vehicle context; or an object association.
16. A non-transitory computer-readable medium storing instructions that, when executed, cause one or more processors to perform operations comprising: receiving sensor data representing an environment; determining, based at least in part on the sensor data, that an object is in the environment; determining a location in the environment, the location associated with at least one of a crosswalk region or a non-drivable region of the environment; determining a first attribute associated with the object, the first attribute associated with a first time; determining a second attribute associated with the object, the second attribute associated with a second time after the first time; inputting the first attribute, the second attribute, and the location to a machine learned model; and receiving, from the machine learned model, a predicted location associated with the object at a third time after the second time.
17. The non-transitory computer-readable medium of claim 16, wherein the location is a first location, the operations further comprising: determining the first location based at least in part on at least one of map data representing the environment or the sensor data representing the environment; determining a threshold region associated with the first location; determining a second location of the object in the environment; determining that the second location of the object is within the threshold region; and selecting, based at least in part on the second location of the object being within the threshold region and at least one of the first attribute or the second attribute, the first location as a destination associated with the object.
18. The non-transitory computer-readable medium of claim 16, wherein the location is a first location, the operations further comprising: establishing a frame of reference, wherein: a second location of the object at the second time is associated with an origin of the frame of reference; a first axis is based at least in part on the origin and the first location; and a second axis is perpendicular to the first axis; and wherein the first attribute is based at least in part on the frame of reference.
19. The non-transitory computer-readable medium of claim 18, wherein: the location is a first location; and the predicted location associated with the object at the third time comprises a lateral offset along the second axis and a distance along the first axis representing a difference between a second location of the object at the second time and the predicted location.
20. The non-transitory computer-readable medium of claim 16, further comprising: determining that the object is not associated with the crosswalk region; and determining that the location is associated with the non-drivable region of the environment.
</claims>
</document>
