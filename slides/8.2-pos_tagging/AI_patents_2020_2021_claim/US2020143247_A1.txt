<document>

<filing_date>
2019-12-25
</filing_date>

<publication_date>
2020-05-07
</publication_date>

<priority_date>
2015-01-23
</priority_date>

<ipc_classes>
G06F40/284,G06F40/295,G06F40/30,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
CONVERSICA
</assignee>

<inventors>
GAINOR, MACGREGOR S.
GINSTROM, RYAN FRANCIS
GOUGE, CONNOR MACK
JONNALAGADDA, SIDDHARTHA REDDY
</inventors>

<docdb_family_id>
70457775
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR IMPROVED AUTOMATED CONVERSATIONS WITH INTENT AND ACTION RESPONSE GENERATION
</title>

<abstract>
Systems and methods for generating intents for a response is provided. The tokens of the response is encoded into a dense vector space as a plurality of vectors. Name entities are extracted, and individual sentences and paragraphs are both classified in response to the vectors. In addition to the tokens being represented in the vector space, the sentences and paragraphs may be represented in the vector space. The entities and intents are then used to determine an action for the system according to a policy that is optimized for. Annotations may be requested when the classifications are below thresholds, and these annotations may be employed in the action determination process. Annotation includes receiving an annotation work in an annotation queue, prioritizing the annotations, and sending the highest priority annotations to the annotator in order. This is used to update the production annotation database.
</abstract>

<claims>
1. A method for generating intents for a response comprising: fixing a number of embeddings; encoding each token of the response in a dense vector space with dimensions equal to the number of embeddings as a plurality of vectors; extracting name entities using the plurality of vectors; classifying individual sentences for the responses using the plurality of vectors to generate sentence level intents; and classifying individual paragraphs for the responses using the plurality of vectors to generate paragraph level intents.
2. The method of claim 1, wherein the number of embeddings are fixed at or more than 300.
3. The method of claim 1, further comprising extending a network to represent sentences and paragraphs of the response in the vector space.
4. The method of claim 1, wherein the classifying the sentence level intents uses a first recurrent neural network (RNN), and the classifying the paragraph level intents uses a second RNN.
5. The method of claim 4, wherein the first RNN and second RNN use Bi-directional Long Short Term Memory (Bi-LSTM).
6. The method of claim 1, wherein the encoding the tokens utilizes at least one of CBOW, Skip-gram and Universal language models.
7. The method of claim 1, wherein the named entities are extracted using a RNN.
8. The method of claim 1, further comprising grouping sentences that are semantically similar.
9. The method of claim 8, wherein the grouping uses a K-nearest neighbor algorithm.
10. The method of claim 8, further comprising training a recurrent neural network for classifying the sentence level intents using the grouping of sentences above a threshold number.
11. A system for generating intents for a response comprising: an encoder for encoding each token of the response in a dense vector space with dimensions equal to at least 300 as a plurality of vectors, and representing sentences and paragraphs of the response in the dense vector space; a plurality of models for performing at least one of extracting name entities using the plurality of vectors, classifying individual sentences for the responses using the plurality of vectors to generate sentence level intents, and classifying individual paragraphs for the responses using the plurality of vectors to generate paragraph level intents.
12. The system of claim 11, wherein the classifying the sentence level intents uses a first recurrent neural network (RNN), and the classifying the paragraph level intents uses a second RNN.
13. The system of claim 12, wherein the first RNN and second RNN use Bi-directional Long Short Term Memory (Bi-LSTM).
14. The system of claim 11, wherein the encoding the tokens utilizes at least one of CBOW, Skip-gram and Universal language models.
15. The system of claim 11, wherein the named entities are extracted using a RNN.
16. The system of claim 11, further comprising a fourth modeling component for grouping sentences that are semantically similar.
17. The system of claim 16, wherein the grouping uses a K-nearest neighbor algorithm.
18. The system of claim 16, wherein the second modeling component further trains a recurrent neural network for classifying the sentence level intents using the grouping of sentences above a threshold number.
19. A method for generating actions for a response comprising: receiving name entities, sentence level intents and paragraph level intents for the response; receiving a policy for a conversation; and optimizing a reward for the policy using the name entities, sentence level intents and paragraph level intents to generate an action.
20. The method of claim 19. wherein the action is determined for the sentence level intents through at least one of a nested Boolean expression, hierarchy of intents, policy gradient algorithms, value iteration algorithms, and reinforcement learning algorithms.
</claims>
</document>
