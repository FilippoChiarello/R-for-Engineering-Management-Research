<document>

<filing_date>
2018-11-28
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2017-11-28
</priority_date>

<ipc_classes>
G01N15/14,G01N33/574,G06K9/00,G06K9/62,G06T7/00,G06T7/155
</ipc_classes>

<assignee>
CADESS MEDICAL
</assignee>

<inventors>
CARLBOM, INGRID
AVENEL, CHRISTOPHE
</inventors>

<docdb_family_id>
64604621
</docdb_family_id>

<title>
PROSTATE CANCER TISSUE IMAGE CLASSIFICATION WITH DEEP LEARNING
</title>

<abstract>
The method of the present invention classifies the nuclei in prostate tissue images with a trained deep learning network and uses said nuclear classification to classify regions, such as glandular regions, according to their malignancy grade. The method according to the present disclosure also trains a deep learning network to identify the category of each nucleus in prostate tissue image data, said category representing the malignancy grade of the tissue surrounding the nuclei. The method of the present disclosure automatically segments the glands and identifies the nuclei in a prostate tissue data set. Said segmented glands are assigned a category by at least one domain expert, and said category is then used to automatically assign a category to each nucleus corresponding to the category of said nucleus' surrounding tissue. A multitude of windows, each said window surrounding a nucleus, comprises the training data for the deep learning network.
</abstract>

<claims>
1. A method for classifying prostate cancer tissue data by using a trained deep learning network, wherein said analysis comprises the steps of: capturing of histological tissue image data from a prostate tissue sample that has been stained with at least two stains, said histological tissue image data comprising a set of pixels, said stains being light absorbent, and one said stain being absorbed primarily by the stroma, the other said stain being absorbed primarily by the nuclei; identifying at least one nucleus in said histological tissue image data; identifying a window of pixels around said nucleus; classifying at least one nucleus as belonging to one category by applying a trained deep learning network to said window around said nucleus in said histological tissue image; classifying at least one region in the histological tissue image data according to the categories of the nuclei contained in said region.
2. The method of claim 1, wherein the identification of said nucleus uses a marked point process.
3. The method of claim 1, wherein said window is square and centered around the centroid of said nucleus.
4. The method of claim 1, wherein said window is of the same size as the windows used to train the deep learning network.
5. The method of claim 1, wherein said deep learning network is a convolutional neural network.
6. The method of claim 1, wherein the classification of said regions comprise the steps of: deriving one density map, said density map corresponding to a portion of said tissue data that represents the stroma; segmenting said density map into at least one gland, using morphologically-based segmentation; classifying said prostate gland with the category of the most prevalent category among its nuclei.
7. A method for training a deep learning network that classifies nuclei in histological tissue image data into categories, the method comprising the steps of: capturing of histological tissue image data from a prostate tissue sample that has been stained with at least two stains, said histological tissue image data comprising a set of pixels, said stains being light absorbent, and one said stain being absorbed primarily by the stroma, the other said stain being absorbed primarily by the nuclei; segmenting said tissue data into at least one gland, where said gland is surrounded by stromal tissue; labelling at least one gland according to its category; identifying at least one nucleus in said histological tissue image data; labelling said nucleus according to the category of said nucleus centroid's surrounding tissue; identifying a window of pixels around said labelled nucleus; training at least one deep learning network, using a multitude of said windows as training data, to recognize the category of at least one nucleus in prostate tissue image data.
8. The method of claim 7, wherein the glandular segmentation further comprises the steps of: deriving one density map, said density map corresponding to a portion of said tissue data that represents the stroma; segmenting said density map into at least one gland.
9. The method of claim 8, wherein said density map is derived using the BCD method.
10. The method of claim 7, wherein said glands have been labelled according to their categories by at least one expert.
11. The method of claim 7, wherein said categories comprise prostate components.
12. The method of claim 7, wherein the identification of said nucleus uses a marked point process.
13. The method of claim 7, wherein said window is square and centered around the centroid of said nucleus.
14. The method of claim 7, wherein said deep learning network is a convolutional neural network.
15. A method for classifying prostate cancer tissue data by using a trained deep learning network, wherein said analysis comprises the steps of: capturing of histological tissue image data from a prostate tissue sample that has been stained with at least two stains, said histological tissue image data comprising a set of pixels, said stains being light absorbent, and one said stain being absorbed primarily by the stroma, the other said stain being absorbed primarily by the nuclei; identifying at least one nucleus in the histological tissue image data; identifying a window of pixels around said nucleus; classifying at least one nucleus as belonging to one category by applying a trained deep learning network to said window around said nucleus in said histological tissue image; classifying at least one region in the histological tissue image data according to the categories of the nuclei contained in said region, wherein the deep learning network has been previously trained by a training method comprising the steps of: capturing of training histological tissue image data from a training prostate tissue sample that has been stained with at least two stains, said training histological tissue image data comprising a set of pixels, said stains being light absorbent, and one said stain being absorbed primarily by the stroma, the other said stain being absorbed primarily by the nuclei; segmenting said training tissue data into at least one training gland, where said training gland is surrounded by stromal tissue; labelling at least one training gland according to its category; identifying at least one training nucleus in said training histological tissue image data; labelling said training nucleus according to the category of said training nucleus centroid's surrounding tissue; identifying a training window of pixels around said training labelled training nucleus; training at least one deep learning network, using a multitude of said training windows as training data, to recognize the category of at least one nucleus in prostate tissue image data.
16. The method of claim 15, wherein at least one of the identifications of individual nuclei uses a marked point process.
17. The method of claim 15, wherein each said window is square, of the same dimensions, as the windows in the deep learning training data and centered around the centroid of an individual nucleus.
18. The method of claim 15, wherein the deep learning network is a convolutional neural network.
19. The method of claim 15, wherein the classification of said regions comprise the substeps of: deriving one density map, said density map corresponding to a portion of said tissue data that represents the stroma; segmenting said density map into at least one gland, classifying said gland with the category of the most prevalent category among its nuclei.
20. The method of claim 15, wherein the glandular segmentation further comprises the substeps of: deriving one density map, said density map corresponding to a portion of said training histological tissue image data that represents the stroma; segmenting said density map into at least one training gland.
21. The method of claim 15, wherein said glands have been labelled according to their categories by at least one expert, the categories comprising prostate components.
22. Image capture and analysis apparatus comprising: microscope adapted to capturing histological tissue image data from a tissue sample that has been stained with at least two stains, the said stains being light absorbent; image processing modules adapted to perform the steps of: creating a deep learning training data set comprising square windows centered around nuclei in said tissue image data; training a deep learning network to recognize the category of at least one nucleus in a data set of histological tissue image; classifying prostate cancer tissue with a trained deep learning network.
23. Image capture and analysis apparatus according to claim 22, wherein the trained deep learning network can reside on a server in a client/server architecture.
24. Image capture and analysis apparatus according to claim 22, wherein the trained deep learning network can reside on a client in a client/server architecture.
</claims>
</document>
