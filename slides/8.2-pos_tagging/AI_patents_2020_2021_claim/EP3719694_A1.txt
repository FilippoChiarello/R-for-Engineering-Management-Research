<document>

<filing_date>
2018-12-21
</filing_date>

<publication_date>
2020-10-07
</publication_date>

<priority_date>
2018-01-04
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06K9/62
</ipc_classes>

<assignee>
HANGZHOU HIKVISION DIGITAL TECHNOLOGY COMPANY
</assignee>

<inventors>
KANG, Weichang
REN, Zhihao
SHEN, Chuan
</inventors>

<docdb_family_id>
67143832
</docdb_family_id>

<title>
NEURAL NETWORK MODEL-BASED HUMAN FACE LIVING BODY DETECTION
</title>

<abstract>
A method, an apparatus and an electronic device for face liveness detection based on a neural network model are provided. The method includes: a target visible light image and a target infrared image of a target object to be detected are obtained (S101); a first face image is extracted from the target visible light image, and a second face image is extracted from the target infrared image (SI02); a target image array of the target object is generated based on multiple monochromatic components of the first face image and a monochromatic component of the second face image (S103); and feeding the target image array into a pre-trained neural network model for detection, to obtain a face liveness detection result of the target object (S104).
</abstract>

<claims>
1. A face liveness detection method based on a neural network model, comprising: obtaining a target visible light image and a target infrared image of a target object to be detected; extracting, from the target visible light image, a first face image containing only a face part; extracting, from the target infrared image, a second face image containing only the face part; generating a target image array of the target object based on multiple monochromatic components of the first face image and a monochromatic component of the second face image; and feeding the target image array into a neural network model pre-trained for detection, to obtain a face liveness detection result of the target object.
2. The method of claim 1, wherein the neural network model is trained in the following manner comprising: obtaining a visible light image and an infrared image of each of a plurality of samples, wherein sample types of the plurality of samples include positive samples and negative samples, the positive samples are live-body objects, and the negative samples are non-live-body objects; for each of the plurality of samples, extracting a first sample image containing only a face part from the visible light image of the sample; extracting a second sample image containing only the face part from the infrared image of the sample; generating a target image array of the sample based on multiple monochromatic components of the first sample image and a monochromatic component of the second sample image; and training a pre-initialized neural network model based on the target image array of each of the plurality of samples and the sample type of each of the plurality of samples.
3. The method of any of claims 1 to 2, wherein generating the target image array of the target object based on the multiple monochromatic components of the first face image and the monochromatic component of the second face image comprises:
using each of the multiple monochromatic components of the first face image and the monochromatic component of the second face image as one-dimensional data, respectively, to constitute the target image array of the target object with multi-dimension.
4. The method of any of claims 1 to 2, wherein generating the target image array of the target object based on the multiple monochromatic components of the first face image and the monochromatic component of the second face image comprises: performing dimensionality reduction on a combination of the multiple monochromatic components of the first face image and the monochromatic component of the second face image to obtain a target grayscale image; and using one-dimensional data corresponding to the target grayscale image to constitute the target image array of the target object with one-dimension.
5. The method of any of claims 1 to 2, wherein generating the target image array of the target object based on the multiple monochromatic components of the first face image and the monochromatic component of the second face image comprises: performing image preprocessing on the first face image and the second face image; and determining the target image array of the target object based on multiple monochromatic components of the preprocessed first face image and a monochromatic component of the preprocessed second face image.
6. A face liveness detection apparatus based on a neural network model, comprising: an image obtaining unit, configured to obtain a target visible light image and a target infrared image of a target object to be detected; a face image extracting unit, configured to extract a first face image containing only a face from the target visible light image, and a second face image containing only the face from the target infrared image; a target image array generating unit, configured to generate a target image array of the target object based on multiple monochromatic components of the first face image and a monochromatic component of the second face image; and a determining unit, configured to feed the target image array into a neural network model pre-trained for detection, to obtain a face liveness detection result of the target object.
7. The apparatus of claim 6, wherein the neural network model is trained by a model training unit, and the model training unit is configured to: obtain a visible light image and an infrared image of each of a plurality of samples, wherein sample types of the plurality of samples include positive samples and negative samples, the positive samples are live-body objects, and the negative samples are non-live-body objects; for each of the plurality of samples, extract a first sample image containing only a face part from the visible light image of the sample; extract a second sample image containing only the face part from the infrared image of the sample; generate a target image array of the sample based on multiple monochromatic components of the first sample image and a monochromatic component of the second sample image; and train a pre-initialized neural network model based on the target image array of each of the plurality of samples and the sample type of each of the plurality of samples.
8. The apparatus of any of claims 6 to 7, wherein the target image array generating unit is configured to:
use each of the multiple monochromatic components of the first face image and the monochromatic component of the second face image as one-dimensional data, respectively, to constitute the target image array of the target object with multi-dimension.
9. The apparatus of any of claims 6 to 7, wherein the target image array generating unit is configured to: perform dimensionality reduction on a combination of the multiple monochromatic components of the first face image and the monochromatic component of the second face image to obtain a target grayscale image; and use one-dimensional data corresponding to the target grayscale image to constitute the target image array of the target object with one-dimension.
10. The apparatus of any of claims 6 to 7, wherein the target image array generating unit is configured to: perform image preprocessing on the first face image and the second face image; and determine the target image array of the target object based on multiple monochromatic components of the preprocessed first face image and a monochromatic component of the preprocessed second face image.
11. An electronic device, comprising: an internal bus, a memory, a processor, and a communications interface, wherein,
the processor, the communications interface, and the memory communicate with each other through the internal bus;
the memory is configured to store machine-readable instructions corresponding to a face liveness detection method based on a neural network model; and
the processor is configured to read and execute the machine-readable instructions on the memory to implement the face liveness detection method based on the neural network model according to any of claims 1 to 5.
</claims>
</document>
