<document>

<filing_date>
2019-02-20
</filing_date>

<publication_date>
2020-08-27
</publication_date>

<priority_date>
2019-02-20
</priority_date>

<ipc_classes>
G06F3/16,G10L15/18,G10L15/22,G10L17/00,H04M3/493
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
ALTHAUS, JAN
CASADO, DIEGO MELENDO
HUME, TOM
ROM, MOHAMAD HASSAN
SHARIFI, MATTHEW
</inventors>

<docdb_family_id>
65686058
</docdb_family_id>

<title>
UTILIZING PRE-EVENT AND POST-EVENT INPUT STREAMS TO ENGAGE AN AUTOMATED ASSISTANT
</title>

<abstract>
Techniques are described herein for selectively processing a user's utterances captured prior to and after an event that invokes an automated assistant to determine the user's intent and/or any parameters required for resolving the user's intent. In various implementations, respective measures of fitness for triggering responsive action by the automated assistant may be determined for pre-event and a post-event input streams. Based on the respective measures of fitness, one or both of the pre-event input stream or post-event input stream may be selected and used to cause the automated assistant to perform one or more responsive actions.
</abstract>

<claims>
What is claimed is:
1. A method implemented using one or more processors, comprising:
executing an automated assistant in an inactive listening state at least in part on a computing device operated by a user;
while in the inactive listening state, detecting an event that triggers transition of the automated assistant from the inactive listening state into an active listening state, wherein first data indicative of sound captured by one or more microphones prior to the event is
temporarily stored, as a pre-event input stream, in a memory buffer of the computing device operated by the user;
obtaining, as a post-event input stream, second data indicative of sound captured by one or more of the microphones after detecting the event;
while in the active listening state, determining respective measures of fitness of the pre-event and post-event input streams for triggering responsive action by the automated assistant;
based on the respective measures of fitness, selecting the pre-event input stream or post-event input stream; and
causing the automated assistant to perform one or more responsive actions based on the selected input stream.
2. The method of claim 1, further comprising monitoring sound captured by one or more of the microphones for one or more hot words, wherein the event that triggers transition of the automated assistant from the inactive listening state into the active listening state comprises detection of one or more of the hot words during the monitoring.
3. The method of claim 2, further comprising performing speaker recognition processing on at least a portion of the sound captured by the one or more microphones to determine an identity of the user, wherein transition of the automated assistant from the inactive listening state into the active listening state is further triggered in response to a determination that the identity of the user satisfies one or more criteria.
4. The method of claim 3, wherein the one or more criteria include the identity of the user matching an owner of the computing device.
5. The method of claim 2, wherein the monitoring is performed using a digital signal processor integral with the computing device operated by the user.
6. The method of claim 5, wherein the digital signal processor is integral with a digital signal processing chip, and wherein the memory buffer comprises a digital signal processing buffer onboard the digital signal processing chip.
7. The method of claim 2, wherein one or more of the hot words is a pronoun, and the method further includes resolving the pronoun to one or more tokens extracted from the selected input stream.
8. The method of claim 1, wherein the memory buffer comprises a circular memory buffer that is periodically overwritten by newly captured audio data.
9. The method of claim 1, wherein the memory buffer is configured to temporarily store audio data captured over a predetermined time interval.
10. The method of claim 1, wherein determining the respective measures of fitness includes determining respective similarity measures between the pre-event and post-event input streams and one or more known command syntaxes.
11. The method of claim 10, wherein determining the respective measures of fitness includes analyzing one or more features of the user's voice in one or both of the pre-event and post-event input streams.
12. The method of claim 11, wherein the analyzing includes comparing the one or features of the user's voice to one or more voice features observed from utterances containing commands for automated assistants.
13. The method of claim 11, wherein the analyzing includes applying the one or features of the user's voice as input across a machine learning model, wherein the machine learning model is trained to generate output indicative of whether the input is directed to an automated assistant.
14. A system comprising one or more processors and memory storing instructions that, in response to execution of the instructions by the one or more processors, cause the one or more processors to perform the following operations:
executing an automated assistant in an inactive listening state at least in part on a computing device operated by a user; while in the inactive listening state, detecting an event that triggers transition of the automated assistant from the inactive listening state into an active listening state, wherein first data indicative of sound captured by one or more microphones prior to the event is
temporarily stored, as a pre-event input stream, in a memory buffer of the computing device operated by the user;
obtaining, as a post-event input stream, second data indicative of sound captured by one or more of the microphones after detecting the event;
while in the active listening state, determining respective measures of fitness of the pre-event and post-event input streams for triggering responsive action by the automated assistant;
based on the respective measures of fitness, selecting the pre-event input stream or post-event input stream; and
causing the automated assistant to perform one or more responsive actions based on the selected input stream.
15. The system of claim 14, further comprising monitoring sound captured by one or more of the microphones for one or more hot words, wherein the event that triggers transition of the automated assistant from the inactive listening state into the active listening state comprises detection of one or more of the hot words during the monitoring.
16. The system of claim 15, further comprising performing speaker recognition processing on at least a portion of the sound captured by the one or more microphones to determine an identity of the user, wherein transition of the automated assistant from the inactive listening state into the active listening state is further triggered in response to a determination that the identity of the user satisfies one or more criteria.
17. The system of claim 16, wherein the one or more criteria include the identity of the user matching an owner of the computing device.
18. The system of claim 15, wherein the monitoring is performed using a digital signal processor integral with the computing device operated by the user.
19. At least one non-transitory computer-readable medium comprising instructions that, in response to execution of the instructions by one or more processors, cause the one or more processors to perform the following operations: executing an automated assistant in an inactive listening state at least in part on a computing device operated by a user;
while in the inactive listening state, detecting an event that triggers transition of the automated assistant from the inactive listening state into an active listening state, wherein first data indicative of sound captured by one or more microphones prior to the event is
temporarily stored, as a pre-event input stream, in a memory buffer of the computing device operated by the user;
obtaining, as a post-event input stream, second data indicative of sound captured by one or more of the microphones after detecting the event;
while in the active listening state, determining respective measures of fitness of the pre-event and post-event input streams for triggering responsive action by the automated assistant;
based on the respective measures of fitness, selecting the pre-event input stream or post-event input stream; and
causing the automated assistant to perform one or more responsive actions based on the selected input stream.
20. The at least one non-transitory computer-readable medium of claim 19, further comprising instructions for monitoring sound captured by one or more of the microphones for one or more hot words, wherein the event that triggers transition of the automated assistant from the inactive listening state into the active listening state comprises detection of one or more of the hot words during the monitoring.
</claims>
</document>
