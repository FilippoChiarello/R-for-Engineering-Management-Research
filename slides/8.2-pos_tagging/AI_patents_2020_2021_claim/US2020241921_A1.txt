<document>

<filing_date>
2019-01-28
</filing_date>

<publication_date>
2020-07-30
</publication_date>

<priority_date>
2019-01-28
</priority_date>

<ipc_classes>
G06F9/50,G06N3/04
</ipc_classes>

<assignee>
EMC IP HOLDING COMPANY
</assignee>

<inventors>
GOTTIN, VIN√çCIUS MICHEL
CALMON, TIAGO SALVIANO
</inventors>

<docdb_family_id>
71733763
</docdb_family_id>

<title>
BUILDING NEURAL NETWORKS FOR RESOURCE ALLOCATION FOR ITERATIVE WORKLOADS USING REINFORCEMENT LEARNING
</title>

<abstract>
Reinforcement learning agents for resource allocation for iterative workloads, such as training Deep Neural Networks, are configured. One method comprises obtaining a specification of an iterative workload comprising multiple states and a set of available actions for each state, and a domain model of the iterative workload relating allocated resources with service metrics; adjusting weights of a reinforcement learning agent by performing iteration steps for each simulated iteration of the iterative workload and using variables from the simulated iteration to refine the reinforcement learning agent; and determining a dynamic resource allocation policy for the iterative workload. The exemplary iteration steps comprise: (a) selecting an action for a current state, obtaining a reward for the selected action and selecting a next state based on the current state and/or the selected action; (b) updating a function that evaluates a quality of a plurality of state-action combinations; and (c) repeating steps (a) and (b) with a new allocation of resources.
</abstract>

<claims>
1. A method, comprising: obtaining (i) a specification of an iterative workload comprising a plurality of states of the iterative workload and a set of available actions for one or more of the plurality of states, and (ii) a domain model of the iterative workload that relates an amount of resources allocated in training data with one or more service metrics, wherein a duration of one simulated iteration using said domain model of the iterative workload satisfies a predefined duration criteria; adjusting weights of at least one reinforcement learning agent by performing iteration steps for each simulated iteration of the iterative workload and then using variables observed during the simulated iteration to refine the at least one reinforcement learning agent; and determining, by the at least one reinforcement learning agent implemented using at least one processing device, a dynamic resource allocation policy for the iterative workload, wherein the iteration steps for each simulated iteration of the iterative workload comprise: (a) employing the at least one reinforcement learning agent to select an action from the set of available actions for a current state, obtain a reward for the selected action and select a next state based on one or more of the current state and the selected action for the current state; (b) updating, by the at least one reinforcement learning agent, a function that evaluates a quality of a plurality of state-action combinations; and (c) repeating the employing and updating steps with a new allocation of resources for simulated iteration of the iterative workload.
2. The method of claim 1, wherein the domain model is obtained from sample training executions used to learn the relationship between the amount of resources allocated and the one or more service metrics.
3. The method of claim 1, wherein the step of adjusting weights of the at least one reinforcement learning agent employs a reward metric based on a difference between a desired service metric and a measured service metric.
4. The method of claim 1, wherein the step of adjusting weights of the at least one reinforcement learning agent comprises a neural network selecting an action from the set of available actions based on a current state and an expected reward of the selected action and comparing the expected reward of the selected action to the actual obtained reward.
5. The method of claim 1, wherein the iterative workload comprises a training of a Deep Neural Network.
6. The method of claim 1, wherein possible actions for resource allocation are discretized using a minimum control action parameter.
7. The method of claim 1, wherein the simulated iteration executes in a simulated environment that generates observations from the domain model.
8. A computer program product, comprising a tangible machine-readable storage medium having encoded therein executable code of one or more software programs, wherein the one or more software programs when executed by at least one processing device perform the following steps: obtaining (i) a specification of an iterative workload comprising a plurality of states of the iterative workload and a set of available actions for one or more of the plurality of states, and (ii) a domain model of the iterative workload that relates an amount of resources allocated in training data with one or more service metrics, wherein a duration of one simulated iteration using said domain model of the iterative workload satisfies a predefined duration criteria; adjusting weights of at least one reinforcement learning agent by performing iteration steps for each simulated iteration of the iterative workload and then using variables observed during the simulated iteration to refine the at least one reinforcement learning agent; and determining, by the at least one reinforcement learning agent, a dynamic resource allocation policy for the iterative workload, wherein the iteration steps for each simulated iteration of the iterative workload comprise: (a) employing the at least one reinforcement learning agent to select an action from the set of available actions for a current state, obtain a reward for the selected action and select a next state based on one or more of the current state and the selected action for the current state; (b) updating, by the at least one reinforcement learning agent, a function that evaluates a quality of a plurality of state-action combinations; and (c) repeating the employing and updating steps with a new allocation of resources for simulated iteration of the iterative workload.
9. The computer program product of claim 8, wherein the domain model is obtained from sample training executions used to learn the relationship between the amount of resources allocated and the one or more service metrics.
10. The computer program product of claim 8, wherein the step of adjusting weights of the at least one reinforcement learning agent employs a reward metric based on a difference between a desired service metric and a measured service metric.
11. The computer program product of claim 8, wherein the step of adjusting weights of the at least one reinforcement learning agent comprises a neural network selecting an action from the set of available actions based on a current state and an expected reward of the selected action and comparing the expected reward of the selected action to the actual obtained reward.
12. The computer program product of claim 8, wherein the iterative workload comprises a training of a Deep Neural Network.
13. The computer program product of claim 8, wherein possible actions for resource allocation are discretized using a minimum control action parameter.
14. An apparatus, comprising: a memory; and at least one processing device, coupled to the memory, operative to implement the following steps: obtaining (i) a specification of an iterative workload comprising a plurality of states of the iterative workload and a set of available actions for one or more of the plurality of states, and (ii) a domain model of the iterative workload that relates an amount of resources allocated in training data with one or more service metrics, wherein a duration of one simulated iteration using said domain model of the iterative workload satisfies a predefined duration criteria; adjusting weights of at least one reinforcement learning agent by performing iteration steps for each simulated iteration of the iterative workload and then using variables observed during the simulated iteration to refine the at least one reinforcement learning agent; and determining, by the at least one reinforcement learning agent, a dynamic resource allocation policy for the iterative workload, wherein the iteration steps for each simulated iteration of the iterative workload comprise: (a) employing the at least one reinforcement learning agent to select an action from the set of available actions for a current state, obtain a reward for the selected action and select a next state based on one or more of the current state and the selected action for the current state; (b) updating, by the at least one reinforcement learning agent, a function that evaluates a quality of a plurality of state-action combinations; and (c) repeating the employing and updating steps with a new allocation of resources for simulated iteration of the iterative workload.
15. The apparatus of claim 14, wherein the domain model is obtained from sample training executions used to learn the relationship between the amount of resources allocated and the one or more service metrics.
16. The apparatus of claim 14, wherein the step of adjusting weights of the at least one reinforcement learning agent employs a reward metric based on a difference between a desired service metric and a measured service metric.
17. The apparatus of claim 14, wherein the step of adjusting weights of the at least one reinforcement learning agent comprises a neural network selecting an action from the set of available actions based on a current state and an expected reward of the selected action and comparing the expected reward of the selected action to the actual obtained reward.
18. The apparatus of claim 14, wherein the iterative workload comprises a training of a Deep Neural Network.
19. The apparatus of claim 14, wherein possible actions for resource allocation are discretized using a minimum control action parameter.
20. The apparatus of claim 14, wherein the simulated iteration executes in a simulated environment that generates observations from the domain model.
</claims>
</document>
