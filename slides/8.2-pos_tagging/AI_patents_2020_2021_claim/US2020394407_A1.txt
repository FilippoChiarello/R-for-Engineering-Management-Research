<document>

<filing_date>
2020-06-12
</filing_date>

<publication_date>
2020-12-17
</publication_date>

<priority_date>
2019-06-14
</priority_date>

<ipc_classes>
B62J50/20,G06K9/00,G06K9/62,G06N20/00,G06T7/70
</ipc_classes>

<assignee>
SHIMANO
</assignee>

<inventors>
MASUTA, NORIKO
Chikai, Kozo
Tanaka, Shou
Hommoto, Yasuho
Nakamura, Katsuo
Shimazu, Hayato
Nakashima, Yasuhiro
Tagawa, Kenji
</inventors>

<docdb_family_id>
73547136
</docdb_family_id>

<title>
DETECTION DEVICE, DETECTION METHOD, GENERATION METHOD, COMPUTER PROGRAM, AND STORAGE MEDIUM
</title>

<abstract>
Provided are a detecting device, a detecting method, a generating method, and a computer-readable storage medium that allow the user to readily obtain information on an object related to a human-powered vehicle. The detecting device includes a control unit that detects an object related to a human-powered vehicle as a target object from a first image including at least a part of the human-powered vehicle, and outputs related information related to the target object.
</abstract>

<claims>
1. A detecting device comprising: a control unit including processing circuitry, the control unit being configured to detect in a first image including at least a part of a human-powered vehicle an object that is classified as a target object related to the human-powered vehicle, and output information related to the target object.
2. The detecting device according to claim 1, wherein the control unit detects the object by executing a machine learning model, the machine learning model having been trained on a training data set during a training phase, and being configured at run-time to receive the first image as input, and in response, output identification information that identifies the target object and a confidence value of the identification of the object as the target object.
3. The detecting device according to claim 1, wherein the object includes a component of the human-powered vehicle and the target object includes a target component, and the control unit detects the component of the human-powered vehicle as the target component in the first image.
4. The detecting device according to claim 3, wherein the control unit outputs the related information and a second image featuring the target component.
5. The detecting device according to claim 3, wherein the related information includes component information related to the target component.
6. The detecting device according to claim 5, wherein the component information includes at least one of information on a type of the target component, a specification of the target component, an assembling method for the target component, an installing method for the target component, a disassembling method for the target component, an adjusting method for the target component, and a replacement for the target component.
7. The detecting device according to claim 6, wherein the information on the installing method includes at least one of information on a component for installing the target component in the human-powered vehicle and information on a tool required for installation of the target component.
8. The detecting device according to claim 6, wherein the information on a replacement includes information on another component required for the target component to be replaced with the replacement.
9. The detecting device according to claim 3, wherein the control unit outputs information on an installed state of the target component detected in the human-powered vehicle.
10. The detecting device according to claim 3, wherein the target component is one of a plurality of target components detected by the control unit in the first image, and the control unit outputs information on a matching state among the plurality of target components as the related information.
11. The detecting device according to claim 1, wherein the object includes a frame of the human-powered vehicle, and the control unit detects the frame as a target frame in the first image.
12. The detecting device according to claim 11, wherein the control unit outputs the related information and a third image featuring the target frame.
13. The detecting device according to claim 11, wherein the control unit outputs information on a component to be recommended in accordance with the target frame, and user information including at least one of physical information and attribute information of a user of the human-powered vehicle as the related information.
14. The detecting device according to claim 13, wherein the physical information includes information on a position of a joint of the user.
15. The detecting device according to claim 1, wherein the control unit outputs the related information as at least one of text data and graphical data.
16. The detecting device according to claim 1, further comprising a display unit that displays information output from the control unit.
17. The detecting device according to claim 16, wherein the display unit accepts input of selecting the related information as related information to be selected, and the control unit outputs detailed information of the related information to be selected.
18. The detecting device according to claim 16, wherein the display unit is configured to receive a user selection of the target component in the second image, and in response to the user selection, the control unit outputs information related to the target component.
19. The detecting device according to claim 1, further comprising a non-volatile storage device in communication with the processing circuitry, the non-volatile storage device being configured to store information output from the processing circuitry of the control unit.
20. The detecting device according to claim 19, wherein the control unit stores identification information of the target object in the storage device in association with the related information.
21. The detecting device according to claim 19, wherein the control unit stores identification information of the target object in the storage device in association with identification information of the user of the human-powered vehicle.
22. The detecting device according to claim 1, wherein the control unit outputs the identification information of the detected target object in association with the related information to an external device.
23. The detecting device according to claim 1, wherein the control unit outputs the identification information of the detected target object in association with the identification information of the user of the human-powered vehicle to an external device.
24. The detecting device according to claim 1, wherein the control unit outputs information for prompting the user to input the first image in accordance with a traveling history of the human-powered vehicle.
25. The detecting device according to claim 1, wherein the control unit outputs the first image in association with the traveling history of the human-powered vehicle to an external device.
26. The detecting device according to claim 1, wherein the control unit outputs the first image in association with traveling environment information indicating traveling environment of the human-powered vehicle to an external device.
27. The detecting device according to claim 2, wherein a training computer trains the machine learning model using training data including labeled images, each of the labeled images including pixel data showing a part of the human-powered vehicle and being labeled with identification information of a target object shown in each of the images, the images having been collected through the Internet.
28. The detecting device according to claim 2, wherein a training computer trains the machine learning model using training data including rendered images generated by an application program of designs relating to at least one of a frame and a component of the human-powered vehicle, and identification information associated with a target object for each of the rendered images.
29. The detecting device according to claim 2, wherein a training computer trains the machine learning model using training data including a plurality of images obtained when at least one of a frame and a component of the human-powered vehicle is viewed from a plurality of different angles.
30. The detecting device according to claim 2, wherein the control unit, upon determining that the confidence value that is output from the learning model is equal to or less than a predetermined value, outputs a plurality of identification information candidates of the object in descending order of the confidence value of each, receives a user selection of one of the plurality of the identification information candidates, and retrains the learning model by a fourth image labeled with the selected identification information candidate.
31. A detection method executable by a processor, the method comprising: detecting an object related to a human-powered vehicle as a target object in a first image including at least a part of the human-powered vehicle; and outputting information related to the target object.
32. A method for generating a learning model, the method comprising: creating training data obtained by labeling a plurality of first images each including at least a part of a human-powered vehicle with identification information of objects related to the human-powered vehicle, and generating a learning model based on the created training data that detects, in accordance with input of an image, an object related to the human-powered vehicle as a target object in the image, and outputs identification information of the target object and a confidence value.
33. A computer-readable storage medium comprising instructions configured to be executed by a processor of a computer, the instructions including: detecting an object related to a human-powered vehicle as a target object in a first image including at least a part of the human-powered vehicle; and outputting information related to the target object.
</claims>
</document>
