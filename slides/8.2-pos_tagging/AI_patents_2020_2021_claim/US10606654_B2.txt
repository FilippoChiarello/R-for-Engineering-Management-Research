<document>

<filing_date>
2017-10-10
</filing_date>

<publication_date>
2020-03-31
</publication_date>

<priority_date>
2015-04-29
</priority_date>

<ipc_classes>
G06F9/48,G06F9/50
</ipc_classes>

<assignee>
HUAWEI TECHNOLOGIES COMPANY
</assignee>

<inventors>
SHAO GANG
TAN WEIGUO
</inventors>

<docdb_family_id>
53812469
</docdb_family_id>

<title>
Data processing method and apparatus
</title>

<abstract>
A data processing method and apparatus are disclosed. The method is determining candidate computing frameworks for each sub-task in a sub-task set; predicating operation time and resource consumption that correspond to each candidate computing framework when the candidate computing framework executes the sub-task; and selecting, in the candidate computing frameworks according to the predicated operation time and resource consumption that correspond to each candidate computing framework when the candidate computing framework executes the sub-task, a target computing framework executing the sub-task (204), and executing the sub-task (205). In this way, a resource management system selects a target computing framework from multiple computing frameworks according to operation time and resource consumption, to execute each sub-task, so as to improve the data processing efficiency and working performance of the system.
</abstract>

<claims>
1. A data processing method, comprising: receiving a task request that carries a task submitted by a user; generating a sub-task set comprising at least one sub-task according to the task in the task request; determining input data for executing each sub-task in the sub-task set; performing the following operations for each sub-task in the sub-task set; determining, in all computing frameworks configured in a system, computing frameworks capable of executing the sub-task as candidate computing frameworks, wherein a quantity of the candidate computing frameworks is greater than or equal to two; separately predicting, according to the input data of the sub-task and a prediction model that corresponds to each candidate computing framework, operation time and resource consumption that correspond to each candidate computing framework for executing the sub-task; and selecting, in the candidate computing frameworks according to the operation time and the resource consumption that correspond to each candidate computing framework for executing the sub-task, a fixed target computing framework for executing the sub-task; and subsequent to selecting the fixed target computing framework, executing the corresponding sub-task based on the fixed target computing framework selected for executing each sub-task in the sub-task set.
2. The method of claim 1, wherein the task request further carries input data of the task, and wherein determining the input data for executing each sub-task comprises determining the input data for executing each sub-task according to the input data of the task carried in the task request.
3. The method of claim 1, wherein before receiving the task request, the method further comprises encapsulating, in all the computing frameworks configured in the system and using a preset programming language, application program interfaces (APIs) that are in all computing frameworks capable of executing a task having a same task type and that are capable of executing the task having the same task type to form a unified API, and wherein determining the computing frameworks that are capable of executing the sub-task as candidate computing frameworks comprises: determining a task type of the sub-task; determining a unified API corresponding to the task type of the sub-task; determining, according to the determined unified API, all computing frameworks capable of executing the sub-task of the task type; and using the determined computing frameworks as the candidate computing frameworks.
4. The method of claim 1, wherein obtaining the prediction model corresponding to the candidate computing framework comprises: reading a preset training sample set, wherein the preset training sample set is preset for a capability of the candidate computing framework for executing the sub-task; and training, using the operation time and the resource consumption as target features separately, features other than the operation time and the resource consumption in the preset training sample set to obtain the prediction model corresponding to the candidate computing framework.
5. The method of claim 1, wherein selecting the fixed target computing framework comprises: selecting, in the candidate computing frameworks, a candidate computing framework whose predicted resource consumption is less than an available resource of the system as a first candidate computing framework; and selecting, in the first candidate computing framework, a first candidate computing framework whose predicted operation time is the shortest as the fixed target computing framework.
6. The method of claim 4, wherein after executing the corresponding sub-task, the method further comprises: using each feature generated during execution of the sub-task in the fixed target computing framework of the sub-task as a new training sample; and adding the new training sample to the preset training sample set.
7. A data processing apparatus, comprising: a processor; and a non-transitory computer-readable storage medium coupled to the processor and configured to store programming instructions for execution by the processor, wherein the programming instructions comprise: instructions for receiving a task request that carries a task submitted by a user; instructions for generating a sub-task set comprising at least one sub-task according to the task in the task request; instructions for determining input data for executing each sub-task; for each sub-task in the sub-task set: instructions for determining, in all computing frameworks configured in a system, computing frameworks that are capable of executing the sub-task as candidate computing frameworks, wherein a quantity of the candidate computing frameworks is greater than or equal to two; instructions for separately predicting, according to the input data of the sub-task and a prediction model that corresponds to each candidate computing framework, operation time and resource consumption that correspond to each candidate computing framework for executing the sub-task; and instructions for selecting, in the candidate computing frameworks according to the operation time and the resource consumption that correspond to each candidate computing framework for executing the sub-task, a fixed target computing framework for executing the sub-task; and instructions for executing, subsequent to selecting the fixed target computing framework, the corresponding sub-task based on the fixed target computing framework selected for executing each sub-task in the sub-task set.
8. The apparatus of claim 7, wherein the task request further carries input data of the task, and wherein the programming instructions further comprise instructions for determining the input data for executing each sub-task according to the input data of the task carried in the task request.
9. The apparatus of claim 7, wherein the programming instructions further comprise instructions for encapsulating, before the task request is received, in all the computing frameworks configured in the system and using a preset programming language, application program interfaces (APIs) that are in all computing frameworks capable of executing a task having a same task type and that are capable of executing the task having the same task type to form a unified API, and wherein when determining the computing frameworks capable of executing the sub-task as the candidate computing frameworks, the programming instructions further comprise: instructions for determining a task type of the sub-task; instructions for determining a unified API corresponding to the task type of the sub-task; and instructions for determining, according to the determined unified API, all computing frameworks capable of executing the sub-task of the task type; and instructions for using the determined computing frameworks as the candidate computing frameworks.
10. The apparatus of claim 7, wherein when obtaining the prediction model corresponding to the candidate computing framework, the programming instructions further comprise: instructions for reading a preset training sample set, wherein the preset training sample set is preset for a capability of the candidate computing framework for executing the sub-task; and instructions for training, using the operation time and the resource consumption as target features separately, features other than the operation time and the resource consumption in the preset training sample set to obtain the prediction model corresponding to the candidate computing framework.
11. The apparatus of claim 7, wherein the instructions for selecting the fixed target computing framework comprise: instructions for selecting, in the candidate computing frameworks, a candidate computing framework whose predicted resource consumption is less than an available resource of the system as a first candidate computing framework; and instructions for selecting, in the first candidate computing framework, a first candidate computing framework whose predicted operation time is the shortest as the fixed target computing framework.
12. The apparatus of claim 10, wherein the programming instructions further comprise: instructions for using each feature that is generated during execution of the sub-task in the fixed target computing framework of the sub-task as a new training sample after executing the corresponding sub-task based on the fixed target computing framework; and instructions for adding the new training sample to the preset training sample set.
13. A non-transitory computer-readable storage medium comprising instructions which, when executed by a computer, cause the computer to: receive a task request that carries a task submitted by a user; generate a sub-task set comprising at least one sub-task according to the task in the task request; determine input data for executing each sub-task; perform the following operations for each sub-task in the sub-task set: determine, in all computing frameworks configured in a system, computing frameworks that are capable of executing the sub-task as candidate computing frameworks, wherein a quantity of the candidate computing frameworks is greater than or equal to two; separately predict, according to the input data of the sub-task and a prediction model that corresponds to each candidate computing framework, operation time and resource consumption that correspond to each candidate computing framework for executing the sub-task; and select, in the candidate computing frameworks according to the operation time and the resource consumption that correspond to each candidate computing framework for executing the sub-task, a fixed target computing framework for executing the sub-task; and subsequent to selecting the fixed target computing framework, execute the corresponding sub-task based on the fixed target computing framework selected for executing each sub-task in the sub-task set.
14. The computer-readable storage medium of claim 13, wherein the task request further carries input data of the task, and wherein the instructions cause the computer to determine the input data for executing each sub-task by causing the computer to determine the input data for executing each sub-task according to the input data of the task carried in the task request.
15. The computer-readable storage medium of claim 13, wherein before receiving the task request, the instructions cause the computer to encapsulate, in all the computing frameworks configured in the system and using a preset programming language, application program interfaces (APIs) that are in all computing frameworks capable of executing a task having a same task type and that are capable of executing the task having the same task type to form a unified API, and wherein the instructions cause the computer to determine the computing frameworks that are capable of executing the sub-task as candidate computing frameworks by causing the computer to: determine a task type of the sub-task; determine a unified API corresponding to the task type of the sub-task; determine, according to the determined unified API, all computing frameworks capable of executing the sub-task of the task type; and use the determined computing frameworks as the candidate computing frameworks.
16. The computer-readable storage medium of claim 13, wherein the instructions cause the computer to obtain the prediction model corresponding to the candidate computing framework by causing the computer to: read a preset training sample set, wherein the preset training sample set is preset for a capability of the candidate computing framework for executing the sub-task; and train, using the operation time and the resource consumption as target features separately, features other than the operation time and the resource consumption in the preset training sample set to obtain the prediction model corresponding to the candidate computing framework.
17. The computer-readable storage medium of claim 16, wherein after executing the corresponding sub-task based on the fixed target computing framework for executing each sub-task in the sub-task set, the instructions further cause the computer to: use each feature generated during execution of the sub-task in the fixed target computing framework of the sub-task as a new training sample; and add the new training sample to the preset training sample set.
18. The computer-readable storage medium of claim 13, wherein the instructions cause the computer to select the fixed target computing framework by causing the computer to: select, in the candidate computing frameworks, a candidate computing framework whose predicted resource consumption is less than an available resource of the system as a first candidate computing framework; and select, in the first candidate computing framework, a first candidate computing framework whose predicted operation time is the shortest as the fixed target computing framework.
</claims>
</document>
