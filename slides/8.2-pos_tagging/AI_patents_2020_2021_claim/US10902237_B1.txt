<document>

<filing_date>
2019-06-19
</filing_date>

<publication_date>
2021-01-26
</publication_date>

<priority_date>
2019-06-19
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
AGGARWAL, MANOJ
SMITH, KORWIN JON
Garfield, Jason
Williams, Jordan Tyler
</inventors>

<docdb_family_id>
74191061
</docdb_family_id>

<title>
Utilizing sensor data for automated user identification
</title>

<abstract>
This disclosure describes techniques for identifying users that are enrolled for use of a user-recognition system and updating enrollment data of these users over time. To enroll in the user-recognition system, the user may initially scan his or her palm. The resulting image data may later be used when the user requests to be identified by the system by again scanning his or her palm. However, because the characteristics of user palms may change over the time, the user-recognition system may continue to build more and more data for use in recognizing the user, in addition to removing older data that may no longer accurately represent current characteristics of respective user palms.
</abstract>

<claims>
1. A system comprising: one or more processors; and one or more computer-readable media storing computer-executable instructions that, when executed, cause the one or more processors to perform operations comprising: receiving, at a first time, first image data representing a palm of a user; generating first feature data using the first image data; storing a first association between a user profile of the user and the first feature data; receiving second image data at a second time; generating second feature data using the second image data; analyzing the second feature data with reference to the first feature data; determining, based at least in part on the analyzing, that the second image data corresponds to the palm of the user; calculating a confidence level representing a confidence that the second image data corresponds to the palm of the user; determining that the confidence level is greater than a threshold confidence level; determining that a predefined amount of time has elapsed since updating the user profile of the user; storing a second association between the user profile and the second feature data based at least in part on the determining that the confidence level is greater than the threshold confidence level and the determining that the predefined amount of time has elapsed since updating the user profile of the user; receiving third image data at a third time; generating third feature data using the third image data; and analyzing the third feature data with reference to data that is based at least in part on the first feature data and the second feature data.
2. The system as recited in claim 1, the operations further comprising analyzing the second feature data with reference to at least the first feature data and with reference to fourth feature data associated with a previous recognition of the palm of the user, and wherein the calculating of the confidence level comprises calculating the confidence level based at least in part on the analyzing of the second feature data with reference to at least the first feature data and the fourth feature data.
3. The system as recited in claim 1, wherein the confidence level comprises a first confidence level and the operations further comprising: determining, based at least in part on the analyzing of the third feature data with reference to data that is based at least in part on the first feature data and the second feature data, that the third image data corresponds to the palm of the user; calculating a second confidence level representing a confidence that the third image data corresponds to the palm of the user; determining that the second confidence level is not greater than the threshold confidence level; and refraining from storing a third association between the user profile and the third feature data.
4. A method comprising: receiving first image data depicting at least a portion of a user; storing, in association with a user profile of the user, at least a portion of the first image data or first feature data generated using the first image data; receiving second image data; generating second feature data using the second image data; analyzing the second feature data with reference to the first feature data to calculate a confidence level indicating a likelihood that the second image data corresponds to the user; determining that the confidence level is greater than a first threshold confidence level; determining, based at least in part on determining that that the confidence level is greater than the first threshold confidence level, that the second image data corresponds to the user; determining that the confidence level is greater than a second threshold confidence level that is greater than the first threshold confidence level; storing, in association with the user profile and based at least in part on determining that the confidence level is greater than the second threshold confidence level, at least a portion of the second image data or the second feature data; receiving third image data; generating third feature data using the third image data; and analyzing the third feature data with reference to data that is based at least in part on the first feature data and the second feature data.
5. The method as recited in claim 4, wherein the first image data depicts a palm of the user, and the first feature data corresponds to at least one of creases in the palm of the user, veins in the palm of the user, or a palmprint of the palm of the user.
6. The method as recited in claim 4, further comprising analyzing the second feature data with reference to data that is based at least in part on the first feature data and fourth feature data associated with a previous recognition of the user, and wherein the calculating of the confidence level comprises calculating the confidence level based at least in part on the analyzing of the second feature data with reference to the data that is based at least in part on the first feature data and the fourth feature data.
7. The method as recited in claim 4, further comprising: determining that a predefined amount of time has elapsed since the storing of the at least one of the first image data or the first feature data in association with the user profile; and wherein the storing the at least the portion of the second image data or the second feature data is further based at least in part on determining that the predefined amount of time has elapsed.
8. The method as recited in claim 4, wherein the confidence level comprises a first confidence level, and further comprising: calculating, based at least in part on the analyzing of the third feature data with reference to data that is based at least in part on the first feature data and the second feature data, a second confidence level indicating a likelihood that the third image data corresponds to the user; determining that the second confidence level is greater than first threshold confidence level but less than the second threshold confidence level; and storing an indication that the third image data corresponds to the user.
9. The method as recited in claim 4, further comprising: determining, based at least in part on the analyzing of the third feature data with reference to data that is based at least in part on the first feature data and the second feature data, that the third image data corresponds to the user; determining that the user profile is to be updated; storing, in association with the user profile, at least a portion of the third image data or the third feature data; and removing, from the user profile, the at least a portion of the first image data or the first feature data.
10. The method as recited in claim 9, further comprising: receiving fourth image data; generating fourth feature data using the fourth image data; and analyzing the fourth feature data with reference to data that is based at least in part on the second feature data and the third feature data.
11. The method as recited in claim 4, wherein the second image data corresponds to multiple images captured within a threshold amount of time, and further comprising: selecting at least one image of the multiple images based one at least one of a focus of the at least one image, a quality of the at least one image, or a discriminability of a portion of the user depicted by the at least one image; and wherein the storing the at least a portion of the second image data or the second feature data in association with the user profile comprises storing, in association with the user profile, at least one of image data corresponding to the selected at least one image or feature data corresponding to the selected at least one image.
12. The method as recited in claim 4, further comprising: receiving an indication that the second image data does not correspond to the user; determining, from the user profile, at least one of fourth image data determined to correspond to the user or fourth feature data generated from the fourth image data; analyzing the second feature data with reference to the fourth feature data; and calculating, based at least in part on the analyzing the second feature data with reference to the fourth feature data, a score indicating a likelihood that the second image data corresponds to the user.
13. A system comprising: one or more processors; and one or more computer-readable media storing computer-executable instructions that, when executed, cause one or more processors to perform operations comprising: receiving first image data depicting at least a portion of a user; storing, in association with a user profile of the user, at least a portion of the first image data or first feature data generated using the first image data; receiving second image data; generating second feature data using the second image data; analyzing the second feature data with reference to the first feature data to calculate a confidence level indicating a likelihood that the second image data corresponds to the user; determining that the confidence level is greater than a first threshold confidence level; determining, based at least in part on determining that that the confidence level is greater than the first threshold confidence level, that the second image data corresponds to the user; determining that the confidence level is greater than second a threshold confidence level; storing, in association with the user profile and based at least in part on determining that the confidence level is greater than the second threshold confidence level, at least a portion of the second image data or the second feature data; receiving third image data; generating third feature data using the third image data; and analyzing the third feature data with reference to data that is based at least in part on the first feature data and with reference to the second feature data.
14. The system as recited in claim 13, wherein the first image data depicts a palm of the user, and the first feature data corresponds to at least one of creases in the palm of the user, veins in the palm of the user, or a palmprint of the palm of the user.
15. The system as recited in claim 13, the operations further comprising analyzing the second feature data with reference to data that is based at least in part on the first feature data and fourth feature data associated with a previous recognition of the user, and wherein the calculating of the confidence level comprises calculating the confidence level based at least in part on the analyzing of the second feature data with reference to that data that is based at least in part on the first feature data and the fourth feature data.
16. The system as recited in claim 13, the operations further comprising: determining that a predefined amount of time has elapsed since the storing of the at least one of the first image data or the first feature data in association with the user profile; and wherein the storing the at least the portion of the second image data or the second feature data is further based at least in part on determining that the predefined amount of time has elapsed.
17. The system as recited in claim 13, wherein the confidence level comprises a first confidence level, and the operations further comprising: calculating, based at least in part on the analyzing of the third feature data with reference to data that is based at least in part on the first feature data and the second feature data, a second confidence level indicating a likelihood that the third image data corresponds to the user; determining that the second confidence level is greater than the first threshold confidence level but less than second first threshold confidence level; and storing an indication that the third image data corresponds to the user.
18. The system as recited in claim 13, the operations further comprising: determining, based at least in part on the analyzing of the third feature data with reference to the data that is based at least in part on the first feature data and the second feature data, that the third image data corresponds to the user; determining that the user profile is to be updated; storing, in association with the user profile, at least a portion of the third image data or the third feature data; and removing, from the user profile, the at least at least a portion of the first image data or the first feature data.
19. The system as recited in claim 18, the operations further comprising: receiving fourth image data; generating fourth feature data using the fourth image data; and analyzing the fourth feature data with reference to data that is based at least in part on data that is based at least in part on the second feature data and the third feature data.
20. The system as recited in claim 13, wherein the second image data corresponds to multiple images captured within a threshold amount of time, and the operations further comprising: selecting at least one image of the multiple images based one at least one of a focus of the at least one image, a quality of the at least one image, or a discriminability of a portion of the user depicted by the at least one image; and wherein the storing the at least a portion of the second image data or the second feature data in association with the user profile comprises storing, in association with the user profile, at least one of image data corresponding to the selected at least one image or feature data corresponding to the selected at least one image.
</claims>
</document>
