<document>

<filing_date>
2017-10-25
</filing_date>

<publication_date>
2020-04-14
</publication_date>

<priority_date>
2017-10-25
</priority_date>

<ipc_classes>
G06F17/27,G06F3/16,G06F8/38,G06N20/00,G10L15/18,G10L15/22,G10L15/26
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
ASHOORI, MARYAM
WEISZ, JUSTIN D.
</inventors>

<docdb_family_id>
66169940
</docdb_family_id>

<title>
Machine learning to determine and execute a user interface trace
</title>

<abstract>
A system, computer program product, and method are provided for use with an intelligent computer platform to convert speech intents to one or more physical actions. The aspect of converting speech intent includes receiving audio, converting the audio to text, parsing the text into segments, identifying a physical action and associated application that are proximal in time to the received audio. A corpus is searched for evidence of a pattern associated with the received audio and corresponding physical action(s) and associated application. An outcome is generated from the evidence. The outcome includes identification of an application and production of an affirmative instruction. The instruction is converted to a user interface trace that is executed within the identified application.
</abstract>

<claims>
1. A computer system comprising: a processing unit operatively coupled to memory; an artificial intelligence platform, in communication with the processing unit; a knowledge engine in communication with the processing unit to decipher verbal content upon activation by the artificial intelligence platform, including: capture the verbal content and convert the captured verbal content into a text representation, including identify one or more segments in the representation; capture a physical interaction associated with a first application proximal in time with the captured content; analyze the captured verbal content in relation to the captured physical interactions with the application, and identify a correlation between an entry in the text representation with the captured first application interactions; search entries in a corpus for evidence of a pattern associated with the correlated text representation with the captured physical interaction, wherein the pattern is two or more user interface traces of the first application associated with the converted text representation; select a user interface activity from the pattern evidence, wherein the selected user interface activity is an instruction to invoke an affirmative instruction to invoke a physical action with a strongest congruence to the pattern; and transmit the affirmative instruction to an operating system operatively coupled to the artificial intelligence platform to identify an application and execute a user interface trace that defines the selected user interface activity within the identified application.
2. The system of claim 1, wherein the identified application is selected from the group consisting of: the first application and a second application operatively coupled to the operating system, and execution of the user interface trace further comprises activation of the identified application.
3. The system of claim 1, wherein execution of the user interface trace produces a physical action in the selected application following receipt of the captured verbal content.
4. The system of claim 1, wherein selection of the user interface activity from the pattern evidence further comprising the knowledge engine to format the user interface activity action to a user interface trace.
5. The system of claim 1, wherein the capture physical interaction includes an action selected from the group consisting of: menu selection, a navigation action, screen view, user interface element tap, keyed entry, sensor data, and geographical location.
6. The system of claim 1, wherein the operating system identified application is uninstalled, and further comprising the operating system to recommend installation of the identified application.
7. A computer program product to convert verbal content into a physical action, the computer program product comprising a computer readable storage device having program code embodied therewith, the program code executable by a processing unit to: capture the verbal content and convert the captured content into a text representation, including identify one or more segments in the representation; capture a physical interaction associated with a first application proximal in time with the captured content; analyze the captured content in relation to the captured physical action with the application, and identify a correlation between an entry in the text representation with the captured first application interaction; search entries in a corpus for evidence of a pattern associated with the correlated text representation with the captured physical interaction, wherein the pattern is two or more user interface traces of the first application associated with the converted text representation; select a user interface activity from the pattern evidence, wherein the selected user interface activity is an instruction to invoke an affirmative instruction to invoke a physical action with a strongest congruence to the pattern; and transmit the affirmative instruction to an operating system operatively coupled to the artificial intelligence platform to identify an application; and generate an outcome, the outcome including execution of a user interface trace that defines the selected user interface activity within the identified application.
8. The computer program product of claim 7, wherein the identified application is selected from the group consisting of: the first application and a second application operatively coupled to the operating system, and execution of the user interface trace further comprises activation of the identified application.
9. The computer program product of claim 7, wherein the program code to execute the user interface trace produces a physical action in the selected application following receipt of the captured content.
10. The computer program product of claim 7, wherein the program code to select the user interface activity from the pattern evidence further comprises program code to format the user interface activity action to a user interface trace.
11. The computer program product of claim 7, wherein the capture physical interaction includes an action selected from the group consisting of: menu selection, a navigation action, screen view, user interface element tap, keyed entry, sensor data, and geographical location.
12. The computer program product of claim 7, wherein the operating system identified application is uninstalled, and further comprising the operating system to recommend installation of the identified application.
13. A method to decipher a verbal phrase upon activation by the artificial intelligence platform comprising: capturing the verbal content and converting the captured content into a text representation, including identifying one or more segments in the representation; capturing a physical interaction associated with a first application proximal in time with the captured content; analyzing the captured content in relation to the captured physical action with the application, and identifying a correlation between an entry in the text representation with the captured first application interaction; searching entries in a corpus for evidence of a pattern associated with the correlated text representation with the captured physical interaction, wherein the pattern is two or more user interface traces of the first application associated with the correlated text representation; selecting a user interface activity from the pattern evidence, wherein the selected user interface activity is an instruction to invoke an affirmative instruction to invoke a physical action with a strongest congruence to the pattern; and transmitting the affirmative instruction to an operating system operatively coupled to the artificial intelligence platform to identify an application and execute a user interface trace that defines the selected user interface activity within the identified application.
14. The method of claim 13, wherein the identified application is selected from the group consisting of: the first application and a second application operatively coupled to the operating system, and execution of the user interface trace further comprises activation of the identified application.
15. The method of claim 13, wherein executing of the user interface trace produces a physical action in the selected application following receipt of the capture content.
16. The method of claim 13, wherein selection of the user interface activity from the pattern evidence further comprising the knowledge engine formatting the user interface activity action to a user interface trace.
17. The method of claim 13, wherein the captured physical interaction includes an action selected from the group consisting of: menu selection, a navigation action, screen view, user interface element tap, keyed entry, sensor data, and geographical location.
18. The method of claim 13, wherein the operating system identified application is uninstalled, and further comprising the operating system recommending installation of the identified application.
</claims>
</document>
