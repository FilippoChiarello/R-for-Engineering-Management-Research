<document>

<filing_date>
2020-02-27
</filing_date>

<publication_date>
2020-09-03
</publication_date>

<priority_date>
2019-02-27
</priority_date>

<ipc_classes>
G06F16/45,G06F16/48,G06N3/02,G06N3/08
</ipc_classes>

<assignee>
VERITONE
</assignee>

<inventors>
KETTLER, DAVID
NGUYEN, PETER
SCHWAMB, KARL
STEELBERG, CHAD
ZHAO YU
</inventors>

<docdb_family_id>
72238529
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR NEURAL NETWORK ORCHESTRATION
</title>

<abstract>
Methods and systems for classifying a multimedia file using interclass data is disclosed. One of the methods can use classification results from one or more engines of different classes to select a different engine for the original classification task. For example, given an audio segment with associated metadata and image data, the disclosed interclass method can use the classification results from a topic classification of metadata and/or an image classification result of the image data as inputs for selecting a new transcription engine to transcribe the audio segment.
</abstract>

<claims>
What is claimed is:
1. A method for classifying a first media segment of a first data type having a corresponding media segment of a second data type, the method comprising:
extracting a first set of media features of the first media segment of the first data type; generating, using an engine prediction neural network, a best candidate neural network based at least on the first set of media features, wherein the best candidate neural network comprises a neural network having a highest predicted value of accuracy;
determining whether a predicted value of accuracy of the best candidate neural network is above a predetermined accuracy threshold;
when the predicted value of accuracy of the best candidate neural network is below the predetermined accuracy threshold, classifying the corresponding media segment of a second data type using a second classification neural network; and
selecting, based at least on results of the classification of the corresponding media segment of a second data type, a third classification neural network to classify the first media segment of the first data type, wherein the first and second data types are different, and wherein the third classification neural network and the best candidate neural network are different.
2. The method of claim 1, wherein extracting the first set of media features of the first data type comprises extracting audio features of the first media segment using outputs of one or more layers of a speech-to-text classification neural network, wherein the first data type comprises audio data and the corresponding media segment of second data type comprises image data, transcription data, or metadata.
3. The method of claim 2, wherein the corresponding media segment spans a duration of 30 seconds before and after from when the first media segment occurs within a multimedia file.
4. The method of claim 1, wherein extracting the first set of media features of the first data type comprises extracting image features of the first media segment using outputs of one or more layers of an image classification neural network, wherein the first data type comprises image data and the corresponding media segment of second data type comprises audio data, transcription data, or metadata.
5. The method of claim 1, further classifying the corresponding media segment of a second data type using the second classification neural network comprising:
extracting a second set of media features of the corresponding media segment of the second data type; and
generating, using the engine prediction neural network, a best candidate neural network based at least on the second set of media features, wherein the second classification neural network comprises the best candidate neural network.
6. The method of claim 1, wherein extracting the first set of media features of the first data type comprises extracting the first set of media features of the first media segment using outputs of one or more hidden layers of a fourth classification neural network trained to classify data of the first data type, wherein the first data type comprises audio data, image data, transcription data, or metadata.
7. The method of claim 6, wherein the engine prediction neural network is trained to associate outputs of the one or more hidden layers of the fourth classification neural network with predicted classification performances of a plurality of neural network.
8. The method of claim 6, wherein the first set of media features is extracted from a last hidden layer of the fourth classification neural network.
9. The method of claim 6, wherein the first set of media features is extracted from a first and last hidden layer of the fourth classification neural network.
10. The method of claim 1, wherein selecting the third image classification neural network comprises:
determining context of the corresponding media segment based at least on the classification result of the corresponding media segment received from the second classification neural network; and
selecting the third classification neural network based on the determined context.
11. A method for classifying a portion of an image, the method comprising:
segmenting the image into a plurality of image portions;
extracting image features of a first image portion of the plurality of image portion using a first image classification engine;
inputting the extracted image features into an engine prediction neural network to generate a list of one or more best candidate engines;
determining a predicted accuracy value for each best candidate engines;
if none of the best candidate engines has a predicted accuracy value above a predetermined accuracy threshold, identifying an alternate data set associated with the first image portion, the alternate data set comprises non-image data;
requesting a second classification engine to classify the alternate data set, wherein the second classification engine is trained to classify data in a same class as the alternate data set; receiving, from the second classification engine, a second classification result of the alternate data set; and
selecting, based at least on the second classification result of the alternate data set, a third image classification engine to re-classify the portion of the image, wherein the first and third image classification engines are different.
12. The method of claim 11, wherein the alternate data set comprises audio data occurring within 30 seconds before and after from an instant the image appearing in the multimedia file.
13. The method of claim 11, wherein the alternate data set comprises metadata occurring within 30 seconds before and after from an instant the image appearing in the multimedia file.
14. The method of claim 11, wherein extracting the image features of the first image portion comprises using outputs of one or more hidden layers of the first image classification engine, wherein the outputs comprise weight values of the one or more hidden layers.
15. The method of claim 14, wherein the engine prediction neural network is trained to associate the weight values of the one or more hidden layers of the first image classification engine with predicted classification performance values of the one or more best candidate engines.
16. The method of claim 15, wherein the weight values of a last hidden layer of the first image classification engine are used as inputs to the engine prediction neural network.
17. The method of claim 16, wherein the first set of media features is extracted from a first and last hidden layer of the fourth classification engine.
18. The method of claim 11, wherein requesting the second classification engine to classify the alternate data set comprises:
extracting media features of the alternate data set; and
generating, using the engine prediction neural network, a best candidate engine based at least on the extracted media features of the alternate data set, wherein the second classification engine comprises a neural network with a highest predicted accuracy value.
19. The method of claim 11, wherein selecting the third image classification engine comprises:
determining context of the first image portion based at least on the second classification result; and
selecting the third image classification engine based on the determined context.
20. A system for classifying a first media segment of a first data type having a corresponding media segment of a second data type, the system comprising:
a memory;
one or more processors coupled to the memory, the one or more processors configured to: extract a first set of media features of the first media segment of the first data type; generate, using an engine prediction neural network, a best candidate neural network based at least on the first set of media features, wherein the best candidate neural network comprises a neural network having a highest predicted value of accuracy;
determine whether a predicted value of accuracy of the best candidate neural network is above a predetermined accuracy threshold;
when the predicted value of accuracy of the best candidate neural network is below the predetermined accuracy threshold, classify the corresponding media segment of a second data type using a second classification neural network; and
select, based at least on results of the classification of the corresponding media segment of a second data type, a third classification neural network to classify the first media segment of the first data type, wherein the first and second data types are different, and wherein the third classification neural network and the best candidate neural network are different.
</claims>
</document>
