<document>

<filing_date>
2020-05-22
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-06
</priority_date>

<ipc_classes>
G11C11/419,H01L27/11
</ipc_classes>

<assignee>
STMICROELECTRONICS
</assignee>

<inventors>
CHAWLA, NITIN
GROVER, ANUJ
ROY, TANMOY
</inventors>

<docdb_family_id>
73650773
</docdb_family_id>

<title>
IN-MEMORY COMPUTE ARRAY WITH INTEGRATED BIAS ELEMENTS
</title>

<abstract>
An in-memory compute (IMC) device includes a compute array having a first plurality of cells. The compute array is arranged as a plurality of rows of cells intersecting a plurality of columns of cells. Each cell of the first plurality of cells is identifiable by its corresponding row and column. The IMC device also includes a plurality of computation engines and a plurality of bias engines. Each computation engine is respectively formed in a different one of a second plurality of cells, wherein the second plurality of cells is formed from cells of the first plurality. Each computation engine is formed at a respective row and column intersection. Each bias engine of the plurality of bias engines is arranged to computationally combine an output from at least one of the plurality of computation engines with a respective bias value.
</abstract>

<claims>
1. An in-memory compute (IMC) device, comprising: a compute array having a first plurality of cells, the compute array arranged as a plurality of rows of cells intersecting a plurality of columns of cells, each cell of the first plurality of cells identifiable by its corresponding row and column; a plurality of computation engines, each computation engine respectively formed in a different one of a second plurality of cells, the second plurality of cells being formed from cells of the first plurality of cells, each computation engine formed at a respective row and column intersection; and a plurality of bias engines, each bias engine of the plurality of bias engines arranged to computationally combine an output from at least one of the plurality of computation engines with a respective bias value.
2. The IMC device of claim 1 wherein a portion of the first plurality of cells is arranged as an array of memory bitcells.
3. The IMC device of claim 2 wherein the array of memory bitcells is formed as a static random access memory (SRAM) memory array.
4. The IMC device of claim 1 wherein at least some of the plurality of computation engines are arranged to perform at least one gating operation.
5. The IMC device of claim 1 wherein at least some of the plurality of computation engines are arranged to perform at least one mathematical operation.
6. The IMC device of claim 1 wherein the plurality of bias engines is arranged as an array.
7. The IMC device of claim 6 wherein the plurality of bias engines arranged as the array are formed in adjacent cells of the first plurality of cells.
8. The IMC device of claim 1 wherein each bias engine of the plurality of bias engines is arranged as a memory bitcell.
9. The IMC device of claim 1, comprising: consolidation circuitry coupled to each of the plurality of columns of cells, the consolidation circuitry arranged to form at least one output value generated from data in one or more of a computation engine and a bias engine.
10. The IMC device of claim 9 wherein the consolidation circuitry includes at least one sensing element.
11. An in-memory compute (IMC) method, comprising: storing a plurality of neural network kernel values or feature values in a respective plurality of memory bitcells of an in-memory compute memory device, wherein the in-memory compute memory device is organized having a first plurality of cells arranged as a plurality of rows of cells intersecting a plurality of columns of cells, each cell of the first plurality of cells identifiable by its corresponding row and column; performing a plurality of in-memory functions, wherein at least some in-memory functions of the plurality of in-memory functions take ones of the plurality of neural network kernel values or feature values as operands; storing results of the plurality of in-memory functions in a respective second plurality of cells, the second plurality of cells being formed from cells of the first plurality of cells; and computationally combining the results of the plurality of in-memory functions with a respective plurality of bias values.
12. The IMC method of claim 11 wherein a portion of the in-memory compute memory device is a static random access memory (SRAM) memory device.
13. The IMC method of claim 11 wherein the plurality of in-memory functions includes at least one gating function or at least one mathematical function.
14. The IMC method of claim 11 wherein computationally combining the results of the plurality of in-memory functions with the respective plurality of bias values includes: combining a row of results information with a row of bias values.
15. The IMC method of claim 11 wherein computationally combining the results of the plurality of in-memory functions with the respective plurality of bias values includes: producing a set of computationally combined values; and storing the set of computationally combined values in memory bitcells of the first plurality of cells without passing the set of computationally combined values out of the in-memory compute memory device.
16. The IMC method of claim 11 wherein computationally combining the results of the plurality of in-memory functions with the respective plurality of bias values includes: producing a set of computationally combined values; storing the set of computationally combined values in memory bitcells of the first plurality of cells; and passing at least some of the set of computationally combined values out of the in-memory compute memory device.
17. A system, comprising: an in-memory compute memory device having arranged therein: an array of cells, the array of cells addressable via selected ones of a plurality of rows of cells that intersect a plurality of columns of cells, wherein each cell of the array of cells is identifiable by its corresponding row and column; a plurality of computation engines formed at selected row and column intersections; and a plurality of bias engines arranged to computationally combine an output from at least one of the plurality of computation engines with a respective bias value; functional logic; and a processor coupled to the in-memory compute memory device and the functional logic, wherein the processor is arranged to perform functions of a learning machine, the functions of the learning machine including: storing a plurality of neural network kernel values or feature values in a respective first plurality of memory bitcells of the in-memory compute memory device; receiving input data from the functional logic; performing a plurality of in-memory functions using at least some of the plurality of computation engines, wherein at least some in-memory functions of the plurality of in-memory functions take ones of the plurality of neural network kernel values or feature values as first operand data and at least some of the input data as second operand data; storing results of the plurality of in-memory functions in a respective second plurality of memory bitcells of the in-memory compute memory device; and computationally combining the results of the plurality of in-memory functions with a respective plurality of bias values.
18. The system of claim 17 wherein the in-memory compute memory device, the functional logic, and the processor are arranged as an Internet of Things (loT) device, an industrial device, or a vehicle-based device.
19. The system of claim 17 wherein the functions of the learning machine include: a first level of learning machine functions that produce a first result; and a second level of learning machine functions that produce a second result, wherein the first level of learning machine functions are performed first, and wherein the second level of learning machine functions are selectively performed based on the first result.
20. The system of claim 19 wherein the first level of learning machine functions operate at a first power level, and the second level of learning machine functions operate at a second power level that is different from the first power level.
21. The system of claim 17 wherein the input data from the functional logic is received as streaming data from the functional logic.
</claims>
</document>
