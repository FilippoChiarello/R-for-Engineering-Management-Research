<document>

<filing_date>
2020-01-23
</filing_date>

<publication_date>
2020-08-06
</publication_date>

<priority_date>
2019-01-31
</priority_date>

<ipc_classes>
A61B5/11,G06K9/00
</ipc_classes>

<assignee>
KONICA MINOLTA CORPORATION
</assignee>

<inventors>
IKEDA NAOKI
</inventors>

<docdb_family_id>
69187645
</docdb_family_id>

<title>
POSTURE ESTIMATION DEVICE, BEHAVIOR ESTIMATION DEVICE, STORAGE MEDIUM STORING POSTURE ESTIMATION PROGRAM, AND POSTURE ESTIMATION METHOD
</title>

<abstract>
A posture estimation device includes: a processor that: obtains detected information indicating a feature of a subject, wherein the feature is detected based on an image that is captured by an imager from a position where the subject is viewed from above, calculates a feature amount based on the obtained detected information, updates, based on a geometric relationship between the imager and the subject, a model parameter for estimating a posture of the subject by machine learning using the calculated feature amount in a time series, and estimates the posture of the subject using the updated model parameter.
</abstract>

<claims>
1. A posture estimation device comprising: a processor that: obtains detected information indicating a feature of a subject, wherein the feature is detected based on an image that is captured by an imager from a position where the subject is viewed from above; calculates a feature amount based on the obtained detected information; updates, based on a geometric relationship between the imager and the subject, a model parameter for estimating a posture of the subject by machine learning using the calculated feature amount in a time series; and estimates the posture of the subject using the updated model parameter.
2. The posture estimation device according to claim 1, wherein the processor further: estimates the posture of the subject using a hidden Markov model, and updates the model parameter for calculating an output probability of the hidden Markov model based on the geometric relationship between the imager and the subject.
3. The posture estimation device according to claim 1, wherein the processor further calculates an index corresponding to the geometric relationship between the imager and the subject, the geometric relationship is at least one of a position, orientation, and a posture of the subject with respect to the imager, and the processor further updates the model parameter for estimating the posture of the subject based on the calculated index.
4. The posture estimation device according to claim 1, wherein the detected information is at least one of a human rectangle, a head rectangle, and a joint point detected from the image.
5. A behavior estimation device comprising: the posture estimation device according to claim 1, wherein the processor further estimates behavior of the subject based on the estimated posture.
6. A non-transitory computer-readable storage medium storing a posture estimation program that causes a computer to: obtain detected information indicating a feature of a subject, wherein the feature is detected based on an image that is captured by an imager from a position where the subject is viewed from above; calculate a feature amount based on the obtained detected information; update, based on a geometric relationship between the imager and the subject, a model parameter for estimating a posture of the subject by machine learning using the calculated feature amount in a time series; and estimate the posture of the subject using the updated model parameter.
7. The non-transitory recording medium according to claim 6, wherein the program further causes the computer to: estimate the posture of the subject using a hidden Markov model, and update the model parameter for calculating an output probability of the hidden Markov model based on the geometric relationship between the imager and the subject.
8. The non-transitory recording medium according to claim 6, wherein the geometric relationship is at least one of a position, orientation, and a posture of the subject with respect to the imager, and the program further causes the computer to: calculate an index corresponding to the geometric relationship between the imager and the subject, and update the model parameter for estimating the posture of the subject based on the calculated index.
9. The non-transitory recording medium according to claim 6, wherein the detected information is at least one of a human rectangle, a head rectangle, and a joint point detected from the image.
10. A posture estimation method that causes a computer to execute a posture estimation program, the method comprising: obtaining detected information indicating a feature of a subject, wherein the feature is detected based on an image that is captured by an imager from a position where the subject is viewed from above; calculating a feature amount based on the obtained detected information; updating, based on a geometric relationship between the imager and the subject, a model parameter for estimating a posture of the subject by machine learning using the calculated feature amount in a time series; and estimating the posture of the subject using the updated model parameter.
11. The posture estimation method according to claim 10, further comprising: estimating the posture of the subject using a hidden Markov model, and updating the model parameter for calculating an output probability of the hidden Markov model based on the geometric relationship between the imager and the subject.
12. The posture estimation method according to claim 10, wherein the geometric relationship is at least one of a position, orientation, and a posture of the subject with respect to the imager, and the method further comprising: calculating an index corresponding to the geometric relationship between the imager and the subject, and updating the model parameter for estimating the posture of the subject based on the calculated index.
13. The posture estimation method according to claim 10, wherein the detected information is at least one of a human rectangle, a head rectangle, and a joint point detected from the image.
</claims>
</document>
