<document>

<filing_date>
2018-07-10
</filing_date>

<publication_date>
2021-01-12
</publication_date>

<priority_date>
2018-07-10
</priority_date>

<ipc_classes>
A01B79/00,G01N21/00,G06F3/0481,G06K9/00,G06K9/03,G06K9/34,G06K9/62,G06Q50/02,G06T17/05,G06T7/00,G06T7/90
</ipc_classes>

<assignee>
ADROIT ROBOTICS
</assignee>

<inventors>
AQUINO, JR., PLINIO THOMAZ
CORTEZ, JR., MILTON PEREZ
GURZONI, JR., JOSE ANGELO
</inventors>

<docdb_family_id>
66867588
</docdb_family_id>

<title>
Systems, devices, and methods for in-field diagnosis of growth stage and crop yield estimation in a plant area
</title>

<abstract>
Methods, devices, and systems may be utilized for detecting one or more properties of a plant area and generating a map of the plant area indicating at least one property of the plant area. The system comprises an inspection system associated with a transport device, the inspection system including one or more sensors configured to generate data for a plant area including to: capture at least 3D image data and 2D image data; and generate geolocational data. The datacenter is configured to: receive the 3D image data, 2D image data, and geolocational data from the inspection system; correlate the 3D image data, 2D image data, and geolocational data; and analyze the data for the plant area. A dashboard is configured to display a map with icons corresponding to the proper geolocation and image data with the analysis.
</abstract>

<claims>
1. A crop yield estimation system for detecting one or more properties of a plant area, the crop yield estimate system comprising: an inspection system mountable to a transport device, the inspection system comprising: a global positioning system; at least two stereoscopic cameras for capturing image data from at least two focal points; a communication system; at least one processor; and at least one non-transitory computer-readable storage medium storing instructions thereon that, when executed by the at least one processor, cause the inspection system to: capture at least three-dimensional (3D) image data and two-dimensional (2D) image data of the plant area via the at least two stereoscopic cameras; receive geolocational data via the global positioning system; pre-process the captured at least three-dimensional (3D) image data and the two-dimensional (2D) image data of the plant area at the inspection system to determine color, brightness, and resolution of the at least three-dimensional (3D) image data and the two-dimensional (2D) image data of the plant area; associate, at the inspection system, the at least three-dimensional (3D) image data and the two-dimensional (2D) image data with the received geolocational data; and generate pre-processed data including the at least three-dimensional (3D) image data and the two-dimensional (2D) image data and the associated geolocational data; a datacenter remote from the inspection system, the datacenter configured to: receive the pre-processed data from the inspection system; analyze the pre-processed data via one or more machine learning techniques to identify the one or more properties of the plant area and locations of the one or more properties; responsive to the identified one or more properties, generate one or more automated recommendations for dosing of fertilizers and pesticides in one or more areas of the plant area; and generate a map with icons indicating the one or more properties and the locations of the one or more properties; and a dashboard configured to display the map and the generated one or more automated recommendations.
2. The crop yield estimation system of claim 1, wherein the inspection system further comprises at least one of an environment sensor unit, an inertial movement unit, or a radio unit.
3. The crop yield estimation system of claim 2, wherein the environmental sensor unit comprises at least one of an actinometer, an altimeter, an anemometer, a barometer, a disdrometer, a hygrometer, a pyrheliometer, a psychrometer, a pyranometer, a rain gauge, a thermometer, and a solar irradiance sensor.
4. The crop yield estimation system of claim 1, wherein pre-processing the captured data further comprises, responsive to the determined color, brightness, and resolution of the at least three-dimensional (3D) image data and the two-dimensional (2D) image data of the plant area: correcting color of the captured at least three-dimensional (3D) image data and the two-dimensional (2D) image data; correcting brightness of the captured at least three-dimensional (3D) image data and the two-dimensional (2D) image data; and adjusting resolution of the captured at least three-dimensional (3D) image data and the two-dimensional (2D) image data.
5. The crop yield estimation system of claim 4, wherein pre-processing the captured data further comprises responsive to determining that the one or more of the color, the brightness, or the resolution of the at least three-dimensional (3D) image data and the two-dimensional (2D) image data is below a threshold requirement, recapturing the at least three-dimensional (3D) image data and the two-dimensional (2D) image data until the one or more of the color, the brightness, or the resolution of the at least three-dimensional (3D) image data and the two-dimensional (2D) image data meets the threshold requirement.
6. The crop yield estimation system of claim 1, wherein the transport device is selected from the group consisting of a tractor, farm machinery, a vehicle, an all-terrain vehicle (ATV), a four-wheeler, a three-wheeler, an air-craft, a drone, and a robot.
7. The crop yield estimation system of claim 1, wherein the datacenter is further configured to determine and generate output data based at least partially on the pre-processed data, wherein the output data comprises at least one of growth stage, estimated crop yield, estimated crop forecast, estimated plant health, disease estimate, nutrient deficiency estimate, fruit quantity, flower quantity, fruit size, fruit diameter, tree or vine height, trunk or stem diameter, trunk or stem circumference, tree or vine volume, canopy volume, color, leaf color, leaf density, plant abnormalities, historical data, biological data, and agricultural engineering data.
8. A crop yield estimation system for generating a map of a plant area indicating at least one property of the plant area, the system comprising: an inspection system comprising: a global positioning system; at least two stereoscopic cameras for capturing image data from at least two focal points; a communication system; at least one processor; and at least one non-transitory computer-readable storage medium storing instructions thereon that, when executed by the at least one processor, cause the inspection system to: capture at least three-dimensional (3D) image data and two-dimensional (2D) image data of the plant area via the at least two stereoscopic cameras; receive geolocational data via the global positioning system; pre-process the captured at least three-dimensional (3D) image data and the two-dimensional (2D) image data of the plant area at the inspection system to determine color, brightness, and resolution of the at least three-dimensional (3D) image data and the two-dimensional (2D) image data of the plant area; associate, at the inspection system, the at least three-dimensional (3D) image data and the two-dimensional (2D) image data with the received geolocational data; and generate pre-processed data including the at least three-dimensional (3D) image data and the two-dimensional (2D) image data and the associated geolocational data; a datacenter remote from the inspection system, the datacenter and in communication with the inspection system via the communication system, wherein the datacenter is configured to: receive the pre-processed data from the inspection system; analyze the pre-processed data via one or more machine learning techniques to identify the at least one property of the plant area and locations of the identified at least one property; responsive to the identified at least one property, generate one or more automated recommendations for dosing of fertilizers and pesticides in one or more areas of the plant area; generate a map of the plant area using the identified at least one property of the plant area and a location of the identified at least one property, wherein the map includes at least one icon indicating the identified the at least one property, wherein a position of the at least one icon within the map correlates to the location of the at least one identified property; and a dashboard configured to display the map and the generated one or more automated recommendations.
9. The crop yield estimation system of claim 8, wherein the inspection system further comprises at least one of a high-definition infrared camera, an inertial movement unit, or a radio unit.
10. The crop yield estimation system of claim 9, wherein the inspection system further comprises: at least one of a high-definition infrared camera; and instructions that, when executed by the at least one processor, cause the inspection system to: capture high-definition infrared image data via the high-definition infrared camera; and capture inertial movement data via the inertial movement unit.
11. The crop yield estimation system of claim 10, wherein the datacenter comprises: a data processing system comprising a communications framework, a processor unit, memory, persistent storage, a communications unit, an input/output unit, knowledge base data sources, and a software stack; wherein the datacenter is configured to: reconstruct three-dimensional (3D) point cloud data using the at least three-dimensional (3D) image data and two-dimensional (2D) image data captured via the at least two stereoscopic cameras; segment the at least three-dimensional (3D) image data and two-dimensional (2D) image data to generate segmented image data; use the segmented image data, the reconstructed three-dimensional (3D) point cloud data, and the knowledge base data sources to identify the properties of the plant area; combine the segmented image data and the reconstructed three-dimensional (3D) point cloud data to generate a three-dimensional (3D) model of each plant of the plant area; and combine the three-dimensional (3D) model of each plant and the identified properties of the plant area to generate the map of the plant area.
12. The crop yield estimation system of claim 11, wherein the knowledge base data sources comprise historical, biological, climate, and agricultural engineering data concerning the plant area.
13. A method for generating a map of a plant area indicating one or more properties of one or more plants in the plant area, the method comprising: moving an inspection system across the plant area; capturing at least three-dimensional (3D) image data and two-dimensional (2D) image data of the plant area via at least two stereoscopic cameras; receiving geolocational data from a global positioning system; pre-processing the captured at least three-dimensional (3D) image data and the two-dimensional (2D) image data of the plant area at the inspection system to determine color, brightness, and resolution of the captured at least three-dimensional (3D) image data and the two-dimensional (2D) image data of the plant area; associating, at the inspection system, the at least three-dimensional (3D) image data and the two-dimensional (2D) image data with the received geolocational data; generating pre-processed data including the at least three-dimensional (3D) image data and the two-dimensional (2D) image data and the associated geolocational data; transmitting, from the inspection system and to a datacenter remote from the inspection system, the pre-processed data; analyzing, with the datacenter, the pre-processed data via one or more machine learning techniques to identify the one or more properties of the plant area and locations of the one or more properties; responsive to the identified one or more properties, generating one or more automated recommendations for dosing of fertilizers and pesticides in one or more areas of the plant area; generating, with the datacenter, a three-dimensional map using the at least three-dimensional (3D) image data and the two-dimensional (2D) image data, the identified one or more properties, and locations of the identified one or more properties in which indications of the identified one or more properties are visible in the map in positions correlating to the locations of the identified one or more properties in the plant area; and displaying the map on dashboard viewable by a user and the generated one or more automated recommendations.
14. The method of claim 13, wherein analyzing, with the datacenter, the pre-processed data comprises: reconstructing three-dimensional (3D) point cloud data using the captured at least three-dimensional (3D) image data and the two-dimensional (2D) image data; segmenting the at least three-dimensional (3D) image data and the two-dimensional (2D) image data to generate segmented image data; and identifying properties of the plant area based at least partially on each of the segmented image data, the three-dimensional 3D point cloud data, and knowledge base data sources.
15. The method of claim 13, wherein generating the map of the plant area comprises: combining the segmented image data and the three-dimensional (3D) point cloud data; generating a three-dimensional (3D) model of each plant of the plant area based at least partially on the combined segmented image data and three-dimensional (3D) point cloud data; and combining the geolocational data, the three-dimensional (3D) model of each plant, the identified one or more properties, and the locations of the identified one or more properties to generate the map of the plant area.
16. The method of claim 13, wherein the map is interactive, and wherein the identified one or more properties are selectable within the map to view additional data associated with a selected identified property.
17. The method of claim 13, further comprising: based at least partially on the identified one or more properties, predicting a ripening date of fruit of plants within the plant area; and generating the one or more automated recommendations for dosing of fertilizers and pesticides to adjust a ripening date of the fruit plants within the plant area.
18. The method of claim 13, further comprising segmenting the pre-processed data to identify which parts of the pre-processed data correspond to fruits, tree canopy, and flowers.
19. The method of claim 18, further comprising determining which identified fruits are free from occlusion by other objects.
20. The method of claim 13, further comprising receiving a map of the plant area from the datacenter and moving the inspection system across the plant area according to a route of the map.
</claims>
</document>
