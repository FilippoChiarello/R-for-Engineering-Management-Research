<document>

<filing_date>
2019-08-14
</filing_date>

<publication_date>
2020-02-20
</publication_date>

<priority_date>
2018-08-17
</priority_date>

<ipc_classes>
A61B8/08,G06F17/18,G06K9/62,G06N3/08,G06N5/04,G06T7/00,G06T7/70,G16H50/20
</ipc_classes>

<assignee>
INVENTIVE GOVERNMENT SOLUTIONS
</assignee>

<inventors>
MEHANIAN, COUROSH
WILSON, BENJAMIN K.
ZHENG, XINLIANG
KULHARE, SOURABH
</inventors>

<docdb_family_id>
69524194
</docdb_family_id>

<title>
AUTOMATED ULTRASOUND VIDEO INTERPRETATION OF A BODY PART, SUCH AS A LUNG, WITH ONE OR MORE CONVOLUTIONAL NEURAL NETWORKS SUCH AS A SINGLE-SHOT-DETECTOR CONVOLUTIONAL NEURAL NETWORK
</title>

<abstract>
In an embodiment, an intelligent system includes an electronic circuit configured to execute a neural network, to detect at least one feature in an image of a body portion while executing the neural network, and to determine a respective position and a respective class of each of the detected at least one feature while executing the neural network. For example, such a system can execute a neural network to detect at least one feature in an image of a lung, to determine a respective position within the image of each detected feature, and to classify each of the detected features as one of the following: A-line, B-line, pleural line, consolidation, and pleural effusion.
</abstract>

<claims>
1. A method, comprising: receiving an image of a body portion; detecting, with a neural network, at least one feature in the image; and determining, with the neural network, a respective position and a respective class of each of the detected at least one feature.
2. The method of claim 1 wherein the image of the body portion includes an image of a lung.
3. 3.-4. (canceled)
5. The method of claim 1 wherein determining a respective position of each of the detected at least one feature includes determining a respective container that bounds the detected feature.
6. The method of claim 1 wherein determining a respective position of each of the detected at least one feature includes determining a respective bounding box in which the feature is disposed.
7. The method of claim 1 wherein determining a respective position of each of the detected at least one feature includes determining a coordinate of a respective bounding box in which the feature is disposed.
8. The method of claim 1 wherein determining a respective position of each of the detected at least one feature includes determining a size of a respective bounding box in which the feature is disposed.
9. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining a respective probability that the feature belongs to the respective class.
10. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining a respective confidence level that the feature belongs to the respective class.
11. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes: determining a respective probability that the feature belongs to the respective class; and determining that the feature belongs to the respective class in response to the respective probability being greater than a threshold for the respective class.
12. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes: determining probabilities that the detected at least one feature belongs to respective classes; and determining that the feature belongs to the one of the respective classes corresponding to the highest one of the probabilities.
13. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes an A-line.
14. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural line.
15. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural effusion.
16. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a B-line.
17. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes merged B-lines.
18. The method of claim 1, further comprising: detecting, with the neural network, at least one respective feature in each of multiple ones of the image and at least one other image of the body portion; determining, with the neural network, that each of the detected at least one respective feature is a respective detected B-line, and a respective position of each of the detected B-lines; grouping the detected B-lines in at least one cluster in response to the respective positions of the detected B-lines, each cluster corresponding to a respective actual B-line; and determining, with the neural network, a respective position of each actual B-line in response to a corresponding one of the at least one cluster.
19. The method of claim 1, further comprising: detecting, with the neural network, at least one respective feature in each of multiple ones of the image and at least one other image of the body portion; determining, with the neural network, that each of the detected at least one respective feature belongs to a same class, and a respective position of each of the detected at least one of the respective feature; grouping the detected features in at least one cluster in response to the respective positions of the detected features, each cluster corresponding to a respective actual feature; and determining, with the neural network, a respective position of each actual feature in response to a corresponding one of the at least one cluster.
20. The method of claim 1 wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a consolidation.
21. The method of claim 1, further comprising: wherein determining a respective class of each of the detected at least one feature includes determining that at least one of the detected at least one feature includes a pleural effusion; and determining a severity of the pleural effusion.
22. The method of claim 1, further comprising: wherein the image of the body portion includes an image of a lung; and diagnosing a pathology of the lung in response to the respective determined class of each of the detected at least one feature.
23. The method of claim 1, further comprising: wherein the image of the body portion includes an image of a lung; and diagnosing a pathology of the lung in response to the respective position and to the respective determined class of each of the detected at least one feature.
24. 24.-64. (canceled)
65. A system, comprising: an electronic circuit configured to execute a neural network; to detect at least one feature in an image of a body portion while executing the neural network; and to determine a respective position and a respective class of each of the detected at least one feature while executing the neural network.
66. The system of claim 65 wherein the neural network includes a convolutional neural network.
67. The system of claim 65 wherein the neural network includes a single-shot-detector convolutional neural network.
68. The system of claim 65, further comprising an ultrasound transducer coupled to the electronic circuit and configured to acquire the image.
69. The system of claim 65 wherein the electronic circuit, while executing the neural network, is configured to detect at least one feature in an ultrasound image of a lung.
70. 70.-87. (canceled)
88. The system of claim 65 wherein the electronic circuit includes a control circuit.
89. 89.-93. (canceled)
94. The system of claim 65 wherein the image includes an M-mode image.
95. (canceled)
96. The system of claim 65 wherein the body portion includes a lung and the function is lung sliding.
97. 97.-145. (canceled)
146. A tangible, non-transitory computer-readable medium storing instructions that, when executed by a computing circuit, cause the computing circuit, or another circuit under control of the computing circuit, to execute a neural network: to detect at least one feature in an image of a body portion; and to determine a respective position and a respective class of each of the detected at least one feature.
147. 147.-150. (canceled)
</claims>
</document>
