<document>

<filing_date>
2020-03-05
</filing_date>

<publication_date>
2020-09-10
</publication_date>

<priority_date>
2019-03-07
</priority_date>

<ipc_classes>
G06F40/20,G06N20/00,G10L15/06,G10L15/183
</ipc_classes>

<assignee>
VERINT AMERICAS
</assignee>

<inventors>
FREEMAN, CYNTHIA
</inventors>

<docdb_family_id>
69779905
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR DETERMINING REASONS FOR ANOMALIES USING CROSS ENTROPY RANKING OF TEXTUAL ITEMS
</title>

<abstract>
A framework for reducing the number of textual items reviewed to determine the source of or reason for an anomaly in a time series that is used to track metrics in textual data is provided. According the framework, textual items in a time window corresponding to the anomaly are ranked according to the cross-entropy as determined by applying a language model to the relevant textual items and ranking textual items that most likely triggered an anomaly in time series data based on the cross-entropy value. In an aspect, a predetermined number of textual items having the highest cross-entropy are provided or all textual items having cross-entropy value higher than predetermine threshold are provided.
</abstract>

<claims>
1. A method that includes one or more processing devices performing operations comprising: detecting an anomaly in a time series that is used to track metrices in textual data; identifying a time step ai(t) associated with the detected anomaly; collecting relevant textual data from a time window twindow associated with the detected anomaly; training a language model on the relevant textual data; for every textual item at time step ai(t), calculating a cross-entropy value according to the language model; and generating a set of textual items having a cross-entropy value greater that a predetermined value.
2. The method of claim 1, wherein the time window twindow is just before time step ai(t).
3. The method of claim 1, wherein the set of textual items is produced in rank order from greatest cross-entropy value to least cross-entropy value.
4. The method of claim 1, wherein the set of textual items contains a predetermined number of textual items having the greatest cross-entropy values.
5. The method of claim 1, wherein the cross-entropy value is indicative of how surprising a textual item is as compared with an immediate previous linguistic state according to the language model.
6. The method of claim 1, wherein the language model is snapshot language model.
7. The method of claim 1, further comprising identifying at least one of the textual items as most likely triggering the anomaly in the time series.
8. A system comprising: a processing device; and a memory device in which instructions executable by the processing device are stored for causing the processor to: detect an anomaly in a time series that is used to track metrices in textual data; identify a time step ai(t) associated with the detected anomaly; collect relevant textual data from a time window twindow associated with the detected anomaly; train a language model on the relevant textual data; for every textual item at time step ai(t), calculate a cross-entropy value according to the language model; and generate a set of textual items having a cross-entropy value greater that a predetermined value.
9. The system of claim 8, wherein the time window twindow is just before time step ai(t).
10. The system of claim 8, wherein the set of textual items is produced in rank order from greatest cross-entropy value to least cross-entropy value.
11. The system of claim 8, wherein the set of textual items contains a predetermined number of textual items having the greatest cross-entropy values.
12. The system of claim 8, wherein the cross-entropy value is indicative of how surprising a textual item is as compared with an immediate previous linguistic state according to the language model.
13. The system of claim 8, wherein the language model is snapshot language model.
14. The system of claim 8, further comprising the memory device storing instructions executable by the processing device for causing the processor to identify at least one of the textual items as most likely triggering the anomaly in the time series.
15. A non-transitory computer-readable storage medium having program code that is executable by a processor to cause a computing device to perform operations, the operations comprising: detecting an anomaly in a time series that is used to track metrices in textual data; identifying a time step ai(t) associated with the detected anomaly; collecting relevant textual data from a time window twindow associated with the detected anomaly; training a language model on the relevant textual data; for every textual item at time step ai(t), calculating a cross-entropy value according to the language model; and generating a set of textual items having a cross-entropy value greater that a predetermined value.
16. The non-transitory computer-readable storage medium of claim 15, wherein the time window twindow is just before time step ai(t).
17. The non-transitory computer-readable storage medium of claim 15, wherein the set of textual items is produced in rank order from greatest cross-entropy value to least cross-entropy value.
18. The non-transitory computer-readable storage medium of claim 15, wherein the set of textual items contains a predetermined number of textual items having the greatest cross-entropy values.
19. The non-transitory computer-readable storage medium of claim 15, wherein the cross-entropy value is indicative of how surprising a textual item is as compared with an immediate previous linguistic state according to the language model.
20. The non-transitory computer-readable storage medium of claim 15, wherein the language model is snapshot language model.
21. The non-transitory computer-readable storage medium of claim 15, the operations further comprising identifying at least one of the textual items as most likely triggering the anomaly in the time series.
</claims>
</document>
