<document>

<filing_date>
2019-03-26
</filing_date>

<publication_date>
2020-09-30
</publication_date>

<priority_date>
2019-03-26
</priority_date>

<ipc_classes>
G06F17/16,G06N20/00,G06N7/00
</ipc_classes>

<assignee>
ROBERT BOSCH
</assignee>

<inventors>
Kandemir, Melih
Rakitsch, Barbara
Xu, Buote
Reeb, David
</inventors>

<docdb_family_id>
65991579
</docdb_family_id>

<title>
LEARNING PARAMETERS OF A PROBABILISTIC MODEL COMPRISING GAUSSIAN PROCESSES
</title>

<abstract>
A system (100) is disclosed for learning a set of parameters of a probabilistic model with a layer of multiple Gaussian processes, e.g., a deep GP, from a training dataset. The set of parameters comprises at least inducing locations for the multiple Gaussian processes, and parameters of a probability distribution approximating outputs of the multiple Gaussian processes at the multiple inducing locations. The probability distribution comprises a multivariate normal probability distribution with a covariance matrix defined by a Kronecker product of a first matrix indicating a similarity between the multiple Gaussian processes and a second matrix indicating a similarity between the multiple inducing locations. A system (200) is further disclosed that uses the set of parameters to determine one or more samples of an output of the probabilistic model for a given input, e.g., to determine a mean and/or an uncertainty estimate for the probabilistic model.
</abstract>

<claims>
1. A system (100) for learning a set of parameters of a probabilistic model, the probabilistic model comprising one or more layers, a layer of the one or more layers comprising multiple Gaussian processes, the system comprising: - a data interface (120) for accessing a training dataset (030) comprising multiple training inputs and corresponding training outputs; - a processor subsystem (140) arranged to determine the set of parameters (050) of the probabilistic model by optimizing the set of parameters with respect to the training dataset, wherein the set of parameters comprises at least: - a set of multiple inducing locations for the multiple Gaussian processes; - parameters of a probability distribution approximating outputs of the multiple Gaussian processes at the multiple inducing locations, wherein the probability distribution comprises a multivariate normal probability distribution, a covariance matrix of the multivariate normal distribution being defined by a Kronecker product of a first matrix indicating a similarity between the multiple Gaussian processes and a second matrix indicating a similarity between the multiple inducing locations.
2. System (100) as in claim 1, wherein optimizing the set of parameters comprises maximizing an evidence lower bound with respect to the training dataset.
3. System (100) as in claim 1 or 2, wherein optimizing the set of parameters comprises sampling an output of the probabilistic model given a training input and computing a likelihood of obtaining the training output corresponding to the training input from the sampled output under a noise distribution.
4. System (100) as in claim 3, wherein sampling the output of the probabilistic model for the training input comprises: - determining a sample probability distribution of outputs of the multiple Gaussian processes for the training input by marginalizing out the probability distribution approximating the outputs of the multiple Gaussian processes at the multiple inducing locations from a joint probability distribution; - sampling outputs of the multiple Gaussian processes for the training input according to the sample probability distribution.
5. System (100) as in any one of claims 2 to 4, wherein maximizing the evidence lower bound comprises performing stochastic gradient descent on an objective function comprising the evidence lower bound.
6. System (100) as in any one of claims 1 to 5, wherein determining the set of parameters comprises optimizing a Kullback-Leibler divergence between the probability distribution approximating the outputs of the multiple Gaussian processes at the multiple inducing locations and a prior probability distribution of the outputs of the multiple Gaussian processes at the multiple inducing locations.
7. System (100) as in any one of claims 1 to 6, wherein the first matrix is a diagonal matrix.
8. System (100) as in any one of claims 1 to 7, wherein a Gaussian process of the multiple Gaussian processes has a squared exponential kernel.
9. System (100) as in any one of claims 1 to 8, wherein the set of parameters of the probabilistic model comprises one or more kernel hyperparameters, each Gaussian process of the multiple Gaussian processes having a kernel defined by the one or more kernel hyperparameters.
10. System (200) for applying a probabilistic model to an input, the probabilistic model comprising one or more layers, a layer of the one or more layers comprising multiple Gaussian processes, the system comprising: - a data interface (220) for accessing the input (060) and a set of parameters (050) of the probabilistic model, wherein the set of parameters comprises at least: - a set of multiple inducing locations for the multiple Gaussian processes; - parameters of a probability distribution approximating outputs of the multiple Gaussian processes at the multiple inducing locations, wherein the probability distribution comprises a multivariate normal probability distribution, a covariance matrix of the multivariate normal distribution being defined by a Kronecker product of a first matrix indicating a similarity between the multiple Gaussian processes and a second matrix indicating a similarity between the inducing locations. - a processor subsystem (240) arranged to determine a sample of an output of the probabilistic model on the input (060) based on the set of parameters (050) of the probabilistic model.
11. System (200) as in claim 10, wherein the processor is configured to determine multiple samples of the output of the probabilistic model on the input and determine an uncertainty estimate therefrom.
12. Method (500) of learning a set of parameters of a probabilistic model, the probabilistic model comprising one or more layers, a layer of the one or more layers comprising multiple Gaussian processes, the method comprising: - accessing (510) a training dataset comprising multiple training inputs and corresponding training outputs; - determining the set of parameters of the probabilistic model by optimizing (520) the set of parameters with respect to the training dataset, wherein the set of parameters comprises at least: - a set of multiple inducing locations for the multiple Gaussian processes; - parameters of a probability distribution approximating outputs of the multiple Gaussian processes at the multiple inducing locations, wherein the probability distribution comprises a multivariate normal probability distribution, a covariance matrix of the multivariate normal distribution being defined by a Kronecker product of a first matrix indicating a similarity between the multiple Gaussian processes and a second matrix indicating a similarity between the multiple inducing locations.
13. Method (600) of applying a probabilistic model to an input, the probabilistic model comprising one or more layers, a layer of the one or more layers comprising multiple Gaussian processes, the method comprising: - accessing (610) the input and a set of parameters of the probabilistic model, wherein the set of parameters comprises at least: - a set of multiple inducing locations for the multiple Gaussian processes; - parameters of a probability distribution approximating outputs of the multiple Gaussian processes at the multiple inducing locations, wherein the probability distribution comprises a multivariate normal probability distribution, a covariance matrix of the multivariate normal distribution being defined by a Kronecker product of a first matrix indicating a similarity between the multiple Gaussian processes and a second matrix indicating a similarity between the inducing locations. - determining (620) a sample of an output of the probabilistic model on the input based on the set of parameters of the probabilistic model.
14. A computer-readable medium (700) comprising transitory or non-transitory data (710) representing instructions arranged to cause a processor system to perform the computer-implemented method according to claim 12 or 13.
15. A computer-readable medium (700) comprising transitory or non-transitory data (710) representing a set of parameters of a probabilistic model, the probabilistic model comprising one or more layers, a layer of the one or more layers comprising multiple Gaussian processes, the set of parameters comprising at least: - a set of multiple inducing locations for the multiple Gaussian processes; - parameters of a probability distribution approximating outputs of the multiple Gaussian processes at the multiple inducing locations, wherein the probability distribution comprises a multivariate normal probability distribution, a covariance matrix of the multivariate normal distribution being defined by a Kronecker product of a first matrix indicating a similarity between the multiple Gaussian processes and a second matrix indicating a similarity between the inducing locations.
</claims>
</document>
