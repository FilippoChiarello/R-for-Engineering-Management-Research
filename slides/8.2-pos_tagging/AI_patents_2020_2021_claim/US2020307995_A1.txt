<document>

<filing_date>
2019-03-26
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-26
</priority_date>

<ipc_classes>
B82Y10/00,G06N3/06,G11C13/02
</ipc_classes>

<assignee>
VATHYS
</assignee>

<inventors>
GHOSH, TAPABRATA
</inventors>

<docdb_family_id>
72603950
</docdb_family_id>

<title>
Machine Learning Processor Employing a Monolithically Integrated Memory System
</title>

<abstract>
Disclosed are systems and methods for monolithically-integrating an artificial intelligence processor system and a nanotube memory system on the same die to achieve high memory density and low power consumption.
</abstract>

<claims>
1. A machine learning processor system comprising: one or more processor circuits optimized for handling machine learning operations; and a nanotube memory system configured to receive read and write operations of the one or more processor circuits.
2. The system of claim 1, wherein the processor circuits and the nanotube memory system are monolithically integrated on a same die.
3. The system of claim 1, wherein the nanotube memory system comprises CNT fabric-based resistance switching.
4. The system of claim 1, wherein the nanotube memory system comprises a cross-bar architecture or a 1 transistor-1 resistor (1T1R) architecture.
5. The system of claim 1, wherein the one or more processor circuits and the nanotube memory system are side-by-side on a substrate, or vertically stacked on a substrate, or a combination of side-by-side and vertically stacked relative to one another and relative to themselves.
6. The system of claim 1, wherein the nanotube memory system comprises homogenous memory cells made of carbon nanotubes.
7. The system of claim 1, wherein the nanotube memory system comprises heterogenous memory cells made of one or more of carbon nanotubes, gallium nitride nanotubes, and silicon nanotubes.
8. The system of claim 1, wherein one or more current sensing amplifiers are used to read from and/or write into cells of the nanotube memory system.
9. The system of claim 1, wherein the machine learning operations comprise one or more of: neural network, deep neural network, convolutional neural network (CNN), generating and/or processing activation functions, back-propagation, error minimization operations, statistical processing of data, inference using neural networks and training of neural networks.
10. A computer system comprising the machine learning processor system of claim 1.
11. A method comprising: reading, from a nanotube memory system, data associated with a plurality of machine learning operations; performing, on a plurality of machine learning processors, a plurality of machine learning operations on the data; and writing in the nanotube memory system.
12. The method of claim 11, wherein the plurality of machine learning processors and the nanotube memory system are monolithically integrated on a same die.
13. The method of claim 11, wherein the nanotube memory system comprises CNT fabric-based resistance switching.
14. The method of claim 11, wherein the nanotube memory system comprises a cross-bar architecture or a 1 transistor-1 resistor (1T1R) architecture.
15. The method of claim 11, wherein the plurality of machine learning processors and the nanotube memory system are side-by-side on a substrate, or vertically stacked on a substrate, or a combination of side-by-side and vertically stacked relative to one another and relative to themselves.
16. The method of claim 11, wherein the nanotube memory system comprises homogenous memory cells made of carbon nanotubes.
17. The method of claim 11, wherein the nanotube memory system comprises heterogenous memory cells made of one or more of carbon nanotubes, gallium nitride nanotubes and silicon nanotubes.
18. The method of claim 11, wherein one or more current sensing amplifiers are used to read from and/or write into cells of the nanotube memory system.
19. The method of claim 11, wherein the machine learning operations comprise one or more of: neural network, deep neural network, convolutional neural network (CNN), generating and/or processing activation functions, back-propagation, error minimization operations, statistical processing of data, inference using neural networks and training of neural networks.
20. A computer system configured to perform the method of claim 11.
</claims>
</document>
