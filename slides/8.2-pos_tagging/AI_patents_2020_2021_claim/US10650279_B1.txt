<document>

<filing_date>
2019-12-22
</filing_date>

<publication_date>
2020-05-12
</publication_date>

<priority_date>
2019-01-31
</priority_date>

<ipc_classes>
G06F17/18,G06K9/00,G06K9/32,G06K9/62,G06N3/04,G06N3/063
</ipc_classes>

<assignee>
STRADVISION
</assignee>

<inventors>
SHIN, DONGSOO
LEE, HYUNG SOO
JANG, TAEWOONG
KIM, HAK-KYOUNG
JE, HONGMO
YEO, DONGHUN
SUNG, MYUNGCHUL
KIM, KYE-HYEON
KIM, YONGJOONG
JEONG, KYUNGJOONG
RYU, WOOJU
NAM, WOONHYUN
BOO, SUKHOON
CHO, HOJIN
LEE, MYEONG-CHUN
</inventors>

<docdb_family_id>
70612711
</docdb_family_id>

<title>
Learning method and learning device for heterogeneous sensor fusion by using merging network which learns non-maximum suppression
</title>

<abstract>
A learning method for generating integrated object detection information of an integrated image by integrating first object detection information and second object detection information is provided. The method includes steps of: (a) a learning device, if the first object detection information and the second object detection information is acquired, instructing a concatenating network included in a DNN to generate pair feature vectors including information on pairs of first original ROIs and second original ROIs; (b) the learning device instructing a determining network included in the DNN to apply FC operations to the pair feature vectors, to thereby generate (i) determination vectors and (ii) box regression vectors; (c) the learning device instructing a loss unit to generate an integrated loss, and performing backpropagation processes by using the integrated loss, to thereby learn at least part of parameters included in the DNN.
</abstract>

<claims>
1. A learning method for generating integrated object detection information of at least one integrated image by integrating first object detection information and second object detection information each corresponding to a first original image and a second original image on a specific space, to be used for generating the integrated image, without extra computation on the integrated image, comprising steps of: (a) a learning device, if the first object detection information and the second object detection information are acquired by processing the first original image and the second original image, instructing a concatenating network included in a Deep Neural Network (DNN) to generate one or more pair feature vectors including information on one or more pairs of first original Region of Interests (ROIs) included in the first original image and second original ROIs in the second original image; (b) the learning device instructing a determining network included in the DNN to apply one or more Fully-Connected (FC) operations to the pair feature vectors, to thereby generate (i) one or more determination vectors including information on probabilities of the first original ROIs and the second original ROIs included in each of the pairs being appropriate to be integrated and (ii) one or more box regression vectors including information on each of relative locations of integrated ROIs, corresponding to at least part of the pairs, comparing to each of original locations of each component of said at least part of the pairs, on the integrated image; (c) the learning device instructing a loss unit to generate an integrated loss by referring to the determination vectors, the box regression vectors and their corresponding (GTs), and performing backpropagation processes by using the integrated loss, to thereby learn at least part of parameters included in the DNN.
2. The method of claim 1, wherein, at the step of (a), a specific pair feature vector, which is one of the pair feature vectors, includes (i) first class information of a first specific object included in the first original image, (ii) feature values of a first specific original ROI including the first specific object, (iii) coordinate values of a first specific original bounding box corresponding to the first specific original ROI, (iv) coordinate values of the first specific original ROI, (v) second class information of a second specific object included in the second original image, (vi) feature values of a second specific original ROI including the second specific object, (vii) coordinate values of a second specific original bounding box corresponding to the second specific original ROI, and (viii) coordinate values of the second specific original ROI.
3. The method of claim 2, wherein, at the step of (b), a specific determination vector, which is one of the determination vectors and corresponds to the specific pair feature vector, includes information on a probability of the first specific original ROI and the second specific original ROI being integrated on the integrated image, and a specific box regression vector, which is one of the box regression vectors and corresponds to the specific pair feature vector, includes information on coordinates of a specific integrated bounding box generated by merging the first specific original ROI and the second specific original ROI on the integrated image.
4. The method of claim 1, wherein, at the step of (c), the learning device instructs the loss unit (i) to generate a determination loss by using at least part of the determination vectors through a cross entropy method, (ii) to generate a box regression loss by using at least part of the box regression vectors through a smooth-L1 method, and (iii) to generate the integrated loss by referring to the determination loss and the box regression loss.
5. The method of claim 4, wherein, at the step of (c), the determination loss is generated by a formula below: wherein n denotes the number of the determination vectors, vci denotes an i-th determination vector, vC-GTi denotes an i-th determination GT vector on the i-th determination vector, and the box regression loss is generated by a formula below: wherein n denotes the number of the box regression vectors, vci denotes an i-th box regression vector, vC-GTi denotes an i-th box regression GT vector on the i-th box regression vector.
6. The method of claim 1, wherein the learning device instructs each of deep learning neurons included in one or more layers of the DNN to repeatedly apply one or more convolutional operations to its input by using its own at least one parameter and deliver its output to its next deep learning neuron, to thereby generate the pair feature vectors, the determination vectors and the box regression vectors.
7. The method of claim 1, wherein, at the step of (b), the learning device instructs the determining network included in the DNN to generate the determination vectors by applying at least part of the FC operations to the pair feature vectors, and to generate the one or more box regression vectors corresponding to one or more specific pair feature vectors, among the pair feature vectors, whose values in corresponding specific determination vectors denoting specific probabilities of specific pairs to be integrated are larger than a prescribed threshold, by applying the other part of the FC operations to the specific pair feature vectors.
8. A testing method for generating integrated object detection information for testing of at least one integrated image for testing by integrating first object detection information for testing and second object detection information for testing each corresponding to a first original image for testing and a second original image for testing on a specific space for testing, to be used for generating the integrated image for testing, without extra computation on the integrated image for testing, comprising steps of: (a) on condition that (1) a learning device, if first object detection information for training and second object detection information for training have been acquired by processing first original image for training and the second original image for training, has instructed a concatenating network included in a DNN to generate one or more pair feature vectors for training including information on one or more pairs for training of first original Region of Interests (ROIs) for training included in the first original image for training and second original ROIs for training in the second original image for training; (2) the learning device has instructed a determining network included in the Deep Neural Network (DNN) to apply one or more Fully-connected (FC) operations to the pair feature vectors for training, to thereby generate (i) one or more determination vectors for training including information on probabilities of the first original ROIs for training and the second original ROIs for training included in each of the pairs for training being appropriate to be integrated and (ii) one or more box regression vectors for training including information on each of relative locations of integrated ROIs for training, corresponding to at least part of the pairs for training, comparing to each of original locations of each component of said at least part of the pairs for training, on the integrated image for training; (3) the learning device has instructed a loss unit to generate an integrated loss by referring to the determination vectors for training, the box regression vectors for training and their corresponding (GTs), and performing backpropagation processes by using the integrated loss, to thereby learn at least part of parameters included in the DNN, a testing device, if the first object detection information for testing and the second object detection information for testing are acquired by processing the first original image for testing and the second original image for testing, instructing the concatenating network included in the DNN to generate one or more pair feature vectors for testing including information on one or more pairs for testing of first original ROIs for testing included in the first original image for testing and second original ROIs for testing in the second original image for testing; (b) the testing device instructing the determining network included in the DNN to apply one or more FC operations to the pair feature vectors for testing, to thereby generate (i) one or more determination vectors for testing including information on probabilities of the first original ROIs for testing and the second original ROIs for testing included in each of the pairs for testing being appropriate to be integrated and (ii) one or more box regression vectors for testing including information on each of relative locations of integrated ROIs for testing, corresponding to at least part of the pairs for testing, comparing to each of original locations of each component of said at least part of the pairs for testing, on the integrated image for testing; and (c) the testing device instructing a merging unit to generate the integrated object detection information for testing by merging at least part of the pairs for testing of first original bounding boxes for testing and second original bounding boxes for testing by referring to the determination vectors for testing and the box regression vectors for testing.
9. The method of claim 8, wherein the first object detection information for testing and the second object detection information for testing are acquired from the first original image for testing and the second original image for testing, each acquired through a first camera for a first direction and a second camera for a second direction installed on a vehicle including the test device.
10. The method of claim 8, wherein, at the step of (a), a specific pair feature vector for testing, which is one of the pair feature vectors for testing, includes (i) first class information for testing of a first specific object for testing included in the first original image for testing, (ii) feature values for testing of a first specific original ROI for testing including the first specific object for testing, (iii) coordinate values of a first specific original bounding box for testing corresponding to the first specific original ROI for testing, (iv) coordinate values of the first specific original ROI for testing, (v) second class information for testing of a second specific object for testing included in the second original image for testing, (vi) feature values for testing of a second specific original ROI for testing including the second specific object for testing, (vii) coordinate values of a second specific original bounding box for testing corresponding to the second specific original ROI for testing and (viii) coordinate values of the second specific original ROI for testing.
11. The method of claim 10, wherein, at the step of (b), a specific determination vector for testing, which is one of the determination vectors for testing and corresponds to the specific pair feature vector for testing, includes information on a probability of the first specific original ROI for testing and the second specific original ROI for testing being integrated on the integrated image for testing, and a specific box regression vector for testing, which is one of the box regression vectors for testing and corresponds to the specific pair feature vector for testing, includes information on coordinates of a specific integrated bounding box for testing generated by merging the first specific original ROI for testing and the second specific original ROI for testing on the integrated image for testing.
12. A learning device for generating integrated object detection information of at least one integrated image by integrating first object detection information and second object detection information each corresponding to a first original image and a second original image on a specific space, to be used for generating the integrated image, without extra computation on the integrated image, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform processes of: (I) if the first object detection information and the second object detection information are acquired by processing the first original image and the second original image, instructing a concatenating network included in a Deep Neural Network (DNN) to generate one or more pair feature vectors including information on one or more pairs of first original Region of Interest (ROIs) included in the first original image and second original ROIs in the second original image; (II) instructing a determining network included in the DNN to apply one or more Fully-connected (FC) operations to the pair feature vectors, to thereby generate (i) one or more determination vectors including information on probabilities of the first original ROIs and the second original ROIs included in each of the pairs being appropriate to be integrated and (ii) one or more box regression vectors including information on each of relative locations of integrated ROIs, corresponding to at least part of the pairs, comparing to each of original locations of each component of said at least part of the pairs, on the integrated image; (III) instructing a loss unit to generate an integrated loss by referring to the determination vectors, the box regression vectors and their corresponding (GTs), and performing backpropagation processes by using the integrated loss, to thereby learn at least part of parameters included in the DNN.
13. The learning device of claim 12, wherein, at the process of (I), a specific pair feature vector, which is one of the pair feature vectors, includes (i) first class information of a first specific object included in the first original image, (ii) feature values of a first specific original ROI including the first specific object, (iii) coordinate values of a first specific original bounding box corresponding to the first specific original ROI, (iv) coordinate values of the first specific original ROI, (v) second class information of a second specific object included in the second original image, (vi) feature values of a second specific original ROI including the second specific object, (vii) coordinate values of a second specific original bounding box corresponding to the second specific original ROI, and (viii) coordinate values of the second specific original ROI.
14. The learning device of claim 13, wherein, at the process of (II), a specific determination vector, which is one of the determination vectors and corresponds to the specific pair feature vector, includes information on a probability of the first specific original ROI and the second specific original ROI being integrated on the integrated image, and a specific box regression vector, which is one of the box regression vectors and corresponds to the specific pair feature vector, includes information on coordinates of a specific integrated bounding box generated by merging the first specific original ROI and the second specific original ROI on the integrated image.
15. The learning device of claim 12, wherein, at the process of (III), the processor instructs the loss unit (i) to generate a determination loss by using at least part of the determination vectors through a cross entropy method, (ii) to generate a box regression loss by using at least part of the box regression vectors through a smooth-L1 method, and (iii) to generate the integrated loss by referring to the determination loss and the box regression loss.
16. The learning device of claim 15, wherein, at the process of (III), the determination loss is generated by a formula below: wherein n denotes the number of the determination vectors, vci denotes an i-th determination vector, vC-GTi denotes an i-th determination GT vector on the i-th determination vector, and the box regression loss is generated by a formula below: wherein n denotes the number of the box regression vectors, vci denotes an i-th box regression vector, vC-GTi denotes an i-th box regression GT vector on the i-th box regression vector.
17. The learning device of claim 12, wherein the processor instructs each of deep learning neurons included in one or more layers of the DNN to repeatedly apply one or more convolutional operations to its input by using its own at least one parameter and deliver its output to its next deep learning neuron, to thereby generate the pair feature vectors, the determination vectors and the box regression vectors.
18. The learning device of claim 12, wherein, at the process of (II), the processor instructs the determining network included in the DNN to generate the determination vectors by applying at least part of the FC operations to the pair feature vectors, and to generate the one or more box regression vectors corresponding to one or more specific pair feature vectors, among the pair feature vectors, whose values in corresponding specific determination vectors denoting specific probabilities of specific pairs to be integrated are larger than a prescribed threshold, by applying the other part of the FC operations to the specific pair feature vectors.
19. A test device for generating integrated object detection information for testing of at least one integrated image for testing by integrating first object detection information for testing and second object detection information for testing each corresponding to a first original image for testing and a second original image for testing on a specific space for testing, to be used for generating the integrated image for testing, without extra computation on the integrated image for testing, comprising: at least one memory that stores instructions; and at least one processor configured to execute instructions to perform processes of: (I) on condition that (1) a learning device, if first object detection information for training and second object detection information for training have been acquired by processing first original image for training and the second original image for training, has instructed a concatenating network included in a Deep Neural Network (DNN) to generate one or more pair feature vectors for training including information on one or more pairs for training of first original Region of Interests (ROIs) for training included in the first original image for training and second original ROIs for training in the second original image for training; (2) the learning device has instructed a determining network included in the DNN to apply one or more Fully-connected (FC) operations to the pair feature vectors for training, to thereby generate (i) one or more determination vectors for training including information on probabilities of the first original ROIs for training and the second original ROIs for training included in each of the pairs for training being appropriate to be integrated and (ii) one or more box regression vectors for training including information on each of relative locations of integrated ROIs for training, corresponding to at least part of the pairs for training, comparing to each of original locations of each component of said at least part of the pairs for training, on the integrated image for training; (3) the learning device has instructed a loss unit to generate an integrated loss by referring to the determination vectors for training, the box regression vectors for training and their corresponding (GTs), and performing backpropagation processes by using the integrated loss, to thereby learn at least part of parameters included in the DNN, a learning device, if the first object detection information for testing and the second object detection information for testing is acquired by processing the first original image for testing and the second original image for testing, instructing the concatenating network included in the DNN to generate one or more pair feature vectors for testing including information on one or more pairs for testing of first original ROIs for testing included in the first original image for testing and second original ROIs for testing in the second original image for testing; (II) instructing the determining network included in the DNN to apply one or more FC operations to the pair feature vectors for testing, to thereby generate (i) one or more determination vectors for testing including information on probabilities of the first original ROIs for testing and the second original ROIs for testing included in each of the pairs for testing being appropriate to be integrated and (ii) one or more box regression vectors for testing including information on each of relative locations of integrated ROIs for testing, corresponding to at least part of the pairs for testing, comparing to each of original locations of each component of said at least part of the pairs for testing, on the integrated image for testing; and (III) instructing a merging unit to generate the integrated object detection information for testing by merging at least part of the pairs for testing of first original bounding boxes for testing and second original bounding boxes for testing by referring to the determination vectors for testing and the box regression vectors for testing.
20. The test device of claim 19, wherein the first object detection information for testing and the second object detection information for testing are acquired from the first original image for testing and the second original image for testing, each acquired through a first camera for a first direction and a second camera for a second direction installed on a vehicle including the test device.
21. The test device of claim 19, wherein, at the process of (I), a specific pair feature vector for testing, which is one of the pair feature vectors for testing, includes (i) first class information for testing of a first specific object for testing included in the first original image for testing, (ii) feature values for testing of a first specific original ROI for testing including the first specific object for testing, (iii) coordinate values of a first specific original bounding box for testing corresponding to the first specific original ROI for testing, (iv) coordinate values of the first specific original ROI for testing, (v) second class information for testing of a second specific object for testing included in the second original image for testing, (vi) feature values for testing of a second specific original ROI for testing including the second specific object for testing, (vii) coordinate values of a second specific original bounding box for testing corresponding to the second specific original ROI for testing and (viii) coordinate values of the second specific original ROI for testing.
22. The test device of claim 21, wherein, at the process of (II), a specific determination vector for testing, which is one of the determination vectors for testing and corresponds to the specific pair feature vector for testing, includes information on a probability of the first specific original ROI for testing and the second specific original ROI for testing being integrated on the integrated image for testing, and a specific box regression vector for testing, which is one of the box regression vectors for testing and corresponds to the specific pair feature vector for testing, includes information on coordinates of a specific integrated bounding box for testing generated by merging the first specific original ROI for testing and the second specific original ROI for testing on the integrated image for testing.
</claims>
</document>
