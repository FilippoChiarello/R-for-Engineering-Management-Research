<document>

<filing_date>
2019-02-19
</filing_date>

<publication_date>
2020-03-24
</publication_date>

<priority_date>
2009-01-29
</priority_date>

<ipc_classes>
A63F13/40,G06F3/00,G06F3/01,G06F3/03,G06K9/00,H04N5/222
</ipc_classes>

<assignee>
SONY CORPORATION
</assignee>

<inventors>
YOKONO, JUN
YAMAOKA, KEISUKE
</inventors>

<docdb_family_id>
42353869
</docdb_family_id>

<title>
Information processing device and method, program and recording medium for identifying a gesture of a person from captured image data
</title>

<abstract>
An information processing device includes: an outline extraction unit extracting an outline of a subject from a picked-up image of the subject; a characteristic amount extraction unit extracting a characteristic amount, by extracting sample points from points making up the outline, for each of the sample points; an estimation unit estimating a posture of a high degree of matching as a posture of the subject by calculating a degree of the characteristic amount extracted in the characteristic amount extraction unit being matched with each of a plurality of characteristic amounts that are prepared in advance and represent predetermined postures different from each other; and a determination unit determining accuracy of estimation by the estimation unit using a matching cost when the estimation unit carries out the estimation.
</abstract>

<claims>
1. An information processing apparatus, comprising: circuitry configured to obtain an image of at least a part of a human subject, wherein the image is captured by an imaging device, estimate a position of a joint of the human subject based on the obtained image, the joint being a place at which two parts of the human subject are joined, output, on the basis of the estimated position of the joint of the human subject, joint position data indicative of the estimated position of the joint and the image of the at least the part of the human subject, and estimate a posture of the human subject based on the output joint position data.
2. The information processing apparatus of claim 1, wherein the circuitry is configured to output the joint position data further based on a discriminator learned by a machine learning.
3. The information processing apparatus of claim 2, wherein the discriminator is learned by Boosting.
4. The information processing apparatus of claim 1, wherein the joint position data includes position information of a coordinate of the image data, and the position information of the coordinate indicates a two-dimensional coordinate of more than one joint of the human subject.
5. The information processing apparatus of claim 1, wherein the circuitry is configured to output the joint position data further based on estimation accuracy data.
6. The information processing apparatus of claim 5, wherein the joint position data includes a numerical value indicative of a likelihood of the estimation result.
7. The information processing apparatus of claim 5, wherein the circuitry is further configured to: output a plurality of the joint position data for a plurality of the estimated positions of a plurality of the joints; and estimate the posture of the human subject based on the output plurality of joint position data and the estimation accuracy data.
8. The information processing apparatus of claim 1, wherein the circuitry is further configured to: output the image of the at least a part of the human subject; and overlap the plurality of points indicative of the estimated position of the joint on the image and a straight line between the plurality of points on the image.
9. The information processing apparatus of claim 1, wherein the circuitry is further configured to: generate an instruction to control a gaming application in accordance with the estimated posture.
10. The information processing apparatus of claim 1, wherein the circuitry is further configured to: determine a gesture of the at least the part of the human subject based on the estimated posture.
11. The information processing apparatus of claim 1, wherein the circuitry is further configured to: determine whether the estimated posture corresponds to one of predetermined postures.
12. The information processing apparatus of claim 1, wherein the circuitry is further configured to: output, using the plurality of points and a plurality of lines indicative of the estimated position of the joint, the joint position data.
13. A method, comprising: obtaining, using an imaging device, an image of at least a part of a human subject; estimating, using circuitry, a position of a joint of the human subject based on the obtained image, the joint being a place at which two parts of the human subject are joined; outputting, on the basis of the estimated position of the joint of the human subject, joint position data indicative of the estimated position of the joint and the image of the at least the part of the human subject; and estimating a posture of the human subject based on the output joint position data.
14. The method of claim 13, wherein the outputting the joint position data is further based on a discriminator learned by a machine learning.
15. The method of claim 14, wherein the discriminator is learned by Boosting.
16. The method of claim 13, wherein the joint position data includes position information of a coordinate of the image data, and the position information of the coordinate indicates two-dimensional coordinate of more than one joint of the human subject.
17. A non-transitory computer-readable medium storing instructions that, when executed by at least one processor, cause the at least one processor to perform a method, comprising: obtaining, using an imaging device, an image of at least a part of a human subject; estimating a position of a joint of the human subject based on the obtained image, the joint being a place at which two parts of the human subject are joined; outputting, on the basis of the estimated position of the joint of the human subject, joint position data indicative of the estimated position of the joint and the image of the at least the part of the human subject; and estimating a posture of the human subject based on the output joint position data.
18. The non-transitory computer-readable medium of claim 17, wherein the outputting the joint position data is further based on a discriminator learned by a machine learning.
19. The non-transitory computer-readable medium of claim 18, wherein the discriminator is learned by Boosting.
20. The non-transitory computer-readable medium of claim 17, wherein the joint position data includes position information of a coordinate of the image data, and the position information of the coordinate indicates two-dimensional coordinate of more than one joint of the human subject.
</claims>
</document>
