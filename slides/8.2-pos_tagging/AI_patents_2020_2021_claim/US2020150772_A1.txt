<document>

<filing_date>
2019-01-09
</filing_date>

<publication_date>
2020-05-14
</publication_date>

<priority_date>
2018-11-09
</priority_date>

<ipc_classes>
A61B5/00,A61B5/1455,G01P15/18,G06F3/01
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
QUINN, PHILIP
ZHU, ZHUANGDI
</inventors>

<docdb_family_id>
70551293
</docdb_family_id>

<title>
Sensing Hand Gestures Using Optical Sensors
</title>

<abstract>
The present disclosure provides for one-handed, touch-free interaction with smartwatches. An optical sensor in the smartwatch detects a user's hand and finger movements on the arm wearing the smartwatch. The gesture detection and recognition approaches in this design are lightweight and efficient to operate on small devices.
</abstract>

<claims>
1. A method for detecting hand motions by a wearable device, comprising: emitting, by a light source, light towards a user's skin; receiving, by an optical sensor, reflected light; reading, by one or more processors, raw sensor data from the optical sensor; filtering, by the one or more processors, the raw sensor data to reduce noise; identifying, by the one or more processors, features in the filtered signal that correspond to movements of the wrist, hand, or fingers; matching, by the one or more processors, the identified features to a specific gestural action; and performing, by the one or more processors, an interface operation corresponding to the specific gestural action.
2. The method of claim 1, wherein the wearable device is a smartwatch worn on the user's arm.
3. The method of claim 2, wherein the light is reflected off target and non-target objects in the user's arm.
4. The method of claim 3, wherein the target objects include hemoglobin.
5. The method of claim 1, wherein the filtering comprises high-pass filtering and low-pass filtering.
6. The method of claim 5, wherein the filtering further comprises a median filter adapted to reduce spikes in the raw sensor data.
7. The method of claim 1, further comprising: receiving sensor data from an inertial measurement unit (IMU); wherein the filtering comprises using the sensor data from the IMU to filter out noise from the raw sensor data from the optical sensor.
8. The method of claim 1, wherein identifying features comprises identifying changing points in the filtered sensor data.
9. The method of claim 1, wherein the matching comprises matching the identified features to recorded features for particular gestures.
10. The method of claim 1, wherein the interface operation controls a function of the wearable electronic device.
11. A wearable electronic device adapted to receive input from hand gesture of an arm on which the device is worn, comprising: a light source configured to light towards the user's arm; an optical sensor adapted to receive reflected light from the user's arm; a memory storing information regarding gestural actions and interface operations; one or more processors in communication with the optical sensor and the memory, the one or more processors configured to: receive raw sensor data from the optical sensor; filter the raw sensor data to reduce noise; identify features in the filtered signal that correspond to movements of the wrist, hand, or fingers of the arm wearing the device; match the identified features to a specific gestural action; and perform an interface operation corresponding to the specific gestural action.
12. The wearable electronic device of claim 11, wherein the wearable electronic device is a smartwatch, and the light is reflected off target and non-target objects in the user's arm.
13. The wearable electronic device of claim 12, wherein the target objects include hemoglobin.
14. The wearable electronic device of claim 11, wherein the filtering comprises high-pass filtering and low-pass filtering.
15. The wearable electronic device of claim 14, wherein the filtering further comprises a median filter adapted to reduce spikes in the raw sensor data.
16. The wearable electronic device of claim 11, further comprising: an inertial measurement unit (IMU) adapted to detect motions of the user's arm when the wearable electronic device is worn; wherein the filtering comprises using readings from the IMU to filter out noise from the raw sensor data from the optical sensor.
17. The wearable electronic device of claim 11, wherein identifying features comprises identifying changing points in the filtered sensor data.
18. The wearable electronic device of claim 11, wherein the matching comprises matching the identified features to recorded features for particular gestures.
19. The wearable electronic device of claim 1, wherein the interface operation controls a function of the wearable electronic device.
20. A system, comprising: a photoplethysmogram (PPG) sensor adapted to be positioned in close proximity to a user's arm; an inertial measurement unit (IMU) adapted to be positioned in close proximity to the user's arm; wherein each of the PPG sensor and the IMU are configured to receive data signals measuring movements of the user's arm; and one or more processing units, configured to process the received data signals, such processing including extracting features indicating particular hand gestures, and correlate the detected features with input operations for the one or more processors.
</claims>
</document>
