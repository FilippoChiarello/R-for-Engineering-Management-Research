<document>

<filing_date>
2016-11-07
</filing_date>

<publication_date>
2020-02-11
</publication_date>

<priority_date>
2015-11-06
</priority_date>

<ipc_classes>
G01S5/02,G01S5/20,G06K9/00,G06K9/32,G06K9/62,G06T7/73,G10L15/02
</ipc_classes>

<assignee>
SQUAREHEAD TECHNOLOGY
</assignee>

<inventors>
HAFIZOVIC, INES
NYVOLD, STIG OLUF
OLSEN, FRODE BERG
HELGESEN, JON PETTER
DALENG, JOHANNES ALMING
</inventors>

<docdb_family_id>
55132411
</docdb_family_id>

<title>
UAV detection
</title>

<abstract>
A system for detecting, classifying and tracking unmanned aerial vehicles (UAVs) comprising: at least one microphone array arranged to provide audio data; at least one camera arranged to provide video data; and at least one processor arranged to generate a spatial detection probability map comprising a set of spatial cells. The processor assigns a probability score to each cell as a function of: an audio analysis score generated by comparing audio data to a library of audio signatures; an audio intensity score generated by evaluating a power of at least a portion of a spectrum of the audio data; and a video analysis score generated by using an image processing algorithm to analyse the video data. The system is arranged to indicate that a UAV has been detected in one or more spatial cells if the associated probability score exceeds a predetermined detection threshold.
</abstract>

<claims>
1. A system for detecting, classifying and tracking unmanned aerial vehicles in a zone of interest, the system comprising: at least one microphone array including a plurality of microphones, the at least one microphone array being arranged to provide audio data; at least one camera arranged to provide video data; and at least one processor arranged to process the audio data and the video data to generate a spatial detection probability map comprising a set of spatial cells, wherein the processor assigns a probability score to each cell within the set of spatial cells, said probability score being a function of: an audio analysis score generated by an audio analysis algorithm, said audio analysis algorithm comprising comparing the audio data corresponding to the spatial cell to a library of audio signatures; an audio intensity score generated by evaluating an amplitude of at least a portion of a spectrum of the audio data corresponding to the spatial cell; and a video analysis score generated by using an image processing algorithm to analyse the video data corresponding to the spatial cell, wherein the system is arranged to indicate that an unmanned aerial vehicle has been detected in one or more spatial cells within the zone of interest if the probability score assigned to said one or more spatial cells exceeds a predetermined detection threshold.
2. The system as claimed in claim 1, comprising a plurality of cameras and wherein audio data from the at least one microphone array is used to enhance depth detection carried out using the plurality of cameras.
3. The system as claimed in claim 1, comprising a plurality of microphone arrays wherein every microphone array includes a camera.
4. The system as claimed in claim 1, wherein at least two microphone arrays and/or cameras are mapped to one another using a known spatial relationship between the physical locations of the microphone array(s) and/or camera(s), such that said microphone array(s) and/or camera(s) share a common coordinate system.
5. The system as claimed in claim 1, wherein the system comprises a peripheral sensor subsystem, wherein the peripheral sensor subsystem comprises at least one from the group comprising: a global navigation satellite system sensor; a gyroscope; a magnetometer; an accelerometer; a clock; an electronic anemometer; and a thermometer.
6. The system as claimed in claim 5, wherein the peripheral sensor subsystem is integrated into one or more microphone arrays.
7. The system as claimed in claim 1, wherein the set of cells is generated automatically.
8. The system as claimed in claim 1, wherein the processor is arranged selectively to increase a number of spatial cells in at least a subset of said zone of interest if the probability score assigned to one or more spatial cells in said subset exceeds a predetermined cell density change threshold.
9. The system as claimed in claim 8, wherein the cell density change threshold is lower than the detection threshold.
10. The system as claimed in claim 1, wherein the processor is arranged selectively to refine the resolution of at least one microphone array and/or camera if the probability score assigned to said one or more spatial cells exceeds a predetermined resolution change threshold.
11. The system as claimed in claim 10, wherein the resolution change threshold is lower than the detection threshold.
12. The system as claimed in claim 1, wherein at least one camera is arranged to zoom in on an area within the zone of interest if the probability score assigned to said one or more spatial cells exceeds a predetermined zoom threshold.
13. The system as claimed in claim 12, wherein the zoom change threshold is lower than the detection threshold.
14. The system as claimed in claim 1, wherein the set of spatial cells is further mapped to calibration data comprising a plurality of global positioning system coordinates.
15. The system as claimed in claim 14, arranged to generate said calibration data by detecting a known audio and/or visual signature associated with a calibration drone.
16. The system as claimed in claim 1, the set of cells is generated automatically.
17. The system as claimed in claim 1, wherein each of the at least one microphone array(s) and/or camera(s) is time synchronised.
18. The system as claimed in claim 17, wherein the time synchronisation is achieved by sending each microphone array and/or camera a timestamp generated by a central server.
19. The system as claimed in claim 1, wherein audio data from at least one microphone array is used to guide the analysis of video data from at least one camera.
20. The system as claimed in claim 1, wherein video data from at least one camera is used to guide the analysis of audio data from at least one microphone array.
21. The system as claimed in claim 1, wherein the image processing algorithm comprises: calculating a mean frame from a subset of previously received video data frames; subtracting said mean frame from subsequently received video data frames to generate a difference image; and comparing said difference image to a threshold within each visual spatial cell to generate the video analysis score.
22. The system as claimed in claim 1, wherein the library of audio signatures comprises a plurality of audio signatures associated with unmanned aerial vehicles in a plurality of scenarios.
23. The system as claimed in claim 1, wherein the audio analysis algorithm comprises classifying the detected unmanned aerial vehicle based on the closest match to an audio signature in said library.
24. The system as claimed in claim 1, wherein the image processing algorithm comprises classifying the detected unmanned aerial vehicle.
25. The system as claimed in claim 1, wherein the audio analysis algorithm comprises compensating for a predetermined source of noise proximate to the zone of interest.
26. The system as claimed in claim 25, wherein the audio analysis algorithm comprises compensating for the predetermined source of noise automatically.
27. The system as claimed in claim 1, wherein the audio analysis algorithm comprises a gradient algorithm, wherein the gradient algorithm is arranged to measure a relative change in a spatial audio distribution across one or more of the spatial cells.
28. The system as claimed in claim 1, wherein the processor is arranged to process said audio and visual data in a series of repeating timeframes such that it processes data for every spatial cell within each timeframe.
29. The system as claimed in claim 1, wherein the processor is arranged to analyse each spatial cell in parallel.
30. The system as claimed in claim 1, wherein the probability score is a total of the audio analysis score, the audio intensity score, and the video analysis score.
31. The system as claimed in claim 1, wherein the probability score is an average of the audio analysis score, the audio intensity score, and the video analysis score.
32. The system as claimed in claim 31, wherein the probability score is a weighted average of the audio analysis score, the audio intensity score, and the video analysis score.
33. The system as claimed in claim 1, wherein the probability score function is varied dynamically during a regular operation of the system.
</claims>
</document>
