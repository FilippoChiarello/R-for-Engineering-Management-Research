<document>

<filing_date>
2019-07-01
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2019-07-01
</priority_date>

<ipc_classes>
G06Q10/06,G06Q50/08,G07C5/00
</ipc_classes>

<assignee>
CATERPILLAR
</assignee>

<inventors>
PETRANY, PETER JOSEPH
Vogel, Jeremy Lee
</inventors>

<docdb_family_id>
74066776
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR MANAGING TOOLS AT A WORKSITE
</title>

<abstract>
A method receiving image information with one or more processor(s) and from a sensor disposed at a worksite and determining an identity of a work tool disposed at the worksite based at least partly on the image information. The method further includes receiving location information with the one or more processor(s), the location information indicating a first location of the sensor at the worksite. Additionally, the method includes determining a second location of the work tool at the worksite based at least partly on the location information. In some instances, the method includes generating a worksite map with the one or more processor(s), the worksite map identifying the work tool and indicating the second location of the work tool at the worksite, and at least one of providing the worksite map to an additional processor and causing the worksite map to be rendered via a display.
</abstract>

<claims>
1. A method, comprising: receiving image information with one or more processor(s) and from a sensor disposed at a worksite; determining an identity of a work tool disposed at the worksite based at least partly on the image information; receiving location information with the one or more processor(s), the location information indicating a first location of the sensor at the worksite; determining a second location of the work tool at the worksite based at least partly on the location information; generating a worksite map with the one or more processor(s), the worksite map identifying the work tool and indicating the second location of the work tool at the worksite; and at least one of providing the worksite map to an additional processor and causing the worksite map to be rendered via a display.
2. The method of claim 1, wherein the sensor is carried by a machine at the worksite.
3. The method of claim 2, wherein the machine comprises a first machine, and causing the worksite map to be rendered comprises displaying the worksite map at a monitor carried by a second machine.
4. The method of claim 2, wherein the machine comprises a first machine, the method further comprising causing an audio speaker carried by a second machine at the worksite to generate an audio output indicating the second location of the work tool.
5. The method of claim 2, further comprising: causing, with the one or more processor(s), the machine to travel along a first path, based at least partly on a first travel parameter; determining a second travel parameter, based at least partly on determining the second location of the work tool at the worksite; and causing, with the one or more processor(s), the machine to travel along a second path that is different than the first path, based at least partly on the second travel parameter.
6. The method of claim 1, further comprising determining, with the one or more processor(s) and based at least partly on the image information, a tool characteristic associated with the work tool, and wherein causing the worksite map to be rendered includes outputting at least one of a graphical representation or an audio output of the tool characteristic.
7. A system, comprising: a machine adapted to perform operations at a worksite; a sensor adapted to determine image information associated with the worksite; and one or more processor(s) adapted to: determine a tool characteristic, associated with a work tool disposed at the worksite, based at least partly on the image information; determine a first location associated with the work tool based at least in part on a second location of the machine; generate a worksite map identifying the work tool and indicating the first location associated with the work tool; and at least one of providing the worksite map to an additional processor and causing the worksite map to be rendered via a display.
8. The system of claim 7, wherein the image information includes a first frame associated with a first timestamp and a second frame associated with a second timestamp that is different than the first timestamp, and wherein determining the first location comprises: determining, based at least partly on the first frame, a first distance value associated with the work tool and a background marker; determining, based at least partly on the second frame, a second distance value associated with the work tool and the background marker; and determining a difference between the first distance value and the second distance value.
9. The system of claim 8, wherein the one or more processor(s) are adapted to determine the first location based at least in in part on a path of travel of the machine.
10. The system of claim 7, wherein the one or more processor(s) are adapted to determine the tool characteristic based at least in in part on: a machine-learning algorithm executable at the machine, the machine-learning algorithm being configured to determine a confidence interval associated with the tool characteristic based at least in part on a training data set stored at the machine.
11. The system of claim 10, wherein the one or more processor(s) are further adapted to: determine that the tool characteristic is stored in a worksite tool database, the worksite database storing information indicating one or more work tools present at the worksite.
12. The system of claim 11, wherein the tool characteristic comprises at least one of a work tool identifier, a work tool model, a work tool type, a work tool weight, a work tool dimension, or a work tool history.
13. The system of claim 12, wherein the one or more processor(s) are carried by the machine.
14. The system of claim 7, wherein the sensor comprises a first camera carried by the machine and the image information comprises first image information, the system further comprising a second camera carried by the machine, wherein determining the first location includes determining a difference between the first image information and second image information determined by the second camera.
15. The system of claim 7, wherein the image information reflects from a surface of the work tool.
16. A method comprising: receiving, with a processor and from at least one sensor of a first machine: a first indicator identifying a location associated with a work tool at a worksite; and a second indicator identifying a tool characteristic associated with the work tool; determining, with the processor, that a second machine is traveling a first path that is within a predetermined threshold distance of the location; and sending, to the second machine, with the processor, and based at least in part on determining that the second location is traveling the path that is within the predetermined threshold distance of the location, a third indicator identifying the location of the work tool, wherein the third indicator is executable to cause the second machine to travel a second path that is different than the first path.
17. The method of claim 16, wherein the second path is outside the predetermined threshold distance of the location.
18. The method of claim 16, wherein the second machine is located a distance apart from the first machine, and sending the third indicator is based, at least in part, on the distance apart being less than a predetermined threshold.
19. The method of claim 16, further comprising receiving, from a third machine that is different than the first machine, a fourth indicator of the location associated with the work tool, and wherein the third indicator represents at least an average based on the first indicator and the fourth indicator.
20. The method of claim 16, wherein the first indicator is based, at least in part, on image information received at a camera carried by the first machine and directed at a surface of the work tool.
</claims>
</document>
