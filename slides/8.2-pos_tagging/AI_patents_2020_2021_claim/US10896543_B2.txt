<document>

<filing_date>
2015-08-19
</filing_date>

<publication_date>
2021-01-19
</publication_date>

<priority_date>
2014-08-25
</priority_date>

<ipc_classes>
B62D57/032,G06F1/16,G06F3/00,G06T11/00,G06T13/00,G06T19/00,G09G5/00
</ipc_classes>

<assignee>
X DEVELOPMENT
</assignee>

<inventors>
KUFFNER, JAMES JOSEPH
</inventors>

<docdb_family_id>
54072963
</docdb_family_id>

<title>
Methods and systems for augmented reality to display virtual representations of robotic device actions
</title>

<abstract>
Example methods and systems for augmented reality interfaces to display virtual representations of robotic device actions are provided. An example method includes receiving information that indicates an action or an intent of a robotic device to perform a task, and the action or the intent includes one or more of a planned trajectory of the robotic device to perform at least a portion of the task and an object to be handled by the robotic device to perform at least a portion of the task. The method also includes providing, for display by a computing device on an augmented reality interface, a virtual representation of the action or the intent, and the virtual representation includes as annotations on the augmented reality interface at least a portion of the planned trajectory of the robotic device or highlighting the object to be handled by the robotic device.
</abstract>

<claims>
1. A computer-implemented method comprising: receiving information that indicates an action or an intent of a robotic device to perform a task, wherein the action or the intent includes one or more of a planned trajectory of the robotic device to perform at least a portion of the task and an object to be handled by the robotic device to perform at least a portion of the task; receiving a camera feed from a field of view of the robotic device; displaying by a computing device on an augmented reality interface, a virtual representation of the action or the intent, wherein the virtual representation includes as annotations on the augmented reality interface at least a portion of the planned trajectory of the robotic device or highlighting the object to be handled by the robotic device overlaid onto the camera feed from the field of view of the robotic device; providing, by a device remote from the robotic device, a projection of light along a pathway to modify the action or the intent of the robotic device; and in response to providing the projection of light, receiving from the robotic device one or more of an updated planned trajectory of the robotic device and an updated object to be handled by the robotic device.
2. The method of claim 1, further comprising: animating the virtual representation on the augmented reality interface to illustrate the robotic device performing the task according to the planned trajectory.
3. The method of claim 1, wherein the virtual representation includes a set of virtual footprints to represent future movement of the robotic device along the portion of the planned trajectory.
4. The method of claim 1, wherein the virtual representation includes a line on a floor covering the portion of the planned trajectory of the robotic device.
5. The method of claim 1, wherein the virtual representation includes an indication on the object where the robotic device plans to handle the object.
6. The method of claim 1, wherein receiving the information that indicates the action or the intent of the robotic device to perform the task comprises receiving the information before the robotic device initiates performance of the task.
7. The method of claim 1, further comprising: determining one or more robotic devices in proximity to the computing device; requesting, from the one or more robotic devices in proximity to the computing device, information that indicates actions or intents of the one or more robotic devices; and displaying one or more virtual representations per the one or more robotic devices that respectively indicate the actions or the intents.
8. The method of claim 1, further comprising: providing by the computing device information to modify the action or the intent of the robotic device, wherein the information includes outputs of an accelerometer of the computing device based on motion of the computing device; and in response, receiving from the robotic device one or more of an updated planned trajectory of the robotic device and an updated object to be handled by the robotic device.
9. The method of claim 1, wherein the computing device is a first computing device, and the method further comprises: receiving from a second computing device information to modify the action or the intent of the robotic device, wherein the information includes outputs of an accelerometer of the second computing device based on motion of the second computing device; and in response, receiving from the robotic device one or more of an updated planned trajectory of the robotic device and an updated object to be handled by the robotic device.
10. A non-transitory computer readable medium having stored thereon instructions that, upon execution by a computing device, cause the computing device to perform functions comprising: receiving information that indicates an action or an intent of a robotic device to perform a task, wherein the action or the intent includes one or more of a planned trajectory of the robotic device to perform at least a portion of the task and an object to be handled by the robotic device to perform at least a portion of the task; receiving a camera feed from a field of view of the robotic device; displaying on an augmented reality interface, a virtual representation of the action or the intent, wherein the virtual representation includes as annotations on the augmented reality interface at least a portion of the planned trajectory of the robotic device or highlighting the object to be handled by the robotic device overlaid onto the camera feed from the field of view of the robotic device; providing, by the computing device which is remote from the robotic device, a projection of light along a pathway to modify the action or the intent of the robotic device; and in response to providing the projection of light, receiving from the robotic device one or more of an updated planned trajectory of the robotic device and an updated object to be handled by the robotic device.
11. The non-transitory computer readable medium of claim 10, wherein: receiving the information that indicates the action or the intent of the robotic device to perform the task comprises receiving the information before the robotic device initiates performance of the task; and displaying the virtual representation of the action or the intent overlaid onto a representation of an environment in which the robotic device resides including the robotic device in the environment.
</claims>
</document>
