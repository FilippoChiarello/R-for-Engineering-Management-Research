<document>

<filing_date>
2018-09-12
</filing_date>

<publication_date>
2020-09-08
</publication_date>

<priority_date>
2017-09-12
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06K9/62,G06T7/00,G06T7/40,G06T7/73,G16H10/40,G16H10/60,G16H30/40,G16H40/67,G16H50/20,G16H80/00
</ipc_classes>

<assignee>
NANTOMICS
</assignee>

<inventors>
SONG BING
JABER, MUSTAFA
</inventors>

<docdb_family_id>
65631862
</docdb_family_id>

<title>
Few-shot learning based image recognition of whole slide image at tissue level
</title>

<abstract>
A computer implemented method of generating at least one shape of a region of interest in a digital image is provided. The method includes obtaining, by an image processing engine, access to a digital tissue image of a biological sample; tiling, by the image processing engine, the digital tissue image into a collection of image patches; obtaining, by the image processing engine, a plurality of features from each patch in the collection of image patches, the plurality of features defining a patch feature vector in a multidimensional feature space including the plurality of features as dimensions; determining, by the image processing engine, a user selection of a user selected subset of patches in the collection of image patches; classifying, by applying a trained classifier to patch vectors of other patches in the collection of patches, the other patches as belonging or not belonging to a same class of interest as the user selected subset of patches; and identifying one or more regions of interest based at least in part on the results of the classifying.
</abstract>

<claims>
1. A computer implemented method of generating at least one shape of a region of interest in a digital image, the method comprising: obtaining, by an image processing engine, access to a digital tissue image of a biological sample; tiling, by the image processing engine, the digital tissue image into a collection of image patches; obtaining, by the image processing engine, a plurality of features from each patch in the collection of image patches, the plurality of features defining a patch feature vector in a multidimensional feature space including the plurality of features as dimensions; determining, by the image processing engine, a user selection of a user selected subset of patches in the collection of image patches, wherein the user selection further includes a selection, prior to selection of the subset of patches in the collection of image patches, of whether the user selected subset of patches are positive or negative patches; classifying, by applying a trained classifier to patch vectors of other patches in the collection of patches, the other patches as belonging or not belonging to a same class of interest as the user selected subset of patches; and identifying one or more regions of interest based at least in part on the results of the classifying.
2. The method of claim 1, wherein the step of tiling the digital tissue image includes creating image patches that are of a uniform size and a uniform shape.
3. The method of claim 2, wherein the image patches of uniform size and uniform shape include square patches of less than or equal to 1,000 pixels by 1,000 pixels.
4. The method of claim 3, wherein the square patches are less than or equal to 400 pixels by 400 pixels.
5. The method of claim 3, wherein the square patches are less than or equal to 256 pixels by 256 pixels.
6. The method of claim 1, wherein the step of tiling the digital tissue image includes creating image patches that are of non-uniform size and shape.
7. The method of claim 1, wherein the collection of image patches includes non-overlapping patches.
8. The method of claim 1, wherein the trained classifier includes a support vector machine.
9. The method of claim 8, wherein the support vector machine includes a two-class support vector machine.
10. The method of claim 1, wherein the trained classifier comprises a support vector machine and training patches used to train the support vector machine are generated by a second support vector machine.
11. The method of claim 10, wherein the second support vector machine is a one-class support vector machine that is trained by training patches comprising the user selected subset of patches.
12. The method of claim 10, wherein the support vector machine is a two-class support vector machine and the second support vector machine is a one-class support vector machine that is trained by training patches comprising the user selected subset of patches.
13. The method of claim 1, wherein obtaining the features comprises submitting each patch to a trained image processing neural network that executes feature extraction processing, the feature extraction processing having been trained on images of a variety of known objects.
14. The method of claim 13, wherein the neural network is a convolutional neural network.
15. The method of claim 13, wherein the neural network has been trained on at least 1,000,000 images and the variety of known objects comprises objects belonging to at least 1,000 different classes of known objects.
16. The method of claim 13, wherein a majority of the known objects are not digital tissue images of biological samples.
17. The method of claim 15, wherein a majority of the known objects are not digital tissue images of biological samples.
18. The method of claim 13, wherein all of the known objects are not digital tissue images of biological samples.
19. The method of claim 13, wherein all of the known objects are not in the same class of interest as the user selected subset of patches.
20. The method of claim 1, further comprising causing a computing device to render the region of interest shapes on a display.
21. The method of claim 1, wherein the region of interest shapes includes at least one tissue mask.
22. The method of claim 21, wherein the at least one tissue mask comprises a microdissection mask.
23. The method of claim 1, wherein the class of interest comprises at least one cancer class.
24. The method of claim 23, wherein the at least one cancer class includes one of the following types of cancer: breast cancer, bladder cancer, brain cancer, lung cancer, pancreatic cancer, skin cancer, colorectal cancer, prostate cancer, stomach cancer, liver cancer, cervical cancer, esophageal cancer, leukemia, non-hodgkin lymphoma, kidney cancer, uterine cancer, bile duct cancer, bone cancer, ovarian cancer, gallbladder cancer, gastrointestinal cancer, oral cancer, throat cancer, ocular cancer, pelvic cancer, spinal cancer, testicular cancer, vaginal cancer, vulvar cancer, or thyroid cancer.
25. The method of claim 1, wherein the class of interest comprises at least one of the following types of tissue: abnormal tissue, benign tissue, malignant tissue, bone tissue, skin tissue, nerve tissue, interstitial tissue, muscle tissue, connective tissue, scar tissue, lymphoid tissue, fat, epithelial tissue, nervous tissue, or blood vessels.
26. The method of claim 1, wherein the digital tissue image comprises a slide image of a tissue sample slide.
27. The method of claim 26, wherein the slide image comprises a digital histopathology image.
28. The method of claim 26, wherein the slide image includes biological sample metadata comprising digital information associated with at least one of the following: a tissue type, a tissue donor, a scanner, a stain, a staining technique, an identifier of a preparer, an image size, a sample identifier, a tracking identifier, a version number, a file type, an image date, a symptom, a diagnosis, an identifying information of treating physician, a medical history of the tissue donor, a demographic information of the tissue donor, a medical history of family of the tissue donor, or a species of the tissue donor.
29. An apparatus for generating at least one shape of a region of interest in a digital image, the apparatus comprising: a non-transitory, computer readable memory storing software instructions; and a processor coupled with the computer readable memory, and, upon execution of the software instructions, is configurable to: obtain access to a digital tissue image of a biological sample; tile the digital tissue image into a collection of image patches; obtain a plurality of features from each patch in the collection of image patches, the plurality of features defining a patch feature vector in a multidimensional feature space including the plurality of features as dimensions; determine a user selection of a user selected subset of patches in the collection of image patches, wherein the user selection further includes a selection, prior to selection of the subset of patches in the collection of image patches, of whether the user selected subset of patches are positive or negative patches; classify, by applying a trained classifier to patch vectors of other patches in the collection of patches, the other patches as belonging or not belonging to a same class of interest as the user selected subset of patches; and identify one or more regions of interest based at least in part on the results of the classifying.
30. A computer implemented method of generating training data to train a machine learning system, the method comprising: obtaining, by an image processing engine, access to a digital tissue image of a biological sample; tiling, by the image processing engine, the digital tissue image into a collection of image patches; obtaining, by the image processing engine, a plurality of features from each patch in the collection of image patches, the plurality of features defining a patch feature vector in a multidimensional feature space including the plurality of features as dimensions; determining, by the image processing engine, a user selection of a user selected subset of patches in the collection of image patches, wherein the user selection further includes a selection, prior to selection of the subset of patches in the collection of image patches, of whether the user selected subset of patches are positive or negative patches; classifying, by applying a trained generic classifier to patch vectors of other patches in the collection of patches, the other patches as belonging or not belonging to a same class of interest as the user selected subset of patches; and generating, by the image processing engine, training data for the machine learning system based on the classifying of the user-selected and the other patches in the collection of patches.
</claims>
</document>
