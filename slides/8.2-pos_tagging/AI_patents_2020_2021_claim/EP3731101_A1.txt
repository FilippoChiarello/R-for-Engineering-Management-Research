<document>

<filing_date>
2020-03-19
</filing_date>

<publication_date>
2020-10-28
</publication_date>

<priority_date>
2019-04-26
</priority_date>

<ipc_classes>
G06F12/02,G06F12/06,G06F12/1036,G06F13/16,G06F9/50,G06N3/04,G06N3/063
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
DOSHI, Kshitij
BERNAT, Francesc Guim
ZIAKAS, Dimitrios
MALONE, Kimberly
SCHMISSEUR, Mark
</inventors>

<docdb_family_id>
67541676
</docdb_family_id>

<title>
ARCHITECTURAL ENHANCEMENTS FOR COMPUTING SYSTEMS HAVING ARTIFICIAL INTELLIGENCE LOGIC DISPOSED LOCALLY TO MEMORY
</title>

<abstract>
A semiconductor chip is described. The semiconductor chip includes memory address decoder logic circuitry comprising different memory address bit manipulation paths to respectively impose different memory interleaving schemes for memory accesses directed to artificial intelligence information in a memory and non artificial intelligence information in the memory. The artificial intelligence information is to be processed with artificial intelligence logic circuitry disposed locally to the memory.
</abstract>

<claims>
1. A semiconductor chip, comprising:
memory address decoder logic circuitry comprising different memory address bit manipulation paths to respectively impose different memory interleaving schemes for memory accesses directed to artificial intelligence information in a memory and non artificial intelligence information in the memory, wherein, the artificial intelligence information is to be processed with artificial intelligence logic circuitry disposed locally to the memory.
2. The semiconductor chip of claim 1 wherein the memory address decoder logic circuitry is within a caching agent.
3. The semiconductor chip of claim 1 wherein the memory address decoder logic circuitry is within a memory controller.
4. The semiconductor chip of claim 3 wherein the memory controller comprises artificial intelligence processing logic.
5. The semiconductor chip of claim 1 wherein address space of the memory is partitioned into artificial intelligence address space and standard address space, the artificial intelligence address space further partitioned into separately configurable sections, each separately configurable section to be allocated to information for a particular AI model.
6. The semiconductor chip of claim 5 wherein an AI model's memory interleaving scheme is defined in the AI model's allocated configurable memory section.
7. The semiconductor chip of claim 6 wherein no interleaving is a configuration option of the AI model's allocated configurable memory section.
8. The semiconductor chip of claim 1 wherein the artificial intelligence information is to be accessed without interleaving.
9. The semiconductor chip of claim 1 wherein the memory comprises memory modules comprises artificial intelligence processing logic circuitry.
10. A semiconductor chip, comprising:
a processing core comprising at least one of: a) a translation lookaside buffer having an entry format that includes information that identifies if the entry's corresponding memory space contains information to be processed by an artificial intelligence model; b) an instruction execution pipeline to execute a memory access instruction, the memory access instruction having an instruction format, the instruction format having content that identifies: i) information in memory to be processed by an artificial intelligence model that is implemented with logic circuitry disposed locally to the memory; ii) the artificial intelligence model; iii) where a result generated by the artificial intelligence model is to be stored.
11. The semiconductor chip of claim 10 further comprising a caching agent, the caching agent to bypass interleaving memory address bit manipulation logic if a memory request includes information from the translation lookaside buffer that memory space targeted by the memory request contains artificial intelligence information to be processed by an artificial intelligence model.
12. The semiconductor chip of claim 10 wherein the instruction format identifies the information in memory to be processed by an artificial intelligence model with an object ID.
13. A computing system, comprising: a network interface; a plurality of processing cores; a memory system having integrated AI processing logic; and, memory address decoder logic circuitry comprising different memory address bit manipulation paths to respectively impose different memory interleaving schemes for memory accesses directed to artificial intelligence information in a memory and non artificial intelligence information in the memory, wherein, the artificial intelligence information is to be processed with artificial intelligence logic circuitry disposed locally to the memory.
14. The computing system of claim 13 wherein at least one of the processing cores further comprise at least one of: a) a translation lookaside buffer having an entry format that includes information that identifies if the entry's corresponding memory space contains information to be processed by an artificial intelligence model; b) an instruction execution pipeline to execute and instruction, the instruction having an instruction format, the instruction format having content that identifies: i) information in memory to be processed by an artificial intelligence model; ii) the artificial intelligence model; iii) where a result generated by the artificial intelligence model is to be stored.
</claims>
</document>
