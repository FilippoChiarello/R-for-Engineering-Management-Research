<document>

<filing_date>
2019-07-08
</filing_date>

<publication_date>
2020-04-29
</publication_date>

<priority_date>
2018-10-26
</priority_date>

<ipc_classes>
G06K9/32,G06K9/46,G06K9/62,G06N3/04,G06N3/08,G06T7/10
</ipc_classes>

<assignee>
STRADVISION
</assignee>

<inventors>
JANG, TAEWOONG
JEONG, KYUNGJOONG
KIM, HAK-KYOUNG
KIM, KYE-HYEON
RYU, WOOJU
KIM, INSU
BOO, SUKHOON
JE, HONGMO
KIM, YONGJOONG
CHO, HOJIN
SUNG, MYUNGCHUL
NAM, WOONHYUN
YEO, DONGHUN
</inventors>

<docdb_family_id>
67211567
</docdb_family_id>

<title>
CNN-BASED LEARNING METHOD, LEARNING DEVICE FOR SELECTING USEFUL TRAINING DATA AND TEST METHOD, TEST DEVICE USING THE SAME
</title>

<abstract>
A convolutional neural network (CNN)-based learning method for selecting useful training data is provided. The CNN-based learning method includes steps of: a learning device (a) instructing a first CNN module (i) to generate a first feature map, and instructing a second CNN module to generate a second feature map; (ii) to generate a first output indicating identification information or location information of an object by using the first feature map, and calculate a first loss by referring to the first output and its corresponding GT; (b) instructing the second CNN module (i) to change a size of the first feature map and integrate the first feature map with the second feature map, to generate a third feature map; (ii) to generate a fourth feature map and to calculate a second loss; and (c) backpropagating the auto-screener's loss generated by referring to the first loss and the second loss.
</abstract>

<claims>
1. A convolutional neural network (CNN)-based learning method for selecting useful training data, comprising steps of: (a) a learning device, if at least one input image is acquired, (i) instructing a first CNN module capable of obtaining identification information or location information of a specific object in the input image to apply at least one convolution operation to the input image, to thereby generate a first feature map, and (ii) instructing a second CNN module capable of auto-screening useful training data to be used for a learning process of the first CNN module to apply at least one convolution operation to the input image, to thereby generate a second feature map; (b) the learning device instructing the first CNN module to generate a first output indicating the identification information or the location information of the specific object by using the first feature map, then calculate a first loss by referring to the first output and its corresponding ground truth (GT); (c) the learning device inputting the first feature map to the second CNN module, then instructing the second CNN module to change a size of the first feature map to be same as a size of the second feature map and then integrate the first feature map with the second feature map, to thereby generate a third feature map; (d) the learning device instructing the second CNN module to apply at least one convolution operation to the third feature map to generate a fourth feature map, and then to calculate a second loss, as a prediction value of the first loss, by using the fourth feature map; (e) the learning device calculating an auto-screener's loss by referring to the first loss and the second loss; and (f) the learning device performing backpropagation by using the auto-screener's loss, to thereby optimize at least one parameter of the second CNN module.
2. The CNN-based learning method of Claim 1, wherein, at the step of (f), the learning device performs backpropagation by using the first loss, to thereby optimize at least one parameter of the first CNN module.
3. The CNN-based learning method of Claim 1, wherein the first CNN module is included in one of an object detection system for detecting a size and a location of the specific object, a classification system for identifying a type of the specific object, and a segmentation system for distinguishing an area corresponding to the specific object from other areas,
wherein the second CNN module is included in an auto-screening system for automatically selecting at least one specific input image, which respectively includes its corresponding specific object with a low possibility of being correctly detected, among a plurality of input images inputted to the first CNN module,
wherein the first output represents one of an output of the object detection system, that of the classification system, and that of the segmentation system, and
wherein the low possibility of being correctly detected is determined by referring to information on whether a possibility is less than a predetermined threshold.
4. The CNN-based learning method of Claim 1, wherein the size of the second feature map is greater than the size of the first feature map, and
wherein, at the step of (c), the learning device instructs the second CNN module to increase the size of the first feature map to be same as the size of the second feature map.
5. The CNN-based learning method of Claim 4, wherein, at the step of (c), the learning device instructs the second CNN module to apply a predetermined number of convolution operations to the first feature map, to thereby change the size of the first feature map to be same as the size of the second feature map.
6. The CNN-based learning method of Claim 1, wherein, at the step of (c), the learning device instructs the second CNN module to concatenate the first feature map and the second feature map, to thereby generate the third feature map.
7. The CNN-based learning method of Claim 1, wherein, at the step of (d), the learning device instructs the second CNN module to allow the fourth feature map to pass through at least one of a pooling layer and a fully-connected (FC) layer, to thereby calculate the second loss.
8. A method for selecting useful training data based on convolutional neural network (CNN), comprising steps of: (a) on condition that (I) a learning device (i) has instructed a first CNN module capable of obtaining identification information or location information of a specific object in a training image to apply at least one predetermined convolution operation to the training image, to thereby generate a first feature map for training, and (ii) has instructed a second CNN module capable of auto-screening useful training data to be used for a learning process of the first CNN module to apply at least one convolution operation to the training image, to thereby generate a second feature map for training; (II) the learning device has instructed the first CNN module to generate a first output for training indicating the identification information or the location information of the specific object by using the first feature map for training, then calculate a first loss by referring to the first output for training and its corresponding ground truth (GT); (III) the learning device has inputted the first feature map for training to the second CNN module, then has instructed the second CNN module to change a size of the first feature map for training to be same as a size of the second feature map for training and then integrate the first feature map for training with the second feature map for training, to thereby generate a third feature map for training; (IV) the learning device has instructed the second CNN module to apply at least one convolution operation to the third feature map for training to generate a fourth feature map for training, and then to calculate a second loss, as a prediction value of the first loss, by using the fourth feature map; (V) the learning device has calculated an auto-screener's loss by referring to the first loss and the second loss; and (VI) the learning device has performed backpropagation by using the auto-screener's loss, to thereby optimize at least one parameter of the second CNN module, a testing device obtaining each of image candidates as each test image; (b) the testing device (i) instructing the first CNN module to apply at least one convolution operation to the test image, to thereby generate a first feature map for testing, and (ii) instructing the second CNN module to apply at least one convolution operation to the test image, to thereby generate a second feature map for testing; (c) the testing device inputting the first feature map for testing to the second CNN module, then instructing the second CNN module to change a size of the first feature map for testing to be same as a size of the second feature map for testing and then integrating the first feature map for testing with the second feature map for testing, to thereby generate a third feature map for testing; (d) the testing device instructing the second CNN module to apply at least one convolution operation to the third feature map for testing to generate a fourth feature map for testing, and then to calculate a predicted loss by using the fourth feature map for testing; and (e) the testing device selecting at least one image of which the predicted loss is equal to or greater than a predetermined threshold, among the image candidates, as training images to be used for a learning process of the first CNN module.
9. A learning device for selecting useful training data, comprising: a communication part for acquiring at least one input image; and a processor for performing processes of (I) (I-1) instructing a first CNN module capable of obtaining identification information or location information of a specific object in the input image to apply at least one convolution operation to the input image, to thereby generate a first feature map, and (I-2) instructing a second CNN module capable of auto-screening useful training data to be used for a learning process of the first CNN module to apply at least one convolution operation to the input image, to thereby generate a second feature map, (II) instructing the first CNN module to generate a first output indicating the identification information or the location information of the specific object by using the first feature map, then calculate a first loss by referring to the first output and its corresponding ground truth (GT), (III) inputting the first feature map to the second CNN module, then instructing the second CNN module to change a size of the first feature map to be same as a size of the second feature map and then integrate the first feature map with the second feature map, to thereby generate a third feature map, (IV) instructing the second CNN module to apply at least one convolution operation to the third feature map to generate a fourth feature map, and then to calculate a second loss, as a prediction value of the first loss, by using the fourth feature map, (V) calculating an auto-screener's loss by referring to the first loss and the second loss, and (VI) performing backpropagation by using the auto-screener's loss, to thereby optimize at least one parameter of the second CNN module.
10. The learning device of Claim 9, wherein, at the process of (VI), the processor performs backpropagation by using the first loss, to thereby optimize at least one parameter of the first CNN module.
11. The learning device of Claim 9, wherein the first CNN module is included in one of an object detection system for detecting a size and a location of the specific object, a classification system for identifying a type of the specific object, and a segmentation system for distinguishing an area corresponding to the specific object from other areas,
wherein the second CNN module is included in an auto-screening system for automatically selecting at least one specific input image, which respectively includes its corresponding specific object with a low possibility of being correctly detected, among a plurality of input images inputted to the first CNN module,
wherein the first output represents one of an output of the object detection system, that of the classification system, and that of the segmentation system, and
wherein the low possibility of being correctly detected is determined by referring to information on whether a possibility is less than a predetermined threshold.
12. The learning device of Claim 9, wherein the size of the second feature map is greater than the size of the first feature map, and
wherein, at the process of (III), the processor instructs the second CNN module to increase the size of the first feature map to be same as the size of the second feature map.
13. The learning device of Claim 12, wherein, at the process of (III), the processor instructs the second CNN module to apply a predetermined number of convolution operations to the first feature map, to thereby change the size of the first feature map to be same as the size of the second feature map.
14. The learning device of Claim 9, wherein, at the process of (III), the processor instructs the second CNN module to concatenate the first feature map and the second feature map, to thereby generate the third feature map.
15. The learning device of Claim 9, wherein, at the process of (IV), the processor instructs the second CNN module to allow the fourth feature map to pass through at least one of a pooling layer and a fully-connected (FC) layer, to thereby calculate the second loss.
16. A testing device for selecting useful training data based on convolutional neural network (CNN), comprising: a communication part for obtaining each of image candidates as each test image, on condition that (i) a learning device (i-1) has instructed a first CNN module capable of obtaining identification information or location information of a specific object in a training image to apply at least one predetermined convolution operation to the training image, to thereby generate a first feature map for training, and (i-2) has instructed a second CNN module capable of auto-screening useful training data to be used for a learning process of the first CNN module to apply at least one convolution operation to the training image, to thereby generate a second feature map for training; (ii) the learning device has instructed the first CNN module to generate a first output for training indicating the identification information or the location information of the specific object by using the first feature map for training, then calculate a first loss by referring to the first output for training and its corresponding ground truth (GT); (iii) the learning device has inputted the first feature map for training to the second CNN module, then has instructed the second CNN module to change a size of the first feature map for training to be same as a size of the second feature map for training and then integrate the first feature map for training with the second feature map for training, to thereby generate a third feature map for training; (iv) the learning device has instructed the second CNN module to apply at least one convolution operation to the third feature map for training to generate a fourth feature map for training, and then to calculate a second loss, as a prediction value of the first loss, by using the fourth feature map; (v) the learning device has calculated an auto-screener's loss by referring to the first loss and the second loss; and (vi) the learning device has performed backpropagation by using the auto-screener's loss, to thereby optimize at least one parameter of the second CNN module; and a processor for performing processes of (I) (I-1) instructing the first CNN module to apply at least one convolution operation to the test image, to thereby generate a first feature map for testing, and (I-2) instructing the second CNN module to apply at least one convolution operation to the test image, to thereby generate a second feature map for testing, (II) inputting the first feature map for testing to the second CNN module, then instructing the second CNN module to change a size of the first feature map for testing to be same as a size of the second feature map for testing and then integrating the first feature map for testing with the second feature map for testing, to thereby generate a third feature map for testing, (III) instructing the second CNN module to apply at least one convolution operation to the third feature map for testing to generate a fourth feature map for testing, and then to calculate a predicted loss by using the fourth feature map for testing, and (IV) selecting at least one image of which the predicted loss is equal to or greater than a predetermined threshold, among the image candidates, as training images to be used for a learning process of the first CNN module.
</claims>
</document>
