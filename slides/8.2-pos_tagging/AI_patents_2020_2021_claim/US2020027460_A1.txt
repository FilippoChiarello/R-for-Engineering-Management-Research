<document>

<filing_date>
2019-09-26
</filing_date>

<publication_date>
2020-01-23
</publication_date>

<priority_date>
2019-08-30
</priority_date>

<ipc_classes>
G06F3/01,G10L13/04,G10L15/18,G10L15/22,G10L15/25
</ipc_classes>

<assignee>
LG ELECTRONICS
</assignee>

<inventors>
CHOI, HYEON SIK
SEO, JAE PIL
</inventors>

<docdb_family_id>
68071008
</docdb_family_id>

<title>
COMMUNICATION ROBOT AND METHOD FOR OPERATING THE SAME
</title>

<abstract>
Disclosed are a communication robot and a method for operating the same capable of smoothly processing speech recognition by executing an artificial intelligence (AI) algorithm and/or a machine learning algorithm in 5G environment connected for Internet of things. A method for operating a communication robot according to an embodiment of the present disclosure may include collecting speech uttered by two or more utterers approaching within a predetermined distance from the communication robot, collecting photographed images of the two or more utterers, determining whether a case where utterers of a wake-up word and a continuous word included in the uttered speech are the same is a first case, or whether a case where the utterers of the wake-up and the continuous word included in the uttered speech are different is a second case, and determining a voice reception enhancement direction according to the first case or the second case.
</abstract>

<claims>
1. A method for operating a communication robot disposed at an any location, the method comprising: collecting speech uttered by two or more utterers approaching within a predetermined distance from the communication robot; collecting photographed images of the two or more titterers approaching within the predetermined distance from the communication robot; determining whether a case where utterers of a wake-up word and a continuous word included in the uttered speech are the same is a first case, or whether a case where the utterers of the wake-up word and the continuous word included in the uttered speech are different is a second case by analyzing the uttered speech and the photographed image; and determining a voice reception enhancement direction for speech recognition according to the first case or the second case determined in the determining.
2. The method of claim 1, wherein the determining includes: estimating a first utterance direction according to a detection of a position of the utterer that utters the wake-up word among the two or more utterers; estimating a second utterance direction according to a detection of a position of the utterer that utters the continuous word among the two or more utterers by analyzing the photographed images of each of the two or more utterers; determining, as the first case, a case where a difference between the first utterance direction and the second utterance direction is within a reference value; and determining, as the second case, a case where a difference between the first utterance direction and the second utterance direction exceeds the reference value.
3. The method of claim 2, wherein the estimating of a first utterance direction includes estimating the first utterance direction according to the detection of the position of the utterer uttering the wake-up word using a time delay of arrival (TDOA) algorithm which detects directions of sound sources based on a correlation of time differences in sound sources collected by a plurality of microphones in a time domain.
4. The method of claim 2, wherein the estimating of a second utterance direction includes estimating, as the second utterance direction, a difference value between a reference coordinate set in a camera generating the photographed images of the two or more utterers and a position coordinate of the utterer uttering the continuous word included in the photographed image generated by the camera.
5. The method of claim 2, further comprising: tracking gazes of each of the two or more utterers from the photographed images of each of the two or more utterers prior to the estimating of a second utterance direction; performing lipreading recognition of each of the two or more utterers from the photographed images of each of the two or more utterers; and determining an utterer that is uttering as a result of performing the lipreading recognition as the utterer uttering the continuous word while staring at the communication robot as a result of tracking the gaze.
6. The method of claim 2, wherein the determining of a voice reception enhancement direction includes further increasing sensitivity of speech uttered from the first utterance direction than before, if it is determined in the determining that the case where the difference between the first utterance direction and the second utterance direction is within the reference value is the first case.
7. The method of claim 2, wherein the determining of a voice reception enhancement direction includes further increasing sensitivity of speech uttered from the second utterance direction than before, if it is determined in the determining that the case where the difference between the first utterance direction and the second utterance direction exceeds the reference value is the second case.
8. The method of claim 1, further comprising: performing speech recognition on the continuous word after the determining of the voice reception enhancement direction.
9. The method of claim 8, wherein the performing of speech recognition on the continuous word includes activating the speech recognition in response to the reception of the wake-up word uttered by any one of the two or more utterers.
10. The method of claim 9, wherein the performing of the speech recognition on the continuous word includes: generating continuous word text obtained by converting the continuous word into text; understanding an utterance intention of the continuous word by performing syntactic analysis and semantic analysis on the continuous word text; generating response text using a knowledge base corresponding to the utterance intention; and converting the response text into response uttered speech in a natural language utterance form.
11. A communication robot disposed at an any location, the communication robot comprising: a first collector configured to collect speech uttered by two or more utterers approaching within a predetermined distance from the communication robot; a second collector configured to collect photographed images of the two or more utterers approaching within the predetermined distance from the communication robot; a determiner configured to determine whether a case where utterers of a wake-up word and a continuous word included in the uttered speech are the same is a first case, or whether a case where the utterers of the wake-up word and the continuous word included in the uttered speech are different is a second case by analyzing the uttered speech and the photographed image; and a signal processor configured to determine a voice reception enhancement direction for speech recognition according to the first case or the second case determined by the determiner.
12. The communication robot of claim 11, wherein the determiner includes: a first estimator configured to estimate a first utterance direction according to a detection of a position of the utterer that utters the wake-up word among the two or more utterers; a second estimator configured to estimate a second utterance direction according to a detection of a position of the utterer that utters the continuous word among the two or more utterers by analyzing the photographed images of each of the two or more utterers; and an utterer determiner configured to determine, as the first case, a case where a difference between the first utterance direction and the second utterance direction is within a reference value and determine, as the second case, a case where a difference between the first utterance direction and the second utterance direction exceeds the reference value.
13. The communication robot of claim 12, wherein the first estimator is configured to estimate the first utterance direction according to the detection of the position of the utterer uttering the wake-up word using a time delay of arrival (TDOA) algorithm which detects directions of sound sources based on a correlation of time differences in sound sources collected by a plurality of microphones in a time domain.
14. The communication robot of claim 12, wherein the second estimator is configured to estimate, as the second utterance direction, a difference value between a reference coordinate set in a camera generating the photographed images of the two or more utterers and a position coordinate of the utterer uttering the continuous word included in the photographed image generated by the camera.
15. The communication robot of claim 12, further comprising: a continuous word utterer determiner configured to track gazes of each of the two or more titterers from the photographed images of each of the two or more titterers prior to the estimating of the second utterance direction, perform lipreading recognition of each of the two or more utterers from the photographed images of each of the two or more utterers, and determine an utterer that is uttering as a result of performing the lipreading recognition as the utterer uttering the continuous word while staring at the communication robot as a result of tracking the gaze.
16. The communication robot of claim 12, wherein the signal processor is configured to further increase sensitivity of speech uttered from the first utterance direction than before, if it is determined by the determiner that the case where the difference between the first utterance direction and the second utterance direction is within the reference value is the first case.
17. The communication robot of claim 12, wherein the signal processor is configured to further increase sensitivity of speech uttered from the second utterance direction than before, if it is determined by the determiner that the case where the difference between the first utterance direction and the second utterance direction exceeds the reference value is the second case.
18. The communication robot of claim 11, further comprising: a speech recognizer configured to perform speech recognition on the continuous word after the determining of the voice reception enhancement direction.
19. The communication robot of claim 18, wherein the speech recognizer is configured to be activated in response to the reception of the wake-up word uttered by any one of the two or more utterers.
20. The communication robot of claim 19, wherein the speech recognizer is configured to generate continuous word text obtained by converting the continuous word into text, understand an utterance intention of the continuous word by performing syntactic analysis and semantic analysis on the continuous word text, generate response text using a knowledge base corresponding to the utterance intention, and convert the response text into response uttered speech in a natural language utterance form.
</claims>
</document>
