<document>

<filing_date>
2019-04-16
</filing_date>

<publication_date>
2020-10-21
</publication_date>

<priority_date>
2019-04-16
</priority_date>

<ipc_classes>
G10L21/0272,G10L25/30
</ipc_classes>

<assignee>
FRAUNHOFER
FRIEDRICH-ALEXANDER-UNIVERSITAET ERLANGEN-NUERNBERG
</assignee>

<inventors>
HABETS, EMANUEL
MACK, Wolfgang
</inventors>

<docdb_family_id>
66217806
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR DETERMINING A DEEP FILTER
</title>

<abstract>
A method for determining a deep filter comprises the following steps:• receiving a mixture;• estimating using a deep neural network the deep filter, wherein the estimating is performed, such that the deep filter, when applying to elements of the mixture, obtains estimates of respective elements of the desired representation;wherein the deep filter of at least one dimension comprises a tensor with elements.
</abstract>

<claims>
1. A method (100) for determining a deep filter (10x) of at least one-dimension, comprising: receiving (110) a mixture (10); estimating (120) using a deep neural network the deep filter (10x), wherein the estimating (120) is performed, such that the deep filter (10x), when applying to elements of the mixture (10), obtains estimates of respective elements of the desired representation (11), wherein the deep filter (10x) of at least one dimension comprises a tensor with elements (sx,y).
2. The method (100) according to claim 1, wherein the mixture (10) comprises a realor complex-valued time-frequency presentation or a feature representation of it; and wherein the desired representation (11) comprises a desired realor complex-valued time-frequency presentation or a feature representation of it.
3. The method (100) according to one of the previous claims, wherein the deep filter (10x) comprises a realor complex-valued time-frequency filter; and/or wherein the deep filter (10x) of at least one dimension is described in the short-time Fourier transform domain.
4. The method (100) according to one of the previous claims, wherein the step of estimating (120) is performed for each element of the mixture (10) or for a predetermined portion of the elements of the mixture (10).
5. The method (100) according to one of the previous claims, wherein the estimating (120) is performed for at least two sources.
6. The method (100) according to one of the previous claims, further comprising the step of defining a filter structure with its filter variables for the deep filter (10x) of at least one dimension.
7. The method (100) according to one of the previous claims, wherein the deep neural network comprises a number of output parameters equal to the number of filter values of a filter function of the deep filter (10x).
8. The method (100) according to one of the previous claims, wherein the at least one dimension are out of a group comprising time, frequency and sensor, or
wherein the at least one of the dimensions is across time or frequency.
9. The method (100) according to one of the previous claims, wherein the deep neural network comprises a batch-normalization layer, a bidirectional long short-term memory layer, a feed-forward output layer with a tanh activation and/or one or more additional layer.
10. The method (100) according to one of the previous claims, further comprising the step of training the deep neural network.
11. The method (100) according to claim 10, wherein the deep neural network is trained by optimizing of the mean squared error between a ground truth of the desired representation (11) and an estimate of the desired representation (11) ; or
wherein the deep neural network is trained by reducing the reconstruction error between the desired representation (11) and an estimate of the desired representation (11) ; or
wherein the training is performed by a magnitude reconstruction.
12. The method (100) according to one of the previous claims, wherein the estimating (120) is performed by use of the formula: wherein 2 · L + 1 is a filter dimension in the time-frame direction and 2 · I + 1 is a filter dimension in a frequency direction and is the complex conjugated 1D or 2D filter.
13. The method (100) according to claim 10, 11 or 12, wherein the training is performed by use of the following formula: wherein Xd(n, k) is the desired representation (11) and X̂d(n, k) the estimated desired representation (11), or by use of the following formula: wherein Xd(n, k) is the desired representation (11) and X̂d(n, k) is the estimated desired representation (11) .
14. The method (100) according to one of the previous claims, wherein the tensor elements (sx,y) of the deep filter (10x) are bounded in magnitude or bounded in magnitude by use of the following formula: wherein is a complex conjugated 2D filter.
15. A method (100) for filtering comprising the steps of the method (100) as defined by one of the claims 1 to 14 as well as the following steps:
applying the deep filter (10x) to the mixture (10).
16. A method (100) according to claim 15, wherein the step of applying is performed element-wise.
17. The method (100) according to claim 15 or 16, wherein the applying is performed by summing up to obtain an estimate of the desired representation (11) in a respective tensor element (sx,y).
18. The use of the method (100) according to one of claims 15 to 17 for signal extraction or for signal separation of at least two sources.
19. The use of the method (100) according to one of claims 15 to 17 for signal reconstruction.
20. Computer program for performing, when running on a computer, one of the methods according to one of claims 1 to 19.
21. An apparatus for determining a deep filter (10x), the apparatus comprising
an input for receiving (110) a mixture (10);
a deep neural network for estimating (120) the deep filter (10x) such that the deep filter (10x), when applying to elements of the mixture (10), obtains estimates of respective elements of the desired representation (11);
wherein the deep filter (10x) of at least one dimension comprises a tensor with elements (sx,y).
</claims>
</document>
