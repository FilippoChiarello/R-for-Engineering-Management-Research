<document>

<filing_date>
2017-12-26
</filing_date>

<publication_date>
2020-03-17
</publication_date>

<priority_date>
2017-12-26
</priority_date>

<ipc_classes>
B25J11/00,B25J13/00,B25J9/00,G06K9/00,G10L13/00,G10L13/02,G10L15/08,G10L15/18,G10L15/22,G10L15/26,G10L21/0208,G10L25/84
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
LENCHNER, JONATHAN
GUO, SHANG QING
</inventors>

<docdb_family_id>
66950577
</docdb_family_id>

<title>
Initiating synthesized speech outpout from a voice-controlled device
</title>

<abstract>
A system, a computer program product, and method for controlling synthesized speech output on a voice-controlled device. A sensor is used to capture an image of a face of a person. A database of previously stored images of facial features is accessed. In response to i) not recognizing the at least one person the voice-controlled device selects a first set of conversational starters; ii) recognizing the person and recognizing previous communications with the person, the voice-controlled device selects a second set of conversational starters; iii) recognizing the person and not recognizing previous communications with the person, the voice-controlled device selects a third set of conversational starters; or iv) recognizing the at least one person and recognizing previous communications with the person selecting but do not know the person's name selecting a fourth set of conversational starters. The voice controlled device outputs the selected set of conversational starters.
</abstract>

<claims>
1. A computer-implemented method on a voice-controlled device for controlling synthesized speech output, the method comprising: capturing, with a sensor, an image of a face of at least one person; accessing a database of previously stored images of facial features; in response to not recognizing the at least one person then selecting a first set of conversational starters; recognizing the at least one person and recognizing a previous communication with the person then selecting a second set of conversational starters; recognizing the at least one person and not recognizing a previous communication with the person then selecting a third set of conversational starters; recognizing the at least one person and recognizing a previous communication with the person but do not know the person's identity then selecting a fourth set of conversational starters; detecting, with at least one sensor, whether the at least one person remains within a first settable distance from the voice-controlled device; and in response to the person being detected and a settable period of time having elapsed, then outputting synthesized speech using one of the set of conversational starters.
2. The computer-implemented method of claim 1, wherein the voice-controlled device is a robot.
3. The computer-implemented method of claim 1, wherein the at least one sensor is a visible light camera sensor, an infra-red camera sensor, laser pulse-based radar sensor, an acoustical sensor, or a combination thereof.
4. The computer-implemented method of claim 1, further comprising: capturing audio input while outputting synthesized speech; in response to the captured audio is recognized as speech, pausing the outputting of synthesized speech; and not recognized as speech and above a settable background noise threshold, pausing the outputting of synthesized speech.
5. The computer-implemented method of claim 4, further comprising: filtering out the outputting of synthesized speech from the audio input.
6. The computer-implemented method of claim 4, further comprising: in response to the capture audio being not recognized as speech and a volume of the audio input below or equal to a settable background noise threshold, and the pausing of the outputting of synthesized speech being within a settable pause timeframe, resuming the outputting of synthesized speech based.
7. The computer-implemented method of claim 4, further comprising: capturing, with the sensor, a second image of the face of the person that has been previously captured and whose image was compared to the database of previously stored images of facial features; detecting that the person remains within a settable distance from the voice-controlled device; and in response to the capture audio being not recognized as speech and a volume of the audio input below or equal to a settable background noise threshold, and the pausing of the outputting of synthesized speech, and the person detected within the settable distance, resuming the outputting of synthesized speech.
8. A voice-controlled device for controlling synthesized speech output, the voice-controlled device comprising: a processor device; and a memory operably coupled to the processor device and storing computer-executable instructions causing: capturing, with a sensor, an image of a face of at least one person; accessing a database of previously stored images of facial features; in response to not recognizing the at least one person then selecting a first set of conversational starters; recognizing the at least one person and recognizing a previous communication with the person then selecting a second set of conversational starters; recognizing the at least one person and not recognizing a previous communication with the person then selecting a third set of conversational starters; recognizing the at least one person and recognizing previous communications with the person but do not know the person's identity then selecting a fourth set of conversational starters; detecting, with at least one sensor, whether the at least one person remains within a first settable distance from the voice-controlled device; and in response to the person being detected and a settable period of time having elapsed, then outputting synthesized speech using one of the set of conversational starters.
9. The voice-controlled device of claim 8, wherein the voice-controlled device is a robot.
10. The voice-controlled device of claim 8, wherein the at least one sensor is a visible light camera sensor, an infra-red camera sensor, laser pulse-based radar sensor, an acoustical sensor, or a combination thereof.
11. The voice-controlled device of claim 8, further comprising: capturing audio input while outputting synthesized speech; in response to the captured audio is recognized as speech, pausing the outputting of synthesized speech; and not recognized as speech and above a settable background noise threshold, pausing the outputting of synthesized speech based.
12. The voice-controlled device of claim 11, further comprising: filtering out the outputting of synthesized speech based from the audio input.
13. The voice-controlled device of claim 11, further comprising: in response to the capture audio being not recognized as speech and a volume of the audio input below or equal to a settable background noise threshold, and the pausing of the outputting of synthesized speech being within a settable pause timeframe, resuming the outputting of synthesized speech.
14. The voice-controlled device of claim 11, further comprising: capturing, with the sensor, a second image of the face of the person that has been previously captured and whose image was compared to the database of previously stored images of facial features; detecting that the person remains within a settable distance from the voice-controlled device; and in response to the capture audio being not recognized as synthesized speech and a volume of the audio input below or equal to a settable background noise threshold, and the pausing of the outputting of synthesized speech, and the person detected within the settable distance, resuming the outputting of synthesized speech based.
15. A computer program product for controlling synthesized speech output, the computer program product comprising: a non-transitory computer readable storage medium readable by a voice-controlled device and storing program instructions for execution by the voice-controlled device, said program instructions comprising: capturing, with a sensor, an image of a face of at least one person; accessing a database of previously stored images of facial features; in response to not recognizing the at least one person then selecting a first set of conversational starters; recognizing the at least one person and recognizing a previous communication with the person then selecting a second set of conversational starters; recognizing the at least one person and not recognizing a previous communication with the person then selecting a third set of conversational starters; recognizing the at least one person and recognizing a previous communication with the person but do not know the person's identity then selecting a fourth set of conversational starters; detecting, with at least one sensor, whether the at least one person remains within a first settable distance from the voice-controlled device; and in response to the person being detected and a settable period of time having elapsed, then outputting synthesized speech using one of the set of conversational starters.
16. The computer program product of claim 15, wherein the voice-controlled device is a robot.
17. The computer program product of claim 15, wherein the at least one sensor is a visible light camera sensor, an infra-red camera sensor, laser pulse-based radar sensor, an acoustical sensor, or a combination thereof.
18. The computer program product of claim 15, further comprising: capturing audio input while outputting synthesized speech; in response to the captured audio is recognized as speech, pausing the outputting of synthesized speech; and not recognized as speech and above a settable background noise threshold, pausing the outputting of synthesized speech.
19. The computer program product of claim 18, further comprising: filtering out the outputting of synthesized speech based on speech input from the audio input.
20. The computer program product of claim 18, further comprising: in response to the capture audio being not recognized as speech and a volume of the audio input below or equal to a settable background noise threshold, and the pausing of the outputting of synthesized speech being within a settable pause timeframe, resuming the outputting of synthesized speech.
</claims>
</document>
