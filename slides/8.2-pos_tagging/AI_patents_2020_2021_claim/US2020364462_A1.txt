<document>

<filing_date>
2020-05-13
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-13
</priority_date>

<ipc_classes>
A63B24/00,G06K9/00
</ipc_classes>

<assignee>
Hole-In-One Media, Inc.
</assignee>

<inventors>
IMES, KEVIN, R.
</inventors>

<docdb_family_id>
71094804
</docdb_family_id>

<title>
AUTONOMOUS ACTIVITY MONITORING SYSTEM AND METHOD
</title>

<abstract>
A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A processor and memory associated and in communication with the camera is disposed near the location of the activity. The system may include AI logic configured to identify a user recorded within a video frame captured by the camera. The system may also detect and identify a user when the user is located within a predetermined area. The system may include a video processing engine configured to process images within the video frame to identify the user and may modify and format the video upon identifying the user and the activity. The system may include a communication module to communicate formatted video to a remote video processing system, which may further process the video and enable access to a mobile app of the user.
</abstract>

<claims>
1. A system for automatically recording and processing an activity, the system comprising; a first remote camera disposed at a first geographic location to record a video of a first predetermined activity; a first processor and memory operatively associated with the first remote camera and in communication with the camera, the first processor and memory located near the first geographic location; a local video processing engine associated with the first processor and memory, the local video processing engine configured to process frames of video captured by the first remote camera of a first user participating in the first predetermined activity; wherein the first processor is further configured to modify the video upon identifying the first user and the first predetermined activity; a communication module capable of communicating a formatted video to a remote video processing system, the remote video processing system configured to further process the formatted video and enable access of the processed video to the first user.
2. The system of claim 1, wherein the processor is configured to detect a position of the first user using one or more of: a geofence; a GPS location; facial recognition; object recognition; clothing recognition; motion detection; RFID detection; Bluetooth detection; Wifi detection; Radar sensing; and Heat sensing.
3. The system of claim 2 further including an artificial intelligent (AI) logic accessible to the first processor and configured with logic to identify one or more users recorded within a video frame captured by the first remote camera.
4. The system of claim 2, wherein the first processor is configured to: identify the first user; automatically record the first user when the first user is positioned within a first predetermined area; associate a first recording of the first user with the first user; associate a second recording of the first user with the first user; and process the first and second recording of the first user and to define the formatted video associated with the first user.
5. The system of claim 2, wherein the first processor is configured to detect and identify a second user within the first predetermined area.
6. The system of claim 5, wherein the first processor is configured to automatically record the second user and the first processor is configured to process a recording associated with the second user.
7. The system of claim 5, wherein the first processor is configured to determine which user of the first and second user is to be recorded.
8. The system of claim 5, wherein the first processor is configured to transmit a message to the first user or the second user indicating that the first user or the second user will be recorded.
9. The system of claim 1, wherein the first processor is configured to generate a location grid over at least a portion of the first geographic location.
10. The system of claim 9, wherein the first processor is configured to detect a location of the first user within the location grid and further configured to detect a location of an object associated with the first user within the location grid.
11. The system of claim 1, wherein the first processor is configured to monitor a location of the first user while the first user is located within the first geographic location.
12. The system of claim 1, wherein the first processor is configured to add a graphical element to the first processed recording based on data associated with the recording.
13. The system of claim 12, wherein the graphical element can include one or more graphical elements added to one or more frames of the video, the graphical elements including: textual information displaying a location of the video; one or more names of the location where the video was recorded; the name of the first user; the date the video was recorded; a logo or other marketing images associated with the location; a colored trace created to show a graphic line between frames of a moving object; graphic objects; and augmented reality elements.
14. The system of claim 13, wherein the colored trace includes creating a trace for one or more of: a golf ball flight path; a football player running path; a football flight path; a soccer player running path; a soccer ball flight path; a downhill skier or snowboarder path; a swimming path of a swimmer; a swimming path of a fish caught by the first user; a boating path of a catamaran or boat racing vessel; and a biking path of a mountain or race bike.
15. A system for automatically recording and processing an activity, the system comprising; a first remote camera disposed at a first geographic location to record a video of a first predetermined activity; a first processor and memory operatively associated with the first remote camera and in communication with the camera, the first processor and memory located near the first geographic location; artificial intelligent (AI) logic accessible to the processor and configured with logic to identify a user recorded within a video frame captured by the first remote camera; a local video processing engine associated with the first processor and memory, the local video processing engine configured to process images within the video frame to identify the first user; wherein the first processor is further configured to modify the video upon identifying the first user and the first predetermined activity; and a communication module capable of communicating a formatted video to a remote video processing system, the remote video processing system configured to further process the formatted video and enable access to a mobile app of the identified first user.
16. The system of claim 15, wherein the AI logic further comprises logic capable of identifying one or more of: a golfer; a golf ball; a shirt; a shirt color; pants; a pants color; a skirt; a skirt color; a hat; a hat color; a golf glove; golf shoes; a golf cart; one or more persons in a golf cart; a golf tee; a golf club; an iron; a driver; a utility club; a putter; a wedge; a golf ball logo; a male; a female; a child; a junior; a shirt logo; a caddie; a marshal; a brand; a left handed golfer; a right handed golfer; a visor; glasses; sunglasses; a beverage; a tee box; a color of a tee box; trees; a fairway; a cart path; a green; a pin; a hole; a sand bunker; a water hazard; a grass hazard; woods; out-of-bounds; rough; a first cut of a green; a second cut of a green; birds; bugs; animals; a distance from tee to pin; a distance from tee to front of green; a distance from tee to center of green; a distance from tee to back of green; red stakes; white stakes; yellow stakes; change in elevation; clouds; rain; snow; fog; mist; mud; wind; topology of green; or cut of hole.
17. The system of claim 16, wherein the AI logic further comprises logic capable of identifying an activity including one or more of: golf activity; football activity; soccer activity; lacrosse activity; baseball activity; basketball activity; tennis activity; pickleball activity; beanbag toss activity; bowling activity; billiards activity; swimming activity; diving activity; racing activity; hockey activity; field hockey activity; disc golf activity; rugby activity; skiing activity; snowboarding activity; biking activity; fishing activity; boating activity; and sports activity.
18. The system of claim 17, wherein the remote video processing system further comprises: a remote video processing and management system in communication with the first processor, the remote video processing and management system configured to receive a first series of recorded videos and process the first series of recorded videos to create the AI logic; wherein the processing of the first series of recorded videos includes tagging one or more uniquely identified objects within one or more frames of each of the recorded videos, the tagging including tags for identifying users and user activities within the recorded video; wherein the processing further includes creating the AI logic including a neural network of tagged objects and distributing the AI logic to the first processor for use in processing video at the predetermined location; and wherein the processing further includes receiving the formatted video from the communication module and modifying the formatted video based on use of the mobile app.
19. The system of claim 15, further including a remote video processing and management system in communication with the video processing system, the remote video processing management system comprising: a network processor coupled to cloud storage storing processed video received from the video processing system and the first remote camera; an artificial intelligence (AI) enabled graphics processing engine configured to access the formatted video and process the formatted video; graphical assets accessible to the AI enabled graphics processing engine to be added to one or more frames of the formatted video; a format manager configured to format the formatted video based on a distribution location of the formatted video; and a distribution manager accessible to the network processor, the distribution manager configured to distribute the formatted video to the distribution location.
20. The system of claim 19, further comprising a mobile app associated with the distribution manager, the mobile app including content provided by the distribution manager including: one or more formatted videos output by the remote video processing and management system; a list of videos created using one or more activities; a list of location where the one or more videos were recorded; a social media feature to share the formatted video; and a virtual coaching feature configured to enable a coach to access and comment on the formatted video of the first user.
21. The system of claim 15, further comprising: wherein the processor is configured to identify a second user recorded within the video frame captured by the first remote camera; wherein the processor is configured to extract video frames from the first video, the video frames including the second user; wherein the processor is configured to combine the extracted video frames into a second formatted video, the second formatted video including the second user; and wherein the communication module communicates the second formatted video to the remote video processing system configured to further process the video and enable access to a mobile app of the identified second user.
22. The system of claim 21, wherein the remote video processing and management system is further configured to: identify the second user in proximity to the first user during the recorded activity; initiate access of a second video generated by the remote video processing system to the first user; and enable the first user access to the second video using the mobile app.
23. A method of automatically recording and providing video, the method comprising: recording a video of a predetermined activity using a first remote camera located at a first geographic location; processing the video at the first geographic location, wherein the processing includes: identifying a first user performing the predetermined activity; extracting image frames from the video including the first user during the predetermined activity; and merging the extracted image frames to generate a formatted video; and outputting the formatted video to a remote video processing system for additional processing.
24. The method of claim 23, further comprising the steps of: identifying a second user performing the predetermined activity within the video; extracting additional image frames including the second user performing the predetermined activity; merging the additional image frames to generate a second formatted video; and outputting the second formatted video to the remote video processing system.
25. The method of claim 23, further comprising: providing a second remote camera at the first geographic location; identifying the first geographic location as a golf hole on a golf course; establishing a first geofence around the tee box of the golf hole; establishing a second geofence around the green of the golf hole; detecting when a first user is within the first geofence; activating recording of the first remote camera and the second remote camera in response to identifying the first user within the first geofence to record the predetermined activity; detecting when the first user is within the second geofence; detecting when the first user leaves the second geofence; and disabling recording of the predetermined activity when the first user leaves the second geofence.
26. The method of claim 25 further comprising: wherein the first geofence includes a first geofence radius; and wherein the second geofence includes a second geofence radius that is different than the first geofence radius.
27. The method of claim 25 further comprising: wherein the first geofence includes a first geofence size; and wherein the second geofence includes a second geofence size that is different than the first geofence size.
28. The method of claim 23 further comprising: identifying the predetermined activity as a golf activity; extracting a first image frame to identify a golf ball at a first location within the first image frame; extracting a second image frame at a period of time later than the first image frame; determining if the golf ball moved to another location within the second image frame; drawing a colored line from within the second image frame that extends to the first location; repeating drawing the line with subsequent frames until the golf ball is no longer visible; estimating where the golf ball lands; and drawing a colored line to the estimated location of where the golf ball lands.
29. The method of claim 23 further comprising: creating an AI logic using previously recorded activities to identify a specific activity; identifying the specific activity using the AI logic; identifying the first user performing the specific activity; initiating extracting of image frames of the specific activity; and combining the extracted image frames of the specific activity.
30. The method of claim 29 wherein the creating an AI logic further comprises the steps of: identifying a golfer holding a golf club within a previously recorded video; tagging the golfer having specific clothes, a golf club, and a golf ball; repeating the identifying and tagging steps over numerous previously recorded activities and image frames; generating the AI logic using the tagged images; and using the AI logic at a golf course having the first remote camera.
</claims>
</document>
