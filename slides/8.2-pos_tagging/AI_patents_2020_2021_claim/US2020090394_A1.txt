<document>

<filing_date>
2019-10-17
</filing_date>

<publication_date>
2020-03-19
</publication_date>

<priority_date>
2018-09-19
</priority_date>

<ipc_classes>
G06F17/18,G06F3/01,G06F3/16,G06T13/40,G06T17/00
</ipc_classes>

<assignee>
XRSPACE COMPANY
</assignee>

<inventors>
LIN, TING-CHIEH
HONG, WEI-ZHE
KUNG, MING-YANG
CHU, FENG-SENG
</inventors>

<docdb_family_id>
69773029
</docdb_family_id>

<title>
AVATAR FACIAL EXPRESSION GENERATING SYSTEM AND METHOD OF AVATAR FACIAL EXPRESSION GENERATION FOR FACIAL MODEL
</title>

<abstract>
An avatar facial expression generating system and a method of avatar facial expression generation are provided. In the method, user data relating to sensing result of a user is obtained. A first and a second emotional configurations are determined. The first and second emotional configuration maintain during a first and a second duration, respectively. A transition emotional configuration is determined based on the first emotional configuration and the second emotional configuration, in which the transition emotional configuration maintains during a third duration. Facial expressions of an avatar are generated based on the first emotional configuration, the transition emotional configuration, and the second emotional configuration, respectively. The third duration exists between the first duration and the second duration. Accordingly, a normal facial expression on an avatar would be presented while encountering the emotion transformation.
</abstract>

<claims>
1. A method of avatar facial expression generation, comprising: obtaining user data, wherein the user data is related to sensing result of a user; determining a first emotional configuration and a second emotional configuration based on the user data, wherein the first emotional configuration maintains during a first duration, and the second emotional configuration maintains during a second duration different from the first duration; determining a transition emotional configuration based on the first emotional configuration and the second emotional configuration, wherein the transition emotional configuration maintains during a third duration different from the first duration; and generating facial expressions of an avatar based on the first emotional configuration, the transition emotional configuration, and the second emotional configuration, respectively, wherein the third duration exists between the first duration and the second duration.
2. The method of avatar facial expression generation according to claim 1, wherein the step of determining the transition emotional configuration comprises: combining the first and second emotional configurations, to generate at least one emotional combination; and determining the at least one emotional combination as the transition emotional configuration.
3. The method of avatar facial expression generation according to claim 2, wherein the at least one emotional combination is related to a weighted relation of the first and second emotional configurations.
4. The method of avatar facial expression generation according to claim 3, further comprising: dividing the third duration into a plurality of time periods; and determining the weighted relation according to a linear relation of the first and second emotional configurations, wherein the weighted relation comprises a first weight of the first emotional configuration and a second weight of the second emotional configuration, the first weight at different time periods decreases and the second weight at different time periods increases along with time based on the linear relation.
5. The method of avatar facial expression generation according to claim 1, wherein the step of generating the transition emotional configuration comprises: determining a length of the third duration according to a difference between a first emotional value of the first emotional configuration and a second emotional value of the second emotional configuration.
6. The method of avatar facial expression generation according to claim 5, further comprising: providing a plurality of emotion categories, wherein each of the emotion categories comprises at least one level, the first and second emotional configurations correspond to a first level of a first emotion of the emotion categories, and the second emotional configuration corresponds to a second level of a second emotion of the emotion categories; and determining a different between the first level of the first emotion and the second level of the second emotion as the difference between the first emotional configuration and the second emotional configuration.
7. The method of avatar facial expression generation according to claim 1, wherein the step of generating the transition emotional configuration comprises: obtaining a character of a user, wherein the facial model is an avatar of the user; and determining the third duration according to the character of the user.
8. The method of avatar facial expression generation according to claim 1, wherein the user data is voice data, and the step of determining the first and second emotional configuration comprises: determining whether a key word or a key phrase is detected in the voice data; and determining a triggering condition for the first or second emotional configuration is met in response to the key word or the key phrase being detected.
9. The method of avatar facial expression generation according to claim 1, wherein the user data is motion sensing data, and the step of determining the first and second configuration comprises: determining whether a key motion is detected in the motion sensing data; and determining a triggering condition for the first or second emotional configuration is met in response to the key motion being detected.
10. The method of avatar facial expression generation according to claim 1, wherein the user data is image data, and the step of determining the first and second configuration comprises: determining whether a key motion is detected in the image data; and determining the triggering condition is met in response to the key motion being detected.
11. The method of avatar facial expression generation according to claim 1, wherein the step of generating the facial expressions of the avatar comprises: selecting one of the facial expressions from an expression group according to a probability distribution, wherein the expression group comprises a plurality of the facial expressions.
12. The method of avatar facial expression generation according to claim 1, wherein the step of generating the facial expressions of the avatar comprises: generating the facial expressions in real-time in response to determining the first emotional configuration and the second emotional configuration.
13. An avatar facial expression generating system, comprises: an input apparatus, obtaining user data, wherein the user data is related to sensing result of a user; a memory, storing a program code; and a processor, coupled to the memory, and loading the program code to perform: determining a first emotional configuration and a second emotional configuration based on the user data, wherein the first emotional configuration maintains during a first duration, and the second emotional configuration maintains during a second duration different from the first duration; determining a transition emotional configuration based on the first emotional configuration and the second emotional configuration, wherein the transition emotional configuration maintains during a third duration different from the first duration; and generating facial expressions of an avatar based on the first emotional configuration, the transition emotional configuration, and the second emotional configuration, respectively, wherein the third duration exists between the first duration and the second duration.
14. The avatar facial expression generating system according to claim 13, wherein the processor further performs: combining the first and second emotional configurations, to generate at least one emotional combination; and determining the at least one emotional combination as the transition emotional configuration.
15. The avatar facial expression generating system according to claim 14, wherein the at least one emotional combination is related to a weighted relation of the first and second emotional configurations.
16. The avatar facial expression generating system according to claim 15, wherein the processor further performs: dividing the third duration into a plurality of time periods; and determining the weighted relation according to a linear relation of the first and second emotional configurations, wherein the weighted relation comprises a first weight of the first emotional configuration and a second weight of the second emotional configuration, the first weight at different time periods decreases and the second weight at different time periods increases along with time based on the linear relation.
17. The avatar facial expression generating system according to claim 13, wherein the processor further performs: determining a length of the third duration according to a difference between a first emotional value of the first emotional configuration and a second emotional value of the second emotional configuration.
18. The avatar facial expression generating system according to claim 17, wherein the processor further performs: providing a plurality of emotion categories, wherein each of the emotion categories comprises at least one level, the first and second emotional configurations correspond to a first level of a first emotion of the emotion categories, and the second emotional configuration corresponds to a second level of a second emotion of the emotion categories; and determining a different between the first level of the first emotion and the second level of the second emotion as the difference between the first emotional configuration and the second emotional configuration.
19. The avatar facial expression generating system according to claim 13, wherein the processor further performs: obtaining a character of a user, wherein the facial model is an avatar of the user; and determining the third duration according to the character of the user.
20. The avatar facial expression generating system according to claim 13, wherein the user data is voice data, and the processor further performs: determining whether a key word or a key phrase is detected in the voice data; and determining a triggering condition for the first or second emotional configuration is met in response to the key word or the key phrase being detected.
21. The avatar facial expression generating system according to claim 13, wherein the user data is motion sensing data, and the processor further performs: determining whether a key motion is detected in the motion sensing data; and determining a triggering condition for the first or second emotional configuration is met in response to the key motion being detected.
22. The avatar facial expression generating system according to claim 13, wherein the user data is image data, and the processor further performs: determining whether a key motion is detected in the image data; and determining the triggering condition is met in response to the key motion being detected.
23. The avatar facial expression generating system according to claim 13, wherein the processor further performs: selecting one of the facial expressions from an expression group according to a probability distribution, wherein the expression group comprises a plurality of the facial expressions.
24. The avatar facial expression generating system according to claim 13, wherein the processor further performs: generating the facial expressions in real-time in response to determining the first emotional configuration and the second emotional configuration.
</claims>
</document>
