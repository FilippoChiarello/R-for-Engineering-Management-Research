<document>

<filing_date>
2020-07-08
</filing_date>

<publication_date>
2021-01-14
</publication_date>

<priority_date>
2019-07-11
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
VENIERIS, Stylianos
KIM, Hyeji
LASKARIDIS, Stefanos
</inventors>

<docdb_family_id>
74103217
</docdb_family_id>

<title>
METHOD AND SYSTEM FOR IMPLEMENTING A VARIABLE ACCURACY NEURAL NETWORK
</title>

<abstract>
Disclosed is an electronic apparatus. The electronic apparatus includes a memory storing at least one instruction, and a processor coupled to the memory and configured to control the electronic apparatus, the processor configured to identify one of a plurality of exit points included in a neural network based on at least one constraint in at least one of processing or the electronic apparatus, process the input data via the neural network and obtain processing results output from the identified exit point as output data.
</abstract>

<claims>
1. A method for controlling an electronic apparatus, the method comprising: receiving input data; identifying one of a plurality of exit points included in a neural network based on at least one constraint in at least one of processing or the electronic apparatus; processing the input data via the neural network; and obtaining processing results output from the identified exit point as output data.
2. The method as claimed in claim 1, wherein the plurality of exit points are equidistantly spaced in the neural network.
3. The method as claimed in claim 1, wherein the identifying comprises identifying one of the plurality of exit points based on at least one of a time taken to reach each exit point or accuracy.
4. The method as claimed in claim 1, wherein the plurality of exit points are positioned in a coarse-grained or fine-grained domain of the neural network.
5. The method as claimed in claim 1, wherein the identifying comprises identifying one of a plurality of classifiers included in the neural network based on constraints in at least one of the processing or the electronic apparatus.
6. The method as claimed in claim 1, further comprising: obtaining information on at least one of a computational load of the electronic apparatus, a memory capacity of the electronic apparatus, or power consumption of the electronic apparatus, wherein the identifying comprises identifying one of the plurality of exit points based on the obtained information.
7. The method as claimed in claim 1, wherein the obtaining comprises, based on a confidence of the processing result being greater than or equal to a predetermined confidence level, obtaining the processing result as the output data.
8. The method as claimed in claim 7, further comprising: based on the confidence of the processing result being less than the predetermined confidence level, further processing the input data through a neural network after the identified exit point.
9. The method as claimed in claim 1, further comprising: receiving a command to select a low-latency mode, wherein the identifying comprises identifying one of the plurality of exit points based on time constraints corresponding to the low-latency mode.
10. The method as claimed in claim 1, further comprising: receiving a command to select a confidence-based mode, wherein the identifying comprises identifying one of the plurality of exit points based on the confidence level corresponding to the confidence-based mode.
11. The method as claimed in claim 10, further comprising: receiving an additional processing command for the processing result; additionally processing the input data through a neural network after the identified exit point; and obtaining the additionally-processed data from the neural network as the output data.
12. The method as claimed in claim 1, further comprising: calibrating the neural network based on at least one of a processing capacity of the electronic apparatus, a memory capacity of the electronic apparatus, or a power capacity of the electronic apparatus.
13. The method as claimed in claim 12, wherein the calibrating comprises reducing a number of classes used for processing the input data and outputting the processing result.
14. The method as claimed in claim 12 wherein the calibrating comprises partitioning the neural network into a first portion configured to be executed by the electronic apparatus and a second portion configured to be executed by a remote server, and wherein the obtaining comprises processing the input data through the first portion.
15. The method as claimed in claim 14, wherein based on a confidence of the processing result through the first portion being greater than or equal to the predetermined confidence level, the processing result through the first portion is obtained as the output data.
16. The method as claimed in claim 15, further comprising: based on the confidence of the processing result through the first portion being less than the predetermined confidence level, transmitting the processing result through the first portion to the remote server; and receiving, from the remote server, a result obtained by additionally processing, through the second portion, the processing result through the first portion.
17. An electronic apparatus comprising: a memory storing at least one instruction; and a processor coupled to the memory and configured to control the electronic apparatus, wherein the processor is configured to: identify one of a plurality of exit points included in a neural network based on at least one constraint in at least one of processing or the electronic apparatus; process the input data via the neural network; and obtain processing results output from the identified exit point as output data.
18. The electronic apparatus as claimed in claim 17, wherein the processor is configured to identify one of the plurality of exit points based on information on at least one of a computational load of the electronic apparatus, a memory capacity of the electronic apparatus, or power consumption of the electronic apparatus.
19. The electronic apparatus as claimed in claim 17, wherein the processor, based on a confidence of the processing result being greater than or equal to a predetermined confidence level, is configured to obtain the processing result as the output data.
20. The electronic apparatus as claimed in claim 19, wherein the processor, based on the confidence of the processing result being less than the predetermined confidence level, is configured to further processes the input data through a neural network after the identified exit point.
</claims>
</document>
