<document>

<filing_date>
2019-03-15
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2019-03-15
</priority_date>

<ipc_classes>
G06F13/16,G06F13/42,G06F9/48,G06N3/08
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
ANANTARAMAN, ARAVINDH
APPU, ABHISHEK R.
GALOPPO VON BORRIES, NICOLAS C.
KIM, SUNGYE
KOKER, ALTUG
MACPHERSON, MIKE
MAIYURAN, SUBRAMANIAM
OULD-AHMED-VALL, ELMOUSTAPHA
RANGANATHAN VASANTH
RAY, JOYDEEP
Andrei, Valentin
</inventors>

<docdb_family_id>
69740543
</docdb_family_id>

<title>
LOCAL MEMORY SHARING BETWEEN KERNELS
</title>

<abstract>
One embodiment provides for a general-purpose graphics processing unit comprising a set of processing elements to execute one or more thread groups of a second kernel to be executed by the general-purpose graphics processor, an on-chip memory coupled to the set of processing elements, and a scheduler coupled with the set of processing elements, the scheduler to schedule the thread groups of the kernel to the set of processing elements, wherein the scheduler is to schedule a thread group of the second kernel to execute subsequent to a thread group of a first kernel, the thread group of the second kernel configured to access a region of the on-chip memory that contains data written by the thread group of the first kernel in response to a determination that the second kernel is dependent upon the first kernel.
</abstract>

<claims>
1. A general-purpose graphics processor comprising: a set of processing elements to execute one or more thread groups of a second kernel to be executed by the general-purpose graphics processor; an on-chip memory coupled to the set of processing elements; and a scheduler coupled with the set of processing elements, the scheduler to schedule the thread groups of the kernel to the set of processing elements, wherein the scheduler is to schedule a second thread group of the second kernel to execute subsequent to a first thread group of a first kernel and, in response to a determination that the second kernel is dependent upon the first kernel, the second thread group is configured to access a region of the on-chip memory that contains data written by the first thread group.
2. The general-purpose graphics processor as in claim 1, wherein the scheduler is to configure the second thread group to access the region of the on-chip memory that contains data written by the first thread group in response to the determination that the second kernel is dependent upon the first kernel and that the first thread group and the second thread group have a same number of threads.
3. The general-purpose graphics processor as in claim 2, wherein the scheduler is to clear at least a portion of the on-chip memory before execution of a third thread group of a third kernel in response to a determination that the third kernel is not dependent upon the first kernel or the second kernel.
4. The general-purpose graphics processor as in claim 3, wherein the scheduler is to clear at least a portion of the on-chip memory before execution of a third thread group of a third kernel in response to a determination that the third thread group has a different number of threads than the first thread group and the second thread group.
5. The general-purpose graphics processor as in claim 4, wherein the scheduler is to bypass a clear of the region of on-chip memory that contains data written by the first thread group in response to the determination that the second kernel is dependent upon the first kernel.
6. The general-purpose graphics processor as in claim 5, wherein the first kernel is to compute output of a first layer of a neural network and write output data to the on-chip memory.
7. The general-purpose graphics processor as in claim 6, wherein the second kernel is to read the output data from the on-chip memory and compute output of a second layer of a neural network, the first layer of the neural network connected to the second layer of the neural network.
8. The general-purpose graphics processor as in claim 1, wherein the on-chip memory includes an implicitly managed cache memory and an explicitly managed shared memory.
9. A method on a parallel processor, the method comprising: receiving a first kernel and a second kernel for execution on a partition of the parallel processor; detecting that the first kernel and the second kernel have a dependency relationship; scheduling a first thread group for the first kernel and a second thread group for the second kernel for concurrent execution on the parallel processor; and enabling the first thread group and the second thread group to access overlapping regions of shared memory.
10. The method as in claim 9, additionally comprising computing output for a first layer of a neural network via the first thread group and computing output for a second layer of the neural network via the second thread group.
11. The method as in claim 9, additionally comprising scheduling a third thread group for a third kernel when the third kernel does not have a dependency relationship with the first kernel and the second kernel and preventing the third thread group from accessing a region of shared memory used by the first thread group or the second thread group.
12. The method as in claim 9, additionally comprising scheduling a third thread group for a third kernel when the third kernel has a dependency relationship with the second kernel and does not have a dependency relationship with the first kernel, wherein the third thread group and the second thread group are enabled to access overlapping regions of the shared memory.
13. The method as in claim 9, wherein the parallel processor is a general-purpose graphics processor.
14. A non-transitory machine-readable medium storing instructions to cause one or more processors to perform operations comprising: loading shader program code for compilation; detecting that the shader program calls multiple interdependent kernels using the same grid size; and marking the interdependent kernels as executable without clearing shared local memory between executions of the multiple interdependent kernels.
15. A non-transitory machine-readable medium as in claim 14, wherein the multiple interdependent kernels are to compute output of multiple successive layers of a neural network.
16. A circuit board comprising: a host interconnect; a general-purpose graphics processor coupled to the host interconnect, the general-purpose graphics processor including a set of processing elements to execute one or more thread groups of a second kernel to be executed by the general-purpose graphics processor, an on-chip memory coupled to the set of processing elements, and a scheduler coupled with the set of processing elements, the scheduler to schedule the thread groups of the kernel to the set of processing elements, wherein the scheduler is to schedule a second thread group of the second kernel to execute subsequent to a first thread group of a first kernel and, in response to a determination that the second kernel is dependent upon the first kernel, the second thread group is configured to access a region of the on-chip memory that contains data written by the first thread group; and a memory coupled to the host interconnect and the general-purpose graphics processor.
17. The circuit board as in claim 16, wherein the scheduler of the general-purpose graphics processor is to configure the second thread group to access the region of the on-chip memory that contains data written by the first thread group in response to the determination that the second kernel is dependent upon the first kernel and that the first thread group and the second thread group have a same number of threads.
18. The circuit board as in claim 17, wherein the scheduler is to clear at least a portion of the on-chip memory before execution of a third thread group of a third kernel in response to a determination that the third kernel is not dependent upon the first kernel or the second kernel or in response to a determination that the third thread group has a different number of threads than the first thread group and the second thread group.
19. The circuit board as in claim 18, wherein the scheduler is to bypass a clear of the region of on-chip memory that contains data written by the first thread group in response to the determination that the second kernel is dependent upon the first kernel.
20. The circuit board as in claim 19, wherein the first kernel is to compute output of a first layer of a neural network and write output data to the on-chip memory, and wherein the second kernel is to read the output data from the on-chip memory and compute output of a second layer of a neural network, the first layer of the neural network connected to the second layer of the neural network.
</claims>
</document>
