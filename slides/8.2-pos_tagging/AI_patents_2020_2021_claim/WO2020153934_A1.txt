<document>

<filing_date>
2019-01-21
</filing_date>

<publication_date>
2020-07-30
</publication_date>

<priority_date>
2019-01-21
</priority_date>

<ipc_classes>
G06F21/44,G06N20/00
</ipc_classes>

<assignee>
HEWLETT-PACKARD DEVELOPMENT COMPANY
INSTITUTO ATLANTICO
</assignee>

<inventors>
HECKLER, CLAUDIO ANDRE
MELO, TIAGO BARBOSA
</inventors>

<docdb_family_id>
71735832
</docdb_family_id>

<title>
FAULT PREDICTION MODEL TRAINING WITH AUDIO DATA
</title>

<abstract>
Examples of methods for fault prediction model training with audio data are described herein. In some examples, service event data and audio data corresponding to client devices are received. In some examples, a portion of the audio data is selected based on the service event data. In some examples, a machine learning model is trained for fault prediction based on the portion of audio data.
</abstract>

<claims>
1. A method, comprising:
receiving service event data and audio data corresponding to client
devices;
selecting a portion of the audio data based on the service event data; and
training a machine learning model for fault prediction based on the
portion of audio data.
2. The method of claim 1 , further comprising transmitting the trained machine learning model to the client devices.
3. The method of claim 2, further comprising receiving a predicted fault alert from a client device based on the trained machine learning model.
4. The method of claim 1 , wherein selecting the portion of the audio data comprises selecting a first portion of the audio data within a period of time from a service event.
5. The method of claim 1 , wherein the machine learning model comprises an input corresponding to an operating state of a client device, wherein the client device is to operate in a plurality of operating states.
6. The method of claim 1 , further comprising training a plurality of machine learning models including the machine learning model, wherein each of the plurality of machine learning models corresponds to an operating state of a client device.
7. The method of claim 1 , wherein parts of the audio data respectively correspond to a plurality of operating states of the client devices. 8. The method of claim 7, wherein the parts of the audio data comprise at least one subset corresponding to an idle state, a pre-heat state, a test rollers state, a paper retrieval state, a toner application state, a fusing state, or a paper ejection state.
9. The method of claim 1 , wherein the client devices are a plurality of printers.
10. The method of claim 1 , further comprising identifying a set of service events corresponding to a previously unidentified type of fault, and wherein the selecting the portion of the audio data is based on the set of service events.
11. An apparatus, comprising:
a memory to store support case data and sound data corresponding to remote client devices;
a processor coupled to the memory, wherein the processor is to:
retrieve a portion of the sound data from the memory based on the support case data; and
train a machine learning model to predict a fault based on the portion of the sound data.
12. The apparatus of claim 11 , wherein retrieving the portion of the sound data comprises locating a set of audio signatures in the sound data
corresponding to a type of support case.
13. The apparatus of claim 11 , wherein the processor is to:
validate the machine learning model based on a second portion of the sound data; and
send the machine learning model to the remote client devices in a case that the machine learning model satisfies a validation criterion. 14. A non-transitory tangible computer-readable medium storing executable code, comprising:
code to cause a processor to receive a machine learning model that is trained based on selected audio signatures corresponding to a service event; and
code to cause the processor to utilize the machine learning model to classify audio as indicating a potential fault.
15. The computer-readable medium of claim 14, further comprising code to cause the processor to transmit a predicted fault alert in response to classifying the audio as indicating the potential fault.
</claims>
</document>
