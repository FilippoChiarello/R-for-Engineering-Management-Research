<document>

<filing_date>
2019-09-09
</filing_date>

<publication_date>
2020-01-02
</publication_date>

<priority_date>
2017-03-07
</priority_date>

<ipc_classes>
A63B102/32,A63B69/36,A63B71/02,A63B71/06,G02B27/01,G06F3/01,G06N20/00,G06T13/40,G06T19/00,G06T7/20
</ipc_classes>

<assignee>
VGOLF
</assignee>

<inventors>
BENNETT, PATRICK
KUDIRKA, THOMAS
</inventors>

<docdb_family_id>
67844966
</docdb_family_id>

<title>
Mixed-reality golf tracking and simulation
</title>

<abstract>
A mixed-reality golf simulation system includes a ball-tracking sub-system to generate ball-tracking data when a golf ball is hit by a user, a near-eye display, a storage device to store images of a hole of a golf course associated with location coordinates of a plurality of locations along the hole, and a controller. The controller may direct the near-eye display to display a mixed-reality environment from the perspective of a location on the hole based on images associated with the location, receive ball-tracking data including a landing location of a ball hit by the user, alert the user if the landing location is a target pin, and direct the near-eye display to display a mixed-reality environment from the perspective of the landing location based on images associated with the landing location if the landing location is not the target pin.
</abstract>

<claims>
1. A mixed-reality golf simulation system comprising: a ball-tracking sub-system configured to generate ball-tracking data when a golf ball is hit by a user; a near-eye display with a partially-transparent display element configured to display mixed-reality virtual objects displayed over physical objects within a user field of view, wherein the near-eye display includes a user input device; a storage device to store images of a hole of a golf course from a plurality of locations along the hole, wherein the images are associated with location coordinates of the plurality of locations along the hole; and a controller communicatively coupled to the ball-tracking sub-system and the near-eye display, the controller including one or more processors configured to execute program instructions causing the one or more processors to virtually play the hole by repeatedly: directing the near-eye display to display a mixed-reality environment including a virtual reality scene from the perspective of a first location on the hole over at least a portion of the user field of view, wherein the virtual reality scene from the perspective of the first location includes images from the storage device associated with location coordinates of the first location; receiving ball-tracking data of a ball hit by the user in real-time from the ball-tracking sub-system, wherein the ball-tracking data includes a landing location of the ball associated with a shot; alerting the user that the hole is completed if the landing location of the ball is the target pin; directing the near-eye display to display the mixed-reality environment including a virtual reality scene from the perspective of the landing location of the ball over at least a portion of the user field of view if the landing location of the ball is not a target pin, wherein the virtual reality scene from the perspective of the landing location of the ball includes images from the storage device associated with location coordinates of the landing location of the ball; and receiving ball-tracking data of a ball hit by the user in real-time from the ball-tracking sub-system, wherein the ball-tracking data includes an additional landing location of the ball associated with an additional shot.
2. The mixed-reality golf simulation system of claim 1, wherein the one or more processors are further configured to execute program instructions causing the one or more processors to: direct the near-eye display to display a virtual object representing a trajectory of the ball associated with the shot.
3. The mixed-reality golf simulation system of claim 1, wherein the ball-tracking sub-system comprises: one or more sensors integrated within the ball, wherein the one or more sensors transmit the ball-tracking data to the controller via wireless communication.
4. The mixed-reality golf simulation system of claim 3, wherein the ball-tracking sub-system comprises: at least one of a motion sensor, an accelerometer, an orientation sensor, or a position sensor.
5. The mixed-reality golf simulation system of claim 1, wherein the ball-tracking sub-system generates ball-tracking data of the ball over a launch window, wherein the launch window ends when motion of the ball is hindered by a ball containment device, wherein the ball containment device comprises: at least one of a net or a screen.
6. The mixed-reality golf simulation system of claim 1, wherein the near-eye display includes one or more head orientation sensors to determine a head orientation of the user, wherein the near-eye display is configured to display an unobstructed real-world view when the one or more head orientation sensors determine that a gaze direction of the user is directed at the ball prior to the shot, wherein the near-eye display is further configured to transition to a display of the mixed reality environment when the near-eye determines that a gaze direction of the user is directed above a selected angle.
7. The mixed-reality golf simulation system of claim 6, wherein the near-eye display is configured to fade transparency values of the one or more virtual objects of the mixed reality environment based on the gaze direction of the user.
8. The mixed-reality golf simulation system of claim 1, wherein the one or more processors are further configured to execute program instructions causing the one or more processors to: direct the near-eye display to display a virtual object representing at least one of a launch velocity, a launch angle, a hook angle, a rotation axis, a rotation rate, a hang time, a carry distance, a roll distance, or a total distance associated with the shot.
9. The mixed-reality golf simulation system of claim 1, wherein the virtual reality scene comprises: an avatar associated with a remote user.
10. The mixed-reality golf simulation system of claim 1, further comprising: a user-tracking sub-system including one or more sensors to generate user-motion data indicative of motion of the user during a shot.
11. The mixed-reality golf simulation system of claim 10, wherein the one or more sensors comprise: at least one of a camera or one or more wearable sensors.
12. The mixed-reality golf simulation system of claim 10, wherein the one or more processors are further configured to execute program instructions causing the one or more processors to: direct the near-eye display to display a virtual object including an avatar representing the user after a shot, wherein the avatar simulates motion of the user during the shot based on the user-motion data.
13. The mixed-reality golf simulation system of claim 1, wherein the ball-tracking sub-system is located external to the ball.
14. The mixed-reality golf simulation system of claim 13, wherein the ball-tracking sub-system comprises: at least one of a camera, a doppler-tracking device, or a LIDAR-tracking device.
15. A mixed-reality golf simulation system comprising: a ball-tracking sub-system configured to generate ball-tracking data for golf balls hit by a user; a near-eye display with a partially-transparent display element configured to display mixed-reality virtual objects displayed over physical objects within a user field of view; and a controller communicatively coupled to the ball-tracking sub-system and the near-eye display, the controller including one or more processors configured to execute program instructions causing the one or more processors to: direct the near-eye display to display a mixed-reality environment including virtual objects within at least a portion of the user field of view, wherein at least a portion of the field of view is unobstructed to provide visualization of physical objects through the near-eye display; receive ball-tracking data for a plurality of golf balls hit by the user with a first club type of two or more club types; receive ball-tracking data for a plurality of balls hit by the user with at least a second club type of the two or more club types; train a club selector to select a club for the user based on the ball-tracking data associated with the first club type and the ball-tracking data associated with the at least a second club type; select a club for the user from any of the two or more club types based on a distance to a pin with the club selector.
16. The mixed-reality golf simulation system of claim 15, wherein select, with the club selector, clubs for the user for one or more subsequent shots based on the distance to the pin comprises: train the club selector using a machine learning technique.
17. The mixed-reality golf simulation system of claim 15, wherein the one or more processors are further configured to execute program instructions causing the one or more processors to: receive environmental conditions associated with at least a portion of the ball-tracking data; and train the club selector based on the environmental conditions.
18. The mixed-reality golf simulation system of claim 17, wherein receive environmental conditions associated with at least a portion of the ball-tracking data comprises: receive environmental conditions associated with at least a portion of the ball-tracking data from the user via a user input device.
19. The mixed-reality golf simulation system of claim 17, wherein receive environmental conditions associated with at least a portion of the ball-tracking data comprises: receive environmental conditions associated with at least a portion of the ball-tracking data from one or more environmental sensors.
20. The mixed-reality golf simulation system of claim 15, wherein the mixed-reality environment includes at least one of at least one of a fairway, a green, or a pin.
21. The mixed-reality golf simulation system of claim 15, wherein the near-eye display includes one or more head orientation sensors to determine a head orientation of the user, wherein the one or more processors are further configured to execute program instructions causing the one or more processors to: direct the near-eye display to display, based on the head orientation of the user received from the near-eye display, at least a partially unobstructed real-world view through the partially-transparent display element when the user is looking at a location from which a golf ball is to be hit.
22. The mixed-reality golf simulation system of claim 15, wherein the mixed-reality environment includes a virtual reality scene obstructing at least a portion of the field of view from a vantage point of the user at a selected location within the virtual reality scene.
23. A mixed-reality golf simulation system comprising: a ball-tracking sub-system configured to generate ball-tracking data when a golf ball is hit by a user; a user-tracking sub-system configured to generate user-tracking data when the golf ball is hit by the user; a near-eye display with a partially-transparent display element configured to display mixed-reality virtual objects displayed over physical objects within a user field of view, wherein the near-eye display includes a user input device; and a controller communicatively coupled to the golf ball-tracking sub-system and the near-eye display, the controller including one or more processors configured to execute program instructions causing the one or more processors to: direct the near-eye display to display a mixed-reality environment including virtual objects within at least a portion of the user field of view, wherein at least a portion of the field of view is unobstructed to provide visualization of physical objects through the near-eye display; receive ball-tracking data of a golf ball hit by the user in real-time from the ball-tracking sub-system; receive user-tracking data of the user as the golf ball is hit by the user in real-time from the user-tracking sub-system, wherein the user-tracking data is indicative of a motion of the user as the golf ball is hit by the user; and direct the near-eye display to display virtual objects in the mixed-reality display environment including a virtual avatar simulating the motion of the user as the golf ball is hit by the user, wherein the virtual avatar is a three-dimensional virtual object viewable from multiple angles by the user in the mixed-reality environment.
</claims>
</document>
