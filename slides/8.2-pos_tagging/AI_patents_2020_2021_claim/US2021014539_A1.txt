<document>

<filing_date>
2018-03-30
</filing_date>

<publication_date>
2021-01-14
</publication_date>

<priority_date>
2018-03-30
</priority_date>

<ipc_classes>
H04N21/218,H04N21/2343,H04N21/2662,H04N21/41,H04N21/414,H04N21/422,H04N21/4402
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
YANG YU
FLEMING, KRISTOFFER
ZHANG XU
KARACAOGLU, ULUN
GAO JIE
LIN, YUNBIAO
ZHOU, YONGFA
QIU BO
HIRANANDANI, MANISH
TANG, WENYI
YANG, JIANWEI
WANG, YATING
Frishman, Yaniv
Talmor Marcovici, Sharon
</inventors>

<docdb_family_id>
68062111
</docdb_family_id>

<title>
DYNAMIC VIDEO ENCODING AND VIEW ADAPTATION IN WIRELESS COMPUTING ENVIRONMENTS
</title>

<abstract>
An apparatus of embodiments, as described herein, includes one or more processors to track data associated with movement of a computing device accessible to a user, and evaluate the data and compare a latency with latency thresholds, where the data indicates the latency and the latency thresholds associated with a frame. The one or more processors are further to maintain a current video encoding rate, if the latency is lower than a first latency threshold and greater than a second latency threshold. The current video encoding rate is decreased if the latency is equal to or greater than the first latency threshold, where the current video encoding rate is increased if the latency is lower than the second latency threshold. The one or more processors are further to present the frame at the computing device including one or more of a wearable device and a mobile device.
</abstract>

<claims>
1. 1-19. (canceled)
20. An apparatus comprising: one or more processors to: track data associated with movement of a computing device accessible to a user; evaluate the data and compare a latency with latency thresholds, wherein the data indicates the latency and the latency thresholds associated with a frame; maintain a current video encoding rate, if the latency is lower than a first latency threshold and greater than a second latency threshold; decrease the current video encoding rate, if the latency is equal to or greater than the first latency threshold; increase the current video encoding rate if the latency is lower than the second latency threshold; and present the frame at the computing device including one or more of a wearable device and a mobile device.
21. The apparatus of claim 20, wherein the data includes one or more of motion speed, estimated frame size, and current video encoding rate, wherein the current video encoding rate is based on variable bit rate, wherein the wearable device includes a head-mounted device, wherein the mobile device includes a smartphone.
22. The apparatus of claim 21, wherein the one or more processors are further to estimate the latency threshold based on the data such that that the frame is presented and not skipped at the computing device, wherein the latency is estimated based on estimated frame size, motion speed, and a wireless link throughput, and wherein the latency thresholds are estimated based on one or more of a graphics processor rendering time, video encoding time, video decoding time, wireless network interface device schedule, and device motion-triggered activities including one or more of calibration and beamforming.
23. The apparatus of claim 20, wherein the one or more processors are further to: estimate pose and angular velocity data associated with an overdrawn frame; and calculate field of view (FOV) angular data based on the pose and velocity data associated with the overdrawn frame.
24. The apparatus of claim 23, wherein the one or more processors are further to crop and resize the overdrawn frame based on the FOV angular data, and adjust the cropped and resized overdrawn frame.
25. The apparatus of claim 24, wherein the one or more processors are further to communicate the adjusted frame and FOV angular data to the computing device to update projection matrix based on the adjusted frame and the FOV angular data, wherein the adjusted frame is presented based on the projection matrix.
26. The apparatus of claim 20, wherein the apparatus is wireles sly in communication with the computing device over a communication medium, wherein the apparatus includes one or more processors including a graphics processor co-located with an application processor on a common semiconductor package.
27. A method comprising: tracking, by a first computing device, data associated with movement of a second computing device accessible to a user; evaluating the data and compare a latency with latency thresholds, wherein the data indicates the latency and the latency thresholds associated with a frame; and maintaining a current video encoding rate, if the latency is lower than a first latency threshold and greater than a second latency threshold, wherein the current video encoding rate is decreased if the latency is equal to or greater than the first latency threshold, wherein the current video encoding rate is increased if the latency is lower than the second latency threshold; and presenting the frame at the second computing device including one or more of a wearable device and a mobile device.
28. The method of claim 27, wherein the data includes one or more of motion speed, estimated frame size, and current video encoding rate, wherein the current video encoding rate is based on variable bit rate, wherein the wearable device includes a head-mounted device, wherein the mobile device includes a smartphone.
29. The method of claim 28, further comprising estimating the latency threshold based on the data such that that the frame is presented and not skipped at the computing device, wherein the latency is estimated based on estimated frame size, motion speed, and a wireless link throughput, and wherein the latency thresholds are estimated based on one or more of a graphics processor rendering time, video encoding time, video decoding time, wireless network interface device schedule, and device motion-triggered activities including one or more of calibration and beamforming.
30. The method of claim 27, further comprising: estimating pose and angular velocity data associated with an overdrawn frame; and calculating field of view (FOV) angular data based on the pose and velocity data associated with the overdrawn frame.
31. The method of claim 30, further comprising: cropping and resizing the overdrawn frame based on the FOV angular data; and adjusting the cropped and resized overdrawn frame.
32. The method of claim 31, further comprising communicating the adjusted frame and FOV angular data to the computing device to update projection matrix based on the adjusted frame and the FOV angular data, wherein the adjusted frame is presented based on the projection matrix.
33. The method of claim 27, wherein the first computing device is wirelessly in communication with the second computing device over a communication medium, wherein the first computing device includes one or more processors including a graphics processor co-located with an application processor on a common semiconductor package.
34. A computer-readable medium having stored thereon instructions which, when executed by a first computing device, causes the first computing device to facilitate operations comprising: tracking data associated with movement of a second computing device accessible to a user; evaluating the data and compare a latency with latency thresholds, wherein the data indicates the latency and the latency thresholds associated with a frame; and maintaining a current video encoding rate, if the latency is lower than a first latency threshold and greater than a second latency threshold, wherein the current video encoding rate is decreased if the latency is equal to or greater than the first latency threshold, wherein the current video encoding rate is increased if the latency is lower than the second latency threshold, and presenting the frame at the second computing device including one or more of a wearable device and a mobile device.
35. The computer-readable medium of claim 34, wherein the data includes one or more of motion speed, estimated frame size, and current video encoding rate, wherein the current video encoding rate is based on variable bit rate, wherein the wearable device includes a head-mounted device, wherein the mobile device includes a smartphone.
36. The computer-readable medium of claim 34, wherein the operations comprise estimating the latency threshold based on the data such that that the frame is presented and not skipped at the computing device, wherein the latency is estimated based on estimated frame size, motion speed, and a wireless link throughput, and wherein the latency thresholds are estimated based on one or more of a graphics processor rendering time, video encoding time, video decoding time, wireless network interface device schedule, and device motion-triggered activities including one or more of calibration and beamforming.
37. The computer-readable medium of claim 34, wherein the operations comprise: estimating pose and angular velocity data associated with an overdrawn frame; and calculating field of view (FOV) angular data based on the pose and velocity data associated with the overdrawn frame.
38. The computer-readable medium of claim 37, wherein the operations comprise: cropping and resizing the overdrawn frame based on the FOV angular data; and adjusting the cropped and resized overdrawn frame.
39. The computer-readable medium of claim 38, further comprising communicating the adjusted frame and FOV angular data to the computing device to update projection matrix based on the adjusted frame and the FOV angular data, wherein the adjusted frame is presented based on the projection matrix.
40. The computer-readable medium of claim 34, wherein the first computing device is wireles sly in communication with the second computing device over a communication medium, wherein the first computing device includes one or more processors including a graphics processor co-located with an application processor on a common semiconductor package.
</claims>
</document>
