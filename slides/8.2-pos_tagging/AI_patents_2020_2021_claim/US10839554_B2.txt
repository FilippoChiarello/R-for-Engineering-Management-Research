<document>

<filing_date>
2018-01-05
</filing_date>

<publication_date>
2020-11-17
</publication_date>

<priority_date>
2018-01-05
</priority_date>

<ipc_classes>
B25J9/00,G06K9/00,G06K9/62,G06N3/08,G06T19/00,G06T7/73
</ipc_classes>

<assignee>
IROBOT CORPORATION
</assignee>

<inventors>
AL-MOHSSEN, HUSAIN
BASSA, ANGELA
</inventors>

<docdb_family_id>
67140841
</docdb_family_id>

<title>
Image labeling for cleaning robot deep learning system
</title>

<abstract>
A computer-implemented method for labeling images includes capturing, using an augmented-reality enabled device, a first set of images that include views of a first object; at the augmented-reality enabled device, for each of the first set of images, identifying the first object and generating a bounding box that is associated with the first object; receiving an input providing a first label for the first object; and at the augmented-reality enabled device, for each of at least some of the first set of images, associating the first label with the first object bound by the bounding box.
</abstract>

<claims>
1. A computer-implemented method comprising: receiving, at one or more data processors, a first set of images that include views of a first object; establishing a coordinate system of a virtual space that corresponds to a real-world space in which the first object is located; receiving a first input identifying the first object in one of the first set of images, the first input providing a first label for the first object, the first label indicative of an identity of the first object; receiving a second input for overlaying a virtual object on the first object in the one of the first set of images; and processing, using the one or more data processors, the other ones of the first set of images, including: automatically overlaying the virtual object on the first object in the other ones of the first set of images, automatically identifying the first object in the other ones of the first set of images based on the virtual object in the other ones of the first set of images, and automatically associating the first object with the first label.
2. The method of claim 1, further comprising training a recognition module using the first set of images as input to the recognition module, in which the first object has been associated with the first label, to generate a trained recognition module that is configured to recognize the first object in additional images.
3. The method of claim 2, wherein the first set of images include views of a mobile cleaning robot, and the method comprises: processing the first set of images to generate a second set of images such that the second set of images include top-view images of the mobile cleaning robot, and processing the top-view images of the mobile cleaning robot to identify an orientation angle of the mobile cleaning robot; and wherein training the recognition module comprises training the recognition module to recognize an orientation angle of the mobile cleaning robot in additional images.
4. The method of claim 1 in which processing the other ones of the first set of images comprises, for each of at least some of the first set of images, identifying edges of the first object and generating a bounding box that bounds the edges of the first object.
5. The method of claim 4 in which processing the other ones of the first set of images comprises identifying the bounding box in each of the images and associating the first object within the bounding box with the first label.
6. The method of claim 1, comprising for each of the other ones of the first set of images, generating a bounding box that bounds the virtual object, and associating the first object within the bounding box with the first label.
7. The method of claim 6, comprising: for each of the other ones of the first set of images, prior to generating the bounding box, determining a difference between the image with the virtual object overlaid on the first object and the image without the virtual object, and determining a size and a position of the bounding box based on the difference.
8. The method of claim 1, comprising capturing a video that includes at least one of (i) images of the first object taken from a plurality of viewing angles relative to the first object, (ii) images of the first object taken from a plurality of distances relative to the first object, or (iii) images of the first object taken under a plurality of lighting conditions for the first object, in which the first set of images comprise frames of the video.
9. The method of claim 1, comprising: displaying, on a user interface, the one of the first set of images that includes the first object, receiving, through the user interface, the first input identifying the first object, and receiving, through the user interface, the first label for the first object.
10. The method of claim 1, comprising: training a recognition module using the first set of images as input to the recognition module, in which the first object has been associated with the first label, to generate a trained recognition module that is configured to recognize the first object in additional images not included in the first set of images.
11. An apparatus comprising: an input module configured to receive a first set of images that include views of a first object; an identification module configured to receive a first input identifying the first object in one of the first set of images, the first input providing a first label for the first object, wherein the first label is indicative of an identity of the first object, and an augmented reality module configured to: establish a coordinate system of a virtual space that corresponds to a real-world space in which the first object is located, receive a second input for overlaying a virtual object on the object in the one of the first set of images, and automatically overlay the virtual object on the first object in the other ones of the first set of images; wherein the identification module is further configured to process the other ones of the first set of images to automatically identify the first object in the other ones of the first set of images based on the virtual object in the other ones of the first set of images; and a labeling module configured to associate the first object in the first set of images with the first label.
12. The apparatus of claim 11, further comprising a training module configured to train a recognition module using the first set of images, in which the first object has been associated with the first label, to generate a trained recognition module configured to recognize the first object in additional images.
13. The apparatus of claim 11 in which the identification module is configured to: for each of the other ones of the first set of images, generate a bounding box that bounds the virtual object, and wherein the labeling module is configured to associate the object within the bounding box with the first label.
14. The apparatus of claim 13 in which the identification module is configured to: for each of the other ones of the first set of images, prior to generating the bounding box, determine a difference between the image with the virtual object overlaid on the first object and the image without the virtual object, and determine a size and a position of the bounding box based on the difference.
15. The apparatus of claim 11, in which the first set of images comprise frames of a video, and the identification module is configured to identify the first object in the frames of the video.
16. The apparatus of claim 11, comprising a user interface configured to: display the one of the first set of images that includes the first object, receive the first input identifying the first object, and receive the first label for the first object.
</claims>
</document>
