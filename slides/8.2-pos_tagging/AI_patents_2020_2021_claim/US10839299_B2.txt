<document>

<filing_date>
2016-10-28
</filing_date>

<publication_date>
2020-11-17
</publication_date>

<priority_date>
2016-10-28
</priority_date>

<ipc_classes>
G06F3/01,G06F3/0484,G06N20/00,G06N5/04,G06N99/00,G16H30/20,G16H30/40,G16H40/63
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
SATI, MARWAN
</inventors>

<docdb_family_id>
62021535
</docdb_family_id>

<title>
Non-leading computer aided detection of features of interest in imagery
</title>

<abstract>
An illustrative embodiment of a computer-implemented process for non-leading computer aided detection of features of interest in a dataset, designates a particular formation using a computer recognizable gesture to identify a gestured location in an analyzed view of the dataset in response to a user identifying the particular formation in the analyzed view. The dataset is generated by a computer and representative of a portion of an object characterized by the dataset. Responsive to identifying the gestured location, the particular formation is displayed to the user, and a composition is revealed including additional structural imagery, functional imagery and findings resulting from machine learning and analysis. Responsive to revealing the composition to the user, the user is prompted to select performance of accept selection, reject selection or modify selection with regard to the particular formation displayed.
</abstract>

<claims>
1. A computer-implemented process for non-leading computer aided detection of features of interest in a dataset, the computer-implemented process comprising: generating an analyzed view of the dataset by the computer by analyzing the dataset using machine learning and analysis of the dataset and associated data derived from one of an internal source and an external source and storing results of the machine learning and analysis after predetermined checkpoints each corresponding to performing a predetermined amount of the analyzing, wherein the analyzed view includes analysis for a plurality of formations within the dataset, and wherein the analyzing using machine learning and analysis produces for the plurality of formations within the dataset additional structural imagery, functional imagery and findings including prior anatomical information of a patient, associated literature, and anatomical information correlated from other patients with a corresponding medical condition; designating a particular formation using a computer recognizable gesture to identify a gestured location in the analyzed view of the dataset associated with the particular formation, wherein the particular formation of the analyzed view of the dataset is representative of a portion of an object characterized by the dataset; displaying, by the computer, the particular formation to a user, and revealing a composition for the particular formation including additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations of the dataset, in response to identifying the gestured location, wherein when the machine learning and analysis are prior to completion, the revealing further comprising: revealing the composition for the particular formation including the additional structural imagery, functional imagery and findings up to a current point of processing; and providing additional time for completion of the machine learning and analysis in response to an indication from the user; and prompting, by the computer, the user to select performance of one of accept selection, reject selection and modify selection with regard to the composition revealed in response to revealing the composition to the user, wherein the composition includes the additional structural imagery, functional imagery and findings from the machine learning and analysis associated with the particular formation displayed.
2. The computer-implemented process of claim 1, wherein the dataset is representative of information specific to data selected from a group consisting of Medical EKG/ECG data, Medical sleep study data, and Medical pathology data.
3. The computer-implemented process of claim 1, wherein in response to a predetermined algorithm used by the computer that has not finished performing the analysis, the computer revealing what has been identified up to a current point in processing, and indicating that the predetermined algorithm has not finished; providing an indication of a current status of completion of the analysis at the current point in processing; providing an estimated time of completion of the analysis from the current point in processing; and prompting the user when finished.
4. The computer-implemented process of claim 1, wherein the computer recognizable gesture is an action including a single "mouse click" to identify the gestured location in the analyzed view, and wherein the dataset includes a medical image that conforms to a DICOM format.
5. The computer-implemented process of claim 1, wherein performing accept selection further comprises: combining the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed, with a diagnosis; and generating a report including the diagnosis.
6. The computer-implemented process of claim 1, wherein performing reject selection further comprises: prompting, by the computer, the user for selection of another gestured location in a view of the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed.
7. The computer-implemented process of claim 1, wherein performing modify selection further comprises: presenting the particular formation corresponding to the gestured location after a modification, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed.
8. A computer-implemented process for non-leading computer aided detection of features of interest in medical imagery, the computer-implemented process comprising: receiving, by a computer, one or more digital images; receiving, by the computer, one or more of patient data, other patient data, pathological data and anatomical data, wherein the pathological data and the anatomical data are derived from one of an internal source and an external source to form a dataset including the one or more digital images received; performing, by the computer, an analysis of the dataset using machine learning and storing results of the machine learning and analysis after predetermined checkpoints each corresponding to performing a predetermined amount of the analysis, wherein the analyzed data includes analysis for a plurality of formations within the dataset, and wherein the analysis using machine learning produces for the plurality of formations within the dataset additional structural imagery, functional imagery and findings including prior anatomical information of a patient, associated literature, and anatomical information correlated from other patients with a corresponding medical condition; prompting, by the computer, a user for a selection of a particular formation using a gestured location in a view of the analyzed data associated with the particular formation revealing a composition for the particular formation including additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations; presenting, by the computer, the composition corresponding to the gestured location of the user associated with the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations, wherein when the machine learning and analysis are prior to completion, the presenting further comprising: revealing the composition for the particular formation including the additional structural imagery, functional imagery and findings up to a current point of processing; and providing additional time for completion of the machine learning and analysis in response to an indication from the user; prompting, by the computer, the user for a selected action from a set of actions consisting of accept selection, reject selection and modify selection; in response to the selected action being the reject selection, further prompting the user for a selection of a new gestured location in a view of the composition for the particular formation including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations; in response to the selected action being the modify selection, presenting the composition corresponding to the gestured location of the user associated with the particular formation after a modification, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations; in response to the selected action being the accept selection, combining the composition for the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations, with a diagnosis; and generating a report.
9. A computer program product for non-leading computer aided detection of features of interest in a dataset, the computer program product comprising: one or more computer readable storage media collectively containing computer executable program code stored thereon for execution by a computer, the computer executable program code comprising: computer executable program code for generating an analyzed view of the dataset by analyzing the dataset using machine learning and analysis of the dataset and associated data derived from one of an internal source and an external source and storing results of the machine learning and analysis after predetermined checkpoints each corresponding to performing a predetermined amount of the analyzing, wherein the analyzed view includes analysis for a plurality of formations within the dataset, and wherein the analyzing using machine learning and analysis produces for the plurality of formations within the dataset additional structural imagery, functional imagery and findings including prior anatomical information of a patient, associated literature, and anatomical information correlated from other patients with a corresponding medical condition; computer executable program code, responsive to a user identifying a particular formation in the analyzed view of the dataset generated by machine learning and analysis and representative of a portion of an object characterized by the dataset, for designating the particular formation using a computer recognizable gesture to identify a gestured location in the analyzed view of the dataset associated with the particular formation; computer executable program code, responsive to identifying the gestured location, for displaying the particular formation to the user, and revealing a composition for the particular formation including additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations of the dataset, wherein when the machine learning and analysis are prior to completion, the revealing further comprising: revealing the composition for the particular formation including the additional structural imagery, functional imagery and findings up to a current point of processing; and providing additional time for completion of the machine learning and analysis in response to an indication from the user; and computer executable program code, responsive to revealing the composition for the particular formation including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis for the plurality of formations, for prompting the user to select performance of one of accept selection, reject selection and modify selection with regard to the composition revealed.
10. The computer program product of claim 9, wherein the dataset is representative of information specific to data selected from a group consisting of Medical EKG/ECG data, Medical sleep study data, and Medical pathology data.
11. The computer program product of claim 9, wherein the computer recognizable gesture is an action including a single "mouse click" to identify the gestured location in the analyzed view, and wherein the dataset includes a medical image that conforms to a DICOM format.
12. The computer program product of claim 9, wherein the computer executable program code to perform accept selection further comprises: computer executable program code for combining the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed, with a diagnosis; and computer executable program code for generating a report including the diagnosis.
13. The computer program product of claim 9, wherein the computer executable program code to perform reject selection further comprises: computer executable program code for prompting the user for a selection of another gestured location in a view of the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed.
14. The computer program product of claim 9, wherein the computer executable program code to perform modify selection further comprises: computer executable program code for presenting the particular formation corresponding to the gestured location after a modification, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed.
15. A computer program product for non-leading computer aided detection of features of interest in medical imagery, the computer program product comprising: one or more computer readable storage media collectively containing computer executable program code stored thereon for execution by a computer, the computer executable program code comprising: computer executable program code for receiving one or more digital images; computer executable program code for receiving one or more of patient data, other patient data, pathological data and anatomical data, wherein the pathological data and the anatomical data are derived from one of an internal source and an external source to form a dataset including the one or more digital images received; computer executable program code for performing an analysis of the dataset using machine learning and storing results of the machine learning and analysis after predetermined checkpoints each corresponding to performing a predetermined amount of the analysis, wherein the analyzed data includes analysis for a plurality of formations within the dataset, and wherein the analysis using machine learning produces for the plurality of formations within the dataset additional structural imagery, functional imagery and findings including prior anatomical information of a patient, associated literature, and anatomical information correlated from other patients with a corresponding medical condition; computer executable program code for prompting a user for a selection of a particular formation in a view of the analyzed data and revealing a composition for the particular formation including additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formation, wherein the selection serves as a gestured location associated with the particular formation; computer executable program code for presenting the composition corresponding to the gestured location of the user associated with the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations, wherein when the machine learning and analysis are prior to completion, the presenting further comprising: revealing the composition for the particular formation including the additional structural imagery, functional imagery and findings up to a current point of processing; and providing additional time for completion of the machine learning and analysis in response to an indication from the user; computer executable program code for prompting the user for a selected action from a set of actions consisting of accept selection, reject selection and modify selection; computer executable program code, responsive to the selected action being the reject selection, for prompting the user for a selection of a new gestured location in a view of the composition for the particular formation including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations; computer executable program code, responsive to the selected action being the modify selection, for presenting the composition corresponding to the gestured location to the user associated with the particular formation after a modification, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations; computer executable program code, responsive to the selected action being the accept selection, for combining the composition for the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations, with a diagnosis; and computer executable program code for generating a report.
16. The computer program product of claim 15, further comprising: computer executable program code for revealing what has been identified up to a current point in processing, and indicating that a predetermined algorithm is not finished when computer executable program code for the predetermined algorithm has not finished performing the analysis; computer executable program code for providing an indication of a current status of completion of the analysis at the current point in processing; computer executable program code for providing an estimated time of completion of the analysis from the current point in processing; and computer executable program code for prompting the user when finished.
17. An apparatus for non-leading computer aided detection of features of interest in a dataset, the apparatus comprising: a communications fabric; a memory connected to the communications fabric, wherein the memory contains computer executable program code; a communications unit connected to the communications fabric; an input/output unit connected to the communications fabric; a display connected to the communications fabric; and a processor unit connected to the communications fabric, wherein the processor unit executes the computer executable program code to direct the apparatus to: generate an analyzed view of the dataset by analyzing the dataset using machine learning and analysis of the dataset and associated data derived from one of an internal source and an external source and store results of the machine learning and analysis after predetermined checkpoints each corresponding to performing a predetermined amount of the analyzing, wherein the analyzed view includes analysis for a plurality of formations within the dataset, and wherein the analyzing using machine learning and analysis produces for the plurality of formations within the dataset additional structural imagery, functional imagery and findings including prior anatomical information of a patient, associated literature, and anatomical information correlated from other patients with a corresponding medical condition; designate a particular formation using a computer recognizable gesture to identify a gestured location in the analyzed view of the dataset associated with the particular formation, wherein the particular formation of the analyzed view of the dataset is representative of a portion of an object characterized by the dataset; display, by the processor unit in response to identifying the gestured location, the particular formation to a user, and reveal a composition for the particular formation including additional structural imagery, functional imagery and findings resulting from the machine learning and analysis of the plurality of formations, wherein when the machine learning and analysis are prior to completion, the revealing further comprising: revealing the composition for the particular formation including the additional structural imagery, functional imagery and findings up to a current point of processing; and providing additional time for completion of the machine learning and analysis in response to an indication from the user; and prompt the user to select performance of one of accept selection, reject selection and modify selection with regard to the composition revealed in response to revealing the composition to the user, wherein the composition includes the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed.
18. The apparatus of claim 17, wherein the dataset is representative of information specific to data selected from a group consisting of Medical EKG/ECG data, Medical sleep study data, and Medical pathology data.
19. The apparatus of claim 17, wherein the processor unit further executes the computer executable program code to direct the apparatus to: reveal what has been identified up to a current point in processing, and indicate that a predetermined algorithm is not finished when the predetermined algorithm has not finished performing the analysis; provide an indication of a current status of completion of the analysis at the current point in processing; provide an estimated time of completion of the analysis from the current point in processing; and prompt the user when finished.
20. The apparatus of claim 17, wherein the computer recognizable gesture is an action including a single "mouse click" to identify the gestured location in the analyzed view, and wherein the dataset includes a medical image that conforms to a DICOM format.
21. The apparatus of claim 17, wherein the processor unit executes the computer executable program code to direct the apparatus to perform accept selection, and to further direct the apparatus to: combine the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed, with a diagnosis; and generate a report including the diagnosis.
22. The apparatus of claim 17, wherein the processor unit executes the computer executable program code to direct the apparatus to perform reject selection, and to further direct the apparatus to: prompt the user for selection of another gestured location in a view of the particular formation, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed.
23. The apparatus of claim 17, wherein the processor unit executes the computer executable program code to direct the apparatus to perform modify selection, and to further direct the apparatus to: present the particular formation corresponding to the gestured location after a modification, including the additional structural imagery, functional imagery and findings resulting from the machine learning and analysis associated with the particular formation displayed.
</claims>
</document>
