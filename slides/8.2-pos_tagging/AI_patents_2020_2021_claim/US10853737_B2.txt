<document>

<filing_date>
2016-02-22
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2016-02-22
</priority_date>

<ipc_classes>
G06N20/00,G06N5/04,G06N99/00
</ipc_classes>

<assignee>
PRINCETON UNIVERSITY
VERMA, NAVEEN
WANG ZHUO
</assignee>

<inventors>
VERMA, NAVEEN
WANG ZHUO
</inventors>

<docdb_family_id>
59630045
</docdb_family_id>

<title>
Machine-learning classifier based on comparators for direct inference on analog sensor data
</title>

<abstract>
A weak binary classifier configured to receive an input signal for classification and generate a classification output is disclosed. The weak binary classifier includes a plurality of weighting amplifier stages, each weighting amplifier stage being configured to receive the input signal for classification and a weighting input derived from a classifier model and generate a weighted input signal, the plurality of weighting amplifier stages being configured to generate a plurality of positive weighted input signals coupled to a positive summing node and a plurality of negative weighted input signals coupled to a negative summing node. The weak binary classifier also includes a comparator having a non-inverting input coupled to the positive summing node and an inverting input coupled to the negative summing node and being configured to generate a weak classification output based on the plurality of weighted input signals.
</abstract>

<claims>
1. A strong binary classifier comprising: a plurality of weak binary classifiers, each comprising: a plurality of weighting amplifier stages, each weighting amplifier stage configured to receive an input signal for classification and generate a weighted input signal; a positive summing node and a negative summing node coupleable to the plurality of weighting amplifier stages, the positive summing node configured to generate a positive input signal for classification based on positive-weighted input signals generated from the plurality of weighting amplifier stages, the negative summing node configured to generate a negative input signal for classification based on negative-weighted input signals generated from the plurality of weighting amplifier stages; and a comparator coupled to the positive summing node and negative summing node, the comparator configured to compare a sum of the positive-weighted input signals and a sum of the negative-weighted input signals to generate a weak classification output; a digital voter coupled to the plurality of weak binary classifiers, the digital voter configured to generate a strong classification output based on the plurality of weak classification outputs; and a trainer coupled to the plurality of weak binary classifiers, the trainer configured to iteratively train the plurality of weak binary classifiers based on incorporating a non-convex optimization constraint reformulated to be solvable via quadratic programming into generating the weighted input signals to constrain a precision of the weights applied to the input signals.
2. The strong binary classifier of claim 1 wherein the trainer is further configured to train subsequent weak binary classifiers while taking into account any training errors from training prior weak classifiers to correct misclassifications.
3. The strong binary classifier of claim 1 wherein the trainer is further configured to perform Error Adaptive Classifier Boosting (EACB) to iteratively train the plurality of weak binary classifiers and take into account non-ideal aspects of hardware implementing the weak binary classifiers.
4. The strong binary classifier of claim 1, wherein each weighting amplifier stage further comprises a positive signal input and a negative signal input to control whether the weighting amplifier stage is coupled to the positive summing node or the negative summing node.
5. The strong binary classifier of claim 1, wherein each weighting amplifier stage further comprises a positive weighting amplifier and a negative weighting amplifier associated with a bit position of a weighting value derived from a classifier model.
6. The strong binary classifier of claim 1, wherein noise of each comparator is set by a capacitance of corresponding positive and negative summing nodes.
7. The strong binary classifier of claim 1, wherein the trainer is further configured to iteratively train the plurality of weak binary classifiers based on a constrained resolution regression that creates a cost function to reduce resolution required of the weights applied to the input signals.
8. The strong binary classifier of claim 1, wherein the trainer is further configured to reduce features based on Fisher's criterion.
9. A method of performing classification using a strong binary classifier, the method comprising: generating a plurality of weak classification outputs via a plurality of weak binary classifiers, each generation of a weak classification output comprising: generating a weighted input signal from a received input signal for classification via a plurality of weighting amplifier stages; generating a positive input signal for classification based on positive-weighted input signals generated from the plurality of weighting amplifier stages via a positive summing node; generating a negative input signal for classification based on negative-weighted input signal generated from the plurality of weighting amplifier stages via a negative summing node; comparing a sum of the positive-weighted input signal and a sum of the negative-weighted input signal via a comparator; generating a strong classification output based on the plurality of weak classification outputs via a digital voter; and iteratively training the plurality of weak binary classifiers via a trainer based on incorporating a non-convex optimization constraint reformulated to be solvable via quadratic programming into generating the weighted input signals to constrain a precision of the weights applied to the input signals.
10. The method of claim 9 further comprising training via the trainer subsequent weak classifiers while taking into account any training errors from training prior weak classifiers to correct misclassifications.
11. The method of claim 9 further comprising performing via the trainer Error Adaptive Classifier Boosting (EACB) to iteratively train the plurality of weak binary classifiers and take into account non-ideal aspects of hardware implementing the weak binary classifiers.
12. The method of claim 9, wherein each generation of a weak classification output further comprises controlling via a positive signal input and a negative signal input whether the weighting amplifier stage is coupled to the positive summing node or the negative summing node.
13. The method of claim 9, further comprising setting noise of each comparator by a capacitance of corresponding positive and negative summing nodes.
14. The method of claim 9, further comprising iteratively training the plurality of weak binary classifiers via a trainer based on a constrained resolution regression that creates a cost function to reduce resolution required of the weights applied to the input signals.
15. The method of claim 9, further comprising reducing features via a trainer based on Fisher's criterion.
16. A weak binary classifier configured to receive a plurality of input signals for classification and generate a weak classification output, the weak binary classifier comprising: a plurality of weighting amplifier stages, each weighting amplifier stage configured to receive an input signal for classification and generate a weighted input signal; a positive summing node and a negative summing node coupleable to the plurality of weighting amplifier stages, the positive summing node configured to generate a positive input signal for classification based on positive-weighted input signals generated from the plurality of weighting amplifier stages, the negative summing node configured to generate a negative input signal for classification based on negative-weighted input signals generated from the plurality of weighting amplifier stages; and a comparator coupled to the positive summing node and negative summing node, the comparator configured to compare a sum of the positive-weighted input signals and a sum of the negative-weighted input signals to generate a weak classification output; the weak binary classifier configured to be iteratively trained based on incorporating a non-convex optimization constraint reformulated to be solvable via quadratic programming into generating the weighted input signals to constrain a precision of the weights applied to the input signals.
17. The weak binary classifier of claim 16, further comprising a plurality of polarity switches, each polarity switch coupled to a corresponding weighting amplifier stage and configured to couple the weighted input signal of the corresponding weighting amplifier stage to the positive summing node or the negative summing node based on a polarity of the weighted input signal.
18. The weak binary classifier of claim 16, wherein the weak binary classifier is further configured to be iteratively trained based on Error Adaptive Classifier Boosting (EACB).
19. The weak binary classifier of claim 16, wherein the weak binary classifier is further configured to be iteratively trained based on a constrained resolution regression that creates a cost function to reduce resolution required of the weights applied to the input signals.
20. The weak binary classifier of claim 16, wherein the weak binary classifier is further configured to be iteratively trained based on a feature reduction via Fisher's criterion.
</claims>
</document>
