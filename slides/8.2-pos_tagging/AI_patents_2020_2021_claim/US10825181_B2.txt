<document>

<filing_date>
2019-03-29
</filing_date>

<publication_date>
2020-11-03
</publication_date>

<priority_date>
2016-12-30
</priority_date>

<ipc_classes>
G06F3/01,G06F3/0481,G06F3/0484,G06F3/16,G06K9/00,G06K9/32,G06T7/11
</ipc_classes>

<assignee>
FACEBOOK
</assignee>

<inventors>
HO, CONNIE YEEWEI
CHEUNG, VINCENT CHARLES
PALURI, BALMANOHAR
</inventors>

<docdb_family_id>
62709087
</docdb_family_id>

<title>
Image segmentation with touch interaction
</title>

<abstract>
In one embodiment, a method includes detecting one or more objects in an image, generating at least one mask for each of the detected objects, wherein each of the masks is defined by a perimeter, classifying the detected objects, receiving gesture input in relation to the image, determining whether one or more locations associated with the gesture input correlate with any of the masks, and providing feedback regarding the image in response to the gesture input. Each of the masks may include data identifying the corresponding detected object, and the perimeter of each mask may correspond to a perimeter of the corresponding detected object. The perimeter of the corresponding detected object may separate the detected object from one or more portions of the image that are distinct from the detected object.
</abstract>

<claims>
1. A method comprising: by a computing device, detecting first and second objects in an image; by the computing device, generating a first mask for the first object and a second mask for the second object, wherein each mask is defined by a corresponding perimeter; by the computing device, classifying the first and second objects, wherein the classifying identifies a first classification based on the first object and a second classification based on the second object; by the computing device, receiving first gesture input in relation to the image; by the computing device, identifying a first location associated with the first gesture input, wherein the first location corresponds to the first mask for the first object; by the computing device, identifying a relationship between the first and second objects; and by the computing device, providing first feedback regarding the image, wherein the first feedback is in response to the first gesture input and comprises a description of the relationship between the first and second objects.
2. The method of claim 1, wherein the first location associated with the first gesture input is within the perimeter that corresponds to the first mask.
3. The method of claim 1, wherein the description comprises identifications of the first and second objects based on the respective first and second classifications.
4. The method of claim 3, wherein the identifications of the first and second objects comprise names of the first and second objects, and the names are based on the first and second classifications.
5. The method of claim 1, wherein the first and second classifications are identified using an image classification algorithm.
6. The method of claim 1, wherein the relationship between the first and second objects is identified using an image segmentation or classification algorithm.
7. The method of claim 6, further comprising: by the computing device, determining a size ratio between the first and second objects, wherein the size ratio is based on the respective first and second classifications; by the computing device, determining a relative position of the first object in relation to the second object, wherein the relative position is determined based on a comparison of the relative sizes of the first and second objects in the image to the size ratio, wherein the relative position of the first object in relation to the second object indicates whether the first object is in front of or behind the second object, and the description of the relationship between the first and second objects describes the relative position of the first object in relation to the second object.
8. The method of claim 6, wherein the first location associated with the first gesture input corresponds to a region in which first and second objects overlap, wherein the detecting the first and second objects in the image is performed by the image segmentation algorithm, and the image segmentation algorithm further determines that the first object is in front of the second object, and wherein the description of the relationship between the first and second objects identifies the first and second objects and indicates that the first object is in front of the second object.
9. The method of claim 8, further comprising: by the computing device, receiving second gesture input in relation to the image, wherein the second gesture input is received subsequently to the first gesture input; by the computing device, identifying a second location associated with the second gesture input, wherein the second location corresponds to the first mask for the first object; and by the computing device, providing second feedback regarding the image, wherein the second feedback is in response to the second gesture input and identifies the second object.
10. The method of claim 9, wherein the first and second gesture inputs comprise subsequent taps in the region in which first and second objects overlap on a touch screen of the computing device.
11. The method of claim 6, wherein the second object is contained within the first object, wherein the detecting the first and second objects in the image is performed by the image segmentation algorithm, and the image segmentation algorithm further generates a list of one or more objects nested within the first object, the list of objects including the second object, and wherein the description indicates that the first object contains other objects.
12. The method of claim 11, wherein the description further comprises the names or types of the one or more objects nested within the first object.
13. The method of claim 11, wherein a size threshold is associated with one or more of the objects nested within the first object, and wherein the description further includes one or more descriptions of one or more of the objects nested within the first object that are smaller than the size threshold.
14. The method of claim 6, wherein the first object is contained within the second object, wherein the detecting the first and second objects in the image is performed by the image segmentation algorithm, and the image segmentation algorithm further generates a list of one or more objects nested within the second object, the list of objects including the first object, and wherein the description indicates that the first object is contained in the second object.
15. The method of claim 1, wherein each of the masks comprises data identifying the corresponding detected object, and the perimeter that defines each mask corresponds to a perimeter of the detected object for which the mask is generated.
16. The method of claim 1, wherein the first feedback is played as speech by an audio output component of the computing device.
17. The method of claim 1, wherein the first feedback is displayed as text by a display component of the computing device.
18. The method of claim 1, wherein the first gesture input comprises a swipe gesture across a touch screen of the computing device or a tap gesture on the touch screen, at least a portion of the gesture input is detected at the first location, and at least a portion of the image is displayed on the touch screen at the first location.
19. One or more computer-readable non-transitory storage media embodying software that is operable when executed to: detect first and second objects in an image; generate a first mask for the first object and a second mask for the second object, wherein each mask is defined by a corresponding perimeter; classify the first and second objects, wherein the classifying identifies a first classification based on the first object and a second classification based on the second object; receive first gesture input in relation to the image; identify a first location associated with the first gesture input, wherein the first location corresponds to the first mask for the first object; identify a relationship between the first and second objects; and provide first feedback regarding the image, wherein the first feedback is in response to the first gesture input and comprises a description of the relationship between the first and second objects.
20. A system comprising: one or more processors; and a memory coupled to the processors comprising instructions executable by the processors, the processors being operable when executing the instructions to: detect first and second objects in an image; generate a first mask for the first object and a second mask for the second object, wherein each mask is defined by a corresponding perimeter; classify the first and second objects, wherein the classifying identifies a first classification based on the first object and a second classification based on the second object; receive first gesture input in relation to the image; identify a first location associated with the first gesture input, wherein the first location corresponds to the first mask for the first object; identify a relationship between the first and second objects; and provide first feedback regarding the image, wherein the first feedback is in response to the first gesture input and comprises a description of the relationship between the first and second objects.
</claims>
</document>
