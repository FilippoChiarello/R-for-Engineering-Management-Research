<document>

<filing_date>
2019-12-30
</filing_date>

<publication_date>
2020-04-30
</publication_date>

<priority_date>
2018-10-18
</priority_date>

<ipc_classes>
B60W30/095,B60W40/02,B60W60/00,G06K9/00,G06K9/62
</ipc_classes>

<assignee>
CORTICA
</assignee>

<inventors>
ODINAEV, KARINA
RAICHELGAUZ, IGAL
</inventors>

<docdb_family_id>
70325357
</docdb_family_id>

<title>
SITUATION BASED PROCESSING
</title>

<abstract>
A method for situation aware processing, the method may include detecting a situation, based on first sensed information at a first period; selecting, from reference information, a situation related subset of the reference information, wherein the situation related subset of the reference information is related to the situation; and performing, by a situation related processing unit, a situation related processing, wherein the situation related processing is based on the situation related subset of the reference information and on second sensed information sensed at a second period, wherein the situation related processing comprises at least one out of object detection and object behavior estimation,
</abstract>

<claims>
We claim:
1. A method for situation aware processing, the method comprises: detecting a situation, based on first sensed information at a first period; selecting, from reference information, a situation related subset of the reference information, wherein the situation related subset of the reference information is related to the situation; and performing, by a situation related processing unit, a situation related processing, wherein the situation related processing is based on the situation related subset of the reference information and on second sensed information sensed at a second period, wherein the situation related processing comprises at least one out of object detection and object behavior estimation.
2. The method according to claim 1 wherein the selecting is followed by uploading the situation related subset of the reference information to the situation related processing unit.
3. The method according to claim 1 wherein the performing of the situation related processing comprises ignoring reference information that is not a part of the situation related subset of the reference information.
4. The method according to claim 1 wherein the reference information comprises concept structures, wherein each concept structure comprises multiple signatures and metadata related to the multiple signatures; wherein the situation related subset of the reference information comprises concept structures related to the situation.
5. The method according to claim 4 comprising: calculating one or more second signatures of the second sensed information; and searching, out of the concept structures related to the situation, for at least one matching concept structure that matches the one or more second signatures.
6. The method according to claim 5 comprising determining at least an identity of a detected object based on metadata of the at least one matching concept structure.
7. The method according to claim 5 wherein the detecting of the situation is executed without searching for matching concept structures.
8. The method according to claim 5 wherein the detecting of the situation is executed without calculating signatures of a type used in the object related processing.
9. The method according to claim 1 comprising determining, based on the situation, a relevancy value for each portion out of multiple portions of the second sensed information.
10. The method according to claim 9 comprising performing the situation related processing based on the relevancy value of the each portion.
11. The method according to claim 9 wherein the determining of the relevancy value comprises finding, for a certain type of object, a relevant portion and an irrelevant portion; and wherein the performing of the situation related processing is executed without searching for the certain type of object within the irrelevant portion.
12. The method according to claim 9 comprising determining a resolution of signatures or concept structures based on the relevancy value of the each portion.
13. The method according to claim 12 wherein the preforming of the situation related processing within the irrelevant portion is executed without using concept structures that describe the object of the certain type.
14. The method according to claim 1 wherein the detecting of the situation is executed by processing the first sensed information in a manner that differs from the performing an object detection, during the situation related processing.
15. The method according to claim 1 wherein the situation related processing is the object detection.
16. The method according to claim 1 wherein the situation related processing is the object behavior estimation.
17. The method according to claim 16 comprising determining, based at least on an outcome of the object behavior estimation and at least one autonomous driving rule, whether to apply autonomous driving or to apply human controlled driving.
18. The method according to claim 1 wherein the detecting of the situation comprises detecting a location of the vehicle.
19. The method according to claim 1 wherein the detecting of the situation comprises detecting at least one out of (a) a location of the vehicle, (b) one or more weather conditions, (c) one or more contextual parameters, (d) a road condition, (e) a traffic parameter.
20. The method according to claim 1 wherein the second period follows the first period.
21. The method according to claim 1 wherein the second period starts before an end of the first period.
22. A system for situation aware processing, the system comprises a situation related processing unit and a memory unit; wherein the memory unit is configured to store first sensed information sensed at a first period; wherein the situation related processing unit is configured to: detect a situation, based on the first sensed information, select, from reference information, a situation related subset of the reference information, wherein the situation related subset of the reference information is related to the situation; and perform a situation related processing to find detected objects, wherein the situation related processing is based on the situation related subset of the reference information and on second sensed information sensed by one or more second vehicle sensors at a second period.
23. A non-transitory computer readable medium that stores instructions for: detecting a situation, based on first sensed information at a first period; selecting, from reference information, a situation related subset of the reference information, wherein the situation related subset of the reference information is related to the situation; and performing, by a situation related processing unit, a situation related processing, wherein the situation related processing is based on the situation related subset of the reference information and on second sensed information sensed at a second period, wherein the situation related processing comprises at least one out of object detection and object behavior estimation.
24. A method for generating a hybrid representation of a media unit, the method comprises: receiving or generating the media unit; processing the media unit by performing multiple iterations, wherein at least some of the multiple iterations comprises applying, by spanning elements of the iteration, dimension expansion process that are followed by a merge operation; selecting, based on an output of the multiple iterations, media unit regions of interest that contributed to the output of the multiple iterations; and providing the hybrid representation, wherein the hybrid representation comprises shape information regarding shapes of the media unit regions of interest, and a media unit signature that comprises identifiers that identify the media unit regions of interest.
25. The method according to claim 24 wherein the selecting of the media regions of interest is executed per segment out of multiple segments of the media unit.
26. The method according to claim 24 wherein the shape information comprises polygons that represent shapes that substantially bound the media unit regions of interest.
27. The method according to claim 24 wherein the providing of the hybrid representation of the media unit comprises compressing the shape information of the media unit to provide compressed shape information of the media unit.
28. The method according to claim 27 comprising: comparing the media unit signature of the media unit to signatures of multiple concept structures to find a matching concept structure that has at least one matching signature that matches to the media unit signature; and calculating higher accuracy shape information that is related to regions of interest of the media unit, wherein the higher accuracy shape information is of higher accuracy than the compressed shape information of the media unit, wherein the calculating is based on shape information associated with at least some of the matching signatures.
29. The method according to claim 28 comprising determining shapes of the media unit regions of interest using the higher accuracy shape information.
30. The method according to claim 28 wherein for each media unit region of interest, the calculating of the higher accuracy shape information comprises virtually overlaying shapes of corresponding media units of interest of at least some of the matching signatures.
</claims>
</document>
