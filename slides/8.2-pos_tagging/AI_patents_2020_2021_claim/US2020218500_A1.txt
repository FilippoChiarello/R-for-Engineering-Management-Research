<document>

<filing_date>
2019-11-22
</filing_date>

<publication_date>
2020-07-09
</publication_date>

<priority_date>
2019-01-04
</priority_date>

<ipc_classes>
G06F16/64,G06F16/68,G06F3/16,G06F9/451
</ipc_classes>

<assignee>
HANLEY, JOSEPH THOMAS
</assignee>

<inventors>
HANLEY, JOSEPH THOMAS
</inventors>

<docdb_family_id>
71404297
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR AUDIO INFORMATION INSTRUCTION
</title>

<abstract>
A system is disclosed. The system has an audio instruction module, comprising computer-executable code stored in non-volatile memory, a processor, and a user interface. The audio instruction module, the processor, and the user interface are configured to provide a DAW environment for a user, provide a MIDI editor in the DAW environment to the user, audibly provide a sound recording to the user during a first time period, edit a first data using the MIDI editor during a second time period, compare the first data to a second data defining the sound recording, and provide a feedback data to the user, the feedback data comparing the first data to the second data. The first time period is separate from the second time period.
</abstract>

<claims>
1. A system, comprising: an audio instruction module, comprising computer-executable code stored in non-volatile memory; a processor; and a user interface; wherein the audio instruction module, the processor, and the user interface are configured to: provide a DAW environment for a user; provide a MIDI editor in the DAW environment to the user; audibly provide a sound recording to the user during a first time period; edit a first data using the MIDI editor during a second time period; compare the first data to a second data defining the sound recording; and provide a feedback data to the user, the feedback data comparing the first data to the second data; wherein the first time period is separate from the second time period.
2. The system of claim 1, wherein the audio instruction module, the processor, and the user interface are further configured to audibly provide a second sound recording to the user during the second time period, the second sound recording being based on the first data.
3. The system of claim 1, wherein the feedback data includes a first data set of song notes that are displayed to the user via the user interface in a first color, the first data set of song notes being identically included in both the first and second data.
4. The system of claim 3, wherein the feedback data includes a second data set of song notes that are displayed to the user via the user interface in a second color, the second data set of song notes being different from each other in the first and second data.
5. The system of claim 4, wherein the feedback data includes a third data set of song notes that are displayed to the user via the user interface in a third color, the third data set of song notes being included in the second data and missing from the first data.
6. The system of claim 5, wherein the feedback data includes a numerical score based on the first data set, the second data set, and the third data set.
7. The system of claim 1, wherein the audio instruction module, the processor, and the user interface are further configured to either audibly provide the sound recording to the user during the first time period or edit the first data using the MIDI editor during the second time period based on input data received from the user.
8. The system of claim 7, wherein the first time period includes a plurality of first time sub-periods and the second time period includes a plurality of second time sub-periods, each of the first time sub-periods and second time sub-periods occurring separately from each other.
9. The system of claim 8, wherein the user iteratively provides the input data controlling the audio instruction module, the processor, and the user interface to either audibly provide the sound recording to the user during the first time period or edit the first data using the MIDI editor during the second time period.
10. The system of claim 1, wherein the audio instruction module, the processor, and the user interface are further configured to display a video to the user at a time prior to the first time period and the second time period.
11. A method, comprising: providing a DAW environment for a user via a user interface; providing a MIDI editor in the DAW environment to the user; audibly providing a sound recording to the user during a first time period; editing a first data using the MIDI editor during a second time period; comparing the first data to a second data defining the sound recording; and providing feedback data to the user, the feedback data comparing the first data to the second data; wherein the first time period is separate from the second time period.
12. The method of claim 11, further comprising audibly providing a second sound recording to the user during the second time period, the second sound recording being based on the first data.
13. The method of claim 11, further comprising either audibly providing the sound recording to the user during the first time period or editing the first data using the MIDI editor during the second time period based on input data received from the user.
14. The method of claim 13, wherein the first time period includes a plurality of first time sub-periods and the second time period includes a plurality of second time sub-periods, each of the first time sub-periods and second time sub-periods occurring separately from each other.
15. The method of claim 14, wherein the user iteratively provides the input data to either audibly provide the sound recording to the user during the first time period or edit the first data using the MIDI editor during the second time period, the plurality of first time sub-periods being interspersed with the plurality of second time sub-periods.
16. A system, comprising: a music instruction module, comprising computer-executable code stored in non-volatile memory; a processor; and a user interface; wherein the music instruction module, the processor, and the user interface are configured to: provide a DAW environment for a user; provide a MIDI editor in the DAW environment to the user; audibly play a first song to the user during a first time period; edit a first data including song notes using the MIDI editor during a second time period; audibly play a second song to the user during the second time period, the second song being based on the first data; compare the first data to a second data defining the first song; and provide a feedback data to the user, the feedback data comparing the first data to the second data; wherein the first time period is separate from the second time period.
17. The system of claim 16, wherein the feedback data includes a first data set of song notes that are displayed to the user via the user interface in a first color, the first data set of song notes being identically included in both the first and second data.
18. The system of claim 17, wherein the feedback data includes a second data set of song notes that are displayed to the user via the user interface in a second color, the second data set of song notes being different from each other in the first and second data.
19. The system of claim 18, wherein the feedback data includes a third data set of song notes that are displayed to the user via the user interface in a third color, the third data set of song notes being included in the second data and missing from the first data.
20. The system of claim 19, wherein the feedback data includes a numerical score based on the first data set, the second data set, and the third data set.
</claims>
</document>
