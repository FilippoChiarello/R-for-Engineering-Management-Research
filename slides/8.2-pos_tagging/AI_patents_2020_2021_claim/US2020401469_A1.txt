<document>

<filing_date>
2019-06-19
</filing_date>

<publication_date>
2020-12-24
</publication_date>

<priority_date>
2019-06-19
</priority_date>

<ipc_classes>
G06F11/07,G06F9/451,G06K9/62
</ipc_classes>

<assignee>
KING.COM
</assignee>

<inventors>
ANDELKOVIC, ALEXANDER
REINAUDO, Alice
KARIMI, Sara
</inventors>

<docdb_family_id>
74037791
</docdb_family_id>

<title>
COMPUTER METHOD AND A COMPUTER DEVICE FOR ANALYZING COMPUTER IMPLEMENTED APPLICATIONS
</title>

<abstract>
A computer implemented method comprises analysing data defining the first image which is displayable when a computer application runs to determine at least one candidate user interactive area in the image. A user interactive area is one which is responsive to user input when the computer application is run. The method comprises attempting to interact with the determined at least one candidate user interactive area and comparing the data defining the first image with data defining a further image to determine if the respective candidate user interactive area is an interactive area.
</abstract>

<claims>
1. A computer implemented method comprising: analysing by at least one processor of a computer device data defining the first image which is displayable when a computer application runs to determine at least one candidate user interactive area in the image, a user interactive area being one which is responsive to user input when the computer application is run; causing at least one processor of the computer device to attempt to interact with the determined at least one candidate user interactive area; and comparing by the at least one processor of the computer device the data defining the first image with data defining a further image to determine if the respective candidate user interactive area is an interactive area.
2. The method as claimed in claim 1, comprising causing the further image to be displayable in response to the attempt to interact with the determined at least one candidate user interactive area
3. The method as claimed in claim 1, comprising running the computer application on at least one of the at least processor of the computer device and at least one processor of another computer device.
4. The method as claimed in claim 1, comprising capturing at least one of the data defining the first image and the further image.
5. The method as clamed in claim 1, comprising causing at least one of the first image and the further image to be displayed on a display.
6. The method as claimed in claim 1, comprising determining if the respective candidate area is an interactive area by determining a similarity between the first and further images.
7. The method as claimed in claim 1, comprising determining if the respective candidate area is an interactive area by determining if the first and further images are substantially different.
8. The method as claimed in claim 1, comprising carrying out the method steps of claim 1 for a plurality of different images displayable when the computer application runs to provide a tree relationship between the different images which is displayable.
9. The method of claim 8, comprising storing the tree relationship.
10. The method of claim 9, comprising subsequently generating a further tree relationship.
11. The method of claim 8, comprising analysing the tree relationship to determine one or more anomalies.
12. The method as claimed in claim 11, comprising comparing at least a part of the provided tree relationship with a corresponding reference tree relationship to determine one or more anomalies.
13. The method of claim 1, comprising providing at least one file, the at least one file comprising data defining a plurality of different images displayable when the computer application runs.
14. The method of claim 1 comprising analysing data defining one or more of a plurality of different images displayable when the computer application runs to determine an error condition.
15. The method of claim 14, wherein the error condition comprises one or more of missing text information and missing texture information.
16. A computer implemented method comprising: running on at least one processor of a computer device a computer application; capturing by at least one processor of the computer device data defining a first screenshot of an image caused to be displayed on a display of the device by the computer application; analysing by at least one processor of the computer device data defining the first screenshot to determine at least one candidate user interactive area in the screenshot, a user interactive area being one which is responsive to user input when the computer application is run; causing at least one processor of the computer device to attempt to interact with the determined at least one candidate user interactive area; capturing by at least one processor of the computer device data defining another screenshot of an image caused to be to be displayed on a display of the device by the computer application in response to the attempt to interact with the determined at least one candidate user interactive area; and comparing by the at least one processor of the computer device the first screenshot with the further screenshot to determine if the respective candidate user interactive area is an interactive area.
17. A computer apparatus comprising at least one processor and at least one memory including computer code for one or more programs, the at least one memory and the computer code configured, with the at least one processor, to cause the apparatus at least to: analyse the data defining the first image which is displayable when a computer application runs to determine at least one candidate user interactive area in the image, a user interactive area being one which is responsive to user input when the computer application is run; cause an to attempt to interact with the determined at least one candidate user interactive area; and compare the data defining the first image with data defining a further image to determine if the respective candidate user interactive area is an interactive area.
18. The apparatus as claimed in claim 17, wherein the at least one memory and the computer code are configured, with the at least one processor, to cause the apparatus to cause the further image to be displayable in response to the attempt to interact with the determined at least one candidate user interactive area
19. The apparatus as claimed in claim 17, wherein the at least one memory and the computer code are be configured, with the at least one processor, to cause the apparatus to determine if the respective candidate area is an interactive area by determining a similarity between the first and further images.
20. The apparatus as claimed in claim 17, wherein the at least one memory and the computer code are be configured, with the at least one processor, to cause the apparatus to carry out the steps of claim 17 for a plurality of different images displayable when the computer application runs to provide a tree relationship between the different images which is displayable.
21. The apparatus as claimed in claim 17, wherein the at least one memory and the computer code are be configured, with the at least one processor, to cause the apparatus to analyse the tree relationship to determine one or more anomalies.
22. The apparatus as claimed in claim 17, wherein the at least one memory and the computer code are be configured, with the at least one processor, to cause the apparatus to compare at least a part of the provided tree relationship with a corresponding reference tree relationship to determine one or more anomalies.
23. A computer readable non-transitory storage medium carrying one or more computer executable instructions which when run on at least one processor cause: analysing of data defining the first image which is displayable when a computer application runs to determine at least one candidate user interactive area in the image, a user interactive area being one which is responsive to user input when the computer application is run; causing an attempt to interact with the determined at least one candidate user interactive area; and comparing the data defining the first image with data defining a further image to determine if the respective candidate user interactive area is an interactive area.
</claims>
</document>
