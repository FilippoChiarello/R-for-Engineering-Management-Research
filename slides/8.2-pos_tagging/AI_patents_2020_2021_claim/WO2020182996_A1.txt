<document>

<filing_date>
2020-03-13
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2019-03-13
</priority_date>

<ipc_classes>
H04N9/31
</ipc_classes>

<assignee>
L'OREAL
</assignee>

<inventors>
BOKARIS, PANAGIOTIS-ALEXANDROS
HADDAD, MICHAEL
TRAN, LOIC
</inventors>

<docdb_family_id>
65818494
</docdb_family_id>

<title>
SYSTEMS, DEVICES, AND METHODS FOR PROJECTING DIGITAL CONTENT INCLUDING HAIR COLOR CHANGES ONTO A USER'S HEAD, FACE, OR BODY
</title>

<abstract>
In an embodiment, a virtual hair coloration system includes: a projector 22 configured to project digital content including a makeup application tutorial onto the user's hair; and a dynamic mapping unit 24; 30 operably coupled to the projector, wherein the dynamic mapping unit is configured to establish a dynamic correspondence between pixels of the projector 22 and features of the user's hair.
</abstract>

<claims>
1. A virtual hair coloration system, comprising:
a projector (22) configured to project digital content including a makeup application tutorial onto the user's hair; and
a dynamic mapping unit (24; 30) operably coupled to the projector, wherein the dynamic mapping unit is configured to establish a dynamic correspondence between pixels of the projector (22) and features of the user's hair.
2. The system according to claim 1 , wherein the dynamic correspondence between the pixels of the projector and features of the user's hair is a first dynamic correspondence, and wherein the dynamic mapping unit (24; 30) is configured to establish a second dynamic correspondence between the pixels of the projector (22) and features of the user's face.
3. The system according to claim 1 or 2, further comprising:
a dynamic distortion compensation unit (26) operably coupled to the projector (22), wherein the dynamic distortion compensation unit (26) is configured to compensate, in real time, at least one of color distortions and geometrical distortions of the user's facial surface or the user's hair.
4. The system according to any of the preceding claims, wherein the dynamic mapping unit (24; 30) comprises a depth camera configured to dynamically determine a depth contour of the user's facial surface or the user's hair.
5. The system according to claim 4, wherein the depth camera comprises at least one of a time-of-flight sensor and a Doppler-effect transducer configured to determine the depth contour of the user's hair.
6. The system according to any of the preceding claims, wherein the dynamic mapping unit (24; 30) comprises a coaxial optics setup having a beam splitter (27), wherein the beam splitter (27) is configured to direct an image of the user's facial surface or an image of the user's hair to a camera of the dynamic mapping unit, and wherein the projector is configured to project digital content including the makeup application tutorial onto the user's hair.
7. The system according to claim 6, wherein the camera is a 2D camera, and wherein the dynamic mapping (24; 30) is configured to establish the dynamic correspondence between individual pixels of the projector and features of the user's facial surface irrespective of a depth contour of the user's face or the user's hair.
8. The system according to any of the preceding claims, wherein the projector (22) is configured to project at least a first virtual object and a second virtual object, the second virtual object indicative of different environmental lighting condition from the first virtual object.
9. The system according to any of the preceding claims, wherein the dynamic correspondence with the depth-resolved digital representation of the user's hair includes the dynamic correspondence with at least one facial landmark.
10. The system according to any of the preceding claims, wherein the dynamic correspondence with the depth-resolved digital representation of the user's hair includes the dynamic correspondence with at least one partial three-dimensional representation of the user's hair.
11. The system according to any of the preceding claims, wherein the dynamic correspondence with the depth-resolved digital representation of the user's hair includes the dynamic correspondence with at least one of a facial landmark, a wrinkle, a skinfold, or an anatomical feature in a facial image.
12. A method of projecting digital content including a makeup application tutorial onto a user, comprising:
establishing, by a dynamic mapping unit, a dynamic correspondence between pixels of a projector and features of a user's hair, wherein the dynamic mapping unit is operably coupled to the projector; and
projecting, by the projector, digital content including the makeup application tutorial onto the user's hair.
13. The method according to claim 12, wherein establishing, by the dynamic mapping unit, the dynamic correspondence between pixels of the projector and features of the user's hair includes projecting a light pattern that comprises a structured light projection, a structured code projection, a light strip projection, a spatially-encoded pattern, a temporally-encoded pattern or a reference image projection.
14. The method according to claim 12 or 13, wherein establishing, by the dynamic mapping unit, the dynamic correspondence between pixels of the projector and features of the user's hair includes generating a depth-resolved digital representation of at least a portion of the user's hair.
15. The method according to any of the preceding claims 12 to 14, wherein projecting digital content including the makeup application tutorial includes projecting digitally generated, content representative of a hair styling process.
</claims>
</document>
