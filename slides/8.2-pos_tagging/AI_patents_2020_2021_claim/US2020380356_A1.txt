<document>

<filing_date>
2018-02-09
</filing_date>

<publication_date>
2020-12-03
</publication_date>

<priority_date>
2017-02-23
</priority_date>

<ipc_classes>
G06F17/18,G06N20/00,G06N3/08
</ipc_classes>

<assignee>
SONY CORPORATION
</assignee>

<inventors>
YOSHIYAMA, KAZUKI
</inventors>

<docdb_family_id>
63253269
</docdb_family_id>

<title>
INFORMATION PROCESSING APPARATUS, INFORMATION PROCESSING METHOD, AND PROGRAM
</title>

<abstract>
There is provided an information processing apparatus, an information processing method, and a program for enabling quantization with high accuracy. Quantization is performed assuming that a distribution of values calculated by a machine learning operation is based on a predetermined probability distribution. The operation is an operation in deep learning, and the quantization is performed on the basis of a notion that a distribution of gradients calculated by the operation based on the deep learning is based on the predetermined probability distribution. The quantization is performed when a value obtained by learning in one apparatus is supplied to another apparatus in distributed learning in which machine learning is performed by a plurality of apparatuses in a distributed manner. The present technology can be applied to an apparatus that performs machine learning such as deep learning in a distributed manner.
</abstract>

<claims>
1. An information processing apparatus that performs quantization assuming that a distribution. of values calculated by a machine learning operation is based on a predetermined probability distribution.
2. The information processing apparatus according to claim 1, wherein the operation is an operation in deep learning, and the quantization is performed on a basis of a notion that a distribution of gradients calculated by the operation based on the deep learning is based on the predetermined probability distribution.
2. The information processing apparatus according to claim 1, wherein the quantization is performed when a value obtained by learning in one apparatus is supplied to another apparatus in distributed learning in which machine learning is performed by a plurality of apparatuses in a distributed manner,
4. The information processing apparatus according to claim 1, wherein the predetermined probability distribution is a distribution that forms a left-right symmetrical graph with a peak value as a central axis.
5. The information processing apparatus according to claim 1, wherein the predetermined probability distribution is a distribution for which one mean or one median is calculable.
6. The information processing apparatus according to claim 1, wherein the predetermined probability distribution is any one of a normalized distribution, a Laplace distribution, a Cauchy distribution, and a Student-T distribution.
7. The information processing apparatus according to claim 1, wherein a constant of a function of the predetermined probability distribution is obtained from the calculated values.
8. The information processing apparatus according to claim 1, wherein a ratio of quantization is set, a value in the predetermined probability distribution, the value corresponding to the ratio, is set as a threshold value, and a value equal to or larger than the threshold value or equal to or smaller than the threshold value of the calculated values is extracted.
9. The information processing apparatus according to claim 2, wherein the quantization is performed for the gradient itself as a quantization target or for a cumulative gradient obtained by cumulatively adding the gradients as a quantization target.
10. An information processing method comprising a step of performing quantization assuming that a distribution of values calculated by a machine learning operation is based on a predetermined probability distribution.
11. A program for causing a computer to execute processing including a step of performing quantization assuming that a distribution of values calculated by a machine learning operation is based on a predetermined probability distribution.
</claims>
</document>
