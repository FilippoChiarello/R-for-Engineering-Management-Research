<document>

<filing_date>
2019-10-14
</filing_date>

<publication_date>
2020-02-06
</publication_date>

<priority_date>
2017-11-14
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
TENCENT TECHNOLOGY (SHENZHEN) COMPANY
</assignee>

<inventors>
WANG, XUXIANG
NIE, DAN
</inventors>

<docdb_family_id>
66494844
</docdb_family_id>

<title>
SUMMARY OBTAINING METHOD, APPARATUS, AND DEVICE, AND COMPUTER-READABLE STORAGE MEDIUM
</title>

<abstract>
A summary obtaining method includes obtaining a target document from which a summary is to be obtained; dividing the target document into sentences and dividing each sentence into words; and obtaining a classifier constructed based on a long short-term memory (LSTM) model. The classifier comprises a word-level LSTM layer configured to determine a vector of each sentence according to the words in each sentence, and a sentence-level LSTM layer configured to determine a vector of the target document according to the vector of each sentence. The method further includes determining, by using the classifier, a probability that each sentence is a summary sentence, according to the vector of the target document and a vector of the sentence; and determining a sentence with the probability satisfying a predetermined condition for a summary sentence, as a summary sentence of the target document, and forming the summary according to the summary sentence.
</abstract>

<claims>
1. A summary obtaining method applied to a computer device, comprising: obtaining a target document from which a summary is to be obtained; dividing the target document into sentences and dividing each sentence into words; obtaining a classifier constructed based on a long short-term memory (LSTM) model, wherein the classifier comprises a word-level LSTM layer and a sentence-level LSTM layer, the word-level LSTM layer is configured to determine a vector of each sentence according to the words in each sentence, the sentence-level LSTM layer is configured to determine a vector of the target document according to the vector of each sentence; determining, by using the classifier, a probability that each sentence is a summary sentence, according to the vector of the target document and a vector of the sentence; and determining, in the sentences, a sentence with the probability satisfying a predetermined condition for a summary sentence, as a summary sentence of the target document, and forming the summary of the target document according to the summary sentence of the target document.
2. The method according to claim 1, wherein the vector of the target document is a mean vector of splicing vectors of the sentences, and the splicing vectors comprise forward vectors and backward vectors of the sentences; and each sentence comprises a title of the target document, a vector of the title is a mean vector of splicing vectors of words in the title, and the splicing vectors of the words in the title comprise forward vectors and backward vectors of the words in the title.
3. The method according to claim 2, wherein the determining, by using the classifier, a probability that each sentence is a summary sentence comprises: determining a first similarity according to the vector of the target document and the vector of each sentence, wherein the first similarity is a similarity between each sentence and the target document; determining a second similarity according to the vector of the target document and the vector of the title, wherein the second similarity is a similarity between the title and the target document; determining a third similarity according to the vector of the title and the vector of each sentence, wherein the third similarity is a similarity between each sentence and the title; and determining, according to the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence.
4. The method according to claim 3, wherein: the method further comprises: determining richness of sentence content of each sentence and determining a location of each sentence in the target document; and the determining, according to the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence further comprises: determining, according to the richness of sentence content of each sentence, the location of each sentence in the target document, the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence.
5. The method according to claim 1, wherein the dividing the target document into sentences and dividing each sentence into words comprises: dividing the target document into sentences according to boundary separators between sentences in the target document; dividing each sentence into word sets; and removing words that do not participate in semantic analysis in the word sets, to obtain each sentence used for determining the probability and words participating in the semantic analysis in each sentence.
6. The method according to claim 1, wherein the classifier is trained by: obtaining a document used for training the classifier; dividing the document into sentences and dividing each sentence into words; inputting each sentence to the long short-term memory (LSTM) model, to obtain a vector expression of the document, the vector expression of the document comprising parameters in the LSTM model; and minimizing a cost function by using the vector expression of the document to determine the parameters in the LSTM model to obtain the classifier for summary extraction.
7. The method according to claim 6, wherein the dividing the document into sentences and dividing each sentence into words comprises: dividing the document into sentences according to boundary separators between sentences in the document; dividing each sentence into word sets; and removing words that do not participate in semantic analysis in the word sets, to obtain each sentence used for training the classifier and words participating in the semantic analysis in each sentence.
8. A computer device for obtaining summaries of documents, comprising: an input/output (I/O) interface; a memory storing computer program instructions; and a processor coupled to I/O interface and to the memory and, when executing the computer program instructions, configured to perform: obtaining a target document from which a summary is to be obtained via the I/O interface; dividing the target document into sentences and dividing each sentence into words; obtaining a classifier constructed based on a long short-term memory (LSTM) model, wherein the classifier comprises a word-level LSTM layer and a sentence-level LSTM layer, the word-level LSTM layer is configured to determine a vector of each sentence according to the words in each sentence, the sentence-level LSTM layer is configured to determine a vector of the target document according to the vector of each sentence; determining, by using the classifier, a probability that each sentence is a summary sentence, according to the vector of the target document and a vector of the sentence; and determining, in the sentences, a sentence with the probability satisfying a predetermined condition for a summary sentence, as a summary sentence of the target document, and forming the summary of the target document according to the summary sentence of the target document.
9. The computer device according to claim 8, wherein the vector of the target document is a mean vector of splicing vectors of the sentences, and the splicing vectors comprise forward vectors and backward vectors of the sentences; and each sentence comprises a title of the target document, a vector of the title is a mean vector of splicing vectors of words in the title, and the splicing vectors of the words in the title comprise forward vectors and backward vectors of the words in the title.
10. The computer device according to claim 9, wherein the determining, by using the classifier, a probability that each sentence is a summary sentence comprises: determining a first similarity according to the vector of the target document and the vector of each sentence, wherein the first similarity is a similarity between each sentence and the target document; determining a second similarity according to the vector of the target document and the vector of the title, wherein the second similarity is a similarity between the title and the target document; determining a third similarity according to the vector of the title and the vector of each sentence, wherein the third similarity is a similarity between each sentence and the title; and determining, according to the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence.
11. The computer device according to claim 10, wherein: the processor is further configured to perform: determining richness of sentence content of each sentence and determining a location of each sentence in the target document; and the determining, according to the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence further comprises: determining, according to the richness of sentence content of each sentence, the location of each sentence in the target document, the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence.
12. The computer device according to claim 8, wherein the dividing the target document into sentences and dividing each sentence into words comprises: dividing the target document into sentences according to boundary separators between sentences in the target document; dividing each sentence into word sets; and removing words that do not participate in semantic analysis in the word sets, to obtain each sentence used for determining the probability and words participating in the semantic analysis in each sentence.
13. The computer device according to claim 8, wherein the classifier is trained by: obtaining a document used for training the classifier; dividing the document into sentences and dividing each sentence into words; inputting each sentence to the long short-term memory (LSTM) model, to obtain a vector expression of the document, the vector expression of the document comprising parameters in the LSTM model; and minimizing a cost function by using the vector expression of the document to determine the parameters in the LSTM model to obtain the classifier for summary extraction.
14. The computer device according to claim 13, wherein the dividing the document into sentences and dividing each sentence into words comprises: dividing the document into sentences according to boundary separators between sentences in the document; dividing each sentence into word sets; and removing words that do not participate in semantic analysis in the word sets, to obtain each sentence used for training the classifier and words participating in the semantic analysis in each sentence.
15. A non-transitory computer-readable storage medium storing computer program instructions executable by at least one processor to perform: obtaining a target document from which a summary is to be obtained; dividing the target document into sentences and dividing each sentence into words; obtaining a classifier constructed based on a long short-term memory (LSTM) model, wherein the classifier comprises a word-level LSTM layer and a sentence-level LSTM layer, the word-level LSTM layer is configured to determine a vector of each sentence according to the words in each sentence, the sentence-level LSTM layer is configured to determine a vector of the target document according to the vector of each sentence; determining, by using the classifier, a probability that each sentence is a summary sentence, according to the vector of the target document and a vector of the sentence; and determining, in the sentences, a sentence with the probability satisfying a predetermined condition for a summary sentence, as a summary sentence of the target document, and forming the summary of the target document according to the summary sentence of the target document.
16. The non-transitory computer-readable storage medium according to claim 15, wherein the vector of the target document is a mean vector of splicing vectors of the sentences, and the splicing vectors comprise forward vectors and backward vectors of the sentences; and each sentence comprises a title of the target document, a vector of the title is a mean vector of splicing vectors of words in the title, and the splicing vectors of the words in the title comprise forward vectors and backward vectors of the words in the title.
17. The non-transitory computer-readable storage medium according to claim 16, wherein the determining, by using the classifier, a probability that each sentence is a summary sentence comprises: determining a first similarity according to the vector of the target document and the vector of each sentence, wherein the first similarity is a similarity between each sentence and the target document; determining a second similarity according to the vector of the target document and the vector of the title, wherein the second similarity is a similarity between the title and the target document; determining a third similarity according to the vector of the title and the vector of each sentence, wherein the third similarity is a similarity between each sentence and the title; and determining, according to the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence.
18. The non-transitory computer-readable storage medium according to claim 17, wherein: the computer program instructions are executable by the at least one processor to further perform: determining richness of sentence content of each sentence and determining a location of each sentence in the target document; and the determining, according to the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence further comprises: determining, according to the richness of sentence content of each sentence, the location of each sentence in the target document, the first similarity, the second similarity, and the third similarity, the probability that each sentence is a summary sentence.
</claims>
</document>
