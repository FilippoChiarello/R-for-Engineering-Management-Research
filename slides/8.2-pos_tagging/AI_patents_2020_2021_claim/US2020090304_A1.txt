<document>

<filing_date>
2019-05-03
</filing_date>

<publication_date>
2020-03-19
</publication_date>

<priority_date>
2018-09-13
</priority_date>

<ipc_classes>
G06T3/40,G06T7/00
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
KIM, YONGDEOK
CHOI, TAELIM
LEEM, CHOONSIK
</inventors>

<docdb_family_id>
69774164
</docdb_family_id>

<title>
NON-TRANSITORY COMPUTER-READABLE MEDIUM AND METHOD FOR MONITORING A SEMICONDUCTOR FABRICATION PROCESS
</title>

<abstract>
A non-transitory computer-readable medium for monitoring a semiconductor fabrication process includes an image conversion model having an artificial neural network. The image conversion model, when executed, causes the processor to receive a first image and a second image of a semiconductor wafer. The artificial neural network is trained by inputting a dataset representing the first image and the second image, generating a conversion image of the semiconductor wafer and calibrating weights and biases of the artificial neural network to match the conversion image to the second image. A third image of the semiconductor wafer is generated based on the calibrated weights and biases of the artificial neural network. The image conversion model with the trained artificial neural network may be transmitted to another device for image conversion of low resolution images.
</abstract>

<claims>
1. A non-transitory computer-readable medium for monitoring a semiconductor fabrication process comprising: an image conversion model stored on the non-transitory computer-readable medium, the image conversion model having an artificial neural network, wherein the image conversion model includes instructions executable by at least one processor, the instructions when executed by the at least one processor, causes the processor to perform: receiving a first image and a second image of a semiconductor wafer, the first image and the second image being generated by a measuring device, wherein the second image has a higher resolution than the first image; training the artificial neural network by: inputting a dataset representing the first image and the second image; generating a conversion image of the semiconductor wafer based on the first image, the conversion image having a higher resolution than the first image; calibrating weights and biases of the artificial neural network to match the conversion image to the second image within a predetermined differential reference value; and generating a third image of the semiconductor wafer based on the calibrated weights and biases of the artificial neural network.
2. The non-transitory computer-readable medium of claim 1, wherein the first image and the second image are measured at the same location of the semiconductor wafer by the measuring device.
3. The non-transitory computer-readable medium of claim 1, wherein the generation of the conversion image includes: generating first feature map data associated with the first image, based on first weights of the weights and first biases of the biases; mapping the first feature map data onto second feature map data, based on second weights of the weights and second biases of the biases; and reconstructing the second feature map data to the conversion image, based on third weights of the weights and third biases of the biases.
4. The non-transitory computer-readable medium of claim 1, wherein the processor executing the image conversion model is configured to compare the conversion image to the second image by using Equation 1 to determine differences between the conversion image and the second image. wherein, in Equation 1, W is weights of the artificial neural network, B is biases of the artificial neural network, C is the conversion image, H is the second image, n is a number of images received by the processor of the semiconductor wafer, and L is a loss function.
5. The non-transitory computer-readable medium of claim 3, wherein the generating of the first feature map data includes performing a first convolution operation associated with the first image and the first weights and a first addition operation associated with a first result of the first convolution operation and the first biases, wherein the mapping of the first feature map data onto the second feature map data includes performing a second convolution operation associated with the first feature map data and the second weights and a second addition operation associated with a second result of the second convolution operation and the second biases, and wherein the reconstructing of the second feature map data to the conversion image includes performing a third convolution operation associated with the second feature map data and the third weights and a third addition operation associated with a third result of the third convolution operation and the third biases.
6. The non-transitory computer-readable medium of claim 5, wherein: the first convolution operation is performed by using Equation 2; the second convolution operation is performed by using Equation 3; and the third convolution operation is performed by using Equation 4.
description="In-line Formulae" end="lead"?F1(I)=max(0,W1*I+B1)<Equation 2>description="In-line Formulae" end="tail"? wherein, in Equation 2, F1(I) is the first feature map data, W1 is the first weights, * is a convolution operation, I is the first image, and B1 is the first biases.
description="In-line Formulae" end="lead"?F2(I)=max(0,W2*F1(I)+B2 <Equation 3>description="In-line Formulae" end="tail"? wherein, in Equation 3, F2(I) is the second feature map data, W2 is the second weights, * is a convolution operation, F1(I) is the first feature map data, and B2 is the second biases.
description="In-line Formulae" end="lead"?F2(I)=W3*F2(I)+B3 <Equation 4>description="In-line Formulae" end="tail"? wherein, in Equation 4, F3(I) is the third feature map data, W3 is the third weights, * is a convolution operation, F2(I) is the second feature map data, and B3 is the third biases.
7. The non-transitory computer-readable medium of claim 1, wherein: the measuring device is a scanning electron microscope; and the artificial neural network is a super resolution convolutional neural network (SRCNN) including a first layer based on first weights and first biases, a second layer based on second weights and second biases, and a third layer based on third weights and third biases.
8. The non-transitory computer-readable medium of claim 1, wherein: the processor executing the image conversion model is configured to send a copy of the image conversion model having the trained artificial neural network to a first device; and the first device is configured to generate a first high-resolution converted image from a first low-resolution image of a second semiconductor wafer.
9. The non-transitory computer-readable medium of claim 8, wherein a second device is configured to: receive the first high-resolution converted image from the first device; compare the first high-resolution converted image with a high-resolution reference image; and signal to the first device that the artificial neural network of the image conversion model needs re-calibrating if differences between the first high-resolution converted image and the high-resolution reference image is greater than a predetermined re-calibration differential reference value.
10. The non-transitory computer-readable medium of claim 1, wherein the image conversion model is further configured to cause the at least one processor to correct an offset between the first image and the second image.
11. The non-transitory computer-readable medium of claim 8, wherein a time necessary for the first device to generate the first high-resolution converted image is less than a time necessary for the measuring device to generate the second image.
12. The non-transitory computer-readable medium of claim 1, wherein the at least one processor is included in the measuring device.
13. A method of converting an image of a semiconductor wafer to monitor a semiconductor fabrication process, the method comprising: receiving a first image and a second image of a semiconductor wafer by a processor executing an image conversion model having an artificial neural network; training the artificial neural network of the image conversion model by: inputting a dataset representing the first image and the second image; generating a conversion image of the semiconductor wafer based on the first image, the conversion image having a higher resolution than the first image; calibrating weights and biases of the artificial neural network to match the conversion image to the second image within a predetermined differential reference value; and generating a third image based on the calibrated weights and biases of the artificial neural network.
14. The method of claim 13, wherein the generation of the conversion image includes: generating first feature map data associated with the first image, based on first weights of the weights and first biases of the biases; mapping the first feature map data onto second feature map data, based on second weights of the weights and second biases of the biases; and reconstructing the second feature map data to the conversion image, based on third weights of the weights and third biases of the biases.
15. The method of claim 14, wherein the generating of the first feature map data includes performing a first convolution operation associated with the first image and the first weights and a first addition operation associated with a first result of the first convolution operation and the first biases, wherein the mapping of the first feature map data onto the second feature map data includes performing a second convolution operation associated with the first feature map data and the second weights and a second addition operation associated with a second result of the second convolution operation and the second biases, and wherein the reconstructing of the second feature map data to the conversion image includes performing a third convolution operation associated with the second feature map data and the third weights and a third addition operation associated with a third result of the third convolution operation and the third biases.
16. The method of claim 15, wherein: the first convolution operation is performed by using Equation 2; the second convolution operation is performed by using Equation 3; and the third convolution operation is performed by using Equation 4.
description="In-line Formulae" end="lead"?F1(I)=max(0,W1*I+B1) <Equation 2>description="In-line Formulae" end="tail"? wherein, in Equation 2, F1(I) is the first feature map data, W1 is the first weights, * is a convolution operation, I is the first image, and B1 is the first biases.
description="In-line Formulae" end="lead"?F2(I)=max(0,W2*F1(I)+B2) <Equation 3:>description="In-line Formulae" end="tail"? wherein, in Equation 3, F2(I) is the second feature map data, W2 is the second weights, * is a convolution operation, F1(I) is the first feature map data, and B2 is the second biases.
description="In-line Formulae" end="lead"?F3(I)=W3*F2(I)+B3 <Equation 4>description="In-line Formulae" end="tail"? wherein, in Equation 4, F3(I) is the third feature map data, W3 is the third weights, * is a convolution operation, F2(I) is the second feature map data, and B3 is the third biases.
17. The method of claim 13, further comprising: transmitting a copy of the image conversion model having the trained artificial neural network to a first device; and generating a first high-resolution converted image from a dataset of a first low-resolution image of a second semiconductor wafer by the first device.
18. A system comprising: at least one processor; and at least one non-transitory computer-readable storage medium storing instructions that, when executed by the at least one processor, cause the system to: receive a first image and a second image of a semiconductor wafer, the first image and the second image being generated by a scanning electron microscope, wherein the second image has a higher resolution than the first image; train an artificial neural network of an image conversion model by: inputting a dataset representing the first image and the second image; generate a conversion image of the semiconductor wafer based on the first image, the conversion image having a higher resolution than the first image; calibrating weights and biases of the artificial neural network to match the conversion image to the second image within a predetermined differential reference value; and generating a third image of the semiconductor wafer based on the calibrated weights and biases of the artificial neural network.
19. The system of claim 18, wherein the generation of the conversion image includes: generating first feature map data associated with the first image, based on first weights of the weights and first biases of the biases; mapping the first feature map data onto second feature map data, based on second weights of the weights and second biases of the biases; and reconstructing the second feature map data to the conversion image, based on third weights of the weights and third biases of the biases.
20. The system of claim 19, wherein the generating of the first feature map data includes performing a first convolution operation associated with the first image and the first weights and a first addition operation associated with a first result of the first convolution operation and the first biases, wherein the mapping of the first feature map data onto the second feature map data includes performing a second convolution operation associated with the first feature map data and the second weights and a second addition operation associated with a second result of the second convolution operation and the second biases, and wherein the reconstructing of the second feature map data to the conversion image includes performing a third convolution operation associated with the second feature map data and the third weights and a third addition operation associated with a third result of the third convolution operation and the third biases.
</claims>
</document>
