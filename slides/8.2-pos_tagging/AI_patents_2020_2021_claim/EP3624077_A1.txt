<document>

<filing_date>
2018-09-17
</filing_date>

<publication_date>
2020-03-18
</publication_date>

<priority_date>
2018-09-17
</priority_date>

<ipc_classes>
G01J5/08,G08B13/191
</ipc_classes>

<assignee>
TRIDONIC & COMPANY
ZUMTOBEL LIGHTING
</assignee>

<inventors>
BURTSCHER, FLORIAN
JELICIC, VANA
MITTERBACHER, ANDRE
</inventors>

<docdb_family_id>
63787692
</docdb_family_id>

<title>
OBJECT DETECTION SENSOR NETWORK FOR CALCULATING A MOTION PATH OF AN OBJECT
</title>

<abstract>
The present invention relates to object detection sensors and provides a network 100 including at least two object detection sensors 101, 101'. Each object detection sensor 101, 101' has at least two detection windows 102a, 102b, 102a', 102b' covering different detection areas 103a, 103b, 103a', 103b' or detection angles 104a, 104b, 104a', 104b'. The network 100 also includes one or more processing units 105 supplied with an analogue output signal 106 of each of said object detection sensors 101, 101' and designed for calculating a motion direction 107 of a detected object 108 within the Field-of-View, FOV, 109, 109' of each object detection sensor 101, 101' based on said analogue output signal 106. Further, the network includes a signal combination unit 110, supplied with time-synchronized information of each of the processing units 105 representing the respective calculated motion direction 107, and designed for calculating a motion path 112 of the detected object 108 in an area covering the FOVs 109, 109' of all object detection sensors 101, 101'.
</abstract>

<claims>
1. A network (100) comprising: - at least two object detection sensors (101, 101'), each object detection sensor (101, 101') having at least two detection windows (102a, 102b, 102a', 102b') covering different detection areas (103a, 103b, 103a', 103b') or detection angles (104a, 104b, 104a', 104b'), - one or more processing units (105) supplied with an analogue output signal (106) of each of said object detection sensors (101, 101') and designed for calculating a motion direction (107) of a detected object (108) within the Field-of-View, FOV, (109, 109') of each object detection sensor (101, 101') based on said analogue output signal (106), - a signal combination unit (110), supplied with time-synchronized information (111) of each of the processing units (105) representing the respective calculated motion direction (107), and designed for calculating a motion path (112) of the detected object (108) in an area covering the FOVs (109, 109') of all object detection sensors (101, 101').
2. The network (100) of claim 1,
wherein the object detection sensors (101, 101') are passive infrared, PIR, sensors.
3. The network (100) of any of the preceding claims,
wherein the object detection sensors (101, 101') have partially overlapping FOVs (109, 109').
4. The network (100) of any of the preceding claims,
wherein the object detection sensors (101, 101') send their analogue output signals (106) to a central processing and signal combination unit.
5. The network (100) of any of the preceding claims,
wherein the one or more processing units (105) are provided with a neural network and/or at least one machine learning, ML, algorithm.
6. The network (100) of any of the preceding claims,
wherein the one or more processing units (105) calculate the motion direction (107) in a time synchronized manner and/or associate a time stamp with the calculated motion direction (107), wherein the time stamp is supplied to the signal combination unit (110) together with the information (111) representing the calculated motion direction (107).
7. The network (100) of any of the preceding claims,
wherein the object detection sensors (101, 101') are arranged in the same room of a building.
8. The network (100) of any of the preceding claims,
wherein the signal combination unit (110) is designed to calculate the most probable motion path (112).
9. A method (500) for operating a network (100), wherein the method comprises the steps of: - supplying (501) an analogue output signal (106) of each of at least two object detection sensors (101, 101') to one or more processing units (105), - calculating (502), by the one or more processing units (105), a motion direction (107) of a detected object (108) within the Field-of-View, FOV, (109, 109') of each object detection sensor (101, 101') based on said analogue output signal (106), - supplying (503) time-synchronized information (111) of each of the processing units (105) representing the respective calculated motion direction (107) to a signal combination unit (110), and - calculating (504), by the signal combination unit (110), a motion path (112) of the detected object (108) in an area covering the FOVs (109, 109') of all object detection sensors (101, 101'), wherein each object detection sensor (101, 101') has at least two detection windows (102a, 102b, 102a', 102b') covering different detection areas (103a, 103b, 103a', 103b') or detection angles (104a, 104b, 104a', 104b').
</claims>
</document>
