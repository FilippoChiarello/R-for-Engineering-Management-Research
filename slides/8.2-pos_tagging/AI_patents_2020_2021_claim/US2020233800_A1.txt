<document>

<filing_date>
2020-04-09
</filing_date>

<publication_date>
2020-07-23
</publication_date>

<priority_date>
2019-01-02
</priority_date>

<ipc_classes>
G06F12/0802,G06N20/00
</ipc_classes>

<assignee>
BAKER HUGHES
</assignee>

<inventors>
EDALUR, RAGHU
RAMINI, PURNA
</inventors>

<docdb_family_id>
71122791
</docdb_family_id>

<title>
JUST-IN-TIME DATA PROVISION BASED ON PREDICTED CACHE POLICIES
</title>

<abstract>
Systems, and methods are provided for predicting a cache policy based on application input data. Inputs provided to an application and corresponding to a usage pattern of the application can be received. The inputs can be used with a predictive model to determine a cache policy corresponding to a datastore. The cache policy can include output data to be provided via in the datastore and subsequently provided to a computing device in a just-in-time manner. The predictive model can be trained to output the cache policy based on input data received from a usage point, a provider point, or a datastore configuration.
</abstract>

<claims>
1. A method comprising: receiving data provided as inputs to an application configured on a computing device including a data processor and coupled to a datastore, the data including a plurality of sequential inputs corresponding to a usage pattern of the application and provided with respect to an objective to be performed via an oil and gas computing environment; determining, using the data and a predictive model, a cache policy corresponding to the datastore and including output data to be provided via the datastore, the predictive model trained to output the cache policy; executing the cache policy at the datastore, the execution causing the provision of the output data to the application from the datastore based on the data provided as inputs to the application; providing an output via the application, the output including the output data, wherein the output is provided based on executing the cache policy; and performing at least a portion of the objective via the computing device using the output.
2. The method of claim 1, wherein the oil and gas computing environment is configured with a plurality of computing devices, each including a data processor, to receive inputs and generate outputs associated with operational, diagnostic, analytical, and/or search objectives associated with assets coupled to the oil and gas computing environment.
3. The method of claim 2, wherein the plurality of computing devices includes computing devices configured as a usage point, a provider point, a datastore, and a data source.
4. The method of claim 1, wherein the datastore includes a datastore associated with at least one of an application provider and a third party.
5. The method of claim 1, wherein the cache policy includes an expiration parameter specifying an expiration period for the output data to be available in the datastore.
6. The method of claim 5, further comprising removing output data from the datastore at an end of the expiration period or based on receiving a second data provided as inputs to the application.
7. The method of claim 1, wherein the output data is formatted based on the datastore, the application, or a named user of the application.
8. The method of claim 1, wherein the predictive model is trained in a machine learning process configured to generate the predictive model based on the data provided as inputs to the application collected from a usage point within the oil and gas computing environment, a provider point within the oil and gas computing environment, or a data source within the oil and gas computing environment.
9. The method of claim 8, wherein the machine learning process is configured to generate a plurality of predictive models based on a predetermined schedule, wherein each predictive model of the plurality of predictive models includes at least one new or updated cache policy.
10. The method of claim 9, wherein the pre-determined schedule specifies when to collect data provided as inputs to the application and the data provided as inputs to the application is collected continuously, every hour, every day, every week, every month, or during a user-defined time-period.
11. A system comprising: a memory storing computer-readable instructions and a plurality of prediction models; and a processor, the processor configured to execute the computer-readable instructions, which when executed, cause the processor to perform operations comprising: receiving data provided as inputs to an application configured on a computing device including a data processor and coupled to a datastore, the data including a plurality of sequential inputs corresponding to a usage pattern of the application and provided with respect to an objective to be performed via an oil and gas computing environment; determining, using the data and a predictive model, a cache policy corresponding to the datastore and including output data to be provided via the datastore, the predictive model trained to output the cache policy; executing the cache policy at the datastore, the execution causing the provision of the output data to the application from the datastore based on the data provided as inputs to the application; providing an output, via the application, the output including the output data, based on executing the cache policy; and performing at least a portion of the objective via the computing device using the output.
12. The system of claim 11, wherein the oil and gas computing environment is configured with a plurality of computing devices, each including a data processor, to receive inputs and generate outputs associated with operational, diagnostic, analytical, and/or search objectives associated with assets coupled to the oil and gas computing environment.
13. The system of claim 12, wherein the plurality of computing devices includes computing devices configured as a usage point, a provider point, a datastore, and a data source.
14. The system of claim 11, wherein the datastore includes a datastore associated with at least one of an application provider and a third party.
15. The system of claim 11, wherein the cache policy includes an expiration parameter specifying an expiration period for the output data to be available in the datastore.
16. The system of claim 15, further comprising removing output data from the datastore at an end of the expiration period or based on receiving a second data provided as inputs to the application.
17. The system of claim 11, wherein the output data is formatted based on the datastore, the application, or a specific named user of the application.
18. The method of claim 11, wherein the predictive model is trained in a machine learning process configured to generate the predictive model based on the data provided as inputs to the application collected from a usage point within the oil and gas computing environment, a provider point within the oil and gas computing environment, or a data source within the oil and gas computing environment.
19. The method of claim 18, wherein the machine learning process is configured to generate a plurality of predictive models based on a predetermined schedule, wherein each predictive model of the plurality of predictive models includes at least one new or updated cache policy.
20. The method of claim 19, wherein the pre-determined schedule specifies when to collect the data provided as inputs to the application and the data provided as inputs to the application is collected continuously, every hour, every day, every week, every month, or during a user-defined time-period.
</claims>
</document>
