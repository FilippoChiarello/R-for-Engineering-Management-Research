<document>

<filing_date>
2019-09-23
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-28
</priority_date>

<ipc_classes>
A61B34/10,A61C13/34,A61C9/00,G06T11/00,G06T17/00,G06T19/20,G06T5/00,G06T5/50,G06T7/50,G06T7/70
</ipc_classes>

<assignee>
ALIGN TECHNOLOGY
</assignee>

<inventors>
LI, YINGJIE
SHI, CHAO
GAO, YUN
</inventors>

<docdb_family_id>
69945127
</docdb_family_id>

<title>
GENERIC FRAMEWORK FOR BLURRING OF COLORS FOR TEETH IN GENERATED IMAGES USING HEIGHT MAP
</title>

<abstract>
A method includes determining depth values associated with a first set of pixel locations in a first image of a mouth. A first function is generated for a color channel based on intensities of the color channel at the first set of pixel locations and depth values associated with the first set of pixel locations. Image data comprising a new representation of the teeth is received, wherein the image data comprises a second set of pixel locations and new depth values associated with the second set of pixel locations. A new image is generated based on the image data and the first function, wherein a shape of the teeth is based on the image data and a color of the teeth is based on applying the first function to the second set of pixel locations for the teeth and the new depth values.
</abstract>

<claims>
1. A method comprising: determining, from a first image of a mouth, a first region of the first image comprising a representation of teeth, wherein the first region comprises a first set of pixel locations in the first image; determining depth values associated with one or more of pixel locations in the first set of pixel locations; generating a first function for a first color channel based on a) intensities of the first color channel at the one or more pixel locations in the first set of pixel locations and b) depth values associated with the one or more pixel locations in the first set of pixel locations, wherein the first function comprises a first variable for a first image axis, a second variable for a second image axis and a third variable for a third image axis; receiving image data comprising a new representation of the teeth in a second region, wherein one or more of the teeth have a different position in the image data than in the first image, wherein the second region comprises a second set of pixel locations for the teeth that is different than the first set of pixel locations, and wherein the image data further comprises new depth values associated with pixel locations in the second set of pixel locations; and generating a new image based on the image data and the first function, wherein a shape of the teeth is based on the image data and a color of the teeth is based on applying the first function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth.
2. The method of claim 1, further comprising: generating a first mask for the first image, wherein the first mask identifies the first set of pixel locations of the first region that are associated with the teeth; generating a second mask for the image data; and determining the second region comprising the teeth in the image data using the second mask, wherein the second mask identifies the second set of pixel locations of the second region that are associated with the teeth.
3. The method of claim 1, wherein regions of the image data lack color data for the teeth.
4. The method of claim 1, further comprising: receiving the first image, wherein the first image was generated by an image sensor; generating a three-dimensional (3D) model from the first image; determining the depth values associated with one or more of pixel locations in the first set of pixel locations from the 3D model.
5. The method of claim 4, wherein the first image is a two-dimensional (2D) image, the method further comprising: performing a treatment simulation using the 3D model; generating a new 3D model based on the treatment simulation, where the one or more of the teeth have the different position in the new 3D model; and generating the image data based on the new 3D model, wherein the image data is 2D image data.
6. The method of claim 4, further comprising: identifying a gap between two adjacent teeth; and performing inpainting to fill in the gap between the two adjacent teeth with a color based on a color of a point on at least one of the two adjacent teeth.
7. The method of claim 1, further comprising: generating a second function for a second color channel based on a) intensities of the second color channel at the pixel locations in the first set of pixel locations and b) depth values associated with the one or more pixel locations in the first set of pixel locations; and generating a third function for a third color channel based on a) intensities of the third color channel at the pixel locations in the first set of pixel locations and b) depth values associated with the one or more pixel locations in the first set of pixel locations; wherein the color of the teeth is further based on a) applying the second function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth and b) applying the third function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth.
8. The method of claim 1, wherein the first function comprises a first sub-function f(x,y) for x,y pixel locations and a second sub-function g(z) for depth values.
9. The method of claim 8, wherein the first function comprises an additive or multiplicative combination of the first sub-function and the second sub-function, and wherein the first sub-function and the second sub-function are parametric functions, the method further comprising: performing linear regression to solve for parameters of the first function.
10. The method of claim 8, wherein the first function comprises an additive or multiplicative combination of the first sub-function and the second sub-function, and wherein at least one of the first sub-function or the second sub-function is a non-parametric function, the method further comprising: performing back fitting to solve for functional forms of the first function.
11. The method of claim 1, further comprising: generating a blurred color representation of the teeth by applying the first function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth; and processing the blurred color representation of the teeth and the received image data by a neural network to generate the new image.
12. A computer readable storage medium comprising instructions that, when executed by a processing device, cause the processing device to perform operations comprising: determining, from a first image of a mouth, a first region of the first image comprising a representation of teeth, wherein the first region comprises a first set of pixel locations in the first image; determining depth values associated with one or more of pixel locations in the first set of pixel locations; generating a first function for a first color channel based on a) intensities of the first color channel at the one or more pixel locations in the first set of pixel locations and b) depth values associated with the one or more pixel locations in the first set of pixel locations, wherein the first function comprises a first variable for a first image axis, a second variable for a second image axis and a third variable for a third image axis; receiving image data comprising a new representation of the teeth in a second region, wherein one or more of the teeth have a different position in the image data than in the first image, wherein the second region comprises a second set of pixel locations for the teeth that is different than the first set of pixel locations, and wherein the image data further comprises new depth values associated with pixel locations in the second set of pixel locations; and generating a new image based on the image data and the first function, wherein a shape of the teeth is based on the image data and a color of the teeth is based on applying the first function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth.
13. The computer readable storage medium of claim 12, wherein the instructions further cause the processing device to perform operations comprising: generating a first mask for the first image, wherein the first mask identifies the first set of pixel locations of the first region that are associated with the teeth; generating a second mask for the image data; and determining the second region comprising the teeth in the image data using the second mask, wherein the second mask identifies the second set of pixel locations of the second region that are associated with the teeth.
14. The computer readable storage medium of claim 12, wherein the instructions further cause the processing device to perform operations comprising: receiving the first image, wherein the first image was generated by an image sensor; generating a three-dimensional (3D) model from the first image; and determining the depth values associated with one or more of pixel locations in the first set of pixel locations from the 3D model.
15. The computer readable storage medium of claim 14, wherein the first image is a two-dimensional (2D) image, and wherein the instructions further cause the processing device to perform operations comprising: performing a treatment simulation using the 3D model; generating a new 3D model based on the treatment simulation, where the one or more of the teeth have the different position in the new 3D model; and generating the image data based on the new 3D model, wherein the image data is 2D image data.
16. The computer readable storage medium of claim 12, wherein the instructions further cause the processing device to perform operations comprising: generating a second function for a second color channel based on a) intensities of the second color channel at the pixel locations in the first set of pixel locations and b) depth values associated with the one or more pixel locations in the first set of pixel locations; and generating a third function for a third color channel based on a) intensities of the third color channel at the pixel locations in the first set of pixel locations and b) depth values associated with the one or more pixel locations in the first set of pixel locations; wherein the color of the teeth is further based on a) applying the second function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth and b) applying the third function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth.
17. The computer readable storage medium of claim 12, wherein the first function comprises a first sub-function f(x,y) for x,y pixel locations and a second sub-function g(z) for depth values.
18. The computer readable storage medium of claim 17, wherein the first function comprises an additive or multiplicative combination of the first sub-function and the second sub-function, and wherein the first sub-function and the second sub-function are parametric functions, the operations further comprising: performing linear regression to solve for parameters of the first function.
19. The computer readable storage medium of claim 17, wherein the first function comprises an additive or multiplicative combination of the first sub-function and the second sub-function, and wherein at least one of the first sub-function or the second sub-function is a non-parametric function, the operations further comprising: performing back fitting to solve for parameters of the first function.
20. The computer readable storage medium of claim 12, the operations further comprising: generating a blurred color representation of the teeth by applying the first function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth; and processing the blurred color representation of the teeth and the received image data by a neural network to generate the new image, wherein the neural network is a pixel to pixel generative adversarial network that was trained using a training dataset comprising a plurality of images of smiles.
21. A system comprising: a memory device; and a processing device operatively coupled to the memory device, the processing device to: determine, from a first image of a mouth, a first region of the first image comprising a representation of teeth, wherein the first region comprises a first set of pixel locations in the first image; determine depth values associated with one or more of pixel locations in the first set of pixel locations; generate a first function for a first color channel based on a) intensities of the first color channel at the one or more pixel locations in the first set of pixel locations and b) depth values associated with the one or more pixel locations in the first set of pixel locations, wherein the first function comprises a first variable for a first image axis, a second variable for a second image axis and a third variable for a third image axis; receive image data comprising a new representation of the teeth in a second region, wherein one or more of the teeth have a different position in the image data than in the first image, wherein the second region comprises a second set of pixel locations for the teeth that is different than the first set of pixel locations, and wherein the image data further comprises new depth values associated with pixel locations in the second set of pixel locations; and generate a new image based on the image data and the first function, wherein a shape of the teeth is based on the image data and a color of the teeth is based on applying the first function to the second set of pixel locations for the teeth and the new depth values associated with the second set of pixel locations for the teeth.
</claims>
</document>
