<document>

<filing_date>
2016-03-07
</filing_date>

<publication_date>
2020-07-21
</publication_date>

<priority_date>
2013-07-17
</priority_date>

<ipc_classes>
A61B17/00,A61B17/02,A61B34/10,A61B42/10,A61B5/00,A61B6/00,A61B8/00,A61B8/08,A61B8/12,G06K9/00,G06K9/46,G06K9/62,G06T7/00,G06T7/60
</ipc_classes>

<assignee>
TISSUE DIFFERENTIATION INTELLIGENCE
</assignee>

<inventors>
SINGH, KERN
GUPTA, SACHIN
</inventors>

<docdb_family_id>
56162889
</docdb_family_id>

<title>
Identifying anatomical structures
</title>

<abstract>
Aspects described herein disclose devices, systems, and methods for use in contexts such as minimally invasive surgery (MIS). A device is provided herein having a proximal portion and a distal portion, and an ultrasound transducer may be disposed within the distal portion and configured to scan tissue and identify certain portions of a patent's anatomy during the scanning process. The results of the detection may be presented to an operator of the device aurally and/or visually, such as in a 3-D volumetric image. By scanning the tissue, identifying the anatomy, and presenting the results to an operator, unnecessary damage to elements of the patients anatomy may be avoided or lessened. In some aspects, multiple transducers may be positioned on the device to increase the scanning range and/or scanning accuracy of the device. The device may provide an inner channel for the passage of surgical tools while scanning tissue.
</abstract>

<claims>
1. A system for mapping anatomical tissue, comprising: a device having a shaft, a housing attached to a distal portion of the shaft, and at least one ultrasound transducer disposed in the housing, wherein the at least one ultrasound transducer is configured to provide signal data corresponding to detected tissue in proximity to the at least one ultrasound transducer; and a computing device configured to: identify an anatomical structure by analyzing the signal data by execution of a classification algorithm, wherein the classification algorithm identifies the anatomical structure by comparing a b-mode scan line from the signal data to a plurality of known b-mode scan lines, each known b-mode scan line having been associated with a corresponding type of anatomical structure; and generate, for display, a 2-D mapping or a 3-D volumetric image depicting the anatomical structure, wherein by being configured to identify the anatomical structure by analyzing the signal data by execution of the classification algorithm, the computing device is configured to: threshold a b-mode image of the signal data to generate a binary map of intensity values; after thresholding the b-mode image, filter the b-mode image with a smoothing filter; identify contiguous regions in the filtered b-mode image having a pixel count above a minimum threshold and below a maximum threshold; compare the identified contiguous regions to an area of an ellipse outlining the contiguous regions; and classify the identified contiguous regions as a nerve based on the comparison.
2. The system of claim 1, wherein the shaft further comprises a channel, through the shaft from the distal portion to a proximal portion, wherein the channel is configured to allow passage of a surgical tool through the shaft there through.
3. The system of claim 1, wherein the detected tissue comprises nerve tissue and wherein the 2-D mapping comprises a mapping of the nerve tissue.
4. The system of claim 1, wherein the detected tissue comprises nerve tissue and wherein the 3-D volumetric image comprises a 3-D volumetric image depicting a mapping of the nerve tissue.
5. The system of claim 1 further comprising a glove having at least one finger, wherein the at least one ultrasound transducer is disposed on the at least one finger.
6. A method comprising: receiving, at a computing device, data from at least one ultrasound transducer disposed at a distal portion of a body, wherein the at least one ultrasound transducer is configured to scan a region extending away from a main portion of the body; analyzing, by the computing device by execution of a classification algorithm, the data to identify an anatomical structure located within the region, wherein the classification algorithm identifies the anatomical structure by comparing a b-mode scan line from the data to a plurality of known b-mode scan lines, each known b-mode scan line having been associated with a corresponding type of anatomical structure; and outputting, by the computing device, an indication associated with the anatomical structure, wherein the analyzing, by the computing device by execution of the classification algorithm, comprises: thresholding a b-mode image of the data to generate a binary map of intensity values; after thresholding the b-mode image, filtering the b-mode image with a smoothing filter; identifying contiguous regions in the filtered b-mode image having a pixel count above a minimum threshold and below a maximum threshold; comparing the identified contiguous regions to an area of an ellipse outlining the contiguous regions; and classifying the identified contiguous regions as a nerve based on the comparison.
7. The method of claim 1, wherein the indication comprises a visual identifier of the anatomical structure.
8. The method of claim 7, wherein the visual identifier comprises a 2-D mapping or a 3-D volumetric image of the anatomical structure.
9. The method of claim 6, wherein the receiving the data from the at least one ultrasound transducer comprises receiving the data from the at least one ultrasound transducer disposed on a distal end of at least one finger of a glove as the at least one finger is advanced within the body.
10. The method of claim 6, wherein, based on a determination that the identified contiguous regions has been classified as a nerve, the method further comprising: calculating, for the identified contiguous regions, a signal-to-noise ratio (SNR), a kurtosis, and a skewness; and based on the calculating, verify that the identified contiguous regions comprise a nerve.
11. The system of claim 1, wherein, based on a determination that the identified contiguous regions have been classified as a nerve, the computing device is further configured to: calculate, for the identified contiguous regions, a signal-to-noise ratio (SNR), a kurtosis, and a skewness; and based on the calculation, verify that the identified contiguous regions comprise a nerve.
12. The system of claim 1, wherein, by being configured to identify the anatomical structure by analyzing the signal data by execution of the classification algorithm, the computing device is configured to: perform double thresholding and connected component tracking by hysteresis, wherein, for each pixel in the signal data determined to have an image intensity value between a high threshold and a low threshold, a connected component algorithm is used to determine whether the pixel is connected to a strong nerve pixel having an image intensity value above the high threshold; and classify the anatomical structure as a nerve, based on a comparison of a shape of connected components to a profile of a nerve.
13. The system of claim 1, wherein the classification algorithm comprises a support vector machine (SVM).
14. A non-transitory tangible computer-readable media storing instructions that, when executed, cause one or more computing devices to: receive data from at least one ultrasound transducer disposed at a distal portion of a body, wherein the at least one ultrasound transducer is configured to scan a region extending away from a main portion of the body; analyze, by execution of a classification algorithm, the data to identify an anatomical structure located within the region, wherein the classification algorithm identifies the anatomical structure by comparing a b-mode scan line from the data to a plurality of known b-mode scan lines, each known b-mode scan line having been associated with a corresponding type of anatomical structure; and output an indication associated with the anatomical structure, wherein the instructions, when executed, cause the one or more computing devices to analyze, by execution of the classification algorithm, the data, by causing the one or more computing devices to: threshold a b-mode image of the data to generate a binary map of intensity values; after thresholding the b-mode image, filter the b-mode image with a smoothing filter; identify contiguous regions in the filtered b-mode image having a pixel count above a minimum threshold and below a maximum threshold; compare the identified contiguous regions to an area of an ellipse outlining the contiguous regions; and classify the identified contiguous regions as a nerve based on the comparison.
15. The non-transitory tangible computer-readable media of claim 14, wherein the indication comprises a visual identifier of the anatomical structure.
16. The non-transitory tangible computer-readable media of claim 15, wherein the visual identifier comprises a 2-D mapping or a 3-D volumetric image of the anatomical structure.
17. The non-transitory tangible computer-readable media of claim 14, wherein, based on a determination that the identified contiguous regions has been classified as a nerve, the instructions, when executed, cause the one or more computing devices to: calculate, for the identified contiguous regions, a signal-to-noise ratio (SNR), a kurtosis, and a skewness; and based on the calculation, verify that the identified contiguous regions comprise a nerve.
</claims>
</document>
