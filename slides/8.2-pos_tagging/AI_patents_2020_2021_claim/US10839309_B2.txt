<document>

<filing_date>
2016-06-06
</filing_date>

<publication_date>
2020-11-17
</publication_date>

<priority_date>
2015-06-04
</priority_date>

<ipc_classes>
G06N20/00,G06N99/00,G10L19/008,G10L21/028,G10L25/39
</ipc_classes>

<assignee>
ACCUSONUS
</assignee>

<inventors>
TSILFIDIS, ALEXANDROS
KOKKINIS, ELIAS
Tzannes, Michael
</inventors>

<docdb_family_id>
57452085
</docdb_family_id>

<title>
Data training in multi-sensor setups
</title>

<abstract>
A system and method for constructing training dictionaries with multichannel information. An exemplary method takes into account the effect of the acoustic path while training multichannel acoustic data. A method that uses different time-frequency resolutions in machine learning training is also presented.
</abstract>

<claims>
1. A method for improving the separation of audio sources comprising: obtaining from a sensor a first time series of N audio signal samples s1, s2, . . . , sN corresponding to a known training signal; transforming the time series of N samples to a first spectrogram in the time-frequency domain using a first window length and obtaining a time-frequency representation with a first resolution; wherein the first spectrogram comprises a first number of frequency bins and a first number of time frames; transforming the same time series of N samples s1, s2, . . . , sN to a second spectrogram in the time-frequency domain using a second window length, different from the first window length, and obtaining a time-frequency representation with a second resolution, different from the first resolution; wherein the second spectrogram comprises a second number of frequency bins and a second number of time frames, different from the first number of time frames; mapping the first spectrogram to a third spectrogram through a matrix multiplication such that the third spectrogram comprises a third number of frequency bins and a third number of time frames, equal to the first number of time frames; mapping the second spectrogram to a fourth spectrogram through a matrix multiplication such that the fourth spectrogram comprises the same third number of frequency bins and a fourth number of time frames, equal to the second number of time frames; wherein the third number of frequency bins is different than the first number of frequency bins and the third number of frequency bins is different than the second number of frequency bins; determining elements of a training dictionary from the third and fourth spectrograms using one or more signal processing algorithms; storing the training dictionary elements; using the training dictionary elements to process a second time series of audio signal samples obtained by the sensor; and audibly outputting an audio signal related to the processed second series of audio signal samples.
2. The method of claim 1, wherein the first and second number of frequency bins are different.
3. The method of claim 1, where the source signal is single channel or binaural or multichannel audio signal.
4. The method of claim 1, where the signal processing algorithms are one or more of non-negative matrix factorization, non-negative tensor factorization, independent component analysis, principal component analysis, singular value decomposition, dependent component analysis, low-complexity coding and decoding, stationary subspace analysis, common spatial pattern, empirical mode decomposition, tensor decomposition, canonical polyadic decomposition, higher-order singular value decomposition, and tucker decomposition.
5. The method of claim 1, where the training dictionary is used for source separation.
6. The method of claim 1, where the representations can be obtained with any one or more of a short-time Fourier transform (STFT), a wavelet transform, a polyphase filterbank, a multi rate filterbank, a quadrature mirror filterbank, a warped filterbank, an auditory-inspired filterbank, and a tree-structured array of filterbanks.
7. The method of claim 1, wherein the data are captured in live or studio music events from one or more microphones.
8. The method of claim 1, wherein the frequency bins in the third and fourth spectrogram are non-uniform.
9. A system for improving the separation of audio signals comprising: a sensor that obtains a first time series of N audio signal samples s1, s2, . . . , sN corresponding to a known training signal; a first transformer that transforms the time series of N samples to a first spectrogram in the time-frequency domain using a first window length to obtain a time-frequency representation with a first resolution; wherein the first spectrogram comprises a first number of frequency bins and a first number of time frames; a second transformer that transforms the same time series of N samples s1, s2, . . . , sN to a second spectrogram in the time-frequency domain using a second window length, different from the first window length, to obtain a time-frequency representation with a second resolution, different from the first resolution; wherein the second spectrogram comprises a second number of frequency bins and a second number of time frames, different from the first number of time frames; a processor that maps the first spectrogram to a third spectrogram through a matrix multiplication such that the third spectrogram comprises a third number of frequency bins and a third number of time frames, equal to the first number of time frames; said processor further maps the second spectrogram to a fourth spectrogram through a matrix multiplication such that the fourth spectrogram comprises the same third number of frequency bins and a fourth number of time frames, equal to the second number of time frames; wherein the third number of frequency bins is different than the first number of frequency bins and the third number of frequency bins is different than the second number of frequency bins; said processor further determines elements of a training dictionary from the third and fourth spectrograms using one or more signal processing algorithms; a storage for storing the training dictionary elements; said processor further using the training dictionary elements to process a second time series of audio signal samples obtained by the sensor; and audibly outputting an audio signal related to the processed second series of audio signal samples.
10. The system of claim 9, wherein the first and second number of frequency bins are different.
11. The system of claim 9, wherein the third number of frequency bins are non-uniform.
12. The system of claim 9, wherein the source signal is a single channel or binaural or multichannel audio signal.
13. The system of claim 9, wherein the signal processing algorithms are one or more of non-negative matrix factorization, non-negative tensor factorization, independent component analysis, principal component analysis, singular value decomposition, dependent component analysis, low-complexity coding and decoding, stationary subspace analysis, common spatial pattern, empirical mode decomposition, tensor decomposition, canonical polyadic decomposition, higher-order singular value decomposition, and tucker decomposition.
14. The system of claim 9, wherein the training dictionary is used for source separation.
15. The system of claim 9, wherein a time-frequency representation can be obtained with any one or more of a short-time Fourier transform (STFT), a wavelet transform, a polyphase filterbank, a multi rate filterbank, a quadrature mirror filterbank, a warped filterbank, an auditory-inspired filterbank, and a tree-structured array of filterbanks.
16. The system of claim 9, wherein the frequency bins in the third and fourth spectrogram are non-uniform.
17. A non-transitory information storage media having stored thereon information, that when executed by one or more processors, cause to be performed a method for improving the separation of audio signals comprising: obtaining from a sensor a first time series of N audio signal samples s1, s2, . . . , sN corresponding to a known training signal; transforming the time series of N samples to a first spectrogram in the time-frequency domain using a first window length and obtaining a time-frequency representation with a first resolution; wherein the first spectrogram comprises a first number of frequency bins and a first number of time frames; transforming the same time series of N samples s1, s2, . . . , sN to a second spectrogram in the time-frequency domain using a second window length, different from the first window length, and obtaining a time-frequency representation with a second resolution, different from the first resolution; wherein the second spectrogram comprises a second number of frequency bins and a second number of time frames, different from the first number of time frames; mapping the first spectrogram to a third spectrogram through a matrix multiplication such that the third spectrogram comprises a third number of frequency bins and a third number of time frames, equal to the first number of time frames; mapping the second spectrogram to a fourth spectrogram through a matrix multiplication such that the fourth spectrogram comprises the same third number of frequency bins and a fourth number of time frames, equal to the second number of time frames; wherein the third number of frequency bins is different than the first number of frequency bins and the third number of frequency bins is different than the second number of frequency bins; determining elements of a training dictionary from the third and fourth spectrograms using one or more signal processing algorithms; storing the training dictionary elements; using the training dictionary elements to process a second time series of audio signal samples obtained by the sensor; and audibly outputting an audio signal related to the processed second series of audio signal samples.
18. The media of claim 17, wherein the first and second number of frequency bins are different.
19. The media of claim 17, wherein the third number of frequency bins are non-uniform.
20. The media of claim 17, wherein the source signal is a single channel or binaural or multichannel audio signal.
21. The media of claim 17, wherein the signal processing algorithms are one or more of non-negative matrix factorization, non-negative tensor factorization, independent component analysis, principal component analysis, singular value decomposition, dependent component analysis, low-complexity coding and decoding, stationary subspace analysis, common spatial pattern, empirical mode decomposition, tensor decomposition, canonical polyadic decomposition, higher-order singular value decomposition, and tucker decomposition.
22. The media of claim 17, wherein the training dictionary is used for source separation.
23. The media of claim 17, wherein a time-frequency representation can be obtained with any one or more of a short-time Fourier transform (STFT), a wavelet transform, a polyphase filterbank, a multi rate filterbank, a quadrature mirror filterbank, a warped filterbank, an auditory-inspired filterbank, and a tree-structured array of filterbanks.
24. The media of claim 17, wherein the frequency bins in the third and fourth spectrogram are non-uniform.
</claims>
</document>
