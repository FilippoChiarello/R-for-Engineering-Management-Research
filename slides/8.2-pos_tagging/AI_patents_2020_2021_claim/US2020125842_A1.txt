<document>

<filing_date>
2019-12-23
</filing_date>

<publication_date>
2020-04-23
</publication_date>

<priority_date>
2014-09-30
</priority_date>

<ipc_classes>
G06F3/01,G06K9/00,G06K9/46,G06K9/60,G06K9/62,H04N5/225,H04N5/232,H04N5/33
</ipc_classes>

<assignee>
QUALCOMM
</assignee>

<inventors>
GOUSEV, EVGENI
GOVIL, ALOK
HENCKELS, JEFFERY
MAITAN, JACEK
PARK, EDWIN CHONGWOO
RANGAN VENKAT
</inventors>

<docdb_family_id>
58663429
</docdb_family_id>

<title>
LOW-POWER IRIS SCAN INITIALIZATION
</title>

<abstract>
Apparatuses, methods, and systems are presented for sensing scene-based occurrences. Such an apparatus may comprise a vision sensor system comprising a first processing unit and dedicated computer vision (CV) computation hardware configured to receive sensor data from at least one sensor array comprising a plurality of sensor pixels and capable of computing one or more CV features using readings from neighboring sensor pixels. The vision sensor system may be configured to send an event to be received by a second processing unit in response to processing of the one or more computed CV features by the first processing unit. The event may indicate possible presence of one or more irises within a scene.
</abstract>

<claims>
1. A device comprising: a first camera comprising a sensor array, the sensor array comprising more than one sensor pixel; a second camera; dedicated computer vision (CV) computation hardware configured to receive sensor data from the sensor array and capable of computing one or more CV features using readings from pixels of the sensor array; and a first processing unit communicatively coupled with the dedicated CV computation hardware and configured to: process signals resulting from operations based on the one or more computed CV features, and in response to the processing of the signals resulting from the operations based on the one or more computed CV features, generate an event indicating a reference occurrence; and a second processing unit communicatively coupled with the first processing unit and configured to execute application software in response to receiving the event.
2. The device of claim 1, wherein the first camera is a special-purpose camera dedicated to a sensor system, the sensor system comprising the dedicated CV computation hardware and the first processing unit.
3. The device of claim 2, wherein the pixels of the sensor array, from which the dedicated CV computation hardware is capable of taking readings and computing the one or more CV features, comprises neighboring sensor pixels.
4. The device of claim 1, wherein the sensor array is an event-driven array having a sensor output based on a sensor reading reaching a threshold or changing by a threshold.
5. The device of claim 1, wherein the event is configured to indicate the reference occurrence comprises at least one of: a coming into view of a human face, a coming into view of a human body, an emotion expressed on a human face, coming into view of a non-human animal face, coming into view of a non-human animal body, coming into view of a human hand, a hand gesture, a coming into view of a reference object, a change from an indoor environment to an outdoor environment, a reference movement, rapid movement in a scene indicating a fall, motion toward an object indicating a risk of collision, movement or objects in a scene indicating danger, or any combination thereof.
6. The device of claim 1, wherein the event is configured to indicate the reference occurrence comprises object detection.
7. The device of claim 1, wherein the dedicated CV computation hardware is configured to provide Local Binary Patterns (LBPs).
8. The device of claim 1, further comprising a classifier configured to detect a presence of a reference object in a subset of the sensor data, wherein the operations based on the one or more computed CV features comprise operations performed by the classifier, the reference occurrence being associated with the reference object.
9. The device of claim 8, wherein the first processing unit is configured to receive an indication from the classifier of the presence of the reference object when the presence of the reference object is detected by the classifier.
10. The device of claim 8, wherein the classifier comprises a cascade classifier comprising software executed by the first processing unit.
11. The device of claim 1, wherein the dedicated CV computation hardware comprises an integrated circuit.
12. The device of claim 1, wherein the first processing unit is further configured to disable at least part of the dedicated CV computation hardware to generate at least one lower-power optical sensor reading indicative of ambient light sensing, a proximity detection, a proximity to a reference object, a motion detection, or any combination thereof for use by the second processing unit.
13. The device of claim 1, wherein the first processing unit is configured to disable at least part of the dedicated CV computation hardware while operating in a lower-power mode, detect a scene change in the lower-power mode, and to activate the dedicated CV computation hardware based on detection of the scene change.
14. The device of claim 1, wherein the first processing unit is configured to include, in the event, data associated with the reference occurrence.
15. The device of claim 14, wherein the second processing unit is configured to execute the application software in response to receiving the event comprises the second processing unit utilizing the data associated with the reference occurrence while executing the application software.
16. The device of claim 1, wherein the first processing unit is configured to: perform a higher-power operation as at least part of the operations based on the one or more computed CV features, the higher-power operation consuming more power than a lower-power operation, and provide a parameter for the lower-power operation based on the higher-power operation.
17. The device of claim 16, wherein the lower-power operation includes one or more from the list comprising: ambient light sensing, proximity detection, motion detection, or change detection.
18. A method for sensing dynamic scene-based occurrences with an apparatus, the method comprising: receiving, with dedicated computer vision (CV) computation hardware, sensor data from a sensor array comprising more than one sensor pixel, wherein the sensor array in included in a first camera, and wherein the apparatus comprises the first camera and a second camera; computing, with the dedicated CV computation hardware, one or more CV features using readings from pixels of the sensor array; processing, with a first processing unit, signals resulting from operations based on the one or more computed CV features; generating an event in response to the processing of the signals resulting from the operations based on the one or more computed CV features by the first processing unit, the event indicating a reference occurrence for a second processing unit; and executing, with a second processing unit, application software in response to the event configured.
19. The method of claim 18, wherein the reference occurrence is one or more of: a coming into view of a human face, a coming into view of a human body, an emotion expressed on a human face, coming into view of a non-human animal face, coming into view of a non-human animal body, coming into view of a human hand, a hand gesture, a coming into view of a reference object, a change from an indoor environment to an outdoor environment, a reference movement, rapid movement in a scene indicating a fall, motion toward an object indicating a risk of collision, movement or objects in a scene indicating danger, or any combination thereof.
20. The method of claim 18, further comprising providing, with the dedicated CV computation hardware, Local Binary Patterns (LBPs).
21. The method of claim 18, further comprising detecting, with a classifier, a presence of a reference object in a subset of the sensor data, wherein the operations based on the one or more computed CV features comprise operations performed by the classifier, the reference occurrence being associated with the reference object.
22. The method of claim 21, further comprising, receiving, by the first processing unit, an indication from the classifier of the presence of the reference object when the presence of the reference object is detected by the classifier.
23. The method of claim 21, wherein the classifier comprises software executed by the first processing unit.
24. The method of claim 21, wherein the classifier comprises hardware separate from the first processing unit.
25. The method of claim 18, further comprising: disabling at least part of the dedicated CV computation hardware while operating in a lower-power mode; detecting a scene change while operating in the lower-power mode; and activating the disabled at least part of the dedicated CV computation hardware based on detection of the scene change.
26. The method of claim 18, wherein, receiving, with the dedicated CV computation hardware, the sensor data from the sensor array comprises receiving raw sensor data from the sensor array and wherein no image signal processing is performed on the sensor data prior to the receiving.
27. A method for determining object detection events with an apparatus, the method comprising: receiving, with dedicated computer vision (CV) computation hardware, sensor data from a sensor array, wherein the sensor array in included in a first camera, and wherein the apparatus comprises the first camera and a second camera; computing one or more CV features using readings from pixels of the sensor array; using a first processing unit to: determine, from one or more signals resulting from operations based on the one or more computed CV features that an object has been detected, and in response to the determination, generate an object-detected event; and using a second processing unit to, in response to receiving the object-detected event, execute application software.
28. The method of claim 27, further comprising using the first processing unit to communicate the object-detected event to the second processing unit while the second processing unit is operating in a low-power mode.
29. The method of claim 27, wherein, receiving, with the dedicated CV computation hardware, the sensor data from the sensor array comprises receiving raw sensor data from the sensor array and wherein no image signal processing is performed on the sensor data prior to the receiving.
</claims>
</document>
