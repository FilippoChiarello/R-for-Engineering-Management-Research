<document>

<filing_date>
2019-03-20
</filing_date>

<publication_date>
2020-09-24
</publication_date>

<priority_date>
2019-03-20
</priority_date>

<ipc_classes>
A63F13/79,A63F13/87
</ipc_classes>

<assignee>
ELECTRONIC ARTS
</assignee>

<inventors>
ALI, FARAH MARIAM
AGHDAIE, NAVID
ZAMAN, KAZI ATIF-UZ
SARDARI, MOHSEN
KOLEN, JOHN
PINTO, JERVIS
Gouskova, Polina Igorevna
Nagaraja Rao, Chetan
</inventors>

<docdb_family_id>
72516268
</docdb_family_id>

<title>
TOXICITY-BASED CHAT PERSONALIZATION WITHIN VIDEO GAMES
</title>

<abstract>
Using user-specific prediction models, it is possible to present an individualized view of messages generated by users playing a shared instance of a video game. Further, users with different subjective views of what is offensive may be presented with different forms or annotations of a message. By personalizing the views of messages generated by users, it is possible to reduce or eliminate the toxic environment that sometimes forms when players, who may be strangers to each other and may be located in disparate locations play a shared instance of a video game. Further, the user-specific prediction models may be adapted to filter or otherwise annotate other undesirable messages that may not be offensive, such as a message generated by one user in a video game that includes a solution to an in-game puzzle that another user may not desire to read as it may spoil the challenge for the user.
</abstract>

<claims>
1. A computer-implemented method comprising: as implemented by an interactive computing system configured with specific computer-executable instructions, receiving a text-based message from a first user computing system accessing a shared instance of a video game, the text-based message obtained from an originating user interacting with the shared instance of the video game, and the video game comprising a multiplayer video game that enables multiple users to play the shared instance of the video game together; identifying a first recipient user interacting with the shared instance of the video game; accessing a first prediction model associated with the first recipient user; providing at least the text-based message to the first prediction model to obtain a predicted toxicity of the text-based message; determining that the predicted toxicity of the text-based message satisfies a toxicity threshold; annotating the text-based message based at least in part on the predicted toxicity; and providing the annotated text-based message to a second user computing system executing the shared instance of the video game for presentation to the first recipient user.
2. The computer-implemented method of claim 1, wherein the text-based message is received at a user interface of the video game executing at the first user computing system.
3. The computer-implemented method of claim 1, wherein annotating the text-based message comprises rendering at least a portion of the text-based message unreadable to the first recipient user.
4. The computer-implemented method of claim 1, further comprising providing to the second user computing system, for presentation to the first recipient user one or more of the following: an indication that the text-based message has been annotated or an indication of a reason that the text-based message has been annotated.
5. The computer-implemented method of claim 1, wherein said providing at least the text-based message to the first prediction model to obtain the predicted toxicity of the text-based message comprises: dividing the text-based message into a plurality of segments; and providing each of the plurality of segments to the first prediction model to obtain a predicted toxicity for each of the plurality of segments.
6. The computer-implemented method of claim 5, further comprising aggregating the predicted toxicity for each of the plurality of segments to obtain the predicted toxicity of the text-based message.
7. The computer-implemented method of claim 5, wherein said annotating the text-based message based at least in part on the predicted toxicity comprises annotating a first segment of the plurality of segments associated with a predicted toxicity that satisfies the toxicity threshold while not annotating a second segment of the plurality of segments associated with a predicted toxicity that does not satisfy the toxicity threshold.
8. The computer-implemented method of claim 1, further comprising: accessing context data; and providing at least the text-based message and the context data to the first prediction model to obtain the predicted toxicity of the text-based message.
9. The computer-implemented method of claim 8, wherein the context data comprises one or more of the following: a skill level for the originating user; a skill level for the first recipient user; relationship data between the originating user and the first recipient user; demographic data of the first recipient user; demographic data of the originating user; a genre of the video game; demographic data of one or more additional users accessing the shared instance of the video game; relationship data between the first recipient user and the one or more additional users; a type of the second user computing system; or a location of the second user computing system.
10. The computer-implemented method of claim 1, further comprising: identifying a second recipient user interacting with the shared instance of the video game using a third user computing system; accessing a second prediction model associated with the second recipient user; providing at least the text-based message to the second prediction model to obtain a second predicted toxicity of the text-based message; determining that the second predicted toxicity of the text-based message does not satisfy the toxicity threshold; and providing a non-annotated copy of the text-based message to the third user computing system for presentation to the second recipient user.
11. The computer-implemented method of claim 1, further comprising generating a global prediction model that determines a prediction of toxicity for text-based messages, wherein said generating the global prediction model comprises: accessing a set of training data, the training data comprising a set of text-based messages with varying levels of toxicity as rated by a set of users; accessing a set of toxicity ratings for each of the text-based messages of the set of text-based messages as determined by the set of users; and using a machine learning algorithm to determine the global prediction model parameter function based at least in part on the set of training data and the set of toxicity ratings.
12. The computer-implemented method of claim 1, further comprising generating the first prediction model by at least: accessing a global prediction model; presenting a set of training text-based messages to the first recipient user; obtaining a set of toxicity ratings for each of the training text-based messages of the set of training text-based messages from the first recipient user; and modifying the global prediction model based at least in part on the set of training text-based messages and the set of toxicity ratings to obtain the first prediction model.
13. The computer-implemented method of claim 12, wherein modifying the global prediction model to obtain the first prediction model comprises providing the global prediction model, the set of training text-based messages, and the set of toxicity ratings to a machine learning algorithm.
14. The computer-implemented method of claim 1, wherein the first user computing system and the second user computing system execute the shared instance of the video game by executing at least a portion of the video game.
15. A system comprising: an electronic data store configured to store prediction models that predict the offensiveness of chat messages within a video game that permits multiple user to play the video game together; and a hardware processor in communication with the electronic data store, the hardware processor configured to execute specific computer-executable instructions to at least: receive a chat message from a first user computing system accessing a shared instance of the video game, the chat message obtained from a first user interacting with the shared instance of the video game; identify a second user interacting with the shared instance of the video game using a second user computing system; access from the electronic data store a first prediction model associated with the second user; provide at least the chat message to the first prediction model to obtain a predicted offensiveness of the chat message; determine that the predicted offensiveness of the chat message satisfies an offensiveness threshold; annotate the chat message based at least in part on the predicted offensiveness; and provide the annotated chat message to the second user computing system for presentation to the second user.
16. The system of claim 15, wherein the hardware processor is further configured to annotate the chat message to render at least a portion of the chat message unreadable to the second user.
17. The system of claim 15, wherein the hardware processor is further configured to provide at least the chat message to the first prediction model by at least: dividing the chat message into a plurality of segments; and providing each of the plurality of segments to the first prediction model to obtain a predicted offensiveness for each of the plurality of segments, wherein the hardware processor is further configured to determine the predicted offensiveness of the chat message based on the predicted offensiveness of each of the plurality of segments.
18. The system of claim 15, wherein the hardware processor is further configured to: identify a third user interacting with the shared instance of the video game using a third user computing system; access from the electronic data store a second prediction model associated with the third user; provide at least the chat message to the second prediction model to obtain a second predicted offensiveness of the chat message; determine that the second predicted offensiveness of the chat message does not satisfy the offensiveness threshold; and provide a non-annotated copy of the chat message to the third user computing system for presentation to the third user.
19. The system of claim 15, wherein the hardware processor is further configured to generate the first prediction model by at least: presenting a set of training chat messages to the second user; obtaining an offensiveness rating for each training chat message of the set of training chat messages from the second user; and using a machine learning algorithm to generate the first prediction model based at least in part on the set of training chat messages and the offensiveness rating for each training chat message of the set of training chat messages.
20. The system of claim 15, wherein the hardware processor is further configured to generate the first prediction model by at least: accessing a global offensiveness prediction model generated based on training data obtained from a plurality of users; presenting a set of training chat messages to the second user; obtaining an offensiveness rating for each training chat message of the set of training chat messages from the second user; and using a machine learning algorithm to modify the global offensiveness prediction model based at least in part on the set of training chat messages and the offensiveness rating for each training chat message of the set of training chat messages to generate the first prediction model.
</claims>
</document>
