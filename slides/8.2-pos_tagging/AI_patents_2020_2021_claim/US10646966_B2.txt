<document>

<filing_date>
2019-03-25
</filing_date>

<publication_date>
2020-05-12
</publication_date>

<priority_date>
2016-08-08
</priority_date>

<ipc_classes>
A61F9/08,B23K37/00,B23K9/167,B23K9/173,B23K9/32,G06K9/00,G06K9/62,G06N3/04,H01R13/22,H01R13/24,H01R13/648,H01R4/56
</ipc_classes>

<assignee>
JHU (JOHNS HOPKINS UNIVERSITY)
</assignee>

<inventors>
BILLINGS, SETH D.
BURLINA PHILIPPE M.
COSTELLO, CASH J.
KATYAL, KAPIL D.
ROLLEND, DEREK M.
WOLFE, KEVIN C.
</inventors>

<docdb_family_id>
61072040
</docdb_family_id>

<title>
Object recognition and presentation for the visually impaired
</title>

<abstract>
Apparatuses, systems, and methods for object recognition and presentation are provided. An example apparatus may include a camera, an assistance feedback device, an input device, and processing circuitry. The processing circuitry may be configured receive an image from the camera, compare characteristic features within the image to an object identification dataset to identify object matches for a plurality of objects within the image, receive a selected name of an identified object from the user via the input device, and transmit assistance feedback to the user indicating a position of the selected object within the field of view via the assistance feedback device.
</abstract>

<claims>
That which is claimed:
1. A method to perform object recognition, the method comprising: capturing, by a camera, a plurality of images of a field of view of the camera, the camera in communication with processing circuitry; repeatedly comparing, by the processing circuitry, characteristic features within images of the plurality of images to an object identification dataset to identify object matches for a plurality of objects within the plurality of images; determining, by the processing circuitry, identified objects based on object matches in the plurality of images; filtering, by the processing circuitry, between iterations of comparing the characteristic features to the object identification dataset, to consecutive images over time to estimate positions of the identified objects based on a prior location determination of the identified objects to represent movement with an estimated track state prior to performing object recognition; and transmitting, by the processing circuitry, a position of an identified object based on the estimated track state.
2. The method of claim 1, further comprising: determining, by the processing circuitry, a name for identified objects from the object identification dataset.
3. The method of claim 1, further comprising: determining, by the processing circuitry, locations of the identified objects within the field of view.
4. The method of claim 3, further comprising: receiving, by an input device, a request to find a location for a desired object; determining a position of the desired object within the field of view based on locations of the identified objects within the field of view; and transmitting assistance feedback with the position of the desired object within the field of view.
5. The method of claim 4, wherein the request to find the location of the desired object is received via audible speech and speech recognition is performed to determine a name of the desired object prior to determining a position of the desired object.
6. The method of claim 4, wherein transmitting assistance feedback includes rendering a modified version of an image that contrasts the desired object or an area around the desired object with a remainder of the image.
7. The method of claim 4, wherein transmitting assistance feedback includes rendering a modified version of an image with an area around the desired object being cropped to define an object area and a background area, and wherein the background area is modified to create contrast with the desired object.
8. The method of claim 4, wherein transmitting assistance feedback includes rendering a representation of the desired object.
9. The method of claim 4, wherein the assistance feedback is transmitted to a display configured to output the assistance feedback.
10. The method of claim 1, further comprising: receiving, by an input device, a request to communicate identified objects within the field of view; and transmitting, by an output device, names of identified objects within the field of view in response to receiving the request.
11. The method claim 1, wherein the filtering further comprises applying a Kalman filter to consecutive images.
12. The method of claim 1, wherein the filtering further comprises performing at least one image template match iteration, between iterations of comparing the characteristic features to the object identification dataset, to more than one additional image over time to track movement of objects in the more than one additional image.
13. The method of claim 1, wherein the plurality of images are captured as four-dimensional images including depth.
14. The method of claim 13, further comprising: filtering the plurality of images at a target depth.
15. The method of claim 13, further comprising: detecting a depth of a target point within the plurality of images and output a dynamically controlled audible output that is based on a depth of a selected object relative to a depth of the target point.
16. The method of claim 1, further comprising: using a convolution neural network to compare the characteristic features within the plurality of images to an object identification dataset.
17. The method of claim 1, wherein the camera is affixed to glasses and the processing circuitry is operably coupled to the glasses.
18. A system comprising: a camera; an object identification dataset; and processing circuitry, the processing circuitry configured to: capture, via the camera, a plurality of images of a field of view of the camera; repeatedly compare characteristic features within images of the plurality of images to the object identification dataset to identify object matches; determine identified objects based on object matches in the plurality of images; apply a filter between iterations of comparing the characteristic features to the object identification dataset, to consecutive images over time to estimate positions of the identified objects based on a prior location determination of the identified objects to represent movement with an estimated track state prior to performing object recognition; and transmit a position of an identified object based on the estimated track state.
19. The system of claim 18, further comprising: a display; an audio output device; and an audio input device, wherein the processing circuitry is further configured to: determine a name for identified objects from the object identification dataset; determine locations of the identified objects within the field of view; receive a request, via the audio input device, to communicate the objects within in the field of view; transmit, via the audio output device, names of identified objects in response to receiving the request; receive, via the audio input device, a selected name; determine a selected object based on the selected name, the selected object being one of the identified objects; and provide, via the display, assistance feedback as a rendered modified image that indicates a position of the selected object within the field of view based on determined location and the estimated track state.
20. The system of claim 18, wherein the processing circuitry configured to apply the filter includes being configured to perform at least one image template match iteration, between iterations of comparing the characteristic features to the object identification dataset, to more than one additional image over time to track movement of the objects in the more than one additional image.
</claims>
</document>
