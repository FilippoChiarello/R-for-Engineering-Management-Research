<document>

<filing_date>
2019-08-20
</filing_date>

<publication_date>
2020-03-19
</publication_date>

<priority_date>
2018-09-11
</priority_date>

<ipc_classes>
G06K9/62,H04N19/172,H04N19/61,H04N19/85,H04N21/234,H04N21/4408,H04N21/84
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
HE, DAKE
XU, RUIJIE
</inventors>

<docdb_family_id>
67809737
</docdb_family_id>

<title>
VIDEO CODING USING SEPARATE LEARNING AND FILTERING PATHWAYS
</title>

<abstract>
Separate pathways for filtering and machine learning are introduced within a video coder. A first pathway filters a first copy of a reconstructed frame to produce a filtered frame, which is included in an output video stream for display. A second pathway processes a second copy of the reconstructed frame using a learning model, such as for training and/or inference. The first and second pathways are introduced after the reconstruction stage of an encoder or decoder. The input to each of the first and second pathways is thus produced without using a non-injective function, and, while the first pathway includes at least one non-injective function, the second pathway does not. As a result, training the learning model using the second copy of the reconstructed frame results in a greater classification accuracy upper bound than training the learning model using the filtered frame.
</abstract>

<claims>
1. A decoder, comprising:
an entropy decoding stage configured to entropy decode syntax elements representative of an encoded video frame from an encoded bitstream to produce quantized transform coefficients;
a dequantization stage configured to dequantize the quantized transform coefficients to produce transform coefficients;
an inverse transform stage configured to inverse transform the transform coefficients to produce a prediction residual;
a reconstruction stage configured to reconstruct the prediction residual to produce a reconstructed frame;
a first post-reconstruction pathway configured to filter a first copy of the reconstructed frame using one or more filtering techniques to produce a filtered frame, wherein the filtered frame is for inclusion in an output video stream for display at a user device; and
a second post-reconstruction pathway configured to train a learning model using a second copy of the reconstructed frame.
2. The decoder of claim 1, wherein the second post-reconstruction pathway is configured to train the learning model using the second copy of the reconstructed frame and filter side information received from the first post-reconstruction pathway.
3. The decoder of claim 1 or 2, wherein each function performed at the entropy decoding stage, the dequantization stage, the inverse transform stage, the reconstruction stage, and the second post-reconstruction pathway is an injective function, wherein at least one function performed at the first post-reconstruction pathway is a non-injective function.
4. The decoder of claim 1 or 2, wherein the reconstructed frame is a first reconstructed frame, wherein the reconstruction stage is further configured to produce a second reconstruction frame, wherein the first post-reconstruction pathway is configured to filter a first copy of the second reconstructed frame, wherein the second post-reconstruction pathway is configured to perform one or more inference operations against a second copy of the second frame using the trained learning model.
5. The decoder of any of claims 1 to 4, wherein the one or more filtering techniques include a filtering technique performed using an in-loop filter.
6. The decoder of any of claims 1 to 5, wherein training the learning model using the second copy of the reconstructed frame results in a greater classification accuracy upper bound for the learning model than training the learning model using the filtered frame
7. A method, comprising:
dequantizing quantized transform coefficients representative of encoded video data to produce transform coefficients;
inverse transforming the transform coefficients to produce a prediction residual; reconstructing the prediction residual to produce a reconstructed frame;
filtering a first copy of the reconstructed frame to produce a filtered frame; and processing a second copy of the reconstructed frame using a learning model to identify video content.
8. The method of claim 7, wherein processing the second copy of the reconstructed frame using the learning model to identify the video content comprises:
training the learning model to identify the video content using the second copy of the reconstructed frame.
9. The method of claim 8, wherein training the learning model using the second copy of the reconstructed frame results in a greater classification accuracy upper bound for the learning model than training the learning model using the filtered frame.
10. The method of claim 8 or 9, wherein training the learning model to identify the video content using the second copy of the reconstructed frame comprises:
training the learning model using filter side information, wherein the filter side information is used for the filtering of the first copy of the reconstructed frame.
11. The method of any of claims 7 to 10, wherein the filtered frame is produced using at least one non-injective function, wherein the second copy of the reconstructed frame is produced without using the at least one non-injective function.
12. The method of any of claims 7 to 10, wherein filtering the first copy of the reconstructed frame to produce the filtered frame comprises:
processing the first copy of the reconstructed frame using an inloop filter.
13. The method of any of claims 7 to 12, wherein the encoded video data is first encoded video data, the method further comprising:
performing one or more inference operations against second encoded video data using the trained learning model.
14. The method of any of claims 7 to 13, wherein the encoded video data is decoded from an encoded bitstream, the method further comprising:
outputting the filtered frame within an output video stream for display at a user device.
15. An integrated circuit comprising a processor that executes instructions, the instructions comprising instructions for:
decoding encoded video data from an encoded bitstream to produce a reconstructed frame;
processing a first copy of the reconstructed frame over a first decoding pathway using an in-loop filter to produce an output video stream for display at a user device; and
processing a second copy of the reconstructed frame over a second decoding pathway by using a learning model to identify video content.
16. The integrated circuit of claim 15, wherein the instructions for decoding the encoded video data from the encoded bitstream to produce the reconstructed frame comprise instructions for:
dequantizing quantized transform coefficients representative of the encoded video data to produce transform coefficients;
inverse transforming the transform coefficients to produce a prediction residual; and reconstructing the prediction residual to produce the reconstructed frame.
17. The integrated circuit of claim 15 or 16, wherein the instructions for processing the second copy of the reconstructed frame over the second decoding pathway by using the learning model to identify the video content comprise instructions for:
training the learning model using the second copy of the reconstructed frame.
18. The integrated circuit of claim 17, wherein the instructions for training the learning model using the second copy of the reconstructed frame comprise instructions for: training the learning model using filter side information from the first decoding pathway.
19. The integrated circuit of any of claims 15 to 18, wherein the learning model is a trained learning model, wherein the instructions for processing the second copy of the reconstructed frame over the second decoding pathway by using the learning model to identify the video content comprise instructions for:
performing one or more inference operations against the second copy of the reconstructed frame using the trained learning model.
20. The integrated circuit of any of claims 15 to 19, wherein training the learning model by processing the second copy of the reconstructed frame results in a greater classification accuracy upper bound for the learning model than training the learning model by processing a filtered frame produced by filtering the first copy of the reconstructed frame using the in-loop filter.
21. The integrated circuit of any of claims 15 to 20, wherein processing the first copy of the reconstructed frame over the first decoding pathway includes using at least one non-injective function, wherein processing the second copy of the reconstructed frame over the second decoding pathway omits using the at least one non-injective function.
</claims>
</document>
