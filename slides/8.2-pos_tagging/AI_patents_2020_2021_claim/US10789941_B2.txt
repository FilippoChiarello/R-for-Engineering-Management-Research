<document>

<filing_date>
2018-09-28
</filing_date>

<publication_date>
2020-09-29
</publication_date>

<priority_date>
2018-09-28
</priority_date>

<ipc_classes>
G06F17/14,G06F9/54,G06K9/00,G06K9/46,G06K9/62,G06N3/04,G06N3/08,G10L15/02,G10L15/16,G10L15/22,G10L25/51
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
BOCKLET, TOBIAS
KOTARSKI, MATEUSZ
LOPATKA, KUBA
ZABKIEWICZ, MAREK
</inventors>

<docdb_family_id>
65230435
</docdb_family_id>

<title>
Acoustic event detector with reduced resource consumption
</title>

<abstract>
Techniques are provided for efficient acoustic event detection with reduced resource consumption. A methodology implementing the techniques according to an embodiment includes calculating frames of power spectra based on segments of received acoustic signals. The method further includes two processes, one for detecting impulsive acoustic events and another for detecting continuous acoustic events. The first process includes generating impulsive acoustic event features associated with first and second power spectrum frames, applying a neural network classifier to the impulsive acoustic event features to generate event scores, and detecting an impulsive acoustic event based on those event scores. The second process includes generating reduced-dimension continuous acoustic event features associated with the first and second power spectrum frames, applying a neural network classifier to the reduced-dimension continuous acoustic event features to generate a second set of event scores, and detecting a continuous acoustic event based on the second set of event scores.
</abstract>

<claims>
1. A processor-implemented method for acoustic event detection, the method comprising: generating, by a processor-based system, impulsive acoustic event features associated with frames of an acoustic signal; applying, by the processor-based system, a first neural network classifier to the impulsive acoustic event features to generate a first set of event scores, wherein a first event score of the first set of event scores provides an indication of a probability of an acoustic event being a first type of impulsive acoustic event, wherein a second event score of the first set of event scores provides an indication of a probability of the acoustic event being a second type of impulsive acoustic event; detecting, by the processor-based system, the impulsive acoustic event and a type of the impulsive acoustic event from a plurality of types of impulsive acoustic events, wherein the detecting of the impulsive acoustic event comprises calculating a first difference between an event score associated with a target impulsive event from the first set of event scores and an aggregate score associated with non-target impulsive events from the first set of event scores, and detecting the impulsive acoustic event based on the first difference; generating, by the processor-based system, reduced-dimension continuous acoustic event features associated with the frames of the acoustic signal; applying, by the processor-based system, a second neural network classifier to the reduced-dimension continuous acoustic event features to generate a second set of event scores, wherein a third event score of the second set of event scores provides an indication of a probability of the acoustic event being a first type of continuous acoustic event, and wherein a fourth event score of the second set of event scores provides an indication of a probability of the acoustic event being a second type of continuous acoustic event; and detecting, by the processor-based system, a continuous acoustic event, wherein the detecting of the continuous acoustic event comprises calculating a second difference between an event score associated with a target continuous event from the second set of event scores and an aggregate score associated with non-target continuous events from the second set of event scores, and detecting the continuous acoustic event based on the second difference.
2. The method of claim 1, wherein the generating of the impulsive acoustic event features comprises: applying a linear filter bank to the frames of the acoustic signal to distribute the acoustic signal over linearly spaced frequency bins; and calculating a logarithm of the linearly spaced frequency bins to generate the impulsive acoustic event features.
3. The method of claim 1, wherein the generating of the reduced-dimension continuous acoustic event features comprises: applying a non-linear filter bank to the frames of the acoustic signal to distribute the acoustic signal over non-linearly spaced frequency bins; performing a Discrete Cosine Transform (DCT) on the non-linearly spaced frequency bins; calculating a logarithm of the DCT transformed bins to generate Mel-Frequency Cepstral Coefficients (MFCCs); and performing dimensionality reduction on the MFCCs to generate the reduced-dimension continuous acoustic event features.
4. The method of claim 3, wherein the non-linearly spaced frequency bins conform to Mel frequency scaling or Bark frequency scaling.
5. The method of claim 3, wherein the dimensionality reduction comprises applying a DCT based projection operator to a stored history of the MFCCs.
6. The method of claim 1, wherein the first neural network classifier and the second neural network classifier are deep feedforward neural networks comprising a number of fully connected affine layers, the number of layers in the range of 4 to 6 layers.
7. A system for acoustic event detection, the system comprising: an impulsive event frontend processing circuit to generate impulsive acoustic event features associated with frames of an acoustic signal; a first neural network classifier circuit to generate a first set of event scores based on the impulsive acoustic event features, wherein a first event score of the first set of event scores provides an indication of a probability of an acoustic event being a first type of impulsive acoustic event, and wherein a second event score of the first set of event scores provides an indication of a probability of the acoustic event being a second type of impulsive acoustic event; a first plurality of backend processing circuits to receive the first set of event scores, at least one of the first plurality of backend processing circuits to detect the impulsive acoustic event by calculating a first difference between an event score associated with a target impulsive event from the first set of event scores and an aggregate score associated with non-target impulsive events from the first set of event scores, and detecting the impulsive acoustic event based on the first difference; a continuous event frontend processing circuit to generate reduced-dimension continuous acoustic event features associated with frames of the acoustic signal; a second neural network classifier circuit to generate a second set of event scores based on the reduced-dimension continuous acoustic event features, wherein a third event score of the second set of event scores provides an indication of a probability of the acoustic event being a first type of continuous acoustic event, and wherein a fourth event score of the second set of event scores provides an indication of a probability of the acoustic event being a second type of continuous acoustic event; and a second plurality of backend processing circuits to receive the second set of event scores, at least one of the second plurality of backend processing circuits to detect the continuous acoustic event by calculating a second difference between an event score associated with a target continuous event from the second set of event scores and an aggregate score associated with non-target continuous events from the second set of event scores, and detecting the continuous acoustic event based on the second difference.
8. The system of claim 7, wherein the impulsive event frontend processing circuit comprises: a linear filter bank to distribute the acoustic signal over linearly spaced frequency bins; and a logarithm circuit to calculate the logarithm of the linearly spaced frequency bins to generate the impulsive acoustic event features.
9. The system of claim 7, wherein the continuous event frontend processing circuit comprises: a non-linear filter to distribute the acoustic signal over non-linearly spaced frequency bins; a Discrete Cosine Transform (DCT) circuit to perform a DCT on the non-linearly spaced frequency bins; a logarithm circuit to calculate the logarithm of the DCT transformed bins to generate Mel-Frequency Cepstral Coefficients (MFCCs); and a dimensionality reduction circuit to reduce the dimensionality of the MFCCs to generate the reduced-dimension continuous acoustic event features, wherein the dimensionality reduction comprises applying a DCT based projection operator to a stored history of the MFCCs.
10. The system of claim 7, wherein the first neural network classifier circuit and the second neural network classifier circuit are deep feedforward neural networks comprising a number of fully connected affine layers, the number of layers in the range of 4 to 6 layers.
11. At least one non-transitory computer readable storage medium having instructions encoded thereon that, when executed by one or more processors, cause a process to be carried out for acoustic event detection, the process comprising: generating impulsive acoustic event features associated with frames of an acoustic signal associated with an acoustic event; applying a first neural network classifier to the impulsive acoustic event features to generate a first set of event scores, wherein a first event score of the first set of event scores provides an indication of a probability of the acoustic event being a first type of impulsive acoustic event, wherein a second event score of the first set of event scores provides an indication of a probability of the acoustic event being a second type of impulsive acoustic event; detecting an impulsive acoustic event and a type of the impulsive acoustic event, wherein the detecting of the impulsive acoustic event comprises calculating a first difference between an event score associated with a target impulsive event from the first set of event scores and an aggregate score associated with non-target impulsive events from the first set of event scores, and detecting the impulsive acoustic event based on the first difference; generating reduced-dimension continuous acoustic event features associated with frames of the acoustic signal; applying a second neural network classifier to the reduced-dimension continuous acoustic event features to generate a second set of event scores, wherein a third event score of the second set of event scores provides an indication of a probability of the acoustic event being a first type of continuous acoustic event, wherein a fourth event score of the second set of event scores provides an indication of a probability of the acoustic event being a second type of continuous acoustic event; and detecting a continuous acoustic event, wherein the detecting of the continuous acoustic event comprises calculating a second difference between an event score associated with a target continuous event from the second set of event scores and an aggregate score associated with non-target continuous events from the second set of event scores, and detecting the continuous acoustic event based on the second difference.
12. The computer readable storage medium of claim 11, wherein the generating of the impulsive acoustic event features comprises the operations of: applying a linear filter bank to the frames of the acoustic signal to distribute the acoustic signal over linearly spaced frequency bins; and calculating a logarithm of the linearly spaced frequency bins to generate the impulsive acoustic event features.
13. The computer readable storage medium of claim 11, wherein the generating of the reduced-dimension continuous acoustic event features comprises the operations of: applying a non-linear filter bank to the frames of the acoustic signal to distribute the acoustic signal over non-linearly spaced frequency bins; performing a Discrete Cosine Transform (DCT) on the non-linearly spaced frequency bins; calculating a logarithm of the DCT transformed bins to generate Mel-Frequency Cepstral Coefficients (MFCCs); and performing dimensionality reduction on the MFCCs to generate the reduced-dimension continuous acoustic event features.
14. The computer readable storage medium of claim 13, wherein the dimensionality reduction comprises applying a DCT based projection operator to a stored history of the MFCCs.
15. The computer readable storage medium of claim 11, wherein the first neural network classifier and the second neural network classifier are deep feedforward neural networks comprising a number of fully connected affine layers, the number of layers in the range of 4 to 6 layers.
16. The system of claim 7, wherein: each of the first plurality of backend processing circuits is to detect a corresponding type of impulsive acoustic event of a first plurality of impulsive acoustic events; and each of the second plurality of backend processing circuits is to detect a corresponding type of continuous acoustic event of a second plurality of continuous acoustic events.
17. The method of claim 1, wherein the generating of the reduced-dimension continuous acoustic event features comprises: performing dimensionality reduction to generate the reduced-dimension continuous acoustic event features, and wherein the method comprises refraining from applying dimensionality reduction while generating the impulsive acoustic event features.
</claims>
</document>
