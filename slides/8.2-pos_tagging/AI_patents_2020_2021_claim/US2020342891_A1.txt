<document>

<filing_date>
2020-04-24
</filing_date>

<publication_date>
2020-10-29
</publication_date>

<priority_date>
2019-04-26
</priority_date>

<ipc_classes>
G10L15/16,G10L21/0264,G10L25/18
</ipc_classes>

<assignee>
BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT COMPANY
</assignee>

<inventors>
ZHANG YI
SONG, HUI
Deng, Chengyun
Sha, Yongtao
</inventors>

<docdb_family_id>
72917337
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR ADUIO SIGNAL PROCESSING USING SPECTRAL-SPATIAL MASK ESTIMATION
</title>

<abstract>
Embodiments of the disclosure provide systems and methods for audio signal processing. An exemplary system may include a communication interface configured to receiving a first audio signal acquired from an audio source through a first channel, and a second audio signal acquired from the same audio source through a second channel. The system may also include at least one processor coupled to the communication interface. The at least one processor may be configured to determine channel features based on the first audio signal and the second audio signal individually and determine a cross-channel feature based on the first audio signal and the second audio signal collectively. The at least one processor may further be configured to concatenate the channel features and the cross-channel feature and estimate spectral-spatial masks for the first channel and the second channel using the concatenated channel features and the cross-channel feature. The at least one processor may also be configured to perform beamforming based on the spectral-spatial masks for the first channel and the second channel.
</abstract>

<claims>
1. A system for audio signal processing, comprising: a communication interface configured to receiving a first audio signal acquired from an audio source through a first channel, and a second audio signal acquired from the same audio source through a second channel; and at least one processor coupled to the communication interface and configured to: determine channel features based on the first audio signal and the second audio signal individually; determine a cross-channel feature based on the first audio signal and the second audio signal collectively; concatenate the channel features and the cross-channel feature; estimate spectral-spatial masks for the first channel and the second channel using the concatenated channel features and the cross-channel feature; and perform beamforming based on the spectral-spatial masks for the first channel and the second channel.
2. The system of claim 1, wherein to jointly estimate spectral-spatial masks for the first channel and the second channel, the at least one processor is further configured to: apply a neural network learning model to the concatenated channel features and the cross-channel feature.
3. The system of claim 2, wherein the neural network learning model is a Bidirectional Long Short-Term Memory (BLSTM) with multiple channels.
4. The system of claim 1, wherein to determine the channel features, the at least one processor is further configured to: determine a first magnitude spectrum of the first audio signal and a second magnitude spectrum of the second audio signal, respectively.
5. The system of claim 4, wherein to determine the cross-channel feature, the at least one processor is further configured to: determine an inter-channel level difference as a ratio between the first magnitude spectrum and the second magnitude spectrum.
6. The system of claim 1, wherein to determine the cross-channel feature, the at least one processor is further configured to: determine a first phase spectrum of the first audio signal and a second phase spectrum of the second audio signal, respectively; and determine an inter-channel phase difference as a difference between the first phase spectrum and the second phase spectrum.
7. The system of claim 6, wherein the at least one processor is further configured to: perform a trigonometric function on the inter-channel phase difference.
8. The system of claim 1, wherein the spectral-spatial masks for the first channel include a first speech mask and a first noise mask for the first audio signal, and the spectral-spatial masks for the second channel include a second speech mask and a second noise mask for the second audio signal, wherein the first speech mask, the first noise mask, the second speech mask, and the second noise mask are jointly estimated.
9. The system of claim 8, wherein to perform the beamforming, the at least one processor is further configured to: determine time-frequency representations by performing a Short Time Fourier Transform (STFT) to the first audio signal and the second audio signal; calculate a speech Cross Power Spectral Density (CPSD) matrix based on the first speech mask, the second speech mask, and the time-frequency representations; calculate a noise CPSD matrix based on the first noise mask, the second noise mask, and the time-frequency representations; and perform beamforming using the speech CPSD matrix and the noise CPSD matrix.
10. The system of claim 1, wherein the communication interface is further configured to receiving a third audio signal acquired from the same audio source; and the at least one processor is further configured to: determine an additional channel feature based on the third audio signal; determine an additional cross-channel feature based on the first audio signal and the third audio signal collectively; concatenate the channel features and the cross-channel features; estimate spectral-spatial masks for the first channel, the second channel, and the third channel using the concatenated channel features and the cross-channel feature; and perform beamforming on the spectral-spatial masks for the first channel, the second channel, and the third channel.
11. The system of claim 10, wherein the additional cross-channel feature is indicative of a phase difference between phase spectra of the first audio signal and the third audio signal.
12. A method audio signal processing, comprising: receiving a first audio signal acquired from an audio source through a first channel, and a second audio signal acquired from the same audio source through a second channel; determining channel features based on the first audio signal and the second audio signal individually; determining a cross-channel feature based on the first audio signal and the second audio signal collectively; concatenating the channel features and the cross-channel feature; estimating spectral-spatial masks for the first channel and the second channel using the concatenated channel features and the cross-channel feature; and performing beamforming based on the spectral-spatial masks for the first channel and the second channel.
13. The method of claim 12, wherein estimating spectral-spatial masks for the first channel and the second channel further comprises: applying a neural network learning model to the concatenated channel features and the cross-channel feature.
14. The method of claim 12, wherein determining channel features further comprises: determining a first magnitude spectrum of the first audio signal and a second magnitude spectrum of the second audio signal, respectively.
15. The method of claim 14, wherein determining the cross-channel feature further comprises: determining an inter-channel level difference as a ratio between the first magnitude spectrum and the second magnitude spectrum.
16. The method of claim 12, wherein determining the cross-channel feature further comprises: determining a first phase spectrum of the first audio signal and a second phase spectrum of the second audio signal, respectively; and determining an inter-channel phase difference as a difference between the first phase spectrum and the second phase spectrum.
17. The method of claim 12, wherein the spectral-spatial masks for the first channel include a first speech mask and a first noise mask for the first audio signal, and the spectral-spatial masks for the second channel include a second speech mask and a second noise mask for the second audio signal, wherein the first speech mask, the first noise mask, the second speech mask, and the second noise mask are jointly estimated.
18. The method of claim 17, further comprising: determining time-frequency representations by performing a Short Time Fourier Transform (STFT) to the first audio signal and the second audio signal; calculating a speech Cross Power Spectral Density (CPSD) matrix based on the first speech mask, the second speech mask, and the time-frequency representations; calculating a noise CPSD matrix based on the first noise mask, the second noise mask, and the time-frequency representations; and performing beamforming using the speech CPSD matrix and the noise CPSD matrix.
19. The method of claim 12, further comprising: receiving a third audio signal acquired from the same audio source; determining an additional channel feature based on the third audio signal; determining an additional cross-channel feature based on the first audio signal and the third audio signal collectively; concatenating the channel features and the cross-channel features; estimating spectral-spatial masks for the first channel, the second channel, and the third channel using the concatenated channel features and the cross-channel feature; and performing beamforming on the spectral-spatial masks for the first channel, the second channel, and the third channel.
20. A non-transitory computer-readable medium storing instructions that, when executed by one or more processors, cause the one or more processors to perform a method for audio signal processing, the method comprising: receiving a first audio signal acquired from an audio source through a first channel, and a second audio signal acquired from the same audio source through a second channel; determining channel features based on the first audio signal and the second audio signal individually; determining a cross-channel feature based on the first audio signal and the second audio signal collectively; concatenating the channel features and the cross-channel feature; estimating spectral-spatial masks for the first channel and the second channel using the concatenated channel features and the cross-channel feature; and performing beamforming based on the spectral-spatial masks for the first channel and the second channel.
</claims>
</document>
