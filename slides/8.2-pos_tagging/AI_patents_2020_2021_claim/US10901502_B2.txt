<document>

<filing_date>
2019-06-27
</filing_date>

<publication_date>
2021-01-26
</publication_date>

<priority_date>
2019-06-27
</priority_date>

<ipc_classes>
G02B27/01,G06F3/01,G06F3/0481,G06N20/00,G06T19/00
</ipc_classes>

<assignee>
FACEBOOK
</assignee>

<inventors>
MACKENZIE, KEVIN JAMES
TERRANO, MARK
Erkelens, Ian
</inventors>

<docdb_family_id>
74043070
</docdb_family_id>

<title>
Reducing head mounted display power consumption and heat generation through predictive rendering of content
</title>

<abstract>
Systems, methods, and non-transitory computer-readable media are disclosed for selectively rendering augmented reality content based on predictions regarding a user's ability to visually process the augmented reality content. For instance, the disclosed systems can identify eye tracking information for a user at an initial time. Moreover, the disclosed systems can predict a change in an ability of the user to visually process an augmented reality element at a future time based on the eye tracking information. Additionally, the disclosed systems can selectively render the augmented reality element at the future time based on the predicted change in the ability of the user to visually process the augmented reality element.
</abstract>

<claims>
1. A computer-implemented method comprising: identifying, by an augmented reality system comprising a head mounted display, eye tracking information for a user at an initial time; predicting a change in an ability of the user to visually process an augmented reality element at a future time, within a display of the head mounted display, based on a characteristic of the augmented reality element and using a machine learning model to analyze the eye tracking information for the user at the initial time; and selectively rendering the augmented reality element, within the display of the head mounted display, at the future time based on the predicted change in the ability of the user to visually process the augmented reality element.
2. The computer-implemented method of claim 1, wherein the eye tracking information for the user comprises at least one of eye movement, head movement, or eyelid movement.
3. The computer-implemented method of claim 2, wherein identifying the eye tracking information comprises detecting at least one of an eye movement vector, a blink, or a saccade movement.
4. The computer-implemented method of claim 1, wherein predicting the change in the ability of the user to visually process the augmented reality element at the future time comprises predicting that the user will be unable to visually process the augmented reality element at the future time; and wherein selectively rendering the augmented reality element at the future time comprises terminating a display of the augmented reality element at the future time based on predicting that the user will be unable to visually process the augmented reality element.
5. The computer-implemented method of claim 4, wherein predicting that the user will be unable to visually process the augmented reality element at the future time comprises predicting that the user will blink; and wherein selectively rendering the augmented reality element at the future time comprises terminating the display of the augmented reality element during at least a partial duration of the predicted blink.
6. The computer-implemented method of claim 4, wherein predicting that the user will be unable to visually process the augmented reality element at the future time comprises predicting a beginning of a saccade; and wherein selectively rendering the augmented reality element at the future time comprises terminating the display of the augmented reality element during at least a partial duration of the predicted saccade.
7. The computer-implemented method of claim 1, wherein predicting the change in the ability of the user to visually process the augmented reality element at the future time comprises predicting that the user will become able to visually process the augmented reality element at the future time; and wherein selectively rendering the augmented reality element at the future time comprises displaying the augmented reality element at the future time based on predicting that the user will become able to visually process the augmented reality.
8. The computer-implemented method of claim 7, wherein predicting that the user will become able to visually process the augmented reality element at the future time comprises predicting that the augmented reality element will enter a rendering area of the head mounted display, and wherein selectively rendering the augmented reality element at the future time comprises initiating a graphics pipeline for the augmented reality element in anticipation of the augmented reality element entering the rendering area of the head mounted display.
9. The computer-implemented method of claim 1, further comprising predicting the change in the ability of the user to visually process the augmented reality element at the future time using the machine learning model to analyze the eye tracking information for the user at the initial time and user characteristics of the user.
10. The computer-implemented method of claim 1, wherein selectively rendering the augmented reality element comprises at least one of: displaying the augmented reality element; terminating a display of the augmented reality element; reducing a frame rate of the augmented reality element; reducing a resolution of the augmented reality element; calculating a position of the augmented reality element; or terminating the calculation of the position of the augmented reality element.
11. The computer-implemented method of claim 1, wherein the machine learning model is trained to, based on the eye tracking information for the user at the initial time, predict subsequent eye movement of the user.
12. An augmented reality system comprising: at least one head mounted display; at least one processor; and at least one non-transitory computer-readable storage medium storing instructions that, when executed by the at least one processor, cause the augmented reality system to: identify eye tracking information for a user at an initial time; predict a change in an ability of the user to visually process an augmented reality element at a future time, within a display of the head mounted display, based on a characteristic of the augmented reality element and using a machine learning model to analyze the eye tracking information for the user at the initial time; and selectively render the augmented reality element, within the display of the head mounted display, at the future time based on the predicted change in the ability of the user to visually process the augmented reality element.
13. The augmented reality system of claim 12, wherein the eye tracking information for the user comprises at least one of eye movement, head movement, or eyelid movement.
14. The augmented reality system of claim 12, wherein predicting the change in the ability of the user to visually process the augmented reality element at the future time comprises predicting that the user will be unable to visually process the augmented reality element at the future time; and wherein selectively rendering the augmented reality element at the future time comprises terminating a display of the augmented reality element at the future time based on predicting that the user will be unable to visually process the augmented reality element.
15. The augmented reality system of claim 14, wherein predicting that the user will be unable to visually process the augmented reality element at the future time comprises predicting that the user will blink; and wherein selectively rendering the augmented reality element at the future time comprises terminating the display of the augmented reality element during at least a partial duration of the predicted blink.
16. The augmented reality system of claim 12, wherein predicting the change in the ability of the user to visually process the augmented reality element at the future time comprises predicting that the user will become able to visually process the augmented reality element at the future time; and wherein selectively rendering the augmented reality element at the future time comprises displaying the augmented reality element at the future time based on predicting that the user will become able to visually process the augmented reality element.
17. A non-transitory computer-readable medium storing instructions that, when executed by at least one processor, cause a computer system comprising a head mounted display to: identify eye tracking information for a user at an initial time; predict a change in an ability of the user to visually process an augmented reality element at a future time, within a display of the head mounted display, based on a characteristic of the augmented reality element and using a machine learning model to analyze the eye tracking information for the user at the initial time; and selectively render the augmented reality element, within the display of the head mounted display, at the future time based on the predicted change in the ability of the user to visually process the augmented reality element.
18. The non-transitory computer-readable medium of claim 17, wherein: the eye tracking information for the user comprises at least one of eye movement, head movement, or eyelid movement; and the characteristics of the augmented reality element comprise at least a size of the augmented reality element.
19. The non-transitory computer-readable medium of claim 17, wherein predicting the change in the ability of the user to visually process the augmented reality element at the future time comprises predicting that the user will be unable to visually process the augmented reality element at the future time; and wherein selectively rendering the augmented reality element at the future time comprises terminating a display of the augmented reality element at the future time based on predicting that the user will be unable to visually process the augmented reality element.
20. The non-transitory computer-readable medium of claim 17, wherein predicting the change in the ability of the user to visually process the augmented reality element at the future time comprises predicting that the user will become able to visually process the augmented reality element at the future time; and wherein selectively rendering the augmented reality element at the future time comprises displaying the augmented reality element at the future time based on predicting that the user will become able to visually process the augmented reality element.
</claims>
</document>
