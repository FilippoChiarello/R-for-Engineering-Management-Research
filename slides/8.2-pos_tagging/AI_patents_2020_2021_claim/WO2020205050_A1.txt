<document>

<filing_date>
2020-02-03
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-03-29
</priority_date>

<ipc_classes>
G06F16/901,G06F16/9032
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
LI BING
DENG, YONGGANG
YAN RUI
HE, YUJIE
CHAI, Junyi
GUAN, Maochen
</inventors>

<docdb_family_id>
69740796
</docdb_family_id>

<title>
TRAINING UTTERANCE GENERATION
</title>

<abstract>
A server computing device, including memory storing a knowledge graph including a plurality of ontology entities connected by a plurality of edges. The server computing device may further include a processor configured to generate a glossary file based on the knowledge graph. The glossary file may include a plurality of ontology entities included in the knowledge graph. The processor may receive a plurality of utterance templates. Each utterance template may include an utterance and a predefined intention. For each utterance template, the processor may generate one or more utterance template copies in which one or more ontology entities included in the utterance are replaced with one or more utterance template fields. The processor may generate a plurality of training utterances at least in part by filling the one or more utterance template fields of the one or more utterance template copies with respective ontology entities included in the glossary file.
</abstract>

<claims>
1. A server computing device comprising:
memory storing a knowledge graph including a plurality of ontology entities connected by a plurality of edges;
a processor configured to:
generate a glossary file based on the knowledge graph, wherein the glossary file includes a plurality of ontology entities included in the knowledge graph;
receive a plurality of utterance templates, wherein each utterance template includes an utterance and a predefined intention associated with that utterance;
for each utterance template, generate one or more utterance template copies in which one or more ontology entities included in the utterance are replaced with one or more utterance template fields; and
generate a plurality of training utterances at least in part by filling the one or more utterance template fields of the one or more utterance template copies with respective ontology entities included in the glossary file.
2. The server computing device of claim 1, wherein the processor is further configured to train an intention detector using the plurality of training utterances.
3. The server computing device of claim 2, wherein the intention detector includes a bidirectional long short-term memory (LSTM) network.
4. The server computing device of claim 1, wherein the glossary file further includes a respective ontology entity type of each ontology entity of the plurality of ontology entities.
5. The server computing device of claim 4, wherein:
each utterance template further indicates one or more ontology entity types included in its respective utterance; and
the one or more ontology entity types included in the utterance are selected from the plurality of ontology entity types included in the knowledge graph.
6. The server computing device of claim 5, wherein each training utterance further indicates the one or more respective ontology entity types associated with the one or more respective ontology entities included in that training utterance.
7. The server computing device of claim 5, wherein the processor is configured to fill the at least one utterance template field at least in part by determining that the at least one ontology entity with which the at least one utterance template is filled has an ontology entity type matching an utterance template field type of the at least one utterance template field.
8. The server computing device of claim 1, wherein each ontology entity of the knowledge graph has a respective weight indicated by the glossary file.
9. The server computing device of claim 1, wherein each training utterance includes a training utterance intention selected from among the respective plurality of predefined intentions included in the plurality of utterance templates.
10. A method for use with a server computing device, the method comprising:
storing in memory a knowledge graph including a plurality of ontology entities connected by a plurality of edges;
generating a glossary file based on the knowledge graph, wherein the glossary file includes a plurality of ontology entities included in the knowledge graph;
receiving a plurality of utterance templates, wherein each utterance template includes an utterance and a predefined intention associated with that utterance;
for each utterance template, generating one or more utterance template copies in which one or more ontology entities included in the utterance are replaced with one or more utterance template fields; and
generating a plurality of training utterances at least in part by filling the one or more utterance template fields of the one or more utterance template copies with respective ontology entities included in the glossary file.
11. The method of claim 10, further comprising training an intention detector using the plurality of training utterances.
12. The method of claim 10, wherein the glossary file further includes a respective ontology entity type of each ontology entity of the plurality of ontology entities.
13. The method of claim 12, wherein:
each utterance template further indicates one or more ontology entity types included in its respective utterance; and
the one or more ontology entity types included in the utterance are selected from the plurality of ontology entity types included in the knowledge graph.
14. The method of claim 13, wherein each training utterance further indicates the one or more respective ontology entity types associated with the one or more respective ontology entities included in that training utterance.
15. The method of claim 10, wherein each training utterance includes a training utterance intention selected from among the respective plurality of predefined intentions included in the plurality of utterance templates.
</claims>
</document>
