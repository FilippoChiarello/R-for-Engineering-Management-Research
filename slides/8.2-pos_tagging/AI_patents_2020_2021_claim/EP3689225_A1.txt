<document>

<filing_date>
2020-01-30
</filing_date>

<publication_date>
2020-08-05
</publication_date>

<priority_date>
2019-01-30
</priority_date>

<ipc_classes>
A61B3/00,A61B3/103,A61B3/14
</ipc_classes>

<assignee>
FIELMANN VENTURES
</assignee>

<inventors>
SCHROETER, FRANZISKA
</inventors>

<docdb_family_id>
69411281
</docdb_family_id>

<title>
METHOD, SOFTWARE PRODUCT AND SYSTEM FOR DETERMINING REFRACTION ON A MOBILE TERMINAL
</title>

<abstract>
Die Erfindung betrifft ein Verfahren und ein Softwareprodukt zur Refraktionsbestimmung auf einem mobilen Endgerät (20), sowie ein System.Das mobile Endgerät wird in einem Aufnahmeabstand vor einem der Refraktionsbestimmung zu unterziehenden Messsubjekt (10) positioniert, dessen Augen (12) einer exzentrischen Photorefraktion zu unterziehen sind, so dass die Kamera (24, 26) und die Lichtquelle (28) auf das Gesicht des Messsubjekts (10) gerichtet sind. Es werden Testbilder des Messsubjekts (10) ohne und/oder mit zugeschaltetem Licht aus der Lichtquelle (28) aufgenommen und Aufnahmeabstands A, Aufnahmeparameter, Lichtbedingungen und/oder Ausrichtung des mobilen Endgeräts (20) zur Person (10) anhand der Testbilder optimiert, bis eine zur exzentrischen Photorefraktion geeignete Einstellung gefunden ist. Ferner wird eine Mehrzahl von Messaufnahmen des Messsubjekts (10) aufgenommen, die Mehrzahl von Messaufnahmen im Zuge einer Refraktionsauswertung ausgewertet, wobei Werte für die winkelabhängige Brechkraft eines oder beider Augen (12) ermittelt werden, insbesondere Werte fürSph,CylundAchse.Die Messergebnisse werden ausgegeben und/oder gespeichert.Erfindungsgemäß wird oder werden bei der Auswertung der Testbilder, der Messaufnahmen und/oder bei der Refraktionsauswertung Machine Learning, insbesondere neuronale Netze, eingesetzt.
</abstract>

<claims>
1. Verfahren zur Refraktionsbestimmung an einem Messsubjekt, (10) dessen Augen einer exzentrischen Photorefraktion zu unterziehen sind, auf einem mobilen Endgerät (20), welches eine Kamera (24, 26) mit einer Linse und eine schaltbare Lichtquelle (28) umfasst, die mit einem festen Abstand neben der Linse angeordnet ist, mit den folgenden Verfahrensschritten: a) Positionieren des mobilen Endgeräts (20) in einem initialen Aufnahmeabstand A vor dem Messsubjekt (10), so dass die Kamera (24, 26) und die Lichtquelle (28) auf das Gesicht des Messsubjekts (10) gerichtet sind, b) Aufnehmen von Testbildern des Messsubjekts (10) ohne und/oder mit zugeschaltetem Licht aus der Lichtquelle (28) und Optimieren des Aufnahmeabstands A in Abhängigkeit von der Brechkraft des Auges oder der Augen des Messsubjekts (10) sowie Optimieren von Aufnahmeparametern, von Lichtbedingungen und/oder der Ausrichtung des mobilen Endgeräts (20) zum Messsubjekt (10) anhand der Testbilder, bis eine zur exzentrischen Photorefraktion geeignete Einstellung gefunden ist, c) Aufnehmen einer Mehrzahl von Messaufnahmen des Messsubjekts (10), wobei das mobile Endgerät (20) durch Rotation um eine Achse, die parallel zur optischen Achse der Linse verläuft, nacheinander in zwei oder mehr Winkelorientierungen gebracht wird und in jeder Winkelorientierung eine oder mehrere Messaufnahmen aufgenommen werden, d) Auswerten der Mehrzahl von Messaufnahmen im Zuge einer Refraktionsauswertung, wobei Werte für die winkelabhängige Brechkraft eines oder beider Augen (12) ermittelt werden, insbesondere Werte für Sph, Cyl und Achse, e) Ausgeben und/oder Speichern der Messergebnisse, insbesondere der Werte für Sph, Cyl und Achse eines oder beider Augen (12) des Messsubjekts (10), wobei bei der Auswertung der Testbilder, der Messaufnahmen und/oder bei der Refraktionsauswertung Machine Learning, insbesondere neuronale Netze, in dem mobilen Endgerät oder in einem mit dem mobilen Endgerät datenverbundenen Server (32) eingesetzt wird oder werden.
2. Verfahren nach Anspruch 1, dadurch gekennzeichnet, dass an der Mehrzahl von Testbildern und/oder Messaufnahmen eine bimeridionale oder multimeridionale Refraktionsauswertung ausgeführt wird, wobei an der Mehrzahl von Testbildern und/oder Messaufnahmen jeweils eine Bildanalyse durchgeführt wird, wobei in den Messaufnahmen das Vorhandensein, Größe, Orientierung, Ort, Form und/oder Intensitätsverlauf von reflektiertem Licht, welches in den Messaufnahmen als Möndchen (18) in den Pupillen (16) des Messsubjekts (10) erscheint, sowie der Aufnahmeabstand A ermittelt werden, wobei insbesondere für die bimeridionale Auswertung Messaufnahmen in zwei zueinander senkrecht stehenden Winkelorientierungen aufgenommen werden, insbesondere im Hochund Querformat, und/oder für die multimeridionale Auswertung Messaufnahmen in wenigstens drei, vorzugsweise vier, fünf oder mehr, verschiedenen Winkelorientierungen aufgenommen werden, insbesondere in Winkelabständen von 30°.
3. Verfahren nach Anspruch 1 oder 2, dadurch gekennzeichnet, dass ein Aufnahmeabstand gewählt wird, der etwas, insbesondere bis zu 40%, insbesondere bis zu 20%, größer als der Fernpunkt wenigstens eines Auges (12) des Messsubjekts (10) ist.
4. Verfahren nach einem der Ansprüche 1 bis 3, dadurch gekennzeichnet, dass im Verfahrensschritt b) oder c) zu jeder Messaufnahme geprüft wird, ob diese verwertbar ist, und eine Änderung der Winkelorientierung des Endgeräts (20) dann veranlasst wird, wenn in der bisherigen Winkelorientierung eine festgelegte oder ausreichende Anzahl verwertbarer Messaufnahmen aufgenommen worden ist, wobei insbesondere die Bildanalyse einer Messaufnahme unmittelbar nach dem Aufnehmen der Messaufnahme im Verfahrensschritt c) erfolgt.
5. Verfahren nach einem der Ansprüche 1 bis 4, dadurch gekennzeichnet, dass in den Messaufnahmen das Gesicht des Messsubjekts (10), die Augen (12), die Iris (14) und/oder die Pupille(n) (16) erkannt wird oder werden und ihre Größe, insbesondere in Pixeln, bestimmt werden, sowie das oder die Möndchen (18) innerhalb der erkannten Iris oder Irides (14) erkannt wird oder werden.
6. Verfahren nach Anspruch 5, dadurch gekennzeichnet, dass bei der Erkennung des Gesichts, der Augen (12), der Iris (14), der Pupille (16) und/oder des Möndchens (18) ein oder mehrere neuronale Netzwerke eingesetzt werden, das oder die zuvor für die entsprechende Erkennung trainiert worden war oder waren, wobei insbesondere bei der Bestimmung von Größe, Lage und/oder Helligkeitsverlauf des Möndchens (18) oder der Möndchen (18) eine durch Machine Learning unterstützte Superresolution verwendet wird, die insbesondere unter Verwendung von neuronalen Netzen durchgeführt wird, die anhand von Bildern in hoher und niedriger Auflösung trainiert worden sind, insbesondere dahingehend, die Kante eines Möndchens in der Pupille zu erkennen und zu verdeutlichen.
7. Verfahren nach einem der Ansprüche 1 bis 6, dadurch gekennzeichnet, dass ein System künstlicher Intelligenz, insbesondere Machine Learning oder ein neuronales Netzwerk, eingesetzt wird, um ausgehend von einem oder mehreren Messaufnahmen mit Möndchen (18) und den zugehörigen Messparametern Messabstand A und Exzentrizität e der Lichtquelle Messwerte für Sph, Cyl und Achse zu ermitteln, wobei das System künstlicher Intelligenz zuvor mit Messaufnahmen mit Möndchen (18) von Referenzsubjekten mit bekannten Werten von Sph, Cyl und Achse trainiert worden war.
8. Verfahren nach einem der Ansprüche 1 bis 7, dadurch gekennzeichnet, dass Güte und/oder Verlässlichkeit der Messergebnisse berechnet wird oder werden und bei nicht ausreichender Güte und/oder Verlässlichkeit das Messsubjekt (10) aufgefordert wird, einzelne oder alle Schritte der Messung zu wiederholen oder eine Refraktionsbestimmung beim Augenoptiker durchführen zu lassen.
9. Verfahren nach einem der Ansprüche 1 bis 8, dadurch gekennzeichnet, dass zur Ermittlung des Aufnahmeabstands A eine Pupillendistanz (PD) des Messsubjekts (10) zugrunde gelegt wird, die aus früheren Messungen vorliegt oder vor Durchführung der Messaufnahmen gemessen wird, oder Messdaten eines Abstandssensors oder einer Tiefenkamera des mobilen Endgeräts (20) verwendet werden.
10. Verfahren nach einem der Ansprüche 1 bis 9, dadurch gekennzeichnet, dass zur Bestimmung des Orientierungswinkels einer Messaufnahme ein Orientierungswinkel der Verbindungslinie der Pupillen (16) des Messsubjekts (10) in der Messaufnahme zugrunde gelegt wird, und/oder Messdaten von Neigungssensoren, Magnetfeldsensoren und/oder Beschleunigungssensoren des mobilen Endgeräts (20) verwendet werden.
11. Verfahren nach einem der Ansprüche 1 bis 10, dadurch gekennzeichnet, dass die Auswertung der Messaufnahmen, insbesondere die Erkennung und Vermessung der Möndchen (18), und/ oder die Refraktionsbestimmung von einer auswertenden Person und/oder unter Verwendung von deterministischen Methoden unterstützt und/oder kontrolliert wird.
12. Verfahren nach einem der Ansprüche 1 bis 11, dadurch gekennzeichnet, dass bei der Durchführung eines oder mehrerer der Verfahrensschritte a) bis f) eine Sprachausgabe und/oder Sprachsteuerung und/oder eine Fernbedienung über ein entferntes Gerät, welches mit dem mobilen Endgerät kommunikativ verbunden ist, insbesondere eine Smart-Watch oder ein Tablet-Gerät, eingesetzt wird, wobei in einer Sprachausgabe und/oder einer Ausgabe über das entferne Gerät Anweisungen an das Messsubjekt (10) oder eine Bedienperson gegeben werden, insbesondere in Bezug auf Haltung und Aufnahmeabstand, wobei in einer Sprachsteuerung und/oder einer Steuerung über das entfernte Gerät das Messsubjekt (10) oder eine andere Bedienperson das mobile Endgerät (20) anweist, Testaufnahmen oder Messaufnahmen aufzunehmen und insbesondere auszuwerten.
13. Verfahren nach einem der Ansprüche 1 bis 12, dadurch gekennzeichnet, dass zusätzlich eine Sehstärkenbestimmung (Visusbestimmung) durchgeführt wird und/oder dem Messsubjekt (10) zusätzlich ein oder mehrere subjektive Tests angezeigt werden, insbesondere ein Astigmatismustest oder ein Rot-Grün-Test.
14. Softwareprodukt, welches ausgelegt ist, auf einem mobilen Endgerät (20) abzulaufen und bei Ablaufen auf dem mobilen Endgerät (20) ein Verfahren zur Refraktionsbestimmung gemäß einem der Ansprüche 1 bis 13 auszuführen.
15. System (30) mit wenigstens einem zentralen Server (32) und einer Mehrzahl von mobilen Endgeräten (20), auf denen ein Softwareprodukt gemäß Anspruch 14 installiert ist, wobei die mobilen Endgeräte (20) mittels des Softwareprodukts eingerichtet sind, Datensätze mit den aufgenommenen Messaufnahmen, insbesondere zusammen mit den endgültig gemessenen Werten für Sph, Cyl und Achse, an den wenigstens einen zentralen Server (32) zu übermitteln, wobei der Server (32) eingerichtet ist, anhand eines Teils oder aller übermittelten Datensätze Machine Learning durchzuführen, wobei insbesondere die mobilen Endgeräte (20) des Systems (30) mittels des Softwareprodukts eingerichtet sind, im Machine Learning gelernte Parameter vom Server (32) abzurufen, insbesondere vor Durchführung einer neuen Photorefraktionsbestimmung.
</claims>
</document>
