<document>

<filing_date>
2020-01-17
</filing_date>

<publication_date>
2020-08-05
</publication_date>

<priority_date>
2019-01-29
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62
</ipc_classes>

<assignee>
STRADVISION
</assignee>

<inventors>
JANG, TAEWOONG
CHO, HOJIN
RYU, WOOJU
BOO, SUKHOON
NAM, WOONHYUN
KIM, HAK-KYOUNG
SUNG, MYUNGCHUL
YEO, DONGHUN
JEONG, KYUNGJOONG
KIM, INSU
KIM, YONGJOONG
KIM, KYE-HYEON
JE, HONGMO
</inventors>

<docdb_family_id>
67477700
</docdb_family_id>

<title>
METHOD AND DEVICE FOR MERGING OBJECT DETECTION INFORMATION DETECTED BY EACH OF OBJECT DETECTORS CORRESPONDING TO EACH CAMERA NEARBY FOR THE PURPOSE OF COLLABORATIVE DRIVING BY USING V2X-ENABLED APPLICATIONS, SENSOR FUSION VIA MULTIPLE VEHICLES
</title>

<abstract>
A method for merging object detection information detected by object detectors, each of which corresponds to each of cameras located nearby, by using V2X-based auto labeling and evaluation, wherein the object detectors detect objects in each of images generated from each of the cameras by image analysis based on deep learning is provided. The method includes steps of: if first to n-th object detection information are respectively acquired from a first to an n-th object detectors in a descending order of degrees of detection reliabilities, a merging device generating (k-1)-th object merging information by merging (k-2)-th objects and k-th objects through matching operations, and re-projecting the (k-1)-th object merging information onto an image, by increasing k from 3 to n. The method can be used for a collaborative driving or an HD map update through V2X-enabled applications, sensor fusion via multiple vehicles, and the like.
</abstract>

<claims>
1. A method for merging object detection information detected by object detectors, each of which corresponds to each of cameras located nearby, wherein the object detectors detect objects in each of images generated from each of the cameras by image analysis based on deep learning, comprising steps of: (a) a specific merging device, corresponding to a specific object detector, among merging devices corresponding to the object detectors, if object detection information is acquired from the object detectors, each of which corresponds to each of the cameras located nearby, determining an order of degrees of each set of detection reliabilities of each of the object detectors by referring to the object detection information, wherein each piece of the object detection information includes one or more primary objects corresponding to one or more image-taking bodies whose corresponding cameras take each of the images and one or more secondary objects corresponding to one or more image-taken bodies appearing on at least part of the images generated by each of the cameras; and (b) the specific merging device, supposing that at least part of the object detectors are designated as a first object detector to an n-th object detector in a descending order of the degrees of each set of the detection reliabilities and that each piece of the object detection information acquired from each of the first object detector to the n-th object detector is designated as first object detection information to n-th object detection information, (i) confirming correspondence between first total objects in the first object detection information and second total objects in the second object detection information via at least one matching operation, by referring to the first object detection information and the second object detection information and generating first object merging information by merging the first total objects and the second total objects (ii) confirming correspondence between (k-2)-th objects included in the (k-2)-th object merging information and k-th objects in the k-th object detection information through the matching operation by referring to (k-2)-th object merging information and k-th object detection information, generating (k-1)-th object merging information by merging the (k-2)-th objects and the k-th objects, and re-projecting the (k-1)-th object merging information onto at least one specific image acquired from at least one specific camera corresponding to the specific object detector, by increasing k from 3 to n, wherein the first total objects include the primary objects and the secondary objects, and the second total objects include the primary objects and the secondary objects.
2. The method of Claim 1, wherein the method further comprises a step of:
(c) the specific merging device updating a specific detection reliability of the specific object detector by referring to a degree of similarity between the (k-1)-th object merging information and specific object detection information of the specific object detector.
3. The method of Claim 1, wherein the method further comprises a step of:
(d) the specific merging device auto-labeling (k-1)-th objects in the (k-1)-th object merging information, and learning at least part of one or more parameters of the specific object detector by referring to labels generated by the auto-labeling.
4. The method of Claim 1, wherein each piece of the object detection information includes information on each of the primary objects and information on each of the secondary objects,
wherein the information on each of the primary objects includes status information on each of the primary objects and each set of the detection reliabilities of each of the object detectors corresponding to each of the primary objects, wherein the status information on each of the primary objects includes current location information, current direction information, and current speed information of each of the primary objects, and
wherein the information on each of the secondary objects includes status information on each of the secondary objects and product information on each of the secondary objects wherein the status information on each of the secondary objects includes current location information, current direction information, and current speed information of each of the secondary object.
5. The method of Claim 4, wherein the information on each of the primary objects includes one of product information on each of the primary objects and each piece of product information of each of the object detectors corresponding to each of the primary objects.
6. The method of Claim 5, wherein, at the step of (a), the specific merging device performs one of processes of (i) determining the order of degrees of each set of the detection reliabilities of each of the object detectors using the received detection reliabilities, (ii) determining the order of degrees of each set of the detection reliabilities of each of the object detectors by referring to preset first reliabilities corresponding to each piece of the product information of each of the object detectors, and (iii) determining the order of degrees of each set of the detection reliabilities of each of the object detectors by referring to a preset second reliability set as a base reliability if no feature information of the object detectors is acquired.
7. The method of Claim 1, wherein, supposing that first total objects corresponding to one of the first object detection information and the (k-2)-th object merging information are designated as A1 to Ai and that second total objects corresponding to one of the second object detection information and the k-th object detection information are designated as B1 to Bj, wherein the first total objects include the primary objects and the secondary objects, and the second total objects include the primary objects and the secondary objects,
at the step of (b), the specific merging device calculates cost of correspondence between said A1 to Ai and said B1 to Bj by the matching operation, and merges said A1 to Ai and said B1 to Bj according to the calculated cost.
8. The method of Claim 7, wherein the specific merging device calculates the cost of correspondence between said A1 to Ai and said B1 to Bj by using either any one of following (i) to (v) or a weighted sum of at least two of said (i) to (v), wherein said (i) represents one minus a first IoU which is an intersection over union of three dimensional cubes between one of said A1 to Ai and one of said B1 to Bj, wherein said (ii) represents one minus a second IoU which is an intersection over union of two dimensional rectangles resulting from projecting three dimensional cubes including one of said A1 to Ai and one of said B1 to Bj on a two dimensional plane from a bird's eye view, wherein said (iii) represents a Euclidean distance between centers of mass of one of said A1 to Ai and one of said B1 to Bj, wherein said (iv) represents an angle between one of said A1 to Ai and one of said B1 to Bj, and wherein said (v) represents a difference of speeds between one of said A1 to Ai and one of said B1 to Bj.
9. The method of Claim 7, wherein the specific merging device adds first undetected objects corresponding to either the first object detection information or the (k-2)-th object merging information by an amount of C1 to Cj such that the first undetected objects correspond to said B1 to Bj, and adds second undetected objects corresponding to either the second object detection information or the k-th object detection information by an amount of D1 to Di such that the second undetected objects correspond to said A1 to Ai, and
wherein the specific merging device calculates cost of correspondence between (i) said A1 to Ai and said C1 to Cj and (ii) said B1 to Bj and said D1 to Di, by the matching operation, and merges (i) said A1 to Ai and said C1 to Cj and (ii) said B1 to Bj and said D1 to Di.
10. The method of Claim 9, wherein the specific merging device determines (i) cost of correspondence between (i-1) one of said C1 to Cj and (i-2) one of said B1 to Bj and said D1 to Di and (ii) cost of correspondence between (ii-1) one of said D1 to Di and (ii-2) one of said A1 to Ai and said C1 to Cj, as preset initial values.
11. The method of Claim 7, wherein, at the step of (b), the specific merging device, during a process of merging said A1 to Ai and said B1 to Bj according to the calculated cost, (i) merges status information on the first and the second total objects into a weighted sum with weights being the detection reliabilities corresponding to each of the first and the second total objects, and (ii) merges product information of a certain object detector whose sum of the detection reliabilities is a highest to product information on the first and the second total objects.
12. A specific merging device, corresponding to a specific object detector, among merging devices for merging object detection information detected by object detectors, each of which corresponds to each of cameras located nearby, wherein the object detectors detect objects in each of images generated from each of the cameras by image analysis based on deep learning, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to: perform processes of: (I) if object detection information is acquired from the object detectors, each of which corresponds to each of the cameras located nearby, determining an order of degrees of each set of detection reliabilities of each of the object detectors by referring to the object detection information, wherein each piece of the object detection information includes one or more primary objects corresponding to one or more image-taking bodies whose corresponding cameras take each of the images and one or more secondary objects corresponding to one or more image-taken bodies appearing on at least part of the images generated by each of the cameras, and (II) supposing that at least part of the object detectors are designated as a first object detector to an n-th object detector in a descending order of the degrees of each set of the detection reliabilities and that each piece of the object detection information acquired from each of the first object detector to the n-th object detector is designated as first object detection information to n-th object detection information, (i) confirming correspondence between first total objects in the first object detection information and second total objects in the second object detection information via at least one matching operation, by referring to the first object detection information and the second object detection information and generating first object merging information by merging the first total objects and the second total objects (ii) confirming correspondence between (k-2)-th objects included in the (k-2)-th object merging information and k-th objects in the k-th object detection information through the matching operation by referring to (k-2)-th object merging information and k-th object detection information, generating (k-1)-th object merging information by merging the (k-2)-th objects and the k-th objects, and re-projecting the (k-1)-th object merging information onto at least one specific image acquired from at least one specific camera corresponding to the specific object detector, by increasing k from 3 to n, wherein the first total objects include the primary objects and the secondary objects, and the second total objects include the primary objects and the secondary objects.
13. The specific merging device of Claim 12, wherein each piece of the object detection information includes information on each of the primary objects and information on each of the secondary objects,
wherein the information on each of the primary objects includes status information on each of the primary objects and each set of the detection reliabilities of each of the object detectors corresponding to each of the primary objects, wherein the status information on each of the primary objects includes current location information, current direction information, and current speed information of each of the primary objects, and
wherein the information on each of the secondary objects includes status information on each of the secondary objects and product information on each of the secondary objects wherein the status information on each of the secondary objects includes current location information, current direction information, and current speed information of each of the secondary object.
14. The specific merging device of Claim 13, wherein the information on each of the primary objects includes one of product information on each of the primary objects and each piece of product information of each of the object detectors corresponding to each of the primary objects.
15. The specific merging device of Claim 14, wherein, at the process of (I), the processor performs one of processes of (i) determining the order of degrees of each set of the detection reliabilities of each of the object detectors using the received detection reliabilities, (ii) determining the order of degrees of each set of the detection reliabilities of each of the object detectors by referring to preset first reliabilities corresponding to each piece of the product information of each of the object detectors, and (iii) determining the order of degrees of each set of the detection reliabilities of each of the object detectors by referring to a preset second reliability set as a base reliability if no feature information of the object detectors is acquired.
</claims>
</document>
