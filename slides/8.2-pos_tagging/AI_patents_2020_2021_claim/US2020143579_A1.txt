<document>

<filing_date>
2019-10-31
</filing_date>

<publication_date>
2020-05-07
</publication_date>

<priority_date>
2017-04-08
</priority_date>

<ipc_classes>
G06N3/02,G06N3/04,G06N3/063,G06N3/08,G06T15/00
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
ARMON, AMITAI
BAR-ON, TOMER
BEHAR, MICHAEL
BEN-ARI, ITAMAR
BLEIWEISS, AMIT
COHEN, EHUD
DREYFUSS, JEREMIE
FAIS, YANIV
FAIVISHEVSKY, LEV
JACOB GUY
LEIBOVICH, GAL
SAREL, UZI
SCHWARTZ, TOMER
SHADMIY, YAHAV
SUBAG, JACOB
</inventors>

<docdb_family_id>
61800244
</docdb_family_id>

<title>
Sub-graph in frequency domain and dynamic selection of convolution implementation on a GPU
</title>

<abstract>
In an example, an apparatus comprises a plurality of execution units; and logic, at least partially including hardware logic, to determine a sub-graph of a network that can be executed in a frequency domain and apply computations in the sub-graph in the frequency domain. Other embodiments are also disclosed and claimed.
</abstract>

<claims>
1. (canceled)
2. An apparatus comprising processing circuitry to: obtain a sub-graph of a convolutional neural network to be executed at least in part in a frequency domain; generate a predicted level of activation sparsity for one or more layers of the convolutional neural network; and apply one or more convolutional computations in the sub-graph in the frequency domain, wherein the one or more convolutional computations are performed at variable levels of integer precisions based at least in part on the predicted level of activation sparsity of a layer in the convolutional neural network using a first set of execution resources, while internal computations are performed in a baseline precision level of 8-bits or 16-bits using a second set of execution resources, different from the first set of execution resources.
3. The apparatus of claim 2, the processing circuitry to: dynamically select a convolutional implementation based at least in part on executing a short comparison of one or more convolutions in the convolutional neural network.
4. The apparatus of claim 2, the processing circuitry to: generate a predicted level of activation sparsity for one or more layers of the convolutional neural network using training sample statistics for the convolutional neural network.
5. The apparatus of claim 4, the processing circuitry to: update the predicted level of activation history when operating on the convolutional neural network in inference mode.
6. The apparatus of claim 2, wherein: the first set of execution resources comprises a first plurality of processing elements configured to perform dense convolution operations; and the second set of execution resources comprises a first plurality of processing elements configured to perform dense convolution operations.
7. The apparatus of claim 2, the processing circuitry to: expose one or more embedded cast operations in a load/store instruction to support loading data for the one or more convolutional computations in a variable integer precision.
8. The apparatus of claim 7, the processing circuitry to: select between a 2-bit precision, a 3-bit precision, and a 7-bit precision level.
9. A method, comprising: obtaining a sub-graph of a convolutional neural network to be executed at least in part in a frequency domain; generating a predicted level of activation sparsity for one or more layers of the convolutional neural network; and applying one or more convolutional computations in the sub-graph in the frequency domain, wherein the one or more convolutional computations are performed at variable levels of integer precisions based at least in part on the predicted level of activation sparsity of a layer in the convolutional neural network using a first set of execution resources, while internal computations are performed in a baseline precision level of 8-bits or 16-bits using a second set of execution resources, different from the first set of execution resources.
10. The method of claim 9, further comprising: dynamically selecting a convolutional implementation based at least in part on executing a short comparison of one or more convolutions in the convolutional neural network.
11. The method of claim 9, further comprising: generating a predicted level of activation sparsity for one or more layers of the convolutional neural network using training sample statistics for the convolutional neural network.
12. The method of claim 11, further comprising: updating the predicted level of activation history when operating on the convolutional neural network in inference mode.
13. The method of claim 9, wherein: the first set of execution resources comprises a first plurality of processing elements configured to perform dense convolution operations; and the second set of execution resources comprises a first plurality of processing elements configured to perform dense convolution operations.
14. The method of claim 9, further comprising: exposing one or more embedded cast operations in a load/store instruction to support loading data for the one or more convolutional computations in a variable integer precision.
15. The method of claim 9, further comprising: selecting between a 2-bit precision, a 3-bit precision, and a 7-bit precision level.
16. One or more non-transitory computer readable media comprising instructions which, when executed by processing circuitry, configure the processing circuitry to: obtain a sub-graph of a convolutional neural network to be executed at least in part in a frequency domain; generate a predicted level of activation sparsity for one or more layers of the convolutional neural network; and apply one or more convolutional computations in the sub-graph in the frequency domain, wherein the one or more convolutional computations are performed at variable levels of integer precisions based at least in part on the predicted level of activation sparsity of a layer in the convolutional neural network using a first set of execution resources, while internal computations are performed in a baseline precision level of 8-bits or 16-bits using a second set of execution resources, different from the first set of execution resources.
17. The one or more non-transitory computer readable media of claim 16, further comprising instructions which, when executed by processing circuitry, configure the processing circuitry to: dynamically select a convolutional implementation based at least in part on executing a short comparison of one or more convolutions in the convolutional neural network.
18. The one or more non-transitory computer readable media of claim 16, further comprising instructions which, when executed by processing circuitry, configure the processing circuitry to: generate a predicted level of activation sparsity for one or more layers of the convolutional neural network using training sample statistics for the convolutional neural network.
19. The one or more non-transitory computer readable media of claim 18, further comprising instructions which, when executed by processing circuitry, configure the processing circuitry to: update the predicted level of activation history when operating on the convolutional neural network in inference mode.
20. The one or more non-transitory computer readable media of claim 16, wherein: the first set of execution resources comprises a first plurality of processing elements configured to perform dense convolution operations; and the second set of execution resources comprises a first plurality of processing elements configured to perform dense convolution operations.
21. The one or more non-transitory computer readable media of claim 16, further comprising instructions which, when executed by processing circuitry, configure the processing circuitry to: expose one or more embedded cast operations in a load/store instruction to support loading data for the one or more convolutional computations in a variable integer precision.
</claims>
</document>
