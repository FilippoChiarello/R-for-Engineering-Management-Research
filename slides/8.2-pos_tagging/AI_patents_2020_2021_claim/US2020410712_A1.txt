<document>

<filing_date>
2020-09-15
</filing_date>

<publication_date>
2020-12-31
</publication_date>

<priority_date>
2018-10-30
</priority_date>

<ipc_classes>
B25J9/16,G06T7/00,G06T7/73
</ipc_classes>

<assignee>
LIBERTY REACH
</assignee>

<inventors>
KALLAY, MICHAEL
BARTOS, GARY WILLIAM
HAVEN, G. NEIL
MENG, FANSHENG
</inventors>

<docdb_family_id>
70327567
</docdb_family_id>

<title>
Machine Vision-Based Method and System for Measuring 3D Pose of a Part or Subassembly of Parts
</title>

<abstract>
A machine vision-based method and system for measuring 3D pose of a part or subassembly of parts having an unknown pose are disclosed. A number of different applications of the method and system are disclosed including applications which utilize a reprogrammable industrial automation machine such as a robot. The method includes providing a reference cloud of 3D voxels which represent a reference surface of a reference part or subassembly having a known reference pose. Using at least one 2D/3D hybrid sensor, a sample cloud of 3D voxels which represent a corresponding surface of a sample part or subassembly of the same type as the reference part or subassembly is acquired. The sample part or subassembly has an actual pose different from the reference pose. The voxels of the sample and reference clouds are processed utilizing a matching algorithm to determine the pose of the sample part or subassembly.
</abstract>

<claims>
1. 1-22. (canceled)
23. A machine vision-based method of measuring 3D pose of a part or subassembly of parts having an unknown pose, the method comprising: providing a reference cloud of 3D voxels which represent a reference surface of a reference part or subassembly having a known reference pose; using at least one 2D/3D hybrid sensor to acquire a sample cloud of 3D voxels which represent a corresponding surface of a sample part or subassembly of the same type as the reference part or subassembly and having an actual pose different from the reference pose; and processing the voxels of the sample and reference clouds utilizing a matching algorithm to determine the pose of the sample part or subassembly.
24. The method as claimed in claim 23, wherein the step of providing is at least partially performed by the at least one sensor.
25. The method as claimed in claim 23, wherein the part or subassembly is located and supported in a fixture.
26. The method as claimed in claim 23, further comprising calculating an aligned cloud of 3D voxels which represents a best fit of the reference and sample clouds and displaying a 3D graphic of the aligned cloud and the reference cloud on a 3D display.
27. The method as claimed in claim 26, wherein the 3D display is used to identify whether a subassembly of parts is out of place with respect to other subassemblies of a body of subassemblies.
28. The method as claimed in claim 26, wherein the 3D display is used to visually compare pose of the aligned cloud with the pose of the reference cloud.
29. The method as claimed in claim 25, wherein the fixture comprises a part or a subassembly of parts.
30. The method as claimed in claim 25, wherein the fixture comprises a moveable carrier.
31. The method as claimed in claim 30, wherein the carrier is a storage rack for locating and supporting a plurality of individually fixtured parts or subassemblies of the same type.
32. The method as claimed in claim 30, wherein the carrier is a storage cassette for locating and supporting a plurality of individually fixtured parts or subassemblies of the same type.
33. The method as claimed in claim 30, wherein the carrier is a car carrier for locating and supporting a plurality of individually fixtured vehicle bodies of the same type.
34. The method as claimed in claim 23, wherein each sensor projects a known pattern of radiation to illuminate the part or subassembly with illumination.
35. The method as claimed in claim 34, wherein the illumination is concentrated in the pattern outside of the spectrum of visible radiation.
36. The method as claimed in claim 23, wherein the clouds of 3D voxels include color or grayscale information for each voxel to enhance the pose measurement.
37. The method as claimed in claim 23, wherein the reference cloud represents substantially the entire reference surface.
38. The method as claimed in claim 37, wherein the step of providing includes the steps of providing a CAD model of the part or subassembly and converting the CAD model into the reference cloud.
39. The method as claimed in claim 37, wherein the step of providing includes the steps of rigidly fixturing an as-built part and capturing a plurality of reference clouds of 3D voxels from multiple viewpoints using a plurality of 3D sensors.
40. 40-61. (canceled)
62. A machine vision-based system for measuring 3D pose of a part or subassembly of parts having an unknown pose, the system comprising: a reference cloud of 3D voxels which represent a reference surface of a reference part or subassembly having a known reference pose; at least one 2D/3D hybrid sensor to acquire a sample cloud of 3D voxels which represent a corresponding surface of a sample part or subassembly of the same type as the reference part or subassembly and having an actual pose different from the reference pose; and at least one processor to process the voxels of the sample and reference clouds utilizing a matching algorithm to determine the pose of the sample part or subassembly.
63. The system as claimed in claim 62, wherein the at least one sensor provides the reference cloud.
64. The system as claimed in claim 62, wherein the part or subassembly is located and supported in a fixture.
65. The system as claimed in claim 62, wherein the at least one processor calculates an aligned cloud of 3D voxels which represents a best fit of the reference and sample clouds and wherein the system further comprises a 3D display to display a 3D graphic of the aligned cloud and the reference cloud.
66. The system as claimed in claim 65, wherein the 3D display is used to identify whether a subassembly of parts is out of place with respect to other subassemblies of a body of subassemblies.
67. The system as claimed in claim 65, wherein the 3D display is used to visually compare pose of the aligned cloud with the pose of the reference cloud.
68. The system as claimed in claim 64, wherein the fixture comprises a part or a subassembly of parts.
69. The system as claimed in claim 64, wherein the fixture comprises a moveable carrier.
70. The system as claimed in claim 69, wherein the carrier is a storage rack for locating and supporting a plurality of individually fixtured parts or subassemblies of the same type.
71. The system as claimed in claim 69, wherein the carrier is a storage cassette for locating and supporting a plurality of individually fixtured parts or subassemblies of the same type.
72. The system as claimed in claim 69, wherein the carrier is a car carrier for locating and supporting a plurality of individually fixtured vehicle bodies of the same type.
73. The system as claimed in claim 62, wherein each sensor projects a known pattern of radiation to illuminate the part or subassembly with illumination.
74. The system as claimed in claim 73, wherein the illumination is concentrated in the pattern outside of the spectrum of visible radiation.
75. The system as claimed in claim 62, wherein the clouds of 3D voxels include color or grayscale information for each voxel to enhance the pose measurement.
76. The system as claimed in claim 62, wherein the reference cloud represents substantially the entire reference surface.
77. The system as claimed in claim 76, further comprising a CAD model of the part or subassembly and wherein the control logic converts the CAD model into the reference cloud.
78. The system as claimed in claim 76, further comprising a fixture to rigidly fixture an as-built part and a plurality of sensors to capture a plurality of reference clouds of 3D voxels from multiple viewpoints.
</claims>
</document>
