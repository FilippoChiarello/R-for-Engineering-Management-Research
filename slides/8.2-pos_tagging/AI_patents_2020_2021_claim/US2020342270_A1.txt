<document>

<filing_date>
2020-03-11
</filing_date>

<publication_date>
2020-10-29
</publication_date>

<priority_date>
2019-04-26
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N3/08
</ipc_classes>

<assignee>
TATA CONSULTANCY SERVICES
</assignee>

<inventors>
BHOWMICK, BROJESHWAR
SINHA, SANJANA
GUPTA, KAVYA
BISWAS, Sandika
</inventors>

<docdb_family_id>
69784173
</docdb_family_id>

<title>
WEAKLY SUPERVISED LEARNING OF 3D HUMAN POSES FROM 2D POSES
</title>

<abstract>
Estimating 3D human pose from monocular images is a challenging problem due to the variety and complexity of human poses and the inherent ambiguity in recovering depth from single view. Recent deep learning based methods show promising results by using supervised learning on 3D pose annotated datasets. However, the lack of large-scale 3D annotated training data makes the 3D pose estimation difficult in-the-wild. Embodiments of the present disclosure provide a method which can effectively predict 3D human poses from only 2D pose in a weakly-supervised manner by using both ground-truth 3D pose and ground-truth 2D pose based on re-projection error minimization as a constraint to predict the 3D joint locations. The method may further utilize additional geometric constraints on reconstructed body parts to regularize the pose in 3D along with minimizing re-projection error to improvise on estimating an accurate 3D pose.
</abstract>

<claims>
1. A processor implemented method, comprising: receiving, via one or more hardware processors, an input two dimensional (2D) pose (Y2d) corresponding to a user, wherein the input 2D pose comprises human joint positions in 2D image coordinates; predicting, via a neural network executed by the one or more hardware processors, a three dimensional (3D) pose (Ŷ3d) using the input 2D pose (Y2d), wherein the three dimensional (3D) pose (Ŷ3d) comprises the human joint positions in a 3D space; estimating, via the neural network via a neural network executed by the one or more hardware processors, a re-projected 2D pose (Ŷ2dreproj) from the predicted 3D pose (Ŷ3d) by minimizing a 2D re-projection loss, wherein the 2D re-projection loss is computed by aligning the re-projected 2D pose (Ŷ2dreproj) to the input 2D pose; and determining, using the re-projected 2D pose (Ŷ2dreproj), the predicted 3D pose (Ŷ3d) as an estimated 3D pose, or an optimized 3D pose based on an availability of a 3D ground-truth pose Y3d, wherein the predicted 3D pose is fine-tuned to obtain the optimized 3D pose based on the availability of the 3D ground-truth pose Y3d.
2. The processor implemented method of claim 1, wherein the 3D pose (Ŷ3d) is predicted in a weakly-supervised learning framework using a dataset comprising samples with 2D-3D ground-truth pose pairs.
3. The processor implemented method of claim 1, wherein the 3D pose (Ŷ3d) is predicted in a weakly-supervised learning framework using a dataset comprising samples with (i) 2D-3D ground-truth pose pairs and (ii) 2D ground-truth pose.
4. The processor implemented method of claim 1, wherein a 3D regression loss is computed by aligning the predicted 3D pose (Ŷ3d) to the 3D ground truth pose.
5. A system, comprising: a memory storing instructions; one or more communication interfaces; and one or more hardware processors coupled to the memory via the one or more communication interfaces, wherein the one or more hardware processors are configured by the instructions to: receive an input two dimensional (2D) pose (Y2d) corresponding to a user, wherein the input 2D pose comprises human joint positions in 2D image coordinates; predict, via a neural network comprised in the system, a three dimensional (3D) pose (Ŷ3d) using the input 2D pose (Y2d), wherein the three dimensional (3D) pose (Ŷ3d) comprises the human joint positions in a 3D space; estimate, via the neural network, a re-projected 2D pose (Ŷ2dreproj) from the predicted 3D pose (Ŷ3d) by minimizing a 2D re-projection loss, wherein the 2D re-projection loss is computed by aligning the re-projected 2D pose (Ŷ2dreproj) to the input 2D pose; and determine, using the re-projected 2D pose (Ŷ2dreproj), the predicted 3D pose (Ŷ3d) as an estimated 3D pose, or an optimized 3D pose based on an availability of a 3D ground-truth pose Y3d, wherein the predicted 3D pose is fine-tuned to obtain the optimized 3D pose based on the availability of the 3D ground-truth pose Y3d.
6. The system of claim 5, wherein the 3D pose (Ŷ3d) is predicted in a weakly-supervised learning framework using a dataset comprising samples with (i) 2D-3D ground-truth pose pairs and (ii) 2D ground-truth pose.
7. The system of claim 5, wherein the 3D pose (Ŷ3d) is predicted in a weakly-supervised learning framework using a dataset comprising samples with 2D ground-truth pose.
8. The system of claim 5, wherein a 3D regression loss is computed by aligning the predicted 3D pose (Ŷ3d) to the 3D ground truth pose.
9. One or more non-transitory machine readable information storage mediums comprising one or more instructions which when executed by one or more hardware processors cause weakly supervised learning of 3D human poses from 2D poses by: receiving, via one or more hardware processors, an input two dimensional (2D) pose (Y2d) corresponding to a user, wherein the input 2D pose comprises human joint positions in 2D image coordinates; predicting, via a neural network executed by the one or more hardware processors, a three dimensional (3D) pose (Ŷ3d) using the input 2D pose (Y2d), wherein the three dimensional (3D) pose (Ŷ3d) comprises the human joint positions in a 3D space; estimating, via the neural network via a neural network executed by the one or more hardware processors, a re-projected 2D pose (Ŷ2dreproj) from the predicted 3D pose (Ŷ3d) by minimizing a 2D re-projection loss, wherein the 2D re-projection loss is computed by aligning the re-projected 2D pose (Ŷ2dreproj) to the input 2D pose; and determining, using the re-projected 2D pose (Ŷ2dreproj), the predicted 3D pose (Ŷ3d) as an estimated 3D pose, or an optimized 3D pose based on an availability of a 3D ground-truth pose Y3d, wherein the predicted 3D pose is fine-tuned to obtain the optimized 3D pose based on the availability of the 3D ground-truth pose Y3d.
10. The one or more non-transitory machine readable information storage mediums of claim 9, wherein the 3D pose (Ŷ3d) is predicted in a weakly-supervised learning framework using a dataset comprising samples with 2D-3D ground-truth pose pairs.
11. The one or more non-transitory machine readable information storage mediums of claim 9, wherein the 3D pose (Ŷ3d) is predicted in a weakly-supervised learning framework using a dataset comprising samples with (i) 2D-3D ground-truth pose pairs and (ii) 2D ground-truth pose.
12. The one or more non-transitory machine readable information storage mediums of claim 9, wherein a 3D regression loss is computed by aligning the predicted 3D pose (Ŷ3d) to the 3D ground truth pose.
</claims>
</document>
