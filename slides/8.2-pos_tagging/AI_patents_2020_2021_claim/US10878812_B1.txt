<document>

<filing_date>
2018-09-26
</filing_date>

<publication_date>
2020-12-29
</publication_date>

<priority_date>
2018-09-26
</priority_date>

<ipc_classes>
G10L15/00,G10L15/20,G10L15/22,G10L15/28,G10L25/18,G10L25/21,G10L25/84
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
CHERUKURI, VENKATA SNEHITH
Helwani, Karim
</inventors>

<docdb_family_id>
74039791
</docdb_family_id>

<title>
Determining devices to respond to user requests
</title>

<abstract>
This disclosure describes techniques for selecting which device to respond to user speech within an environment that includes multiple devices. To enable this selection, the techniques described herein create a model indicating a topology of the devices within the environment. To do so, features associated with the user speech are generated and used to generate multi-dimensional points, each representing a corresponding user utterance. The techniques may then group these multi-dimensional points into clusters before projecting the resulting clusters into two dimensions. The two-dimensional clusters may then be used to generate a model (e.g., a Voronoi diagram) representing regions of the environment, with the centroid of each region being associated with a respective device. When a user makes a subsequent request, the user may be localized within one of the regions and the device associated with that region may be chosen to respond to the user.
</abstract>

<claims>
1. A method comprising: receiving a first audio signal generated by a first device in an environment, the first audio signal corresponding to first user speech; receiving a second audio signal generated by a second device in the environment, the second audio signal corresponding to the first user speech; generating a first set of features from the first audio signal; generating a second set of features from the second audio signal; calculating a first point in multi-dimensional space corresponding to the first user speech based at least in part on the first and second sets of features; grouping each of multiple points in multi-dimensional space into a corresponding cluster in multi-dimensional space, the multiple points in multi-dimensional space including the first point; reducing each cluster in multi-dimensional space into a corresponding cluster in two-dimensional Euclidian space; and determining regions of the environment based at least in part on the clusters in two-dimensional Euclidian space, the regions including at least a first region corresponding to the first device and a second region corresponding to the second device.
2. A method as recited in claim 1, further comprising: receiving a third audio signal generated by the first device, the third audio signal corresponding to second user speech; receiving a fourth audio signal generated by the second device, the fourth audio signal corresponding to the second user speech; generating a third set of features from the third audio signal; generating a fourth set of features from the fourth audio signal; calculating a second point in multi-dimensional space corresponding to the second user speech based at least in part on the third and fourth sets of features; reducing the second point into a third point in two-dimensional Euclidian space; determining that the third point is within the first region of the environment; and selecting the first device to respond to the second user speech.
3. A system comprising: one or more processors; and one or more non-transitory computer-readable media storing computer-executable instructions that, when executed, cause the one or more processors to perform acts comprising: receiving a first audio signal generated by a first device in an environment, the first audio signal corresponding to first user speech; receiving a second audio signal generated by a second device in the environment, the second audio signal corresponding to the first user speech; generating features of the first user speech based at least in part on the first and second audio signals; calculating a first point in multi-dimensional space corresponding to the first user speech based at least in part on the features; reducing the first point into a second point in two-dimensional Euclidian space; determining that the second point corresponds to a first region in the environment associated with the first device; and selecting the first device to respond to the first user speech.
4. The system as recited in claim 3, the acts further comprising: determining, for a first frequency band, a first signal energy of the first audio signal corresponding to user speech; determining, for the first frequency band, a second signal energy of the first audio signal corresponding to background noise; determining, for a second frequency band, a third signal energy of the first audio signal corresponding to user speech; and determining, for the second frequency band, a fourth signal energy of the first audio signal corresponding to background noise; and wherein the generating comprises generating the features based at least in part on the first signal energy, the second signal energy, the third signal energy, and the fourth signal energy.
5. The system as recited in claim 3, the acts further comprising: generating a spectrogram corresponding to the first audio signal; generating a first-order derivative of the spectrogram; and determining an amount of edges in the first-order derivative of the spectrogram; and wherein the generating comprises generating the features based at least in part on the amount of edges in the first-order derivative of the spectrogram.
6. The system as recited in claim 3, the acts further comprising calculating a first-order derivative of the first audio signal in a time domain to determine onset of user speech in the first audio signal over time, and wherein the generating comprises generating the features based at least in part on the onset.
7. The system as recited in claim 3, the acts further comprising calculating a spectral flatness of the first audio signal, and wherein the generating comprises generating the features based at least in part on the spectral flatness.
8. The system as recited in claim 3, the acts further comprising estimating a ratio of harmonic components of the first audio signal to non-harmonic components of the first audio signal, and wherein the generating comprises generating the features based at least in part on the ratio.
9. The system as recited in claim 3, the acts further comprising: calculating a first value corresponding to a spectral centroid of the first audio signal; and calculating a second value indicating a distribution of components of the first audio signal about the spectral centroid; and wherein the generating comprises generating the features based at least in part on the first and second values.
10. The system as recited in claim 3, the acts further comprising determining, for the first audio signal, a frequency value below which a threshold amount of energy of the first signal resides, and wherein the generating comprises generating the features based at least in part on the frequency value.
11. The system as recited in claim 3, the acts further comprising: grouping each of multiple points in multi-dimensional space into a corresponding cluster in multi-dimensional space, wherein the multiple points in multi-dimensional space include the first point and each of the multiple points in multi-dimensional space corresponds to previous respective user speech; reducing each cluster in multi-dimensional space into a corresponding cluster in two-dimensional Euclidian space; and determining regions of the environment based at least in part on the clusters in two-dimensional Euclidian space, each of the regions corresponding a respective device in the environment.
12. A system comprising: one or more processors; and one or more non-transitory computer-readable media storing computer-executable instructions that, when executed, cause the one or more processors to perform acts comprising: receiving a first audio signal generated by a first device in an environment, the first audio signal corresponding to first user speech; generating one or more features of the first user speech based at least in part on the first audio signal; calculating a first point in multi-dimensional space corresponding to the first user speech based at least in part on the one or more features; grouping each of multiple points in multi-dimensional space into a corresponding cluster in multi-dimensional space, the multiple points in multi-dimensional space including the first point; reducing each cluster in multi-dimensional space into a corresponding cluster in two-dimensional Euclidian space; and determining one or more regions of the environment based at least in part on the clusters in two-dimensional Euclidian space, the regions including at least a first region corresponding to the first device.
13. The system as recited in claim 12, the acts further comprising: receiving a second audio signal generated by at least one of the first device or a second device in the environment, the second audio signal corresponding to second user speech; generating one or more second features of the second user speech based at least in part on the second audio signal; calculating a second point in multi-dimensional space corresponding to the second user speech based at least in part on the one or more second features; reducing the second point into a third point in two-dimensional Euclidian space; determining that the third point corresponds to the first region in the environment associated with the first device; and selecting the first device to respond to the second user speech.
14. The system as recited in claim 12, the acts further comprising determining, for a first frequency band, a first signal energy of the first audio signal corresponding to user speech; determining, for the first frequency band, a second signal energy of the first audio signal corresponding to background noise; determining, for a second frequency band, a third signal energy of the first audio signal corresponding to user speech; and determining, for the second frequency band, a fourth signal energy of the first audio signal corresponding to background noise; and wherein the generating comprises generating the one or more features based at least in part on the first signal energy, the second signal energy, the third signal energy, and the fourth signal energy.
15. The system as recited in claim 12, the acts further comprising: generating a spectrogram corresponding to the first audio signal; generating a first-order derivative of the spectrogram; and determining an amount of edges in the first-order derivative of the spectrogram; and wherein the generating comprises generating the one or more features based at least in part on the amount of edges in the first-order derivative of the spectrogram.
16. The system as recited in claim 12, the acts further comprising calculating a first-order derivative of the first audio signal in a time domain to determine onset of user speech in the first audio signal over time, and wherein the generating comprises generating the one or more features based at least in part on the onset.
17. The system as recited in claim 12, the acts further comprising calculating a spectral flatness of the first audio signal, and wherein the generating comprises generating the one or more features based at least in part on the spectral flatness.
18. The system as recited in claim 12, the acts further comprising estimating a ratio of harmonic components of the first audio signal to non-harmonic components of the first audio signal, and wherein the generating comprises generating the one or more features based at least in part on the ratio.
19. The system as recited in claim 12, the acts further comprising: calculating a first value corresponding to a spectral centroid of the first audio signal; and calculating a second value indicating a distribution of components of the first audio signal about the spectral centroid; and wherein the generating comprises generating the one or more features based at least in part on the first and second values.
20. The system as recited in claim 12, the acts further comprising determining, for the first audio signal, a frequency value below which a threshold amount of energy of the first signal resides, and wherein the generating comprises generating the one or more features based at least in part on the frequency value.
</claims>
</document>
