<document>

<filing_date>
2019-07-09
</filing_date>

<publication_date>
2020-11-24
</publication_date>

<priority_date>
2016-08-08
</priority_date>

<ipc_classes>
A61F9/08,B23K37/00,B23K9/167,B23K9/173,B23K9/32,G06K9/00,G06K9/62,G06N3/04,H01R13/22,H01R13/24,H01R13/648,H01R4/56
</ipc_classes>

<assignee>
JHU (JOHNS HOPKINS UNIVERSITY)
</assignee>

<inventors>
BILLINGS, SETH D.
KATYAL, KAPIL D.
</inventors>

<docdb_family_id>
68290856
</docdb_family_id>

<title>
Object recognition and presentation for the visually impaired
</title>

<abstract>
An apparatus configured to perform object recognition is provided that includes a camera, an assistance feedback device, and processing circuitry. The processing circuitry may be configured to receive the plurality of images from the camera and repeatedly determine characteristic features within the plurality of images and compare the characteristic features within the plurality of images to an object identification dataset to determine object matches for identified objects within the plurality of images. The processing circuitry may be further configured to determine a name for identified objects from the object identification dataset, output, using the assistance feedback device, a position indicator for identified objects, and output the name of identified objects within the assistance feedback device field of view.
</abstract>

<claims>
That which is claimed is:
1. An apparatus configured to perform object recognition, the apparatus comprising: a camera configured to capture a plurality of images and to transmit the plurality of images to processing circuitry; an assistance feedback device having a field of view that is positionable by a user, the assistance feedback device being in communication with the processing circuitry, the assistance feedback device field of view corresponding to a current camera position; and the processing circuitry configured to: receive the plurality of images from the camera; repeatedly determine characteristic features within the plurality of images and compare the characteristic features within the plurality of images to an object identification dataset to determine object matches for identified objects within the plurality of images; determine a name for identified objects from the object identification dataset; output, using the assistance feedback device, a position indicator for identified objects; and output the name of identified objects within the assistance feedback device field of view.
2. The apparatus of claim 1 further comprising a user input device in communication with the processing circuitry; wherein the processing circuitry is further configured to receive an object category selection from a user input device; and wherein the object matches for identified objects satisfy the object category selection.
3. The apparatus of claim 1 further comprising a user context sensor configured to output user context information to the processing circuitry; wherein the processing circuitry is further configured to: receive the user context information from the user context sensor; determine an object category selection based on the user context information; and determine object matches for identified objects within the object category selection.
4. The apparatus of claim 1, further comprising a user context sensor configured to output user context information to the processing circuitry; wherein the processing circuitry is further configured to: receive the user context information from the user context sensor; and determine an object category selection based on the user context information; and wherein the processing circuitry is configured to compare the characteristic features within the plurality of images to the object identification dataset, the object identification dataset being reduced or expanded based on the object category selection to determine the object matches for the identified objects.
5. The apparatus of claim 4 wherein the user context sensor is a location sensor configured to output location information as user context information.
6. The apparatus of claim 1, wherein the processing circuitry is further configured to output the name of identified objects via an audible output or a refreshable braille display.
7. The apparatus of claim 1 wherein the processing circuitry is further configured to: track movement of the camera to determine camera movement data; determine positions of identified objects based on the camera movement data; and store position data describing the positions of identified objects.
8. The apparatus of claim 7, wherein the processing circuitry is further configured to output a cuing prompt to the user in association with a selected one of the identified objects, the cuing prompt indicating a direction for the user to move the assistance feedback device field of view with respect to the position of the selected one of the identified objects, wherein the position of the selected one of the identified objects is determined based on the stored position data.
9. The apparatus of claim 1, wherein the processing circuitry is further configured to output a cuing prompt to the user in association with a selected one of the identified objects, the cuing prompt indicating a direction for the user to move the assistance feedback device field of view with respect to the position of the selected one of the identified objects, wherein the position of the selected one of the identified objects is within the assistance feedback device field of view or outside of the assistance feedback device field of view.
10. The apparatus of claim 1, wherein the processing circuitry is further configured to output a cuing prompt to the user in association with a selected one of the identified objects, the cuing prompt indicating a direction for the user to move the assistance feedback device field of view with respect to the position of the selected one of the identified objects, the cuing prompt including a dynamic frequency characteristic indicative of a distance from a point in the assistance feedback device field of view to the position of the selected one of the identified objects.
11. The apparatus of claim 1, wherein the processing circuitry is further configured to output a cuing prompt to the user in association with a selected one of the identified objects, the cuing prompt indicating a direction for the user to move the assistance feedback device field of view with respect to the position of the selected one of the identified objects, the cuing prompt comprising a haptic output, audible output, or visual output.
12. A system for performing object recognition, the system comprising: an assistance feedback device comprising a visual prosthesis, the assistance feedback device having a field of view that is positionable via movement of a user; a remote apparatus comprising: a camera configured to capture a plurality of images; and processing circuitry configured to: receive the plurality of images from the camera; repeatedly determine characteristic features within the plurality of images and compare the characteristic features within the plurality of images to an object identification dataset to determine object matches for identified objects within the plurality of images; determine a name for identified objects from the object identification dataset; output, using the assistance feedback device, a position indicator for identified objects to the user; and output the name of identified objects within the assistance feedback device field of view.
13. The system of claim 12, wherein the remote apparatus further comprises a user input device in communication with the processing circuitry; wherein the processing circuitry is further configured to receive an object category selection from a user input device; and wherein the processing circuitry is configured to determine object matches for identified objects, the identified objects satisfying the object category selection.
14. The system of claim 12 further comprising a user context sensor configured to output user context information to the processing circuitry; wherein the processing circuitry is further configured to: receive the user context information from the user context sensor; and determine an object category selection based on the user context information; and wherein the processing circuitry is configured to determine object matches for identified objects, the identified objects satisfying the object category selection.
15. The system of claim 12 wherein the processing circuitry is further configured to: track movement of the camera to determine camera movement data; determine positions of identified objects based on the camera movement data; and store position data describing the positions of identified objects.
16. The system of claim 15, wherein the processing circuitry is further configured to output a cuing prompt to the user in association with a selected one of the identified objects, the cuing prompt indicating a direction for the user to move the assistance feedback device field of view with respect to the position of the selected one of the identified objects, wherein the position of the selected one of the identified objects is determined based on the stored position data.
17. The system of claim 12, wherein the processing circuitry is further configured to output a cuing prompt to the user in association with a selected one of the identified objects, the cuing prompt indicating a direction for the user to move the assistance feedback device field of view with respect to the position of the selected one of the identified objects, wherein the position of the selected one of the identified objects is within the assistance feedback device field of view or outside of the assistance feedback device field of view.
</claims>
</document>
