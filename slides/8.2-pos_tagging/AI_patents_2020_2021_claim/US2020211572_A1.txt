<document>

<filing_date>
2020-01-02
</filing_date>

<publication_date>
2020-07-02
</publication_date>

<priority_date>
2017-07-05
</priority_date>

<ipc_classes>
G06F21/32,G10L17/00,G10L17/02,G10L17/06,G10L17/22,H04L29/08
</ipc_classes>

<assignee>
ALIBABA GROUP
</assignee>

<inventors>
XU, YI
</inventors>

<docdb_family_id>
64950595
</docdb_family_id>

<title>
INTERACTION METHOD, ELECTRONIC DEVICE, AND SERVER
</title>

<abstract>
The present application discloses a method, device, system, and computer system for interfacing with a terminal in connection with performing a service function. The method includes receiving audio information based at least in part on a voice input from a user, determining a service function corresponding to the audio information, determining user information for the user based at least in part on the audio information, and performing the service function based at least in part on the user information.
</abstract>

<claims>
1. A method, comprising: receiving, by one or more processors, audio information based at least in part on a voice input from a user; determining, by the one or more processors, a service function corresponding to the audio information; determining, by the one or more processors, user information for the user based at least in part on the audio information; and performing, by the one or more processors, the service function based at least in part on the user information.
2. The method of claim 1, wherein the user information is associated with characterization information for the user, the characterization information pertaining to one or more characteristics of the user.
3. The method of claim 1, wherein: the method is performed by a server that is in communication with a client; the client obtains the voice input from the user and communicates the audio information to the server; and the client provides a response to the user based on the server performing the service function.
4. The method of claim 1, wherein the method is performed by a smart device that is configured to receive the voice input from the user via a microphone.
5. The method of claim 4, wherein the smart device locally stores the user information.
6. The method of claim 5, wherein the smart device locally stores a mapping of preference data to the user information, and performs the service function based at least in part on the preference data corresponding to the user information.
7. The method of claim 1, wherein the service function is determined based at least in part on converting the audio information to corresponding text and determining whether the corresponding text comprises one or more keywords associated with the service function.
8. The method of claim 1, wherein determining the service function based at least in part on the audio information comprises: converting the audio information into corresponding text information; matching the text information with one or more service instructions comprised in a s service instruction library; and determining that the one or more service instructions matched with the text information correspond to the service function pertaining to the audio information.
9. The method of claim 1, wherein determining the user information for the user based at least in part on the audio information comprises: generating a speech feature vector based at least in part on the audio information; matching the speech feature vector with a user feature vector; and determining the user information associated with the user feature vector that matches the speech feature vector.
10. The method of claim 9, wherein the generating the speech feature vector comprises: generating a feature matrix based at least in part on the audio information; and performing dimension reduction processing with respect to the feature matrix according to a plurality of feature dimensions to obtain a plurality of dimension values used to represent feature dimensions, wherein the plurality of dimension values corresponds to the speech feature vector.
11. The method of claim 9, wherein the generating the speech feature vector comprises at least one of: selecting any one piece of audio information of the user in connection with generating the speech feature vector; and providing specified information to the user and using speech information input by the user according to the specified information as a basis to generate the speech feature vector.
12. The method of claim 1, wherein determining the service function indicated by said audio information comprises: determining whether the audio information comprises a start keyword; and determining the service function indicated by the audio information if the audio information comprises the start keyword.
13. The method of claim 1, further comprising: determining that at least two service functions correspond to the audio information; providing prompt speech information corresponding to the at least two service functions to the user; obtaining a selection instruction corresponding to a selection of a selected service function from the user; and determining that the selected service function corresponding to the selection instruction is a service instruction to be used in connection with performing the service function.
14. The method of claim 1, further comprising: providing, to the user, confirmation information and user preference data pertaining to the service function, the user preference data being comprised in the user information; and in response to receiving a confirmation instruction from the user, performing the service function in accordance with the user preference data.
15. The method of claim 1, further comprising: in response to determining that an identity of the user is indeterminable based on the audio information, determining an option information set associated with the service function; providing option information to the user, wherein the option information is comprised in the option information set and represents an implementation of the service function; receiving a selection instruction from the user, the selection instruction indicating a target option information in the option information set; and performing the service function according to the implementation corresponding to the target option information.
16. The method of claim 15, wherein the option information set comprises a plurality of different possible service functions that correspond to a request in the audio information.
17. A device, comprising: one or more processors configured to: receive audio information based at least in part on a voice input from a user; determine a service function corresponding to the audio information; determine user information for the user based at least in part on the audio information; and perform the service function based at least in part on the user information; and one or more memories coupled to the one or more processors, configured to provide the one or more processors with instructions.
18. A system, comprising: one or more terminals; and one or more servers in communication with the terminal; wherein: the terminal obtains audio information based at least in part on voice input from a user; and the one or more of the terminal and the one or more servers determine a service function corresponding to the audio information, determine user information for the user based at least in part on the audio information, and perform the service function based at least in part on the user information.
19. A computer program product, the computer program product being embodied in a non-transitory computer readable storage medium and comprising computer instructions for: receiving, by one or more processors, audio information based at least in part on a voice input from a user; determining, by the one or more processors, a service function corresponding to the audio information; determining, by the one or more processors, user information for the user based at least in part on the audio information; and performing, by the one or more processors, the service function based at least in part on the user information.
</claims>
</document>
