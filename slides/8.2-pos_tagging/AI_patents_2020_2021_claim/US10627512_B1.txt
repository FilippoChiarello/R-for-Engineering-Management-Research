<document>

<filing_date>
2018-11-29
</filing_date>

<publication_date>
2020-04-21
</publication_date>

<priority_date>
2018-11-29
</priority_date>

<ipc_classes>
G01S17/02,G01S17/93,G06T7/50
</ipc_classes>

<assignee>
LUMINAR TECHNOLOGIES
</assignee>

<inventors>
HICKS, RICHMOND
</inventors>

<docdb_family_id>
70284915
</docdb_family_id>

<title>
Early fusion of lidar return data with camera information
</title>

<abstract>
Lidar return data is fused early with camera information. In one embodiment, a voxel is detected in a frame of a lidar corresponding to an external scene. The voxel is mapped to a patch in a frame of a camera of the external scene corresponding to the voxel. The patch has a plurality of pixels. Each pixel has a plurality of color values. The voxel is augmented with the patch of pixels and the augmented voxel is delivered to a perception engine.
</abstract>

<claims>
1. A method comprising: detecting a voxel in a frame of a lidar corresponding to an external scene, the lidar having a frame rate and a resolution; mapping the voxel to a patch in a frame of a camera of the external scene corresponding to the voxel, the patch having a plurality of pixels, each pixel having a plurality of color values, the camera having a camera frame rate and a resolution; determining data using the patch of pixels; augmenting the voxel with the data of the patch of pixels; and delivering the augmented voxel to a perception engine at the lidar frame rate and resolution.
2. The method of claim 1, wherein the voxel has azimuth, elevation and range and wherein the pixel has one or more color values.
3. The method of claim 1, further comprising downscaling the patch to fewer pixels by an amount determined by a range value of the voxel before determining data using the patch.
4. The method of claim 3, wherein downscaling comprises downscaling by an amount inversely proportional to the range.
5. The method of claim 3, further comprising rectifying the lidar frame by rectifying the augmented voxels after the downscaling.
6. The method of claim 1, further comprising determining a motion vector of the patch using adjacent camera frames and wherein augmenting the voxel comprises augmenting the voxel with the motion vector.
7. The method of claim 6, wherein the camera generates three frames for each lidar frame, the method further comprising determining a first motion vector for the first and second adjacent frames of the three frames and determining a second motion vector for the second and third adjacent frames of the three frames and wherein augmenting the voxel comprises augmenting the voxel with the first and the second motion vectors.
8. The method of claim 1, wherein mapping comprises applying calibration from the voxel to a single pixel of the patch.
9. The method of claim 1, wherein mapping comprises mapping the voxel to a single pixel of the camera frame and then assigning a patch to the single pixel as having pixels within a bounding box defined by the single pixel.
10. The method of claim 9, further comprising adjusting the patch using edge detection to exclude pixels outside of a detected edge.
11. The method of claim 1, further comprising adjusting pixels of the patch by projecting motion onto the pixels to account for temporal differences between the patch and the voxel.
12. A scene sensor system comprising: a lidar system to generate a point cloud of a scene at a lidar frame rate, the point cloud having a plurality of voxels at a lidar resolution; a camera system having a camera to capture a sequence of frames of the scene at a camera frame rate, each frame having a plurality of pixels at a camera resolution; and a fusion processor configured to map voxels of the point cloud to a respective patch in a camera frame, each patch having a plurality of pixels, each pixel having a plurality of color values, to determine data using the respective patches, and to augment the voxels with the data of the respective patch to generate an annotated point cloud configured for use by a perception engine.
13. One or more computer-readable non-transitory storage media embodying software that is operable when executed to perform operations comprising: detecting a voxel in a frame of a lidar corresponding to an external scene, the lidar having a frame rate and a resolution; mapping the voxel to a patch in a frame of a camera of the external scene corresponding to the voxel, the patch having a plurality of pixels, each pixel having a plurality of color values, the camera having a camera frame rate and a resolution; determining data using the patch of pixels; augmenting the voxel with the data of the patch of pixels; and delivering the augmented voxel to a perception engine at the lidar frame rate and resolution.
14. A method comprising: detecting a voxel in a frame of a lidar corresponding to an external scene, the lidar having a lidar frame rate and a resolution; mapping the voxel to a patch in a frame of a camera of the external scene corresponding to the voxel, the camera having a camera frame rate and a resolution, the patch having a plurality of pixels, each pixel having a plurality of color values; determining a motion vector of the patch using adjacent camera frames; augmenting the voxel with the motion vector; and delivering the augmented voxel at the lidar frame rate and resolution to a perception engine.
15. The method of claim 14, wherein the camera generates three frames for each lidar frame, wherein determining a motion vector comprises determining a first motion vector for the first and second adjacent frames of the three frames and determining a second motion vector for the second and third adjacent frames of the three frames and wherein augmenting the voxel comprises augmenting the voxel with the first and the second motion vectors.
16. The method of claim 14, further comprising downscaling the patch to fewer pixels before determining the motion vector, the method further comprising determining color data using the downscaled patch and augmenting the voxel with the determined color data.
17. The method of claim 16, wherein downscaling comprises downscaling by an amount determined by a range value of the voxel.
18. The method of claim 16, wherein downscaling comprises downscaling by an amount inversely proportional to the range.
19. The method of claim 16, wherein the augmented voxel includes azimuth, elevation range, motion, and color for a plurality of pixels.
20. The method of claim 14, further comprising rectifying the camera frame by rectifying the augmented voxels.
</claims>
</document>
