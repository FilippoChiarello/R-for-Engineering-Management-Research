<document>

<filing_date>
2019-07-18
</filing_date>

<publication_date>
2020-04-16
</publication_date>

<priority_date>
2018-10-15
</priority_date>

<ipc_classes>
G06N20/00,G06N3/08,G06T15/00,G06T15/08
</ipc_classes>

<assignee>
SONY CORPORATION
</assignee>

<inventors>
NIELSEN, FRANK
OWADA SHIGERU
</inventors>

<docdb_family_id>
70160046
</docdb_family_id>

<title>
INFORMATION PROCESSING APPARATUS, METHOD, AND PROGRAM
</title>

<abstract>
An information processing apparatus and a method for volume data visualization is provided. The information processing apparatus stores an auto-encoder that includes an encoder network and a decoder network. The encoder network includes a loss function and a first plurality of neural network (NN) layers. The information processing apparatus inputs volume data to an initial NN layer of the first plurality of NN layers and generates a latent image as an output from a final NN layer of the first plurality of NN layers based on application of the encoder network on the input volume data. The information processing apparatus estimates a distance between the generated latent image and a reference image based on the loss function and updates the encoder network based on the estimated distance. Finally, the information processing apparatus outputs the updated encoder network as a trained encoder network based on the estimated distance being a minimum.
</abstract>

<claims>
1. An information processing apparatus, comprising: a memory configured to store an auto-encoder comprising an encoder network and a decoder network, wherein the encoder network includes a loss function and a first plurality of network (NN) layers; and a processor configured to: input volume data to an initial neural network (NN) layer of the first plurality of NN layers; generate a latent image as an output from a final NN layer of the first plurality of NN layers based on application of the encoder network on the input volume data; estimate a distance between the generated latent image and a reference image based on the loss function; update the encoder network based on the estimated distance; and output the updated encoder network as a trained encoder network based on the estimated distance being a minimum.
2. The information processing apparatus according to claim 1, wherein the auto-encoder is a Deep Neural Network (DNN).
3. The information processing apparatus according to claim 1, wherein the input volume data comprises voxel information sampled at regularly aligned voxel centers for an object-of-interest in 3D space.
4. The information processing apparatus according to claim 3, wherein each voxel in the voxel information comprises a set of channels that define a set of volumetric attributes for the corresponding voxel.
5. The information processing apparatus according to claim 1, wherein the generated latent image is a 3-channel RGB image and is a 2D latent representation of the input volume data.
6. The information processing apparatus according to claim 1, wherein the processor is further configured to compress, by the encoder network, the input volume data along a user-defined depth axis of the input volume data to generate the latent image.
7. The information processing apparatus according to claim 1, wherein the processor is further configured to receive an input for a selection of a color image as the reference image from a set of color images.
8. The information processing apparatus in claim 7, wherein the color image is an explosion image.
9. The information processing apparatus in claim 7, wherein the color image is a green forest image.
10. The information processing apparatus according to claim 1, wherein the loss function is a color loss function which indicates a color loss in the generated latent image with respect to the reference image.
11. The information processing apparatus according to claim 1, wherein the processor is further configured to: input the volume data to the initial NN layer of the trained encoder network; and generate a color-shifted latent image as an output from the final NN layer of the trained encoder network, based on the application of the trained encoder network on the input volume data.
12. The information processing apparatus in claim 1, wherein the processor is further configured to generate a style-transferred image based on application of a neural style transfer function on the generated latent image, and wherein the neural style transfer function is based on a style transfer neural network trained to output the style-transferred image.
13. The information processing apparatus in claim 12, wherein the processor is further configured to: input the generated style-transferred image to the decoder network; and generate style-transferred volume data as an output of the decoder network based on application of the decoder network on the input style-transferred image.
14. The information processing apparatus according to claim 1, wherein the processor is further configured to: input the generated latent image to an initial NN layer of a second plurality of NN layers of the decoder network; generate reconstructed volume data as an output from a final NN layer of the second plurality of NN layers based on application of the decoder network on the generated latent image; and estimate a reconstruction error between the reconstructed volume data and the input volume data; update both the encoder network and the decoder network based on the estimated reconstruction error; and output the updated decoder network and the updated encoder network based on the estimated reconstruction error being a minimum.
15. A method, comprising: providing an auto-encoder comprising an encoder network and a decoder network, wherein the encoder network comprises a loss function and a first plurality of network (NN) layers; inputting volume data to an initial neural network (NN) layer of the first plurality of NN layers; generating a latent image as an output from a final NN layer of the first plurality of NN layers based on application of the encoder network on the input volume data; estimating a distance between the generated latent image and a reference image based on a loss function for the encoder network; updating the encoder network based on the estimated distance; and outputting the updated encoder network as a trained encoder network based on the estimated distance being a minimum.
16. The method according to claim 15, further comprising: inputting the volume data to the initial NN layer of the trained encoder network; and generating a color-shifted latent image as an output from the final NN layer of the trained encoder network, based on the application of the trained encoder network on the input volume data.
17. The method according to claim 15, further comprising generating a style-transferred image based on application of a neural style transfer function on the generated latent image, and wherein the neural style transfer function is based on a style transfer neural network trained to output the style-transferred image.
18. The method according to claim 17, further comprising: inputting the generated style-transferred image to the decoder network; and generating style-transferred volume data as an output of the decoder network based on application of the decoder network on the input style-transferred image.
19. The method according to claim 15, further comprising: inputting the generated latent image to an initial NN layer of a second plurality of NN layers of the decoder network; generating reconstructed volume data as an output from a final NN layer of the second plurality of NN layers based on application of the decoder network on the generated latent image; and estimating a reconstruction error between the reconstructed volume data and the input volume data; updating both the encoder network and the decoder network based on the estimated reconstruction error; and outputting both the updated encoder network and the updated decoder network based on the estimated reconstruction error being a minimum.
20. A method, comprising: providing an auto-encoder comprising an encoder network and a decoder network, wherein the encoder network is trained to generate a latent image based on an input of volume data to the encoder network, and wherein the encoder network is trained based on a loss function which measures a distances between the latent image and the volume data; generating a style-transferred image based on application of a neural style transfer function on the latent image, wherein the neural style transfer function is based on a style transfer neural network trained to output the style-transferred image; inputting the generated style-transferred image to the decoder network; and generating style-transferred volume data as an output of the decoder network based on application of the decoder network on the input style-transferred image.
</claims>
</document>
