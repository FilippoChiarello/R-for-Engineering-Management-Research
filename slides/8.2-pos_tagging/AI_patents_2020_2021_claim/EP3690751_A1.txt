<document>

<filing_date>
2019-01-31
</filing_date>

<publication_date>
2020-08-05
</publication_date>

<priority_date>
2019-01-31
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
SIEMENS
</assignee>

<inventors>
KÖPKEN, HANS-GEORG
KROMPAß, DENIS
TOMOV, TOMISLAV
</inventors>

<docdb_family_id>
65268887
</docdb_family_id>

<title>
A METHOD FOR BUILDING A DEEP LATENT FEATURE EXTRACTOR FOR INDUSTRIAL SENSOR DATA
</title>

<abstract>
The present invention relates to a method of and a system for building a latent feature extractor as well as a neural network (NN) comprising latent feature extractor built by said method and/or with said system. The method comprises providing non-uniform training data for a multitude of tasks and optimising parameters θ of a neural network (NN) of the latent feature extractor based on the multitude of tasks.
</abstract>

<claims>
1. Method of building a latent feature extractor, comprising the steps of: - providing non-uniform training data comprising kT training examples for each single task T of a multitude of Ti tasks; and - optimising parameters θ of a neural network of the latent feature extractor based on the multitude of Ti tasks,
wherein the following steps are executed iteratively until the parameters θ have converged: - randomly selecting a single tasks T from the multitude of Ti tasks for optimising the parameters θ; - sampling the current randomly selected task T for nj iterations with the respective kT training examples of the non-uniform training data for optimising the parameters θ based on the current randomly selected task T,
wherein in each iteration n of the nj iterations the following steps are executed: - extracting latent features from a training signal of the current training example k of the respective training examples kT with the latent feature extractor; and - deriving an output signal oi for the current randomly selected task T from the extracted latent features with a respective task module of the current randomly selected task T.
2. Method according to claim 1, wherein the non-uniform training data are sensor data from different sensors.
3. Method according to claim 1 or 2, wherein Ti is between 2 and 1000 and preferably between 2 and 100 and/or wherein nj is between 1 to 10000 and/or wherein each kT is equal to one of 32, 64 and 128.
4. Method according to any preceding claim, further comprising the step of: - normalising the non-uniform training data before the step of optimising.
5. Method according to any preceding claim, wherein the kT training examples for each task T comprise one or multiple training signals from one or multiple sensors.
6. Method according to claim 5, wherein in each iteration n of the nj iterations where the kT training examples for the current randomly selected task T comprise multiple training signals in the step of extracting features are extracted for every training signal of the multiple training signals and wherein in each iteration n of the nj iterations where the kT training examples for the current randomly selected task T comprise multiple training signals the following step is additionally executed: - combining the extracted latent features of each training signal of the multiple training signals into combined extracted features with a respective combiner module of the current randomly selected task T before the step of deriving.
7. System for building a latent feature extractor arranged and configured for executing the method according to claim 1, comprising: - the latent feature extractor for extracting the latent features, wherein the latent feature extractor is shared for each task T of the multitude of Ti tasks; and - task modules for each single task T of the multitude of Ti tasks downstream the latent feature extractor for deriving the output signal oi for the respective task T.
8. System according to claim 7, wherein the system is arranged and configured for executing the method according to any of claims 2 to 5.
9. System according to claim 7 or 8, wherein the latent feature extractor comprises between 10 and 30 layers and wherein each layer comprises between 10 and 1000 neurons.
10. System according to any of claims 7 to 9, wherein each task module comprises between 1 and 2 layers and wherein each layer comprises between 10 and 1000 neurons.
11. System according to any of claims 7 to 10 arranged and configured for executing the method according to claim 6, further comprising downstream the latent feature extractor and upstream the respective task module for each task T where the respective kT training examples comprise multiple training signals a combiner module for combining the extracted latent features of each training signal of the multiple training signals.
12. System according to claim 11, wherein each combiner module comprises between 1 and 2 layers and wherein each layer comprises between 10 and 1000 neurons.
13. Neural network, comprising: - a latent feature extractor built by the method according to any of claims 1 to 6 and/or with the system according to any of claims 7 to 12; - a combiner module downstream the latent feature extractor in case multiple input signals are provided to the neural network; - a specific task module downstream the latent feature extractor and the combiner module, respectively.
14. Neural network according to claim 13, further comprising a normaliser module upstream the latent feature extractor.
15. Neural network according to claim 13 or 14, wherein the latent feature extractor comprises between 10 and 30 layers and wherein each layer comprises between 10 and 1000 neurons and/or
wherein the specific task module comprises between 1 and 2 layers and wherein each layer comprises between 10 and 1000 neurons and/or the combiner module comprises between 1 and 2 layers and wherein each layer comprises between 10 and 1000 neurons.
</claims>
</document>
