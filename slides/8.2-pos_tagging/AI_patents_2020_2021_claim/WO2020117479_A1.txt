<document>

<filing_date>
2019-11-20
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-05
</priority_date>

<ipc_classes>
A47F9/04,G06K9/00,G07G1/00
</ipc_classes>

<assignee>
AIFI
</assignee>

<inventors>
AN, WANGPENG
CHEN LONG
GU, STEVEN
HE, YING
LIU SHUANG
ZHENG YING
ZHUANG, ZIJIE
</inventors>

<docdb_family_id>
70971923
</docdb_family_id>

<title>
TRACKING PERSONS IN AN AUTOMATED-CHECKOUT STORE
</title>

<abstract>
Methods, systems, and apparatus, including computer programs encoded on computer storage media, for tracking a product item in an automated-checkout store. One of the methods includes receiving, by a computer system, data collected by multiple image sensors, the received data including data associated with a person, identifying, by the computer system based on the received data, multiple features of the person, extracting, by the computer system based on the identified features, data associated with the person from the received data, wherein the extracted data correspond to multiple time periods, and determining, by the computer system, a location of the person in each of the time periods based on the extracted data corresponding to the time period, wherein the determining includes aggregating the extracted data collected by different image sensors based at least in part on a location and a line of sight of each of the image sensors.
</abstract>

<claims>
1. A person-tracking method, comprising:
receiving, by a computer system, data collected by a plurality of image sensors, the received data comprising data associated with a person;
identifying, by the computer system based on the received data, a plurality of features of the person;
extracting, by the computer system based on the identified features, data associated with the person from the received data, wherein the extracted data correspond to a plurality of time periods; and
determining, by the computer system, a location of the person in each of the time periods based on the extracted data corresponding to the time period, wherein the determining comprises aggregating the extracted data collected by different image sensors based at least in part on a location and a line of sight of each of the image sensors.
2. The method of Claim 1, wherein the identifying comprises:
assigning an identifier to the person; and
storing the features of the person in association with the identifier.
3. The method of Claim 1, wherein the extracting comprises:
for one of the time periods, determining a location of the person in a preceding time period;
identifying one or more of the image sensors each having a field of view that encompasses the determined location; and
obtaining data collected by the identified image sensors that correspond to the time period.
4. The method of Claim 3, further comprising:
determining a movement path of the person based on the location of the person in each of the time periods;
determining that the person exits the field of view of one or more of the identified image sensors and enters the field of view of one or more other image sensors; and
determining a location of the person in a subsequent time period based at least in part on data collected by the one or more other image sensors.
5. The method of Claim 1, further comprising:
for one of the time periods, detecting a failure of locating the person in a preceding time period; extracting data associated with the person from the received data that correspond to the one of the time periods based on the identified features of the person;
identifying one or more of the image sensors that collected the extracted data; and determining the location of the person based on data collected by the identified image sensors.
6. The method of Claim 1, wherein the extracted data comprises a plurality of images captured by the image sensors, and wherein the aggregating the extracted data comprises: identifying one or more pixels corresponding to the person in each of the images; determining a plurality of lines in a three-dimensional space, wherein each of the lines is determined based on a position of one of the identified pixels in the image containing the pixel and the line of sight of the image sensor capturing the image; and
determining one or more intersection areas of the lines.
7. The method of Claim 1, wherein the plurality of image sensors correspond to a plurality of groups each comprising one or more of the image sensors, and wherein the aggregating the extracted data comprises:
processing the data collected by each group of image sensors to obtain analysis results; and
aggregating the analysis results associated with the plurality of groups of image sensors.
8. The method of Claim 1, wherein the determining the location of the person in each of the time periods further comprises:
determining a plurality of possible locations of the person each being associated with a probability value; and
selecting one of the possible locations as the location of the person based at least in part on the probability values.
9. The method of Claim 1, wherein the determining the location of the person in each of the time periods further comprises:
determining a plurality of possible locations of the person; and
selecting one of the possible locations as the location of the person based at least in part on a previous movement path of the person.
10. The method of Claim 1, wherein the determining the location of the person in each of the time periods further comprises:
combining the extracted data with data collected by one or more vibration sensors.
11. A system for tracking a person in an automated-checkout store comprising a computer system and a plurality of image sensors, the computer system comprising one or more processors and one or more non-transitory computer-readable storage media storing instructions executable by the one or more processors to cause the system to perform operations comprising:
receiving, by the computer system, data collected by the image sensors, the received data comprising data associated with a person;
identifying, by the computer system based on the received data, a plurality of features of the person;
extracting, by the computer system based on the identified features, data associated with the person from the received data, wherein the extracted data correspond to a plurality of time periods; and
determining, by the computer system, a location of the person in each of the time periods based on the extracted data corresponding to the time period, wherein the determining comprises aggregating the extracted data collected by different image sensors based at least in part on a location and a line of sight of each of the image sensors.
12. The system of claim 11, wherein the identifying, by the computer system based on the received data, a plurality of features of the person, comprises:
assigning an identifier to the person; and
storing the plurality of features of the person in association with the identifier.
13. The system of claim 11, wherein the extracting, by the computer system based on the identified features, comprises:
for one of the time periods, determining a location of the person in a preceding time period;
identifying one or more of the image sensors each having a field of view that encompasses the determined location; and
obtaining data collected by the identified image sensors that correspond to the time period.
14. The system of claim 13, wherein the operations further comprise:
determining a movement path of the person based on the location of the person in each of the time periods;
determining that the person exits the field of view of one or more of the identified image sensors and enters the field of view of one or more other image sensors; and determining a location of the person in a subsequent time period based at least in part on data collected by the one or more other image sensors.
15. The system of claim 11, wherein the operations further comprise:
for one of the time periods, detecting a failure of locating the person in a preceding time period;
extracting data associated with the person from the received data that correspond to the one of the time periods based on the identified features of the person;
identifying one or more of the image sensors that collected the extracted data; and determining the location of the person based on data collected by the identified image sensors.
16. The system of claim 11, wherein the extracted data comprises a plurality of images captured by the image sensors, and wherein the aggregating the extracted data comprises:
identifying one or more pixels corresponding to the person in each of the images; determining a plurality of lines in a three-dimensional space, wherein each of the lines is determined based on a position of one of the identified pixels in the image containing the pixel and the line of sight of the image sensor capturing the image; and
determining one or more intersection areas of the lines
17. The system of claim 11, wherein the plurality of image sensors correspond to a plurality of groups each comprising one or more of the image sensors, and wherein the aggregating the extracted data comprises:
processing the data collected by each group of image sensors to obtain analysis results; and
aggregating the analysis results associated with the plurality of groups of image sensors.
18. The system of claim 11, wherein the determining the location of the person in each of the time periods further comprises:
determining a plurality of possible locations of the person each being associated with a probability value; and
selecting one of the possible locations as the location of the person based at least in part on the probability values.
19. The system of claim 11, wherein the determining the location of the person in each of the time periods further comprises:
determining a plurality of possible locations of the person; and selecting one of the possible locations as the location of the person based at least in part on a previous movement path of the person.
20. The system of claim 11, wherein the determining the location of the person in each of the time periods further comprises:
combining the extracted data with data collected by one or more vibration sensors.
</claims>
</document>
