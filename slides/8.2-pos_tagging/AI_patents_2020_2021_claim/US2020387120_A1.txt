<document>

<filing_date>
2020-04-29
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-07
</priority_date>

<ipc_classes>
G05B13/02,G05B23/02,G06K9/62,G06N3/08
</ipc_classes>

<assignee>
HONEYWELL INTERNATIONAL
</assignee>

<inventors>
PRABHAKER, Varun
BEHERA, Bimalananda
PAMULAPARTHY, Venkata Dhruva
GURAJAPU, Prasanna Murthy
</inventors>

<docdb_family_id>
73651538
</docdb_family_id>

<title>
METHOD AND SYSTEM FOR CONNECTED ADVANCED FLARE ANALYTICS
</title>

<abstract>
A method and system for advanced flare analytics in a flare operation monitoring and control system is disclosed that contains a data acquisition and augmentation mechanism whereby data is aquired through a plant network including images of the flare operations from single or multi-camera hubs. A machine learning-based self-adaptive industrial automation system process the images and data and assigns pixels to the images according to categories selected from smoke, flame and steam. The results of the analysis are displayed and a notice is issued when the percentage of pixles in a specific category falls outside a predeterminmed range.
</abstract>

<claims>
1. A method for monitoring and controlling flare operations of an industrial plant using a machine deep learning-based self-adaptive industrial automation system comprising: (a) obtaining, from at least one camera, a sequence of real time images of the flare operation and obtaining data from a network of the industrial plant as to at least one flare parameter; (b) inputting the real time images and data to a machine deep learning configurable system module; (c) analyzing the data by the machine deep learning configurable system module using machine learning models and algorithms to assign pixels of the images to categories selected from smoke, flame, and steam; (d) displaying the results of the analyzing data by the machine deep learning configurable system module; and (d) issuing a notice when the percentage of pixels in a specific category falls outside a predetermined range.
2. The method of claim 1 wherein the at least one camera comprises at least one video camera and at least one thermal camera.
3. The method of claim 1 further comprising adjusting at least one parameter of the real-time operation of the flare operation of the industrial facility based on the results of the analyzing data by the machine deep learning configurable system module.
4. The method of claim 1, wherein the machine learning configurable system module comprises a Fully Convolution Neural Network architecture or a variant thereof.
5. The method of claim 1 further comprising obtaining data from a cloud the data relating to a second or more flare operation of a second industrial plant.
6. The method of claim 1, further comprising generating the machine learning configurable system module comprising: training the machine learning models and algorithms using a first set of data from the obtained data and from historical data stored in a database; and validating the machine learning models and algorithms using a second set of data from the obtained data and from historical data stored in the database.
7. A system for monitoring and controlling flare operations of an industrial plant using a machine deep learning-based self-adaptive configurable subsystem comprising: a) an analytics system comprising a processor comprising: an optical flow subsystem; a data augmentation subsystem; a machine deep learning based self-adaptive configurable subsystem; b) a camera hub comprising at least one camera and a processor configured to receive images from the at least one camera and transmit images to the analytics system; and c) a display configured to receiving the images from the analytics system and display the images generated by the machine deep learning based self-adaptive configurable subsystem wherein pixels of the images are categorized and displayed as smoke, steam, or flame.
8. The system of claim 7 wherein the analytic system receives data for at least one parameter of the operation of the industrial plant from an industrial plant network.
9. The system of claim 8, wherein the at least one camera comprises at least one video camera and at least one thermal camera each camera providing a sequence of real time images of the flare operation to the optical flow subsystem.
10. The system of claim 9, wherein the data augmentation subsystem comprises: a Fully Convolution Neural Network architecture or a variant thereof arranged to receive the real time images from the video and thermal cameras and the at least one plant parameter and augment the data into a form compatible for use by the machine deep learning based self-adaptive configurable subsystem; and transmit the augmented data to the deep learning based self-adaptive configurable subsystem.
11. The system of claim 7 wherein the analytic system further obtains data from a cloud the data relating to a second or more flare operation of a second industrial plant.
12. The system of claim 10, wherein the machine deep learning based self-adaptive configurable subsystem includes at least one deep learning model that receives the augmented data from the augmentation subsystem that uses the deep learning model to analyze the augmented data and assigning categories to the pixels of the real time images, the pixels selected from smoke, flame, and steam.
13. The method of displaying flare operations of an industrial plant using a machine learning-based self-adaptive industrial automation system, the method comprising: dynamically displaying images of the flare operations processed by a machine deep learning configurable subsystem wherein the pixels of camera images are categorized as smoke, steam, or flame.
14. The method of claim 8 further comprising: dynamically displaying a count of missed events and or mitigated events; dynamically displaying a representation of the percentage of pixels in each category; and dynamically displaying a graphical log of events.
15. The method of claim 8 further wherein the camera images of the flare operations is a live feed from at least one video camera.
16. The method of claim 8 further wherein the camera of the flare operations is a live feed from at least one thermal camera.
17. The method of claim 8 wherein the processed pixels of the camera images of the flare operations, the count of missed events and or mitigated events, the representation of the percentage of pixels in each category and the graphical log of events are displayed using a graphical user interface.
18. The method of claim 17 wherein the graphical user interface displays the pixels of the camera images of the flare operations on a display in three separate segments categorized as steam, smoke, steam.
19. The method of claim 17 wherein the graphical user interface displays the images to a user at a stationary monitor.
20. The method of claim 17 wherein the graphical user interface displays the images to a user at mobile device display.
</claims>
</document>
