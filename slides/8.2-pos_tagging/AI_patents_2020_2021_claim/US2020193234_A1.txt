<document>

<filing_date>
2018-12-14
</filing_date>

<publication_date>
2020-06-18
</publication_date>

<priority_date>
2018-12-14
</priority_date>

<ipc_classes>
G06F16/904,G06K9/62,G06N20/00
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
SWEETKIND-SINGER, JOSHUA
PAI, DEEPAK
SRIVASTAVA, VIJAY
VENKITACHALAM, SHANKAR
</inventors>

<docdb_family_id>
71071677
</docdb_family_id>

<title>
ANOMALY DETECTION AND REPORTING FOR MACHINE LEARNING MODELS
</title>

<abstract>
In various embodiments of the present disclosure, output data generated by a deployed machine learning model may be received. An input data anomaly may be detected based at least in part on analyzing input data of the deployed machine learning model. An output data anomaly may further be detected based at least in part on analyzing the output data of the deployed machine learning model. A determination may be made that the input data anomaly contributed to the output data anomaly based at least in part on comparing the input data anomaly to the output data anomaly. A report may be generated that is indicative of the input data anomaly and the output data anomaly, and the report may be transmitted to a client device.
</abstract>

<claims>
1. A computer system comprising: one or more processors; and one or more computer storage media storing computer-usable instructions that, when used by the one or more processors, cause the one or more processors to perform operations comprising: detecting an input data anomaly based at least in part on analyzing input data of a deployed machine learning model; detecting an output data anomaly based at least in part on analyzing output data generated by the deployed machine learning model; determining that the input data anomaly contributed to the output data anomaly based at least in part on comparing the input data anomaly to the output data anomaly; generating a report indicative of the input data anomaly having contributed to the output data anomaly; and transmitting a message including the report to a client device, the message configured to cause the client device to display the report.
2. The system of claim 1, wherein the analyzing the input data comprises: determining historical input data for the deployed machine learning model; and comparing the input data to the historical input data, wherein the detecting the input data anomaly is based at least in part on the comparing the input data to the historical input data.
3. The system of claim 1, wherein the detecting the input data anomaly comprises: based at least in part on comparing the input data to historical input data, determining that the input data includes at least one of a data quality issue or a data distribution issue with respect to the historical input data, wherein the input data anomaly includes the at least one of the data quality issue or the data distribution issue.
4. The system of claim 1, wherein the analyzing the output data of the deployed machine learning model comprises: determining historical output data for the deployed machine learning model; and comparing the output data to the historical output data, wherein the detecting the output data anomaly is based at least in part on the comparing the output data to the historical output data.
5. The system of claim 1, wherein the detecting the output data anomaly comprises: based at least in part on comparing the output data to historical output data, determining that the output data differs from the historical output data by more than a threshold amount.
6. The system of claim 1, wherein the comparing the input data anomaly to the output data anomaly comprises: determining a first time of the output data anomaly; determining a second time of the input data anomaly; and comparing the first time to the second time.
7. The system of claim 1, wherein the determining that the input data anomaly contributed to the output data anomaly comprises: determining, based at least in part on comparing a first time corresponding to the output data anomaly to a second time corresponding to the input data anomaly, that the first time is within a threshold amount of time to the second time.
8. The system of claim 1, wherein the determining that the input data anomaly contributed to the output data anomaly comprises: determining a time frame of a first subset of the output data that corresponds to the output data anomaly; determining that the first input data anomaly contributed to the output data anomaly based at least in part on determining that the first input data anomaly corresponds to a second subset of the input data that corresponds to the time frame of the first subset of the output data.
9. The system of claim 1, wherein the report includes a first indication of the input data anomaly, a second indication of the output data anomaly, and a third indication of the contribution of the input data anomaly to the output data anomaly.
10. The system of claim 1, wherein the input data anomaly is a first input data anomaly, and wherein the one or more computer storage media further store computer-usable instructions that, when used by the one or more processors, cause the one or more processors to perform operations comprising: detecting a second input data anomaly based at least in part on the analyzing the input data of the deployed machine learning model; determining that the second input data anomaly contributed to the output data anomaly based at least in part on comparing the second input data anomaly to the output data anomaly; calculating, using another machine learning model, contribution factors for each type of the input data, the contribution factors representative of degrees of contribution of each type of the input data to the output data of the deployed machine learning model; determining a first contribution factor for a first type of the input data associated with the with the first input data anomaly; and determining a second contribution factor for a second type of the input data associated with the second input data anomaly, wherein, based at least in part on the first contribution factor and the second contribution factor, the message is further indicative of the degrees of contribution of the first input data anomaly and the second input data anomaly to the output data anomaly.
11. The system of claim 1, wherein the input data anomaly is a first input data anomaly, and wherein the one or more computer storage media further store computer-usable instructions that, when used by the one or more processors, cause the one or more processors to perform operations comprising: determining a first weight indicative of a first contribution of the first input data anomaly to the output data anomaly; determining a second weight indicative of a second contribution of a second input data anomaly to the output data anomaly; and determining that the first weight is greater than the second weight, wherein the message is further indicative of the second input data anomaly, and wherein the first input data anomaly is displayed before the second input data anomaly based at least in part on the first weight being greater than the second weight.
12. A computer-implemented method performed by at least one processor, the method comprising: detecting an output anomaly based at least in part on analyzing an output of a deployed machine learning model; detecting a first input anomaly and a second input anomaly based at least in part on analyzing an input to the deployed machine learning model; determining a first degree of contribution of the first input anomaly to a cause of the output anomaly; determining a second degree of contribution of the second input anomaly to the cause of the output anomaly; generating a report indicative of the first degree of contribution and the second degree of contribution; and transmitting the report to a client device for display by the client device.
13. The method of claim 12, wherein the detecting the output anomaly comprises: determining historical performance metrics for outputs of the deployed machine learning model; calculating performance metrics for the output of the deployed machine learning model; and determining that the performance metrics are indicative of the output anomaly based at least in part on comparing the performance metrics to the historical performance metrics.
14. The method of claim 12, wherein the detecting the output anomaly comprises determining that a difference between values of one or more performance metrics and historical values of the one or more performance metrics is greater than a threshold amount based at least in part on comparing the values to the historical values.
15. The method of claim 12, wherein the analyzing the output of the machine learning model comprises: obtaining output data of the deployed machine learning model for a given time period; determining ground truth data for the given time period; comparing the output data for the given time period to the ground truth data for the given time period; and generating values for one or more performance metrics based at least in part on the comparing the output data for the given time period and the ground truth data for the given time period.
16. The method of claim 12, wherein the report includes an indication of a type of anomaly for each of the first input anomaly and the second input anomaly, the type of anomaly corresponding to at least one of an input data quality issue or an input data distribution issue.
17. The system of claim 12, wherein the determining the first degree of contribution of the first input anomaly comprises: determining a time frame of a first subset of the output that corresponds to the output anomaly; and determining that the first input anomaly is causally related to the output anomaly based at least in part on determining that the first input anomaly corresponds to a second subset of the input that corresponds to the time frame of the first subset of the output.
18. The method of claim 12, wherein the analyzing the input comprises: determining historical input data for the machine learning model; and comparing input data of the input to the historical input data.
19. A computer system comprising: an input analyzer means for detecting an input data anomaly based at least in part on analyzing input data of a deployed machine learning model; an output analyzer means for detecting an output data anomaly based at least in part on analyzing output data of the deployed machine learning model; a contribution determiner means for determining a contribution of the input data anomaly to the output data anomaly; and a report generator means for generating a report indicative of the contribution of the input data anomaly to the output anomaly.
20. The computer system of claim 19, wherein the report includes an indication of a type of anomaly of the input anomaly, the type of anomaly corresponding to at least one of an input data quality issue or an input data distribution issue.
</claims>
</document>
