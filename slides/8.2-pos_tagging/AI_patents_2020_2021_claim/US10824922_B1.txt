<document>

<filing_date>
2018-12-12
</filing_date>

<publication_date>
2020-11-03
</publication_date>

<priority_date>
2018-12-12
</priority_date>

<ipc_classes>
G06F7/02,G06K9/00,G06K9/66,G06K9/72,G06N5/04,G06T5/00
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
TUTAR, ISMAIL BAHA
Arici, Tarik
</inventors>

<docdb_family_id>
73019968
</docdb_family_id>

<title>
Similarity detection system
</title>

<abstract>
Similarity detection methods and systems are provided that utilize a convolutional neural network model to jointly learn string matching and semantic textual similarity as an image recognition solution. For example, in some embodiments described herein, the similarity detection system may receive two strings as input, transform the two strings into two separate vectors, generate a high-resolution image and a low-resolution image, apply one or more convolutional operations to each image, and determine string matching and semantic textual similarity based at least partly on the high-resolution image and the low-resolution image.
</abstract>

<claims>
1. A system comprising: a non-transitory computer-readable storage medium storing computer-executable instructions; and one or more hardware processors in communication with the computer-readable memory and configured by the executable instructions to at least: obtain a first sequence of characters and a second sequence of characters, wherein the first sequence describes a first item in a data store and the second sequence describes a second item in the data store; transform the first sequence of characters into a first vector sequence; transform the second sequence of characters into a second vector sequence, wherein the first vector sequence and the second vector sequence each comprise multi-dimensional vectors; generate a first image based at least partly on the first vector sequence and the second vector sequence, the first image comprising a first matrix, wherein a value at an individual position in the first matrix is based at least partly on both a value from the first vector sequence and a value from the second vector sequence; transmit the first image to a first convolutional neural network model, the first convolutional neural network model configured to extract one or more first image features; generate a second image based at least partly on the first vector sequence and the second vector sequence, wherein the second image is formed at least in part by applying a convolution layer to a second matrix with values based at least partly on the first vector sequence and the second vector sequence; transmit the second image to a second convolutional neural network model, the second convolutional neural network model configured to extract one or more second image features; generate a string matching score based at least partly on the one or more first image features; generate a semantic similarity score based at least partly on the one or more second image features; generate a final similarity score based at least partly on the string matching score and the semantic similarity score, the final similarity score representing an estimated likelihood that the first sequence of characters and the second sequence of characters would be perceived by a human as having similar meanings to each other; and merge entries automatically for the first item and the second item in the data store based at least partly on the final similarity score.
2. The system of claim 1, wherein the first matrix is generated by tiling the first vector sequence horizontally, tiling the second vector sequence vertically, and concatenating values from the tiled first vector sequence and the tiled second vector sequence.
3. The system of claim 1, wherein the first image and the second image are transmitted simultaneously to the first convolutional neural network model and the second convolutional neural network model respectively.
4. A system comprising: a non-transitory computer-readable storage medium storing computer-executable instructions; and one or more hardware processors in communication with the computer-readable memory and configured by the executable instructions to at least: obtain a first sequence of characters and a second sequence of characters, wherein the first sequence is associated with a first item in a data store and the second sequence is associated with a second item in the data store; transform the first sequence of characters into a first vector sequence; transform the second sequence of characters into a second vector sequence; generate a first image based at least partly on the first vector sequence and the second vector sequence, the first image comprising a first matrix with values based at least partly on the first vector sequence and the second vector sequence; transmit the first image to a first convolutional learning model, the first convolutional learning model configured to determine an extent to which portions of the first vector sequence and the second vector sequence match each other; generate a second image based at least partly on the first vector sequence and the second vector sequence, wherein the second image is formed by applying one or more convolution operations to a second matrix with values based at least partly on the first vector sequence and the second vector sequence; transmit the second image to a second convolutional learning model, the second convolutional learning model configured to determine semantic textual similarity between the first sequence represented by the first vector sequence and the second sequence represented by the second vector sequence; generate a final similarity score based at least partly on output of the first convolutional learning model and output of the second convolutional learning model; and store an association between the first item and the second item in the data store based at least partly on the final similarity score.
5. The system of claim 4, wherein the first sequence of characters and the second sequence of characters each comprise strings of alphanumeric text.
6. The system of claim 4, wherein transforming the first sequence of characters into a first vector sequence comprises selecting, for each character in the first sequence, values previously associated with the character in a stored data structure.
7. The system of claim 4, wherein the first image has a higher resolution than the second image.
8. The system of claim 4, wherein the first image and the second image are transmitted simultaneously to the first convolutional learning model and the second convolutional learning model respectively.
9. The system of claim 4, wherein the first convolutional learning model is configured to determine the extent to which portions of the first vector sequence and the second vector sequence match each other based on two or more sets of colors, shapes, or patterns detected in the first image.
10. The system of claim 4, wherein the first convolutional learning model is configured to extract one or more first image features by: applying one or more convolution operations to the first image; and applying one or more pooling operations to the first image.
11. The system of claim 10, wherein the one or more convolution operations comprise at least one of edge detection, sharpening, or blurring operations.
12. The system of claim 10, wherein the one or more pooling operations comprise at least one of attention-pooling, max-pooling, min-pooling, average-pooling, or sum-pooling.
13. The system of claim of claim 4, wherein the first convolutional learning model is configured to determine the extent to which portions of the first vector sequence and the second vector sequence match at least in part by detecting one or more diagonal line patterns in the first image.
14. A computer-implemented method comprising: obtaining a first sequence of characters and a second sequence of characters, wherein the first sequence is associated with a first item in a data store and the second sequence is associated with a second item in the data store; transforming the first sequence of characters into a first vector sequence; transforming the second sequence of characters into a second vector sequence; generating a first image based at least partly on the first vector sequence and the second vector sequence, the first image comprising a first matrix with values based at least partly on the first vector sequence and the second vector sequence; transmitting the first image to a first convolutional learning model, the first convolutional learning model configured to determine an extent to which portions of the first vector sequence and the second vector sequence match each other; generating a second image based at least partly on the first vector sequence and the second vector sequence, wherein the second image is formed by applying one or more convolution operations to a second matrix with values based at least partly on the first vector sequence and the second vector sequence; transmitting the second image to a second convolutional learning model, the second convolutional learning model configured to determine semantic textual similarity between the first sequence represented by the first vector sequence and the second sequence represented by the second vector sequence; generating a final similarity score based at least partly on output of the first convolutional learning model and output of the second convolutional learning model; and storing an association between the first item and the second item in the data store based at least partly on the final similarity score.
15. The computer-implemented method of claim 14, wherein the first convolutional learning model is further configured to reduce the dimensionality of one or more feature maps through downsampling or subsampling.
16. The computer-implemented method of claim 14, wherein the first convolutional learning model and the second convolutional learning model are further configured to apply rectified linear unit operations.
17. The computer-implemented method of claim 14, wherein the first convolutional learning model and the second convolutional learning model each identify one or more diagonal line patterns.
18. The computer-implemented method of claim 14, wherein the first image and the second image are transmitted simultaneously to the first convolutional learning model and the second convolutional learning model respectively.
19. The computer-implemented method of claim 14, wherein the first convolutional learning model and the second convolutional learning model are further configured to utilize gradient descent to train the first convolutional learning model and the second convolutional learning model respectively.
20. The computer-implemented method of claim 14, further comprising: identifying a difference between the first sequence of characters and the second sequence of characters; and generating a user interface displaying one or more recommended edits to the first sequence of characters that would cause the first sequence of characters to match the second sequence of characters.
</claims>
</document>
