<document>

<filing_date>
2018-10-02
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-10-02
</priority_date>

<ipc_classes>
G06N3/08,G06N7/00
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
CHEN HAICHUN
LOMADA, VIJETH
BHATIA, VIDIT
</inventors>

<docdb_family_id>
69946875
</docdb_family_id>

<title>
PERFORMING AUTOMATIC SEGMENT EXPANSION OF USER EMBEDDINGS USING MULTIPLE USER EMBEDDING REPRESENTATION TYPES
</title>

<abstract>
The present disclosure relates to systems, non-transitory computer-readable media, and methods for expanding user segments automatically utilizing user embedding representations generated by a trained neural network. For example, a user embeddings system expands a segment of users by identifying holistically similar users from uniform user embeddings that encode behavior and/or realized traits of the users. Further, the user embeddings system facilitates the expansion of user segments in a particular direction and focus to improve the accuracy of user segments.
</abstract>

<claims>
1. In a digital medium environment for generating user embedding types, a computer-implemented method for visualizing user embedding representations, comprising: performing a step for generating a plurality of user embeddings for a plurality of users based on structured user data that transforms user profile data into uniform user embedding vectors; providing, within a graphical user interface provided to a client device, a visualization that displays a segment of user embeddings from the user embeddings generated for the plurality of users; determining, based on user input from the client device to expand the displayed segment of user embeddings, additional user embeddings that are similar to the segment of user embeddings; and providing, within the graphical user interface provided to the client device, an updated visualization that displays the segment of user embeddings and an expanded segment of user embeddings.
2. The computer-implemented method of claim 1, further comprising: displaying, within the graphical user interface, an additional visualization that displays a distribution of user characteristics for the segment of user embeddings plotted in the visualization; receiving a selection of a user characteristic displayed in the additional visualization; identifying user embeddings from the segment of user embeddings displayed in the visualization that have the selected user characteristic; removing the identified user embeddings having the selected user characteristic from the segment of user embeddings; and updating the visualization to exclude display of the identified user embeddings in three-dimensional space.
3. The computer-implemented method of claim 1, further comprising: identifying the user profile data indicating user attributes for the plurality of users; identifying the segment of user embeddings from the generated user embeddings; reducing dimensionality of the segment of user embeddings from high-dimensional space to three-dimensional space, wherein the visualization displays the segment of user embeddings in three-dimensional space; and receiving, from the client device, user input to expand the displayed segment of user embeddings.
4. The computer-implemented method of claim 3, further comprising performing a step for converting user profile data for the plurality of users into structured user data that encodes user attributes into the structured user data.
5. The computer-implemented method of claim 4, wherein performing the step for converting the user profile data for the plurality of users into the structured user data comprises converting the user profile data into organized user interaction data based on content items, interaction types, and interaction timestamps.
6. The computer-implemented method of claim 5, wherein performing the step for generating the user embeddings for the plurality of users based on the structured user data comprises generating the user embeddings for the plurality of users based on the organized user interaction data to obtain homogenous embedding representations from heterogeneous user interaction data.
7. The computer-implemented method of claim 4, wherein performing the step for converting the user profile data for the plurality of users into the structured user data comprises converting the user profile data into user trait sequences for the plurality of users based on user trait data and associated timestamps from the user profile data.
8. The computer-implemented method of claim 7, wherein performing the step for generating the user embeddings for the plurality of users based on the structured user data comprises generating the user embeddings for the plurality of users that encode how traits change over time utilizing the user trait sequences.
9. A non-transitory computer-readable medium storing instructions that, when executed by at least one processor, cause a computer system to: generate user embeddings for a plurality of users generated from structured user data utilizing a neural network trained to create user embeddings that encode user profile data into uniform user embeddings; determine a segment of users from the plurality of users based on user-provided parameters; plot, within a graphical user interface having a user-manipulatable visualization, user embeddings corresponding to the segment of users; receive a selection of a user embeddings type and a user similarity metric; identify additional user embeddings having the selected user embedding type that satisfy the user similarity metric; and update the visualization to display an expanded segment of users comprising the user embeddings corresponding to the segment of users and the additional user embeddings.
10. The non-transitory computer-readable medium of claim 9, wherein: a first user embedding type comprises a user interaction embeddings; and a second user embedding type comprises a user traits embeddings.
11. The non-transitory computer-readable medium of claim 10, further comprising instructions that, when executed by at least one processor, cause the computer system to identify the additional user embeddings based on determining a cosine similarity in high-dimensional space of the generated user embeddings with respect to the user embeddings corresponding to the segment of users.
12. The non-transitory computer-readable medium of claim 11, wherein the instructions that cause the computer system to identify the additional user embeddings comprises: detect a selection of a user similarity metric corresponding to a number of similar users; determine, based on the selected user similarity metric, the number of similar users to be identified; and identify the additional user embeddings until the additional user embeddings match the number of similar users to be identified.
13. The non-transitory computer-readable medium of claim 11, wherein the instructions that cause the computer system to identify the additional user embeddings comprises: detect a selection of a user similarity metric corresponding to a similarity range of similar users; determine, based on the selected user similarity metric, the similarity range of similar users to be identified; and identify the additional user embeddings to include generated user embeddings of the plurality of users that are within the similarity range of the selected user similarity metric.
14. The non-transitory computer-readable medium of claim 11, further comprising instructions that, when executed by at least one processor, cause the computer system to: identify the user profile data that comprises user interaction data indicating the plurality of users performing a plurality of interactions with a plurality of content items; generate the structured user data as user interaction data organized into a hierarchy structure based on the plurality of content items, then the plurality of interactions, then interaction timestamps; and wherein creating the generated user embeddings that encode the user profile data into uniform user embeddings comprises generating the user interaction embeddings for the plurality of users from the organized user interaction data utilizing an interaction-to-vector neural network.
15. The non-transitory computer-readable medium of claim 11, further comprising instructions that, when executed by at least one processor, cause the computer system to: identify the user profile data that comprises user traits that correspond to a plurality of timestamps for the plurality of users; generate the structured user data as user trait sequences for the plurality of users that encodes user trait changes with respect to the plurality of timestamps based on the user traits; and wherein creating the generated user embeddings that encode the user profile data into uniform user embeddings comprises generating user trait embeddings for the plurality of users from the user trait sequences utilizing an LSTM autoencoder neural network trained to generate the user trait embeddings that encode how traits change over time.
16. A system for visualizing user embeddings in low-dimensional space comprising: at least one processor; a memory that comprises: user profile data for a plurality of users; user interaction data for the plurality of users corresponding to interactions with a first digital campaign; and user embeddings for the plurality of users from a neural network trained to generate the user embeddings from the user profile data; at least one non-transitory computer-readable storage medium storing instructions that, when executed by the at least one processor, cause the system to: identify, a segment of users from the plurality of users; determine additional users that have user embeddings within a similarity threshold of the segment of users by utilizing distance comparisons in a high-dimensional vector space; expand the segment of users to comprise the additional users by including users having user embeddings within a threshold distance to the segment of users in the high-dimensional vector space; and facilitating a second promotional campaign to provide content to the expanded segment of users.
17. The system of claim 16, further comprising instructions that, when executed by at least one processor, cause the system to plot, within a graphical user interface, the expanded segment of users as a three-dimensional visualization.
18. The system of claim 16, wherein the instructions that cause the system to determine the additional users that have user embeddings within the similarity threshold of the segment of users comprises: receiving a selection of a user similarity metric and a metric amount corresponding to the user similarity metric; and identifying the additional users based on determining user embeddings from the plurality of users that have a cosine distance to the segment of users satisfying the metric amount.
19. The system of claim 18, wherein: the user similarity metric corresponds to a number of similar users; the metric amount comprises a number of users; and identifying the additional users comprises determining, until the number of similar users is satisfied, users from the plurality of users that have the smallest user embeddings cosine distances to the segment of users who interacted with the content item of the first digital campaign.
20. The system of claim 18, wherein: the user similarity metric corresponds to a similarity range of similar users; the metric amount comprises a distance of similar users, the distance being a radial distance in high-dimensional vector space based on cosine similarity; and identifying the additional users further comprises determining generated user embeddings from the plurality of users that are within the threshold distance of user embeddings to the segment of users who interacted with the content item of the first digital campaign.
</claims>
</document>
