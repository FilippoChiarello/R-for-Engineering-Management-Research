<document>

<filing_date>
2020-03-09
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2019-03-11
</priority_date>

<ipc_classes>
G05D1/02,G06K9/00,G06K9/46,G06K9/62,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
HONDA MOTOR COMPANY
</assignee>

<inventors>
HASEGAWA YUJI
</inventors>

<docdb_family_id>
72424670
</docdb_family_id>

<title>
ROUTE DETERMINATION METHOD
</title>

<abstract>
In an environment in which a plurality of second pedestrians moves along predetermined movement patterns, a plurality of movement routes Rw when a first pedestrian moves toward a destination point is recognized. Data, in which an environmental image indicating a visual environment in front of a virtual robot when the virtual robot moves along each of the movement routes and a moving direction command indicating a moving direction of the virtual robot are combined, is generated as learning data. In the environmental image, colors corresponding to time-series displacement behaviors of a moving object image region is applied to at least a portion of the moving object image region indicating a pedestrian (moving object) present around a robot. Model parameters of a CNN (action model) is learned using the learning data, and a moving velocity command for a robot is determined using a learned CNN.
</abstract>

<claims>
1. A route determination method that is a method for determining a target movement route of a moving apparatus to a destination point in a condition in which a plurality of moving objects is present around the moving apparatus, the route determination method comprising: recognizing a plurality of movement routes of a first moving object when the first moving object moves to the destination point while avoiding interference with each of a plurality of second moving objects in a condition in which the plurality of second moving objects moves along a plurality of respective movement patterns different from each other; generating a plurality of pieces of learning data in which an environmental image having colors corresponding to time-series displacement behaviors of moving object image regions applied to at least a portion of the moving object image regions indicating moving objects present around the moving apparatus is generated as an environmental image indicating a visual environment around the moving apparatus when the moving apparatus moves along each of the plurality of movement routes, and environmental image data including the environmental image and action parameters indicating actions of the moving apparatus are associated with each other; generating a learned model that is the learned action model in which the environmental image data is input whereas the action parameters are output by learning model parameters of the action model in accordance with a designation learning method using the plurality of pieces of learning data; and determining the target movement route of the moving apparatus using the learned model.
2. The route determination method according to claim 1, wherein the environmental image data further includes at least one of a velocity image indicating fluctuations in velocity of the moving apparatus and a directional image indicating a direction of the destination point, in addition to the environmental image.
3. The route determination method according to claim 1, wherein the plurality of pieces of learning data is constituted of the environmental image data and the action parameters associated with the environmental image data, when a virtual image of robot moves along each of the plurality of movement routes in a virtual space.
</claims>
</document>
