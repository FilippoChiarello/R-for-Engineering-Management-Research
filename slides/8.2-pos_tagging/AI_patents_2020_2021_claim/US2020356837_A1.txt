<document>

<filing_date>
2019-09-11
</filing_date>

<publication_date>
2020-11-12
</publication_date>

<priority_date>
2019-05-07
</priority_date>

<ipc_classes>
G06F17/16,G06N3/04,G06N3/08,G06N5/04
</ipc_classes>

<assignee>
APPLE
</assignee>

<inventors>
HARGIL, ASAF
SAZEGARI, ALI
</inventors>

<docdb_family_id>
73046782
</docdb_family_id>

<title>
FAST DEEP LEARNING FULLY-CONNECTED INFERENCE
</title>

<abstract>
This application relates to performing fully-connected inferences using a convolutional neural network. A method includes receiving a two-dimensional input matrix that includes a plurality of elements. The method further includes identifying a two-dimensional weight matrix corresponding to the two-dimensional input matrix, where the two-dimensional weight matrix includes a plurality of weight values. The method further includes transposing a first column of the two-dimensional weight matrix and storing the transposed first column of the two-dimensional weight matrix in a first register having a first length corresponding to the transposed first column. The method further includes generating a first output element by performing a first dot product operation using a first row of the two-dimensional input matrix and the transposed first column. Finally, the method includes storing the first output element in a first row of a two-dimensional output matrix.
</abstract>

<claims>
1. A method for establishing a fully-connected inference implementation using a convolutional neural network, the method comprising, at a computing device: receiving a two-dimensional input matrix that includes a plurality of elements; identifying, by a processor, a two-dimensional weight matrix corresponding to the two-dimensional input matrix, the two-dimensional weight matrix including a plurality of weight values; transposing a first column of the two-dimensional weight matrix to produce a transposed first column; storing the transposed first column of the two-dimensional weight matrix in a first register having a first length corresponding to the transposed first column; generating a first output element by performing a first dot product operation using a first row of the two-dimensional input matrix and the transposed first column; and storing the first output element in a first row of a two-dimensional output matrix.
2. The method of claim 1, wherein the two-dimensional weight matrix is arranged in column-major order.
3. The method of claim 1, wherein the method is implemented by at least one processor included in the computing device, and the at least one processor includes a vector processing unit.
4. The method of claim 1, further comprising: transposing a second column of the two-dimensional weight matrix to produce a transposed second column; and storing the transposed second column of the two-dimensional weight matrix in a second register having a second length corresponding to the transposed second column.
5. The method of claim 4, further comprising: generating a second output element by performing a second dot product operation using the first row of the two-dimensional input matrix and the transposed second column; and storing the second output element in the first row of the two-dimensional output matrix.
6. The method of claim 1, further comprising: generating a third output element by performing a third dot product operation using a second row of the two-dimensional input matrix and the transposed first column; and storing the third output element in a second row of the two-dimensional output matrix.
7. The method of claim 1, wherein weight values associated with the transposed first column are read sequentially.
8. At least one non-transitory computer readable medium storing instructions that, when executed by at least one processor included in a computing device, cause the computing device to perform steps that include: receiving a two-dimensional input matrix that includes a plurality of elements; identifying a two-dimensional weight matrix corresponding to the two-dimensional input matrix, the two-dimensional weight matrix including a plurality of weight values; transposing a first column of the two-dimensional weight matrix to produce a transposed first column; storing the transposed first column of the two-dimensional weight matrix in a first register having a first length corresponding to the transposed first column; generating a first output element by performing a first dot product operation using a first row of the two-dimensional input matrix and the transposed first column; and storing the first output element in a first row of a two-dimensional output matrix.
9. The at least one non-transitory computer readable medium of claim 8, wherein the two-dimensional weight matrix is arranged in column-major order.
10. The at least one non-transitory computer readable medium of claim 8, wherein the at least one processor includes at least one vector processing unit.
11. The at least one non-transitory computer readable medium of claim 8, wherein the steps further include: transposing a second column of the two-dimensional weight matrix to produce a transposed second column; and storing the transposed second column of the two-dimensional weight matrix in a second register having a second length corresponding to the transposed second column.
12. The at least one non-transitory computer readable medium of claim 11, wherein the steps further include: generating a second output element by performing a second dot product operation using the first row of the two-dimensional input matrix and the transposed second column; and storing the second output element in the first row of the two-dimensional output matrix.
13. The at least one non-transitory computer readable medium of claim 8, wherein the steps further include: generating a third output element by performing a third dot product operation using a second row of the two-dimensional input matrix and the transposed first column; and storing the third output element in a second row of the two-dimensional output matrix.
14. The at least one non-transitory computer readable medium of claim 8, wherein weight values associated with the transposed first column are read sequentially.
15. A computing device configured to establishing a fully-connected inference implementation using a convolutional neural network, the computing device comprising: at least one memory storing: a two-dimensional input matrix that includes a plurality of elements, and a two-dimensional weight matrix corresponding to the two-dimensional input matrix, the two-dimensional weight matrix including a plurality of weight values, and at least one vector processor coupled to the at least one memory and configured to cause the computing device to: transpose a first column of the two-dimensional weight matrix to produce a transposed first column; store the transposed first column of the two-dimensional weight matrix in first a register having a first length corresponding to the transposed first column; generate a first output element by performing a first dot product operation using a first row of the two-dimensional input matrix and the transposed first column; and store the first output element in a first row of a two-dimensional output matrix.
16. The computing device of claim 15, wherein the two-dimensional weight matrix is arranged in column-major order.
17. The computing device of claim 15, wherein the at least one vector processor further causes the computing device to: transpose a second column of the two-dimensional weight matrix to produce a transposed second column; and store the transposed second column of the two-dimensional weight matrix in a second register having a second length corresponding to the transposed second column.
18. The computing device of claim 17, wherein the at least one vector processor further causes the computing device to: generate a second output element by performing a second dot product operation using the first row of the two-dimensional input matrix and the transposed second column; and store the second output element in the first row of the two-dimensional output matrix.
19. The computing device of claim 15, wherein the at least one vector processor further causes the computing device to: generate a third output element by performing a third dot product operation using a second row of the two-dimensional input matrix and the transposed first column; and store the third output element in a second row of the two-dimensional output matrix.
20. The computing device of claim 15, wherein weight values associated with the transposed first column are read sequentially.
</claims>
</document>
