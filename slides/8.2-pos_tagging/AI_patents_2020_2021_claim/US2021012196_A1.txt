<document>

<filing_date>
2020-07-10
</filing_date>

<publication_date>
2021-01-14
</publication_date>

<priority_date>
2019-07-11
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
UNIVERSITY OF CALIFORNIA
</assignee>

<inventors>
JAVIDI, TARA
KOUSHANFAR, FARINAZ
LALITHA, ANUSHA
Kilinc, Osman Cihan
</inventors>

<docdb_family_id>
74103221
</docdb_family_id>

<title>
PEER-TO-PEER TRAINING OF A MACHINE LEARNING MODEL
</title>

<abstract>
A method may include training, based on a first training data available at a first node in a network, a first local machine learning model. A first local belief of a parameter set of a global machine learning model may be updated based on the training of the first local machine learning model. A second local belief of the parameter set of the global machine learning model may be received from a second node in the network. The second local belief may have been updated based on the second node training a second local machine learning model. The second local machine learning model may be trained based on a second training data available at the second node. The first local belief may be updated based on the second local belief of the second node. Related systems and articles of manufacture, including computer program products, are also provided.
</abstract>

<claims>
1. A system, comprising: at least one processor; and at least one memory including program code which when executed by the at least one processor provides operations comprising: training, based at least on a first training data available at a first node in a network, a first local machine learning model; updating, based at least on the training of the first local machine learning model, a first local belief of a parameter set of a global machine learning model; receiving, from a second node in the network, a second local belief of the parameter set of the global machine learning model, the second local belief having been updated based at least on the second node training a second local machine learning model, and the second local machine learning model being trained based at least on a second training data available at the second node; and updating, based at least on the second local belief of the second node, the first local belief of the parameter set of the global machine learning model.
2. The system of claim 1, further comprising: sending, to the second node, the first local belief of the parameter set of the global machine learning model such that the second local belief of the second node is further updated based on the first local belief of the first node.
3. The system of claim 1, further comprising: receiving, from a third node in the network, a third local belief of the parameter set of the global machine learning model, the third local belief having been updated based at least on the third node training a third local machine learning model, and the third local machine learning model being trained based at least on a third training data available at the third node; and updating, based at least on an aggregate of the second local belief and the third local belief, the first local belief of the parameter set of the global machine learning model.
4. The system of claim 3, wherein the aggregate of the second local belief and the third local belief comprises an average of the second local belief and the third local belief.
5. The system of claim 1, wherein the second local belief of the second node is further updated based at least on a third local belief of a third node in the network.
6. The system of claim 1, further comprising: performing, based at least on a parameter set of the first local machine learning model trained based on the first training data, a statistical inference of the parameter set of the global machine learning model; and updating, based at least on the statistical inference, the first local belief of the parameter set of the global machine learning model.
7. The system of claim 6, wherein the statistical inference comprises a Bayesian inference.
8. The system of claim 1, wherein the global machine learning model comprises a neural network, and wherein the parameter set includes one or more weights applied by the neural network.
9. The system of claim 1, wherein the global machine learning model comprises a regression model, and wherein the parameter set includes a relationship between one or more independent variables and dependent variables.
10. The system of claim 1, wherein the network includes a plurality of nodes interconnected to form a strongly connected aperiodic graph.
11. A computer-implemented method, comprising: training, based at least on a first training data available at a first node in a network, a first local machine learning model; updating, based at least on the training of the first local machine learning model, a first local belief of a parameter set of a global machine learning model; receiving, from a second node in the network, a second local belief of the parameter set of the global machine learning model, the second local belief having been updated based at least on the second node training a second local machine learning model, and the second local machine learning model being trained based at least on a second training data available at the second node; and updating, based at least on the second local belief of the second node, the first local belief of the parameter set of the global machine learning model.
12. The method of claim 11, further comprising: sending, to the second node, the first local belief of the parameter set of the global machine learning model such that the second local belief of the second node is further updated based on the first local belief of the first node.
13. The method of claim 11, further comprising: receiving, from a third node in the network, a third local belief of the parameter set of the global machine learning model, the third local belief having been updated based at least on the third node training a third local machine learning model, and the third local machine learning model being trained based at least on a third training data available at the third node; and updating, based at least on an aggregate of the second local belief and the third local belief, the first local belief of the parameter set of the global machine learning model.
14. The method of claim 13, wherein the aggregate of the second local belief and the third local belief comprises an average of the second local belief and the third local belief.
15. The method of claim 11, wherein the second local belief of the second node is further updated based at least on a third local belief of a third node in the network.
16. The method of claim 11, further comprising: performing, based at least on a parameter set of the first local machine learning model trained based on the first training data, a statistical inference of the parameter set of the global machine learning model; and updating, based at least on the statistical inference, the first local belief of the parameter set of the global machine learning model.
17. The method of claim 16, wherein the statistical inference comprises a Bayesian inference.
18. The method of claim 11, wherein the global machine learning model comprises a neural network, and wherein the parameter set includes one or more weights applied by the neural network.
19. The method of claim 11, wherein the global machine learning model comprises a regression model, and wherein the parameter set includes a relationship between one or more independent variables and dependent variables.
20. A non-transitory computer readable medium storing instructions, which when executed by at least one data processor, result in operations comprising: training, based at least on a first training data available at a first node in a network, a first local machine learning model; updating, based at least on the training of the first local machine learning model, a first local belief of a parameter set of a global machine learning model; receiving, from a second node in the network, a second local belief of the parameter set of the global machine learning model, the second local belief having been updated based at least on the second node training a second local machine learning model, and the second local machine learning model being trained based at least on a second training data available at the second node; and updating, based at least on the second local belief of the second node, the first local belief of the parameter set of the global machine learning model.
</claims>
</document>
