<document>

<filing_date>
2020-06-08
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-10
</priority_date>

<ipc_classes>
B25J19/02,B25J9/16,G06T7/73
</ipc_classes>

<assignee>
PREFERRED NETWORKS
</assignee>

<inventors>
TAKAHASHI, KUNIYUKI
YONEKURA, Kenta
</inventors>

<docdb_family_id>
73651331
</docdb_family_id>

<title>
GENERATION METHOD FOR TRAINING DATASET, MODEL GENERATION METHOD, TRAINING DATA GENERATION APPARATUS, INFERENCE APPARATUS, ROBOTIC CONTROLLER, MODEL TRAINING METHOD AND ROBOT
</title>

<abstract>
One aspect of the present disclosure relates to a generation method for a training dataset, comprising: capturing, by one or more processors, a target object to which a marker unit recognizable under a first illumination condition is provided; and acquiring, by the one or more processors, a first image where the marker unit is recognizable and a second image obtained by capturing the target object under a second illumination condition.
</abstract>

<claims>
1. A generation method for a training dataset, comprising: capturing, by one or more processors, a target object to which a marker unit recognizable under a first illumination condition is provided; and acquiring, by the one or more processors, a first image where the marker unit is recognizable and a second image obtained by capturing the target object under a second illumination condition.
2. The generation method as claimed in claim 1, wherein the marker unit seems different under the first illumination condition and the second illumination condition.
3. The generation method as claimed in claim 1, wherein the object is amorphous or transparent.
4. The generation method as claimed in claim 1, wherein the object is a clothing, a liquid or a powder.
5. The generation method as claimed in claim 1, wherein the marker unit is a fluorescent marker.
6. A model generation method, comprising: using, by one or more processors, a first image where a marker unit provided to a target object is recognizable under a first illumination condition and a second image obtained by capturing the target object under a second illumination condition to generate a model, wherein the generated model estimates information for the marker unit from the incoming second image.
7. The model generation method as claimed in claim 6, wherein the object is amorphous or transparent.
8. The model generation method as claimed in claim 6, wherein the object is a clothing, a liquid or a powder.
9. The generation method as claimed in claim 6, wherein the marker unit is a fluorescent marker.
10. A training data generation system, comprising: one or more memories; and one or more processors configured to: capture a target object to which a marker unit recognizable under a first illumination condition is provided; emit first illumination conditioned light to the target object; emit second illumination conditioned light to the target object; switch illumination of the first illumination conditioned light to the target object and illumination of the second illumination conditioned light to the target object; and acquire a first image in a state where the marker unit becomes recognizable by emitting the first illumination conditioned light to the target object and a second image in a state where the second illumination conditioned light is emitted to the target object.
11. An inference apparatus, wherein the inference apparatus has a model trained in accordance with the model generation method as claimed in claim 6.
12. A robot, comprising: one or more memories that store a model trained in accordance with the model generation method as claimed in claim 6; and one or more processors configured to control an operation of the robot based on the second image in a state where second illumination conditioned light is emitted to a to-be-operated object.
13. The robot as claimed in claim 12, wherein the object is amorphous or transparent.
14. The robot as claimed in claim 12, wherein the object is a clothing, a liquid or a powder.
15. The robot as claimed in claim 12, wherein the marker unit is a fluorescent marker.
16. The generation method as claimed in claim 1, wherein the marker unit is a light emitting unit recognizable under invisible light, and the second illumination condition is under visible light, and the first illumination condition is under invisible light emitted by the light emitting unit.
17. The generation method as claimed in claim 1, wherein the marker unit is a reflection unit including a recursive reflective material, and the second illumination condition is environmental light, and the first illumination condition is a condition where a capturing unit is capable of capturing reflected light from the reflection unit.
</claims>
</document>
