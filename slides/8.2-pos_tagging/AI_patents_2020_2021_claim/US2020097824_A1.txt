<document>

<filing_date>
2019-11-27
</filing_date>

<publication_date>
2020-03-26
</publication_date>

<priority_date>
2017-12-11
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08,G06N3/10
</ipc_classes>

<assignee>
CAMBRICON TECHNOLOGIES COMPANY
</assignee>

<inventors>
LIU SHAOLI
MENG, XIAOFU
WANG BINGRUI
ZHANG YAO
</inventors>

<docdb_family_id>
66819989
</docdb_family_id>

<title>
NEURAL NETWORK CALCULATION APPARATUS AND METHOD
</title>

<abstract>
The present disclosure discloses a neural network processing module, in which a mapping unit is configured to receive an input neuron and a weight, and then process the input neuron and/or the weight to obtain a processed input neuron and a processed weight; and an operation unit is configured to perform an artificial neural network operation on the processed input neuron and the processed weight. Examples of the present disclosure may reduce additional overhead of the device, reduce the amount of access, and improve efficiency of the neural network operation.
</abstract>

<claims>
1. A neural network operation module, comprising: a mapping unit configured to process input data after receiving the input data to obtain processed input data, wherein the input data includes at least one input neuron and at least one weight, and the processed input data includes a processed input neuron and a processed weight; a storage unit configured to store the processed input neuron, the processed weight, a neural network instruction, and an operation result; an instruction control unit configured to obtain the neural network instruction from an instruction caching unit and decode the neural network instruction into a microinstruction executed by an operation unit; the operation unit configured to obtain the processed input neuron and the processed weight from a first input caching unit and a second input caching unit, and then perform an artificial neural network operation on the processed input neuron and the processed weight according to the microinstruction to obtain the operation result; and an output caching unit configured to cache the operation result.
2. The neural network operation module of claim 1, further comprising a direct memory access unit configured to read/write data between the storage unit and an instruction caching unit, the first input caching unit, the second input caching unit, or the output caching unit, the instruction caching unit configured to cache the neural network instruction read by the direct memory access unit, the first input caching unit configured to cache first cache data read by the direct memory access unit, wherein the first cache data is the processed input neuron or the processed weight, and the second input caching unit configured to cache second cache data read by the direct memory access unit, wherein the second cache data is the processed weight or the processed input neuron, and the second cache data is inconsistent with the first cache data.
3. The neural network operation module of claim 1, wherein the mapping unit includes: a first sparse processing unit configured to process second input data to obtain third output data and second output data, and transmit the third output data to a first data processing unit, and the first data processing unit configured to process first input data according to the third output data to obtain first output data, and when the first input data includes at least one input neuron and the second input data includes the at least one weight, the first output data is the processed input neuron, the second output data is the processed weight, and the third output data is connection data of the weight, when the first input data includes the at least one weight and the second input data includes the at least one input neuron, the first output data is the processed weight, the second output data is the processed input neuron, and the third output data is connection data of the input neuron.
4. The neural network operation module of claim 1, wherein the mapping unit includes: a second sparse processing unit configured to receive third input data, obtain first connection data according to the third input data, and transmit the first connection data to a connection processing unit, a third sparse processing unit configured to receive fourth input data, obtain second connection data according to the fourth input data, and transmit the second connection data to the connection processing unit, the connection processing unit configured to obtain third connection data according to the first connection data and the second connection data, and transmit the third connection data to a second data processing unit, the second data processing unit configured to process the third input data and the fourth input data according to the third connection data after receiving the third input data, the fourth input data, and the third connection data to obtain fourth output data and fifth output data, and when the third input data includes the at least one input neuron and the fourth input data includes the at least one weight, the first connection data is the connection data of the input neuron, the second connection data is the connection data of the weight, the fourth output data is the processed input neuron, and the fifth output data is the processed weight, when the third input data includes the at least one weight and the fourth input data includes the at least one input neuron, the first connection data is the connection data of the weight, the second connection data is the connection data of the input neuron, the fourth output data is the processed weight, and the fifth output data is the processed input neuron.
5. The neural network operation module of claim 3, wherein the connection data of the input neuron and the connection data of the weight being represented in a form of direct index or stride index includes: when the connection data of the input neuron is represented in the form of direct index, the connection data is a string composed of 0 and 1, wherein 0 indicates that an absolute value of the input neuron is smaller than or equal to a first threshold and 1 indicates that the absolute value of the input neuron is greater than the first threshold, when the connection data of the input neuron is represented in the form of stride index, the connection data is a string composed of values of distance between the input neuron whose absolute value is greater than the first threshold and the previous input neuron whose absolute value is greater than the first threshold, when the connection data of the weight is represented in the form of direct index, the connection data is a string composed of 0 and 1, wherein 0 indicates that the absolute value of the weight is smaller than or equal to the second threshold, which means that the input neuron corresponding to the weight is not connected with the output neuron of the weight, and 1 indicates that the absolute value of the weight is greater than the second threshold, which means that the input neuron corresponding to the weight is connected with the output neuron of the weight, the connection data of the weight represented in the form of direct index has two orders of representation: a string of 0 and 1 composed of the connection state between each output neuron and all input neurons, or a string of 0 and 1 composed of the connection state between each input neuron and all output neurons, and when the connection data of the weight is represented in the form of stride index, the connection data is a string of values of distance between the input neuron connected with an output neuron and the previous input neuron connected with the output neuron, wherein when both the connection data of the input neuron and the connection data of the weight are represented in the form of stride index, and the connection data of the weight and a string of the connection data of the input neuron are stored in an order of physical address from low to high, the connection processing unit is configured to: accumulate each element in the string of the connection data of the input data and an element that is stored in a physical address lower than the physical address in which the each element is stored to obtain new elements, wherein the new elements compose fourth connection data, similarly, perform the same operation on the string of the second connection data to obtain fifth connection data, select the same elements from the string of the fourth connection data and the string of the fifth connection data, and sort the elements in an order of element values from small to large to form a new string, and perform a subtraction on each element in the new string and an element (adjacent to the element) whose value is smaller than the value of the element to obtain new elements, wherein the new elements compose the third connection data, wherein when both the first connection data and the second connection data are represented in the form of direct index, the connection processing unit is configured to perform an AND operation on the first connection data and the second connection data to obtain the third connection data, and wherein when one of the first connection data and the second connection data is represented in the form of stride index and the other is represented in the form of direct index, the connection processing unit is configured to: when the first connection data is represented in the form of stride index, convert the first connection data into the connection data represented in the form of direct index, when the second connection data is represented in the form of stride index, convert the second connection data into the connection data represented in the form of direct index, and perform the operation on the first connection data and the second connection data to obtain the third connection data.
6. The neural network operation module of claim 5, wherein when one of the first connection data and the second connection data is represented in the form of stride index and the other is represented in the form of direct index, and the strings representing the first connection data and the second connection data are stored in an order of physical address from low to high, the connection processing unit is further configured to: when the first connection data is represented in the form of stride index, convert the second connection data into the connection data represented in the form of stride index, when the second connection data is represented in the form of stride index, convert the first connection data into the connection data represented in the form of stride index, accumulate each element in the string of the connection data of the input data and an element that is stored in a physical address lower than the physical address in which the each element is stored to obtain new elements, wherein the new elements compose the fourth connection data, similarly, perform the same operation on a string of the second connection data to obtain the fifth connection data, select the same elements from the string of the fourth connection data and the string of the fifth connection data, and sort the elements in an order of element values from small to large to form a new string, and perform a subtraction on each element in the new string and an element (adjacent to the element) whose value is smaller than the value of the element to obtain new elements, wherein the new elements compose the third connection data.
7. The neural network operation module of claim 1, wherein before processing the input data, the mapping unit is further configured to: group the at least one input neuron to obtain M groups of the input neurons, wherein the M is an integer greater than or equal to 1, determine whether each group of the input neurons in the M groups of the input neurons satisfies a first preset condition, wherein the first preset condition includes that a count of the input neuron whose absolute value is smaller than or equal to the third threshold in a group of the input neurons is smaller than or equal to the fourth threshold, when any group of the input neurons in the M groups of the input neurons does not satisfy the first preset condition, delete the group of the input neurons, group the at least one weight to obtain N groups of the weights, wherein the N is an integer greater than or equal to 1, determine whether each group of the weights in the N groups of the weights satisfies a second preset condition, wherein the second preset condition includes that the count of the weight whose absolute value is smaller than or equal to the fifth threshold in a group of the weights is smaller than or equal to the sixth threshold, and when any group of the weights in the N groups of the weights does not satisfy the second preset condition, delete the group of the weights.
8. A neural network operation module, comprising a storage unit configured to store first input data and connection data of the first input data, processed second input data, a neural network instruction, and an operation result, wherein the first input data is an input neuron or a weight, the connection data of the first input data is connection data of the input neuron or connection data of the weight, and the processed second input data is a processed input neuron or a processed weight; a mapping unit configured to obtain the first input data and the connection data of the first input data, process the first input data according to the connection data of the first input data to obtain processed first input data, wherein the processed first input data is the processed input neuron or the processed weight; an instruction control unit configured to obtain the neural network instruction from an instruction caching unit and decode the neural network instruction into a microinstruction executed by an operation unit; the operation unit configured to obtain the processed first input data and the processed second input data and then perform an artificial neural network operation on the processed first input data and the processed second input data according to the microinstruction to obtain the operation result; and an output caching unit configured to cache the operation result.
9. The neural network operation module of claim 8, further comprising a direct memory access unit configured to read/write data between the storage unit and an instruction caching unit, the mapping unit, a first input caching unit, a second input caching unit, or the output caching unit, and the first input caching unit is configured to cache the first input data, the connection data of the first input data, or the processed first input data, the second input caching unit is configured to cache the processed second input data, and the processed second input data is inconsistent with the processed first input data, and the instruction caching unit configured to cache the neural network instruction read by the direct memory access unit.
10. The neural network operation module of claim 9, wherein when the mapping unit is located between the direct memory access unit and the first input caching unit, the mapping unit is configured to obtain the first input data and the connection data of the first input data from the storage unit through the direct memory access unit, and store the processed first input data into the first input caching unit, and the first input caching unit is configured to cache the processed first input data.
11. The neural network operation module of claim 10, wherein when the mapping unit is located between the first input caching unit and the operation unit, the first input caching unit is configured to cache the first input data and the connection data of the first input data, the mapping unit is configured to obtain the first input data and the connection data of the first input data from the first input caching unit, and transmit the processed first input data to the operation unit.
12. The neural network operation module of claim 8, wherein the mapping unit includes: an input data caching unit configured to cache the first input data, wherein the first input data includes at least one input neuron or at least one weight, a connection caching unit configured to cache the connection data of the first input data, and a fourth sparse processing unit configured to process the first input data according to the connection data of the first input data to obtain processed first input data.
13. The neural network operation module of claim 12, wherein the connection data of the input neuron and the connection data of the weight being represented in a form of direct index or stride index includes: when the connection data of the input neuron is represented in the form of direct index, the connection data is a string composed of 0 and 1, wherein 0 indicates that an absolute value of the input neuron is smaller than or equal to a first threshold and 1 indicates that the absolute value of the input neuron is greater than the first threshold, when the connection data of the input neuron is represented in the form of stride index, the connection data is a string composed of values of distance between the input neuron whose absolute value is greater than the first threshold and the previous input neuron whose absolute value is greater than the first threshold, when the connection data of the weight is represented in the form of direct index, the connection data is a string composed of 0 and 1, wherein 0 indicates that the absolute value of the weight is smaller than or equal to the second threshold, which means that the input neuron corresponding to the weight is not connected with the output neuron of the weight, and 1 indicates that the absolute value of the weight is greater than the second threshold, which means that the input neuron corresponding to the weight is connected with the output neuron of the weight, the connection data of the weight represented in the form of direct index has two orders of representation: a string of 0 and 1 composed of the connection state between each output neuron and all input neurons, or a string of 0 and 1 composed of the connection state between each input neuron and all output neurons, and when the connection data of the weight is represented in the form of stride index, the connection data is a string of values of distance between the input neuron connected with an output neuron and the previous input neuron connected with the output neuron.
14. The neural network operation module of claim 8, wherein the mapping unit includes: an input data caching unit configured to cache the first input data, wherein the first input data includes at least one weight, and the absolute value of each of the at least one weight is greater than the second threshold, a connection caching unit configured to cache the connection data of the weight, and a fourth sparse processing unit configured to set the weight between the input neuron and the output neuron that are not connected with each other to 0 to obtain processed first input data, wherein the processed first input data includes the at least one weight and the weight whose value is 0.
15. The neural network operation module of claim 12, wherein before processing the first input data, the mapping unit is further configured to: group the at least one input neuron to obtain M groups of the input neurons, wherein the M is an integer greater than or equal to 1, determine whether each group of the input neurons in the M groups of the input neurons satisfies a first preset condition, wherein the first preset condition includes that the count of the input neuron whose absolute value is smaller than or equal to the third threshold in a group of the input neurons is smaller than or equal to the fourth threshold, when any group of the input neurons in the M groups of the input neurons does not satisfy the first preset condition, delete the group of the input neurons, group the at least one weight to obtain N groups of the weights, wherein the N is an integer greater than or equal to 1, determine whether each group of the weights in the N groups of the weights satisfies a second preset condition, wherein the second preset condition includes that the count of the weight whose absolute value is smaller than or equal to the fifth threshold in a group of the weights is smaller than or equal to the sixth threshold, and when any group of the weights in the N groups of the weights does not satisfy the second preset condition, delete the group of the weights.
16. A neural network operation method, comprising processing input data to obtain processed input data; obtaining a neural operation instruction and decoding the neural operation instruction into a microinstruction; and performing an artificial neural network on the processed input data according to the microinstruction to obtain an operation result.
17. The method of claim 16, wherein the input data includes at least one input neuron and/or a weight, before processing the input data, the method further includes: grouping the at least one input neuron to obtain M groups of the input neurons, wherein the M is an integer greater than or equal to 1, determining whether each group of the input neurons in the M groups of the input neurons satisfies a first preset condition, wherein the first preset condition includes that the count of the input neuron whose absolute value is smaller than or equal to the third threshold in a group of the input neurons is smaller than or equal to the fourth threshold, when any group of the input neurons in the M groups of the input neurons does not satisfy the first preset condition, deleting the group of the input neurons, grouping the at least one weight to obtain N groups of the weights, wherein the N is an integer greater than or equal to 1, determining whether each group of the weights in the N groups of the weights satisfies a second preset condition, wherein the second preset condition includes that the count of the weight whose absolute value is smaller than or equal to the fifth threshold in a group of the weights is smaller than or equal to the sixth threshold, and when any group of the weights in the N groups of the weights does not satisfy the second preset condition, deleting the group of the weights.
18. The method of claim 16, wherein the input data includes the first input data and the second input data, and the processed input data includes the processed first input data and the processed second input data, the processing the input data to obtain the processed input data includes: processing the second input data to obtain the first connection data and the processed second output data, processing the first input data according to the first connection data to obtain the processed second input data, and when the first input data is the input neuron and the second input data is the weight, the first connection data is the connection data of the weight, when the first input data is the weight and the second input data is the input neuron, the first connection data is the connection data of the input neuron.
19. The method of claim 16, wherein the input data includes the input neuron and the weight, and the processed input data includes the processed input neuron and the processed weight, and the processing input data to obtain the processed input data includes: obtaining the connection data of the input neuron and the connection data of the weight according to the input neuron and the weight, processing the connection data of the input neuron and the connection data of the weight to obtain the second connection data, and processing the input neuron and the weight according to the second connection data to obtain the processed input neuron and the processed weight.
20. The neural network operation module of claim 19, wherein when the connection data of the input neuron and the connection data of the weight are represented in the form of direct index, the processing the connection data of the input neuron and the connection data of the weight to obtain the second connection data includes: performing an AND operation on the connection data of the input neuron and the connection data of the weight to obtain the second connection data, wherein the processing the connection data of the input neuron and the connection data of the weight to obtain the second connection data includes: when the connection data of the input neuron is represented in the form of direct index and the connection data of the weight is represented in the form of stride index, converting the connection data of the weight into the connection data represented in the form of direct index, when the connection data of the weight is represented in the form of direct index and the connection data of the input neuron is represented in the form of stride index, converting the connection data of the input neuron into the connection data represented in the form of direct index, and performing the and operation on the connection data of the input neuron and the connection data of the weight to obtain the second connection data, wherein when both the connection data of the input neuron and the connection data of the weight are represented in the form of stride, and the connection data of the weight and a string of the connection data of the input neuron are stored in an order of physical address from low to high, the processing the connection data of the input neuron and the connection data of the weight to obtain the second connection data includes: accumulating each element in the string of the connection data of the input data and an element that is stored in a physical address lower than the physical address in which the each element is stored to obtain new elements, wherein the new elements compose third connection data, similarly, performing the same operation on a string of the connection data of the weight to obtain fourth connection data, selecting the same elements from the string of the third connection data and the string of the fourth connection data, and sorting the elements in an order of element values from small to large to form a new string, and performing a subtraction on each element in the new string and an element (adjacent to the element) whose value is smaller than the value of the element to obtain new elements, wherein the new elements compose the second connection data.
21. The method of claim 20, when the strings representing the connection data of the weight and the connection data of the input neuron are stored in an order of physical address from low to high, the processing the connection data of the input neuron and the connection data of the weight to obtain the second connection data includes: when the connection data of the input neuron is represented in the form of stride index and the connection data of the weight is represented in the form of direct index, converting the connection data of the weight into the connection data represented in the form of stride index, when the connection data of the weight is represented in the form of stride index and the connection data of the input neuron is represented in the form of direct index, converting the connection data of the input neuron into the connection data represented in the form of stride index, accumulating each element in the string of the connection data of the input data and an element that is stored in a physical address lower than the physical address in which the each element is stored to obtain new elements, wherein the new elements compose the third connection data, similarly, performing the same operation on a string of the second connection data to obtain the fourth connection data, selecting the same elements from the string of the third connection data and the string of the fourth connection data, and sorting the elements in an order of element values from small to large to form a new string, and performing a subtraction on each element in the new string and an element (adjacent to the element) whose value is smaller than the value of the element to obtain new elements, wherein the new elements compose the second connection data.
22. The method of claim 16, wherein the processing the input data to obtain the processed input data includes: when the input data includes the input neuron and the connection data of the input neuron, processing the input neuron according to the connection data of the input neuron to obtain the processed input neuron, and when the input data includes the weight and the connection data of the weight, processing the weight according to the connection data of the weight to obtain the processed weight.
23. The method of claim 20, wherein the connection data of the input neuron and the connection data of the weight being represented in the form of direct index or stride index includes: when the connection data of the input neuron is represented in the form of direct index, the connection data is a string composed of 0 and 1, where 0 indicates that the absolute value of the input neuron is smaller than or equal to a first threshold and 1 indicates that the absolute value of the input neuron is greater than the first threshold, when the connection data of the input neuron is represented in the form of stride index, the connection data is a string composed of values of distance between the input neuron whose absolute value is greater than the first threshold and the previous input neuron whose absolute value is greater than the first threshold, when the connection data of the weight is represented in the form of direct index, the connection data is a string composed of 0 and 1, where 0 indicates that the absolute value of the weight is smaller than or equal to the second threshold, which means that the input neuron corresponding to the weight is not connected with the output neuron of the weight, and 1 indicates that the absolute value of the weight is greater than the second threshold, which means that the input neuron corresponding to the weight is connected with the output neuron of the weight, the connection data of the weight represented in the form of direct index may have two orders of representation: a string of 0 and 1 composed of the connection state between each output neuron and all input neurons, or a string of 0 and 1 composed of the connection state between each input neuron and all output neurons, and when the connection data of the weight is represented in the form of stride index, the connection data is a string of values of distance between the input neuron connected with an output neuron and the previous input neuron connected with the output neuron.
</claims>
</document>
