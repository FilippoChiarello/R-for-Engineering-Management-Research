<document>

<filing_date>
2018-12-10
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-10
</priority_date>

<ipc_classes>
G06N3/08
</ipc_classes>

<assignee>
GOVERNMENT OF THE UNITED STATES AS REPRESETNED BY THE SECRETARY OF THE AIR FORCE
</assignee>

<inventors>
ROLLER, COLLEN
</inventors>

<docdb_family_id>
70970184
</docdb_family_id>

<title>
SEGMENT VECTORS
</title>

<abstract>
A neural network system includes one or more computers including a memory to store a set of documents having textual elements; and a processor to partition the set of documents into sentences and paragraphs; create a segment vector space model representative of the sentences and paragraphs; identify textual classifiers from the segment vector space models; and utilize the textual classifiers for natural language processing of the set of documents. The processor may partition the set of documents into words and sentences. The processor may create the segment vector space model representative of sentences, paragraphs, and words, and documents.
</abstract>

<claims>
1. A neural network system comprising one or more computers comprising: a memory to store a set of documents comprising textual elements; and a processor to: partition the set of documents into sentences and paragraphs; create a segment vector space model representative of the sentences and paragraphs; identify textual classifiers from the segment vector space model; and utilize the textual classifiers for natural language processing of the set of documents.
2. The neural network system of claim 1, wherein the processor is to partition the set of documents into words and sentences.
3. The neural network system of claim 1, wherein the processor is to create the segment vector space model representative of sentences, paragraphs, and words.
4. The neural network system of claim 1, wherein the segment vector space model is to reduce an amount of processing time used by a computer to perform the natural language processing by using the partitioning of the set of documents into sentences and paragraphs to identify the textual classifiers to create document embeddings without increasing an amount of training data used by the computer to perform text classification of the set of documents.
5. The neural network system of claim 1, wherein the segment vector space model is to reduce an amount of storage space used by the memory to store training data used to perform the natural language processing of the set of documents by using the partitioning of the set of documents into sentences and paragraphs to identify the textual classifiers to create document embeddings without increasing an amount of the training data used by the computer to perform text classification of the set of documents.
6. A machine-readable storage medium comprising computer-executable instructions that when executed cause a processor of a computer to: contextually map each document in a set of documents to a unique first vector, wherein the first vector is a graphical vector representation of a document; contextually map each paragraph in the set of documents to a unique second vector, wherein the second vector is a graphical vector representation of a paragraph; contextually map each sentence in the set of documents to a unique third vector, wherein the third vector is a graphical vector representation of a sentence; form a computational matrix that combines the first vector, the second vector, and the third vector; and train a machine learning process with the computational matrix to reduce an amount of computer processing resources used to identify semantic and contextual patterns connecting the set of documents.
7. The machine-readable storage medium of claim 6, wherein the instructions, when executed, further cause the processor to contextually map each document in the set of documents as a column in the computational matrix.
8. The machine-readable storage medium of claim 6, wherein the instructions, when executed, further cause the processor to contextually map each paragraph in the set of documents as a column in the computational matrix.
9. The machine-readable storage medium of claim 6, wherein the instructions, when executed, further cause the processor to contextually map each sentence in the set of documents as a column in the computational matrix.
10. The machine-readable storage medium of claim 6, wherein the instructions, when executed, further cause the processor to contextually map each word in the set of documents to a unique fourth vector, wherein the fourth vector is a graphical vector representation of a word.
11. The machine-readable storage medium of claim 10, wherein the instructions, when executed, further cause the processor to contextually map each word in the set of documents as a column in the computational matrix.
12. The machine-readable storage medium of claim 10, wherein the instructions, when executed, further cause the processor to combine the first vector, the second vector, the third vector, and the fourth vector into the computational matrix.
13. The machine-readable storage medium of claim 6, wherein the instructions, when executed, further cause the processor to calculate an average of the first vector, the second vector, and the third vector to represent a document embedding of the set of documents to train the machine learning process.
14. The machine-readable storage medium of claim 10, wherein the instructions, when executed, further cause the processor to calculate an average of the first vector, the second vector, the third vector, and the fourth vector to represent a document embedding of the set of documents to train the machine learning process.
15. A method of training a neural network, the method comprising: constructing a pre-training sequence of the neural network by: providing a set of documents comprising textual elements; defining in-document syntactical elements to partition the set of documents into sentence, paragraph, and document-level segment vector space models; and merging the sentence, paragraph, and document-level segment vector space models into a single vector space model; inputting the pre-training sequence into a natural language processing training process for training the neural network to identify related text in the set of documents.
16. The method of claim 15, wherein the neural network comprises a machine learning system comprising any of logic regression, support vector machines, and K-means processing.
17. The method of claim 15, further comprising defining in-document syntactical elements to partition the set of documents into word-level segment vector space models.
18. The method of claim 17, further comprising merging the word-level segment vector space models with the sentence, paragraph, and document-level segment vector space models into the single vector space model.
19. The method of claim 15, wherein inputting the pre-training sequence into the natural language processing training process reduces an amount of computational processing resources used by a computer to define the syntactical elements in the set of documents.
20. The method of claim 15, wherein the natural language processing training process comprises text classification and sentiment analysis of the set of documents.
</claims>
</document>
