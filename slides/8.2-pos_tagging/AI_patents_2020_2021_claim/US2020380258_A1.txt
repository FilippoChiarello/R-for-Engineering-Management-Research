<document>

<filing_date>
2019-05-31
</filing_date>

<publication_date>
2020-12-03
</publication_date>

<priority_date>
2019-05-31
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N20/00
</ipc_classes>

<assignee>
ROBERT BOSCH
</assignee>

<inventors>
KIM, JI EUN
LIN, WAN-YI
YU, LIXIU
</inventors>

<docdb_family_id>
70738412
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR INTEGRATING MACHINE LEARNING AND CROWD-SOURCED DATA ANNOTATION
</title>

<abstract>
A data annotation system for a machine-learning system includes a computing system configured to execute a machine-learning algorithm for generating data annotations of input data. The computing system is further configured to execute an interface for communicating results and predictions of the machine-learning algorithm to non-expert workers for review. The interface communicates with the non-expert worker using visualization and natural language to elicit feedback to improve performance of the machine-learning algorithm.
</abstract>

<claims>
1. A data annotation system comprising: a computing system programmed to execute a machine-learning algorithm that is programmed to identify a feature as being a predetermined feature and a corresponding confidence level from an input dataset, and, responsive to identifying the feature with the corresponding confidence level exceeding a threshold followed by a reduction in the corresponding confidence level to less than a low-confidence threshold, execute a crowd worker interface that is programmed to generate an interactive task configured to display the input dataset and the feature identified by the machine-learning algorithm and receive feedback from a crowd worker to identify a reason for the reduction.
2. The data annotation system of claim 1, wherein the crowd worker interface is further programmed to cause a text dialog to be displayed on a display screen, wherein the text dialog includes instructions to guide the crowd worker in completing the interactive task.
3. The data annotation system of claim 1, wherein the crowd worker interface is further programmed to receive the feedback from the crowd worker as data corresponding to elements drawn on a display screen.
4. The data annotation system of claim 1, wherein the crowd worker interface is further programmed to receive the feedback from the crowd worker as a text annotation of an on-screen object entered on a display screen.
5. The data annotation system of claim 1, wherein the crowd worker interface is further programmed to cause, responsive to the input dataset corresponding to the reduction being displayed on a display screen, a dialog element to be displayed on the display screen that alerts the crowd worker to the reduction.
6. The data annotation system of claim 1, wherein the crowd worker interface is further programmed to cause a dialog element to be displayed on a display screen that instructs the crowd worker to identify features for which a similar reduction in confidence level is expected to occur.
7. The data annotation system of claim 1, wherein the crowd worker interface is further programmed to convert between machine-learning algorithm representations to visual representations suitable for human understanding.
8. The data annotation system of claim 1, wherein the input dataset is a video segment comprised of a plurality of image frames.
9. The data annotation system of claim 8, wherein the computing system is further programmed to execute the crowd worker interface responsive to the input dataset being randomly selected for monitoring.
10. A method comprising: identifying, by a machine-learning algorithm, a feature as being a predetermined feature and a corresponding confidence level from an input dataset; and generating, responsive to identifying the feature with a confidence level exceeding a threshold followed by a reduction in the confidence level to less than a low-confidence threshold, an interactive task for crowd sourcing to display the input dataset and the feature identified by the machine-learning algorithm on a display screen and receive feedback from a crowd worker to identify a reason for the reduction.
11. The method of claim 10 further comprising causing a text dialog that includes instructions to guide the crowd worker in completing the interactive task to be displayed on the display screen.
12. The method of claim 10 further comprising causing, responsive to the input dataset corresponding to the reduction being displayed on the display screen, a dialog element to be displayed on the display screen that alerts the crowd worker to the reduction.
13. The method of claim 10 further comprising causing a dialog element to be displayed on the display screen that instructs the crowd worker to identify features for which a similar reduction in confidence level is expected to occur.
14. The method of claim 10 further comprising updating a dataset for the machine-learning algorithm with the feedback received from the crowd worker.
15. The method of claim 10 further comprising generating, responsive to input dataset being randomly selected for monitoring, the interactive task for crowd sourcing to display the input dataset and features identified by the machine-learning algorithm on a display screen and receive feedback from a crowd worker to identify inaccurate feature identification.
16. The method of claim 10 further comprising causing a dialog to be displayed that includes operational details of the machine-learning algorithm to aid the crowd worker in understanding the machine-learning algorithm.
17. A data annotation system comprising: a computing system programmed to execute a machine-learning algorithm that is programmed to identify a feature as a predetermined feature from an input dataset, and, responsive to a presence of conditions indicative of the feature being inaccurately identified, execute a crowd worker interface that is programmed to (i) generate an interactive task for completion by a crowd worker, and (ii), upon the interactive task being initiated by the crowd worker, display the feature identified by the machine-learning algorithm as the predetermined feature overlaid on the input dataset and receive feedback from the crowd worker to identify a reason for the feature being inaccurately identified.
18. The data annotation system of claim 17, wherein the crowd worker interface is further programmed to visually communicate predictions of the machine-learning algorithm and to identify areas of concern in natural language.
19. The data annotation system of claim 17, wherein the machine-learning algorithm is further programmed to generate a confidence level corresponding to features identified as the predetermined feature, and the conditions indicative of the predetermined feature being inaccurately identified includes the confidence level being less than a low-confidence threshold.
20. The data annotation system of claim 17, wherein the machine-learning algorithm is further programmed to generate a confidence level corresponding to features identified as the predetermined feature, and the conditions indicative of the predetermined feature being inaccurately identified includes the confidence level being greater than a predetermined threshold followed by a reduction in the confidence level to being less than a low-confidence threshold.
</claims>
</document>
