<document>

<filing_date>
2019-04-30
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2019-04-30
</priority_date>

<ipc_classes>
G10L21/013
</ipc_classes>

<assignee>
AT&T INTELLECTUAL PROPERTY I (AMERICAN TELEPHONE AND TELEGRAPH COMPANY INTELLECTUAL PROPERTY I)
</assignee>

<inventors>
ZAVESKY, ERIC
DECUIR, JASON
GRATZ, ROBERT
</inventors>

<docdb_family_id>
73016087
</docdb_family_id>

<title>
METHOD FOR EMBEDDING AND EXECUTING AUDIO SEMANTICS
</title>

<abstract>
Aspects of the subject disclosure may include, for example, a device that includes a processing system having a processor and a memory that stores executable instructions that, when executed by the processing system, facilitate performance of operations, where the operations include determining parameters for adapting audio in the content to the device, wherein the device renders the content, and wherein the parameters are based on semantic metadata embedded in the content, adapting the audio in the content based on the parameters, and rendering the content, as adapted by the parameters, to represent a semantic in the semantic metadata. Other embodiments are disclosed.
</abstract>

<claims>
1. A device, comprising: a processing system including a processor; and a memory that stores executable instructions that, when executed by the processing system, facilitate performance of operations, the operations comprising: determining parameters for adapting audio in content to the device, wherein the device renders the content, and wherein the parameters are based on semantic metadata embedded in the content; adapting the audio in the content based on the parameters; and rendering the content, as adapted by the parameters, to represent a semantic in the semantic metadata.
2. The device of claim 1, wherein the parameters represent the semantic in a game context, environment context, or a combination thereof.
3. The device of claim 1, wherein the parameters are determined from external device models that are specific to the device.
4. The device of claim 1, wherein the operations further comprise receiving feedback from a user, wherein the feedback rates the rendering.
5. The device of claim 1, wherein the operations further comprise receiving a preference for a new adaptation of the content from a user.
6. The device of claim 1, wherein the processing system comprises a plurality of processors operating in a distributed processing environment.
7. The device of claim 1, wherein the adapting modifies the audio according to pitch, cadence, tempo, key, spectral signature, or a combination thereof.
8. The device of claim 1, wherein the adapting manipulates the audio using audio processing algorithms.
9. The device of claim 1, wherein the adapting modifies the audio according to performance semantics.
10. The device of claim 1, wherein the adapting modifies the audio to accommodate available resources on the device.
11. A machine-readable medium, comprising executable instructions that, when executed by a processing system including a processor, facilitate performance of operations, the operations comprising: determining instructions for manipulating audio in content, wherein the instructions are based on semantic metadata embedded in the content; modifying the audio in the content based on the instructions to represent a semantic in the semantic metadata, thereby creating modified content; and sending the modified content to a device for rendering.
12. The machine-readable medium of claim 11, wherein the processing system comprises a plurality of processors operating in a distributed processing environment.
13. The machine-readable medium of claim 11, wherein the instructions are determined from external device models that are specific to the device.
14. The machine-readable medium of claim 11, wherein the operations further comprise receiving feedback from a user, wherein the feedback rates the rendering.
15. The machine-readable medium of claim 11, wherein the operations further comprise receiving a preference for a new adaptation of the content from a user.
16. The machine-readable medium of claim 11, wherein the modifying modifies the audio according to pitch, cadence, tempo, key, spectral signature, or a combination thereof.
17. A method, comprising: determining, by a processing system including a processor, instructions for manipulating audio in content, wherein the instructions are determined based on semantic metadata embedded in the content; modifying, by the processing system, the audio in the content based on the instructions; and rendering, by the processing system, the content, wherein the audio modified by the instructions represents a semantic in the semantic metadata.
18. The method of claim 17, wherein the audio is modified in a pitch, cadence, tempo, key, spectral signature, or a combination thereof.
19. The method of claim 17, wherein the modifying manipulates the audio using audio processing algorithms.
20. The method of claim 17, wherein the modifying manipulates the audio according to performance semantics.
</claims>
</document>
