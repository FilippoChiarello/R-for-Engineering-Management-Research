<document>

<filing_date>
2019-11-22
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-04
</priority_date>

<ipc_classes>
G06F21/60,G10L15/06,G10L15/22,G10L15/26,G10L15/28,H04M3/42
</ipc_classes>

<assignee>
SORENSON IP HOLDINGS
</assignee>

<inventors>
THOMSON, DAVID
ADAMS, JADIE
</inventors>

<docdb_family_id>
69528938
</docdb_family_id>

<title>
TRAINING OF SPEECH RECOGNITION SYSTEMS
</title>

<abstract>
A method may include obtaining first audio data of a first communication session between a first and second device and during the first communication session, obtaining a first text string that is a transcription of the first audio data and training a model of an automatic speech recognition system using the first text string and the first audio data. The method may further include in response to completion of the training, deleting the first audio data and the first text string and after deleting the first audio data and the first text string, obtaining second audio data of a second communication session between a third and fourth device and during the second communication session obtaining a second text string that is a transcription of the second audio data and further training the model of the automatic speech recognition system using the second text string and the second audio data.
</abstract>

<claims>
CLAIMS
1. A method comprising:
obtaining first audio data of a first communication session between a first device of a first user and a second device of a second user, the first communication session configured for verbal communication;
obtaining, during the first communication session, a first text string that is a transcription of the first audio data;
training, during the first communication session, a model of an automatic speech recognition system using the first text string and the first audio data;
in response to completion of the training of the model using the first text string and the first audio data, deleting the first audio data and the first text string;
after training the model using the first text string and the first audio data, obtaining second audio data of a second communication session between a third device of a third user and a fourth device of a fourth user;
generating, during the second communication session, a transcription of the second audio data by applying the model trained using the first text string and the first audio data; and
providing the transcription of the second audio data to the fourth device for presentation during the second communication session.
2. The method of claim 1, wherein the training of the model of the automatic speech recognition system using the first text string and the first audio data completes after the first communication session.
3. The method of claim 1, wherein the first audio data and the first text string are deleted during the first communication session.
4. The method of any proceeding claim, further comprising:
training, during the second communication session using a second text string of the transcription of the second audio data and the second audio data, a second model used by automatic speech recognition technology; and
in response to completion of the training of the second model using the second text string and the second audio data, deleting the second audio data and the second text string.
5. The method of any proceeding claim, wherein the first text string is generated using automatic speech recognition technology.
6. The method of claim 5, wherein the automatic speech recognition technology generates the first text string using a revoicing of the first audio data.
7. The method of any proceeding claim, wherein the first text string is generated from one or more words of a second text string and one or more words of a third text string, the second text string and the third text string generated by automatic speech recognition technology.
8. The method of any proceeding claim, further comprising providing the transcription of the first audio data to the second device for presentation by the second device during the first communication session.
9. At least one non-transitory computer-readable media configured to store one or more instructions that in response to being executed by at least one computing system cause performance of the method of any proceeding claim.
10. A system comprising:
one or more non-transitory computer readable media configured to store one or more instructions; and
one or more processor communicatively coupled to the one or more non-transitory computer readable media, the one or more processors configured to execute the one or more instructions to cause or direct the system to perform operations, the operations comprising:
obtain first audio data of a first communication session between a first device of a first user and a second device of a second user, the first communication session configured for verbal communication;
obtain, during the first communication session, a first text string that is a transcription of the first audio data;
train, during the first communication session, a model of an automatic speech recognition system using the first text string and the first audio data;
in response to completion of the training of the model using the first text string and the first audio data, delete the first audio data and the first text string; after training the model using the first text string and the first audio data, obtain second audio data of a second communication session between a third device of a third user and a fourth device of a fourth user;
generate, during the second communication session, a transcription of the second audio data by applying the model trained using the first text string and the first audio data; and provide the transcription of the second audio data to the fourth device for presentation during the second communication session.
11. The system of claim 10, wherein the training of the model of the automatic speech recognition system using the first text string and the first audio data completes after the first communication session.
12. The system of claim 10, wherein the first audio data and the first text string are deleted during the first communication session.
13. The system of any of claims 10-12, wherein the first text string is generated using automatic speech recognition technology.
14. The system of any of claims 10-13, wherein the first text string is generated from one or more words of a second text string and one or more words of a third text string, the second text string and the third text string generated by automatic speech recognition technology.
15. The system of any of claims 10-14, wherein the operations further comprise provide the transcription of the first audio data to the second device for presentation by the second device during the first communication session.
</claims>
</document>
