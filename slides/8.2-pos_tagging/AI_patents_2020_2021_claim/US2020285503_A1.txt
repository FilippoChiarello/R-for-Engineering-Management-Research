<document>

<filing_date>
2019-03-10
</filing_date>

<publication_date>
2020-09-10
</publication_date>

<priority_date>
2019-03-10
</priority_date>

<ipc_classes>
G06F17/18,G06F9/455,G06N20/20
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
DOU, YIPING
KAMATH, TANMAYEE PRAKASH
RAMANATHAN CHANDRASEKHAR, ARUN
REMILLARD, CLAUDE
SCHNITZER, MARK STEVEN
SUBRAMANIAN, BALAN
SUNDARESAN, NEELAKANTAN
WEI, YIJIN
</inventors>

<docdb_family_id>
69740851
</docdb_family_id>

<title>
CLOUD RESOURCE MANAGEMENT USING MACHINE LEARNING
</title>

<abstract>
A cloud resource management system trains, through ensemble learning, multiple time series forecasting models to forecast a future idle time of a virtual machine operating on a cloud computing service. The models are trained on historical usage and metric data of the virtual machine. The metric data includes CPU usage, disk usage and network usage. A select one of the models having the best accuracy for a target virtual machine is used in a production run to predict when the virtual machine will be idle. At this time, the virtual machine may be automatically shutdown in order to reduce the expense associated with the continued operation of the virtual machine.
</abstract>

<claims>
1. A system, comprising: at least one processor and a memory; wherein the at least one processor is configured to: receive metric data of a virtual machine, the metric data including CPU usage of the virtual machine at equally-spaced time points over a first time period; train at least one time series forecasting model on the metric data for the first time period; apply the time series forecasting model to determine the CPU usage of the virtual machine at a time interval succeeding the first time period; and when the forecasted CPU usage is below a threshold, initiate actions to reduce resource consumption of the virtual machine.
2. The system of claim 1, wherein the metric data includes one or more of disk I/O usage and network I/O usage.
3. The system of claim 1, wherein the at least one processor is further configured to: apply ensemble learning to train a plurality of time series forecasting models on the metric data simultaneously.
4. The system of claim 3, wherein the plurality of time series forecasting models includes at least one of ARIMA, ETS, TBATS, or a decomposable time series forecasting model.
5. The system of claim 4, wherein the at least one processor is further configured to: select one of the plurality of time series forecasting models to forecast an idle time of the virtual machine based on the CPU usage of the virtual machine.
6. The system of claim 1, wherein the initiation of actions to reduce resource consumption of the virtual machine comprises shutting down the virtual machine.
7. The system of claim 1, wherein the at least one processor is further configured to: generate a cost savings estimate for the reduction of the resource consumption.
8. A method, comprising: obtaining a time series forecasting model trained to predict a future idle time of a virtual machine; receiving metric data during a production run of the virtual machine during a first time period; applying the time series forecasting model to the received metric data to forecast the future idle time of the virtual machine; and initiating measures to shut down the virtual machine during the idle time.
9. The method of claim 8, further comprising: determining the future idle time of the virtual machine based on monitoring CPU usage of the virtual machine at a time period immediately preceding the idle time.
10. The method of claim 9, wherein the future idle time of the virtual machine is based on monitoring disk I/O usage and network I/O usage.
11. The method of claim 8, wherein initiating measures to shut down the virtual machine include requesting permission from a user of the virtual machine to shutdown the virtual machine.
12. The method of claim 8, wherein the time series forecasting model is at least one of ARMIA, TBATS, ETS, or a decomposable time series model.
13. The method of claim 8, wherein the future idle time is based on CPU usage forecasted to be below an idle threshold for the virtual machine, the idle threshold based on historical metric data of the virtual machine.
14. The method of claim 8, wherein the metric data includes CPU usage, network I/O usage, and disk I/O usage obtained at equally-spaced time intervals.
15. The method of claim 8, wherein prior to initiating measures to shut down the virtual machine during the idle time, informing a user of the virtual machine of the forecasted idle time.
16. A device, comprising: at least one processor and a memory; wherein the memory includes instructions that when executed on the at least one processor performs actions that: forecasts a future idle time of a virtual machine executing on a computing device, the forecast achieved through use of a time series forecasting model trained on historical metric data and usage data of the virtual machine, the historical metric data including a time series of equally-spaced data points representing at least CPU usage of the virtual machine during a training period, the forecast based on an idle threshold for the virtual machine; and automatically shuts down the virtual machine at the future idle time.
17. The device of claim 16, wherein the memory includes further instructions that when executed on the at least one processor performs additional actions that: applies ensemble learning to train at least one time series forecasting model to predict when the CPU usage of the virtual machine will be below the idle threshold.
18. The device of claim 16, wherein the at least one time series forecasting model is based on a decomposable time series model, ARIMA, TBATS, or ETS.
19. The device of claim 16, wherein the historical metric data further includes disk I/O usage and network I/O usage.
20. The device of claim 16, wherein automatically shutting down the virtual machine is performed upon concurrence of a user of the virtual machine.
</claims>
</document>
