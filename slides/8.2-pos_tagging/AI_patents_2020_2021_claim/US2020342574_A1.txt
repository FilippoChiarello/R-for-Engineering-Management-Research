<document>

<filing_date>
2020-04-23
</filing_date>

<publication_date>
2020-10-29
</publication_date>

<priority_date>
2019-04-25
</priority_date>

<ipc_classes>
G01S17/89,G06N3/08,G06T5/00,G06T7/20
</ipc_classes>

<assignee>
ROBERT BOSCH
</assignee>

<inventors>
Meinke, Martin
</inventors>

<docdb_family_id>
72839516
</docdb_family_id>

<title>
Method for Generating Digital Image Pairs as Training Data for Neural Networks
</title>

<abstract>
A method for generating a digital image pair for training a neural network to correct noisy image components of noisy images includes determining an extent of object movements within an overlapping region of a stored first digital image and a stored second digital image of an environment of a mobile platform, and determining a respective acquired solid angle of the environment of the mobile platform of the first and second digital images. The method further includes generating the digital image pair from the first digital image and the second digital images, when the respective acquired solid angles of the environment of the first and the second digital image do not differ from one another by more than a defined difference, and the extent of the object movements within the overlapping region of the first and the second digital image is less than a defined value.
</abstract>

<claims>
1. A method for generating a digital image pair for training a neural network to correct noisy image components of noisy images, comprising: determining an extent of object movements within an overlapping region of a stored first digital image and a stored second digital image of an environment of a mobile platform; determining a respective acquired solid angle of the environment of the mobile platform of the stored first digital image and the stored second digital image; and generating the digital image pair from the stored first digital image and the stored second digital image when (i) the respective acquired solid angles of the environment of the store first digital image and the stored second digital image do not differ from one another by more than a defined difference, and (ii) the extent of the object movements within the overlapping region of the stored first digital image and the stored second digital image is less than a defined value.
2. The method according to claim 1, further comprising: determining the extent of the object movements within the overlapping region of the stored first digital image and the stored second digital image using data of an inertial navigation system of the mobile platform.
3. The method according to claim 1, further comprising: determining the respective acquired solid angle of the environment of the mobile platform of the stored first digital image and the stored second digital image using data of an inertial navigation system of the mobile platform.
4. The method according to claim 1, further comprising: ascertaining the extent of the object movement based on a signal of a radar sensor or an image analysis of an optical system or a tracking system.
5. The method according to claim 1, further comprising: determining a difference of the respective acquired solid angle of the environment of the mobile platform of the stored first digital image and the stored second digital image using data of at least one inertial sensor of the mobile platform.
6. The method according to claim 1, further comprising: generating the stored first digital image and the stored second digital image by a transformation of signals of a LIDAR system.
7. The method according to claim 1, further comprising: acquiring the stored first digital image and the stored second digital image based on image-generating systems of a plurality of at least partially automated mobile platforms.
8. A method for training a neural network to correct noisy image components of noisy images, comprising: generating a digital image pair by determining an extent of object movements within an overlapping region of a stored first digital image and a stored second digital image of an environment of a mobile platform, determining a respective acquired solid angle of the environment of the mobile platform of the stored first digital image and the stored second digital image, and generating the digital image pair from the stored first digital image and the stored second digital image when (i) the respective acquired solid angles of the environment of the stored first digital image and the stored second digital image do not differ from one another by more than a defined difference, and (ii) the extent of the object movements within the overlapping region of the stored first digital image and the stored second digital image is less than a defined value; and training the neural network to generate the stored second digital image of the digital image pair using the stored first digital image of the digital image pair as an input variable.
9. The method according to claim 8, further comprising: using the trained neural network for correcting noisy image components of noisy images by transferring a noisy image as an input variable to the trained neural network, and correcting the noisy image components in the image generated by the neural network.
10. The method according to claim 9, further comprising: representing the environment of the mobile platform based on images which have been acquired by image-generating systems from the environment of the mobile platform and the corrected noisy image components, wherein the mobile platform is at least partially automated.
11. The method according to claim 10, further comprising: using the representation of the environment to activate an at least partially automated vehicle and/or to transmit a depiction of the representation to a vehicle occupant.
12. The method according to claim 8, wherein a computer program product comprises commands which, upon the execution of the computer program product by a computer, causes the computer to execute the method.
13. The method according to claim 12, wherein the computer program product is stored on a machine-readable storage medium.
</claims>
</document>
