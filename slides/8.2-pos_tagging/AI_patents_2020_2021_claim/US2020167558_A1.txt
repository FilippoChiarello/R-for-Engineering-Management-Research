<document>

<filing_date>
2020-01-30
</filing_date>

<publication_date>
2020-05-28
</publication_date>

<priority_date>
2017-07-21
</priority_date>

<ipc_classes>
G06K9/00,G06K9/32,G06K9/34,G06K9/62,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
ASENTE, PAUL
YANG, XIAO
YUMER, MEHMET
</inventors>

<docdb_family_id>
65019110
</docdb_family_id>

<title>
SEMANTIC PAGE SEGMENTATION OF VECTOR GRAPHICS DOCUMENTS
</title>

<abstract>
Disclosed systems and methods categorize text regions of an electronic document into document object types based on a combination of semantic information and appearance information from the electronic document. A page segmentation application executing on a computing device provides a textual feature representation and a visual feature representation to a neural network. The application identifies a correspondence between a location of the set of pixels in the electronic document and a location of a particular document object type in an output page segmentation. The application further outputs a classification of the set of pixels as being the particular document object type based on the identified correspondence.
</abstract>

<claims>
1. A method for classifying text regions of an electronic document into document object types, the method comprising: providing, to a neural network executed by a processing device and to generate an output page segmentation of the electronic document, a textual feature representation that represents, in a vector space, a semantic meaning of textual content within an electronic document and a visual feature representation that represents an appearance of a portion of the electronic document that includes a set of pixels depicting the textual content; identifying, by the processing device, a correspondence between a location of the set of pixels in the electronic document and a location of a particular document object type in the output page segmentation; and outputting, by the processing device, a classification of the set of pixels as being the particular document object type based on the identified correspondence.
2. The method of claim 1, wherein the classification of the set of pixels represents a plurality of different document object types that comprises two or more of: a table object type, a paragraph object type, and a caption object type.
3. The method of claim 1, further comprising: identifying, by the processing device, training bounding boxes from rendering commands in a training document, each training bounding box identifying a respective object in the electronic document; and iteratively adjusting the neural network based on a consistency loss computed from training feature representations in a training document
4. The method of claim 3, wherein iteratively adjusting the neural network comprises: computing a value of the consistency loss, wherein the value of the consistency loss indicates that a first document region included in a training bounding box and a second document region included in the training bounding box are represented by different training feature representations; modifying the neural network such that a subsequent value of the consistency loss is decreased in a subsequent iteration; and ceasing iteration based on the consistency loss being minimized.
5. The method of claim 1, wherein the neural network is trained with a set of training documents, the method further comprising: receiving a human-generated sentence; receiving a human-generated section heading; receiving a human-generated list comprising elements from a common source; receiving a human-generated caption; and creating a training document by inserting at least one of a paragraph, a sentence, a section heading, or a caption into a human-generated unstructured vector graphics document.
6. The method of claim 1, further comprising generating the visual feature representation by applying a first portion of a neural network to the electronic document, wherein the output page segmentation is generated by applying a second portion of the neural network to the textual feature representation and the visual feature representation, wherein an output of the second portion of the neural network is a raw page segmentation, wherein generating the output page segmentation comprises transforming the raw page segmentation into the output page segmentation by performing operations comprising: identifying a first segmentation portion of the raw page segmentation that corresponds to the particular document object type and a second segmentation portion of the raw page segmentation that corresponds to a different document object type; identifying, from rendering commands in the electronic document, a common bounding box that includes locations in the electronic document corresponding to the first segmentation portion and the second segmentation portion; determining that the first segmentation portion is larger than the second segmentation portion; and modifying the raw page segmentation based on the first segmentation portion being larger than the second segmentation portion and the common bounding box having locations corresponding to the first and second segmentation portions, wherein modifying the raw page segmentation causes both the first segmentation portion and the second segmentation portion to correspond to the particular document object type.
7. The method of claim 6, the operations further comprising: identifying a third segmentation portion of the raw page segmentation that corresponds to the particular document object type or the different document object type; determining that the third segmentation portion corresponds to a third location in the electronic document that is outside the common bounding box; and modifying the raw page segmentation based on the third segmentation portion corresponding to the third location, wherein modifying the raw page segmentation causes the third segmentation portion to correspond to a background object type.
8. A system comprising: a non-transitory computer-readable medium storing computer-executable instructions for categorizing text regions of an electronic document into document object types; and a processor communicatively coupled to the non-transitory computer-readable medium for executing the computer-executable instructions, wherein executing the computer-executable instructions configures the processor to perform operations comprising: providing, to a neural network, a textual feature representation that represents, in a vector space, a semantic meaning of textual content within an electronic document and a visual feature representation that represents an appearance of a portion of the electronic document that includes a set of pixels depicting the textual content, thereby generating an output page segmentation of the electronic document; identifying, in the output page segmentation, a correspondence between a location of the set of pixels in the electronic document and a location of a particular document object type; and outputting a classification of the set of pixels as being the particular document object type based on the identified correspondence.
9. The system of claim 8, wherein the classification of the set of pixels represents a plurality of different document object types that comprises one or more of: a table object type, a paragraph object type, and a caption object type.
10. The system of claim 8, the operations further comprising: identifying training bounding boxes from rendering commands in a training document, each training bounding box identifying a respective object in the electronic document; and iteratively adjusting the neural network based on a consistency loss computed from training feature representations in a training document, wherein iteratively adjusting the neural network comprises: computing a value of the consistency loss, wherein the value of the consistency loss indicates that a first document region included in a training bounding box and a second document region included in the training bounding box are represented by different training feature representations; modifying the neural network such that a subsequent value of the consistency loss is decreased in a subsequent iteration; and ceasing iteration based on the consistency loss being minimized.
11. The system of claim 8, wherein the neural network is trained with a set of training documents, the operations further comprising: receiving a human-generated sentence; receiving a human-generated section heading; receiving a human-generated list comprising elements from a common source; receiving a human-generated caption; and creating a training document by inserting at least one of a paragraph, a sentence, a section heading, or a caption into a human-generated unstructured vector graphics document.
12. The system of claim 8, the operations further comprising generating the visual feature representation by applying a first portion of a neural network to the electronic document, wherein the output page segmentation is generated by applying a second portion of the neural network to the textual feature representation and the visual feature representation, wherein an output of the second portion of the neural network is a raw page segmentation.
13. The system of claim 12, wherein generating the output page segmentation comprises transforming the raw page segmentation into the output page segmentation by performing operations comprising: identifying a first segmentation portion of the raw page segmentation that corresponds to the particular document object type and a second segmentation portion of the raw page segmentation that corresponds to a different document object type; identifying, from rendering commands in the electronic document, a common bounding box that includes locations in the electronic document corresponding to the first segmentation portion and the second segmentation portion; determining that the first segmentation portion is larger than the second segmentation portion; and modifying the raw page segmentation based on the first segmentation portion being larger than the second segmentation portion and the common bounding box having locations corresponding to the first and second segmentation portions, wherein modifying the raw page segmentation causes both the first segmentation portion and the second segmentation portion to correspond to the particular document object type.
14. The system of claim 13, the operations further comprising: identifying a third segmentation portion of the raw page segmentation that corresponds to the particular document object type or the different document object type; determining that the third segmentation portion corresponds to a third location in the electronic document that is outside the common bounding box; and modifying the raw page segmentation based on the third segmentation portion corresponding to the third location, wherein modifying the raw page segmentation causes the third segmentation portion to correspond to a background object type.
15. The system of claim 8, wherein the neural network comprises: a set of encoder blocks followed by a set of decoder blocks trained to output the visual feature representation, wherein the set of encoder blocks and the set of decoder blocks are included in a first portion of the neural network; an additional decoder block that receives, as a first input, the visual feature representation outputted from the set of decoder blocks, wherein the additional decoder block is included in a second portion of the neural network; and a bridge connection that provides the textual feature representation from a text map generator to the additional decoder block as a second input.
16. A non-transitory computer-readable storage medium storing computer-executable program instructions, wherein when executed by a processing device, the computer-executable program instructions cause the processing device to perform operations comprising: a step for providing, to a neural network to generate an output page segmentation of an electronic document, a textual feature representation that represents, in a vector space, a semantic meaning of textual content within an electronic document and a visual feature representation that represents an appearance of a portion of the electronic document that includes a set of pixels depicting the textual content; a step for receiving, from the neural network, a correspondence between a location of the set of pixels in the electronic document and a location of a particular document object type in the output page segmentation; and a step for outputting a classification of the set of pixels to a user device.
17. The non-transitory computer-readable storage medium of claim 16, wherein the classification of the set of pixels represents a plurality of different document object types that comprises two or more of: a table object type, a paragraph object type, and a caption object type.
18. The non-transitory computer-readable storage medium of claim 16, the operations further comprising: a step for identifying training bounding boxes from rendering commands in a training document, each training bounding box identifying a respective object in the electronic document; and a step for iteratively adjusting the neural network based on a consistency loss computed from training feature representations in a training document, wherein iteratively adjusting the neural network comprises: a step for computing a value of the consistency loss; a step for modifying the neural network such that a subsequent value of the consistency loss is decreased in a subsequent iteration; and a step for ceasing iteration when the consistency loss is below a threshold.
19. The non-transitory computer-readable storage medium of claim 16, wherein the neural network is trained with a set of training documents, the operations further comprising a step for creating a training document by inserting at least one of a paragraph, a sentence, a section heading, or a caption into a human-generated unstructured vector graphics document.
20. The non-transitory computer-readable storage medium of claim 16, the operations further comprising generating the visual feature representation by applying a first portion of a neural network to the electronic document, wherein the output page segmentation is generated by applying a second portion of the neural network to the textual feature representation and the visual feature representation, wherein an output of the second portion of the neural network is a raw page segmentation.
</claims>
</document>
