<document>

<filing_date>
2019-07-31
</filing_date>

<publication_date>
2020-02-06
</publication_date>

<priority_date>
2018-07-31
</priority_date>

<ipc_classes>
G06N3/08,G06T5/00,G06T5/20,G06T7/00
</ipc_classes>

<assignee>
GE PRECISION HEALTHCARE
</assignee>

<inventors>
WOLLENWEBER, SCOTT DAVID
FAN JIAHUA
JIN, XIAO
</inventors>

<docdb_family_id>
69229728
</docdb_family_id>

<title>
DEEP LEARNING-BASED PET SCATTER ESTIMATION SYSTEMS AND METHODS USING AN INCEPTION NEURAL NETWORK MODEL
</title>

<abstract>
Systems, apparatus, methods, and computer-readable storage media to estimate scatter in an image are disclosed. An example apparatus includes a network generator to generate and train an inception neural network using first and second input to deploy an inception neural network model to process image data when first and second outputs of the inception neural network converge, the first input based on a raw sinogram of a first image and the second input based on an attenuation-corrected sinogram of the first image, the inception neural network including a first filter of a first size and a second filter of a second size in a layer to process the first input and/or the second input to generate an estimate of scatter in the first image. The example apparatus also includes an image processor to apply the estimate of scatter to a second image to generate a processed image.
</abstract>

<claims>
1. An apparatus comprising: a network generator to generate and train an inception neural network using a first input and a second input to deploy an inception neural network model to process image data when a first output of the inception neural network from the first input converges with a second output of the inception neural network from the second input, the first input based on a raw sinogram of a first image and the second input based on an attenuation-corrected sinogram of the first image, the inception neural network including a first filter of a first size and a second filter of a second size in a concatenation layer to process at least one of the first input or the second input to generate an estimate of scatter in the first image; and an image processor to apply the estimate of scatter to a second image to generate a processed image and to output the processed image for at least one of storage or display.
2. The apparatus of claim 1, wherein the first image is a positron emission tomography (PET) image.
3. The apparatus of claim 1, wherein the network generator is to determine an attenuation correction factor using a ratio between the first input and the second input.
4. The apparatus of claim 3, wherein the second input includes the attenuation correction factor.
5. The apparatus of claim 1, wherein the first filter includes a 1×n filter and the second filter includes an n×1 filter, the first filter and the second filter combined to implement an n×n convolution filter.
6. The apparatus of claim 1, wherein the first input includes a simulated scatter sinogram.
7. The apparatus of claim 1, where the scatter includes at least one of single scatter, multiple scatter, or out of axial field of view scatter.
8. The apparatus of claim 1, wherein the inception neural network is a multi-scale network including a plurality of blocks of layers of filters, wherein each block of filters is concatenated and a final filter concatenation layer is an input into a fully connected layer that is an input into an activation layer that is an input into an output layer to generate the estimate of scatter.
9. At least one computer-readable storage medium comprising instructions that, when executed, cause at least one processor to: train an inception neural network using a first input and a second input formed from a first image, the first input based on a raw sinogram of the first image and the second input based on an attenuation-corrected sinogram of the first image, the inception neural network including a first filter of a first size and a second filter of a second size in a concatenation layer to process at least one of the first input or the second input to generate an estimate of scatter in the first image; test the inception neural network to determine convergence between a first output of the inception neural network from the first input and a second output of the inception neural network from the second input; and deploy a model of the inception neural network to process a second image to estimate image scattering in the second image for removal of the estimated image scattering from the second image to generate a processed image.
10. The at least one computer-readable storage medium of claim 9, wherein the first image is a positron emission tomography (PET) image.
11. The at least one computer-readable storage medium of claim 9, wherein the instructions, when executed, cause the at least one processor to determine an attenuation correction factor using a ratio between the first input and the second input.
12. The at least one computer-readable storage medium of claim 11, wherein the second input includes the attenuation correction factor.
13. The at least one computer-readable storage medium of claim 9, wherein the first filter includes a 1×n filter and the second filter includes an n×1 filter, the first filter and the second filter combined to implement an n×n convolution filter.
14. The at least one computer-readable storage medium of claim 9, where the scatter includes at least one of single scatter, multiple scatter, or out of axial field of view scatter.
15. The at least one computer-readable storage medium of claim 9, wherein the inception neural network is a multi-scale network including a plurality of blocks of layers of filters, wherein each block of filters is concatenated and a final filter concatenation layer is an input into a fully connected layer that is an input into an activation layer that is an input into an output layer to generate the estimate of scatter.
16. A method of processing an image to estimate and remove image scatter, the method comprising: training an inception neural network using a first input and a second input formed from a first image, the first input based on a raw sinogram of the first image and the second input based on an attenuation-corrected sinogram of the first image, the inception neural network including a first filter of a first size and a second filter of a second size in a concatenation layer to process at least one of the first input or the second input to generate an estimate of scatter in the first image; testing the inception neural network to determine convergence between a first output of the inception neural network from the first input and a second output of the inception neural network from the second input; and deploying a model of the inception neural network to process a second image to estimate image scattering in the second image for removal of the estimated image scattering from the second image to generate a processed image.
17. The method of claim 16, wherein the first image is a positron emission tomography (PET) image.
18. The method of claim 16, further including determining an attenuation correction factor using a ratio between the first input and the second input and incorporating the attenuation correction factor into the second input.
19. The method of claim 16, wherein the first filter includes a 1×n filter and the second filter includes an n×1 filter, the first filter and the second filter combined to implement an n×n convolution filter.
20. The method of claim 16, wherein the inception neural network is a multi-scale network including a plurality of blocks of layers of filters, wherein each block of filters is concatenated and a final filter concatenation layer is an input into a fully connected layer that is an input into an activation layer that is an input into an output layer to generate the estimate of scatter.
</claims>
</document>
