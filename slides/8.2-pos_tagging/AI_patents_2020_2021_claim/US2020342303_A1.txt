<document>

<filing_date>
2019-04-24
</filing_date>

<publication_date>
2020-10-29
</publication_date>

<priority_date>
2019-04-24
</priority_date>

<ipc_classes>
B60W50/14,G06F9/54,G06N3/08,H04N7/18
</ipc_classes>

<assignee>
TOYOTA RESEARCH INSTITUTE
</assignee>

<inventors>
STENT, SIMON A.I.
</inventors>

<docdb_family_id>
72917271
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR SIMULATING INSTANTANEOUS ATTENTIVE HUMAN RESPONSES TO ROAD HAZARDS FOR IMPROVED EARLY WARNING SYSTEMS AND FLEET DATA HARVESTING
</title>

<abstract>
A system for predicting a hazardous event from road-scene data includes an electronic control unit configured to implement a neural network and a camera communicatively coupled to the electronic control unit, wherein the camera generates the road-scene data. The electronic control unit is configured to receive the road-scene data from the camera, and predict, with the neural network, an occurrence of the hazardous event within the road-scene data from the camera.
</abstract>

<claims>
1. A method for predicting a hazardous event from road-scene data, the method comprising: providing a neural network; inputting the road-scene data into the neural network; and predicting, with the neural network, an occurrence of the hazardous event.
2. The method of claim 1, wherein the neural network is trained by: a) inputting road-scene training data to the neural network, wherein the road-scene training data includes at least one sequence of an example hazardous event occurring in a road-scene; b) identifying, with the neural network, one or more patterns of events present in the at least one sequence of the example hazardous event within the road-scene training data; c) updating one or more parameters of the neural network in response to identifying the one or more patterns of events; and d) repeating steps a-c one or more times, wherein the road-scene training data input during a first iteration of training of the neural network is different than a second iteration of training of the neural network.
3. The method of claim 2, wherein the road-scene training data includes road-scene video data captured by a camera attached to a vehicle during a high-G event.
4. The method of claim 1, wherein the neural network is trained by: a) inputting road-scene training data to the neural network; b) inputting gaze-tracking data associated with the road-scene training data; c) inputting physiological response data associated with the road-scene training data; d) evolving the neural network to determine one or more salient portions within the road-scene data based on the gaze-tracking data; e) evolving the neural network to determine one or more risk-weights for the one or more salient portions within the road-scene data based on the physiological response data associated with the road-scene data; and f) repeating steps a-e one or more times, wherein the road-scene training data input during a first iteration of training of the neural network is different than a second iteration of training of the neural network.
5. The method of claim 4, wherein the physiological response data includes pupillometry data.
6. The method of claim 4, wherein the gaze-tracking data and the physiological response data is generated from sensor systems configured to monitor responses of one or more individuals to the road-scene training data.
7. The method of claim 1, further comprising generating a risk-weighted saliency map based on the predicted hazardous event.
8. The method of claim 1, further comprising outputting an alert when the neural network predicts the occurrence of the hazardous event present in the road-scene data.
9. The method of claim 8, wherein the alert is a graded alert corresponding to a degree of the predicted hazardous event.
10. The method of claim 1, wherein the road-scene data includes road-scene video data.
11. The method of claim 1, wherein the neural network is trained to identify one or more patterns preceding the hazardous event.
12. A system for predicting a hazardous event from road-scene data comprising: an electronic control unit configured to implement a neural network; and a camera communicatively coupled to the electronic control unit, wherein the camera generates the road-scene data, and wherein the electronic control unit is configured to: receive the road-scene data from the camera; and predict, with the neural network, an occurrence of the hazardous event within the road-scene data from the camera.
13. The system of claim 12, wherein the electronic control unit is further configured to: generate, with the neural network, a risk-weighted saliency map based on the road-scene data.
14. The system of claim 12, wherein the electronic control unit is further configured to: generate an alert in response to the electronic control unit predicting the occurrence of the hazardous event within the road-scene data.
15. The system of claim 14, wherein the alert is a graded alert corresponding to a degree of the predicted hazardous event.
16. The system of claim 12, wherein the neural network is trained to identify one or more patterns preceding the hazardous event.
17. The system of claim 12, wherein the neural network is trained by the steps: a) inputting road-scene training data to the neural network, wherein the road-scene training data includes at least one sequence of an example hazardous event occurring in a road-scene; b) identifying, with the neural network, one or more patterns of events present in the at least one sequence of the example hazardous event within the road-scene training data; c) updating one or more parameters of the neural network in response to identifying the one or more patterns of events; and d) repeating steps a-c one or more times, wherein the road-scene training data input during a first iteration of training of the neural network is different than a second iteration of training of the neural network.
18. The system of claim 12, wherein the neural network is trained by: a) inputting road-scene training data to the neural network; b) inputting gaze-tracking data associated with the road-scene training data; c) inputting physiological response data associated with the road-scene training data; d) evolving the neural network to determine one or more salient portions within the road-scene data based on the gaze-tracking data; e) evolving the neural network to determine one or more risk-weights for the one or more salient portions within the road-scene data based on the physiological response data associated with the road-scene data; and f) repeating steps a-e one or more times, wherein the road-scene training data input during a first iteration of training of the neural network is different than a second iteration of training of the neural network.
19. A vehicle comprising: an electronic control unit configured to implement a neural network; and a camera communicatively coupled to the electronic control unit, wherein the camera generates road-scene data, and wherein the electronic control unit is configured to: receive the road-scene data from the camera; and predict, with the neural network, an occurrence of a hazardous event within the road-scene data from the camera.
20. The vehicle of claim 19, wherein the electronic control unit is further configured to: generate an alert in response to the electronic control unit predicting the occurrence of the hazardous event within the road-scene data.
</claims>
</document>
