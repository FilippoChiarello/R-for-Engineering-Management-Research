<document>

<filing_date>
2020-06-19
</filing_date>

<publication_date>
2020-12-24
</publication_date>

<priority_date>
2019-06-20
</priority_date>

<ipc_classes>
G10L15/26
</ipc_classes>

<assignee>
UNIVERSITY OF TARTU
</assignee>

<inventors>
Anbarjafari, Gholamreza
Aktas, Kadir
</inventors>

<docdb_family_id>
66999764
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR MANAGING AUDIO-VISUAL DATA
</title>

<abstract>
A method for processing speech data for a speech event, wherein the speech data comprises a visible component and an audible component. The method comprises identifying a first visible feature within the visible component that corresponds to a predetermined visible speech feature and determining a first time corresponding to the occurrence of the first visible feature during the speech event. The method further comprises determining a measurement of a characteristic of the audible component at a second time during the speech event, which has a predefined temporal relationship to the first time at which the first visible feature occurred, and using the determined measurement of a characteristic at the second time to output an evaluation of an attribute, with which the predetermined visible speech feature is associated.
</abstract>

<claims>
1. A method for processing speech data for a speech event, wherein the speech data comprises a visible component and an audible component, the method comprising: identifying a first visible feature within the visible component that corresponds to a predetermined visible speech feature; determining a first time corresponding to occurrence of the first visible feature during the speech event; determining a measurement of a characteristic of the audible component, at a second time, during the speech event, which has a predefined temporal relationship to the first time at which the first visible feature occurred; and using the determined measurement of the characteristic at the second time to output an evaluation of an attribute with which the predetermined visible speech feature is associated.
2. The method of claim 1, wherein the speech event comprises either a live speech or a recorded speech.
3. The method of claim 1, wherein the speech data further comprises characteristic data that comprises information relating to one or more characteristics of at least the visible component or the audible component of the speech data.
4. The method of claim 3, wherein the characteristics of the audible component includes at least one of: volume, pitch, speed, length of pauses between words, tonnetz, ferments, Mel Frequency Cepstral Coefficients, Energy Entropy, Short Time Energy, Zero-Crossing Rate, Spectral Roll-Off, Spectral Centroid, Spectral Flux, Pitch Spectral autocorrelation function (ACF), or Pitch Spectral Harmonic Product Spectrum (HPS).
5. The method of claim 1, wherein the first visible feature within the visible component comprises at least a portion of a word or phrase spoken during the speech event.
6. The method of claim 1, wherein the first visible feature within the visible component comprises a facial expression captured during the speech event.
7. The method of claim 1, wherein identifying the first visible feature that corresponds to the predetermined visible speech feature comprises matching the first visible feature with the predetermined visible speech feature within a predetermined degree of tolerance or error.
8. The method of claim 1, further comprising: identifying a second visible feature within the visible component, wherein the second visible feature corresponds to a second predetermined visible speech feature different than the predetermined visible speech feature to which the first visible feature corresponds; and identifying a third time, during the speech event, at which the second visible feature occurs.
9. The method of claim 1, wherein the predefined temporal relationship dictates the first time is equal to the second time.
10. The method of claim 1, wherein the predefined temporal relationship dictates there is a predetermined time difference between the first time and the second time.
11. The method of claim 1, wherein determining the measurement of the characteristic of the audible component comprises: selecting the characteristic of the audible component from a plurality of characteristics, wherein the predefined temporal relationship between the first time and the second time is dependent on the selected characteristic.
12. A non-transitory computer readable medium having a memory and instructions stored therein which, when executed by a data processing tool, causes the non-transitory computer readable medium to process speech data for a speech event via a method comprising: identifying a first visible feature within a visible component that corresponds to a predetermined visible speech feature; determining a first time corresponding to occurrence of the first visible feature during the speech event; determining a measurement of a characteristic of an audible component at a second time during the speech event, which has a predefined temporal relationship to the first time at which the first visible feature occurred; and outputting an evaluation of an attribute with which the predetermined visible speech feature is associated, responsive to the determined measurement of the characteristic of the audible component at the second time.
13. The non-transitory computer readable medium of claim 12, wherein the speech event comprises at least one of a live speech or a recorded speech.
14. The non-transitory computer readable medium of claim 13, wherein the speech data further comprises characteristic data that comprises information relating to one or more characteristics of at least the visible component or the audible component of the speech data.
15. The non-transitory computer readable medium of claim 14, wherein the characteristics of the audible component includes at least one of: volume, pitch, speed, length of pauses between words, tonnetz, ferments, Mel Frequency Cepstral Coefficients, Energy Entropy, Short Time Energy, Zero-Crossing Rate, Spectral Roll-Off, Spectral Centroid, Spectral Flux, Pitch Spectral autocorrelation function (ACF), or Pitch Spectral Harmonic Product Spectrum (HPS).
16. The non-transitory computer readable medium of claim 14, wherein the first visible feature within the visible component comprises at least a portion of a word or phrase spoken during the speech event.
17. The non-transitory computer readable medium of claim 14, wherein the first visible feature within the visible component comprises a facial expression captured during the speech event.
18. The non-transitory computer readable medium of claim 14, wherein identifying the first visible feature that corresponds to the predetermined visible speech feature comprises matching the first visible feature with the predetermined visible speech feature within a predetermined degree of tolerance.
19. The non-transitory computer readable medium of claim 14, further comprising: identifying a second visible feature within the visible component, wherein the second visible feature corresponds to a second predetermined visible speech feature different than the predetermined visible speech feature to which the first visible feature corresponds; and identifying a third time, during the speech event, at which the second visible feature occurs.
20. A data processing tool comprising a control unit and a memory, wherein the control unit is configured to process speech data for a speech event, wherein the speech data comprises a visible component and an audible component, the control unit further being configured to: identify a first visible feature within the visible component that corresponds to a predetermined visible speech feature; determine a first time corresponding to the occurrence of the first visible feature during the speech event; determine a measurement of a characteristic of the audible component, at a second time, during the speech event, which has a predefined temporal relationship to the first time at which the first visible feature occurred; and use the determined measurement of the characteristic at the second time to output an evaluation of an attribute with which the predetermined visible speech feature is associated.
</claims>
</document>
