<document>

<filing_date>
2020-06-18
</filing_date>

<publication_date>
2020-12-23
</publication_date>

<priority_date>
2019-06-18
</priority_date>

<ipc_classes>
G06F3/01,G06F9/46,G06T19/00
</ipc_classes>

<assignee>
TMRW FOUNDATION IP & HOLDING
</assignee>

<inventors>
YERLI, CEVAT
</inventors>

<docdb_family_id>
71108438
</docdb_family_id>

<title>
MERGED REALITY SYSTEM AND METHOD
</title>

<abstract>
A merged reality system comprises servers in a cloud to edge infrastructure configured to store and process data and models of virtual replicas of real world elements that provide self-computing capabilities and autonomous behavior to the virtual replicas. The data and models are input through a plurality of software platforms, software engines, and sensors connected to things and user devices. The server is further configured to merge the real and virtual data and models in order to augment the real data with the virtual data. A method thereof comprises mapping the real world into a virtual world, generating virtual replicas of the real world; adding models and data of the virtual replicas; connecting the virtual replicas to corresponding real elements in order to enrich and synchronize the virtual replicas with the real-world elements; merging the real and virtual data; and augmenting the real data with the virtual data.
</abstract>

<claims>
1. A merged reality system comprising: at least one server comprising at least one processor and memory including a data store storing a persistent virtual world system comprising one or more virtual replicas of real world elements, the virtual replicas comprising virtual data and having self-computing capabilities and autonomous behavior; and a plurality of connected devices communicating through a network and comprising sensing mechanisms configured to capture real-world data as multi-source data from real-world elements; wherein the real-world data is sent to the persistent virtual world system stored in the server to enrich said virtual replicas and synchronize the virtual replicas with corresponding real-world elements, and wherein the at least one server merges the real-world data and the virtual data into the persistent virtual world system in order to augment the real-world data with the virtual data.
2. The system of claim 1, wherein the virtual replicas include logic and models input through a plurality of software platforms and software engines, and wherein the plurality of software platforms comprise Internet of Things platforms, machine learning platforms, big data platforms, simulation platforms, or spatial data streaming platforms, or a combination thereof, and wherein the plurality of software engines comprise artificial intelligence engines, simulation engines, 3D engines, or haptic engines, or a combination thereof.
3. The system of claim 2, wherein the models comprise one or more of a 3D model, a dynamic model, a geometric model, or a machine learning model, or a combination thereof;
wherein in particular the 3D model comprises a 3D data structure representing at least one 3D object, the 3D data structure comprising quadtrees, BSP trees, sparse voxel octrees, 3D arrays, kD trees, point clouds, wire-frames, boundary representations (B-Rep), constructive solid geometry trees (CSG Trees), bintrees, or hexagonal structures, or combinations thereof; and/or
wherein the machine learning model employs machine learning algorithms based on actual or simulated data that have been used as training data.
4. The system of claim 2 or 3, wherein the models consider a level of detail required by a specific scenario computation, wherein the level of detail adjusts complexity of a model representation depending on distance of the virtual replica from a viewer, object importance, viewpoint-relative speed or position, classification of individual viewers, or combinations thereof.
5. The system of claim 4, wherein the classification of individual viewers comprises artificial intelligence viewers or human viewers, and wherein the level of detail is further adjusted depending on a sub-classification of artificial intelligence viewer or of human viewer.
6. The system of any one of the previous claims, wherein the real-world data comprises real spatial data and the virtual data comprises virtual spatial data, and wherein combinations thereof by the at least one server enable augmenting the real spatial data with the virtual spatial data.
7. The system of claim 6, wherein the virtual spatial data represents a desired location input by a user via a user device, the desired location being different from a real location of the user, prompting the processor to create a copy of an avatar of the user in the desired location.
8. The system of any one of the previous claims, wherein connected virtual replicas create a virtual replica network.
9. The system of claim 8, wherein each of the connected virtual replicas is included in one or more streams representing a goal-specific simulation configured to obtain data from corresponding virtual replicas, in particular the one or more streams form a sub-universe, the sub-universe representing a defined virtualized space of a persistent virtual world system.
10. The system of any one of the previous claims, wherein the system employs a cloud to edge distributed computing infrastructure.
11. A method to generate a merged reality system, the method comprising: mapping real world objects into a virtual world, by generating virtual replicas of the real world objects; adding models and real-world data related to the real world objects to the virtual replicas, thereby providing self-computing capabilities and autonomous behavior to the virtual replicas; merging the real-world data and virtual data; and augmenting the real-world data with the virtual data.
12. The method of claim 11, further comprising: obtaining real spatial data and virtual spatial data; checking whether the real and virtual spatial data coincide; where the real spatial data and virtual spatial data do not coincide, creating a copy of a user avatar in a desired location; where the real spatial data and virtual spatial data coincide, merging the real and virtual spatial data; and augmenting the real spatial data with the virtual spatial data.
13. The method of claim 11 or 12, further comprising connecting the virtual replicas to one another to create a virtual replica network.
14. The method of claim 13, wherein each of the connected virtual replicas is included in one or more streams representing a goal-specific simulation configured to obtain data from corresponding virtual replicas, in particular the one or more streams form a sub-universe, the sub-universe representing a defined virtualized space of a persistent virtual world system.
15. One or more non-transitory computer readable-media having stored thereon instructions configured to cause a computer system comprising memory and at least one processor to perform the method of any one of the previous claims.
</claims>
</document>
