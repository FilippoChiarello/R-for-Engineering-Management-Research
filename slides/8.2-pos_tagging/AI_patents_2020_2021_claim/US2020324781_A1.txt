<document>

<filing_date>
2019-04-10
</filing_date>

<publication_date>
2020-10-15
</publication_date>

<priority_date>
2019-04-10
</priority_date>

<ipc_classes>
B60W40/105,G06T7/246
</ipc_classes>

<assignee>
HONDA MOTOR COMPANY
</assignee>

<inventors>
DARIUSH, BEHZAD
HAYAKAWA, Jun
</inventors>

<docdb_family_id>
72748824
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR ESTIMATING VELOCITY OF AN AUTONOMOUS VEHICLE AND STATE INFORMATION OF A SURROUNDING VEHICLE
</title>

<abstract>
Systems and methods for estimating velocity of an autonomous vehicle and state information of a surrounding vehicle are provided. In some aspects, the system includes a memory that stores instructions for executing processes for estimating velocity of an autonomous vehicle and state information of the surrounding vehicle and a processor configured to execute the instructions. In various aspects, the processes include: receiving image data from an image capturing device; performing a ground plane estimation by predicting a depth of points on a road surface based on an estimated pixel-level depth; determining a three-dimensional (3D) bounding box of the surrounding vehicle; determining the state information of the surrounding vehicle based on the ground plane estimation and the 3D bounding box; and determining the velocity of the autonomous vehicle based on an immovable object relative to the autonomous vehicle. In some aspects, an operation of the autonomous vehicle may be controlled based on at least one of the state information or the velocity of the autonomous vehicles.
</abstract>

<claims>
1. An automated driving (AD) system for estimating velocity of an autonomous vehicle and state information of a surrounding vehicle, the system comprising: a memory that stores instructions for executing processes estimating the velocity of the autonomous vehicle and state information of the surrounding vehicle; and a processor configured to execute the instructions, wherein the processes comprise: receiving image data from an image capturing device; performing a ground plane estimation by predicting a depth of points on a road surface based on an estimated pixel-level depth; determining a three-dimensional (3D) bounding box of the surrounding vehicle; determining the state information of the surrounding vehicle based on the ground plane estimation and the 3D bounding box; and determining the velocity of the autonomous vehicle based on an immovable object relative to the autonomous vehicle, wherein an operation of the autonomous vehicle is controlled based on at least one of the state information or the velocity of the autonomous vehicles.
2. The system of claim 1, wherein the image capturing device comprises a monocular camera.
3. The system of claim 1, wherein the state information of the surrounding vehicle comprises a 3D position of the surrounding vehicle, an orientation of the surrounding vehicle, and a velocity of the surrounding vehicle.
4. The system of claim 3, wherein the 3D position of the surrounding vehicle comprises coordinates of three bottom vertices and a height of the bounding box of the surrounding vehicle.
5. The system of claim 4, wherein performing the ground plane estimation comprises updating one or more ground plane coefficients based on changes in the road surface in real-time.
6. The system of claim 5, wherein updating one or more ground plane coefficients comprises: selecting a plurality of fixed points in a lower portion of the image data that includes the road surface; removing one or more points of the plurality of fixed points that are inappropriate for estimating the ground plane based on which points are outside of the 3D bounding box; and calculating new ground plane coefficients based on remaining ones of the plurality of fixed points, and the processor is further configured to generate a corrected ground plane estimation based on the new ground plane coefficients.
7. The system of claim 6, wherein determining the orientation of the surrounding vehicle is based at least on the corrected ground plane estimation.
8. The system of claim 3, wherein the velocity of the surrounding vehicle comprises an absolute velocity that is based on a difference between the velocity of the autonomous vehicle and a relative velocity of the surrounding vehicle.
9. A method for estimating velocity of an autonomous vehicle and state information of a surrounding vehicle, the method comprising: receiving image data from an image capturing device; performing a ground plane estimation by predicting a depth of points on a road surface based on an estimated pixel-level depth; determining a three-dimensional (3D) bounding box of the surrounding vehicle; determining the state information of the surrounding vehicle based on the ground plane estimation and the 3D bounding box; and determining the velocity of the autonomous vehicle based on an immovable object relative to the autonomous vehicle, wherein an operation of the autonomous vehicle is controlled based on at least one of the state information or the velocity of the autonomous vehicles.
10. The method of claim 9, wherein the image capturing device comprises a monocular camera.
11. The method of claim 9, wherein the state information of the surrounding vehicle comprises a 3D position of the surrounding vehicle, an orientation of the surrounding vehicle, and a velocity of the surrounding vehicle.
12. The method of claim 11, wherein the 3D position of the surrounding vehicle comprises coordinates of three bottom vertices and a height of the bounding box of the surrounding vehicle.
13. The method of claim 12, wherein performing the ground plane estimation comprises updating one or more ground plane coefficients based on changes in the road surface in real-time.
14. The method of claim 13, wherein updating one or more ground plane coefficients comprises: selecting a plurality of fixed points in a lower portion of the image data that includes the road surface; removing one or more points of the plurality of fixed points that are inappropriate for estimating the ground plane based on which points are outside of the 3D bounding box; and calculating new ground plane coefficients based on remaining ones of the plurality of fixed points, and the method further comprises generating a corrected ground plane estimation based on the new ground plane coefficients, wherein the orientation of the surrounding vehicle is based at least on the corrected ground plane estimation.
15. The method of claim 11, wherein the velocity of the surrounding vehicle comprises an absolute velocity that is based on a difference between the velocity of the autonomous vehicle and a relative velocity of the surrounding vehicle.
16. A non-transitory computer-readable storage medium containing executable computer program code for estimating velocity of an autonomous vehicle and state information of a surrounding vehicle, the code comprising instructions configured to cause a processor to: receive image data from an image capturing device; perform a ground plane estimation by predicting a depth of points on a road surface based on an estimated pixel-level depth; determine a three-dimensional (3D) bounding box of the surrounding vehicle; determine the state information of the surrounding vehicle based on the ground plane estimation and the 3D bounding box; and determine the velocity of the autonomous vehicle based on an immovable object relative to the autonomous vehicle, wherein an operation of the autonomous vehicle is controlled based on at least one of the state information or the velocity of the autonomous vehicles.
17. The non-transitory computer-readable storage medium of claim 16, wherein the state information of the surrounding vehicle comprises a 3D position of the surrounding vehicle, an orientation of the surrounding vehicle, and a velocity of the surrounding vehicle.
18. The non-transitory computer-readable storage medium of claim 17, wherein the 3D position of the surrounding vehicle comprises coordinates of three bottom vertices and a height of the bounding box of the surrounding vehicle.
19. The non-transitory computer-readable storage medium of claim 18, wherein updating one or more ground plane coefficients comprises: selecting a plurality of fixed points in a lower portion of the image data that includes the road surface; removing one or more points of the plurality of fixed points that are inappropriate for estimating the ground plane based on which points are outside of the 3D bounding box; calculating new ground plane coefficients based on remaining ones of the plurality of fixed points, and the code further causes the processor to generate a corrected ground plane estimation based on the new ground plane coefficients, wherein the orientation of the surrounding vehicle is based at least on the corrected ground plane estimation.
20. The non-transitory computer-readable storage medium of claim 17, wherein the velocity of the surrounding vehicle comprises an absolute velocity that is based on a difference between the velocity of the autonomous vehicle and a relative velocity of the surrounding vehicle.
</claims>
</document>
