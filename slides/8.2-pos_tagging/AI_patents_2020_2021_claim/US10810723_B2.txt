<document>

<filing_date>
2018-11-15
</filing_date>

<publication_date>
2020-10-20
</publication_date>

<priority_date>
2017-11-15
</priority_date>

<ipc_classes>
G06F17/11,G06K9/00,G06K9/32,G06K9/62,G06N3/04,G06N3/08,G06T7/00
</ipc_classes>

<assignee>
NEC LABORATORIES EUROPE
</assignee>

<inventors>
NIEPERT, MATHIAS
ONORO-RUBIO, DANIEL
</inventors>

<docdb_family_id>
64556854
</docdb_family_id>

<title>
System and method for single image object density estimation
</title>

<abstract>
A method for object density monitoring includes receiving, by a processing server, an input image captured by an image sensor. The method further includes providing an annotated dataset with a target object to be identified in the input image, and providing, by the processing server as output, an object density map generated from the input image. The processing server provides the object density map by using a deep neural network having one or more pairs of a compression layer and a decompression layer connected by gated shortcuts.
</abstract>

<claims>
1. A method for object density monitoring, the method comprising: receiving, by a processing server, an input image captured by an image sensor; providing an annotated dataset with a target object to be identified in the input image; and providing, by the processing server as output, an object density map generated from the input image, wherein the processing server provides the object density map by using a deep neural network having one or more pairs of a respective compression layer and a respective decompression layer connected by a respective gated shortcut, wherein each respective gated shortcut includes a respective gating function configured to receive, as input, an output of the respective compression layer and to generate, as output, gated information, wherein the gated information is generated by filtering the output of the respective compression layer, and wherein the respective decompression layer of each pair is configured to receive, as input, an output of a preceding neighboring layer and the gated information generated as output by the respective gating function.
2. The method according to claim 1, the object density map is a heat map that indicates a number of instances of the target object in different regions of the input image.
3. The method according to claim 1, further comprising, prior to the receiving, by the processing server, the input image captured by the at least one image sensor, training the deep neural network using the annotated dataset.
4. The method according to claim 3, wherein during the training the deep neural network using the annotated dataset, a connection strength of each of the one or more gated shortcuts is learned.
5. The method according to claim 1, wherein the output of the respective compression layer is a feature vector, and wherein the filtering the output of the respective compression layer to generate the gated information comprises multiplying the feature vector by a mask.
6. The method according to claim 5, wherein the mask is a sigmoid function of the feature vector and a set of learned weights.
7. The method according to claim 6, further comprising, prior to the receiving, by the processing server, the input image captured by the at least one image sensor, training the deep neural network using the annotated dataset, wherein the training the deep neural network using the annotated dataset includes learning the weights of the set of learned weights.
8. The method according to claim 1, further comprising providing a total count of a number of instances of the target object in the input image.
9. The method according to claim 1, wherein the image sensor is a camera and/or a microscope.
10. The method according to claim 1, wherein the image sensor is configured to provide a view of a target scene, further comprising providing a plurality of one or more additional image sensors configured to provide a view of the target scene.
11. The method according to claim 10, further comprising connecting the one or more additional image sensors to the processing server via the communication network; receiving, by the processing server, one or more additional input images captured by the one or more additional image sensors; providing, by the processing server as output, one or more additional object density maps, wherein each of the one or more additional object density maps is generated, by using the deep neural network, from a respective one of the one or more additional input images.
12. The method according to claim 11, further comprising providing a total count of a number of instances of the target object in the target scene by considering the object density map and each of the one or more additional object density maps.
13. The method according to claim 1, wherein the input image captured by the image sensor is a still image.
14. A non-transitory computer readable medium having stored thereon instructions for performing a method for object density monitoring, the method comprising: receiving, by a processing server, an input image captured by an image sensor; providing an annotated dataset with a target object to be identified in the input image; and providing, by the processing server as output, an object density map generated from the input image, wherein the processing server provides the object density map by using a deep neural network having one or more pairs of a respective compression layer and a respective decompression layer connected by a respective gated shortcut, wherein each respective gated shortcut includes a respective gating function configured to receive, as input, an output of the respective compression layer and to generate, as output, gated information, wherein the gated information is generated by filtering the output of the respective compression layer, and wherein the respective decompression layer of each pair is configured to receive, as input, an output of a preceding neighboring layer and the gated information generated as output by the respective gating function.
15. A system for object density monitoring, the system comprising: a processing server configured to: receive an input image from an image sensor, receive an annotated dataset with a target object to be identified in the input image, and provide, as output, an object density map generated from the input image, wherein the processing server provides the object density map by using a deep neural network having one or more pairs of a respective compression layer and a respective decompression layer connected by a respective gated shortcut, wherein each respective gated shortcut includes a respective gating function configured to receive, as input, an output of the respective compression layer and to generate, as output, gated information, wherein the gated information is generated by filtering the output of the respective compression layer, and wherein the respective decompression layer of each pair is configured to receive, as input, an output of a preceding neighboring layer and the gated information generated as output by the respective gating function.
16. The method according to claim 1, wherein the output of the respective compression layer is a feature vector, wherein the gated information is a tensor, and wherein the tensor is merged with the output of the preceding neighbor layer so as to provide the input of the respective decompression layer.
17. The method according to claim 16, wherein the tensor is merged with the output of the preceding neighbor layer by way of concatenation or summation.
18. The method according to claim 6, wherein the gated information is a tensor, and wherein the tensor is merged with the output of the preceding neighbor layer so as to provide the input of the respective decompression layer.
19. The method according to claim 3, wherein the training the deep neural network includes minimizing a squared difference between an output of the deep neural network for a given input image and a predetermined density map for the given input image.
20. The method according to claim 19, wherein the training the deep neural network is performed using only a single loss term.
</claims>
</document>
