<document>

<filing_date>
2020-01-29
</filing_date>

<publication_date>
2020-06-30
</publication_date>

<priority_date>
2017-07-05
</priority_date>

<ipc_classes>
G06F40/00,G06F40/289,G06F40/30,G06N20/10,G06N7/00,G06Q30/06
</ipc_classes>

<assignee>
ALIBABA GROUP
</assignee>

<inventors>
SUN, QINGQING
</inventors>

<docdb_family_id>
60748842
</docdb_family_id>

<title>
Risk address identification method and apparatus, and electronic device
</title>

<abstract>
Embodiments of the specification disclose a risk address identification method and apparatus, and an electronic device. The risk address identification method includes: acquiring an address word sequence corresponding to an input address; determining an address word in the address word sequence, the determined address word matching a risk word corresponding to a risk address; generating an observation sequence corresponding to the address word sequence according to the determined address word; processing the observation sequence using a hidden Markov model obtained based on semantics learning before and after address words, to obtain a decision vector, wherein the decision vector represents probabilities of the risk address being matched by address words contained in the address word sequence; and identifying whether the input address is a risk address by making a classification decision on the decision vector.
</abstract>

<claims>
1. A risk address identification method, comprising: acquiring an address word sequence corresponding to an input address; determining an address word in the address word sequence, the determined address word matching a risk word corresponding to a risk address; generating an observation sequence corresponding to the address word sequence according to the determined address word; processing the observation sequence using a hidden Markov model obtained based on semantics learning before and after address words, to obtain a decision vector, wherein the decision vector represents probabilities of the risk address being matched by address words contained in the address word sequence; and identifying whether the input address is a risk address by making a classification decision on the decision vector.
2. The method according to claim 1, wherein acquiring an address word sequence corresponding to an input address comprises: receiving an input address; performing data cleaning processing and word segmentation processing on the input address to obtain the address word sequence corresponding to the input address.
3. The method according to claim 1, wherein determining an address word in the address word sequence matching a risk word corresponding to a risk address comprises: respectively matching the address words in the address word sequence using risk words corresponding to the risk address; and if one of the address words is successfully matched, labeling the matched address word and determining the matched address word as an address word matching a risk word corresponding to the risk address.
4. The method according to claim 3, wherein determining an address word in the address word sequence matching a risk word corresponding to a risk address further comprises: if there is no successfully matched address word, determining that the input address is not a risk address.
5. The method according to claim 3, wherein generating an observation sequence corresponding to the address word sequence according to the determined address word comprises: generating an observation sequence corresponding to the address word sequence according to the determined address word and associated words of the determined address word in the address word sequence, wherein the associated words reflect semantics before and after the determined address word in the address word sequence.
6. The method according to claim 1, wherein obtaining a hidden Markov model based on semantics learning before and after address words comprises: extracting initial parameters according to predefined training samples, and establishing an initial model containing hidden Markov model parameters according to the initial parameters, wherein the training samples are risk addresses or non-risk addresses; generating observation sequences corresponding to the training samples according to address words contained in the training samples and semantics before and after the address words; and training the hidden Markov model parameters according to the initial model and the observation sequences corresponding to the training samples to obtain the hidden Markov model.
7. The method according to claim 6, wherein the initial parameters comprise: an initial probability vector and a state transition matrix; and extracting initial parameters according to predefined training samples comprises: based on a plurality of predefined training samples, obtaining an initial probability vector by respectively performing probability labeling on address words contained in the training samples; and obtaining a state transition matrix of the sample addresses according to state transition probabilities, between a risk word and a non-risk word, of the address words contained in the training samples.
8. The method according to claim 6, wherein training the hidden Markov model parameters according to the initial model and the observation sequences corresponding to the training samples to obtain the hidden Markov model comprises: according to the initial model and the observation sequences corresponding to the training samples, using a Baum-Welch algorithm to train the hidden Markov model parameters to obtain the hidden Markov model.
9. The method according to claim 1, wherein processing the observation sequence using a hidden Markov model obtained based on semantics learning before and after address words to obtain a decision vector comprises: processing the observation sequence using the hidden Markov model obtained by semantics learning before and after address words, and a Viterbi algorithm, to obtain the decision vector.
10. The method according to claim 1, wherein making a classification decision on the decision vector comprises: making a classification decision on the decision vector using a support vector machine model obtained through training.
11. The method according to claim 10, wherein obtaining a support vector machine model through training comprises: acquiring training samples for a support vector machine; mapping the training samples of the support vector machine to a high-dimensional feature space, to obtain a sample feature space corresponding to the training samples of the support vector machine; acquiring, from the sample feature space, parameters representing sample features, and establishing a discrimination function for determining a category of the sample features according to the parameters of the sample features; and training corresponding support vector machine parameters in the discrimination function based on the training samples of the support vector machine, to obtain the support vector machine model.
12. An electronic device, comprising: a processor; and a memory for storing instructions executable by the processor; wherein the processor is configured to: acquire an address word sequence corresponding to an input address; determine an address word in the address word sequence, the determined address word matching a risk word corresponding to a risk address; generate an observation sequence corresponding to the address word sequence according to the determined address word; process the observation sequence using a hidden Markov model obtained based on semantics learning before and after address words, to obtain a decision vector, wherein the decision vector represents probabilities of the risk address being matched by address words contained in the address word sequence; and identify whether the input address is a risk address by making a classification decision on the decision vector.
13. The device according to claim 12, wherein in acquiring an address word sequence corresponding to an input address, the processor is further configured to: receive an input address; and perform data cleaning processing and word segmentation processing on the input address to obtain the address word sequence corresponding to the input address.
14. The device according to claim 12, wherein in determining an address word in the address word sequence matching a risk word corresponding to a risk address, the processor is further configured to: respectively match the address words in the address word sequence using risk words corresponding to the risk address; and if one of the address words is successfully matched, labeling the matched address word and determining the matched address word as an address word matching a risk word corresponding to the risk address.
15. The device according to claim 14, wherein in determining an address word in the address word sequence matching a risk word corresponding to a risk address, the processor is further configured to: if there is no successfully matched address word, determine that the input address is not a risk address.
16. The device according to claim 14, wherein in generating an observation sequence corresponding to the address word sequence according to the determined address word, the processor is further configured to: generate an observation sequence corresponding to the address word sequence according to the determined address word and associated words of the determined address word in the address word sequence, wherein the associated words reflect semantics before and after the determined address word in the address word sequence.
17. The device according to claim 12, wherein the processor is further configured to: extract initial parameters according to predefined training samples, and establish an initial model containing hidden Markov model parameters according to the initial parameters, wherein the training samples are risk addresses or non-risk addresses; generate observation sequences corresponding to the training samples according to address words contained in the training samples and semantics before and after the address words; and train the hidden Markov model parameters according to the initial model and the observation sequences corresponding to the training samples to obtain the hidden Markov model.
18. The device according to claim 17, wherein the initial parameters comprise: an initial probability vector and a state transition matrix; and in extracting initial parameters according to predefined training samples, the processor is further configured to: based on a plurality of predefined training samples, obtain an initial probability vector by respectively performing probability labeling on address words contained in the training samples; and obtain a state transition matrix of the sample addresses according to state transition probabilities, between a risk word and a non-risk word, of the address words contained in the training samples.
19. The device according to claim 17, wherein in training the hidden Markov model parameters according to the initial model and the observation sequences corresponding to the training samples to obtain the hidden Markov model, the processor is further configured to: according to the initial model and the observation sequences corresponding to the training samples, use a Baum-Welch algorithm to train the hidden Markov model parameters to obtain the hidden Markov model.
20. A computer-readable storage medium storing thereon a computer program that, when executed by a processor of a device, causes the device to perform a risk address identification method, the method comprising: acquiring an address word sequence corresponding to an input address; determining an address word in the address word sequence, the determined address word matching a risk word corresponding to a risk address; generating an observation sequence corresponding to the address word sequence according to the determined address word; processing the observation sequence using a hidden Markov model obtained based on semantics learning before and after address words, to obtain a decision vector, wherein the decision vector represents probabilities of the risk address being matched by address words contained in the address word sequence; and identifying whether the input address is a risk address by making a classification decision on the decision vector.
</claims>
</document>
