<document>

<filing_date>
2019-05-23
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2019-05-03
</priority_date>

<ipc_classes>
G06F17/16,G06F7/483,G06F7/499,G06F9/38
</ipc_classes>

<assignee>
TESLA
</assignee>

<inventors>
DAS SARMA, DEBJIT
MCGEE, WILLIAM
TALPES, EMIL
</inventors>

<docdb_family_id>
73016418
</docdb_family_id>

<title>
SCALABLE MATRIX NODE ENGINE WITH CONFIGURABLE DATA FORMATS
</title>

<abstract>
A microprocessor system comprises a matrix computational unit and a control unit. The matrix computational unit includes one or more processing elements. The control unit is configured to provide a matrix processor instruction to the matrix computational unit. The matrix processor instruction specifies a floating-point operand formatted with an exponent that has been biased with a specified bias.
</abstract>

<claims>
1. A microprocessor system, comprising: a matrix computational unit that includes one or more processing elements; and a control unit configured to provide a matrix processor instruction to the matrix computational unit, wherein the matrix processor instruction specifies a floating-point operand formatted with an exponent that has been biased with a specified bias.
2. The system of claim 1, wherein the floating-point operand is a matrix.
3. The system of claim 2, wherein each element of the matrix uses an 8-bit floating-point format.
4. The system of claim 3, wherein the 8-bit floating-point format allocates 1-bit for a sign bit, 4-bits for an exponent field, and 3-bits for a mantissa field.
5. The system of claim 3, wherein the 8-bit floating-point format allocates 1-bit for a sign bit, 5-bits for an exponent field, and 2-bits for a mantissa field.
6. The system of claim 2, wherein the matrix processor instruction specifies a floating-point number format for the floating-point operand from a group of floating-point formats.
7. The system of claim 6, wherein each floating-point format of the group of floating-point formats utilizes a same total number of bits for representing a floating point number and a different number of bits for a mantissa field of the floating point number.
8. The system of claim 1, wherein the specified bias is configured using a register argument.
9. The system of claim 1, wherein the specified bias is selected from a non-consecutive set of pre-determined floating-point exponent biases.
10. The system of claim 1, wherein a configurable bias of the exponent is reconfigurable via the matrix processor instruction.
11. The system of claim 1, wherein each of the one or more processing elements includes a floating-point multiplier and an accumulator.
12. The system of claim 1, wherein each processing element of the one or more processing elements is configured to perform a floating-point multiplication operation in parallel with the other processing elements.
13. The system of claim 1, wherein the matrix processor instruction specifies a designated accumulator for storing intermediate results of the matrix computational unit.
14. A microprocessor system, comprising: a matrix processor, wherein the matrix processor is configured to receive a matrix processor instruction that specifies a floating-point operand formatted with an exponent that has been biased with a specified bias; a post-processing unit; a control unit configured to provide a post-processing instruction to the post-processing unit and the matrix processor instruction to the matrix processor; and a post-processing register file, wherein the post-processing instruction specifies an operand stored in the post-processing register file.
15. The system of claim 14, wherein the post-processing unit is a vector computational unit.
16. The system of claim 14, wherein the operand is a vector operand and the post-processing instruction specifies a data size for each vector element of the operand.
17. A method comprising: receiving a matrix processor instruction from a control unit, wherein the matrix processor instruction specifies a floating-point operand formatted with an exponent that has been biased with a specified bias; issuing one or more reads for data values of the floating-point operand; receiving the data values of the floating-point operand; and loading one or more received data values into a matrix computational unit.
18. The method of claim 17, wherein the floating-point operand is a matrix.
19. A method comprising: receiving a matrix processor instruction from a control unit, wherein the matrix processor instruction specifies a first floating-point operand and a second floating-point operand; loading a first half of the first floating-point operand into a first processing element and a second processing element; loading a second half of the first floating-point operand into a third processing element and a fourth processing element; loading a first half of the second floating-point operand into the first processing element and the third processing element; loading a second half of the second floating-point operand into the second processing element and the fourth processing element; determining a first, second, third, and fourth floating-point multiplication result corresponding to each of the first, second, third, and fourth processing elements; and storing the first, second, third, and fourth floating-point multiplication result in an output accumulator.
20. The method of claim 19, further comprising adding the first, second, third, and fourth floating-point multiplication result together using a vector computational unit.
</claims>
</document>
