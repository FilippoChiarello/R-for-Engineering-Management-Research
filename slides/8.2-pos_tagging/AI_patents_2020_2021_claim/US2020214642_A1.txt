<document>

<filing_date>
2019-12-19
</filing_date>

<publication_date>
2020-07-09
</publication_date>

<priority_date>
2018-12-21
</priority_date>

<ipc_classes>
A61B5/00,A61B5/0205,G16H30/40,G16H50/20,G16H50/30,G16H50/50
</ipc_classes>

<assignee>
ITRI (INDUSTRIAL TECHNOLOGY RESEARCH INSTITUTE)
</assignee>

<inventors>
WU, KUN-TA
LU, WEI-ZHENG
PAN, JUNG-CHUAN
HSU, PO-AN
LIN, CHII-WANN
LEE, KUO-CHUN
WANG, HENG-JIE
</inventors>

<docdb_family_id>
71194275
</docdb_family_id>

<title>
STATE ASSESSMENT SYSTEM, DIAGNOSIS AND TREATMENT SYSTEM, AND METHOD FOR OPERATING THE DIAGNOSIS AND TREATMENT SYSTEM
</title>

<abstract>
A state assessment system, a diagnosis and treatment system and a method for operating the diagnosis and treatment system are disclosed. An oscillator model converts a physiological signal of a subject into a defined feature image. A classification model analyzes state information of the subject based on the feature image. An analysis model outputs a treatment suggestion for the subject based on the state information of the subject. An AR projection device projects acupoint positions of a human body onto the subject, for the subject to be treated based on the treatment suggestion.
</abstract>

<claims>
1. A state assessment system, comprising: a signal capturing device configured for capturing a physiological signal of a subject; and an evaluation device, comprising: an oscillator model configured for converting the physiological signal into a feature image; and a classification model configured for classifying state information of the subject based on the feature image.
2. The state assessment system of claim 1, wherein the oscillator model calculates the physiological signal to obtain a protophase, an internal original oscillator phase and a coupling function sequentially, and takes the coupling function to be the feature image.
3. The state assessment system of claim 1, wherein the physiological signal comprises a heartbeat signal or a respiratory signal, and the oscillator model couples the heartbeat signal and the respiratory signal to be a feature image with heartbeat and respiratory coupled.
4. The state assessment system of claim 1, further comprising an image capturing device configured for capturing and converting a facial image and a tongue image of the subject into a facial feature image and a tongue feature image, respectively.
5. The state assessment system of claim 1, wherein the classification model is a convolutional neural network or a support vector machine.
6. A diagnosis and treatment system, comprising: a signal capturing device configured for capturing a physiological signal of a subject; and an augmented reality apparatus, comprising: an oscillator model configured for converting the physiological signal into a feature image; a classification model configured for classifying state information of the subject based on the feature image; and an analysis model configured for outputting a treatment suggestion for the subject based on the state information of the subject.
7. The diagnosis and treatment system of claim 6, wherein the oscillator model calculates the physiological signal to obtain a protophase, an internal original oscillator phase and a coupling function sequentially, and takes the coupling function to be the feature image.
8. The diagnosis and treatment system of claim 6, wherein the physiological signal comprises a heartbeat signal or a respiratory signal, and the oscillator model couples the heartbeat signal and the respiratory signal to be a feature image with heartbeat and respiratory coupled.
9. The diagnosis and treatment system of claim 6, wherein the augmented reality apparatus further comprises an image capturing device configured for capturing and converting a facial image and a tongue image of the subject into a facial feature image and a tongue feature image, respectively.
10. The diagnosis and treatment system of claim 6, wherein the classification model is a convolutional neural network or a support vector machine.
11. The diagnosis and treatment system of claim 6, wherein the augmented reality apparatus further comprises a projection device configured for projecting acupoint positions of a human body onto an image of the subject displayed on a displaying device of the augmented reality apparatus.
12. The diagnosis and treatment system of claim 6, wherein the augmented reality apparatus further comprises an infrared radiation device configured for projecting infrared radiation onto the subject.
13. The diagnosis and treatment system of claim 6, further comprising a treatment device configured for treating the subject based on the treatment suggestion.
14. The diagnosis and treatment system of claim 13, wherein the treatment device is an electric stimulus device.
15. The diagnosis and treatment system of claim 6, wherein the augmented reality apparatus further comprises a modification model configured for modifying the treatment suggestion for the subject output by the analysis model based on the state information of the subject classified by the classification model when the subject is treated based on the treatment suggestion.
16. A method for operating a diagnosis and treatment system, comprising: using a signal capturing device to capture a physiological signal of a subject; using an oscillator model to convert the physiological signal into a feature image; using a classification model to classify state information of the subject based on the feature image; and using an analysis model to output a treatment suggestion for the subject based on the state information of the subject.
17. The method of claim 16, wherein the oscillator model calculates the physiological signal to obtain a protophase, an internal original oscillator phase and a coupling function sequentially, and takes the coupling function to be the feature image.
18. The method of claim 16, wherein the physiological signal comprises a heartbeat signal or a respiratory signal, and the oscillator model couples the heartbeat signal and the respiratory signal to be a feature image with heartbeat and respiratory coupled.
19. The method of claim 16, further comprising using an image capturing device to capture and convert a facial image and a tongue image of the subject into a facial feature image and a tongue feature image, respectively.
20. The method of claim 16, further comprising using a projection device to project acupoint positions of a human body onto an image of the subject displayed on a displaying device of an augmented reality apparatus.
21. The method of claim 20, further comprising using an infrared radiation device to project infrared radiation onto the subject.
22. The method of claim 16, further comprising using a treatment device to treat the subject based on the treatment suggestion.
23. The method of claim 22, wherein the treatment device is an electric stimulus device.
24. The method of claim 16, further comprising using a modification model to modify the treatment suggestion for the subject output by the analysis model based on the state information of the subject classified by the classification model when the subject is treated based on the treatment suggestion.
</claims>
</document>
