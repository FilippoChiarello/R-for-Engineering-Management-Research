<document>

<filing_date>
2020-06-03
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2019-06-03
</priority_date>

<ipc_classes>
G06F40/166,G06F40/242,G10L15/02,G10L15/187
</ipc_classes>

<assignee>
BEIJING DAJIA INTERNET INFORMATION TECHNOLOGY COMPANY
</assignee>

<inventors>
LI JIE
LI YAN
WANG, XIAORUI
</inventors>

<docdb_family_id>
67790407
</docdb_family_id>

<title>
METHOD, DEVICE AND STORAGE MEDIUM FOR SPEECH RECOGNITION
</title>

<abstract>
Disclosed are a method, device and readable storage medium for speech recognition. The method includes: determining speech features of the speech data by feature extraction on the speech data; determining syllable data corresponding to each of the speech features based on a plurality of feature extraction layers and a softmax function layer included in an acoustic model, where the acoustic model is configured to convert the speech feature into the syllable data; determining text data corresponding to the speech data based on a language model, a pronouncing dictionary and the syllable data, where the pronouncing dictionary is configured to convert the syllable data into the text data, and the language model is configured to evaluate the text data; and outputting the text data.
</abstract>

<claims>
We claim:
1. A method for speech recognition, comprising: determining speech features of speech data by feature extraction on the speech data; determining syllable data corresponding to each of the speech features based on a plurality of feature extraction layers and a softmax function layer included in an acoustic model, wherein the acoustic model is configured to convert the speech feature into the syllable data; determining text data corresponding to the speech data based on a language model, a pronouncing dictionary and the syllable data, wherein the pronouncing dictionary is configured to convert the syllable data into the text data, and the language model is configured to evaluate the text data; and outputting the text data.
2. The method according to claim 1, wherein determining the syllable data comprises: inputting each of the speech features to the acoustic model; determining an intermediate speech feature extracted from each of the speech features based on the feature extraction layers; determining, based on the softmax function, a probability that the intermediate speech feature corresponds to each piece of syllable data in the acoustic model; and determining syllable data with a maximum probability as the syllable data.
3. The method according to claim 1, further comprising: acquiring at least one piece of sample data, wherein each piece of sample data includes a sample speech feature and truth syllable data corresponding to the sample speech feature; determining the acoustic model by training an initial acoustic model based on predicted syllable data and the truth syllable data, wherein the predicted syllable data are obtained by inputting the sample speech feature into the initial acoustic model.
4. The method according to claim 3, wherein acquiring the sample data comprises: acquiring a first correspondence, a second correspondence and a third correspondence; wherein the first correspondence is between a first speech feature of a first language and first text data, the second correspondence is between a second speech feature of a second language and second text data, the third correspondence is between first text sub-data and the second text data, and the first text sub-data is a part of data in the first text data; determining second text data corresponding to each piece of first text sub-data based on the third correspondence, after selecting a plurality of pieces of first text sub-data randomly from the first text data; replacing each piece of first text sub-data by the second text data to obtain mixed text data; determining the mixed text data as the sample text data; replacing the first speech sub-feature corresponding to each piece of first text sub-data by the second speech feature corresponding to the second text data to obtain a mixed speech feature; determining the mixed speech feature as the sample speech feature; determining truth syllable data corresponding to each sample text data; and determining the sample data by combining the truth syllable data, and the sample speech feature.
5. The method according to claim 1, wherein determining the text data comprises: determining preset text data corresponding to the syllable data based on a fourth correspondence in the pronouncing dictionary, wherein the fourth correspondence is between the syllable data and the text data; determining a probability of each piece of preset text data based on the language model; and determining the preset text data with a maximum probability as the text data.
6. The method according to claim 1, further comprising: acquiring sample text corpuses, wherein the sample text corpuses include text corpuses of a first language and text corpuses of a second language; determining a plurality of sample words by segmenting sample text corpuses based on a preset algorithm of word segmentation; determining an occurrence probability that each sample word occurs in the sample text corpuses; and determining the language model by storing each sample word and the occurrence probability corresponding to each sample word into an initial language model.
7. The method according to claim 6, wherein determining the sample text corpuses comprises: acquiring first text corpuses of the first language, second text corpuses of the second language, and a correspondence between the first text corpuses and the second text corpuses; selecting at least one first text sub-corpus from each of the first text corpuses; determining a correspondence between the first text sub-corpus and the second text corpus; replacing each first text sub-corpus by a second text corpus based on the correspondence between the first text sub-corpuses and the second text corpuses to obtain mixed text corpuses; and determining the mixed text corpuses as the sample text corpuses.
8. The method according to claim 1, wherein the pronouncing dictionary comprises a pronouncing dictionary of a first language and a pronouncing dictionary of a second language.
9. An electronic device for speech recognition, comprising a processor and a memory, the memory storing at least one instruction, and the instruction being loaded and executed by the processor to perform: determining speech features of speech data by feature extraction on the speech data; determining syllable data corresponding to each of the speech features based on a plurality of feature extraction layers and a softmax function layer included in an acoustic model, wherein the acoustic model is configured to convert the speech feature into the syllable data; determining text data corresponding to the speech data based on a language model, a pronouncing dictionary and the syllable data, wherein the pronouncing dictionary is configured to convert the syllable data into the text data, and the language model is configured to evaluate the text data; and outputting the text data.
10. The electronic device according to claim 9, wherein determining the syllable data comprises: inputting each of the speech features to the acoustic model; determining an intermediate speech feature extracted from each of the speech features based on the feature extraction layers; determining, based on the softmax function, a probability that the intermediate speech feature corresponds to each piece of syllable data in the acoustic model; and determining syllable data with a maximum probability as the syllable data.
11. The electronic device according to claim 9, further comprising: acquiring at least one piece of sample data, wherein each piece of sample data includes a sample speech feature and truth syllable data corresponding to the sample speech feature; determining the acoustic model by training an initial acoustic model based on predicted syllable data and the truth syllable data, wherein the predicted syllable data are obtained by inputting the sample speech feature into the initial acoustic model.
12. The electronic device according to claim 11, wherein acquiring the sample data comprises: acquiring a first correspondence, a second correspondence and a third correspondence; wherein the first correspondence is between a first speech feature of a first language and first text data, the second correspondence is between a second speech feature of a second language and second text data, the third correspondence is between first text sub-data and the second text data, and the first text sub-data is a part of data in the first text data; determining second text data corresponding to each piece of first text sub-data based on the third correspondence, after selecting a plurality of pieces of first text sub-data randomly from the first text data; replacing each piece of first text sub-data by the second text data to obtain mixed text data; determining the mixed text data as the sample text data; replacing the first speech sub-feature corresponding to each piece of first text sub-data by the second speech feature corresponding to the second text data to obtain a mixed speech feature; determining the mixed speech feature as the sample speech feature; determining truth syllable data corresponding to each sample text data; and determining the sample data by combining the truth syllable data, and the sample speech feature.
13. The electronic device according to claim 9, wherein determining the text data comprises: determining preset text data corresponding to the syllable data based on a correspondence between the syllable data and the text data in the pronouncing dictionary; determining a probability of each piece of preset text data based on the language model; and determining the preset text data with a maximum probability as the text data.
14. The electronic device according to claim 9, further comprising: acquiring sample text corpuses, wherein the sample text corpuses include text corpuses of a first language and text corpuses of a second language; determining a plurality of sample words by segmenting sample text corpuses based on a preset algorithm of word segmentation; determining an occurrence probability that each the sample word occurs in the sample text corpuses; and determining the language model by storing each sample word and the occurrence probability corresponding to each sample word into an initial language model.
15. The electronic device according to claim 14, wherein determining the sample text corpuses comprises: acquiring first text corpuses of the first language, second text corpuses of the second language, and a correspondence between the first text corpuses and the second text corpuses; selecting at least one first text sub-corpus from each of the first text corpuses; determining a correspondence between the first text sub-corpus and the second text corpus; replacing each first text sub-corpus by a second text corpus based on the correspondence between the first text sub-corpuses and the second text corpuses to obtain mixed text corpuses; and determining the mixed text corpuses as the sample text corpuses.
16. The electronic device according to claim 9, wherein the pronouncing dictionary comprises a pronouncing dictionary of a first language and a pronouncing dictionary of a second language.
17. A non-transitory computer readable storage medium for speech recognition, wherein when an instruction in the storage medium is executed by a processor of an electronic device, the electronic device performs: determining speech features of speech data by feature extraction on the speech data; determining syllable data corresponding to each of the speech features based on a plurality of feature extraction layers and a softmax function layer included in an acoustic model, wherein the acoustic model is configured to convert the speech feature into the syllable data; determining text data corresponding to the speech data based on a language model, a pronouncing dictionary and the syllable data, wherein the pronouncing dictionary is configured to convert the syllable data into the text data, and the language model is configured to evaluate the text data; and outputting the text data.
18. The computer readable storage medium according to claim 17, wherein determining the syllable data comprises: inputting each of the speech features to the acoustic model; determining an intermediate speech feature extracted from each of the speech features based on the feature extraction layers; determining, based on the softmax function, a probability that the intermediate speech feature corresponds to each piece of syllable data in the acoustic model; and determining syllable data with a maximum probability as the syllable data.
19. The computer readable storage medium according to claim 17, further comprising: acquiring at least one piece of sample data, wherein each piece of sample data includes a sample speech feature and truth syllable data corresponding to the sample speech feature; determining the acoustic model by training an initial acoustic model based on predicted syllable data and the truth syllable data, wherein the predicted syllable data are obtained by inputting the sample speech feature into the initial acoustic model.
20. The computer readable storage medium according to claim 17, wherein determining the text data comprises: determining preset text data corresponding to the syllable data based on a correspondence between the syllable data and the text data in the pronouncing dictionary; determining a probability of each piece of preset text data based on the language model; and determining the preset text data with a maximum probability as the text data.
</claims>
</document>
