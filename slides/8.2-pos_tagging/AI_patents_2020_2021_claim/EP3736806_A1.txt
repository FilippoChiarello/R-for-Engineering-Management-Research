<document>

<filing_date>
2019-05-31
</filing_date>

<publication_date>
2020-11-11
</publication_date>

<priority_date>
2018-07-05
</priority_date>

<ipc_classes>
G10H1/00,G10L13/033
</ipc_classes>

<assignee>
TENCENT TECHNOLOGY (SHENZHEN) COMPANY
</assignee>

<inventors>
FENG, Qihang
LU, Yi
ZHANG, Zhenyun
ZHENG, Shangzhen
CUI, Lingrui
WU, Xinwan
ZHANG, Ran
WANG, Fangxiao
GUO, Yifan
MEI, Xiao
WANG, Jingxuan
JIANG, Huifu
YU, Le
XIA, Shengfei
ZHOU, Yiting
LIANG, Yidong
</inventors>

<docdb_family_id>
67713854
</docdb_family_id>

<title>
AUDIO SYNTHESIZING METHOD, STORAGE MEDIUM AND COMPUTER EQUIPMENT
</title>

<abstract>
This application relates to an audio synthesis method, a storage medium, and a computer device. The method includes: obtaining a target text; determining a target song according to a selection instruction; synthesizing a self-made song using the target text and tune information of the target song according to a tune control model, the target text being used as the lyrics of the self-made song; and playing the self-made song. The solutions provided in this application improve an audio playback effect.
</abstract>

<claims>
1. An audio synthesis method, comprising: obtaining a target text; determining a target song according to a selection instruction; and synthesizing a self-made song using the target text and tune information of the target song according to a tune control model, the target text being used as the lyrics of the self-made song.
2. The method according to claim 1, wherein the synthesizing a self-made song using the target text and tune information of the target song according to a tune control model comprises: transmitting the target text and a song identifier of the target song to a server, the target text and the song identifier being used for instructing the server to synthesize, after tune information corresponding to the song identifier is found, the self-made song using the target text and the tune information according to the tune control model; and receiving the self-made song returned by the server.
3. The method according to claim 1, wherein the synthesizing a self-made song using the target text and tune information of the target song according to a tune control model comprises: searching for the tune information matching the target song; inputting the target text and the tune information into the tune control model, and determining a tune feature corresponding to each character in the target text according to the tune information by using a hidden layer of the tune control model; and outputting, by using an output layer of the tune control model, the self-made song generated after speech synthesis is performed on each character in the target text according to the corresponding tune feature.
4. The method according to claim 1, wherein the method further comprises an operation of training a tune control model, and the target song is selected from multiple candidate songs, and the tune control model is trained by: collecting candidate song audio corresponding to the candidate songs; determining a candidate song tune corresponding to each candidate song according to the collected candidate song audio; obtaining a text sample; and obtaining the tune control model through training according to the text sample and the candidate song tune.
5. The method according to claim 1, further comprising: determining a target speaking object, wherein the synthesizing a self-made song using the target text and tune information of the target song according to a tune control model comprises: searching for a tune control model corresponding to the target speaking obj ect; and synthesizing the self-made song using the target text and the tune information of the target song, the timbre of the self-made song conforming to the target speaking object, according to the found tune control model.
6. The method according to claim 1, further comprising: configuring the self-made song as background audio; and recording a video based on the background audio.
7. The method according to claim 1, further comprising: receiving a selection instruction; performing, in a case that the target song is determined according to the selection instruction, the operation of synthesizing a self-made song using the target text and tune information of the target song according to a tune control model; and in a case that a target speaking object is determined according to the selection instruction, synthesizing self-made audio using the target text according to a timbre control model matching the target speaking object.
8. The method according to claim 7, wherein the method further comprises an operation of training a timbre control model matching each candidate speaking object, the target speaking object being selected from multiple candidate speaking objects; and
the training a timbre control model matching each candidate speaking object is trained by: collecting an audio material corresponding to each candidate speaking object; determining a phoneme material sequence corresponding to the corresponding candidate speaking object according to each audio material; and obtaining the timbre control model matching each candidate speaking object through training by using the phoneme material sequence corresponding to each candidate speaking object.
9. The method according to claim 7, wherein the synthesizing self-made audio using the target text according to a timbre control model comprises: searching for the timbre control model matching the target speaking object; determining a phoneme sequence corresponding to the target text; synthesizing a self-made speech according to the phoneme sequence by using the timbre control model; and synthesizing the self-made audio according to the self-made speech and a background accompaniment.
10. The method according to claim 7, wherein the receiving a selection instruction comprises: receiving a selection instruction corresponding to a virtual object additional element; and determining the target speaking object corresponding to the virtual object additional element determined according to the selection instruction; and the method further comprises: configuring the self-made audio as background audio; superimposing the virtual object additional element on an acquired image to obtain a video frame; and generating a recorded video using the background audio and the video frame obtained through superimposition.
11. The method according to claim 6, wherein the receiving a selection instruction comprises: receiving a selection instruction for a simulated video call; and determining a picture corresponding to the target speaking object determined according to the selection instruction; and the method further comprises: configuring the self-made audio as background audio; generating a call video frame according to the picture and an acquired image; and generating a recorded video using the background audio and the generated call video frame.
12. A computer-readable storage medium, storing a plurality of computer programs, the computer programs, when executed by a processor, causing the processor to perform a plurality of operations performed in an audio synthesis method: obtaining a target text; determining a target song according to a selection instruction; and synthesizing a self-made song using the target text and tune information of the target song according to a tune control model, the target text being used as the lyrics of the self-made song.
13. A computer device, comprising a memory and a processor, the memory storing a plurality of computer programs, the computer programs, when executed by the processor, causing the processor to perform a plurality of operations performed in an audio synthesis method: obtaining a target text; determining a target song according to a selection instruction; and synthesizing a self-made song using the target text and tune information of the target song according to a tune control model, the target text being used as the lyrics of the self-made song.
14. The computer device according to claim 13, wherein the processor is configured to perform following operations: transmitting the target text and a song identifier of the target song to a server, the target text and the song identifier being used for instructing the server to synthesize, after tune information corresponding to the song identifier is found, the self-made song using the target text and the tune information according to the tune control model; and receiving the self-made song returned by the server.
15. The computer device according to claim 13, wherein the processor is configured to perform following operations: searching for the tune information matching the target song; inputting the target text and the tune information into the tune control model, and determining a tune feature corresponding to each character in the target text according to the tune information by using a hidden layer of the tune control model; and outputting, by using an output layer of the tune control model, the self-made song obtained after speech synthesis is performed on each character in the target text according to the corresponding tune feature.
16. The computer device according to claim 13, wherein the processor is configured to perform following operations: determining a target speaking object; searching for a tune control model corresponding to the target speaking obj ect; and synthesizing the self-made song using the target text and the tune information of the target song, the timbre of the self-made song conforming to the target speaking object, according to the found tune control model.
17. The computer device according to claim 13, wherein the processor is configured to perform following operations: receiving a selection instruction; performing, in a case that the target song is determined according to the selection instruction, the operation of synthesizing a self-made song using the target text and tune information of the target song according to a tune control model; and in a case that a target speaking object is determined according to the selection instruction, synthesizing self-made audio using the target text according to a timbre control model matching the target speaking object.
18. The computer device according to claim 17, wherein the processor is configured to perform following operations: searching for the timbre control model matching the target speaking object; determining a phoneme sequence corresponding to the target text; synthesizing a self-made speech according to the phoneme sequence by using the timbre control model; and synthesizing the self-made audio according to the self-made speech and a background accompaniment.
19. The computer device according to claim 13, wherein the processor is configured to perform following operations: receiving a selection instruction corresponding to a virtual object additional element; and determining the target speaking object corresponding to the virtual object additional element determined according to the selection instruction; and the method further comprises: configuring the self-made audio as background audio; superimposing the virtual object additional element on an acquired image to obtain a video frame; and generating a recorded video using the background audio and the video frame obtained through superimposition.
20. The computer device according to claim 13, wherein the processor is configured to perform following operations: receiving a selection instruction for a simulated video call; and determining a picture corresponding to the target speaking object determined according to the selection instruction; and the method further comprises: configuring the self-made audio as background audio; generating a call video frame according to the picture and an acquired image; and generating a recorded video using the background audio and the generated call video frame.
</claims>
</document>
