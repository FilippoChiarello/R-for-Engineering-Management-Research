<document>

<filing_date>
2020-01-07
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2019-01-07
</priority_date>

<ipc_classes>
G01S13/86,G01S13/89,G01S13/931,G01S7/04,G01S7/41
</ipc_classes>

<assignee>
QUALCOMM
</assignee>

<inventors>
NIESEN, URS
UNNIKRISHNAN, JAYAKRISHNAN
</inventors>

<docdb_family_id>
71403754
</docdb_family_id>

<title>
RESOLUTION OF ELEVATION AMBIGUITY IN ONE-DIMENSIONAL RADAR PROCESSING
</title>

<abstract>
Systems and methods for resolving elevation ambiguity include acquiring, using a 1-D horizontal radar antenna array, a radar frame with range and azimuth information, and predicting a target elevation based on the frame by computing a depth map with a plurality of target depths assigned to corresponding azimuth-elevation pairs. Computing the depth map includes processing the radar frame with an encoder-decoder structured deep convolutional neural network (CNN). The CNN may be trained with a dataset including training radar frames acquired in a number of environments, and compensated ground truth depth maps associated with those environments. The compensated ground truth depth maps may be generated by subtracting a ground-depth from a corresponding ground truth depth map. The ground truth depth maps may be acquired with a 2-D range sensor, such as a LiDAR sensor, a 2-D radar sensor, and/or an IR sensor.
</abstract>

<claims>
WHAT IS CLAIMED IS:
1. A method of resolving elevation ambiguity in the use of one-dimensional (1-D) radar sensor data, comprising:
acquiring, from a radar sensor using a 1-D horizontal antenna array, a radar frame that includes at least range information and azimuth information; and
predicting at least a target elevation based on the radar frame.
2. The method of claim 1, wherein the predicting comprises computing a depth map, wherein:
the depth map includes a plurality of target depths; and
a plurality of target depths is assigned to a corresponding plurality of azimuthelevation pairs.
3. The method of claim 2, wherein computing the depth map includes processing the radar frame with an encoder-decoder structured deep convolutional neural network (CNN).
4. The method of claim 3, wherein the encoder-decoder structured deep CNN is trained using a dataset that includes:
a plurality of training radar frames acquired in one or more of a plurality of particular environments; and
a plurality of compensated ground truth depth maps associated with the one or more of a plurality of particular environments.
5. The method of claim 4, wherein each of the plurality of compensated ground truth depth maps is generated by subtracting a ground-depth from a corresponding ground truth depth map of the plurality of ground truth depth maps.
6. The method of claim 5, wherein the plurality of ground truth depth maps is acquired using a two-dimensional (2-D) range sensor. 7. The method of claim 6, wherein the 2-D range sensor comprises a LiDAR sensor.
8. The method of claim 6, wherein the 2-D range sensor comprises 2-D radar sensor.
9. The method of claim 6, wherein the 2-D range sensor comprises an infra-red (IR) sensor.
10. The method of claim 1, wherein the radar frame further includes Doppler information.
11. An apparatus, comprising:
at least one memory configured to store data and/or instructions; and
at least one processor coupled to the at least one memory, the at least one processor configured to:
acquire, from a radar sensor using a one-dimensional (1-D) horizontal antenna array, a radar frame that includes at least range information and azimuth information; and
predict at least a target elevation based on the radar frame.
12. The apparatus of claim 11, wherein the predicting includes computing a depth map, wherein:
the depth map includes a plurality of target depths; and
a plurality of target depths is assigned to a corresponding plurality of azimuthelevation pairs.
13. The apparatus of claim 12, wherein computing the depth map comprises processing the radar frame with an encoder-decoder structured deep convolutional neural network (CNN).
14. The apparatus of claim 13, wherein the encoder-decoder structured deep CNN is trained using a dataset that includes: a plurality of training radar frames acquired in one or more of a plurality of particular environments; and
a plurality of compensated ground truth depth maps associated with the one or more of a plurality of particular environments.
15. The apparatus of claim 14, wherein each of the plurality of compensated ground truth depth maps is generated by subtracting a ground-depth from a corresponding ground truth depth map of the plurality of ground truth depth maps.
16. The apparatus of claim 15, wherein the plurality of ground truth depth maps is acquired using a two-dimensional (2-D) range sensor.
17. The apparatus of claim 16, wherein the 2-D range sensor comprises one or more of a LiDAR sensor, a 2-D radar sensor, and an infra-red (IR) sensor.
18. The apparatus of claim 11, wherein the radar frame further includes Doppler information.
19. An apparatus, comprising:
means for acquiring, from a radar sensor using a one-dimensional horizontal antenna array, a radar frame that includes at least range information and azimuth information; and
means for predicting at least a target elevation based on the radar frame.
20. The apparatus of claim 19, wherein the means for predicting comprises means for computing a depth map, wherein:
the depth map includes a plurality of target depths; and
a plurality of target depths is assigned to a corresponding plurality of azimuthelevation pairs.
21. The apparatus of claim 20, wherein computing the depth map includes processing the radar frame with an encoder-decoder structured deep convolutional neural network (CNN). 22. The apparatus of claim 21, wherein the encoder-decoder structured deep CNN is trained using a dataset that includes:
a plurality of training radar frames acquired in one or more of a plurality of particular environments; and
a plurality of compensated ground truth depth maps associated with the one or more of a plurality of particular environments.
23. The apparatus of claim 22, wherein each of the plurality of compensated ground truth depth maps is generated by subtracting a ground-depth from a corresponding ground truth depth map of the plurality of ground truth depth maps.
24. The apparatus of claim 23, wherein the plurality of ground truth depth maps is acquired using a two-dimensional (2-D) range sensor.
25. A non-transitory computer-readable medium comprising code, which, when executed by a processor, causes the processor to perform operations to resolve elevation ambiguity in 1-D radar sensor data, the non-transitory computer-readable medium comprising:
code for acquiring, from a radar sensor using a 1 -D horizontal antenna array, a radar frame that includes at least range information and azimuth information; and
code for predicting at least a target elevation based on the radar frame.
26. The non-transitory computer-readable medium of claim 25, wherein the code for predicting comprises code for computing a depth map, wherein:
the depth map includes a plurality of target depths; and
a plurality of target depths is assigned to a corresponding plurality of azimuthelevation pairs.
27. The non-transitory computer-readable medium of claim 26, wherein the code for computing the depth map includes code for processing the radar frame with an encoderdecoder structured deep convolutional neural network (CNN).
28. The non-transitory computer-readable medium of claim 27, wherein the encoderdecoder structured deep CNN is trained using a dataset that includes:
a plurality of training radar frames acquired in one or more of a plurality of particular environments; and
a plurality of compensated ground truth depth maps associated with the one or more of a plurality of particular environments.
29. The non-transitory computer-readable medium of claim 28, wherein each of the plurality of compensated ground truth depth maps is generated by subtracting a grounddepth from a corresponding ground truth depth map of the plurality of ground truth depth maps.
30. The non-transitory computer-readable medium of claim 29, wherein the plurality of ground truth depth maps is acquired using a two-dimensional (2-D) range sensor.
</claims>
</document>
