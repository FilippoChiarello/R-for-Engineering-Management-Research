<document>

<filing_date>
2019-03-30
</filing_date>

<publication_date>
2020-08-20
</publication_date>

<priority_date>
2019-02-15
</priority_date>

<ipc_classes>
G06K9/00,G06K9/32,G06K9/62,G06Q10/06
</ipc_classes>

<assignee>
WIPRO
</assignee>

<inventors>
SIRIPURAPU, RAHUL
TIWARI, ASHWANI
YADHUNANDAN, ULLAM SUBBARAYA
</inventors>

<docdb_family_id>
72040810
</docdb_family_id>

<title>
METHOD AND SYSTEM FOR DETERMINING WORKING CONDITION OF A WORKER PERFORMING QUALITATIVE EVALUATION OF PRODUCTS
</title>

<abstract>
Disclosed herein is method and worker monitoring system for determining working condition of a worker performing qualitative evaluation of products. In some embodiments, a head pose and a position of the worker are detected from plurality of image frames of a predetermined work location of the worker. Thereafter, the head pose is classified into one of a distraction pose and a non-distraction pose upon verifying that the position of worker is within a specified region of interest in the predetermined work location. Finally, working condition of the worker is determined based on classification of the head pose and predetermined operating parameters. In an embodiment, the present disclosure automatically detects when the worker is in a distracted work condition and recommends reverification of the products which were evaluated during the distracted work condition of the worker. Thus, the present disclosure enhances accuracy and reliability of qualitative evaluation of the products.
</abstract>

<claims>
1. A method for determining working condition of a worker performing qualitative evaluation of products, the method comprising: capturing, by a worker monitoring device, video of a predetermined work location, wherein the video is converted into a plurality of image frames; detecting, by the worker monitoring device, a head pose and a position of the worker by analysing the plurality of image frames using one or more predetermined image processing techniques; classifying, by the worker monitoring device, the head pose into one of a distraction pose and a non-distraction pose using pretrained deep learning models, upon verifying the position of the worker within a specified region of interest in the predetermined work location; and determining, by the worker monitoring device, the working condition of the worker based on the classification of the head pose and one or more predetermined operating parameters.
2. The method as claimed in claim 1 comprises training the worker monitoring device with the one or more predetermined image processing techniques for detecting the head pose, wherein the training comprises: receiving a plurality of training images with one or more distinct head poses of the worker; segregating the one or more distinct head poses into one or more classes of head poses based on an angle of the one or more distinct head poses; and annotating the plurality of training images, corresponding to the one or more distinct head poses, to the one or more classes of head poses.
3. The method as claimed in claim 1, wherein classifying the head pose comprises comparing the head pose with one or more classes of head poses and wherein the one or more classes of head poses comprises one of one or more distraction poses and one or more non-distraction poses.
4. The method as claimed in claim 3, wherein the one or more distraction poses are obtained by: extracting one or more distinct head poses of the worker from a plurality of historical image frames of the predetermined work location, using the one or more predetermined image processing techniques; generating a histogram of each of the one or more distinct head poses; identifying a mean frequency value of the one or more distinct head poses from the histogram; and classifying the one or more distinct head poses as the one or more distraction poses based on the mean frequency value.
5. The method as claimed in claim 1, wherein the one or more predetermined operating parameters comprise at least one of a threshold time of distraction, a threshold time of absence of the worker from the predetermined work location and a threshold time period for detecting sleep condition of the worker.
6. The method as claimed in claim 1, wherein the working condition of the worker is at least one of a non-distracted work condition and a distracted work condition, wherein the distracted work condition includes a distraction condition, a sleep condition and a worker absence condition.
7. The method as claimed in claim 6, wherein the sleep condition of the worker is determined by: identifying a plurality of key points, corresponding to the worker, on each of the plurality of image frames, wherein the plurality of key points represent at least one of head of the worker, chest of the worker, shoulder of the worker and arms of the worker; comparing angles between the plurality of key points with corresponding predetermined reference angles for a predetermined time period for determining deviation in the angles; and determining the sleep condition of the worker based on the deviation in the angles.
8. The method as claimed in claim 6, wherein the worker absence condition is determined when position of the worker is not detected within specified region of interest in the plurality of image frames.
9. The method as claimed in claim 6 comprises: generating an alarm event corresponding to the distracted work condition of the worker; combining a plurality of image frames corresponding to the distracted work condition of the worker into a video; and transmitting the alarm event and the video to predetermined worker management personnel for notifying the distracted work condition of the worker.
10. The method as claimed in claim 9, wherein the alarm event comprises information related to at least one of time of occurrence of the distracted work condition, duration of the distracted work condition, predetermined work location of the worker and product identifiers corresponding to one or more products evaluated by the worker during the distracted work condition.
11. A worker monitoring device comprising: a processor; and a memory, communicatively coupled to the processor, wherein the memory stores processor-executable instructions, which on execution, cause the processor to: capture video of a predetermined work location, wherein the video is converted into a plurality of image frames; detect a head pose and a position of the worker by analysing the plurality of image frames using one or more predetermined image processing techniques; classify the head pose into one of a distraction pose and a non-distraction pose using pretrained deep learning models, upon verifying the position of the worker within a specified region of interest in the predetermined work location; and determine the working condition of the worker based on the classification of the head pose and one or more predetermined operating parameters.
12. The worker monitoring device as claimed in claim 11, wherein to train the worker monitoring system with the one or more predetermined image processing techniques for detecting the head pose, the processor is configured to: receive a plurality of training images with one or more distinct head poses of the worker; segregate the one or more distinct head poses into one or more classes of head poses based on an angle of the one or more distinct head poses; and annotate the plurality of training images, corresponding to the one or more distinct head poses, to the one or more classes of head poses.
13. The worker monitoring device as claimed in claim 11, wherein the processor classifies the head pose comprises by comparing the head pose with one or more classes of head poses and wherein the one or more classes of head poses comprises one of one or more distraction poses and one or more non-distraction poses.
14. The worker monitoring device as claimed in claim 13, wherein to obtain the one or more distraction poses, the processor is configured to: extract one or more distinct head poses of the worker from a plurality of historical image frames of the predetermined work location, using the one or more predetermined image processing techniques; generate a histogram of each of the one or more distinct head poses; identify a mean frequency value of the one or more distinct head poses from the histogram; and classify the one or more distinct head poses as the one or more distraction poses based on the mean frequency value.
15. The worker monitoring device as claimed in claim 11, wherein the one or more predetermined operating parameters comprise at least one of a threshold time of distraction, a threshold time of absence of the worker from the predetermined work location and a threshold time period to detect sleep condition of the worker.
16. The worker monitoring device as claimed in claim 11, wherein the working condition of the worker is at least one of a non-distracted work condition and a distracted work condition, wherein the distracted work condition includes a distraction condition, a sleep condition and a worker absence condition.
17. The worker monitoring device as claimed in claim 16, wherein to determine the sleep condition of the worker, the processor is configured to: identify a plurality of key points, corresponding to the worker, on each of the plurality of image frames, wherein the plurality of key points represent at least one of head of the worker, chest of the worker, shoulder of the worker and arms of the worker; compare angles between the plurality of key points with corresponding predetermined reference angles for a predetermined time period to determine deviation in the angles; and determine the sleep condition of the worker based on the deviation in the angles.
18. The worker monitoring device as claimed in claim 16, wherein the processor determines the worker absence condition when position of the worker is not detected within specified region of interest in the plurality of image frames.
19. The worker monitoring device as claimed in claim 16, wherein the processor is further configured to: generate an alarm event corresponding to the distracted work condition of the worker; combine a plurality of image frames corresponding to the distracted work condition of the worker into a video; and transmit the alarm event and the video to predetermined worker management personnel to notify the distracted work condition of the worker.
20. The worker monitoring device as claimed in claim 19, wherein the alarm event comprises information related to at least one of time of occurrence of the distracted work condition, duration of the distracted work condition, predetermined work location of the worker and product identifiers corresponding to one or more products evaluated by the worker during the distracted work condition.
21. A non-transitory computer readable medium including instructions stored thereon that when processed by at least one processor cause a worker monitoring device to perform operations comprising: capturing video of a predetermined work location, wherein the video is converted into a plurality of image frames; detecting a head pose and a position of the worker by analysing the plurality of image frames using one or more predetermined image processing techniques; classifying the head pose into one of a distraction pose and a non-distraction pose using pretrained deep learning models, upon verifying the position of the worker within a specified region of interest in the predetermined work location; and determining the working condition of the worker based on the classification of the head pose and one or more predetermined operating parameters.
</claims>
</document>
