<document>

<filing_date>
2019-11-26
</filing_date>

<publication_date>
2020-03-26
</publication_date>

<priority_date>
2017-09-05
</priority_date>

<ipc_classes>
G06N3/04,G06N3/063,G06N3/08
</ipc_classes>

<assignee>
PANASONIC INTELLECTUAL PROPERTY
</assignee>

<inventors>
RIGAZIO, LUCA
GUDOVSKIY, DENIS A.
</inventors>

<docdb_family_id>
65634935
</docdb_family_id>

<title>
EXECUTION METHOD, EXECUTION DEVICE, LEARNING METHOD, LEARNING DEVICE, AND RECORDING MEDIUM FOR DEEP NEURAL NETWORK
</title>

<abstract>
Executing a deep neural network by obtaining, during deep neural network inference, a binary intermediate feature map in binary representation by converting a floating-point or fixed-point intermediate feature map into a binary vector using a first transformation module; generating a compressed feature map by compressing the binary intermediate feature map using a nonlinear dimensionality reduction layer; storing the compressed feature map into memory; reconstructing the binary intermediate feature map by decompressing the compressed feature map read from the memory using a reconstruction layer corresponding to the nonlinear dimensionality reduction layer; and converting the reconstructed binary intermediate feature map into a floating-point or fixed-point intermediate feature map using a second transformation module.
</abstract>

<claims>
1. An execution method for a deep neural network, the execution method comprising: obtaining, during deep neural network inference, a binary intermediate feature map in binary representation by converting a floating-point or fixed-point intermediate feature map into a binary vector using a first transformation module; generating a compressed feature map by compressing the binary intermediate feature map using a nonlinear dimensionality reduction layer; storing the compressed feature map into memory; reconstructing the binary intermediate feature map by decompressing the compressed feature map read from the memory using a reconstruction layer corresponding to the nonlinear dimensionality reduction layer; and converting the reconstructed binary intermediate feature map into a floating-point or fixed-point intermediate feature map using a second transformation module.
2. The execution method according to claim 1, wherein the nonlinear dimensionality reduction layer is a single projection convolved layer or a sequence of projection convolved layers, and the reconstruction layer is a single reconstruction convolved layer or a sequence of reconstruction convolved layers.
3. A backpropagation-based learning method for the deep neural network executed using the execution method according to claim 1, the learning method comprising: applying an analytical derivative of the first transformation module and the second transformation module to a gradient for a next layer among layers included in the deep neural network to generate a gradient for a previous layer among the layers included in the deep neural network; updating a weight and a bias based on the gradient generated for the previous layer; and initializing a weight for the nonlinear dimensionality reduction layer and a weight for the reconstruction layer, based on an identity mapping function.
4. An execution device for a deep neural network, the execution device comprising: a processor that executes deep neural network inference, wherein the processor: obtains a binary intermediate feature map in binary representation by converting a floating-point or fixed-point intermediate feature map into a binary vector using a first transformation module; generates a compressed feature map by compressing the binary intermediate feature map using a nonlinear dimensionality reduction layer; stores the compressed feature map into memory; reconstructs the binary intermediate feature map by decompressing the compressed feature map read from the memory using a reconstruction layer corresponding to the nonlinear dimensionality reduction layer; and converts the reconstructed binary intermediate feature map into a floating-point or fixed-point intermediate feature map using a second transformation module.
5. A learning device for a deep neural network, the learning device comprising: a processor that executes backpropagation-based learning by the deep neural network executed using the execution method according to claim 1, wherein the processor: applies an analytical derivative of the first transformation module and the second transformation module to a gradient for a next layer among layers included in the deep neural network to generate a gradient for a previous layer among the layers included in the deep neural network; updates a weight and a bias based on the gradient generated for the previous layer; and initializes a weight for the nonlinear dimensionality reduction layer and a weight for the reconstruction layer, based on an identity mapping function.
6. A non-transitory computer-readable recording medium for use in a computer, the recoding medium having a computer program recorded thereon for causing the computer to execute the execution method according to claim 1.
7. A non-transitory computer-readable recording medium for use in a computer, the recoding medium having a computer program recorded thereon for causing the computer to execute the learning method according to claim 3.
</claims>
</document>
