<document>

<filing_date>
2016-04-05
</filing_date>

<publication_date>
2020-02-04
</publication_date>

<priority_date>
2015-10-08
</priority_date>

<ipc_classes>
G06F1/10,G06F15/82,G06F7/483,G06F7/499,G06F9/30,G06F9/32,G06F9/38,G06F9/445,G06N3/04,G06N3/063,G06N3/08
</ipc_classes>

<assignee>
VIA ALLIANCE SEMICONDUCTOR COMPANY
</assignee>

<inventors>
HENRY, G. GLENN
O'BRIEN, KYLE T.
PARKS, TERRY
</inventors>

<docdb_family_id>
58498604
</docdb_family_id>

<title>
Neural network unit with output buffer feedback for performing recurrent neural network computations
</title>

<abstract>
A neural network unit has at least one RAM, an output buffer and an array of neural processing units that: read first time step context layer node values from the output buffer; read second time step input layer node values from the RAM; generate second time step hidden layer node values based on the read input and context layer node values; output the hidden layer node values to the output buffer rather than to the RAM; read the hidden layer node values from the output buffer; generate second time step context layer node values based on the read hidden layer node values; output the context layer node values to the output buffer rather than to the RAM; generate output layer node values using the hidden layer node values; write the output layer node values to the RAM; and repeat for a sequence of time steps.
</abstract>

<claims>
1. A neural network unit (NNU) that performs calculations for a recurrent neural network (RNN) having input layer nodes, hidden layer nodes, output layer nodes and context layer nodes, wherein each of the input layer nodes, hidden layer nodes, output layer nodes, and context layer nodes is implemented in circuitry and configured to perform an arithmetic operation, the NNU comprising: an array of neural processing units (NPU), at least one random access memory (RAM), and an output buffer, the array of NPUs: (a) read, from the output buffer, values of the context layer nodes associated with a first time step; (b) read, from the RAM, values of the input layer nodes associated with a second time step subsequent to the first time step; (c) generate values of the hidden layer nodes associated with the second time step based on the values of the input layer nodes read from the RAM and the values of the context layer nodes read from the output buffer; (d) output the hidden layer node values associated with the second time step to the output buffer rather than to the RAM; (e) read, from the output buffer, the hidden layer node values associated with the second time step; (f) generate values of the context layer nodes associated with the second time step based on the hidden layer node values read from the output buffer; (g) output the context layer node values associated with the second time step to the hidden layer nodes rather than to the RAM; (h) generate values of the output layer nodes associated with the second time step using the hidden layer node values associated with the second time step; (i) write the output layer node values associated with the second time step to the RAM; and (j) repeat (a) through (i) for a sequence of time steps.
2. The NNU of claim 1, further comprising: the array of NPUs comprises N NPUs, each comprising a multiplexed register, an arithmetic unit, and an accumulator circuit, wherein the accumulator circuit has an output and the arithmetic unit that performs operations on inputs, and wherein N is an integer value; the arithmetic unit receives an output of the multiplexed register and an output of the accumulator circuit, and the arithmetic unit generates a result provided to the accumulator circuit; the output buffer is N words wide and is configured to hold N of the context/hidden layer node values; and the N multiplexed registers are arranged to form an N-word hardware rotater that receives the N words of the output buffer.
3. The NNU of claim 2, further comprising: to said (e) read, from the output buffer, the hidden layer node values associated with the second time step, the N NPUs read the N values of the hidden layer nodes from the output buffer into the rotater; the N NPUs read, from the RAM, weight values associated with connections between the hidden layer nodes and the output layer nodes; and to said (f) generate values of the context layer nodes associated with the second time step based on the hidden layer node values read from the output buffer, the N NPUs: rotate the N values of the hidden layer nodes through the rotater for provision to the arithmetic unit of each of the N NPUs; multiply, by each of the N arithmetic units, each of the N rotated hidden layer node values by one of the weight values to generate N respective products; and accumulate, into each of the N accumulator circuits, the N respective products to generate a result.
4. The NNU of claim 3, further comprising: a plurality of activation function units (AFU) that receive the accumulator circuit output of associated one or more of the NPUs and perform an activation function on the accumulator circuit output, wherein each of the AFUs is implemented in circuitry.
5. The NNU of claim 4, further comprising: to said (h) generate values of the output layer nodes associated with the second time step using the hidden layer node values associated with the second time step, the plurality of AFUs: for each result of the N results of the accumulated respective N respective products received from the accumulator circuit output of each of the N NPUs, perform an activation function on the result to generate a respective output layer node value.
6. The NNU of claim 4, further comprising: the plurality of AFUs is N, and each of the N AFUs is coupled to receive the accumulator circuit output of a respective one of the N NPUs and to provide its result of the activation function to a respective one of the N words of the output buffer.
7. The NNU of claim 2, further comprising: to said (a) read, from the output buffer, values of the context layer nodes associated with a first time step, the N NPUs read the N values of the context layer nodes from the output buffer into the rotater; and to said (c) generate values of the hidden layer nodes associated with the second time step based on the values of the input layer nodes read from the RAM and the values of the context layer nodes read from the output buffer, the N NPUs: rotate the N values of the context layer nodes through the rotater for provision to the arithmetic unit of each of the N NPUs; and accumulate, into each of the N accumulator circuits, the N values of the context layer nodes.
8. The NNU of claim 7, further comprising: to said (b) read, from the RAM, values of the input layer nodes associated with a second time step subsequent to the first time step, the N NPUs read the N values of the input layer nodes nodes from the RAM into the rotater; the N NPUs read, from the RAM, weight values associated with connections between the input layer nodes and the hidden layer nodes; and to said (c) generate values of the hidden layer nodes associated with the second time step based on the values of the input layer nodes read from the RAM and the values of the context layer nodes read from the output buffer, the N NPUs further: rotate the N values of the input layer nodes through the rotater for provision to the arithmetic unit of each of the N NPUs; multiply, by each of the N arithmetic units, each of the N rotated input layer node values by one of the weight values to generate N respective products; and accumulate, into each of the N accumulator circuits, the N respective products along with the accumulated N values of the context layer nodes.
9. The NNU of claim 1, further comprising: a program memory that holds instructions of a non-architectural program; a sequencer circuit that fetches the non-architectural program instructions from the program memory and generates micro-operations to control the array of NPUs to perform (a) through (j).
10. The NNU of claim 9, further comprising: the NNU is comprised in a processor that fetches and executes instructions of an architectural program of the processor.
11. The NNU of claim 10, further comprising: the output buffer is accessible by the non-architectural program and is not accessible by the architectural program.
12. The NNU of claim 10, further comprising: the at least one memory is accessible by the architectural program to write the values of the input layer nodes associated with the sequence of time steps and to read the values of the output layer nodes associated with the sequence of time steps; and the program memory is accessible by the architectural program to write the non-architectural program to the program memory.
13. A method for operating a neural network unit (NNU) that performs calculations for a recurrent neural network (RNN) having input layer nodes, hidden layer nodes, output layer nodes and context layer nodes, the NNU having an array of neural processing units (NPU), at least one random access memory (RAM), and an output buffer, wherein each of the input layer nodes, hidden layer nodes, output layer nodes, and context layer nodes is implemented in circuitry and configured to perform an arithmetic operation, the method comprising: (a) reading, from the output buffer, values of the context layer nodes associated with a first time step; (b) reading, from the RAM, values of the input layer nodes associated with a second time step subsequent to the first time step; (c) generating values of the hidden layer nodes associated with the second time step based on the values of the input layer nodes read from the RAM and the values of the context layer nodes read from the output buffer; (d) outputting the hidden layer node values associated with the second time step to the output buffer rather than to the RAM; (e) reading, from the output buffer, the hidden layer node values associated with the second time step; (f) generating values of the context layer nodes associated with the second time step based on the hidden layer node values read from the output buffer; (g) outputting the context layer node values associated with the second time step to the hidden layer nodes rather than to the RAM; (h) generating values of the output layer nodes associated with the second time step using the hidden layer node values associated with the second time step; (i) writing the output layer node values associated with the second time step to the RAM; and (j) repeating (a) through (i) for a sequence of time steps.
14. The method of claim 13, further comprising: the array of NPUs comprises N NPUs, each comprising a multiplexed register, an arithmetic unit, and an accumulator circuit, wherein the accumulator circuit has an output and the arithmetic unit that performs operations on inputs, and wherein N is an integer value; the arithmetic unit receives an output of the multiplexed register and an output of the accumulator circuit, and the arithmetic unit generates a result provided to the accumulator circuit; the output buffer is N words wide and is configured to hold N of the context/hidden layer node values; the N multiplexed registers are arranged to form an N-word hardware rotater that receives the N words of the output buffer; said (e) reading, from the output buffer, the hidden layer node values associated with the second time step comprises: reading, by the N NPUs, the N values of the hidden layer nodes from the output buffer into the rotater; reading, by the N NPUs from the RAM, weight values associated with connections between the hidden layer nodes and the output layer nodes; and said (f) generating values of the context layer nodes associated with the second time step based on the hidden layer node values read from the output buffer comprises: by the N NPUs: rotating the N values of the hidden layer nodes through the rotater for provision to the arithmetic unit of each of the N NPUs; multiplying, by each of the N arithmetic unit, each of the N rotated hidden layer node values by one of the weight values to generate N respective products; and accumulating, into each of the N accumulator circuits, the N respective products to generate a result.
15. The method of claim 14, further comprising: the apparatus includes a plurality of activation function units (AFU) that receive the accumulator circuit output of associated one or more of the NPUs and perform an activation function on the accumulator circuit output, wherein each of the AFUs is implemented in circuitry.
16. The method of claim 15, further comprising: said (h) generating values of the output layer nodes associated with the second time step using the hidden layer node values associated with the second time step, comprises, by the plurality of AFUs: for each result of the N results of the accumulated respective N respective products received from the accumulator circuit output of each of the N NPUs, performing an activation function on the result to generate a respective output layer node value.
17. The method of claim 14, further comprising: said (a) reading, from the output buffer, values of the context layer nodes associated with a first time step, comprises: reading, by the N NPUs, the N values of the context layer nodes from the output buffer into the rotater; and said (c) generating values of the hidden layer nodes associated with the second time step based on the values of the input layer nodes read from the RAM and the values of the context layer nodes read from the output buffer comprises: by the N NPUs: rotating the N values of the context layer nodes through the rotater for provision to the arithmetic unit of each of the N NPUs; and accumulating, into each of the N accumulator circuits, the N values of the context layer nodes.
18. A computer program product encoded in at least one non-transitory computer usable medium for use with a computing device, the computer program product comprising: computer usable program code embodied in said medium, for specifying a neural network unit (NNU) that performs calculations for a recurrent neural network (RNN) having input layer nodes, hidden layer nodes, output layer nodes and context layer nodes, wherein each of the input layer nodes, hidden layer nodes, output layer nodes, and context layer nodes is implemented in circuitry and configured to perform an arithmetic operation, the computer usable program code comprising: first program code for specifying an array of neural processing units (NPU), at least one random access memory (RAM), and an output buffer; and the array of NPUs: (a) read, from the output buffer, values of the context layer nodes associated with a first time step; (b) read, from the RAM, values of the input layer nodes associated with a second time step subsequent to the first time step; (c) generate values of the hidden layer nodes associated with the second time step based on the values of the input layer nodes read from the RAM and the values of the context layer nodes read from the output buffer; (d) output the hidden layer node values associated with the second time step to the output buffer rather than to the RAM; (e) read, from the output buffer, the hidden layer node values associated with the second time step; (f) generate values of the context layer nodes associated with the second time step based on the hidden layer node values read from the output buffer; (g) output the context layer node values associated with the second time step to the hidden layer nodes rather than to the RAM; (h) generate values of the output layer nodes associated with the second time step using the hidden layer node values associated with the second time step; (i) write the output layer node values associated with the second time step to the RAM; and (j) repeat (a) through (i) for a sequence of time steps.
19. The computer program product of claim 18, further comprising: the array of NPUs comprises N NPUs, each comprising a multiplexed register, an arithmetic unit, and an accumulator circuit, wherein the accumulator circuit has an output and the arithmetic unit that performs operations on inputs, and wherein N is an integer value; the arithmetic unit receives an output of the multiplexed register and an output of the accumulator circuit, and the arithmetic unit generates a result provided to the accumulator circuit; the output buffer is N words wide and is configured to hold N of the context/hidden layer node values; and the N multiplexed registers are arranged to form an N-word hardware rotater that receives the N words of the output buffer.
</claims>
</document>
