<document>

<filing_date>
2018-04-27
</filing_date>

<publication_date>
2020-08-11
</publication_date>

<priority_date>
2018-04-27
</priority_date>

<ipc_classes>
A61B34/20,A61B34/30,A61B5/055,A61B90/00
</ipc_classes>

<assignee>
MEDTRONIC NAVIGATION
</assignee>

<inventors>
DATTERI, RYAN
KEMP, JUSTIN
MAHENDRA, NIKHIL
PAITEL, YVAN
RONEN, SHAI
VIGH, ROWENA
WALD, ANDREW
</inventors>

<docdb_family_id>
67002342
</docdb_family_id>

<title>
System and method for a tracked procedure
</title>

<abstract>
Disclosed is a navigation system. The navigation system may be used to at least assist in a procedure. The system may assist in delineating objects and/or determining physical boundaries of image elements. The system may assist in planning and/or a workflow of the procedure.
</abstract>

<claims>
1. A system configured to determine boundaries of selected items within an image by training the system, comprising: a memory system having stored thereon a machine learning process; a processor system configured to: access the machine learning process; determine a trained model based on the machine learning process; access at least one image of an imaged subject; evaluate the at least one image based on the determined trained model; and determine at least one edge of a physical element within the at least one image; and a display device configured to display a representation of the determined at least one edge of the physical element; wherein the machine learning process is a deep convolutional neural network that includes, a plurality of layers, wherein a subsequent layer is deconvoluted into a previous layer; a residual block from the previous layer is added to an output of the subsequent layer in a synthesis process.
2. The system of claim 1, wherein the representation of the determined at least one edge of the physical element includes an icon displayed on the display device to represent the physical boundary of the physical element.
3. The system of claim 1, wherein the at least one image is based on at least one cone beam image.
4. The system of claim 3, wherein the at least one image is a three-dimensional reconstruction of the imaged subject based on the cone beam image.
5. The system of claim 1, wherein the deep convolutional neural network includes a weighted loss function to achieve an accurate segmentation of the at least one image including the determined at least one edge of the physical element.
6. The system of claim 5, wherein the deep convolutional neural network further includes a selected number of filters.
7. The system of claim 6, wherein the accurate segmentation includes segmentation in the at least one image with 2,400 being the selected number of filters.
8. The system of claim 7, wherein the accurate segmentation includes a three-dimensional image output delineating all of the vertebrae in the at least one image.
9. The system of claim 1, wherein an accurate segmentation of the at least one image is of at least one of (i) at least one vertebra, (ii) a portion of at least one vertebra, (iii) a plurality of vertebrae, (iv) portions of a plurality of vertebrae.
10. A system configured to determine boundaries of selected items within an image by training the system, comprising: a memory system having stored thereon a convolutional neural network; a processor system configured to: access the convolutional neural network; access an image data based on cone beam image data that is reconstructed into a three-dimensional image; evaluate the image based on the convolutional neural network including (i) a plurality of layers, wherein a subsequent layer is deconvoluted into a previous layer and (ii) a residual block from the previous layer is added to an output of the subsequent layer in a synthesis process; determine an edge of a physical element represented in the image data based on the evaluation of the image data with the convolutional neural network; and a display device to display a representation of the determined edge of the physical element; wherein the determined edge includes a three-dimensional representation of the physical element.
11. The system of claim 10, wherein the physical element is spinal vertebrae and the image data includes image data of a spine of a patient.
12. The system of claim 11, wherein the convolutional neural network includes more than two layers.
13. The system of claim 12, wherein a number of filters is selected in the convolutional neural network.
14. The system of claim 13, wherein the convolutional neural network is operable to determine a segmentation based on a probability map of the image.
15. The system of claim 10, wherein the a processor system is further configured to evaluate the image based on the convolutional neural network including (i) a weighted loss function relating to the activation function.
16. A method of determining boundaries of selected items within an image by a trained system, comprising: inputting a neural network including a plurality of layers including (i) a convolution process and (ii) at least one deconvolution process between separate layers of the plurality of layers wherein a subsequent layer is deconvoluted into a previous layer and a residual block from the previous layer is added to an output of a subsequent layer in a synthesis process; training the inputted neural network with a selected training data; outputting a trained model; accessing an image data based on cone beam image data that is reconstructed into a three-dimensional image with a processor system; analyzing the accessed image data with the inputted neural network and the trained model; determining an edge of a physical element represented in the image data based on the analysis; and outputting a representation of the determined edge of the physical element; wherein the determined edge includes a three-dimensional representation of the physical element.
17. The method of claim 16, further comprising: displaying with a display device the representation of the determined edge of the physical element.
18. The method of claim 17, further comprising: overlaying the representation on the reconstructed three-dimensional image.
19. The method of claim 17, further comprising: determining a physical dimension of the physical element.
20. The method of claim 16, further comprising: creating the neural network; and saving the created neural network.
21. The method of claim 20, wherein the neural network is a convolutional neural network.
22. The method of claim 21, wherein creating the neural network includes: applying a limited number of filters, and applying a weighted loss function.
23. The method of claim 22, further comprising: saving the trained model for the analyzing the accessed image data with the inputted neural network and the trained model.
24. The method of claim 22, wherein applying the limited number of filters includes applying 2,400 filters to generate the trained model.
</claims>
</document>
