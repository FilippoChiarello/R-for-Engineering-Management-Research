<document>

<filing_date>
2019-08-26
</filing_date>

<publication_date>
2020-02-27
</publication_date>

<priority_date>
2018-08-24
</priority_date>

<ipc_classes>
G06N3/04,G06N3/063,G06N3/08
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
SAMSUNG ELECTRONICS COMPANY
SEOUL NATIONAL UNIVERSITY
</assignee>

<inventors>
CHOI, KI YOUNG
LEE, GUNHEE
KIM, NAMHYUNG
LEE, SEUNGWON
YU, JOONSANG
PARK, HANMIN
</inventors>

<docdb_family_id>
69583746
</docdb_family_id>

<title>
METHOD OF ACCELERATING TRAINING PROCESS OF NEURAL NETWORK AND NEURAL NETWORK DEVICE THEREOF
</title>

<abstract>
A method of accelerating a training process of a neural network includes acquiring activations used in the training process and a bit-vector corresponding to the activations, selecting activations requiring an operation from among the acquired activations by using the bit-vector, and performing backward propagation using the selected activations and filters corresponding to the selected activations.
</abstract>

<claims>
1. A method of accelerating a training process of a neural network, the method comprising: acquiring activations used in the training process and a bit-vector corresponding to the activations; selecting activations requiring an operation from among the acquired activations by using the bit-vector; and performing backward propagation using the selected activations and filters corresponding to the selected activations.
2. The method of claim 1, wherein the selecting comprises selecting activations representing a non-zero value from among the acquired activations by interpreting bits included in the bit-vector.
3. The method of claim 1, wherein the selecting comprises selecting the activations requiring the operation from among the acquired activations, in response to a number of selected activations being less than N, where N is a number of multipliers in a single neural functional unit.
4. The method of claim 1, wherein the selecting comprises selecting the activations requiring the operation from among the acquired activations, in response to interpretation of all bits in the bit-vector not being completed.
5. The method of claim 1, further comprising generating the bit-vector by performing forward propagation on the neural network.
6. The method of claim 1, wherein the performing of the backward propagation comprises performing a multiplication and accumulation operation on the selected activations and the filters corresponding to the selected activations.
7. The method of claim 6, wherein the performing of the backward propagation comprises updating the acquired activations using a result of the multiplication and accumulation operation.
8. The method of claim 1, wherein the filters corresponding to the selected activations are obtained by rearranging filters used in forward propagation where the selected activations are generated.
9. The method of claim 1, further comprising updating filters used in forward propagation using a result of performing the backward propagation.
10. A non-transitory computer-readable recording medium that, when executed by a processor, cause the processor to perform the method of claim 1.
11. A neural network device comprising: a processor configured to read activations used in a training process and a bit-vector corresponding to the activations from the memory; select activations requiring an operation from among the read activations by using the bit-vector; read filters corresponding to the selected activations from the memory; and perform backward propagation using the selected activations and the read filters.
12. The neural network device of claim 11, wherein the processor is further configured to select activations representing a non-zero value from among the read activations by interpreting bits included in the bit-vector.
13. The neural network device of claim 11, wherein the processor is further configured to select the activations requiring the operation from among the read activations, in response to a number of selected activations being less than N, where N is a number of multipliers in a single neural functional unit.
14. The neural network device of claim 11, wherein the processor is further configured to select the activations requiring the operation from among the read activations, in response to interpretation of all bits in the bit-vector not being completed.
15. The neural network device of claim 11, wherein the processor is further configured to generate the bit-vector by performing forward propagation on the neural network.
16. The neural network device of claim 11, wherein the processor is further configured to perform a multiplication and accumulation operation on the selected activations and the filters corresponding to the selected activations.
17. The neural network device of claim 16, wherein the processor is further configured to update the acquired activations using a result of the multiplication and accumulation operation.
18. The neural network device of claim 11, wherein the filters corresponding to the selected activations are obtained by rearranging filters used in forward propagation where the selected activations are generated.
19. The neural network device of claim 11, wherein the processor is further configured to update filters used in forward propagation using a result of performing the backward propagation.
20. The neural network device of claim 11, wherein the processor is further configured to record the updated filters in a memory.
</claims>
</document>
