<document>

<filing_date>
2018-10-01
</filing_date>

<publication_date>
2020-09-29
</publication_date>

<priority_date>
2016-08-23
</priority_date>

<ipc_classes>
G06F21/32,G06K9/00,G06K9/50,G06N3/04,G06N3/08,G06Q20/40
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
KIM, JUNG BAE
YOO, BYUNGIN
CHOI, CHANG KYU
HAN, JAE JOON
LEE, CHANGKYO
KWAK, YOUNGJUN
SON, JINWOO
</inventors>

<docdb_family_id>
59631524
</docdb_family_id>

<title>
Liveness test method and apparatus
</title>

<abstract>
A liveness test method and apparatus is disclosed. A processor implemented liveness test method includes extracting an interest region of an object from a portion of the object in an input image, performing a liveness test on the object using a neural network model-based liveness test model, the liveness test model using image information of the interest region as provided first input image information to the liveness test model and determining liveness based at least on extracted texture information from the information of the interest region by the liveness test model, and indicating a result of the liveness test.
</abstract>

<claims>
1. A processor implemented liveness test method, the liveness test method comprising: extracting an interest region in a face region, of a face of a user, from an input image; and performing a liveness test on the face using a neural network model-based liveness test model, wherein a first image information of the interest region is provided to the liveness test model, and a second image information of the input image or a portion of the input image is provided to the liveness test model.
2. The method of claim 1, wherein the extracting comprises extracting a portion including at least one of an eye, a nose, and lips from the face region of the user in the input image, as the interest region.
3. The method of claim 1, wherein the extracting comprises: detecting facial landmarks in the face region; detecting the face region in the input image based on the facial landmarks; and extracting the interest region based on facial landmarks detected in the face region.
4. The method of claim 3, wherein the face region is smaller than an entire region of the input image and is greater than the interest region.
5. The method of claim 1, wherein the liveness test model outputs a reference value to determine a liveness based on local texture information indicated in the interest region and global shape information indicated in the input image or the portion of the input image.
6. The method of claim 1, wherein the liveness test model includes a recurrent connection structure that is configured so a determination of liveness of the face, with respect to the input image being a current frame, is dependent on a result of a liveness test of the liveness test model obtained with respect to a previous frame.
7. The method of claim 1, wherein the portion of the input image is corresponding to the face region.
8. The method of claim 1, further comprising selectively controlling access to functions of a computing apparatus based on results of the performed liveness test.
9. The method of claim 1, wherein a resolution of the first image information of the interest region is different from a resolution of the second image information of the input image.
10. A processor implemented liveness test method, the liveness test method comprising: extracting an interest region in a face region of a user from an input image; and performing a liveness test on the face using a neural network model-based liveness test model, wherein a first image information of the interest region is provided to the liveness test model, and a second image information of the input image or a portion of the input image is provided to the liveness test model, and wherein the first image information is provided to a first input layer of the liveness test model, and the second image information is provided to a second input layer of the liveness test model.
11. A processor implemented liveness test method, the liveness test method comprising: extracting an interest region in a face region, of a face of a user, from an input image; performing a liveness test on the face using a neural network model-based liveness test model, wherein a first image information of the interest region is provided to the liveness test model, and a second image information of the input image or a portion of the input image is provided to the liveness test model; and adjusting a size of the input image to be the same as a size of the interest region, wherein a resolution of the interest region is higher than a resolution of the input image of which the size is adjusted, and wherein image information of the input image of which the size is adjusted is corresponding to the second image information.
12. A non-transitory computer-readable storage medium storing instructions, that when executed by a processor, cause the processor to perform the method of claim 1.
13. A liveness test computing apparatus comprising: one or more processors configured to: extract an interest region in a face region, of a face of a user, from an input image; and perform a liveness test on the face using a neural network model-based liveness test model, wherein a first image information of the interest region is provided to the liveness test model, and a second image information of the input image or a portion of the input image is provided to the liveness test model.
14. The liveness test computing apparatus of claim 13, wherein, for the extracting of the interest region, the one or more processors are further configured to extract portion including at least one of an eye, a nose, and lips from the face region of the user in the input image, as the interest region.
15. The liveness test computing apparatus of claim 13, wherein the first image information is provided to a first input layer of the liveness test model, and the second image information is provided to a second input layer of the liveness test model.
16. The liveness test computing apparatus of claim 13, wherein the liveness test model outputs a reference value to determine a liveness based on local texture information indicated in the interest region and global shape information indicated in the input image or the portion of the input image.
17. The liveness test computing apparatus of claim 13, wherein the liveness test model includes a recurrent connection structure that is configured so a determining of liveness of the face, with respect to the input image being a current frame, is dependent on results of a liveness test of the liveness test model obtained with respect to a previous frame.
18. The liveness test computing apparatus of claim 13, wherein the portion of the input image is corresponding to the face region.
19. The liveness test computing apparatus of claim 13, wherein the one or more processors are further configured to selectively control access to functions of a computing apparatus based on results of the performed liveness test.
20. A liveness test computing apparatus comprising: one or more processors configured to: extract an interest region in a face region, of a face of a user, from an input image; perform a liveness test on the face using a neural network model-based liveness test model, wherein a first image information of the interest region is provided to the liveness test model, and a second image information of the input image or a portion of the input image is provided to the liveness test model; and adjust a size of the input image to be the same as a size of the interest region, wherein a resolution of the interest region is higher than a resolution of the input image of which the size is adjusted, and wherein image information of the input image of which the size is adjusted is corresponding to the second image information.
</claims>
</document>
