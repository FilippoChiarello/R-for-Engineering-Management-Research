<document>

<filing_date>
2020-06-18
</filing_date>

<publication_date>
2021-01-13
</publication_date>

<priority_date>
2019-07-11
</priority_date>

<ipc_classes>
G06T5/00,G06T7/194
</ipc_classes>

<assignee>
GUANGDONG OPPO MOBILE TELECOMMUNICATIONS CORPORATION
</assignee>

<inventors>
KANG, Jian
</inventors>

<docdb_family_id>
68252697
</docdb_family_id>

<title>
DEPTH IMAGE PROCESSING METHOD AND APPARATUS, AND ELECTRONIC DEVICE
</title>

<abstract>
The present disclosure provides a depth image processing method and apparatus, and an electronic device. The method includes: acquiring a first image acquired by a depth sensor and a second image acquired by an image sensor; determining a scene type according to the first image and the second image; and performing a filtering process on the first image according to the scene type.
</abstract>

<claims>
1. A method for depth image processing, comprising: acquiring (101) a first image acquired by a depth sensor and a second image acquired by an image sensor; determining (102) a scene type according to the first image and the second image; and performing (103) a filtering process on the first image according to the scene type.
2. The method according to claim 1, wherein determining (102) the scene type according to the first image and the second image, comprises: identifying (201) a region of interest from the second image; determining (202) a depth and a confidence coefficient of the depth corresponding to each pixel unit in the region of interest according to the first image; and determining (203) the scene type according to the depth and the confidence coefficient of the depth corresponding to each pixel unit in the region of interest.
3. The method according to claim 2, wherein determining (203) the scene type according to the depth and the confidence coefficient of the depth corresponding to each pixel unit in the region of interest, comprises: performing (301) statistical analysis on the depths corresponding to respective pixel units in the region of interest to obtain a depth distribution, and performing statistical analysis on the confidence coefficients to obtain a confidence coefficient distribution; and determining the scene type according to the depth distribution and the confidence coefficient distribution; wherein the depth distribution is configured to indicate a proportion of pixel units in each depth interval, and the confidence coefficient distribution is configured to indicate a proportion of pixel units in each confidence interval.
4. The method according to claim 3, wherein determining the scene type according to the depth distribution and the confidence coefficient distribution, comprises: in response to determining that a background beyond a measurement range is present in the region of interest according to the confidence coefficient distribution, determining (303) the scene type as a first scene type; and in response to determining according to the confidence coefficient distribution that there is no background beyond the measurement range in the region of interest, determining (304) a distance level between the background and a foreground in the region of interest according to the depth distribution, and determining the scene type as a second scene type or a third scene type according to the distance level, wherein the distance between the background and the foreground in the second scene type is greater than the distance between the background and the foreground in the third scene type.
5. The method according to claim 1, wherein performing (103) the filtering process on the first image according to the scene type, comprises: determining (401) a target confidence threshold according to the scene type; and deleting (402) the depth of a pixel unit in the first image having a confidence coefficient lower than the target confidence threshold, especially, determining (401) the target confidence threshold according to the scene type, comprises: determining a threshold determination strategy according to the scene type; and processing the confidence coefficient of each pixel unit in the first image according to the threshold determination strategy to obtain the target confidence threshold.
6. The method according to any one of claims 1-6, further comprising: adjusting operating parameters of a depth sensor according to the scene type.
7. The method according to claim 6, wherein the depth sensor is a time-of-flight (TOF) camera, and the operating parameters comprise a power of infrared light emitted by the TOF camera and a frequency of the infrared light; and wherein
adjusting the operating parameters of the depth sensor according to the scene type, comprises: querying (601) an operating parameter table according to the scene type to obtain corresponding frequency and power; and adjusting (602) the operating parameters of the depth sensor to the queried frequency and power.
8. A depth image processing apparatus (100), comprising: an acquiring module (110), configured to acquire a first image acquired by a depth sensor and a second image acquired by an image sensor; an identifying module (120), configured to determine a scene type according to the first image and the second image; and a processing module (130), configured to perform a filtering process on the first image according to the scene type.
9. The apparatus (100) according to claim 8, wherein the identifying module (120) comprises: an identifying unit (121), configured to identify a region of interest from the second image; a first determining unit (122), configured to determine a depth and a confidence coefficient of the depth corresponding to each pixel unit in the region of interest according to the first image; and a second determining unit (123), configured to determine the scene type according to the depth and the confidence coefficient of the depth corresponding to each pixel unit in the region of interest.
10. The apparatus according to claim 9, wherein the second determining unit (123) is configured to: perform statistical analysis on the depths corresponding to respective pixel units in the region of interest to obtain a depth distribution, and performing statistical analysis on the confidence coefficients to obtain a confidence coefficient distribution; and determine the scene type according to the depth distribution and the confidence coefficient distribution; wherein the depth distribution is configured to indicate a proportion of pixel units in each depth interval, and the confidence coefficient distribution is configured to indicate a proportion of pixel units in each confidence interval.
11. The apparatus according to claim 10, wherein the second determining unit (123) is configured to: in response to determining that a background beyond a measurement range is present in the region of interest according to the confidence coefficient distribution, determine the scene type as a first scene type; and in response to determining according to the confidence coefficient distribution that there is no background beyond the measurement range in the region of interest, determine a distance level between the background and a foreground in the region of interest according to the depth distribution, and determine the scene type as a second scene type or a third scene type according to the distance level, wherein the distance between the background and the foreground in the second scene type is greater than the distance between the background and the foreground in the third scene type.
12. The apparatus according to claim 8, wherein the processing module (130) comprises: a third determining unit (131), configured to determine a target confidence threshold according to the scene type; and a deleting unit (132), configured to delete the depth of a pixel unit in the first image having a confidence coefficient lower than the target confidence threshold, especially, the third determining unit (131) is configured to: determine a threshold determination strategy according to the scene type; and process the confidence coefficient of each pixel unit in the first image according to the threshold determination strategy to obtain the target confidence threshold.
13. The apparatus according to any one of claims 8-12, further comprising:
an adjusting module (150), configured to adjust operating parameters of a depth sensor according to the scene type.
14. The apparatus according to claim 13, wherein the depth sensor is a time-of-flight (TOF) camera, and the operating parameters comprise a power of infrared light emitted by the TOF camera and a frequency of the infrared light; and
the adjusting module (150) is configured to: query an operating parameter table according to the scene type to obtain corresponding frequency and power; and adjust the operating parameters of the depth sensor to the queried frequency and power.
15. An electronic device, comprising: a depth sensor, configured to acquire a first image; an image sensor, configured to acquire a second image synchronously with the first image; and a processor, configured to perform the method according to any one of claims 1-7.
</claims>
</document>
