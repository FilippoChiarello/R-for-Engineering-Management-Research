<document>

<filing_date>
2018-05-30
</filing_date>

<publication_date>
2020-05-19
</publication_date>

<priority_date>
2012-10-23
</priority_date>

<ipc_classes>
G06K9/00,G06T7/00,H04N5/232
</ipc_classes>

<assignee>
SNAPAID
</assignee>

<inventors>
SIVAN, ISHAY
</inventors>

<docdb_family_id>
50544122
</docdb_family_id>

<title>
Real time assessment of picture quality
</title>

<abstract>
A computerized method for computing the photo quality of a captured image in a device image acquisition system, comprising on-board combining of a plurality of quality indicators computed from said captured image and its previous image frames quality indicators and a confidence level for at least one of said quality indicators; and using a processor to determine, based on said combining, whether photo quality is acceptable and taking differential action depending on whether quality is or is not acceptable.
</abstract>

<claims>
1. A method for estimating quality of at least one image from a plurality of images, for use with a device that comprises in a single enclosure a digital camera module or functionality that comprises at least one optical lens for focusing received light from a scene and an image sensor coupled to the optical lens for capturing an image of the scene; a motion or location sensor for sensing the device motion; and a processor coupled to at least one image sensor and to the digital camera for receiving data therefrom, the method by the processor comprising use of at least one value and weight; obtaining a first value (QI1) responsive to the device motion from the motion or location sensor; estimating a first weight (c1) associated with the first; obtaining a second value (QI2) associated with the digital camera; estimating a second weight (c2) associated with the second value; analyzing the captured image for detecting or recognizing one or more objects in the image and obtaining a third value (QI3) associated with motion of at least one of said objects; estimating a third weight (c3) associated with the third value; obtaining a fourth value (QI4) associated with recognition of object characteristics; estimating a fourth weight (c4) associated with the fourth value; obtaining a fifth value (QI5) associated with aesthetic quality of image based on composition; estimating a fifth weight (c5) associated with the fifth value; and calculating a total quality value according to, or based on values QI1, QI2, QI3 and QI5 and weights c1, c2, c3, c4 and c5.
2. The method according to claim 1, wherein the estimating of the first weight (c1) is responsive to at least one of second, third, fourth or fifth value (QI2, QI3, QI4, QI5); or wherein the estimating of the second weight (c2) is responsive to at least one of the first, third, fourth or fifth value (QI1, QI3, QI4, QI5); or wherein the estimating of the third weight (c3) is responsive to at least one of first, second, fourth or fifth value (QI1, QI2, QI4, QI5); or wherein the estimating of the fourth weight (c4) is responsive to at least one of the first, second, third or fifth value (QI1, QI2, QI3, QI5); or wherein the estimating of the fifth weight (c5) is responsive to at least one of the first, second, third or fourth value (QI1, QI2, QI3, QI4).
3. The method according to claim 1, wherein the first weight (c1) is estimated according to, or based on, a precision error, reading resolution, or drift in time, of the motion or location sensor, and wherein the motion or location sensor consists of, or comprises, an accelerometer, a gyroscope, a Global Positioning System (GPS), or a step counter.
4. The method according to claim 1, wherein the third weight (c3) is estimated according to, or based on, the estimated error in the analyzing the captured image for detecting or recognizing objects in the image.
5. The method according to claim 1, wherein the digital camera further comprises an auto-focus functionality, wherein the auto-focus functionality is coupled to the controlled by the processor, and wherein the method further comprising controlling the auto-focus functionality according to, or based on, the second value (QI2) or the total value.
6. The method according to claim 1, wherein object characteristics are at least one of recognized smile, looking at camera, face importance to user or confidence of object recognition.
7. The method according to claim 1, wherein aesthetic quality of image based on composition includes at least one of: rule of thirds, golden triangle, golden spiral, shapes and lines, amputation avoidance, visual balance, diagonal dominance, non-reference quality indication or relative position of salient regions in the image.
8. The method according to claim 1, further comprising grading the image quality according to, or based on, the total value, and wherein the total value is calculated as a weighted average value according to, or based on, c1*QI1+c2*QI2+c3*QI3+c4*QI4+c5*QI5.
9. The method according to claim 1, for use with a probability distribution function using a mean value (p) and a standard deviation value (a), wherein the estimating of at least one of the weights (c1, c2, c3, c4, c5) is according to, or based on, the respective probability of the at least of the values (QI1, QI2, QI3, QI4, QI5), according to the probability distribution function.
10. The method according to claim 1, for use with a plurality of former values of the respective QI, further comprising calculating the mean value (μ) and the as the standard deviation value (σ) based on the plurality of former values.
11. The method according to claim 1, wherein the acting comprises affecting the digital camera in response to the total value.
12. The method according to claim 1, wherein: the device comprises multiple motion or location sensors for sensing the device motion selected from a group consisting of a gyroscope, accelerometer, Global Positioning System (GPS), 9 Degrees of Freedom (DOF) sensing component, and 10 Degrees of Freedom (DOF) sensing component, wherein the method comprising obtaining a corresponding first value (QI1i) from each of the multiple motion or location sensors responsive to the device motion from the respective motion or location sensor; and estimating or calculating the first value (QI1) based on the multiple first values (QI1i) from the multiple motion or location sensors, or wherein: the analyzing of the captured image comprises applying multiple algorithms selected from a group consisting of an aesthetic algorithm, an artificial neural network employing deep learning algorithm, a corner detection algorithm, a blur detecting algorithm, and Peak Signal-to-Noise Ratio (PSNR) calculation, and the method further comprising obtaining a respective third value (QI3i) associated with each of multiple algorithms, and calculating or estimating the third value (QI3) based on the multiple third values (QI3i) from the multiple algorithms.
13. The method according to claim 1, wherein estimating fourth value (QI4) or forth weight (c4) is based at least partly on a list of configured faces.
14. The method according to claim 1, wherein algorithms of deep learning are used to compute at least one of the values (QI1, QI2, QI3, QI4, QI5).
15. The method according to claim 1, wherein algorithms of deep learning are used to compute the total quality value.
16. The method according to claim 1, wherein the second value is a combination of at least one of digital camera exposure, focus and under or over exposure.
17. A method for estimating quality of at least one image from a stream of images from a video, for use with a device that comprises in a single enclosure a digital camera module or functionality that comprises at least one optical lens for focusing received light from a scene and an image sensor coupled to at least one optical lens for capturing an image of the scene; a motion or location sensor for sensing the device motion; and a processor coupled to the image sensor and to the digital camera for receiving data therefrom, the method by the processor comprising use of at least one value and weight; obtaining a first value (QI1) responsive to the device motion from the motion or location sensor; estimating a first weight (c1) associated with the first; obtaining a second value (QI2) value is a combination of at least one of digital camera exposure, focus and under or over exposure; estimating a second weight (c2) associated with the second value; analyzing the captured image via deep learning algorithms for detecting or recognizing one or more objects in, or one or more characteristics of image or at least one of object characteristics to obtain a third value (QI3) associated with the analysis; calculating a total quality value according to, or based on values QI1, QI2, QI3 and weights c1, c2, c3 and previous values QI1, QI2, QI3 and previous weights c1, c2, c3 in said image stream; and selecting by said processor at least one image from the plurality of images at least partly on said total quality value.
18. The method according to claim 17, where a first value (QI1) can be a combination of accelerometer data, gyro data and camera/lens module.
19. The method according to claim 17, wherein algorithms of deep learning are used to compute at least one of the values (QI1, QI2, QI3, QI4, QI5).
20. The method according to claim 17, wherein algorithms of deep learning are used to compute the total quality value.
</claims>
</document>
