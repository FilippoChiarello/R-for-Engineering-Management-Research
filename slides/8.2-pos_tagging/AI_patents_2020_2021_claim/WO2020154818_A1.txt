<document>

<filing_date>
2020-01-31
</filing_date>

<publication_date>
2020-08-06
</publication_date>

<priority_date>
2019-01-31
</priority_date>

<ipc_classes>
A63F13/825,G06N20/00,G16Z99/00
</ipc_classes>

<assignee>
TREASURED
</assignee>

<inventors>
GIOVANNETTI, VITO SERGIO
VARABEI, MIKITA
</inventors>

<docdb_family_id>
71839894
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR UPDATING OBJECTS IN A SIMULATED ENVIRONMENT
</title>

<abstract>
A system and method for providing a cloud-based interactive simulated reality environment which evolves in a multi-dimensional way over time. The system features a modular design that enables the creation, evolution, and expansion of a personalized simulated reality environment across an unlimited amount of users. More specifically, the system enables the automation of a personalized three-dimensional (3D) simulated reality environment that can transform both independently of and dependently on the user, collaborators, and visitors.
</abstract>

<claims>
1. A system for auto-generating and modifying an evolving simulated reality environment, the system comprising:
a data store; and
at least one processor coupled to the data store, the at least one processor being configured to execute:
an importing module that is adapted to receive multimedia content from at least one user device through a software application, and to store the multimedia content on the data store;
an auto-generation module that is adapted to generate the simulated reality environment, to parse metadata in the multimedia content, and to create a priority score for the multimedia content based at least in part on predetermined rules and learned rules; and
an output module to display the simulated reality environment and the multimedia content in an order in the simulated reality environment based on the priority score for each of the multimedia content.
2. The system of claim 1 , wherein the simulated reality environment is one of a VR environment, a mixed 2D and 3D environment, and an AR environment
3. The system of claim 1 or claim 2, wherein the software application is at least one of an internet application and a mobile application.
4. The system of any one of claims 1 to 3, wherein the importing module is further configured to sort the received multimedia content based on a date of receipt of the content.
5. A system for providing interactions between a plurality of user devices within a simulated reality environment, the system comprising:
a data store; and a processor coupled to the data store, the processor being configured to execute:
an authorization module that is adapted to register an account for a first user device of the plurality of user devices, to receive access permission for the account from a simulated reality environment owner, and to identify visitation and content creation by the first user device, the content comprising at least one 3D object;
a data processing module that is adapted to synchronize interactions by the first user device with evolution pathways of the simulated reality environment, to share the interactions with the simulated reality environment owner and at least one of the plurality of user devices, and to collect a unique activation of the first user device and associated behaviors with at least one of a plurality of 3D objects in the simulated reality environment; and
an output module that is adapted to post multimedia messages and interactable objects to a central repository that influences the evolution pathways associated with the simulated reality environment.
6. The system of claim 5, wherein the simulated reality environment is one of a VR environment, a mixed 2D and 3D environment, and an AR environment.
7. The system of claim 5 or claim 6, wherein the output module is further adapted to send an invitation to at least one of the plurality of user devices with a custom-generated uniform resource locator or key-sensitive code.
8. The system of claim 7, wherein the output module is further adapted to create access permission to at least one of the plurality of user devices to the simulated reality environment. 9. The system of any one of claims 5 to 8, wherein the processor is further configured to execute:
an environment state module that is adapted to monitor the interactions, determine time periods between the interactions, to identify relationships between users of at least two of the plurality of user devices, and to determine and generate data points based at least in part on the interactions, the time periods between the interactions, and the relationships;
an input module that is adapted to receive the data points; and an auto-generation module that is adapted to learn by machine learning changes in placement and presentation of the content within the simulated reality environment, the machine learning based at least in part on a predefined set of rules with weighted distributions for the plurality of user devices, the relationships, and the data points.
10. The system of claim 9, wherein the machine learning is further based at least in part on:
extracting data relating to a location, a date/time, and identities of the plurality of user devices, the extracted data being obtained by an analysis of user submitted images, descriptions, and audio in the content;
obtaining user data from the plurality of user devices relating to the location, the date/time, and the identities of the plurality of user devices; determining differences between the extracted data and the user data; analyzing a first object of a plurality of 3D objects based at least in part on mesh, texture, and 2D representations, generating a plurality of tags based on the analysis and associating the first object to a real world location, a time period, other people, and categories;
grouping the extracted data and the user data, the grouping generating variables with assigned weights that determine how much similarity between different variables is needed for deciding whether or not to group content units together; and searching among the plurality of 3D objects within a grouping for a 3D object that has extracted data most closely matching a combination of the user data and the extracted data to determine search results.
1 1. The system of claim 10, wherein the categories comprise sports, history, science, games, popular knowledge and other relevant tags.
12. The system of any one of claims 5 to 1 1 , wherein the auto-generation module is further adapted to:
group the 3D objects by content unit;
group the content units by content group;
generate group 3D coordinates for each content group;
generate unit 3D coordinates for a content unit within a content group; generate object 3D coordinates for each 3D object within a content unit; and
store in a database the group 3D coordinates, the unit 3D coordinates, the object 3D coordinates, the 3D objects, the extracted data, and the user data.
13. A computer-implemented method for auto-generating and modifying an evolving simulated reality environment, the method comprising:
receiving multimedia content from at least one user device through a software application;
storing the multimedia content on a data store;
generating the simulated reality environment;
parsing metadata in the multimedia content;
creating a priority score for the multimedia content based at least in part on predetermined rules and learned rules; and
displaying the simulated reality environment and the multimedia content in an order in the simulated reality environment based on the priority score for each of the multimedia content.
14. The method of claim 13, wherein the simulated reality environment is one of a VR environment, a mixed 2D and 3D environment, and an AR environment.
15. The method of claim 13 or 14, wherein the software application is at least one of an internet application and a mobile application.
16. The method of any one of claims 13 to 15, further comprising sorting the received multimedia content based on a date of receipt.
17. A computer-implemented method for providing interactions between a plurality of user devices within a simulated reality environment, the method comprising:
registering an account for a first user device of the plurality of user devices;
receiving access permission for the account from a simulated reality environment owner;
identifying visitation and content creation by the first user device, the content comprising at least one 3D object;
synchronizing interactions by the first user device with evolution pathways of the simulated reality environment;
sharing the interactions with the simulated reality environment owner and at least one of the plurality of user devices;
collecting a unique activation of the first user device and associated behaviors with at least one of a plurality of 3D objects in the simulated reality environment; and
posting multimedia messages and interactable objects to a central repository that influences the evolution pathways associated with the simulated reality environment.
18. The method of claim 17, wherein the simulated reality environment is one of a VR environment, a mixed 2D and 3D environment, and an AR environment.
19. The method of claim 17 or claim 18, further comprising sending an invitation to at least one of the plurality of user devices with a custom-generated uniform resource locator or key-sensitive code.
20. The method of claim 19, further comprising creating access permission to at least one of the plurality of user devices to the simulated reality environment.
21. The method of any one of claims 17 to 20, further comprising:
monitoring the interactions;
determining time periods between the interactions;
identifying relationships between users of at least two of the plurality of user devices;
determining and generating data points based at least in part on the interactions, the time periods between the interactions, and the relationships; receiving the data points; and
learning by machine learning changes in placement and presentation of the content within the simulated reality environment, the machine learning based at least in part on a predefined set of rules with weighted distributions for the plurality of user devices, the relationships, and the data points.
22. The method of claim 21 , wherein the machine learning is further based at least in part on:
extracting data relating to a location, a date/time, and identities of the plurality of user devices, the extracted data being obtained by an analysis of user submitted images, descriptions, and audio in the content;
obtaining user data from the plurality of user devices relating to the location, the date/time, and the identities of the plurality of user devices; determining differences between the extracted data and the user data; analyzing a first object of a plurality of 3D objects based at least in part on mesh, texture, and 2D representations, generating a plurality of tags based on the analysis and associating the first object to a real world location, a time period, other people, and categories; grouping the extracted data and the user data, the grouping generating variables with assigned weights that determine how much similarity between different variables is needed for deciding whether or not to group content units together; and
searching among the plurality of 3D objects within a grouping for a 3D object that has extracted data most closely matching a combination of the user data and the extracted data to determine search results.
23. The method of claim 22, wherein the categories comprise sports, history, science, games, popular knowledge and other relevant tags.
24. The method of any one of claims 17 to 23, further comprising:
grouping the 3D objects by content unit;
grouping the content units by content group;
generating group 3D coordinates for each content group;
generating unit 3D coordinates for a content unit within a content group; generating object 3D coordinates for each 3D object within a content unit; and
storing in a database the group 3D coordinates, the unit 3D coordinates, the object 3D coordinates, the 3D objects, the extracted data, and the user data. AMENDED CLAIMS
received by the International Bureau on
06 July 2020 (06.07.2020)
CLAIMS:
1. A system for auto-generating a simulated reality environment, the system comprising:
a data store; and
at least one processor coupled to the data store, the at least one processor being configured to execute:
an importing module that is adapted to receive multimedia content from at least one user device through a software application, and to store the multimedia content on the data store;
an auto-generation module that is adapted to generate the simulated reality environment, to parse metadata in the multimedia content, and to create a priority score for the multimedia content based at least in part on predetermined rules and learned rules; and
an output module to display the simulated reality environment and the multimedia content in an order in the simulated reality environment based on the priority score for each of the multimedia content.
2. The system of claim 1 , wherein the simulated reality environment is one of a VR environment, a mixed 2D and 3D environment, and an AR environment.
3. The system of claim 1 or claim 2, wherein the software application is at least one of an internet application and a mobile application.
4. The system of any one of claims 1 to 3, wherein the importing module is further configured to sort the received multimedia content based on a date of receipt of the content.
5. A system for providing interactions between a plurality of user devices within a simulated reality environment, the system comprising:
a data store; and a processor coupled to the data store, the processor being configured to execute:
an authorization module that is adapted to register an account for a first user device of the plurality of user devices, to receive access permission for the account from a simulated reality environment owner, and to identify visitation and content creation by the first user device, the content comprising at least one 3D object;
a data processing module that is adapted to synchronize interactions by the first user device with evolution pathways of the simulated reality environment, to share the interactions with the simulated reality environment owner and at least one of the plurality of user devices, and to collect a unique activation of the first user device and associated behaviors with at least one of a plurality of 3D objects in the simulated reality environment; and
an output module that is adapted to post multimedia messages and interactable objects to a central repository that influences the evolution pathways of the simulated reality environment.
6. The system of claim 5, wherein the simulated reality environment is one of a VR environment, a mixed 2D and 3D environment, and an AR environment.
7. The system of claim 5 or claim 6, wherein the output module is further adapted to send an invitation to at least one of the plurality of user devices with a custom-generated uniform resource locator or key-sensitive code.
8. The system of claim 7, wherein the output module is further adapted to create access permission to at least one of the plurality of user devices to the simulated reality environment.
9. The system of any one of claims 5 to 8, wherein the processor is further configured to execute:
an environment state module that is adapted to monitor the interactions, determine time periods between the interactions, to identify relationships between users of at least two of the plurality of user devices, and to determine and generate data points based at least in part on the interactions, the time periods between the interactions, and the relationships;
an input module that is adapted to receive the data points; and an auto-generation module that is adapted to learn by machine learning changes in placement and presentation of the content within the simulated reality environment, the machine learning based at least in part on a predefined set of rules with weighted distributions for the plurality of user devices, the relationships, and the data points.
10. The system of claim 9, wherein the machine learning is further based at least in part on:
extracting data relating to a location, a date/time, and identities of the plurality of user devices, the extracted data being obtained by an analysis of user submitted images, descriptions, and audio in the content;
obtaining user data from the plurality of user devices relating to the location, the date/time, and the identities of the plurality of user devices;
determining differences between the extracted data and the user data; analyzing a first object of a plurality of 3D objects based at least in part on mesh, texture, and 2D representations, generating a plurality of tags based on the analysis and associating the first object to a real world location, a time period, other people, and categories;
grouping the extracted data and the user data, the grouping generating variables with assigned weights that determine how much similarity between different variables is needed for deciding whether or not to group content units together; and
searching among the plurality of 3D objects within a grouping for a 3D object that has extracted data most closely matching a combination of the user data and the extracted data to determine search results.
1 1 . The system of claim 10, wherein the categories comprise sports, history, science, games, popular knowledge and other relevant tags.
12. The system of any one of claims 5 to 9, wherein the auto-generation module is further adapted to:
group the 3D objects by content unit;
group the content units by content group;
generate group 3D coordinates for each content group;
generate unit 3D coordinates for a content unit within a content group; generate object 3D coordinates for each 3D object within a content unit; and
store in a database the group 3D coordinates, the unit 3D coordinates, the object 3D coordinates, and the 3D objects.
13. The system of claim 10 or claim 1 1 , wherein the auto-generation module is further adapted to:
group the 3D objects by content unit;
group the content units by content group;
generate group 3D coordinates for each content group;
generate unit 3D coordinates for a content unit within a content group; generate object 3D coordinates for each 3D object within a content unit; and
store in a database the group 3D coordinates, the unit 3D coordinates, the object 3D coordinates, the 3D objects, the extracted data, and the user data.
14. A computer-implemented method for auto-generating a simulated reality environment, the method comprising:
receiving multimedia content from at least one user device through a software application;
storing the multimedia content on a data store;
generating the simulated reality environment;
parsing metadata in the multimedia content;
creating a priority score for the multimedia content based at least in part on predetermined rules and learned rules; and
displaying the simulated reality environment and the multimedia content in an order in the simulated reality environment based on the priority score for each of the multimedia content.
15. The method of claim 14, wherein the simulated reality environment is one of a VR environment, a mixed 2D and 3D environment, and an AR environment.
16. The method of claim 14 or 15, wherein the software application is at least one of an internet application and a mobile application.
17. The method of any one of claims 14 to 16, further comprising sorting the received multimedia content based on a date of receipt.
18. A computer-implemented method for providing interactions between a plurality of user devices within a simulated reality environment, the method comprising:
registering an account for a first user device of the plurality of user devices;
receiving access permission for the account from a simulated reality environment owner;
identifying visitation and content creation by the first user device, the content comprising at least one 3D object;
synchronizing interactions by the first user device with evolution pathways of the simulated reality environment;
sharing the interactions with the simulated reality environment owner and at least one of the plurality of user devices;
collecting a unique activation of the first user device and associated behaviors with at least one of a plurality of 3D objects in the simulated reality environment; and
posting multimedia messages and interactable objects to a central repository that influences the evolution pathways associated with the simulated reality environment.
19. The method of claim 18, wherein the simulated reality environment is one of a VR environment, a mixed 2D and 3D environment, and an AR environment.
20. The method of claim 18 or claim 19, further comprising sending an invitation to at least one of the plurality of user devices with a custom-generated uniform resource locator or key-sensitive code.
21 . The method of claim 20, further comprising creating access permission to at least one of the plurality of user devices to the simulated reality environment.
22. The method of any one of claims 18 to 21 , further comprising:
monitoring the interactions;
determining time periods between the interactions;
identifying relationships between users of at least two of the plurality of user devices;
determining and generating data points based at least in part on the interactions, the time periods between the interactions, and the relationships; receiving the data points; and
learning by machine learning changes in placement and presentation of the content within the simulated reality environment, the machine learning based at least in part on a predefined set of rules with weighted distributions for the plurality of user devices, the relationships, and the data points.
23. The method of claim 22, wherein the machine learning is further based at least in part on: extracting data relating to a location, a date/time, and identities of the plurality of user devices, the extracted data being obtained by an analysis of user submitted images, descriptions, and audio in the content;
obtaining user data from the plurality of user devices relating to the location, the date/time, and the identities of the plurality of user devices;
determining differences between the extracted data and the user data; analyzing a first object of a plurality of 3D objects based at least in part on mesh, texture, and 2D representations, generating a plurality of tags based on the analysis and associating the first object to a real world location, a time period, other people, and categories;
grouping the extracted data and the user data, the grouping generating variables with assigned weights that determine how much similarity between different variables is needed for deciding whether or not to group content units together; and
searching among the plurality of 3D objects within a grouping for a 3D object that has extracted data most closely matching a combination of the user data and the extracted data to determine search results.
24. The method of claim 23, wherein the categories comprise sports, history, science, games, popular knowledge and other relevant tags.
25. The method of any one of claims 18 to 22, further comprising:
grouping the 3D objects by content unit;
grouping the content units by content group;
generating group 3D coordinates for each content group;
generating unit 3D coordinates for a content unit within a content group; generating object 3D coordinates for each 3D object within a content unit; and
storing in a database the group 3D coordinates, the unit 3D coordinates, the object 3D coordinates, and the 3D objects.
26. The method of claim 23 or claim 24, further comprising:
grouping the 3D objects by content unit;
grouping the content units by content group;
generating group 3D coordinates for each content group;
generating unit 3D coordinates for a content unit within a content group; generating object 3D coordinates for each 3D object within a content unit; and
storing in a database the group 3D coordinates, the unit 3D coordinates, the object 3D coordinates, the 3D objects, the extracted data, and the user data.
</claims>
</document>
