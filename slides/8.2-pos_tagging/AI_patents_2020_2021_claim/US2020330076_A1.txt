<document>

<filing_date>
2018-10-08
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2017-10-16
</priority_date>

<ipc_classes>
A61B8/00,A61B8/08,A61B8/14
</ipc_classes>

<assignee>
PHILIPS ELECTRONICS
</assignee>

<inventors>
PETERS, JOCHEN
WEBER, FRANK MICHAEL
SCHMIDT-RICHBERG, ALEXANDER
EWALD, ARNE
WISSEL, TOBIAS
</inventors>

<docdb_family_id>
60117583
</docdb_family_id>

<title>
AN ULTRASOUND IMAGING SYSTEM AND METHOD
</title>

<abstract>
An ultrasound imaging system comprises a display for displaying a received ultrasound image. A user interface is provided for receiving user commands for controlling the ultrasound imaging process, and it receives a user input which identifies a point or region of the displayed ultrasound image. An image depth is determined which is associated with the identified point or region and the imaging process is controlled to tailor the imaging to the identified point or region.
</abstract>

<claims>
1. An ultrasound imaging system, comprising: an ultrasound probe for generating ultrasound signals and receiving reflected echo signals; a processing system for controlling the generation of the ultrasound signals and processing of the received reflected echo signals; a display for displaying a received ultrasound image; and a user interface for receiving user commands for controlling the generation of the ultrasound signals and/or processing of the received reflected echo signals, wherein the user interface is adapted to receive a user input which identifies a point or region of a displayed ultrasound image, and wherein the processing system is adapted to derive an anatomical feature identification and/or an image depth associated with the identified point or region and control the generation of the ultrasound signals and the processing of the received reflected echo signals to adapt them to the identified point or region based on the derived anatomical feature identification and/or image depth.
2. A system as claimed in claim 1, wherein the processing system is adapted to adjust one or more of: the frame rate; the contrast; the gain settings; the focal zone.
3. A system as claimed in claim 1, wherein the processing system is adapted to adjust the frequency in response to a derived depth.
4. A system as claimed in claim 1, wherein the processing system is adapted to adapt the frequency to maximize the received signal.
5. A system as claimed in claim 1, wherein the processing system is adapted to identify anatomical structures within the image and to identify an anatomical structure at the identified point or region, and to control the generation of the ultrasound signals and/or processing of the received reflected echo signals to adapt them to the identified anatomical structure.
6. A system as claimed in claim 1, wherein the user interface is adapted to receive a further command, wherein: the further command indicates that focal depth adjustment is desired, and the processing system is adapted to adjust the frequency in response to the derived depth; or the further command indicates that focal zone adjustment is desired, and the processing system is adapted to adjust the width of the beam at the focus and the focus depth in response to the derived depth; or the further command indicates that a field of view adjustment is desired, and the processing system is adapted to adjust the field of view in response to the derived depth; or the further command indicates that time gain compensation adjustment is desired, and the processing system is adapted to adjust the time gain compensation in response to the derived depth.
7. A system as claimed in claim 6, wherein the user interface is adapted to receive the further command as one or more of: a touch screen pinch command; a single click mouse or touch screen command; a double click mouse or touch screen command; a two finger touch screen interaction; a mouse or touch screen slider interaction; a selection from a list of options.
8. A system as claimed in claim 1, wherein the user interface is adapted to receive the user input which identifies a point or region as one or more of: a touch screen point identification; a region drawn over a touch screen; a single click point identification using a mouse; a region drawn using a mouse.
9. An ultrasound imaging method, comprising: generating ultrasound signals and receiving and processing reflected echo signals; displaying a received ultrasound image; and receiving user commands for controlling the generation of the ultrasound signals and/or processing of the received reflected echo signals, wherein the user command identifies a point or region of a displayed ultrasound image, wherein the method comprises deriving an anatomical feature identification and/or an image depth associated with the identified point or region and controlling (308) the generation of the ultrasound signals and processing of the received reflected echo signals to adapt them to the identified point or region.
10. A method as claimed in claim 9, comprising adjusting one or more of: the frame rate; the contrast; the gain settings; the focal zone.
11. A method as claimed in claim 9, comprising adapting the frequency in response to a derived depth.
12. A method as claimed in claim 9, comprising: identifying anatomical structures within the image and identifying an anatomical structure at the identified point or region, and controlling the generation of the ultrasound signals and/or processing of the received reflected echo signals to adapt them to the identified anatomical structure.
13. A method as claimed in claim 9, comprising receiving a further user command, wherein: the further command indicates that focal depth adjustment is desired, and the method comprises adapting the frequency in response to the derived depth; or the further command indicates that focal zone adjustment is desired, and the method comprises adjusting the width of the beam at the focus and the focus depth in response to the derived depth; or the further command indicates that a field of view adjustment is desired, and the method comprises adjusting the field of view in response to the derived depth; or the further command indicates that time gain compensation adjustment is desired, and the method comprises adapting the time gain compensation in response to the derived depth.
14. A method as claimed in claim 13, comprising receiving the further command as one or more of: a touch screen pinch command; a single click mouse or touch screen command; a double click mouse or touch screen command; a two finger touch screen interaction; a mouse or touch screen slider interaction; a selection from a list of options.
15. A computer program comprising computer program code means which is adapted, when said program is run on a computer, to implement the controlling, processing, deriving, adapting, identifying and adjusting steps of claim 10.
</claims>
</document>
