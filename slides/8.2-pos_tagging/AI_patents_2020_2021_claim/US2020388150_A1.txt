<document>

<filing_date>
2019-06-06
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-06
</priority_date>

<ipc_classes>
G06K9/00,G06N20/00,G06T15/08,G08G1/01,G08G1/16
</ipc_classes>

<assignee>
VERIZON PATENT AND LICENSING
</assignee>

<inventors>
RAHMAN, MOHAMMAD NAIMUR
HERSON, ANDREW W.
Owens, Destah
</inventors>

<docdb_family_id>
73650713
</docdb_family_id>

<title>
Monitoring a scene to analyze an event using a plurality of image streams
</title>

<abstract>
A simulation platform may receive, from a plurality of image capture devices, a plurality of image streams that depict an event. The simulation platform may identify an object that is depicted in each of the plurality of image streams. The simulation platform may determine, for each of the plurality of image streams, respective image-based coordinates of a path associated with the object during the event. The simulation platform may determine, based on the respective image-based coordinates and timestamps of the plurality of image streams, simulation coordinates associated with a path of the object during the event. The simulation platform may detect, based on the simulation coordinates, that the object is involved in a collision during the event. The simulation platform may perform an action associated with detecting that the object is involved in the collision.
</abstract>

<claims>
1. A method, comprising: receiving, by a device, a first image stream that depicts a scene during a time period, wherein the first image stream is captured, by a first image capture device, from a first geographical position associated with the scene during the time period, and receiving, by the device, a second image stream that depicts the scene, wherein the second image stream is captured, by a second image capture device, from a second geographical position associated with the scene that is different from the first geographical position; receiving, by the device, metadata associated with the first image stream and the second image stream, wherein the metadata includes first geographical position information that identifies the first geographical position and second geographical position information that identifies the second geographical position; identifying, by the device and using an object detection model, a vehicle that is depicted in the first image stream; determining, by the device and based on the first geographical position information, first image-based coordinates associated with a path of the vehicle, wherein the first image-based coordinates are determined based on the first image stream and the first geographical position; determining, by the device and using the object detection model, that the vehicle is depicted in the second image stream; determining, by the device and based on the second geographical position information, second image-based coordinates associated with the path of the vehicle, wherein the second image-based coordinates are determined based on the second image stream and the second geographical position; determining, by the device and based on the first image-based coordinates and the second image-based coordinates, simulation coordinates of the path, wherein the simulation coordinates correspond to three-dimensional (3D) coordinates of the scene; generating, by the device and based on the simulation coordinates, a 3D graphical simulation of the path of the vehicle, during the time period, within the scene; and performing, by the device, an action associated with the 3D graphical simulation.
2. The method of claim 1, wherein the vehicle is determined to be in the second image stream based on identifying the vehicle in the first image stream.
3. The method of claim 1, wherein the object detection model comprises a machine learning model that is trained to detect the vehicle based on historical information associated with detecting one or more other vehicles.
4. The method of claim 1, wherein the simulation coordinates are determined based on synchronizing the first image stream and the second image stream according to first timestamps of the first image stream and second timestamps of the second image stream, wherein the first timestamps and the second timestamps correspond to the time period.
5. The method of claim 1, wherein the first image-based coordinates and the second image-based coordinates are two-dimensional (2D) coordinates.
6. The method of claim 1, wherein performing the action comprises at least one of: causing the 3D graphical simulation to be presented via a display device, transmitting the 3D graphical simulation to a user device, or storing the 3D graphical simulation in a storage device.
7. The method of claim 1, wherein performing the action comprises: detecting, based on the 3D graphical simulation, a traffic event involving the vehicle; and transmitting, to a user device, a notification to indicate that the traffic event occurred at the scene.
8. A device, comprising: one or more memories; and one or more processors communicatively coupled to the one or more memories, configured to: receive a plurality of image streams that depict a traffic event, wherein the plurality of image streams are captured by a plurality of traffic cameras in different geographical positions of an area of the event; identify, using an object detection model, a vehicle that is depicted in each of the plurality of image streams, wherein the vehicle is involved in the traffic event; determine, for each of the plurality of image streams, respective image-based coordinates of a path associated with the vehicle during the traffic event, wherein the respective image-based coordinates are determined based on a respective geographical position of a respective traffic camera and a path of the vehicle that is depicted in the respective image stream; determine, based on the respective image-based coordinates for each of the plurality of image streams, simulation coordinates associated with a path of the vehicle during the traffic event, wherein the simulation coordinates correspond to a three-dimensional (3D) space associated with the different geographical positions; detect, based on the simulation coordinates, a traffic incident associated with the vehicle during the traffic event; and perform an action associated with the traffic incident.
9. The device of claim 8, wherein the vehicle is a first vehicle, the respective image-based coordinates are first respective image-based coordinates, and the simulation coordinates are first simulation coordinates, and wherein the one or more processors are further to: identify, using the object detection model, a second vehicle depicted in each of the plurality of image streams, wherein the second vehicle is involved in the traffic event; determine, for each of the plurality of image streams, respective second image-based coordinates of a path associated with the second vehicle during the traffic event, wherein the respective second image-based coordinates are determined based on respective geographical positions of the plurality of traffic cameras and a path of the second vehicle that is depicted in the respective image stream; determine, based on the respective second image-based coordinates for each of the plurality of image streams, second simulation coordinates associated with a path of the second vehicle during the traffic event, wherein the second simulation coordinates correspond to the 3D space associated with the traffic event; and detect, based on the second simulation coordinates, that the traffic incident involves the second vehicle.
10. The device of claim 9, wherein the one or more processors, when detecting that the traffic incident involves the second vehicle, are to: determine that the path of the first vehicle and the path of the second vehicle include a point of intersection; and determine that the traffic incident involved the first vehicle and the second vehicle colliding based on the first vehicle and the second vehicle being within a threshold distance of the point of intersection at a same time.
11. The device of claim 8, wherein the object detection model comprises a machine learning model that is trained to detect the vehicle in the plurality of image streams, wherein the machine learning model is trained based on training images that depict a plurality of vehicles.
12. The device of claim 8, wherein the simulation coordinates are further determined based on synchronizing the respective image-based coordinates according to timestamps associated with the plurality of image streams.
13. The device of claim 8, wherein the one or more processors, when performing the action, are to at least one of: generate, based on the simulation coordinates, a 3D graphical simulation of the traffic incident, control a traffic control device in the area of the traffic event, or transmit, to a user device, a notification associated with the traffic incident.
14. The device of claim 8, wherein the traffic incident is detected in real-time relative to the traffic event.
15. A non-transitory computer-readable medium storing instructions, the instructions comprising: one or more instructions that, when executed by one or more processors, cause the one or more processors to: receive, from a plurality of image capture devices, a plurality of image streams that depict an event, wherein the plurality of image capture devices are located at different geographical positions in an area of the event; identify, using an object detection model, an object that is depicted in each of the plurality of image streams, wherein the object is involved in the event; determine, for each of the plurality of image streams, respective image-based coordinates of a path associated with the object during the event, wherein the respective image-based coordinates are determined based on a respective geographical position of a respective image capture device and a path of the object that is depicted in the respective image stream; determine, based on the respective image-based coordinates and timestamps of the plurality of image streams, simulation coordinates associated with a path of the object during the event, wherein the simulation coordinates correspond to the area of the event; detect, based on the simulation coordinates, that the object is involved in a collision during the event; and perform an action associated with detecting that the object is involved in the collision.
16. The non-transitory computer-readable medium of claim 15, wherein, to detect that the object is a same object that is depicted in the plurality of image streams, the object detection model is configured to: determine that a first image stream, of the plurality of image streams, depicts a first moving object that is associated with a movement characteristic; determine that a second image stream, of the plurality of image streams, depicts a second moving object that is associated with the movement characteristic; and detect, based on both the first moving object and the second moving object having the movement characteristic, that the first moving object and the second moving object are the same object.
17. The non-transitory computer-readable medium of claim 15, wherein the object is a first object and the collision involves a second object associated with the event, and wherein the one or more instructions, that cause the one or more processors to perform the action, cause the one or more processors to: generate a three-dimensional simulation of the event, based on the simulation coordinates, that enables the collision to be analyzed from a plurality of different perspectives of the area.
18. The non-transitory computer-readable medium of claim 15, wherein the respective image-based coordinates are two-dimensional (2D) coordinates and the simulation coordinates are three-dimensional (3D) coordinates.
19. The non-transitory computer-readable medium of claim 15, wherein the simulation coordinates are determined based on combining the respective image-based coordinates and mapping combinations of the respective image-based coordinates to a coordinate system associated with the simulation coordinates, wherein the coordinate system is defined by the area of the event.
20. The non-transitory computer-readable medium of claim 15, wherein the one or more instructions that cause the one or more processors to perform the action, cause the one or more processors to: send, in real-time relative to the event, a notification to a user device to indicate that the collision occurred, wherein the user device is used to monitor the area.
</claims>
</document>
