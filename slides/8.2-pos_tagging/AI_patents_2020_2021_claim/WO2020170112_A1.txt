<document>

<filing_date>
2020-02-17
</filing_date>

<publication_date>
2020-08-27
</publication_date>

<priority_date>
2019-02-18
</priority_date>

<ipc_classes>
H04L12/58,H04L29/06
</ipc_classes>

<assignee>
FIDO VOICE
</assignee>

<inventors>
DOWGIALLO, MARIA
LELIWA, GNIEWOSZ
RUTKIEWICZ, GRZEGORZ
TEMPSKA, PATRYCJA
WROCZYNSKI, MICHAL
</inventors>

<docdb_family_id>
72040914
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR DETECTION AND CLASSIFICATION OF UNDESIRED ONLINE ACTIVITY AND INTERVENTION IN RESPONSE
</title>

<abstract>
An intervention method and system for intervening in online bullying is described. in various embodiments, and an online violence detection system available online on communicatively coupled to multiple databases and the multiple system processors, wherein the online detection system is also communicatively coupled to multiple online communities, multiple data sources, and multiple other online systems and online applications. The method and system determine whether autonomous instant action is appropriate, or whether referring the interaction to a moderation dashboard is appropriate. A moderator dashboard is included in one embodiment.
</abstract>

<claims>
1. A intervention system for intervening in online bullying, the system comprising: multiple databases available online;
multiple system processors available online;
an online violence detection system available online on communicatively coupled to the multiple databases and the multiple system processors, wherein the online detection system is also communicatively coupled to multiple online communities, multiple data sources, and multiple other online systems and online applications;
the intervention system executing, through the multiple processors, the method for intervening in online bullying, comprising
receiving published material;
interacting with the online violence detection system;
determining whether autonomous instant action is appropriate, or whether referring the interaction to a moderation dashboard is appropriate;
generating user reporting and also generating a moderator's verification, wherein the moderation dashboard also can generate a moderator action.
2. The system of claim 1, wherein the method executed by the intervention system further comprises interventions performed by automatic agents comprising chatter bots, and wherein the interventions do not include blocking users, deleting users, or banning users.
3. The system of claim 1, wherein the method executed by the intervention system further comprises interventions performed by human mediators, and wherein the interventions do not include blocking users, deleting users, or banning users.
4. The system of claim 1, wherein the method executed by the intervention system further comprises interventions performed by human mediators and chatter bots, and wherein multiple interventors may be chosen among the following:
concealed chatter hot; revealed chatter bot;
amateur human mediator; and
professional human mediator.
5. The system of claim 4, wherein the intervention system dynamically manages chatter bots, including adding new chatter bots to the system, assigning chatter bots to certain identified groups of violent users, and generating new chatter bots as needed.
6. The system of claim 1, wherein the method further comprises:
defining types of interventions, including empathetic, normative, and authoritative.
7. The system of claim 1, wherein the method further comprises defining types of interventions by an effect desired to be had on a violent user.
8. A intervention system for intervening in online bullying, the system comprising: multiple databases available online, comprising a knowledge base that that includes popular conversation topics, a set of predefined scripts, and classifiers predefined to interoperate with the knowledge base;
multiple system processors available online;
an online violence detection system available online on communicatively coupled to the multiple databases and the multiple system processors, wherein the online detection system is also communicatively coupled to multiple online communities, multiple data sources, and multiple other online systems and online applications;
the intervention system executing, through the multiple processors, the method for intervening in online bullying, comprising
receiving published material;
interacting with the online violence detection system;
determining whether autonomous instant action is appropriate, or whether referring the interaction to a moderation dashboard is appropriate;
generating user reporting and also generating a moderator's verification, wherein the moderation dashboard also can generate a moderator action.
9. The system of claim 8, wherein the method executed by the intervention system further comprises interventions performed by automatic agents comprising chatter bots, and wherein the interventions do not include blocking users, deleting users, or banning users.
10. The system of claim 8, wherein the method executed by the intervention system further comprises interventions performed by human mediators, and wherein the interventions do not include blocking users, deleting users, or banning users.
11. The system of claim 8, wherein the method executed by the intervention system further comprises interventions performed by human mediators and chatter bots, and wherein multiple interventors may be chosen among the following:
concealed chatter hot;
revealed chatter hot;
amateur human mediator; and
professional human mediator.
12. The system of claim 11, wherein the intervention system dynamically manages chatter bots, including adding new chatter bots to the system, assigning chatter bots to certain identified groups of violent users, and generating new chatter bots as needed.
13. The system of claim 8, wherein the method further comprises:
defining types of interventions, including empathetic, normative, and authoritative.
14. The system of claim 8, wherein the method further comprises defining types of interventions by an effect desired to had on a violent user.
15. A intervention and detection method for detecting and intervening in online bullying, the method comprising:
accessing multiple databases available online; accessing multiple system processors available online;
receiving published material;
determining whether autonomous instant action is appropriate, or whether referring the interaction to a moderation dashboard is appropriate;
generating user reporting and also generating a moderator's verification, wherein the moderation dashboard also can generate a moderator action.
16. The method of claim 15, wherein the method executed by the intervention system further comprises interventions performed by automatic agents comprising chatter bots, and wherein the interventions do not include blocking users, deleting users, or banning users.
17. The method of claim 15, wherein the method executed by the intervention system further comprises interventions performed by human mediators, and wherein the interventions do not include blocking users, deleting users, or banning users.
18. The method of claim 15, wherein the method executed by the intervention system further comprises interventions performed by human mediators and chatter bots, and wherein multiple interventors may be chosen among the following:
concealed chatter bot;
revealed chatter bot;
amateur human mediator; and
professional human mediator.
19. The method of claim 18, including adding new chatter bots to the system, assigning chatter bots to certain identified groups of violent users, and generating new chatter bots as needed.
20. The method of claim 15, further comprising defining types of interventions, including empathetic, normative, and authoritative.
</claims>
</document>
