<document>

<filing_date>
2019-09-05
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2018-09-05
</priority_date>

<ipc_classes>
G06K9/62,G06T5/00,G06T7/00
</ipc_classes>

<assignee>
VANDERBILT UNIVERSITY
</assignee>

<inventors>
JANG, HOJIN
TONG, FRANK
</inventors>

<docdb_family_id>
69639927
</docdb_family_id>

<title>
NOISE-ROBUST NEURAL NETWORKS AND METHODS THEREOF
</title>

<abstract>
The exemplified methods and systems facilitate the training of a noise-robust deep learning network that is sufficiently robust in the recognition of objects in images having extremely noisy elements such that the noise-robust network can match, or exceed, the performance of human counterparts. The extremely noisy elements may correspond to extremely noisy viewing conditions, e.g., that often manifests themselves in the real-world as poor weather or environment conditions, sub-optimal lighting conditions, sub-optimal image acquisition or capture, etc. The noise-robust deep learning network is trained both (i) with noisy training images with low signal-to-combined-signal-and-noise ratio (SSNR) and (ii) either with noiseless, or generally noiseless, training images or a second set of noisy training images having a SSNR value greater than that of the low-SSNR noisy training images.
</abstract>

<claims>
1. A method of training a neural network, the method comprising: obtaining, by one or more processors, a plurality of source training images from one or more databases of images; and generating, by the one or more processors, a set of one or more noisy training images, including a set of first noisy training images, wherein each of said set of first noisy training images is generated based on each of the plurality of source training images by: adjusting values of a substantial portion of the pixels of a given source training image to reduce the effective dynamic range of the given source training image; and adjusting, to introduce noise, values of pixels of the range-adjusted source training image to generate a given first noisy training image of the set thereof; wherein the set of first noisy training images in combination with either a set of noiseless images or generally noiseless images or a set of second noisy training images are used as training images to train the neural network.
2. The method of claim 1, wherein ranges over which pixel intensity values in the noisy training images vary due to the introduced noise is as large as, or larger than, ranges over which pixel intensity values vary due to information originating from the source training images.
3. The method of claim 1, wherein variance of the pixel intensity values arising from the introduced noise exceeds variance of the pixel intensity values that arise from the source training images.
4. The method of claim 1, wherein the step of adjusting the pixel values of the range-adjusted source training image to generate the noisy training image includes: combining generated noise values arising from the introduced noise to values of a substantial portion of the pixels of the range-adjusted source training image to generate a combined-noise image; and re-centering the range of the combined-noise image.
5. The method of claim 1 further comprising: generating, by the one or more processors, the second noisy training image of the set of one or more noisy training images, wherein the first noisy training image has a first associated SSNR (signal-to-combined-signal-and-noise ratio) value and the second noisy training image has a second associated SSNR value, wherein the first associated SSNR value and the second associated SSNR value are different, and wherein the first noisy training image and the second noisy training image are used in combination with noiseless images or generally noiseless images as training images to train the neural network.
6. The method of claim 1, wherein the introduced noise comprises a combination of both spatially uncorrelated noise and spatially correlated noise.
7. The method of claim 1, wherein the introduced noise is applied in a non-uniform manner.
8. The method of claim 1, wherein the introduced noise comprises spatially uncorrelated pixel noise.
9. The method of claim 1, wherein the introduced noise consists substantially of Gaussian pixel noise.
10. The method of claim 1, wherein the introduced noise comprises spatially correlated noise that follows or resembles a 1/FÎ± power spectrum in the Fourier domain.
11. The method of claim 1, wherein the introduced noise comprises a plurality of image elements having a semi-opaque component and/or an opaque component.
12. The method of claim 1, wherein the introduced noise is introduced to a channel selected from the group consisting of: a chrominance channel of the dynamic-range adjusted source training image, in which different noise images are introduced to the red, green, and blue channels, and a luminance channel of the dynamic-range adjusted source training image, in which the same noise image is introduced to the red, green and blue channels.
13. The method of claim 1, further comprising: converting, by the one or more processors, the plurality of source training images to greyscale, wherein the introduced noise is used to adjust scalar values of the plurality of converted greyscale source training images.
14. The method of claim 1, wherein the plurality of source training images, or a portion thereof, comprise one or more captured frames of a recorded video, including a first captured frame and a second captured frame, wherein the introduced noise of the first captured frame includes a component of spatiotemporal-correlated noise associated with the introduced noise of the second captured frame.
15. The method of claim 1, wherein the plurality of source training images, or a portion thereof, comprise one or more captured frames of a recorded video, including a first captured frame and a second captured frame, wherein the introduced noise of the first captured frame is spatially uncorrelated with the introduced noise of the second captured frame.
16. The method of claim 1, wherein a database of the one or more databases of images comprises a plurality of sets of images, wherein each set of the sets of images is associated with an image category.
17. The method of claim 1, wherein each noisy training image of the set of one or more noisy training images comprises an associated SSNR value, and wherein the associated SSNR values for a portion of the set of noisy training images are sampled from a range of SSNR values or from a set of discrete SSNR values.
18. The method of claim 1 further comprising: applying, by the one or more processor, the set of generated one or more noisy images in combination with either a set of generally noiseless images or a second set of noisy training images as training images to the training of the neural network.
19. The method of claim 1, wherein the neural network is selected from the group consisting of an autoencoder, a probabilistic neural network, a time delay neural network, and a convolutional neural network, deep neural network, deep convolutional network, deconvolutional network, feed-forward based neural network, recurrent based neural network, general adversarial network, variational auto encoder, Kohonen network, Support Vector Machine, and Markov chain-based networks.
20. The method of claim 1, wherein the set of first noisy training images in combination with the set of noiseless images or generally noiseless images are used as training images to train the neural network.
21. The method of claim 1, wherein the set of first noisy training images in combination with the set of second noisy training images are used as training images to train the neural network.
22. The method of claim 1, further comprising: storing the set of the noisy images to a database from which the images can be retrieved for eventual training and/or testing of the neural network.
23. The method of claim 1, wherein the trained neural network is used in a control application, a diagnostic application, or computer vision application.
24. The method of claim 1, wherein the trained neural network is used to generate and apply labels for image categories to a set of images.
25. The method of claim 1, wherein the trained neural network is used to categorize and localize multiple different types of objects contained in a set of images.
26. A system comprising: one or more processors; and a memory having instructions stored thereon, wherein execution of the instructions by the one or more processors causes the one or more processors to: obtain a plurality of source training images from one or more databases of images; and generate a set of one or more noisy training images, including a set of first noisy training images, wherein each of said set of first noisy training images is generated based on each of the plurality of source training images by: adjusting values of a substantial portion of the pixels of a given source training image to reduce the effective dynamic range of the given source training image; and adjusting, to introduce noise, values of pixels of the range-adjusted source training image to generate a given first noisy training image of the set thereof; wherein the set of first noisy training images in combination with either a set of noiseless images or generally noiseless images or a set of second noisy training images are used as training images to train the neural network.
27. A non-transitory computer readable medium having instructions stored thereon, wherein execution of the instructions by one or more processors causes the one or more processors to: obtain a plurality of source training images from one or more databases of images; and generate a set of one or more noisy training images, including a set of first noisy training images, wherein each of said set of first noisy training images is generated based on each of the plurality of source training images by: adjusting values of a substantial portion of the pixels of a given source training image to reduce the effective dynamic range of the given source training image; and adjusting, to introduce noise, values of pixels of the range-adjusted source training image to generate a given first noisy training image of the set thereof; wherein the set of first noisy training images in combination with either a set of noiseless images or generally noiseless images or a set of second noisy training images are used as training images to train the neural network.
</claims>
</document>
