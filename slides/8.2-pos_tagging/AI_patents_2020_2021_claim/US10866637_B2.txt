<document>

<filing_date>
2016-09-14
</filing_date>

<publication_date>
2020-12-15
</publication_date>

<priority_date>
2016-02-02
</priority_date>

<ipc_classes>
G04G21/08,G06F1/16,G06F3/01,G06K9/00,G06K9/62,G06N3/02,G06N3/08
</ipc_classes>

<assignee>
KAIST (KOREA ADVANCED INSTITUTE OF SCIENCE AND TECHNOLOGY)
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
BAE, CHISUNG
JIN, KWI HYUK
KWON, UI KUN
SHIN, JIN WOO
</inventors>

<docdb_family_id>
59387575
</docdb_family_id>

<title>
Gesture classification apparatus and method using EMG signal
</title>

<abstract>
A gesture classification apparatus and method is disclosed. The apparatus may include a feature extractor configured to extract a plurality of features using a electromyogram (EMG) data group obtained from an EMG signal sensor including a plurality of channels, an artificial neural network including an input layer to which the EMG data group corresponding to the plurality of features is input and an output layer configured to output a preset gesture corresponding to the plurality of features, and a gesture recognizer configured to recognize a gesture performed by a user and corresponding to the extracted features.
</abstract>

<claims>
1. A gesture classification apparatus, comprising: at least one processor, the processor comprising instructions for executing: a feature extractor configured to extract a plurality of features using an electromyogram (EMG) data group obtained from an EMG signal sensor comprising a plurality of channels, and generate an EMG data map of a dimension corresponding to the number of the channels, wherein the EMG data map indicates a distribution of features for each gesture; an artificial neural network comprising an input layer to which the EMG data group corresponding to the plurality of features is input, and an output layer configured to output a preset gesture corresponding to the plurality of features; and a gesture recognizer configured to recognize a gesture performed by a user and corresponding to the extracted features using the artificial neural network, wherein the plurality of features is extracted by moving, on a time axis, a preset-sized window of an EMG signal output from the EMG signal sensor.
2. The apparatus of claim 1, further comprising: a preprocessor configured to remove noise from data obtained from the EMG signal sensor and perform normalization on the data having the noise removed.
3. The apparatus of claim 2, wherein the preprocessor is configured to additionally remove a floor value of each channel from data obtained from each channel.
4. The apparatus of claim 2, wherein the preprocessor is configured to extract the EMG data group based on a location of a channel having a maximum value among the plurality of channels.
5. The apparatus of claim 1, wherein the feature extractor is configured to extract a preset number of features from the EMG data map and calculating a performance based on a ratio between a within-cluster variance of each gesture and a between-cluster variance associated with another gesture.
6. The apparatus of claim 1, wherein the artificial neural network includes: a first hidden layer disposed between the input layer and the output layer, and wherein the first hidden layer is mapped to the input layer in the EMG data group.
7. The apparatus of claim 6, wherein the artificial neural network includes: a second hidden layer disposed between the first hidden layer and the output layer, and wherein the number of nodes included in the second hidden layer is greater than the number of nodes included in the output layer, and is less than the number of nodes included in the first hidden layer.
8. The apparatus of claim 1, wherein the artificial neural network is trained through general learning based on an EMG data group obtained from the EMG signal sensor sensing gestures performed by a plurality of users, and is trained through adaptive learning based on an EMG data group obtained from the EMG signal sensor sensing the gesture performed by the user.
9. A gesture classification method, comprising: obtaining an electromyogram (EMG) data group from a plurality of channels; extracting a plurality of features using the EMG data group by generating an EMG data map of a dimension corresponding to the number of channels, wherein the EMG data map indicates a distribution of features for each gesture; and recognizing, using an artificial neural network, a gesture performed by a user and corresponding to the extracted features, wherein the plurality of features is extracted by moving, on a time axis, a preset-sized window of an EMG signal output from the EMG signal sensor.
10. The method of claim 9, wherein the extracting of the plurality of features includes: calculating a performance based on a ratio between a within-cluster variance of each gesture and a between-cluster variance associated with another gesture; and extracting a preset number of features based on the calculated performance.
11. The method of claim 9, wherein the artificial neural network includes an input layer to which the EMG data group corresponding to the plurality of features is input, and an output layer configured to output a preset gesture corresponding to the plurality of features.
12. The method of claim 11, wherein the artificial neural network includes: a first hidden layer disposed between the input layer and the output layer, and wherein the first hidden layer is mapped to the input layer in the EMG data group.
13. The method of claim 12, wherein the artificial neural network includes a second hidden layer disposed between the first hidden layer and the output layer, and wherein the number of nodes included in the second hidden layer is greater than the number of nodes included in the output layer, and is less than the number of nodes included in the first hidden layer.
14. The method of claim 9, wherein the artificial neural network is trained through general learning based on an EMG data group obtained from an EMG signal sensor sensing gestures performed by a plurality of users, and is trained through adaptive learning based on an EMG data group obtained from the EMG signal sensor sensing a gesture performed by a corresponding user.
15. A non-transitory computer-readable storage medium storing instructions to cause a processor to perform the method of claim 9.
16. A wearable device comprising: a sensor configured to obtain an input electromyogram (EMG) signal from a body portion of a user being in contact with the sensor through a plurality of channels; and a processor configured to extract a plurality of features by moving, on a time axis, a preset-sized window of the input EMG signal, generating an EMG data map of a dimension corresponding to the number of the channels, recognize a gesture performed by a user and corresponding to the plurality of features using an artificial neural network, and perform a command corresponding to the recognized gesture, wherein the EMG data map indicates a distribution of features for each gesture, wherein the plurality of features is extracted by moving, on a time axis, a preset-sized window of an EMG signal output from the EMG signal sensor.
17. The wearable device of claim 16, wherein the processor is configured to adjust, based on a user feature using the input EMG signal obtained from the user, reference EMG signals of a plurality of users that are pre-trained through the artificial neural network.
18. The wearable device of claim 17, wherein the artificial neural network includes an input layer to which an EMG data group corresponding to the plurality of features is input, and an output layer configured to output a preset gesture corresponding to the plurality of features.
</claims>
</document>
