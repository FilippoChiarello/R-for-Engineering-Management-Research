<document>

<filing_date>
2018-02-28
</filing_date>

<publication_date>
2020-03-03
</publication_date>

<priority_date>
2018-02-28
</priority_date>

<ipc_classes>
G06F16/31,G06F16/35,G10L15/06,G10L15/16,G10L15/183,G10L25/30
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
GONG YIFAN
LI JINYU
DAS, AMIT
ZHAO, RUI
</inventors>

<docdb_family_id>
67685145
</docdb_family_id>

<title>
Speech recognition using connectionist temporal classification
</title>

<abstract>
Generally discussed herein are devices, systems, and methods for speech recognition. Processing circuitry can implement a connectionist temporal classification (CTC) neural network (NN) including an encode NN to receive an audio frame and generate a current encoded hidden feature vector, an attend NN to generate, based on a current encoded hidden feature vector and a first context vector from a previous time slice, a weight vector indicating an amount the current encoded hidden feature vector, a previous encoded hidden feature vector, and a future encoded hidden feature vector from a future time slice contribute to a current, second context vector, an annotate NN to generate the current, second context vector based on the weight vector, the current encoded hidden feature vector, the previous encoded hidden feature vector, and the future encoded hidden feature vector, and a normal NN to generate a normalized output vector based on the context vector.
</abstract>

<claims>
1. Processing circuitry configured to implement a connectionist temporal classification (CTC) neural network (NN), the CTC NN comprising: an encode NN to receive an audio frame as input and generate a current encoded hidden feature vector as output; an attend NN to generate, based on the current encoded hidden feature vector and a first context vector from a previous time slice, a weight vector indicating an amount the current encoded hidden feature vector, a previous encoded hidden feature vector, and a future encoded hidden feature vector from a future time slice contribute to a current, second context vector; an annotate NN to generate the current, second context vector based on the weight vector, the current encoded hidden feature vector, the previous encoded hidden feature vector, and the future encoded hidden feature vector; and a normal NN to generate a normalized output vector based on the context vector.
2. The processing circuitry of claim 1, wherein the CTC NN further comprises a language model (LM) NN to receive a weighted context vector from the normal NN and to generate an LM feature vector based on the weighted context vector, wherein the first context vector is the LM feature vector.
3. The processing circuitry of claim 1, wherein: the weight vector is a first vector; and the attend NN is further to generate the first weight vector based on a second weight vector from a previous time slice.
4. The processing circuitry of claim 1, wherein CTC NN further comprises: a feed forward NN generate a weighted encoded hidden feature vector based on the current encoded hidden feature vector; and wherein the attend NN is to generate the weight vector based on the weighted encoded hidden feature vector instead of the current encoded hidden feature vector.
5. The processing circuitry of claim 1, wherein the annotate NN generates the second, current context vector non-uniformly to alter the second, current context vector component-by-component based on a corresponding component the weight vector.
6. The processing circuitry of claims, wherein alteration of the second, current context vector includes a Hadamard product of the weight vector and the encoded hidden feature vector.
7. The processing circuitry of claim 1, wherein the annotate NN generates the second; current context vector uniformly to alter each component of the second, context vector in a same manner.
8. The processing circuitry of claim 1, wherein the normal NN includes a feed forward NN to produce a weighted context vector based on the first context vector, and wherein the attend NN is to generate the weight vector based on the weighted context vector instead of the first context vector.
9. The processing circuitry of claim 1, wherein the encode NN includes a recurrent NN.
10. A method of speech recognition comprising: receiving, by an encode neural network (NN), an audio frame as input and generate a current encoded hidden feature vector as output; generating, by an attend NN and based on a current encoded hidden feature vector and a first context vector from a previous time slice, a weight vector indicating an amount the current encoded hidden feature vector, a previous encoded hidden feature vector, and a future encoded hidden feature vector from a future time slice contribute to a current, second context vector; generating, by an annotate NN, the current; second context vector based on the weight vector, the current encoded hidden feature vector, the previous encoded hidden feature vector, and the future encoded hidden feature vector; generating, by a normal NN, a normalized output vector based on the context vector; and translating the normalized output vector to text.
11. The method of claim 10, further comprising receiving, by a language model (LM) NN, a weighted context vector from the normal NN and to generate an LM feature vector based on the weighted context vector, wherein the first context vector is the LM feature vector.
12. The method of claim 10, wherein: the weight vector is a first vector; and the attend NN is further to generate the first weight vector based on a second weight vector from a previous time slice.
13. The method of claim 10, further comprising: generating, by a feed forward NN, a weighted encoded hidden feature vector based on the current encoded hidden feature vector; and generating, by the attend NN, the weight vector based on the weighted encoded hidden feature vector instead of the current encoded hidden feature vector.
14. The method of claim 10, further comprising non-uniformly altering the second, current context vector component-by-component based on a corresponding component the weight vector.
15. The method of claim 14, wherein altering the second, current context vector includes a Hadamard product of the weight vector and the encoded hidden feature vector.
16. A non-transitory machine-readable medium including instructions that, when executed by a machine, configure the machine to perform operations comprising: receiving, by an encode neural network (NN), an audio frame as input and generate a current encoded hidden feature vector as output; generating, by an attend NN and based on a current encoded hidden feature vector and a first context vector from a previous time slice, a weight vector indicating an amount the current encoded hidden feature vector, a previous encoded hidden feature vector, and a future encoded hidden feature vector from a future time slice contribute to a current, second context vector; generating, by an annotate NN, the current, second context vector based on the weight vector, the current encoded hidden feature vector, the previous encoded hidden feature vector, and the future encoded hidden feature vector; generating, by a normal NN, a normalized output vector based on the context vector; and translating the normalized output vector to text.
17. The non-transitory machine-readable medium of claim 16, wherein the annotate NN generates the second, current context vector uniformly to alter each component of the second, context vector in a same manner.
18. The non-transitory machine-readable medium of claim 16, wherein the normal NN includes a feed forward NN to produce a weighted context vector based on the first context vector, and wherein the attend NN is to generate the weight vector based on the weighted context vector instead of the first context vector.
19. The non-transitory machine-readable medium of claim 16, further comprising receiving, by a language model (LM) NN, a weighted context vector from the normal NN and to generate an LM feature vector based on the weighted context vector, wherein the first context vector is the LM feature vector.
20. The non-transitory machine-readable medium of claim 16, further comprising non-uniformly altering the second, current context vector component-by-component based on a corresponding component the weight.
</claims>
</document>
