<document>

<filing_date>
2019-01-04
</filing_date>

<publication_date>
2020-07-09
</publication_date>

<priority_date>
2019-01-04
</priority_date>

<ipc_classes>
A61B5/16,G06K9/00,G06Q30/00,G10L15/18,G10L15/26,G10L17/26,G10L25/63
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
YOSHIDA, TADAYUKI
TAKANO, SAWA
</inventors>

<docdb_family_id>
71404312
</docdb_family_id>

<title>
SENTIMENT ADAPTED COMMUNICATION
</title>

<abstract>
Methods, computer program products, and systems are presented. The method computer program products, and systems can include, for instance: examining communication data of a first human user to return one or more sentiment attribute of the communication data; processing the communication data to return sentiment neutral adapted communication data, the processing being in dependence on the one or more sentiment attribute; presenting to a second human user a sentiment neutral adapted communication, the sentiment neutral adapted communication being based on the sentiment neutral adapted communication data; augmenting second communication data to return adapted second communication data, the augmenting being in dependence of the one or more sentiment attribute; and presenting to the first human user an adapted second communication, the adapted second communication being based on the adapted second communication data.
</abstract>

<claims>
1. A computer implemented method comprising: examining communication data of a first human user to return one or more sentiment attribute of the communication data; processing the communication data to return sentiment neutral adapted communication data, the processing being in dependence on the one or more sentiment attribute; presenting to a second human user a sentiment neutral adapted communication, the sentiment neutral adapted communication being based on the sentiment neutral adapted communication data; augmenting second communication data to return adapted second communication data, the augmenting being in dependence of the one or more sentiment attribute; and presenting to the first human user an adapted second communication, the adapted second communication being based on the adapted second communication data.
2. The computer implemented method of claim 1, wherein the second communication data is communication data of the second human user.
3. The computer implemented method of claim 1, wherein the second communication data is an autonomously generated predetermined question that maps to an open field of a form list of open factual data items for collecting from the first human user, the form list being displayed on user interface viewable by the second human user.
4. The computer implemented method of claim 1, wherein the presenting the adapted second communication data includes using a mechanical robot physically located in an environment of the first human user.
5. The computer implemented method of claim 1, wherein the examining communication data of the first human user includes one or more of the following selected from the group consisting of: (a) examining converting vocal utterance data of the first human user to text using a speech to text converted; (b) examining acoustical characteristics of vocal utterance data of the first human user to return sentiment data based on a mapping between vocal utterance acoustical characteristics and exhibited sentiment; (c) examining text based data entered into a client computer device by the first human user; and (d) examining video data representing facial expressions of the first human user.
6. The computer implemented method of claim 1, wherein the communication data of the first human user includes one or more of the following selected from the group consisting of: (a) vocal utterance data of the first human user, (b) entered text based data entered by the first human user into a user interface; and (c) video data representing one or more facial expression of the first human user.
7. The computer implemented method of claim 1, wherein the processing the communication data to return sentiment neutral adapted communication data includes identifying a certain phrase defined by the communication data having a sentiment parameter value exceeding a threshold, predicting that the certain phrase has a null meaning and replacing the certain phrase with a null phrase.
8. The computer implemented method of claim 1, wherein the processing the communication data to return sentiment neutral adapted communication data includes identifying a certain phrase defined by the communication data having a sentiment parameter value exceeding a threshold, predicting that the certain phrase has a meaning in common with a particular sentiment neutral phrase and replacing the certain phrase with the particular sentiment neutral phrase.
9. The computer implemented method of claim 1, wherein the presenting to a second human user a sentiment neutral adapted communication includes presenting a communication including one or more of the following selected from the group consisting of: (a) a synthesized voice communication, and (b) a text communication.
10. The computer implemented method of claim 1, wherein the presenting to the first human user the adapted second communication includes presenting to the first human user one or more of the following selected from the group consisting of: (a) a facial expression gesture by a mechanical robot; (b) a hand gesture by a mechanical robot; (c) a facial expression gesture by a rendered 3D humanoid model representing a virtual agent; (d) a hand gesture by a rendered 3D humanoid model representing a virtual agent; (e) a synthesized voice communication, and (f) a text communication.
11. The computer implemented method of claim 1, wherein the presenting to a second human user a sentiment neutral adapted communication includes presenting a communication including each of: (a) a synthesized voice communication, and (b) a text communication, and wherein the presenting to the first human user the adapted second communication includes presenting to the first human user each of: (i) a facial gesture; (ii) a hand gesture; (iii) a synthesized voice communication, and (iv) a text communication.
12. The computer implemented method of claim 1, wherein the augmenting the second communication data to return adapted second communication data includes using a decision data structure that cognitively maps exhibited sentiment of the first human user to action decisions specifying communication content augmentations.
13. The computer implemented method of claim 1, wherein the communication data of a first human user to return one or more sentiment attribute of the communication data, includes identifying a phrase defined by the communication data, determining that the phrase has a sentiment parameter value exceeding a threshold, wherein the sentiment parameter value is an anger sentiment parameter value.
14. The computer implemented method of claim 1, wherein the adapted communication data has an associated anger sentiment parameter value that is reduced relative to an anger sentiment parameter value associated to the communication data.
15. The computer implemented method of claim 1, wherein the adapted communication data has an associated anger sentiment parameter value that is reduced relative to an anger sentiment parameter value associated to the communication data, and wherein the communication data is a communication data segment representing one or more of the following selected from the group consisting of: (a) a vocal utterance segment delimited by a pause; (b) a sentence; (c) a phrase, (d) a word.
16. The computer implemented method of claim 1, wherein the presenting to a second human user a sentiment neutral adapted communication includes presenting text based data defining the adapted communication on a displayed user interface, wherein displayed user interface displays a form list that specifies factual data items for collecting from the first user, wherein open data fields of the form list indicate factual items remaining for collection from the first human user.
17. The computer implemented method of claim 1, wherein the presenting to a second human user a sentiment neutral adapted communication includes presenting text based data defining the adapted communication on a displayed user interface, wherein displayed user interface displays a form list that specifies factual data items for collecting from the first user, wherein open data fields of the form list indicate factual items remaining for collection from the first user, and wherein the displayed user interface further displays an emotion graph, that graphically depicts sentiment parameter values of a plurality of sentiment values, the plurality of sentiment parameter values indicating a current emotional state of the patron user, wherein the plurality of sentiment parameter values include an anger sentiment parameter values.
18. The computer implemented method of claim 1, wherein the first human user is a patron user and wherein the second human user is an enterprise agent user of an enterprise that provides services to the patron user, wherein the presenting the adapted second communication includes using a mechanical robot physically located in a common enterprise venue with the first human user, wherein the examining communication data of the first human user includes each of: (I) examining converting vocal utterance data of the first human user to text using a speech to text converted; (II) examining acoustical characteristics of vocal utterance data of the first human user to return sentiment data based on a mapping between vocal utterance acoustical characteristics and exhibited sentiment; (III) examining text based data entered into a client computer device by the first human user; and (IV) examining video data representing facial expressions of the first human user, wherein the presenting to a second human user a sentiment neutral adapted communication includes presenting a communication including each of: (a) a synthesized voice communication, and (b) a text communication, and wherein the presenting to the first human user the adapted second communication includes presenting to the first human user each of: (i) a facial gesture presented by the mechanical robot; (ii) a hand gesture presented by the mechanical robot; (iii) a synthesized voice communication presented by the mechanical robot, and (iv) a text communication presented on a display mounted to the mechanical robot, wherein the adapted communication data has an associated anger sentiment parameter value that is reduced relative to an anger sentiment parameter value associated to the communication data, wherein the processing the communication data to return sentiment neutral adapted communication data includes identifying a certain phrase defined by the communication data having a sentiment parameter value exceeding a threshold, predicting that the certain phrase has a null meaning and replacing the certain phrase with a null phrase, wherein the processing the communication data to return sentiment neutral adapted communication data includes identifying a certain phrase defined by the communication data having a sentiment parameter value exceeding a threshold, predicting that the certain phrase has a meaning in common with a particular sentiment neutral phrase and replacing the certain phrase with the particular sentiment neutral phrase, wherein the presenting to a second human user a sentiment neutral adapted communication includes presenting text based data defining the adapted communication on a displayed user interface, wherein displayed user interface displays a form list that specifies factual data items for collecting from the first user, wherein open data fields of the form list indicate factual items remaining for collection from the first user, and wherein the displayed user interface further displays an emotion graph, that graphically depicts sentiment parameter values of a plurality of sentiment values, the plurality of sentiment parameter values indicating a current emotional state of the patron user, wherein the plurality of sentiment parameter values include an anger sentiment parameter values.
19. A computer program product comprising: a computer readable storage medium readable by one or more processing circuit and storing instructions for execution by one or more processor for performing a method comprising: examining communication data of a first human user to return one or more sentiment attribute of the communication data; processing the communication data to return sentiment neutral adapted communication data, the processing being in dependence on the one or more sentiment attribute; presenting to a second human user a sentiment neutral adapted communication, the sentiment neutral adapted communication being based on the sentiment neutral adapted communication data; augmenting second communication data to return adapted second communication data, the augmenting being in dependence of the one or more sentiment attribute; and presenting to the first human user an adapted second communication, the adapted second communication being based on the adapted second communication data.
20. A system comprising: a memory; at least one processor in communication with memory; and program instructions executable by one or more processor via the memory to perform a method comprising: examining communication data of a first human user to return one or more sentiment attribute of the communication data; processing the communication data to return sentiment neutral adapted communication data, the processing being in dependence on the one or more sentiment attribute; presenting to a second human user a sentiment neutral adapted communication, the sentiment neutral adapted communication being based on the sentiment neutral adapted communication data; augmenting second communication data to return adapted second communication data, the augmenting being in dependence of the one or more sentiment attribute; and presenting to the first human user an adapted second communication, the adapted second communication being based on the adapted second communication data.
</claims>
</document>
