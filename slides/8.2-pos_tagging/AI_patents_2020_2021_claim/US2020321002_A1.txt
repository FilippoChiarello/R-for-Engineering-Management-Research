<document>

<filing_date>
2020-03-23
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-05
</priority_date>

<ipc_classes>
G06N3/04,G10L15/22
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
DIRAFZOON, ALIREZA
Shin, JongHo
Anshu, Aviral
</inventors>

<docdb_family_id>
72661688
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR CONTEXT-ENRICHED ATTENTIVE MEMORY NETWORK WITH GLOBAL AND LOCAL ENCODING FOR DIALOGUE BREAKDOWN DETECTION
</title>

<abstract>
A method, an electronic device and computer readable medium for dialogue breakdown detection are provided. The method includes obtaining a verbal input from an audio sensor. The method also includes generating a reply to the verbal input. The method additionally includes identifying a local context from the verbal input and a global context from the verbal input, additional verbal inputs previously received by the audio sensor, and previous replies generated in response to the additional verbal inputs. The method further includes identifying a dialogue breakdown in response to determining that the reply does not correspond to the local context and the global context. In addition, the method includes generating sound corresponding to the reply through a speaker when the dialogue breakdown is not identified.
</abstract>

<claims>
1. A method comprising: obtaining a verbal input from an audio sensor; generating, by a processor, a reply to the verbal input; identifying, by the processor, a local context from the verbal input and a global context from the verbal input, additional verbal inputs previously received by the audio sensor, and previous replies generated in response to the additional verbal inputs; identifying, by the processor, a dialogue breakdown in response to determining that the reply does not correspond to the local context and the global context; and generating sound corresponding to the reply through a speaker when the dialogue breakdown is not identified.
2. The method of claim 1, further comprising: generating, by the processor, a notification that indicates that the dialogue breakdown occurred in response to identifying the dialogue breakdown, wherein the notification includes at least one of a sound notification generated by the speaker and a visual notification output to a display.
3. The method of claim 1, further comprising: recovering, by the processor, from the dialogue breakdown based on the local context and the global context in response to identification of the dialogue breakdown.
4. The method of claim 3, wherein recovering from the dialogue breakdown comprises: identifying, by the processor, at least one of a first confidence score associated with automatic speech recognition, a second confidence score associated with natural language understanding, and a third confidence score associated with the verbal input; identifying, by the processor, context associated with a state, based on verifying that the context associated with the state corresponds to the local context, and the global context, and at least one of the first confidence score, the second confidence score, and the third confidence score; and generating, by the processor, a modified reply based on the context associated with the state, wherein the state includes at least one of a slot, a keyword, a sentence, and the verbal input.
5. The method of claim 1, further comprising: encoding the verbal input using a Long Short Term Memory (LSTM) Network to identify temporal relationships between the verbal input, the previous replies, and the additional verbal inputs; identifying the local context from focused keywords within the verbal input; and identifying the global context from repeated keywords and mutual context information within the verbal input, the reply, the additional verbal inputs, and the previous replies.
6. The method of claim 5 wherein identifying the global context comprises identifying a quantity of the additional verbal inputs and the previous replies based on a window size that is at least one of a fixed window size or a varying window size.
7. The method of claim 1, wherein identifying the dialogue breakdown comprises: generating a memory score that is associated with a first label, the memory score indicates a probability that the first label corresponds to the reply and the global context; generating an utterance score that is associated with the first label, the utterance score indicates a probability that the reply corresponds to the verbal input; assigning a first weight to the memory score and a second weight to the utterance score to generate a weighted memory score and a weighted utterance score, respectively; generating a weighted score based on combining the weighted memory score and the weighted utterance score, the weighted score is associated with the first label; and comparing the weighted score to a previous weighted scores that are associated with respective labels, wherein the dialogue breakdown is identified when the first label is associated with the dialogue breakdown, and the weighted score is larger than the previous weighted scores.
8. An electronic device comprising: an audio sensor; a speaker configured to generate sound; and a processor operably coupled to the audio sensor and the speaker; a memory operably coupled to the processor, the memory including instructions executable by the processor to: obtain a verbal input from the audio sensor, generate a reply to the verbal input, identify a local context from the verbal input and a global context from the verbal input, additional verbal inputs previously received by the audio sensor, and previous replies generated in response to the additional verbal inputs, identify a dialogue breakdown in response to determining that the reply does not correspond to the local context and the global context, and generate the sound corresponding to the reply through the speaker when the dialogue breakdown is not identified.
9. The electronic device of claim 8, wherein: the electronic device further comprises a display; and the memory includes further instructions to generate a notification that indicates that the dialogue breakdown occurred in response to identifying the dialogue breakdown, wherein the notification includes at least one of a sound notification generated by the speaker and a visual notification output to the display.
10. The electronic device of claim 8, wherein the memory includes further instructions to recover from the dialogue breakdown based on the local context and the global context in response to identification of the dialogue breakdown.
11. The electronic device of claim 10, wherein to recover from the dialogue breakdown, the memory includes instructions to: identify at least one of a first confidence score associated with automatic speech recognition, a second confidence score associated with natural language understanding, and a third confidence score associated with the verbal input; identify context associated with a state, based on verifying that the context associated with the state corresponds to the local context, and the global context, and at least one of the first confidence score, the second confidence score, and the third confidence score; and generate a modified reply based on the context associated with the state, wherein the state includes at least one of a slot, a keyword, a sentence, and the verbal input.
12. The electronic device of claim 8, wherein to identify the local context and the global context, the memory includes instructions to: encode the verbal input using a Long Short Term Memory (LSTM) Network to identify temporal relationships between the verbal input, the previous replies, and the additional verbal inputs; identify the local context from focused keywords within the verbal input; and identify the global context from repeated keywords and mutual context information within the verbal input, the reply, the additional verbal inputs, and the previous replies.
13. The electronic device of claim 12, wherein to identify the global context, the memory includes instructions to identify a quantity of the additional verbal inputs and the previous replies based on a window size that is at least one of a fixed window size or a varying window size.
14. The electronic device of claim 8, wherein to identify the dialogue breakdown, the memory includes instructions to: generate a memory score that is associated with a first label, the memory score indicates a probability that the first label corresponds to the reply and the global context; generate an utterance score that is associated with the first label, the utterance score indicates a probability that the reply corresponds to the verbal input; assign a first weight to the memory score and a second weight to the utterance score to generate a weighted memory score and a weighted utterance score, respectively; generate a weighted score based on combining the weighted memory score and the weighted utterance score, the weighted score is associated with the first label; and compare the weighted score to a previous weighted scores that are associated with respective labels, wherein the dialogue breakdown is identified when the first label is associated with the dialogue breakdown, and the weighted score is larger than the previous weighted scores.
15. A non-transitory machine-readable medium containing instructions that when executed cause at least one processor of an electronic device to: obtain a verbal input from an audio sensor; generate a reply to the verbal input; identify a local context from the verbal input and a global context from the verbal input, additional verbal inputs previously received by the audio sensor, and previous replies generated in response to the additional verbal inputs; identify a dialogue breakdown in response to determining that the reply does not correspond to the local context and the global context; and generate sound corresponding to the reply through a speaker when the dialogue breakdown is not identified.
16. The non-transitory machine-readable medium of claim 15, further containing instructions that when executed cause the at least one processor to: generate a notification that indicates that the dialogue breakdown occurred in response to identifying the dialogue breakdown, wherein the notification includes at least one of a sound notification generated by the speaker and a visual notification output to a display.
17. The non-transitory machine-readable medium of claim 15, further containing instructions that when executed cause the at least one processor to: recover from the dialogue breakdown based on the local context and the global context in response to identification of the dialogue breakdown.
18. The non-transitory machine-readable medium of claim 17, wherein the instructions that when executed cause the at least one processor to recover from the dialogue breakdown, comprise instructions that when executed cause the at least one processor to: identify at least one of a first confidence score associated with automatic speech recognition, a second confidence score associated with natural language understanding, and a third confidence score associated with the verbal input; identify context associated with a state, based on verifying that the context associated with the state corresponds to the local context, and the global context, and at least one of the first confidence score, the second confidence score, and the third confidence score; and generate a modified reply based on the context associated with the state, wherein the state includes at least one of a slot, a keyword, a sentence, and the verbal input.
19. The non-transitory machine-readable medium of claim 15, further containing instructions that when executed cause the at least one processor to: encode the verbal input using a Long Short Term Memory (LSTM) Network to identify temporal relationships between the verbal input, the previous replies, and the additional verbal inputs; identify the local context from focused keywords within the verbal input; and identify the global context from repeated keywords and mutual context information within the verbal input, the reply, the additional verbal inputs, and the previous replies.
20. The non-transitory machine-readable medium of claim 15, further containing instructions that when executed cause the at least one processor to: generate a memory score that is associated with a first label, the memory score indicates a probability that the first label corresponds to the reply and the global context; generate an utterance score that is associated with the first label, the utterance score indicates a probability that the reply corresponds to the verbal input; assign a first weight to the memory score and a second weight to the utterance score to generate a weighted memory score and a weighted utterance score, respectively; generate a weighted score based on combining the weighted memory score and the weighted utterance score, the weighted score is associated with the first label; and compare the weighted score to a previous weighted scores that are associated with respective labels, wherein the dialogue breakdown is identified when the first label is associated with the dialogue breakdown, and the weighted score is larger than the previous weighted scores.
</claims>
</document>
