<document>

<filing_date>
2019-10-31
</filing_date>

<publication_date>
2020-02-27
</publication_date>

<priority_date>
2016-08-18
</priority_date>

<ipc_classes>
G06N3/04,G06N3/063,G10L15/20,G10L21/0208
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
FUKUDA TAKASHI
</inventors>

<docdb_family_id>
61192053
</docdb_family_id>

<title>
TRAINING OF FRONT-END AND BACK-END NEURAL NETWORKS
</title>

<abstract>
A computer-implemented method for training a front-end neural network ("front-end NN") and a back-end neural network ("back-end NN") is provided. The method includes combining the back-end neural network with the front-end neural network to form a joint layer to thereby generate a combined neural network. The method also includes training the combined neural network for a speech recognition with a set of utterances as training data, with the joint layer having a plurality of frames and each frame having a plurality of bins, and where one or more specific units in each frame are dropped during the training, each of the specific units being selected randomly or based on a bin number to which the respective unit is set within its frame, with the specific units corresponding to one or more common frequency bands.
</abstract>

<claims>
1. A computer-implemented method for training a front-end neural network and a back-end neural network, the method comprising: combining the back-end neural network with the front-end neural network to form a joint layer to thereby generate a combined neural network; and training the combined neural network for a speech recognition with a set of utterances as training data, wherein the joint layer comprises a plurality of frames and each frame comprises a plurality of bins, and wherein one or more specific units in each frame are dropped during the training, each of the specific units being selected randomly or based on a bin number to which the respective unit is set within its frame, the plurality of the specific units corresponding to one or more common frequency bands.
2. The method according to claim 1, wherein the front-end neural network is configured to estimate clean frequency filter bank features from noisy input features, the noisy input features having a higher-dimensional feature space than a feature space being had by the clean frequency filter bank features.
3. The method according to claim 2, wherein the clean frequency filter bank features are log Mel-frequency filter bank features.
4. The method according to claim 2, wherein the noisy input features are log-power spectral input features.
5. The method according to claim 1, wherein the front-end neural network is configured to estimate clean frequency filter bank features from noisy frequency filter bank input features, wherein the noisy frequency filter bank input features and the clean frequency filter bank features are in the same feature space.
6. The method according to claim 5, wherein the noisy frequency filter bank input features, the clean frequency filter bank features, or a combination of these are log Mel-frequency filter bank features.
7. The method according to claim 1, wherein the output layer of the front-end neural network is composed of a plurality of units and corresponds to a plurality of frames before and after a center frame.
8. The method according to claim 1, wherein combining the back-end neural network with the front-end neural network further comprises integrating the output layer of the front-end neural network as a hidden layer in the combined neural network.
9. The method according to claim 1, wherein the method further comprises: setting a plurality of specific units for the dropping, each of the specific units corresponding to a specific frequency band.
10. The method according to claim 1, the method further comprising: training the front-end neural network, wherein the trained front-end neural network is used in the combining.
11. A speech recognition system which performs a speech recognition using the combined neural network which was trained according to the method described in claim 1.
12. A system, comprising: a processor; and a memory storing a program, which, when executed on the processor, performs an operation for training a front-end neural network and a back-end neural network, the operation comprising: combining the back-end neural network for a speech recognition with the front-end neural network to form a joint layer to thereby generate a combined neural network; and training the combined neural network for a speech recognition with a set of utterances as training data, wherein the joint layer comprises a plurality of frames and each frame comprises a plurality of bins, and wherein one or more specific units in each frame are dropped during the training, each of the specific units being selected randomly or based on a bin number to which the respective unit is set within its frame, the plurality of the specific units corresponding to one or more common frequency bands.
13. A computer program product for training a front-end neural network and a back-end neural network, the computer program product comprising a computer usable storage medium having program instructions embodied therewith, wherein the computer readable storage medium is not a transitory signal per se,_the program instructions executable by a computer to cause the computer to perform a method comprising: combining the back-end neural network with the front-end neural network to form a joint layer to thereby generate a combined neural network; and training the combined neural network for a speech recognition with a set of utterances as training data, wherein the joint layer comprises a plurality of frames and each frame comprises a plurality of bins, and wherein one or more specific units in each frame are dropped during the training, each of the specific units being selected randomly or based on a bin number to which the respective unit is set within its frame, the plurality of the specific units corresponding to one or more common frequency bands.
14. The computer program product according to claim 13, wherein the front-end neural network is configured to estimate clean frequency filter bank features from noisy input features, the noisy input features having a higher-dimensional feature space than a feature space being had by the clean frequency filter bank features.
15. The computer program product according to claim 14, wherein the clean frequency filter bank features are log Mel-frequency filter bank features.
16. The computer program product according to claim 13, wherein the front-end neural network is configured to estimate clean frequency filter bank features from noisy frequency filter bank input features, wherein the noisy frequency filter bank input features and the clean frequency filter bank features are in the same feature space.
17. The computer program product according to claim 16, wherein the noisy input features are log-power spectral input features.
18. The computer program product according to claim 13, wherein the output layer of the front-end neural network is composed of a plurality of units and corresponds to a plurality of frames before and after a center frame.
19. The computer program product according to claim 13, wherein combining the back-end neural network with the front-end neural network further comprises integrating the output layer of the front-end neural network as a hidden layer in the combined neural network.
20. The computer program product according to claim 13, wherein the method further comprises: setting a plurality of specific units for the dropping, each of the specific units corresponding to a specific frequency band.
</claims>
</document>
