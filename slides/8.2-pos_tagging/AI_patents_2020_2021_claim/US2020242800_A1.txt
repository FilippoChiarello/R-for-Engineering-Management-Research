<document>

<filing_date>
2019-12-19
</filing_date>

<publication_date>
2020-07-30
</publication_date>

<priority_date>
2019-01-29
</priority_date>

<ipc_classes>
G06K9/00,G06T7/73
</ipc_classes>

<assignee>
INSTITUTE FOR INFORMATION INDUSTRY
</assignee>

<inventors>
CHEN, HUNG-EN
CHIU, JING-MING
CHANG, HSIAO-CHEN
CHO, WEI-YU
HSU, YU-LING
</inventors>

<docdb_family_id>
71732718
</docdb_family_id>

<title>
DETERMINATION APPARATUS AND METHOD FOR GAZE ANGLE
</title>

<abstract>
A determination apparatus and method for gaze angle are provided. The apparatus analyzes an image to generate a plurality of facial triaxial positioning values and a plurality of facial landmark points. The apparatus obtains a plurality of specific facial landmark points from the facial landmark points to generate a heatmap, and compares the heatmap with a standard heatmap to generate an image compensation value. The apparatus performs a facial correcting process based on the image and the image compensation value to generate a virtual corrected image. The apparatus analyzes the virtual corrected image to obtain a displacement of pupil. The apparatus determines a gaze angle of a user according to a determination model for gaze angle, the facial triaxial positioning values and the displacement of pupil.
</abstract>

<claims>
1. A determination apparatus for gaze angle, comprising: a storage, storing a determination model for gaze angle; an image capturing device, being configured to capture an image; a processor, being electrically connected to the storage and the image capture device and configured to perform the following operations: analyzing the image to generate a plurality of first facial triaxial positioning values and a plurality of first facial landmark points; obtaining a plurality of specific facial landmark points from the first facial landmark points to generate a heatmap, and comparing the heatmap with a standard heatmap to generate an image compensation value, wherein the image compensation value indicates a displacement of facial landmark; performing a facial correcting process based on the image and the image compensation value to generate a virtual corrected image; analyzing the virtual corrected image to obtain a first displacement of pupil; and determining a gaze angle of a user according to the determination model for gaze angle, the first facial triaxial positioning values, and the first displacement of pupil.
2. The determination apparatus for gaze angle of claim 1, wherein the first facial triaxial positioning values include a yaw, a pitch, and a roll, and each of the yaw, the pitch, and the roll corresponds to a value.
3. The determination apparatus for gaze angle of claim 1, wherein the first facial landmark points are used to mark a plurality of facial feature positions, and the facial feature positions at least include feature positions of a corner of the left eye, a corner of the right eye, a nasal tip, a left end of the mouth, and a right end of the mouth, the heatmap is generated based on the facial feature positions, and the facial correcting process is performing a facial frontalization process.
4. The determination apparatus for gaze angle of claim 3, wherein the facial correcting process further comprises the following operations: performing a couple-agent discriminator process after performing the facial frontalization process, wherein the couple-agent discriminator process is used to enhance simulation accuracy of the virtual corrected image.
5. The determination apparatus for gaze angle of claim 1, wherein the operation of analyzing the virtual corrected image further comprises the following operations: analyzing the virtual corrected image to generate a plurality of second facial landmark points; selecting a plurality of eye contour feature points according to the second facial landmark points, and extracting a pupil feature point from the eye contour feature points; and obtaining the first displacement of pupil based on the pupil feature point.
6. The determination apparatus for gaze angle of claim 1, wherein the determination model for gaze angle is established by the following steps: receiving a plurality of sample images and a plurality of second displacements of pupil corresponding to the sample images respectively; analyzing each of the sample images to generate a plurality of second facial triaxial positioning values corresponding to each of the sample images; and establishing the determination model for gaze angle through machine learning according to the second displacements of pupil and the second facial triaxial positioning values corresponding to each of the sample images.
7. The determination apparatus for gaze angle of claim 6, wherein each of the second displacements of pupil corresponding to each of the sample images is a value measured by a measuring device for displacement of pupil when capturing each of the sample images.
8. The determination apparatus for gaze angle of claim 1, wherein the processor further determines a relative coordinate of gazing according to the gaze angle and a coordinate of a gaze target.
9. The determination apparatus for gaze angle of claim 8, wherein the processor further determines one of the objects corresponding to the relative coordinate of gazing, and provides a piece of information corresponding to the object to the user.
10. A determination method for gaze angle, being adapted for a determination apparatus for gaze angle, the determination apparatus comprising a storage, an image capturing device, and a processor, the storage storing a determination model for gaze angle, the image capturing device being configured to capture an image, and the determination method being performed by the processor and comprising: analyzing the image to generate a plurality of first facial triaxial positioning values and a plurality of first facial landmark points; obtaining a plurality of specific facial landmark points from the first facial landmark points to generate a heatmap, and comparing the heatmap with a standard heatmap to generate an image compensation value, wherein the image compensation value indicates a displacement of facial landmark; performing a facial correcting process based on the image and the image compensation value to generate a virtual corrected image; analyzing the virtual corrected image to obtain a first displacement of pupil; and determining a gaze angle of a user according to the determination model for gaze angle, the first facial triaxial positioning values, and the first displacement of pupil.
11. The determination method for gaze angle of claim 10, wherein the first facial triaxial positioning values include a yaw, a pitch, and a roll, and each of the yaw, the pitch, and the roll corresponds to a value.
12. The determination method for gaze angle of claim 10, wherein the first facial landmark points are used to mark a plurality of facial feature positions, and the facial feature positions at least include feature positions of a corner of the left eye, a corner of the right eye, a nasal tip, a left end of the mouth, and a right end of the mouth, the heatmap is generated based on the facial feature positions, and the facial correcting process is performing a facial frontalization process.
13. The determination method for gaze angle of claim 12, wherein the facial correcting process further comprises: performing a couple-agent discriminator process after performing the facial frontalization process, wherein the couple-agent discriminator process is used to enhance simulation accuracy of the virtual corrected image.
14. The determination method for gaze angle of claim 10, wherein the step of analyzing the virtual corrected image further comprises: analyzing the virtual corrected image to generate a plurality of second facial landmark points; selecting a plurality of eye contour feature points according to the second facial landmark points, and extracting a pupil feature point from the eye contour feature points; and obtaining the first displacement of pupil based on the pupil feature point.
15. The determination for gaze angle method of claim 10, wherein the determination model for gaze angle is established by the steps comprising: receiving a plurality of sample images and a plurality of second displacements of pupil corresponding to the sample images respectively; analyzing each of the sample images to generate a plurality of second facial triaxial positioning values corresponding to each of the sample images; and establishing the determination model for gaze angle through machine learning according to the second displacements of pupil and the second facial triaxial positioning values corresponding to each of the sample images.
16. The determination method for gaze angle of claim 15, wherein each of the second displacements of pupil corresponding to each of the sample images is a value measured by a measuring device for displacement of pupil when capturing each of the sample images.
17. The determination method for gaze angle of claim 10, wherein the determination method further comprises: determining a relative coordinate of gazing according to the gaze angle and a coordinate of a gaze target.
18. The determination method for gaze angle of claim 17, wherein the determination method further comprises: determining one of the objects corresponding to the relative coordinate of gazing, and provides a piece of information corresponding to the object to the user.
</claims>
</document>
