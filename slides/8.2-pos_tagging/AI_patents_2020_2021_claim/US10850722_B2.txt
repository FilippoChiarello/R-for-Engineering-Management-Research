<document>

<filing_date>
2018-09-10
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2017-03-07
</priority_date>

<ipc_classes>
B60W10/04,B60W10/10,B60W10/184,B60W10/20,B60W30/09,B60W30/12,B60W40/04,G05D1/00,G05D1/02,G08G1/16
</ipc_classes>

<assignee>
Motional AD LLC
</assignee>

<inventors>
FRAZZOLI, EMILIO
QIN, BAOXING
</inventors>

<docdb_family_id>
63445020
</docdb_family_id>

<title>
Planning for unknown objects by an autonomous vehicle
</title>

<abstract>
Among other things, a world model is maintained of an environment of a vehicle. A hypothetical object in the environment that cannot be perceived by sensors of the vehicle is included in the world model.
</abstract>

<claims>
1. A method of controlling an autonomous vehicle, the method comprising: generating a model of an environment of the autonomous vehicle, comprising: generating, based on sensor data collected by one or more sensors of the autonomous vehicle, a model of a perceived environment, the perceived environment comprising regions in the environment that are detectable by the one or more sensors, and generating, based on the sensor data and external data, a model of an unperceived environment, the unperceived environment comprising regions in the environment that are undetectable by the one or more sensors, wherein generating the model of the unperceived environment includes determining a boundary between the perceived environment and the unperceived environment; generating a hypothetical object in the model of the unperceived environment, wherein the hypothetical object has one or more properties; and controlling the autonomous vehicle to drive in the environment based on the one or more properties of the hypothetical object.
2. The method of claim 1, wherein determining the boundary comprises: determining a physical range of the one or more sensors.
3. The method of claim 1, wherein determining the boundary comprises: receiving data from the one or more sensors; and using the data from the one or more sensors to distinguish a perceivable ground from a foreground that obscures a portion of the ground.
4. The method of claim 1, wherein the one or more sensors include a LIDAR sensor, and wherein determining the boundary comprises: receiving a point cloud from the LIDAR sensor; determining, based on a known ground elevation, that a first point in a particular vertical slice of the point cloud that is perpendicular to a ground plane characterizes a ground location; determining that a different second point in the particular vertical slice of the point cloud characterizes an object that obscures the ground; and defining the boundary in the particular vertical slice as located between the first point and the second point.
5. The method of claim 1, wherein generating the hypothetical object in the model of the unperceived environment comprises: receiving data describing a configuration of the unperceived environment; based on the configuration of the unperceived environment, placing a model of the hypothetical object at a location in the model of the unperceived environment, the model of the hypothetical object including discretized points defining a shape of the hypothetical object; and assigning properties to the model of the hypothetical object.
6. The method of claim 5, wherein the hypothetical object is a vehicle, wherein the data describing the configuration of the unperceived environment includes data describing a road in the unperceived environment, and wherein placing the model of the vehicle at the location involves placing the vehicle on an unperceived segment of the road.
7. The method of claim 1, wherein the properties include motion characteristics of the hypothetical object.
8. The method of claim 7, wherein the motion characteristics include at least one of an orientation, a direction of motion, or a speed of the hypothetical object, wherein the orientation, direction, or speed are based on the external data.
9. The method of claim 8, wherein controlling the autonomous vehicle based on the one or more properties of the hypothetical object comprises: determining a predicted trajectory of the hypothetical object based on the orientation, direction, and speed; and controlling the autonomous vehicle to avoid the predicted trajectory of the hypothetical object.
10. The method of claim 9, wherein the predicted trajectory of the hypothetical object is a worst-case trajectory of the hypothetical object.
11. The method of claim 1, wherein the external data includes at least one of map information, geographic information, traffic information, or traffic law information.
12. An apparatus comprising: one or more processors; and a memory storage in data communication with the one or more processors, the memory storage storing instructions executable by the one or more processors and that upon such execution cause the one or more processors to perform operations comprising: generating a model of an environment of an autonomous vehicle, comprising: generating, based on sensor data collected by one or more sensors of the autonomous vehicle, a model of a perceived environment, the perceived environment comprising regions in the environment that are detectable by the one or more sensors, and generating, based on the sensor data and external data, a model of an unperceived environment, the unperceived environment comprising regions in the environment that are undetectable by the one or more sensors, wherein generating the model of the unperceived environment includes determining a boundary between the perceived environment and the unperceived environment; generating a hypothetical object in the model of the unperceived environment, wherein the hypothetical object has one or more properties; and controlling the autonomous vehicle to drive in the environment based on the one or more properties of the hypothetical object.
13. The apparatus of claim 12, wherein determining the boundary comprises: determining a physical range of the one or more sensors.
14. The apparatus of claim 12, wherein determining the boundary comprises: receiving data from the one or more sensors; and using the data from the one or more sensors to distinguish a perceivable ground from a foreground that obscures a portion of the ground.
15. The apparatus of claim 12, wherein the one or more sensors include a LIDAR sensor, and wherein determining the boundary comprises: receiving a point cloud from the LIDAR sensor; determining, based on a known ground elevation, that a first point in a particular vertical slice of the point cloud that is perpendicular to a ground plane characterizes a ground location; determining that a different second point in the particular vertical slice of the point cloud characterizes an object that obscures the ground; and defining the boundary in the particular vertical slice as located between the first point and the second point.
16. The apparatus of claim 12, wherein generating the hypothetical object in the model of the unperceived environment comprises: receiving data describing a configuration of the unperceived environment; based on the configuration of the unperceived environment, placing a model of the hypothetical object at a location in the model of the unperceived environment, the model of the hypothetical object including discretized points defining a shape of the hypothetical object; and assigning properties to the model of the hypothetical object.
17. The apparatus of claim 16, wherein the hypothetical object is a vehicle, wherein the data describing the configuration of the unperceived environment includes data describing a road in the unperceived environment, and wherein placing the model of the vehicle at the location involves placing the vehicle on an unperceived segment of the road.
18. The apparatus of claim 12, wherein the properties include motion characteristics of the hypothetical object, wherein the motion characteristics include at least one of an orientation, a direction of motion, or a speed of the hypothetical object, wherein the orientation, direction, or speed are based on the external data.
19. The apparatus of claim 18, wherein controlling the autonomous vehicle based on the one or more properties of the hypothetical object comprises: determining a predicted trajectory of the hypothetical object based on the orientation, direction, and speed; and controlling the autonomous vehicle to avoid the predicted trajectory of the hypothetical object.
20. A non-transitory computer storage medium encoded with a computer program, the program comprising instructions that when executed by data processing apparatus cause the data processing apparatus to perform operations comprising: generating a model of an environment of an autonomous vehicle, comprising: generating, based on sensor data collected by one or more sensors of the autonomous vehicle, a model of a perceived environment, the perceived environment comprising regions in the environment that are detectable by the one or more sensors, and generating, based on the sensor data and external data, a model of an unperceived environment, the unperceived environment comprising regions in the environment that are undetectable by the one or more sensors, wherein generating the model of the unperceived environment includes determining a boundary between the perceived environment and the unperceived environment; generating a hypothetical object in the model of the unperceived environment, wherein the hypothetical object has one or more properties; and controlling the autonomous vehicle to drive in the environment based on the one or more properties of the hypothetical object.
</claims>
</document>
