<document>

<filing_date>
2020-06-16
</filing_date>

<publication_date>
2021-01-28
</publication_date>

<priority_date>
2019-07-23
</priority_date>

<ipc_classes>
G06F16/23,G06F16/25,G06N20/00,G06N5/04,G06Q10/06,G06Q10/10,G06Q20/38,G06Q30/02,G06Q40/00
</ipc_classes>

<assignee>
PredictiveHR, Inc.
</assignee>

<inventors>
Lyerly, William M.
Occhino, Charles
</inventors>

<docdb_family_id>
74190450
</docdb_family_id>

<title>
CURRENCY REDUCTION FOR PREDICTIVE HUMAN RESOURCES SYNCHRONIZATION RECTIFICATION
</title>

<abstract>
A method and system for repairing data with incongruent or incompatible types that detects anomalies in human resources data, and if anomalies are present in the data, then suggests to a user corrections and synchronizing actions that better match patterns in the data, specifically listing reasons why the data is potentially erroneous and justifies the suggestion based on objective data to aid the user in accepting corrections and synchronizing actions or performing further review and analysis on the data using the method and system.
</abstract>

<claims>
1. A computer implemented method for automatically detecting and rectifying data anomalies to synchronize human resource datasets, the method comprising: receiving, using a computing device, raw human resource data from an external source, the raw human resource data including compensation data and storing the received raw human resource data in data storage according to a source data schema; configuring, using a computing device, the raw human resource data stored in data storage according to a source data schema including currency reduction on the compensation data and storing the configured data in data storage; processing, using a computing device, the configured data to determine anomalies in in the compensation data using a machine learning predictive model and storing the results in data storage; and generating and displaying, through a graphical user interface of a computing device, the results of the predictive model indicating anomalies in the compensation data stored in the data storage together with potential reasons for anomalies and suggested correction to rectify and synchronize the data.
2. The method of claim 1, wherein the step of configuring the raw human resource data comprises: performing data enrichment on the raw data; performing deep character level inspection on enriched data; extracting numerical data from the enriched data; analyzing the numerical data and performing currency reduction; calculating first level metrics; and transforming currency data and updating data records with transformed data.
3. The method of claim 1, wherein the step of processing the configured data comprises: segregating and preparing test datasets and training datasets; generating and evaluating feature sets comprising extracting relevant content from the transformed data; fitting, validating, and testing predictive model; deploying the predictive model and transforming currency data; and calculating second level metrics using model data.
4. The method of claim 1, wherein the performing currency reduction comprises transforming currency data into a standardized format.
5. The method of claim 1, wherein storing the received raw human resource data in data storage according to a source data schema comprising creating an extract from the raw data comprising rows and columns, stored in data storage comprising at least one database or network of distributed files residing on a plurality of network-based non-transitory storage devices, and creating input variables from relevant content in the raw data, the input variables to be populated into the predictive model storing information in a standardized format.
6. The method of claim 2, wherein data enrichment of the raw data maps data fields or records comprising a location or an office to a predefined and populated economic zone that is associated with currencies, then stored in data storage.
7. The method of claim 2, wherein calculating first level metrics comprises performing simple search and count tasks against a source schema, wherein calculation results are stored in data storage.
8. The method of claim 2, wherein deep character level inspection inspects each character in a row or column of the enriched data, categorizing each character as a symbol, letter or space, and wherein multiple characters are joined together, and patterns are identified, and results of deep character level inspection are stored in data storage.
9. The method of claim 8, wherein extracting numerical data analyzes the results of deep character level inspection to identify currency symbols and abbreviations in compensation columns, and numerical components that fit patterns representing numbers are identified as currency amounts and stored in data storage.
10. The method of claim 8, wherein the currency amounts are converted to a query currency using conversion rates for days closest to a job posting date or open date.
11. The method of claim 8, wherein the currency amounts are converted to query currency comprising United States Dollars (USD) using conversion rates for days closest to a job posting date or open date.
12. The method of claim 3, wherein segregating and preparing test datasets and training datasets further comprises training the predictive model using a training dataset selected from the raw data and a test dataset selected from the raw data, wherein training rows comprising the training datasets are marked if currencies in compensation columns and currencies flagged for economic zone column match and then are reduced to a singular value, and wherein test rows comprising the test datasets are marked as all rows that do not fit into training rows.
13. The method of claim 3, wherein a feature set comprises a grouping of features, and generating and evaluating feature sets comprises using recursive feature elimination and cross-validation techniques and iterating through and combining features, including non-categorical features and feature groups for categorical features, adding and/or subtracting features in dynamic combinations in a series of loops to form at least one feature set, wherein constraints are placed on a minimum and a maximum number of features and feature groups to contain in a feature set, and outputting a number of feature sets with individual features being ranked with respect to one another within each feature set.
14. The method of claim 3, wherein the at least one predictive model further comprises a multiple logistic regression model used to find an equation that best predicts the probability of a value derived from a function of variables indicating predictions for which currencies belong to which job records in the raw data, training dataset and testing dataset.
15. The method of claim 14, wherein fitting, validating and testing the at least one predictive model further comprises: training a logistic regression model applying machine learning algorithms to the at least one predictive model and calculating model accuracy wherein feature sets are tested in the at least one predictive model for accuracy with respect to results corresponding to the training datasets to create a hierarchy of one or more candidate models wherein the one or more candidate models that produce a highest level of accuracy using training data of the training datasets are selected for use in the at least one predictive model, wherein accuracy is calculated as a ratio of correctly predicted observation to total observations and wherein a currency model with a highest probability is used for a predicted currency of a row singular currency value is set as a correct value for the training dataset which is fed into logistic regression algorithms to output a number of features sets that are individually applied to the logistic regression algorithms using training data for both the test datasets and training datasets; and after logistic regression models comprising the at least one predictive model for all relevant currencies have been calculated, the at least one predictive model is fit with test data of the test dataset and the at least one predictive model is run to identify potential errant rows or records in the raw data and test data of the test dataset, wherein training data and test data are applied using a feature set with the highest level of accuracy to the logistic regression model that calculates the features and creates predictions for which currencies belong to which job records, where anomalous predicted currencies for the test data are identified as differentials between predicted currency of the test dataset and currency used in an economic zone and/or currency code, wherein if currency information is not present for both the economic zone and the currency code, a row is tagged as anomalous.
16. The method of claim 3, wherein calculating second level metrics using model data comprises calculations performed against features of the feature sets to explain reasons why anomalous records or jobs were labeled as particular currencies, wherein once calculations are performed on the features sets that were selected to be used with a logistic regression algorithm, wherein second level calculations are used to determine if the predictions made by a logistic regression algorithm yield useable, consistent results, and wherein second level metrics comprise one or more of: detect currency symbols in compensation columns; detect currency abbreviation in compensation columns; job count as related to geography, job specific and recruitment personnel feature groups; average job counts as related to geography, percentile of base USD amount; percentile of the budget bonus USD amount; and combinations thereof.
17. The method of claim 1, wherein automatically generating and displaying, to the user, through the graphical user interface of the computing device, results of the predictive model further comprises at least one list indicating instances of erroneous data in the raw data presented to the user using a web page, app or other electronic format jobs are linked to predicted currencies with a corresponding listing of potential reasons why the raw data is erroneous and suggested corrections to rectify the raw data and synchronize the raw data including a notification that justifies the suggested corrections using evidence derived from the raw data and test dataset as well as providing, through a graphical user interface, tools for the user to analyze and review potentially erroneous data and accept suggested corrections or other actions synchronizing data, such that the user can manually decide which anomalous jobs are errors, not-errors or unknown, wherein resultant data can then be reprocessed using the method, with potentially new anomalies being detected and old anomalies being tagged as not being anomalies.
18. The method of claim 17, wherein displaying, to the user, through the graphical user interface of the computing device, results of the predictive model further comprises outputting at least one of a numerical score, a graphical format, a Venn diagram, a visual aid and a notification.
19. The method of claim 18, wherein displaying a notification to the user comprises accessing a table in the data storage that has narratives stored and selecting or extracting numbers or values from second level calculations that are inserted into the narratives when thresholds are breached or exceeded, where each narrative of the narratives that is triggered when thresholds are breached or exceeded is inserted and combined into the notification displayed to the user on the graphical user interface with numbers or values inserted into it, for review by the user.
20. A system for automatically detecting and rectifying data anomalies to synchronize datasets, the system comprising: one or more databases or distributed file systems communicating over an electronic network and configured for data storage; and a computing device comprising one or more processors, memory, programmable instructions or applications, machine learning algorithm modules calculation engines, and at least one operating system (OS), and configured to: receive, raw human resource data from an external source, the raw human resource data including compensation data and store the received raw human resource data in data storage according to a source data schema; configure the raw human resource data stored in data storage according to a source data schema including currency reduction on the compensation data and store the configured data in data storage; process the configured data to determine anomalies in in the compensation data using a machine learning predictive model and storing the results in data storage; and a graphical user interface configured to generate and display the results of the predictive model indicating anomalies in the compensation data stored in the data storage together with potential reasons for anomalies and suggested correction to rectify and synchronize the data.
21. The system of claim 20, wherein to configure the raw human resource data the computing device: performs data enrichment on the raw data; performs deep character level inspection on enriched data; extracts numerical data from the enriched data; analyzes the numerical data and performing currency reduction; calculates first level metrics; and transforms currency data and updates data records with transformed data.
22. The system of claim 20, wherein to process the configured data the computing device: segregates and prepares test datasets and training datasets; generates and evaluates feature sets comprising extracting relevant content from the transformed data; fits, validates, and tests predictive model; deploys the predictive model and transforms currency data; and calculates second level metrics using model data.
23. The system of claim 20, further configured to create an extract from the raw data comprising rows and columns, stored in data storage comprising at least one database or network of distributed files residing on a plurality of network-based non-transitory storage devices, and creating input variables from relevant content in the raw data, the input variables to be populated into the predictive model storing information in a standardized format.
24. The system of claim 21, wherein data enrichment of the raw data maps data fields or records comprising a location or an office to a predefined and populated economic zone that is associated with currencies, then stored in data storage.
25. The system of claim 21, wherein first level metrics are calculated by performing simple search and count tasks against a source schema, wherein calculation results are stored in data storage.
26. The system of claim 21, wherein deep character level inspection is performed each character in a row or column of the enriched data, categorizing each character as a symbol, letter or space, and wherein multiple characters are joined together, and patterns are identified, and results of deep character level inspection are stored in data storage.
27. The system of claim 21, wherein the system is further configured to extract numerical data from results of deep character level inspection to identify currency symbols and abbreviations in compensation columns, and numerical components that fit patterns representing numbers are identified as currency amounts and stored in data storage, and wherein the currency amounts are converted to a query currency using conversion rates for days closest to a job posting date or open date.
28. The system of claim 22, wherein the system is further configured to use test datasets and training datasets to train the predictive model using a training dataset selected from the raw data and a test dataset selected from the raw data, wherein training rows comprising the training datasets are marked if currencies in compensation columns and currencies flagged for economic zone column match and then are reduced to a singular value, and wherein test rows comprising the test datasets are marked as all rows that do not fit into training rows.
29. The system of claim 22, wherein a feature set comprises a grouping of features, and generating and evaluating feature sets comprises using recursive feature elimination and cross-validation techniques and iterating through and combining features, including non-categorical features and feature groups for categorical features, adding and/or subtracting features in dynamic combinations in a series of loops to form at least one feature set, wherein constraints are placed on a minimum and a maximum number of features and feature groups to contain in a feature set, and outputting a number of feature sets with individual features being ranked with respect to one another within each feature set.
30. The system of claim 22, wherein the at least one predictive model further comprises a multiple logistic regression model used to find an equation that best predicts the probability of a value derived from a function of variables indicating predictions for which currencies belong to which job records in the raw data, training dataset and testing dataset.
31. The system of claim 22, wherein the system is further configured to fit, validate and test the at least one predictive model by: training a logistic regression model applying machine learning algorithms to the at least one predictive model and calculating model accuracy wherein feature sets are tested in the at least one predictive model for accuracy with respect to results corresponding to the training datasets to create a hierarchy of one or more candidate models wherein the one or more candidate models that produce a highest level of accuracy using training data of the training datasets are selected for use in the at least one predictive model, wherein accuracy is calculated as a ratio of correctly predicted observation to total observations and wherein a currency model with a highest probability is used for a predicted currency of a row singular currency value is set as a correct value for the training dataset which is fed into logistic regression algorithms to output a number of features sets that are individually applied to the logistic regression algorithms using training data for both the test datasets and training datasets; and after logistic regression models comprising the at least one predictive model for all relevant currencies have been calculated, the at least one predictive model is fit with test data of the test dataset and the at least one predictive model is run to identify potential errant rows or records in the raw data and test data of the test dataset, wherein training data and test data are applied using the feature set with the highest level of accuracy to the logistic regression model that calculates the features and creates predictions for which currencies belong to which job records, where anomalous predicted currencies for the test data are identified as differentials between predicted currency of the test dataset and currency used in an economic zone and/or currency code, wherein if currency information is not present for both the economic zone and the currency code, a row is tagged as anomalous.
32. The system of claim 22, wherein second level metrics are calculated from calculations performed against features of the feature sets to explain reasons why anomalous records or jobs were labeled as particular currencies, wherein once calculations are performed on the features sets that were selected to be used with a logistic regression algorithm, wherein second level calculations are used to determine if the predictions made by a logistic regression algorithm yield useable, consistent results, and wherein second level metrics comprise one or more of: detect currency symbols in compensation columns; detect currency abbreviation in compensation columns; job count as related to geography, job specific and recruitment personnel feature groups; average job counts as related to geography, percentile of base USD amount; percentile of the budget bonus USD amount; and combinations thereof.
33. The system of claim 20, wherein the graphical user interface of the computing device is further configured to automatically generate and display, to the user, results of the predictive model comprising at least one list indicating instances of erroneous data in the raw data presented to the user using a web page, app or other electronic format jobs are linked to predicted currencies with a corresponding listing of potential reasons why the raw data is erroneous and suggested corrections to rectify the raw data and synchronize the raw data including a notification that justifies the suggested corrections using evidence derived from the raw data and test dataset as well as providing, through a graphical user interface, tools for the user to analyze and review potentially erroneous data and accept suggested corrections or other actions synchronizing data, such that the user can manually decide which anomalous jobs are errors, not-errors or unknown, wherein resultant data can then be reprocessed using the method, with potentially new anomalies being detected and old anomalies being tagged as not being anomalies.
34. The system of claim 20, wherein the graphical user interface of the computing device is further configured to display, to the user, results of the predictive model comprising output including at least one of a numerical score, a graphical format, a Venn diagram, a visual aid and a notification, wherein a notification to the user comprises accessing a table in the data storage that has narratives stored and selecting or extracting numbers or values from second level calculations that are inserted into the narratives when thresholds are breached or exceeded, where each narrative of the narratives that is triggered when thresholds are breached or exceeded is inserted and combined into the notification displayed to the user on the graphical user interface with numbers or values inserted into it, for review by the user.
35. A non-transitory computer-readable medium for automatically detecting and rectifying data anomalies to synchronize datasets, the non-transitory computer-readable medium comprising stored electronic instructions that when executed on at least one computing device perform steps comprising: receiving, using a computing device, raw human resource data from an external source, the raw human resource data including compensation data and storing the received raw human resource data in data storage according to a source data schema; configuring, using a computing device, the raw human resource data stored in data storage according to a source data schema including currency reduction on the compensation data and storing the configured data in data storage; processing, using a computing device, the configured data to determine anomalies in in the compensation data using a machine learning predictive model and storing the results in data storage; and generating and displaying, through a graphical user interface of a computing device, the results of the predictive model indicating anomalies in the compensation data stored in the data storage together with potential reasons for anomalies and suggested correction to rectify and synchronize the data.
36. A computer implemented method for automatically detecting and rectifying data anomalies to synchronize datasets, the method comprising: receiving, using a computing device, raw data from an external data source; performing data enrichment on the raw data received; performing deep character level inspection on enriched data; extracting numerical data from the enriched data; analyzing the numerical data and performing currency reduction; calculating first level metrics; transforming currency data and updating data records with transformed data; segregating and preparing test datasets and training datasets; generating and evaluating feature sets comprising extracting relevant content from the transformed data; fitting, validating and testing a predictive model; deploying the predictive model and transforming currency data; calculating second level metrics using model data; and automatically generating and presenting, to a user, through a graphical user interface, results of the predictive model deployed in a displayable format for further end user remediation comprising indicating instances of erroneous data in the raw data together with a corresponding listing of potential reasons why the raw data is erroneous, and suggested corrections to rectify the raw data and synchronize the raw data.
37. A system for automatically detecting and rectifying data anomalies to synchronize datasets, the system comprising: one or more databases or distributed file systems communicating over an electronic network and configured for data storage, a computing device comprising one or more processors, memory, programmable instructions or applications, machine learning algorithm modules calculation engines, and at least one operating system (OS), and configured to: receive raw data from an external data source; perform data enrichment on the raw data received; perform deep character level inspection on enriched data; extract numerical data from the enriched data; analyze the numerical data and perform currency reduction; calculate first level metrics; transform currency data and updating data records with transformed data; segregate and prepare test datasets and training datasets; generate and evaluate feature sets comprising extracting relevant content from the transformed data; fit, validate and test a predictive model; deploy the predictive model to transform currency data; calculate second level metrics using model data; and a graphical user interface configured to automatically generate and present, to a user, results of the predictive model deployed in a displayable format for further end user remediation comprising a list indicating instances of erroneous data in the raw data together with a corresponding listing of potential reasons why the raw data is erroneous, and suggested corrections to rectify the raw data and synchronize the raw data.
38. A non-transitory computer-readable medium for automatically detecting and rectifying data anomalies to synchronize datasets, the non-transitory computer-readable medium comprising stored electronic instructions that when executed on at least one computing device perform steps comprising: receiving, using the at least one computing device, raw data from a data source; performing data enrichment on the raw data received; performing deep character level inspection on enriched data; extracting numerical data from the enriched data; analyzing the numerical data and performing currency reduction; calculating first level metrics; transforming currency data and updating data records with transformed data; segregating and preparing test datasets and training datasets; generating and evaluating feature sets comprising extracting relevant content from the transformed data; fitting, validating and testing a predictive model; deploying the predictive model and transforming currency data; calculating second level metrics using model data; and automatically generating and presenting, to a user, through a graphical user interface, results of the predictive model deployed in a displayable format for further end user remediation comprising a list indicating instances of erroneous data in the raw data together with a corresponding listing of potential reasons why the raw data is erroneous, and suggested corrections to rectify the raw data and synchronize the raw data.
</claims>
</document>
