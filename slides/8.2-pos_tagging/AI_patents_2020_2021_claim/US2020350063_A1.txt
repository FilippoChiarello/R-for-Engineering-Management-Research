<document>

<filing_date>
2020-05-01
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2019-05-03
</priority_date>

<ipc_classes>
G06T7/00,G06T7/70,G16H10/60,G16H40/20,G16H50/20
</ipc_classes>

<assignee>
IMAGE STREAM MEDICAL
</assignee>

<inventors>
MITCHELL, EDDIE E.
RENZI PETER
Thornton, Thomas Michael
</inventors>

<docdb_family_id>
73017019
</docdb_family_id>

<title>
CONTEXT AND STATE AWARE TREATMENT ROOM EFFICIENCY
</title>

<abstract>
A system and method are provided for performing operations comprising: receiving one or more images from an image capture device of a medical treatment location; applying a trained machine learning model to the one or more images to detect presence of a patient in the medical treatment location, the trained machine learning model being trained to establish a relationship between one or more features of images of the medical treatment location and patient presence; generating context assessment for the medical treatment location based on the detected presence of the patient; and transmitting, over a network, the context assessment for presentation on a user interface of a client device.
</abstract>

<claims>
1. A method comprising: receiving one or more images from an image capture device of a medical treatment location; applying a trained machine learning model to the one or more images to detect presence of a patient in the medical treatment location, the trained machine learning model being trained to establish a relationship between one or more features of images of the medical treatment location and patient presence; generating context assessment for the medical treatment location based on the detected presence of the patient; and transmitting, over a network, the context assessment for presentation on a user interface of a client device.
2. The method of claim 1, wherein the trained machine learning model is further trained to distinguish between presence of the patient and presence of medical treatment location personnel.
3. The method of claim 1, wherein the trained machine learning model is trained by: receiving a plurality of training videos, a first set of the training videos comprising a gurney with a patient, and a second set of the training videos comprising the gurney without the patient, each of the plurality of training videos being tagged with information identifying the gurney; applying the machine learning model to a first training video of the plurality of training videos to estimate a location of the gurney in the first training video; obtaining the information identifying the gurney associated with the first training video; computing a deviation between the estimated location of the gurney in the first training video and the obtained information identifying the gurney; updating parameters of the machine learning model based on the computed deviation; and repeating the applying, obtaining, computing and updating steps for a second of the plurality of training videos.
4. The method of claim 3, wherein the plurality of training videos are captured. at different camera angles using a single camera or multiple cameras, and wherein regions in a panoramic camera are designated for use as different ones of the plurality of training videos.
5. The method of claim 3, wherein the plurality of training videos are captured. at different lighting conditions.
6. The method of claim 3, further comprising adjusting the plurality of training videos by applying one or more photographic filters.
7. The method of claim 1, wherein the trained machine learning model comprises a neural network, linear regression, logistical regression, random forest, gradient boosted trees, support vector machines, decision trees, nearest neighbor, or na√Øve banes.
8. The method of claim 1, further comprising receiving a medical procedure stream, wherein the context assessment is generated based on the medical procedure stream and the detected presence of the patient.
9. The method of claim 1, wherein applying the trained machine learning model to the one or more images to detect presence of the patient in the medical treatment location comprises: estimating a location of a gurney in the one or more images based on an output of the trained machine learning model; applying object recognition techniques to a portion of the one or more images corresponding to the location of the gurney to determine existence of the patient on the gurney; in response to determining that the patient exists on the gurney, detecting that the patient is present in the medical treatment location; and in response to determining that the patient fails to exist on the gurney, detecting that the patient is absent from the medical treatment location.
10. The method of claim 1, further comprising: determining a camera angle associated with the image capture device; and selecting the trained machine learning model from a plurality of trained machine learning models based on the determined camera angle, each of the plurality of trained machine learning models corresponding to a different camera angle.
11. The method of claim 1, wherein the context assessment comprises patient arrival time and departure times at the medical treatment location, presence of a doctor at the medical treatment location, condition of a cut being open or closed, presence of cleaning staff at the medical treatment location, readiness of the medical treatment location.
12. The method of claim 1, wherein a medical procedure is performed at the medical treatment location, further comprising determining, as the context assessment, a number of personnel at the medical treatment location while the medical procedure is being performed.
13. The method of claim 12, further comprising receiving a telemetry stream of the medical procedure or an audio stream of the medical procedure, the telemetry stream comprising at least one of patient scheduling information, electronic medical record (EMR) data, or patient registration information.
14. The method of claim 12, further comprising determining, as the context assessment, a number of times a door to enter the medical treatment location is opened while the medical procedure is being performed.
15. The method of claim 1, wherein the context assessment comprises at least one of timeout start time, timeout finish time, video device connection state, video device disconnection state, procedure information, physician information, procedure duration, variance between a scheduled start time of the procedure and when presence of the patient is detected, or turnover time based on a determination that the patient is no longer present.
16. The method of claim 1, further comprising: alerting one or more stakeholders about a medical procedure performed at the medical treatment location; associating the medical procedure with one or more outcomes of the medical procedure; and tracking medical treatment location efficiency and utilization.
17. The method of claim 1, wherein the image capture device includes at least one of: a first video camera monitoring patient arrival, departure and people counting throughout a medical procedure; a second video camera monitoring state of the patient and a sterile field including an instrument table; a third video camera configured to capture different angles of the medical treatment location; or a fourth video camera configured to capture a panoramic view of the medical treatment location and designate different portions of the panoramic view.
18. A system comprising: one or more processors configured to perform operations comprising: receiving one or more images from an image capture device of a medical treatment location; applying a trained machine learning model to the one or more images to detect presence of a patient in the medical treatment location, the trained machine learning model being trained to establish a relationship between one or more features of images of the medical treatment location and patient presence; generating context assessment for the medical treatment location based on the detected presence of the patient; and transmitting, over a network, the context assessment for presentation on a user interface of a client device.
19. The system of claim 18, wherein the trained machine learning model is further trained to distinguish between presence of the patient and presence of medical treatment location personnel.
20. A non-transitory computer-readable medium comprising non-transitory computer-readable instructions that, when executed by one or more processors, configure the one or more processors to perform operations comprising: receiving one or more images from an image capture device of a medical treatment location; applying a trained machine learning model to the one or more images to detect presence of a patient in the medical treatment location, the trained machine learning model being trained to establish a relationship between one or more features of images of the medical treatment location and patient presence; generating context assessment for the medical treatment location based on the detected presence of the patient; and transmitting, over a network, the context assessment for presentation on a user interface of a client device.
</claims>
</document>
