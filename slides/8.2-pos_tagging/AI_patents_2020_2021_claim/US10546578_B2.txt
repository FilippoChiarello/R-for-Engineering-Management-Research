<document>

<filing_date>
2017-12-20
</filing_date>

<publication_date>
2020-01-28
</publication_date>

<priority_date>
2016-12-26
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08,G10L15/16,G10L15/18,G10L15/22,G10L15/30,G10L21/00
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
PARK, MEE-JEONG
KIM, JAE-DEOK
</inventors>

<docdb_family_id>
62625039
</docdb_family_id>

<title>
Method and device for transmitting and receiving audio data
</title>

<abstract>
An artificial intelligence (AI) system configured to simulate functions of a human brain, such as recognition, determination, etc., by using a machine learning algorithm, such as deep learning, etc., and an application thereof. The AI system includes a method performed by a device to transmit and receive audio data to and from another device includes obtaining a voice input that is input by a first user of the device, obtaining recognition information indicating a meaning of the obtained voice input, transmitting the obtained voice input to the other device, determining whether an abnormal situation occurs, in which a second user of the other device does not understand the transmitted voice input, and transmitting the obtained recognition information to the other device, based on a result of the determination.
</abstract>

<claims>
1. A device comprising: a user input interface configured to obtain a voice input that is input by a first user of the device; a communication interface configured to transmit the obtained voice input to another device; and a controller configured to: obtain recognition information indicating a meaning of the obtained voice input, and determine whether an abnormal situation occurs, in which a second user of the other device does not understand the transmitted voice input, wherein the communication interface is further configured to transmit the obtained recognition information to the other device, based on a result of the determination.
2. The device of claim 1, wherein the controller is further configured to: obtain a first artificial intelligence (AI) voice recognition model configured to interpret the voice input of the first user, and generate text indicating the meaning of the voice input of the first user by using the first AI voice recognition model.
3. The device of claim 2, wherein the first AI voice recognition model is generated in the device and registered in the device.
4. The device of claim 2, wherein the first AI voice recognition model is generated in another device of the first user and provided to the device.
5. The device of claim 1, further comprising: a display configured to display, on a screen of the device, a check message checking whether the obtained recognition information indicates the meaning of the voice input, when the abnormal situation occurs, wherein the controller is further configured to correct the recognition information, based on an input generated by the first user to correct the recognition information, in response to the displayed check message, and wherein the communication interface is further configured to transmit the corrected recognition information to the other device.
6. The device of claim 1, wherein the controller is further configured to determine whether the abnormal situation occurs, by analyzing at least one voice input of the second user received from the other device.
7. The device of claim 6, wherein the controller is further configured to: convert the at least one voice input of the second user into text, and determine, based on whether a predetermined phrase is comprised in the converted text, whether the abnormal situation occurs.
8. The device of claim 1, wherein the communication interface is further configured to receive, from the other device, a request for the recognition information indicating the meaning of the voice input.
9. The device of claim 1, wherein the communication interface is further configured to receive, from the other device, recognition information indicating a meaning of a voice input of the second user, the voice input being input to the other device by the second user, and wherein the controller is further configured to: analyze content of a conversation between the first user and the second user based on the recognition information indicating the meaning of the voice input of the first user and the recognition information indicating the meaning of the voice input of the second user, and determine, based on the analyzed content of the conversation, whether the abnormal situation occurs.
10. The device of claim 1, further comprising: a memory configured to store a conversation log of the first user, wherein the communication interface is further configured to receive a conversation log of the second user, from the other device, and wherein the controller is further configured to: reconstruct content of a conversation based on the stored conversation log of the first user and the received conversation log of the second user, determine a subject of the conversation by analyzing the reconstructed content of the conversation, extract, from the reconstructed content of the conversation, a portion in which the abnormal situation occurs, in which the first user does not understand the voice input of the second user received from the other device, and generate notes comprising at least one of the reconstructed content of the conversation, the determined subject of the conversation, and the extracted portion in which the abnormal situation occurs.
11. A method, performed by a device, of transmitting and receiving audio data to and from another device, the method comprising: obtaining a voice input that is input by a first user of the device; obtaining recognition information indicating a meaning of the obtained voice input; transmitting the obtained voice input to the other device; determining whether an abnormal situation occurs, in which a second user of the other device does not understand the transmitted voice input; and transmitting the obtained recognition information to the other device, based on a result of the determination.
12. The method of claim 11, further comprising: obtaining a first artificial intelligence (AI) voice recognition model configured to interpret the voice input of the first user, wherein the obtaining of the recognition information comprises generating text indicating the meaning of the voice input of the first user by using the first AI voice recognition model.
13. The method of claim 12, wherein the first AI voice recognition model is generated in another device of the first user and provided to the device.
14. The method of claim 11, further comprising: displaying, on a screen of the device, a check message checking whether the obtained recognition information indicates the meaning of the voice input, when the abnormal situation occurs; and correcting the recognition information, based on an input generated by the first user to correct the recognition information, in response to the displayed check message, wherein the transmitting of the obtained recognition information comprises transmitting the corrected recognition information to the other device.
15. The method of claim 11, wherein the determining of whether the abnormal situation occurs comprises determining whether the abnormal situation occurs, by analyzing at least one voice input of the second user received from the other device.
16. The method of claim 15, wherein the determining of whether the abnormal situation occurs comprises: converting the at least one voice input of the second user into text; and determining, based on whether a predetermined phrase is comprised in the converted text, whether the abnormal situation occurs.
17. The method of claim 11, wherein the determining of whether the abnormal situation occurs comprises receiving, from the other device, a request for the recognition information indicating the meaning of the voice input.
18. The method of claim 11, further comprising: receiving, from the other device, recognition information indicating a meaning of a voice input of the second user, the voice input being input to the other device by the second user; and analyzing content of a conversation between the first user and the second user based on the recognition information indicating the meaning of the voice input of the first user and the recognition information indicating the meaning of the voice input of the second user, wherein the determining of whether the abnormal situation occurs comprises determining, based on the analyzed content of the conversation, whether the abnormal situation occurs.
19. The method of claim 11, further comprising: storing a conversation log of the first user in the device; receiving a conversation log of the second user, from the other device; reconstructing content of a conversation based on the stored conversation log of the first user and the received conversation log of the second user; determining a subject of the conversation by analyzing the reconstructed content of the conversation; extracting, from the reconstructed content of the conversation, a portion in which the abnormal situation occurs, in which the first user does not understand the voice input of the second user received from the other device; and generating notes comprising at least one of the reconstructed content of the conversation, the determined subject of the conversation, and the extracted portion in which the abnormal situation occurs.
20. A non-transitory computer-readable recording medium having embodied thereon a program for executing the method of claim 11.
21. The device of claim 8, wherein the transmitting of the obtained recognition information to the other device is in response to receiving, from the other device, the request for the recognition information indicating the meaning of the voice input.
</claims>
</document>
