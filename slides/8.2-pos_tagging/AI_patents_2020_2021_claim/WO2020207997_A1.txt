<document>

<filing_date>
2020-04-07
</filing_date>

<publication_date>
2020-10-15
</publication_date>

<priority_date>
2019-04-09
</priority_date>

<ipc_classes>
G06T11/60
</ipc_classes>

<assignee>
PHILIPS ELECTRONICS
</assignee>

<inventors>
VAN BREE, KARL
GEBRE, BINYAM
</inventors>

<docdb_family_id>
66429148
</docdb_family_id>

<title>
MODIFYING AN APPEARANCE OF HAIR
</title>

<abstract>
According to various embodiments, a method of modifying an appearance of hair in an image of a head of a subject is disclosed. The method comprises providing, as an input to a first trained neural network model, an image of a head of a subject having a region of hair; generating, using the first trained neural network model and based on the image of the head, a hair layer comprising an estimated representation of portions of the image containing hair, and a face layer comprising an estimated representation of the head of the subject with the region of hair having been removed; providing, as an input to a second trained neural network model, an indication of a defined hairstyle to be incorporated into the image, and the generated hair layer; generating, using the second trained neural network model, a modified hair layer based on the indication of the defined hairstyle and the generated hair layer; and generating, using a processor, a modified image of the head of the subject by applying the modified hair layer to the generated face layer.
</abstract>

<claims>
1. A method of modifying an appearance of hair in an image of a head of a subject, the method comprising:
providing, as an input to a first trained neural network model, an image of a head of a subject having a region of hair;
generating, using the first trained neural network model and based on the image of the head, a hair layer comprising an estimated representation of portions of the image including hair, and a face layer comprising an estimated representation of the head of the subject with the region of hair having been removed;
providing, as an input to a second trained neural network model, an indication of a defined hairstyle to be incorporated into the image, and the generated hair layer;
generating, using the second trained neural network model, a modified hair layer based on the indication of the defined hairstyle and the generated hair layer; and
generating, using a processor, a modified image of the head of the subject by applying the modified hair layer to the generated face layer.
2. A method according to claim 1, further comprising:
generating, using the first trained neural network model and based on the image of the head, a hair mask defining the region of the image that contains hair.
3. A method according to claim 2, further comprising:
receiving, at a processor, an annotation of the image of the head of the subject, the annotation comprising an indication of the region of the image that contains hair; and calculating, using a processor, a degree of accuracy of the generated hair mask with regard to the received annotation.
4. A method according to claim 2 or claim 3, further comprising:
providing, as an input to the second trained neural network model, the generated hair mask;
wherein generating the modified hair layer comprises generating a modified hair layer based on the generated hair mask, such that hair in the modified hair layer is generated only within regions defined by the generated hair mask.
5. A method according to any of claims 2 to 4, further comprising:
receiving, via a user interface, a user input to modify a parameter of at least one of the generated hair layer, the indication of the defined hairstyle and the hair mask.
6. A method according to any of the preceding claims, wherein at least one of the first and second trained neural network models comprises or forms part of a generative adversarial network.
7. A method according to any of the preceding claims, further comprising:
providing the modified image for presentation to a user.
8. A method according to any of the preceding claims, further comprising:
evaluating, using a discriminative network, a quality of the generated face layer with regard to an image of a head of a subject with no visible hair in the region.
9. A method according to any of the preceding claims, further comprising:
evaluating, using a discriminative network, a quality of the generated modified image of the head of the subject.
10. A method of training a neural network model to manipulate an appearance of hair in an image of a head of a subject, the method comprising:
generating a training dataset comprising a plurality of images of heads of subjects, each having hair in a particular region, and a plurality of images of heads of subjects, each without hair in the particular region; and
training the neural network model to generate, based on an input image of a head of a subject having hair in the particular region, an estimated representation of the head of the subject with the hair in the particular region having been removed.
11. A method of training a neural network model to manipulate an appearance of hair in an image, the method comprising:
generating a training dataset comprising a plurality of hair layers, each hair layer comprising an estimated representation of portions of the image containing hair, and a plurality of indicators of defined hairstyles to be incorporated into an image; and
training the neural network model to generate, based on an input hair layer and a particular defined hairstyle, a modified hair layer.
12. A method according to claim 11, further comprising:
providing to the neural network model during said training, a hair mask defining an extent of a hair-containing portion of the input hair layer and a noise element.
13. A computer program product comprising a computer-readable medium, the computer-readable medium having computer-readable code embodied therein, the computerreadable code being configured such that, on execution by a suitable computer or processor, the computer or processor is caused to perform the method as claimed in any of the preceding claims.
14. An apparatus for modifying an image of a head of a subject, the apparatus comprising:
a memory comprising instruction data representing a set of instructions; and a processor configured to communicate with the memory and to execute the set of instructions, wherein the set of instructions, when executed by the processor, cause the processor to:
provide, as an input to a first trained neural network model, an image of a head of a subject having a region of hair;
generate, using the first trained neural network model and based on the image of the head, a hair layer comprising estimated representation of portions of the image containing hair, and a face layer comprising a representation of the head of the subject with the region of hair having been removed;
provide, as an input to a second trained neural network model, an indication of a defined hairstyle to be incorporated into the image, and the generated hair layer;
generate, using the second trained neural network model and based on the indication of the defined hairstyle and the generated hair layer, a modified hair layer resembling the defined hairstyle; and generate a modified image of the head of the subject by applying the modified hair layer to the generated face layer.
15. An apparatus according to claim 14, further comprising:
a display to display the modified image of the head of the subject.
</claims>
</document>
