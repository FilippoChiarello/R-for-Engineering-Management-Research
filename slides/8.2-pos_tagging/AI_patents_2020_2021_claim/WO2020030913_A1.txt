<document>

<filing_date>
2019-08-07
</filing_date>

<publication_date>
2020-02-13
</publication_date>

<priority_date>
2018-08-07
</priority_date>

<ipc_classes>
G06N20/20,G06N3/04,G06N5/00,G06N5/04
</ipc_classes>

<assignee>
SOPHOS
</assignee>

<inventors>
DUCAU, FELIPE
HARANG, RICHARD
</inventors>

<docdb_family_id>
67659904
</docdb_family_id>

<title>
METHODS AND APPARATUS FOR MANAGEMENT OF A MACHINE-LEARNING MODEL TO ADAPT TO CHANGES IN LANDSCAPE OF POTENTIALLY MALICIOUS ARTIFACTS
</title>

<abstract>
In some embodiments, an apparatus includes a memory and a processor. The processor can be configured to train a machine-learning(ML)model to output an identification of whether an artifact is malicious and (2) a confidence value associated with the identification of whether the artifact is malicious. The processor can further be configured to receive a set of artifacts during a set of time periods, and provide a representation of each artifact from the set of artifacts to obtain as an output of the MLmodel including an indication of whether that artifact is malicious and a confidence value associated with the indication. The processor can be further configured to calculate a confidence metric for each time period based on the confidence value associated with each artifact, and send an indication to retrain the MLmodel based on the confidence metric for at least one time period meeting a retraining criterion.
</abstract>

<claims>
1. An apparatus, comprising:
a memory; and
a processor operatively coupled to the memory, the processor configured to:
train, at a time, a machine learning model to output (1) an identification of whether an artifact is malicious and (2) a confidence value associated with the identification of whether the artifact is malicious,
receive a set of artifacts during each time period from a set of time periods, each time period from the set of time periods being after the time,
for each time period from the set of time periods, provide a representation of each artifact from the set of artifacts received during that time period to the machine learning model to obtain as an output of the machine learning model an indication of whether that artifact is malicious and a confidence value associated with the indication of whether that artifact is malicious,
calculate a confidence metric for each time period from the set of time periods based on the confidence value associated with each artifact from the set of artifacts received during that time period,
send an indication to retrain the machine learning model in response to the confidence metric for at least one time period from the set of time periods meeting a retraining criterion.
2. The apparatus of claim 1 , wherein each time period from the set of time periods overlaps at least one remaining time period from the set of time periods.
3. The apparatus of claim 1, wherein each time period from the set of time periods is mutually exclusive of the remaining time periods from the set of time periods.
4. The apparatus of claim 1, wherein the machine learning model is at least one of a neural network, a decision tree or a random forest.
5. The apparatus of claim 1, wherein the confidence metric for each time period from the set of time periods is a percentage associated with (1) a number of artifacts from the set of artifacts received during that time period that have a confidence value above a confidence value threshold and (2) a total number of artifacts from the set of artifacts received during that time period.
6. The apparatus of claim 1, wherein, for each time period from the set of time periods, the processor is configured to define for each artifact from the set of artifacts received during that time period a feature vector associated with that artifact as the representation of that artifact.
7. The apparatus of claim 1, wherein the confidence value for each artifact from the set of artifacts received during each time period from the set of time periods is associated with a degree of similarity of that artifact with a set of training artifacts used to train the machine learning model.
8. A processor-readable medium storing code representing instructions to be executed by a processor, the instructions comprising code to cause the processor to:
train, at a time, a machine learning model to output (1) an identification of whether an artifact is malicious and (2) a confidence value associated with the identification of whether the artifact is malicious;
receive, during a time period after the time, a set of artifacts;
for each artifact from the set of artifacts, provide a representation of that artifact as an input to the machine learning model to obtain as an output of the machine learning model an indication of whether that artifact is malicious and a confidence value associated with the indication of whether that artifact is malicious; compare the confidence value for each artifact from the set of artifacts to a high confidence criterion to identify a number of artifacts having confidence values that meet the high confidence criterion; compare the confidence value for each artifact from the set of artifacts to a low confidence criterion to identify a number of artifacts having confidence values that meet the low confidence criterion; and send an indication to retrain the machine learning model in response to a metric associated with at least one of the number of artifacts having confidence values that meet the high confidence criterion or the number of artifacts having confidence values that meet the low confidence criterion meeting a retraining criterion.
9. The processor-readable medium of claim 8, wherein the metric is associated with the number of artifacts having confidence values that meet the high confidence criterion and the retraining criterion is a high retraining threshold, the code to cause the processor to send includes code to cause the processor to send the indication in response to a value for the metric being below the high retraining threshold.
10. The processor-readable medium of claim 8, wherein the metric a first metric and is associated with the number of artifacts having confidence values that meet the high confidence criterion, the retraining criterion being met based on a value for the first metric being below a high retraining threshold and a value for a second metric associated with the number of artifacts having confidence values that meet the low confidence criterion being below a low retraining threshold.
11. The processor-readable medium of claim 8, wherein the metric a first metric and is associated with the number of artifacts having confidence values that meet the high confidence criterion, the retraining criterion being met based on a value for the first metric being below a high retraining threshold or a value for a second metric associated with the number of artifacts having confidence values that meet the low confidence criterion being below a low retraining threshold.
12. The processor-readable medium of claim 8, wherein the machine learning model is at least one of a neural network, a decision tree or a random forest.
13. The processor-readable medium of claim 8, the code further comprising code to cause the processor to: for each artifact from the set of artifacts, define a feature vector associated with that artifact as the representation of that artifact.
14. The processor-readable medium of claim 8, wherein the confidence value for each artifact from the set of artifacts is associated with a degree of similarity of that artifact with a set of training artifacts used to train the machine learning model.
15. A method, comprising: training, at a time, a machine learning model to output (1) an identification of whether an artifact is malicious and (2) a confidence value associated with the identification of whether the artifact is malicious; receiving, during a time period after the time, a set of artifacts; for each artifact from the set of artifacts, providing a representation of that artifact as an input to the machine learning model to obtain as an output of the machine learning model an indication of whether that artifact is malicious and a confidence value associated with the indication of whether that artifact is malicious; comparing the confidence value for each artifact from the set of artifacts to a confidence criterion to identify a number of artifacts having confidence values that do not meet the confidence criterion; and sending an indication to retrain the machine learning model in response to a metric associated with the number of artifacts meeting a retraining criterion.
16. The method of claim 15, wherein the metric is a percentage associated with (1) the number of artifacts and (2) a total number of artifacts received during the time period.
17. The method of claim 15, wherein the time period is a first time period and the number of artifacts is a first number of artifacts, the metric is a rate of increase associated with a second number of artifacts and the first number of artifacts, the second number of artifacts including artifacts (1) from a set of artifacts received during a second time period before the first time period and (2) having confidence values not meeting the confidence criterion.
18. The method of claim 15, wherein the machine-learning model is at least one of a neural network, a decision tree or a random forest.
19. The method of claim 15, further comprising: for each artifact from the set of artifacts, defining a feature vector associated with that artifact as the representation of that artifact.
20. The method of claim 15, wherein the confidence value for each artifact from the set of artifacts is associated with a degree of similarity of that artifact with a set of training artifacts used to train the machine-learning model.
</claims>
</document>
