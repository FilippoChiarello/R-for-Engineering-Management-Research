<document>

<filing_date>
2018-01-31
</filing_date>

<publication_date>
2020-01-02
</publication_date>

<priority_date>
2017-01-31
</priority_date>

<ipc_classes>
G05D1/00,G05D1/02,G06K9/00,G06K9/62
</ipc_classes>

<assignee>
UNIVERSITY OF CALIFORNIA
</assignee>

<inventors>
TRIVEDI, MOHAN, M.
MARTIN, SUJITHA
YUEN, KEVAN
</inventors>

<docdb_family_id>
63040153
</docdb_family_id>

<title>
MACHINE LEARNING BASED DRIVER ASSISTANCE
</title>

<abstract>
A method for machine learning based driver assistance is provided. The method may include detecting, in one or more images of a driver operating an automobile, one or more facial landmarks. The detection of the one or more facial landmarks may include applying, to the one or more images, a first machine learning model. A gaze dynamics of the driver may be determined based at least on the one or more facial landmarks. The gaze dynamics of the driver may include a change in a gaze zone of the driver from a first gaze zone to a second gaze zone. A state of the driver may be determined based at least on the gaze dynamics of the driver. An operation of the automobile may be controlled based at least on the state of the driver. Related systems and articles of manufacture, including computer program products, are also provided.
</abstract>

<claims>
1. A system, comprising: at least data processor; and at least one memory storing instructions which, when executed by the at least one data processor, result in operations comprising: detecting, in one or more images of a driver operating an automobile, one or more facial landmarks, the detection of the one or more facial landmarks comprising applying, to the one or more images, a first machine learning model; determining, based at least on the one or more facial landmarks, a gaze dynamics of the driver, the gaze dynamics of the driver comprising a change in a gaze zone of the driver from a first gaze zone to a second gaze zone; determining, based at least on the gaze dynamics of the driver, a state of the driver; and controlling, based at least on the state of the driver, an operation of the automobile.
2. The system of claim 1, wherein the one or more facial landmarks includes a pupil, an iris, and/or an eyelid.
3. The system of claim 1, further comprising: training, based at least on training data, the first machine learning model, the training data including a plurality of images that includes and/or excludes the one or more facial landmarks, and the first machine learning model being trained to detect the one or more facial landmarks in the plurality of images.
4. The system of claim 1, further comprising: detecting, in the one or more images of the driver operating the automobile, a face, the detection of the face comprising applying, to the one or more images, a second machine learning model.
5. The system of claim 4, further comprising: training, based at least on training data, the second machine learning model, the training data including a plurality of images that includes and/or excludes the face, and the second machine learning model being trained to detect the face in the plurality of images.
6. The system of claim 1, wherein the first gaze zone and/or the second gaze zone comprises different areas at which the driver looks while operating the automobile.
7. The system of claim 1, wherein the first gaze zone and/or the second gaze zone corresponds to a left side mirror of the automobile, a right side mirror of the automobile, a rear view mirror of the automobile, an instrument cluster of the automobile, a center console of the automobile, a first portion of a windshield directly in front of the driver, a second portion of the windshield to a right of the driver, and/or a driver side window.
8. The system of claim 1, wherein the determination of the state of the driver comprises comparing the gaze dynamics of the driver to at least one gaze model associated with a maneuver, and wherein the at least one gaze model comprises gaze zones observed in drivers performing the maneuver.
9. The system of claim 8, wherein the at least one gaze model comprises a Gaussian distribution of the gaze zones observed in drivers performing the maneuver.
10. The system of claim 8, wherein the at least one gaze model comprises gaze zones observed in drivers before an execution of the maneuver, during the execution of the maneuver, and/or after the execution of the maneuver.
11. The system of claim 1, wherein the first gaze zone and/or the second gaze zone corresponds to one or more eyes of the driver being closed and/or cast downward, and wherein the state of the driver comprises that the driver is inattentive.
12. The system of claim 1, wherein the first machine learning model comprises a neural network, a regression model, an instance-based model, a regularization model, a decision tree, a Bayesian model, a clustering model, an associative model, a deep learning model, a dimensionality reduction model, and/or an ensemble model.
13. The system of claim 1, wherein the first machine learning model is configured to output a heat map comprising a first location having a first color and a second location having a second color, wherein the first location and the second location comprises different portions of the one or more images, wherein the first color corresponds to a first probability of the one or more facial landmarks being present at the first location, and wherein the second color corresponds to a second probability of the one or more facial landmarks being present at the second location.
14. The system of claim 1, wherein the control of the operation of the automobile comprises steering, acceleration, deceleration, and/or braking.
15. The system of claim 1, further comprising: determining, based at least on the one or more images of the driver, a head pose of the driver, the head pose of the driver comprising a position and/or an orientation of a head of the driver, and the gaze dynamics of the driver further being determined based at least on the head pose of the driver.
16. A computer-implemented method, comprising: detecting, in one or more images of a driver operating an automobile, one or more facial landmarks, the detection of the one or more facial landmarks comprising applying, to the one or more images, a first machine learning model; determining, based at least on the one or more facial landmarks, a gaze dynamics of the driver, the gaze dynamics of the driver comprising a change in a gaze zone of the driver from a first gaze zone to a second gaze zone; determining, based at least on the gaze dynamics of the driver, a state of the driver; and controlling, based at least on the state of the driver, an operation of the automobile.
17. The method of claim 16, wherein the one or more facial landmarks includes a pupil, an iris, and/or an eyelid.
18. The method of claim 16, further comprising: training, based at least on training data, the first machine learning model, the training data including a plurality of images that includes and/or excludes the one or more facial landmarks, and the first machine learning model being trained to detect the one or more facial landmarks in the plurality of images.
19. The method of claim 16, further comprising: detecting, in the one or more images of the driver operating the automobile, a face, the detection of the face comprising applying, to the one or more images, a second machine learning model.
20. The method of claim 19, further comprising: training, based at least on training data, the second machine learning model, the training data including a plurality of images that includes and/or excludes the face, and the second machine learning model being trained to detect the face in the plurality of images.
21. 21-33. (canceled)
</claims>
</document>
