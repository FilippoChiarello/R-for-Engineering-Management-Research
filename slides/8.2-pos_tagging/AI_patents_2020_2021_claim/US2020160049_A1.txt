<document>

<filing_date>
2020-01-21
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2017-11-22
</priority_date>

<ipc_classes>
G06K9/00,G06T7/292
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
TICKOO, OMESH
SILVA, ANDRADIGE PUBUDU MADHAWA
VARADARAJAN, SRENIVAS
DATTA, PARUAL
CARROLL, ERIN
TIWARI, NIKITA
</inventors>

<docdb_family_id>
65019111
</docdb_family_id>

<title>
AGE CLASSIFICATION OF HUMANS BASED ON IMAGE DEPTH AND HUMAN POSE
</title>

<abstract>
A mechanism is described for facilitating age classification of humans using image depth and human pose according to one embodiment. A method of embodiments, as described herein, includes facilitating, by one or more cameras of a computing device, capturing of a video stream of a scene having persons, and computing overall-depth torso lengths of the persons based on depth torso lengths of the persons. The method may further include comparing the overall-depth torso lengths with a predetermined threshold value representing a separation age between adults and children, and classifying a first set of the persons as adults if a first set of the overall-depth torso lengths associated with the first set of persons is greater than the threshold value.
</abstract>

<claims>
1. 1-20. (canceled)
21. An apparatus comprising: one or more cameras coupled to one or more processors, wherein the one or more processors to facilitate the one or more cameras to capture a video stream of scene having images of persons, the one or more processors to: evaluate the images and approximate depth values of the persons; detect, based on the approximate depth values, the persons in the scene and partition the persons into depth-based tiles using the depth values; compute, based on the approximate depth values, depth torso lengths of the persons; and classify, based on the depth torso lengths, the persons as adults or children, and estimate pixel locations of one or more body parts of each person to detect placement and length of each of the one or more body parts.
22. The apparatus of claim 21, wherein a first set of persons is classified as the adults based on a first set of depth torso lengths corresponding to the first set of persons being greater than a threshold value, and wherein a second set of persons is classified as the children based on a second set of depth torso lengths corresponding to the second set of persons being lower than or equal to the threshold value, wherein the threshold value represents a separation age point between adults age and child age.
23. The apparatus of claim 21, wherein the one or more processors are further to: facilitate a deep neural network to scale the depth-based tiles, where scaling of the depth-based tiles includes red green blue (RGB) tile scaling, wherein the one or more body parts include one or more of heads, necks, shoulders, and hips.
24. The apparatus of claim 23, wherein the one or more processors are further to compute image torso length of the persons, wherein an image torso length of a person represents a distance between a neck and a hip center of the person.
25. The apparatus of claim 21, wherein the one or more processors are further to convert the image torso lengths into the depth torso lengths of the persons based on normalized depths associated with the persons, wherein a depth torso length represents a real torso length, and wherein each normalized depth is inferred from a position of each person with respect to the one or more cameras.
26. The apparatus of claim 25, wherein a depth torso length represents a real torso length, and wherein each normalized depth is inferred from a position of each person with respect to the one or more cameras, wherein the one or more processors include a graphics processor co-located with an application processor on a common semiconductor package.
27. A method comprising: facilitating, by one or more cameras of a computing device, capturing of a video stream of a scene having images of persons; evaluating the images and approximate depth values of the persons; detecting, based on the approximate depth values, the persons in the scene and partition the persons into depth-based tiles using the depth values; computing, based on the approximate depth values, depth torso lengths of the persons; and classifying, based on the depth torso lengths, the persons as adults or children, and estimating pixel locations of one or more body parts of each person to detect placement and length of each of the one or more body parts.
28. The method of claim 27, wherein a first set of persons is classified as the adults based on a first set of depth torso lengths corresponding to the first set of persons being greater than a threshold value, and wherein a second set of persons is classified as the children based on a second set of depth torso lengths corresponding to the second set of persons being lower than or equal to the threshold value, wherein the threshold value represents a separation age point between adults age and child age.
29. The method of claim 27, wherein the one or more processors are further to: facilitate a deep neural network to scale the depth-based tiles, where scaling of the depth-based tiles includes red green blue (RGB) tile scaling, wherein the one or more body parts include one or more of heads, necks, shoulders, and hips.
30. The method of claim 29, wherein the one or more processors are further to compute image torso length of the persons, wherein an image torso length of a person represents a distance between a neck and a hip center of the person.
31. The method of claim 27, wherein the one or more processors are further to convert the image torso lengths into the depth torso lengths of the persons based on normalized depths associated with the persons, wherein a depth torso length represents a real torso length, and wherein each normalized depth is inferred from a position of each person with respect to the one or more cameras.
32. The method of claim 31, wherein a depth torso length represents a real torso length, and wherein each normalized depth is inferred from a position of each person with respect to the one or more cameras, wherein the one or more processors include a graphics processor co-located with an application processor on a common semiconductor package.
33. At least one non-transitory machine-readable medium comprising instructions which, when executed by a computing device, cause the computing device to perform operations comprising: facilitating, by one or more cameras, capturing of a video stream of a scene having images of persons; evaluating the images and approximate depth values of the persons; detecting, based on the approximate depth values, the persons in the scene and partition the persons into depth-based tiles using the depth values; computing, based on the approximate depth values, depth torso lengths of the persons; and classifying, based on the depth torso lengths, the persons as adults or children, and estimating pixel locations of one or more body parts of each person to detect placement and length of each of the one or more body parts.
34. The non-transitory machine-readable medium of claim 33, wherein a first set of persons is classified as the adults based on a first set of depth torso lengths corresponding to the first set of persons being greater than a threshold value, and wherein a second set of persons is classified as the children based on a second set of depth torso lengths corresponding to the second set of persons being lower than or equal to the threshold value, wherein the threshold value represents a separation age point between adults age and child age.
35. The non-transitory machine-readable medium of claim 33, wherein the one or more processors are further to: facilitate a deep neural network to scale the depth-based tiles, where scaling of the depth-based tiles includes red green blue (RGB) tile scaling, wherein the one or more body parts include one or more of heads, necks, shoulders, and hips.
36. The non-transitory machine-readable medium of claim 35, wherein the one or more processors are further to compute image torso length of the persons, wherein an image torso length of a person represents a distance between a neck and a hip center of the person.
37. The non-transitory machine-readable medium of claim 33, wherein the one or more processors are further to convert the image torso lengths into the depth torso lengths of the persons based on normalized depths associated with the persons, wherein a depth torso length represents a real torso length, and wherein each normalized depth is inferred from a position of each person with respect to the one or more cameras.
38. The non-transitory machine-readable medium of claim 37, wherein a depth torso length represents a real torso length, and wherein each normalized depth is inferred from a position of each person with respect to the one or more cameras, wherein the one or more processors include a graphics processor co-located with an application processor on a common semiconductor package.
</claims>
</document>
