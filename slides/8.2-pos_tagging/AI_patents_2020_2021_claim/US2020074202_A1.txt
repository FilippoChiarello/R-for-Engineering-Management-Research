<document>

<filing_date>
2019-03-07
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2018-08-29
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N3/08,G06T1/20,G06T1/60
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
KIM, CHOL-MIN
KO, TAE-KYEONG
LEE, JI-YONG
SEO, DEOK-HO
</inventors>

<docdb_family_id>
69639917
</docdb_family_id>

<title>
ELECTRONIC DEVICES AND METHODS OF OPERATING ELECTRONIC DEVICES
</title>

<abstract>
An electronic device includes a graphic processor and a memory device. The graphic processor includes an artificial neural network engine that makes an object recognition model learn by using learning data and weights to provide a learned object recognition model. The memory device, divides a feature vector into a first sub feature vector and a second feature vector, and performs a first calculation to apply the second sub feature vector and the weights to the learned object recognition model to provide a second object recognition result. The artificial neural network engine performs a second calculation to apply the first sub feature vector and the weights to the learned object recognition model to provide a first object recognition result and provides the first object recognition result to the memory device. The second calculation is performed in parallel with the first calculation.
</abstract>

<claims>
1. An electronic device, comprising: a graphic processor including an artificial neural network engine to make an object recognition model learn by using learning data and weights to provide a learned object recognition model; and a memory device to store the learning data and the weights, to divide a feature vector extracted from an input data into a first sub feature vector and a second sub feature vector, to provide the first sub feature vector to the graphic processor, to receive the learned object recognition model from the graphic processor, and to perform a first calculation to apply the second sub feature vector and the weights to the learned object recognition model to provide a second object recognition result, wherein the artificial neural network engine is to perform a second calculation to apply the first sub feature vector and the weights to the learned object recognition model to provide a first object recognition result, and to provide the first object recognition result to the memory device, the second calculation being performed in parallel with the first calculation.
2. The electronic device as claimed in claim 1, wherein the memory device is to store the first object recognition result, and to merge the first object recognition result and the second object recognition result to provide a merged object recognition result to a user.
3. The electronic device as claimed in claim 1, wherein the memory device includes: a buffer die to communicate with the graphic processor and an external device; a plurality of memory dies stacked on the buffer die; and a plurality of through silicon vias (TSVs) extending through the plurality of memory dies to connect to the buffer die, wherein each of plurality of memory dies includes a memory cell array which includes a plurality of dynamic memory cells coupled to a plurality of word-lines and a plurality of bit-lines and the dynamic memory cells store the learning data, the weights and the feature vector, and wherein the buffer die includes a processor-in-memory circuit connected to the memory dies through plurality of TSVs, and the processor-in-memory circuit divides the feature vector into the first sub feature vector and the second sub feature vector, and performs the first calculation.
4. The electronic device as claimed in claim 3, wherein the processor-in-memory circuit includes: a data distributor to receive the feature vector from at least some of the memory dies, to divide the feature vector into the first sub feature vector and the second sub feature vector, and to provide the first sub feature vector to the graphic processor; a multiplication and accumulation (MAC) circuit to receive the second sub feature vector from the data distributor, to apply the weights to the second sub feature vector from the data distributor, and to perform the second calculation to output the second object recognition result; and a controller to control the MAC circuit.
5. The electronic device as claimed in claim 4, wherein the MAC circuit is to perform matrix-vector multiplication operation on the second sub feature vector and the weights.
6. The electronic device as claimed in claim 4, further comprising: a central processing unit (CPU) to communicate with the graphic processor and the memory device through a bus, wherein the CPU includes a system software to control the data distributor and the controller, and the system software is to determine a division ratio of the first sub feature vector and the second sub feature vector.
7. The electronic device as claimed in claim 6, wherein the data distributor is to provide the first sub feature vector and the second sub feature vector by dividing the feature vector based on at least one object included in the feature vector under control of the system software.
8. The electronic device as claimed in claim 6, wherein distributor is to provide the first sub feature vector and the second sub feature vector by dividing the feature vector by a half under control of the system software.
9. The electronic device as claimed in claim 3, wherein the buffer die further include a pooler to receive the first object recognition result and the second object recognition result when the first calculation and the second calculation are completed, and to provide a merged object recognition result by merging the first object recognition result and the second object recognition result.
10. The electronic device as claimed in claim 3, wherein the memory device further includes a nonvolatile memory device formed on the buffer die and the nonvolatile memory device stores the learned object recognition model.
11. The electronic device as claimed in claim 1, wherein: the first sub feature vector and the second sub feature vector include at least some duplicate data, the graphic processor is to provide the memory device with an intermediate operation result on the at least some duplicate data, and the memory device is to perform the first calculation using the intermediate operation result on the at least some duplicate data.
12. The electronic device as claimed in claim 1, wherein the artificial neural network engine is to provide the learned object recognition model to the memory device when a similarity between a result of applying the learning data and the weights to the object recognition model and an expected value of the learning data is equal to or greater than a reference value.
13. The electronic device as claimed in claim 1, wherein the object recognition model includes a neural network model or a deep learning model which performs computing based on connection relationship among a plurality of network nodes and the weights of the network nodes.
14. The electronic device as claimed in claim 13, wherein the object recognition model includes: an input layer to receive the learning data or the first sub feature vector, the input layer including a plurality of input nodes; an output layer to generate an output of the learning data or the first sub feature vector, the output layer including a plurality of output nodes; a hidden layer to connect the input layer to the output layer, the hidden layer including a plurality of hidden nodes; a plurality of first connection lines which connect the input nodes to the hidden nodes with first weights; and a plurality of second connection lines which connect the hidden nodes to the output nodes with second weights.
15. The electronic device as claimed in claim 13, wherein the artificial neural network engine includes: a learning module to make the object recognition model learn by using the learning data and the weights; and a recognition module to apply the first sub feature vector and the weights to the learned object recognition model to provide the first object recognition result.
16. The electronic device as claimed in claim 15, wherein the learning module includes: a model learning unit to determine the object recognition model learn by using the learning data and the weights; a model storing unit to store the learned object recognition model; and a model evaluation unit to evaluate the learned object recognition model based on an evaluation data.
17. An electronic device, comprising an application processor to provide a learning data and weights, wherein the application processor is to provide a feature vector extracted from object data constituting an object; a graphic processor including an artificial neural network engine to make an object recognition model learn by using the learning data and the weights to provide a learned object recognition model; and a memory device to store the learning data, the weights, and the feature vector extracted from an input data received from the application processor, to provide learning data and the weights to the graphic processor, to divide the feature vector into a first sub feature vector and a second sub feature vector, to provide the first sub feature vector to the graphic processor, to store the learned object recognition model from the graphic processor, and to perform a first calculation to apply the second sub feature vector and the weights to the learned object recognition model to provide a second object recognition result, wherein the artificial neural network engine is to perform a second calculation to apply the first sub feature vector and the weights to the learned object recognition model to provide a first object recognition result, and to provide the first object recognition result to the memory device, the second calculation being performed in parallel with the first calculation.
18. The electronic device as claimed in claim 17, wherein the memory device includes: a buffer die to communicate with the graphic processor and an external device; a plurality of memory dies stacked on the buffer die; and a plurality of through silicon vias (TSVs) extending through the plurality of memory dies to connect to the buffer die, wherein each of plurality of memory dies includes a memory cell array which includes a plurality of dynamic memory cells coupled to a plurality of word-lines and a plurality of bit-lines and the dynamic memory cells store the learning data, the weights and the feature vector, and wherein the buffer die includes a processor-in-memory connected to the memory dies through plurality of TSVs, and the processor-in-memory is to divide the feature vector into the first sub feature vector and the second sub feature vector and to perform the first calculation.
19. A method of operating an electronic device that includes a graphic processor including an artificial neural network engine, and a memory device communicating with the graphic processor, the method comprising: making, in the artificial neural network engine, an object recognition model learn by applying learning data and weights to the object recognition model to provide a learned object recognition model; dividing, by a data distributor in the memory device, a feature vector associated with an input data into a first sub feature vector and a second sub feature vector to provide the first sub feature vector to the graphic processor; performing, by a multiplication and accumulation (MAC) circuit in the memory device, a first calculation to apply the second sub feature vector and the weights to the learned object recognition model to provide a second object recognition result; and performing, by the artificial neural network engine, a second calculation to apply the first sub feature vector and the weights to the learned object recognition model to provide a first object recognition result; and merging, by a pooler in the memory device, the first object recognition result and the second object recognition result to provide a merged object recognition result to a user, wherein the first calculation and the second calculation are performed in parallel with each other.
20. The method as claimed in claim 19, wherein the memory device includes: a buffer die to communicate with the graphic processor and an external device; a plurality of memory dies stacked on the buffer die; and a plurality of through silicon vias (TSVs) extending through the plurality of memory dies to connect to the buffer die, wherein each of plurality of memory dies includes a memory cell array having a plurality of dynamic memory cells coupled to a plurality of word-lines and a plurality of bit-lines, the dynamic memory cells storing the learning data, the weights and the feature vector, and wherein the buffer die includes a processor-in-memory connected to the memory dies through the plurality of TSVs, and the processor-in-memory is to divide the feature vector into the first sub feature vector and the second sub feature vector, and to perform the first calculation.
</claims>
</document>
