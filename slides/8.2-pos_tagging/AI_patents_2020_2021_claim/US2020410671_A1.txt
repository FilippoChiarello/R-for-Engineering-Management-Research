<document>

<filing_date>
2019-10-21
</filing_date>

<publication_date>
2020-12-31
</publication_date>

<priority_date>
2019-06-28
</priority_date>

<ipc_classes>
G06N20/10,G06N3/08,G06N7/00,G06T7/00,G06T7/70
</ipc_classes>

<assignee>
SHANDONG UNIVERSITY OF SCIENCE AND TECHNOLOGY
</assignee>

<inventors>
WANG YUANHONG
LU, XINMING
PENG, YANJUN
MA, Yingran
PENG, Haixin
</inventors>

<docdb_family_id>
74044146
</docdb_family_id>

<title>
CT LYMPH NODE DETECTION SYSTEM BASED ON SPATIAL-TEMPORAL RECURRENT ATTENTION MECHANISM
</title>

<abstract>
The present disclosure discloses a CT lymph node detection system based on a spatial-temporal recurrent attention mechanism and specifically relates to the field of medical image analysis technologies. Based on a deep convolutional neural network and a recurrent attention mechanism, the present disclosure can construct an attention feature map adaptive to a lesion size in a slice direction and a spatial direction of a lymph node CT sequence. Firstly, a high-level spatial feature corresponding to the lymph node CT image is extracted by use of a pre-trained convolutional network; secondly, a recurrent attention mechanism based on a Gaussian Kernel Function is constructed with a slice at the center of the lymph node as a reference in a spatial domain; based on this, a temporal (slice direction) attention mechanism based on a Gaussian Mixture Model is performed; in addition, a predicted attention position is constrained based on the prior information of position distribution of the lymph node in the CT slice sequence; finally, in combination with the high-level features extracted by the two attention methods, the recurrent neural network performs classification to obtain a lymph node detection result.
</abstract>

<claims>
1. A CT lymph node detection system based on spatial-temporal recurrent attention mechanism, comprising a training sample extracting module, a deep layer feature extracting network, a feature embedding network, and a spatial-temporal recurrent attention target detection module, wherein a detection process includes the following steps: at step 1, position coordinate information is marked for the obtained lymph node dcm-format file and a corresponding lymph node by use of the training sample extracting module, and a CT slice image block sequence Ii (i=1,2, . . . , L), Ii ∈W×H, with CT slice image blocks being length L, width W and height H is extracted for each lymph node by using a pydicom module in python; at step 2, extracting a high-level spatial feature map sequence corresponding to the CT slice image block sequence of each lymph node is extracted by using a VGG-16 model pre-trained by a natural image according to the deep layer feature extracting network and denoting the high-level spatial feature map sequence as {X0, . . . , XL}. at step 3, constructing the feature embedding network to perform dimension reduction for the input high-level feature map sequence and output a feature map Ai; at step 4, constructing a spatial-temporal recurrent attention frame, and performing a spatial attention mechanism is performed based on a recurrent neural network and the Gaussian Kernel Function to obtain a spatial attention result gS(t). at step 5, performing a temporal attention mechanism for the spatial attention result gS(t) obtained at step 4 to obtain a spatial-temporal attention feature ĝ(t). at step 6, predicting a lymph node positive score ŷt of the recurrent attention iteration step by using the recurrent neural network constructed at step 4 in combination with the spatial-temporal attention feature ĝ(t) obtained at step 5; at step 7, constructing a loss function of the model to perform steps 4-6 for T times, and performing supervised training for the model by using a gradient back propagation algorithm; at step 8, performing iterative training for the model by repeating steps 3-7, until a trained model is obtained at the end of training; and at step 9, inputting the lymph node CT sequence to be detected to perform a model reasoning process, and taking a positive score ŷT output by the final recurrent attention as a CT lymph node detection result.
2. The CT lymph node detection system according to claim 1, wherein the step 4 specifically comprises the following steps: at step 4.1, constructing a long short-term memory network (LSTM) of two layers; at step 4.2, initializing the state of the long short-term memory network by constructing an encoding process of the feature map; at step 4.3, predicting a spatial attention position within a range of the feature map by using a sending network; at step 4.4, constructing an attention matrix l(t) based on a two-dimension Gaussian Kernel Function; and at step 4.5, l(t) is multiplied by Ai element by element and then added up so as to obtain the spatial attention result gS(t).
3. The CT lymph node detection system according to claim 2, wherein at step 4.1, the recurrent neural network is constructed based on the long short-term memory network of two layers and a hidden layer is expressed as shown in the following formula (1):
description="In-line Formulae" end="lead"?ht(1)=Rrecur(ĝ(t),ht-1(1)|Wr1)description="In-line Formulae" end="tail"?
description="In-line Formulae" end="lead"?ht(2)=Rrecur(ht(1),ht-1(2)|Wr2) (1)description="In-line Formulae" end="tail"? wherein Rrecur(⋅) corresponding ht(1) is expanded as shown in the following formula (2): wherein, it, ft and of represent an input gate, a forget gate and an output gate respectively; ct and lit represent a cell state and a hidden layer state respectively; ĝ(t) represents a feature vector input into the long short-term memory network by the t-th step of attention mechanism; M: ab is an affine transformation composed of trainable parameters, a=d+E, b=4d; d is the same vector dimension corresponding to it, ft, ot, gt, ct and ht, E is a dimension of an input feature subjected to dimension reduction, and Rrecur(⋅) corresponding to ht(2) is obtained by replacing ĝ(t) in the above Rrecur(⋅) with ht(1).
4. The CT lymph node detection system according to claim 2, wherein the step 4.2 specifically comprises the following steps: at step 4.2.1, constructing a new double-layer long short-term memory network having the same structure as formula (1); at step 4.2.2, dividing the feature map Amid corresponding to the exact center of a CT slice sequence of each lymph node at step 3 according to a spatial neighborhood; specifically, dividing 8×8×200 into 16 sub-feature blocks with 2×2×200 based on adjacent four positions as one group; and at step 4.2.3, inputting the 16 sub-feature blocks into the new double-layer long short-term memory network sequentially clockwise from outside to inside to go through 16 cycles and obtain a cell state c′T(2) corresponding to the second layer of the LSTM at the last moment so as to initialize the cell state c0(2) of the second layer of the long short-term memory network at step 4.1.
5. The CT lymph node detection system according to claim 2, wherein the step 4.3 specifically comprises the following steps: at step 4.3.1, concatenating a feature vector ht(2) output by the first hidden layer of the long short-term memory network and a feature result gS,Center(t) corresponding to the center of the slice sequence in the recurrent attention iteration step to obtain [ht(2), gS,Center(t)]; At step 4.3.2, inputting [ht(2), gS,Center(t)] to a sending network composed of one fully-connected layer to perform regression for the spatial attention position of the next recurrent iteration step as shown in the formula (3):
description="In-line Formulae" end="lead"?(μS(t+1), σS(t+1)=σ(WS[ht(2), gS,Center(t)]+bS) (3)description="In-line Formulae" end="tail"? wherein μS(t+1)=(μS,x(t+1), μS,y(t+1)) represents an attention position coordinate predicted at the t+1 moment, where the variance σS(t+1) of the Gaussian Kernel is set to a fixed value 0.1, thus, WS∈2×(R+E), and bS∈2×1 only corresponds to two output nodes.
6. The CT lymph node detection system according to claim 2, wherein at the step 4.4, after an attention position coordinate μS(t) is obtained, an attention template matrix is constructed based on the two-dimension Gaussian Kernel Function and softmax as shown in the following formula (4): wherein ϕ(li|μS(t), σS(t))=C·exp(li−μS(t))/2σS(t), li={(xi, yl)}j=1K×K is discrete equidistant position coordinates normalized to the interval [0, 1] within the range Ai; C is Gaussian normalized constant which is a fixed value 10.
7. The CT lymph node detection system according to claim 1, wherein the step 5 specifically comprises the following steps: at step 5.1, constructing a mixture density network to predict an attention position μT(t) of a slice direction. at step 5.2, obtaining an attention weight vector l′(t) obtained based on Gaussian Mixture Distribution; and at step 5.3, multiplying l′(t) by the input feature gS(t) element by element and performing addition to obtain the spacial-temporal attention feature ĝ(t).
8. The CT lymph node detection system according to claim 7, wherein the step 5.1 specifically comprises the following steps: at step 5.1.1, equally dividing the sequence feature gS(t) corresponding to each lymph node into left and right halves, that is gLeft(t) and gRight(t); at step 5.1.2, forming the mixture density network is formed by one fully-connected hidden layer to perform regression for the temporal attention position coordinate and the Mixture Gaussian Function parameters as shown in the following formula (5):
description="In-line Formulae" end="lead"?Z(t)=σ(WTgS/2(t)+bT) (5)description="In-line Formulae" end="tail"? wherein gS/2(t)∈E·L/2 represents the left half or the right half of gS(t); WT∈2C×E·L/2, bT∈2C×1 represents a training parameter of the mixture density network, C represents a component number of the Gaussian Mixture Model respectively corresponding to the left half and the right half of the sequence feature, and σ is sigmoid function. at step 5.1.3, distributing respective regression coefficients ZLeft(t)∈2C×1 and ZRight(t)∈2C×1 of the left half and the right half are both distributed to the Gaussian Mixture Model according to a rule of Z0: C-1(t)→πT(t) and ZC: 2C-1(t)→μT(t); and at step 5.1.4, with the formula (6), limiting μLeft is limited to [0, 0.5) and limiting μRight to (0.5, 1],
description="In-line Formulae" end="lead"?μLeft←μLeft×0.5, μRight←0.5×(1+μRight) (6)description="In-line Formulae" end="tail"?
9. The CT lymph node detection system according to claim 7, wherein the step 5.2 specifically comprises the following steps: at step 5.2.1, normalizing the coefficient πT(t) of each Gaussian component is normalized with softmax, that is, πT(t)←softmax(πT(t)), and fixing a variance ΣT(t) of all Gaussian components as 0.1; at step 5.2.2, in combination with the Gaussian Mixture Model parameters (πT(t), μT(t), ΣT(t)) derived from the slice feature vectors of the left and right halves, a corresponding temporal attention weight vector l′i(t) is obtained based on the formula (7). wherein N is a Gaussian mixture density function.
description="In-line Formulae" end="lead"?N(li|πT(t), μT(t), ΣT(t))=Σc=1CπT,c(t)ϕc(li,μT,c(t),ΣT,c(t)), s.t.Σc=1CπT,c(t)=1ϕc(li|μT,c(t),ΣT,c(t))=C·exp(li−μT,c(t))/2ΣT,c(t) (8)description="In-line Formulae" end="tail"?
10. The CT lymph node detection system according to claim 1, wherein at step 7, a target function for the model to receive supervised training is obtained in the following steps: at step 7.1, constructing a classification loss function; and investigating cross-entropy loss functions corresponding to all recurrent attention iteration steps as shown in the following formula (9): wherein yi and ŷt,i are a real lymph node positive score and a predicted lymph node positive score, which are a total number of the recurrent attention iterations; at step 7.2, a constraint term of a predicted position of the spatial attention mechanism is constructed in the following two steps: at step 7.2.1, constructing a "convergent" constraint term of the position, and constraining the predicted spatial attention position is constrained to around the center of the feature map based on Batch Normalization and the prior information of the lymph node being at the center of the slice, as shown in the following formula (10): wherein β and γ are trainable parameters introduced by the Batch Normalization; d is an output dimension of the sending network; and m is a batch sample capacity; at step 7.2.2, constructing a "divergent" constraint term of the position is constructing the uniformly-distributed cross-entropy loss functions according to different positions predicted in the entire recurrent attention process, as shown in the following formula (11):
description="In-line Formulae" end="lead"?FS=Const−Σt=1TPUniflog[softmax(μS(t))] (11)description="In-line Formulae" end="tail"? wherein PUnif: Uniform (0, K2) represents a uniform distribution within a spatial range of the feature map; the constant Const is set to 1. at step 7.3, constructing a constraint term of a predicted position of the temporal attention mechanism; applying the "convergent" constraint term is applied to the predicted position, further introducing the batch normalization layer to the mixture density network and minimizing the formula (10) so that the attention positions of the left and right halves in the direction of slice μT(t)≈(0.25, 0.75); and at step 7.4, constructing a final entire loss function of the model is constructed as shown in the following formula (12):
</claims>
</document>
