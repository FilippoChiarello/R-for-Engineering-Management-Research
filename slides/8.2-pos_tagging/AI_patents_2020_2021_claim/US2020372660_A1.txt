<document>

<filing_date>
2019-09-24
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2019-05-21
</priority_date>

<ipc_classes>
G06F17/15,G06F17/16,G06N3/04,G06T7/194
</ipc_classes>

<assignee>
BEIHANG UNIVERSITY
</assignee>

<inventors>
LI JIA
ZHAO, QINPING
XIA, CHANGQUN
SU, Jinming
</inventors>

<docdb_family_id>
67884636
</docdb_family_id>

<title>
IMAGE SALIENT OBJECT SEGMENTATION METHOD AND APPARATUS BASED ON RECIPROCAL ATTENTION BETWEEN FOREGROUND AND BACKGROUND
</title>

<abstract>
An image salient object segmentation method and an apparatus based on reciprocal attention between a foreground and a background, and the method includes: obtaining a feature map corresponding to a training image based on a convolutional neural backbone network, and obtaining foreground and background initial feature responses according to the feature map; obtaining a reciprocal attention weight matrix, and updating the foreground and background initial feature responses according to the reciprocal attention weight matrix, to obtain foreground and background feature maps; training the convolutional neural backbone network according to the foreground and the background feature maps based on a cross entropy loss function and a cooperative loss function, to obtain a foreground and background segmentation convolutional neural network model; and inputting an image to be segmented into the foreground and background segmentation convolutional neural network model to obtain foreground and background prediction results.
</abstract>

<claims>
1. An image salient object segmentation method based on reciprocal attention between a foreground and a background, comprising: obtaining a feature map corresponding to a training image based on a convolutional neural backbone network, and obtaining a foreground initial feature response and a background initial feature response according to the feature map corresponding to the training image; obtaining a reciprocal attention weight matrix according to the foreground initial feature response and the background initial feature response, and updating the foreground initial feature response and the background initial feature response according to the reciprocal attention weight matrix to obtain a foreground feature map and a background feature map; training the convolutional neural backbone network according to the foreground feature map and the background feature map based on a cross entropy loss function and a cooperative loss function, to obtain a foreground and background segmentation convolutional neural network model; and inputting an image to be segmented into the foreground and background segmentation convolutional neural network model to obtain a foreground prediction result and a background prediction result.
2. The method according to claim 1, wherein the obtaining a feature map corresponding to a training image based on a convolutional neural backbone network, and obtaining a foreground initial feature response and a background initial feature response according to the feature map corresponding to the training image, specifically comprises: inputting the training image, and extracting a branch feature from the training image according to the convolutional neural backbone network to obtain the feature map corresponding to the training image; performing a foreground feature aggregating on the feature map corresponding to the training image to obtain the foreground initial feature response; and performing a background feature aggregating on the feature map corresponding to the training image to obtain the background initial feature response.
3. The method according to claim 1, wherein the obtaining a reciprocal attention weight matrix according to the foreground initial feature response and the background initial feature response, and updating the foreground initial feature response and the background initial feature response according to the reciprocal attention weight matrix to obtain a foreground feature map and a background feature map, specifically comprises: obtaining a corresponding foreground response map and a corresponding background response map according to the foreground initial feature response and the background initial feature response; obtaining the reciprocal attention weight matrix according to the foreground response map and the background response map; multiplying the foreground initial feature response by the reciprocal attention weight matrix to obtain a first result, and multiplying the background initial feature response by the reciprocal attention weight matrix to obtain a second result; summing the first result and the background initial feature response to obtain the background feature map; and summing the second result and the foreground initial feature response to obtain the foreground feature map.
4. The method according to claim 1, wherein the cross entropy loss function is specifically:
description="In-line Formulae" end="lead"?Lce=Dc(Sig(φB(πB)), GB)+Dc(Sig(φF(πF), GF),description="In-line Formulae" end="tail"? wherein, Lce is the cross entropy loss function, Sig(·) is a sigmoid function, Dc(·) is a cross entropy function, φB(πB) is the background feature map, φF(πF) is the foreground feature map, GB is a reference map of a background image, and GF is a reference map of a foreground map.
5. The method according to claim 1, wherein the cooperative loss function is specifically:
description="In-line Formulae" end="lead"?Lkl=Dkl(Sig(ϕB(πB)), 1−Sig(ϕF(πF))+Dkl(Sig(ϕB(πB)), Sig(ϕF(πF))),description="In-line Formulae" end="tail"? wherein, Lkl is the cooperative loss function, Dkl(·) is a KL distance, Sig(·) is a sigmoid function, φB(πB) is the background feature map, and φF(πF) is the foreground feature map.
6. The method according to claim 1, wherein after the inputting an image to be segmented into the foreground and background segmentation convolutional neural network model to obtain a foreground prediction result and a background prediction result, the method further comprises: obtaining a difference value between the foreground prediction result and the background prediction result to obtain a corresponding difference image; and filtering pixel points of the difference image according to a preset threshold to obtain a salient object segmentation result.
7. The method according to claim 6, wherein the salient object segmentation result is specifically:
description="In-line Formulae" end="lead"?Sal=relu(Sig(φF(πF))−Sig(φB(πB))),description="In-line Formulae" end="tail"? wherein, Sal is the salient object segmentation result, relu(·) is a ReLU activation function, Sig(·) is a sigmoid function, φB(πB) is the background feature map, φF(πF) is the foreground feature map.
8. An image salient object segmentation apparatus based on reciprocal attention between a foreground and a background, comprising: a first processing module, configured to obtain a feature map corresponding to a training image based on a convolutional neural backbone network, and obtain a foreground initial feature response and a background initial feature response according to the feature map corresponding to the training image; a second processing module, configured to obtain a reciprocal attention weight matrix according to the foreground initial feature response and the background initial feature response, and update the foreground initial feature response and the background initial feature response according to the reciprocal attention weight matrix to obtain a foreground feature map and a background feature map; a training module, configured to train the convolutional neural backbone network according to the foreground feature map and the background feature map based on a cross entropy loss function and a cooperative loss function, to obtain a foreground and background segmentation convolutional neural network model; and a segmentation module, configured to input an image to be segmented into the foreground and background segmentation convolutional neural network model to obtain a foreground prediction result and a background prediction result.
9. An image salient object segmentation device based on reciprocal attention between a foreground and a background, comprising: at least one processor and a memory; wherein the memory stores computer execution instructions; the at least one processor executes the computer execution instructions stored by the memory such that the at least one processor performs the image salient object segmentation method based on reciprocal attention between a foreground and a background according to claim 1.
10. A computer readable storage medium, wherein the computer readable storage medium stores computer execution instructions that, when executed by a processor, implement the image salient object segmentation method based on reciprocal attention between a foreground and a background according to claim 1.
</claims>
</document>
