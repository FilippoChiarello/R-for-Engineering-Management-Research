<document>

<filing_date>
2017-09-19
</filing_date>

<publication_date>
2020-06-02
</publication_date>

<priority_date>
2016-09-21
</priority_date>

<ipc_classes>
G01S17/08,G01S17/931,G05D1/00,G05D1/02,G06N20/00,G06N5/04
</ipc_classes>

<assignee>
APPLE
</assignee>

<inventors>
AL-DAHLE, AHMAD
GARG, KSHITIZ
XU, XINYU
</inventors>

<docdb_family_id>
70856063
</docdb_family_id>

<title>
Shared sensor data across sensor processing pipelines
</title>

<abstract>
Sensor data captured at by different sensors may be shared across different sensor processing pipelines. Sensor processing pipelines may process captured sensor data from respective sensors. Some of the sensor data that is received or processed at one sensor data processing pipeline may be provided to another sensor data processing pipeline so that subsequent processing stages at the recipient sensor processing pipeline may process the combined sensor data in order to determine a perception decision. Different types of sensor data may be shared, including raw sensor data, processed sensor data, or data derived from sensor data. A control system may perform control actions based on the perception decisions determined by the sensor processing pipelines that share sensor data.
</abstract>

<claims>
1. An apparatus, comprising: a plurality of different sensors that capture respective sensor data; one or more devices configured to perform sensor data processing, the one or more devices comprising: different processing pipelines configured to determine perception decisions based, at least in part, on sensor data received from the plurality of sensors; wherein a first processing pipeline of the processing pipelines is configured to: determine a first perception decision based on first sensor data received from one or more of the different sensors having a first sensor type; determine a second perception decision based on second sensor data received from one or more of the different sensors having a second sensor type; determine a fused perception decision based on the first perception decision and the second perception decision; and send the first sensor data received or processed at the first processing pipeline to a second processing pipeline of the processing pipelines; and wherein the second processing pipeline is configured to: fuse the first sensor data sent from the first processing pipeline with the second sensor data received or processed at the second processing pipeline; and process the fused sensor data at one or more stages in the second processing pipeline prior to the determination of a perception decision at the second processing pipeline, wherein the perception decision at the second processing pipeline is based on the fused sensor data.
2. The apparatus of claim 1, wherein the first sensor data received or processed at the first processing pipeline that is sent to the second processing pipeline is raw sensor data received from the first sensor.
3. The apparatus of claim 1, wherein to process the fused sensor data at one or more stages in the second processing pipeline, the second processing pipeline is configured to determine a classification for one or more objects based on the fused sensor data.
4. The apparatus of claim 3, wherein the respective sensor data received or processed at the first processing pipeline that is sent to the second processing pipeline comprises one or more image features extracted from image sensor data at the first processing pipeline, wherein the second processing pipeline processes LiDAR sensor data received from a LiDAR device.
5. The apparatus of claim 1, wherein one of one or more processing stages at the first processing pipeline is a classification stage that applies a machine learning model trained on a same type of sensor data as the first sensor data that is sent to the second processing pipeline and a same type of sensor data as the second sensor data received at the second processing pipeline.
6. The apparatus of claim 1, wherein the one or more devices are configured to determine a final perception decision based, at least in part, on the perception decisions determined by the different processing pipelines.
7. The apparatus of claim 6, wherein the one or more devices are implemented as part of sensor data processing in an autonomous navigation system installed on a vehicle, and wherein the autonomous navigation system is configured to perform one or more navigation actions based, at least in part, on the final perception decision.
8. A method, comprising: performing, by one or more computing devices: receiving respective sensor data from a plurality of different sensors for processing at different processing pipelines to determine respective perception decisions at the different processing pipelines; performing, at a first processing pipeline of the different processing pipelines: determining a first perception decision based on first sensor data received from one or more of the different sensors having a first sensor type; determining a second perception decision based on second sensor data received from one or more of the different sensors having a second sensor type; determining a fused perception decision based on the first perception decision and the second perception decision; and providing the first sensor data received or processed at the first processing pipelines to a second processing pipeline of the processing pipelines prior to determination of a respective perception decision at the second processing pipeline; and performing, at a second processing pipeline of the different processing pipelines: combining the provided sensor data with the second sensor data received from the second sensor at the second processing pipeline; and processing the combined sensor data at one or more processing stages within the second processing pipeline, wherein the respective perception decision determined at the second processing pipeline is based, at least in part, on the combined sensor data.
9. The method of claim 8, wherein the first sensor data provided to the second processing pipeline are one or more features extracted from the first sensor data at the first processing pipeline.
10. The method of claim 9, wherein the one or more features extracted from the first sensor data at the first processing pipeline are one or more features extracted from LiDAR sensor data.
11. The method of claim 8, wherein processing the combined sensor data at the one or more processing stages within the second processing pipeline comprises classifying one or more objects based on the combined sensor data.
12. The method of claim 8, wherein the plurality of different sensors comprise at least one of an image sensor, a LiDAR sensor, an infrared sensor, a radar sensor, a global positioning satellite (GPS) sensor, inertial measurement sensor, or an angular rate sensor.
13. The method of claim 8, further comprising determining a final perception decision based, at least in part, on the perception decisions determined by the different processing pipelines.
14. The method of claim 13, further comprising sending the final perception decision to a control engine implemented as part of a control system.
15. A non-transitory, computer readable storage medium, storing program instructions that when executed by one or more computing devices cause the one or more computing devices to implement: receiving respective sensor data from a plurality of different sensors for processing at different processing pipelines to determine respective perception decisions at the different processing pipelines; performing, at a first processing pipeline of the different processing pipelines: determining a first perception decision based on first sensor data received from one or more of the different sensors having a first sensor type; determining a second perception decision based on second sensor data received from one or more of the different sensors, having a second sensor type; determining a fused perception decision based on the first perception decision and the second perception decision; and sending the first sensor data received or processed at the first processing pipeline, to the second processing pipeline that receives the second sensor data prior to the determination of the respective perception decision at the second processing pipeline; and performing, at the second processing pipeline of the different processing pipelines: fusing, at the second processing pipeline of the different processing pipelines, the provided first sensor data received or processed at the first processing pipeline, with the second sensor data received at the second processing pipeline; and processing the fused sensor data at one or more processing stages within the second processing pipeline, wherein the respective perception decision determined at the second processing pipeline is based, at least in part, on the fused sensor data.
16. The non-transitory, computer readable storage medium of claim 15, wherein, in processing the fused sensor data at one or more processing stages within the second processing pipeline, the program instructions cause the one or more computing devices to implement classifying one or more objects based on the fused sensor data.
17. The non-transitory, computer readable storage medium of claim 16, wherein the respective sensor data received or processed at the first processing pipeline that is sent to the second processing pipeline is one or more image features extracted from image sensor data at the first processing pipeline, wherein the second processing pipeline processes LiDAR sensor data received from a LiDAR.
18. The non-transitory, computer readable storage medium of claim 15, wherein the program instructions cause the one or more computing devices to further implement: sending the second sensor data received or processed at the second processing pipeline to the first processing pipeline; fusing the sensor data received from the second processing pipeline with the first sensor data received from the first sensor at the first processing pipeline to generate other fused sensor data; and processing the other fused sensor data at one or more processing stages within the first processing pipeline, wherein the respective perception decision determined at the first processing pipeline is based, at least in part, on the other fused sensor data.
19. The non-transitory, computer readable storage medium of claim 15, wherein the program instructions cause the one or more computing devices to further implement determining a final perception decision based, at least in part, on the perception decisions determined by the different processing pipelines.
20. The non-transitory, computer readable storage medium of claim 19, wherein the one or more computing devices implement an autonomous navigation system installed on a vehicle, and wherein the program instructions cause the one or more computing devices to further implement performing one or more navigation actions based, at least in part, on the final perception decision.
</claims>
</document>
