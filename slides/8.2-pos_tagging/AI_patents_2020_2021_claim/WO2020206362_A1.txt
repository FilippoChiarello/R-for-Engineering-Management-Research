<document>

<filing_date>
2020-04-03
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-04
</priority_date>

<ipc_classes>
G02B21/18,G06T7/37
</ipc_classes>

<assignee>
INSCOPIX
</assignee>

<inventors>
VISSCHER, KOEN
XU, Pei Sabrina
NEUFELD, Shay
</inventors>

<docdb_family_id>
72666281
</docdb_family_id>

<title>
MULTI-MODAL MICROSCOPIC IMAGING
</title>

<abstract>
Disclosed herein are adapters configured to be optically coupled to a plurality of microscopes, said adapter comprising: a) a first microscope interface configured to optically couple a first microscope to an optical element in optical communication with an optical probe; b) a second microscope interface configured to optically couple a second microscope to the optical element in optical communication with the optical probe; and c) an optical arrangement configured to direct light collected from a sample with aid of the optical probe to (1) the first microscope and second microscope simultaneously, or (2) the first microscope or second microscope selectively.
</abstract>

<claims>
WHAT IS CLAIMED IS:
1. A method for providing multi-modal imaging using a plurality of microscopes, said method comprising:
a) receiving a functional imaging data and structural imaging data from an adapter comprising (i) a first microscope interface configured to optically couple a first microscope to an optical element in optical communication with an optical probe to provide the functional imaging data of a sample, and (ii) a second microscope interface configured to optically couple a second microscope to the optical element in optical communication with the optical probe to provide the structural imaging data of the sample;
b) processing the received functional imaging data to generate a first overlaid image; c) processing the structural imaging data to generate a second overlaid image; and d) generating a third overlay of the first overlaid image and the second overlaid image.
2. The method of claim 1, wherein the first overlaid image is generated by obtaining a first cell map, constructing a structural image from a mean projection of a motion corrected movie, and overlaying the cell map with the structural image.
3. The method of claim 1, wherein the second overlaid image is generated by obtaining structural data, using the structural data to generate a 2p/confocal structural image, obtaining functional data, using the functional data to generate a 2p/confocal functional image, and overlaying the 2p/confocal structural image and the 2p/confocal functional image.
4. The method of claim 1, further comprising co-registering the first overlaid image and the second overlaid image prior to generating the third overlay.
5. The method of claim 1, wherein the first overlaid image is set to a first color channel, and the second overlaid image is set to a second color channel different from the first color channel when generating the third overlay.
6. The method of claim 1, wherein the first microscope is a one-photon microscope.
7. The method of claim 1, wherein the second microscope is a two-photon microscope. 8 The method of claim 1, wherein the second microscope is a confocal microscope.
9. The method of claim 1, wherein the first microscope and the second microscope are of different types.
10. The method of claim 1, wherein the first microscope interface is configured to permit the adapter to bear the weight of the first microscope.
11. The method of claim 10, wherein the first microscope weighs 20 grams or less.
12. The method of claim 10, wherein the first microscope has a volume of 30 cm3 or less.
13. The method of claim 1, wherein the second microscope interface is configured to permit the second microscope to bear the weight of the adapter.
14. The method of claim 1, wherein the first microscope interface and the second microscope interface are provided on a housing.
15. The method of claim 14, wherein the first microscope interface and the second microscope interface are provided on different sides of the housing.
16. The method of claim 14, wherein at least a portion of the optical probe extends out of the housing.
17. The method of claim 1, wherein the optical element is contained within the housing.
18. The method of claim 1, wherein the optical probe is attachable and separable from the adapter.
19. The method of claim 1, wherein the optical probe comprises a GRIN lens.
20. The method of claim 1, wherein the first microscope and the second microscope are configured to generate images based on light collected from the sample.
21. The method of claim 20, wherein the adapter is configured to cause an image generated by the first microscope and an image generated by the second microscope to align.
22. The method of claim 1, wherein the first microscope interface and the second adapter interface allow the adapter to be coupled and decoupled from the first microscope and the second microscope.
23. The method of claim 1, wherein the second microscope interface is configured to allow the adapter to be coupled to a plurality of different types of microscopes.
24. The method of claim 1, wherein the first microscope or the second microscope is configured to capture three-dimensional data.
25. The method of claim 4, wherein co-registering the first overlaid image and the second overlaid image comprises dividing the first overlaid image and the second overlaid image into a plurality of sections and performing image registration for each of the plurality of sections.
26. The method of claim 4, wherein co-registering the first overlaid image and the second overlaid image comprises aligning at least a portion of the first overlaid image and the second overlaid image based at least in part on a coordinate transformation.
27. The method of claim 26, wherein the coordinate transformation is derived based at least in part on a difference in a size, a shape, a position, or an orientation of a similar feature within the first overlaid image and the second overlaid image.
28. The method of claim 27, wherein the similar feature comprises a cell or a neuron, wherein the cell or the neuron has a tuning curve that is generated in response to light stimuli.
29. The method of claim 27, further comprising using the difference in the size, shape, position, or orientation of the similar feature to characterize an amount of distortion or warping of the similar feature between the first overlaid image and the second overlaid image.
30. The method of claim 27, further comprising using the difference in the size, shape, position, or orientation of the similar feature to train a neural network to determine how the size, shape, position, or orientation of the similar feature is altered between different optical imaging modalities.
31. The method of claim 30, wherein the neural network comprises a convolutional neural network.
32. A system for providing multi-modal imaging, comprising:
an adapter comprising (i) a first microscope interface configured to optically couple a first microscope to an optical element in optical communication with an optical probe to provide functional imaging data of a sample, and (ii) a second microscope interface configured to optically couple a second microscope to the optical element in optical communication with the optical probe to provide structural imaging data of the sample; and
a processor configured to (i) process the received functional imaging data to generate a first overlaid image, (ii) process the structural imaging data to generate a second overlaid image, and (iii) generate a third overlay of the first overlaid image and the second overlaid image.
33. The system of claim 32, wherein the processor is configured to generate the first overlaid image by obtaining a first cell map, constructing a structural image from a mean projection of a motion corrected movie, and overlaying the cell map with the structural image.
34. The system of claim 32, wherein the processor is configured to generate the second overlaid image by obtaining structural data, using the structural data to generate a 2p/confocal structural image, obtaining functional data, using the functional data to generate a 2p/confocal functional image, and overlaying the 2p/confocal structural image and the 2p/confocal functional image.
35. The system of claim 32, wherein the processor is configured to co-register the first overlaid image and the second overlaid image prior to generating the third overlay.
36. The system of claim 32, wherein the processor is configured to set the first overlaid image to a first color channel and the second overlaid image to a second color channel different from the first color channel when generating the third overlay.
37. The system of claim 32, wherein the first microscope is a one-photon microscope.
38. The system of claim 32, wherein the second microscope is a two-photon microscope.
39. The system of claim 32, wherein the second microscope is a confocal microscope.
40. The system of claim 32, wherein the first microscope and the second microscope are of different types.
41. The system of claim 32, wherein the first microscope interface is configured to permit the adapter to bear the weight of the first microscope.
42. The system of claim 41, wherein the first microscope weighs 20 grams or less.
43. The system of claim 41, wherein the first microscope has a volume of 30 cm3 or less.
44. The system of claim 32, wherein the second microscope interface is configured to permit the second microscope to bear the weight of the adapter.
45. The system of claim 32, wherein the first microscope interface and the second microscope interface are provided on a housing.
46. The system of claim 45, wherein the first microscope interface and the second microscope interface are provided on different sides of the housing.
47. The system of claim 45, wherein at least a portion of the optical probe extends out of the housing.
48. The system of claim 32, wherein the optical element is contained within the housing.
49. The system of claim 32, wherein the optical probe is attachable and separable from the adapter.
50. The system of claim 32, wherein the optical probe comprises a GRIN lens.
51. The system of claim 32, wherein the first microscope and the second microscope are configured to generate images based on light collected from the sample.
52. The system of claim 51, wherein the adapter is configured to cause an image generated by the first microscope and an image generated by the second microscope to align.
53. The system of claim 32, wherein the first microscope interface and the second adapter interface allow the adapter to be coupled and decoupled from the first microscope and the second microscope.
54. The system of claim 32, wherein the second microscope interface is configured to allow the adapter to be coupled to a plurality of different types of microscopes.
55. The system of claim 32, wherein the first microscope or the second microscope is configured to capture three-dimensional data.
56. The system of claim 35, wherein the processor is configured to co-register the first overlaid image and the second overlaid image by dividing the first overlaid image and the second overlaid image into a plurality of sections and performing image registration for each of the plurality of sections.
57. The system of claim 35, wherein the processor is configured to co-register the first overlaid image and the second overlaid image by aligning at least a portion of the first overlaid image and the second overlaid image based at least in part on a coordinate transformation.
58. The system of claim 57, wherein the coordinate transformation is derived based on a difference in a size, a shape, a position, or an orientation of a similar feature within the first overlaid image and the second overlaid image.
59. The system of claim 58, wherein the similar feature comprises a cell or a neuron, wherein the cell or the neuron has a tuning curve that is generated in response to light stimuli.
60. The system of claim 58, wherein the processor is configured to use the difference in the size, shape, position, or orientation of the similar feature to characterize an amount of distortion or warping of the similar feature between the first overlaid image and the second overlaid image.
61. The system of claim 58, wherein the processor is configured to use the difference in the size, shape, position, or orientation of the similar feature to train a neural network to determine how the size, shape, position, or orientation of the similar feature is altered between different optical imaging modalities.
62. The system of claim 61, wherein the neural network comprises a convolutional neural network.
</claims>
</document>
