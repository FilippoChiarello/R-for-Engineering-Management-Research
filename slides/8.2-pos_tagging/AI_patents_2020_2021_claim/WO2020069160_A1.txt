<document>

<filing_date>
2019-09-26
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-27
</priority_date>

<ipc_classes>
G05D1/00,G10L15/00
</ipc_classes>

<assignee>
SALESFORCE.COM
</assignee>

<inventors>
MA, CHIH-YAO
XIONG, CAIMING
</inventors>

<docdb_family_id>
69947468
</docdb_family_id>

<title>
SELF-AWARE VISUAL-TEXTUAL CO-GROUNDED NAVIGATION AGENT
</title>

<abstract>
An agent for navigating a mobile automated system is disclosed herein. The navigation agent receives a navigation instruction and visual information for one or more observed images. The navigation agent is provided or equipped with self-awareness, which provides or supports the following abilities: identifying which direction to go or proceed by determining the part of the instruction that corresponds to the observed images (visual grounding), and identifying which part of the instruction has been completed or ongoing and which part is potentially needed for the next action selection (textual grounding). In some embodiments, the navigation agent applies regularization to ensures that the grounded instruction can correctly be used to estimate the progress made towards the navigation goal (progress monitoring).
</abstract>

<claims>
1. A computing device comprising:
a memory containing machine readable medium storing machine executable code; and one or more processors coupled to the memory and configurable to execute the machine executable code to cause the one or more processors to:
receive a navigation instruction for instructing a mobile automated system to navigate an environment in which the mobile automated system is located;
receive visual information for the environment, the visual information comprising one or more images observed for the environment as the mobile automated system is navigated therethrough;
generate an instruction grounding based at least in part on the navigation instruction, the instruction grounding identifying which part of the navigation instruction has been completed by the mobile automated system and which part of the navigation instruction is outstanding;
generate a visual grounding based at least in part on the visual information, the visual grounding identifying a direction in which the mobile automated system should proceed; and
using the instruction grounding and the visual grounding, generate an action for the mobile automated system to perform for navigating the environment.
2. The computing device of claim 1, wherein the machine executable code further causes the one or more processors to monitor progress of navigation of the automated system to ensure that the instruction grounding accurately reflects the navigation progress.
3. The computing device of claim 1 or 2, wherein the machine executable code causes the one or more processors to:
generate an encoder context based on the instruction grounding and the visual grounding; and
generate the action for the mobile automated system using the encoder context.
4. The computing device of any of claims 1-3, wherein the machine executable code causes the one or more processors to perform a natural language processing task on the navigation instruction.
5. The computing device of any of claims 1-4, wherein the machine executable code causes the one or more processors to identify a navigable direction with the highest correlation to the instruction grounding.
6. The computing device of any of claims 1-5, wherein the machine executable code causes the one or more processors to:
identify a plurality of directions in which the mobile automated system can navigate; and for each identified navigable direction, generate a respective probability.
7. A method for navigating a mobile automated system, the method comprising:
receiving, at one or more processors, a navigation instruction for instructing the mobile automated system to navigate an environment in which the mobile automated system is located; receiving, at the one or more processors, visual information for the environment, the visual information comprising one or more images observed for the environment as the mobile automated system is navigated therethrough;
generating, at the one or more processors, an instruction grounding based at least in part on the navigation instruction, the instruction grounding identifying which part of the navigation instruction has been completed by the mobile automated system and which part of the navigation instruction is outstanding;
generating, at the one or more processors, a visual grounding based at least in part on the visual information, the visual grounding identifying a direction in which the mobile automated system should proceed; and
using the instruction grounding and the visual grounding, generating, at the one or more processors, an action for the mobile automated system to perform for navigating the
environment.
8. The method of claim 7, comprising monitoring progress of navigation of the automated system to ensure that the instruction grounding accurately reflects the navigation progress.
9. The method of claim 7 or 8, wherein generating an action comprises:
generating an encoder context based on the instruction grounding and the visual grounding; and
generating the action for the mobile automated system using the encoder context.
10. The method of any of claims 7-9, comprising performing a natural language processing task on the navigation instruction.
11. The method of any of claims 7-10, wherein generating an action comprises identifying a navigable direction with the highest correlation to the instruction grounding.
12. The method of any of claims 7-11, wherein generating an action comprises:
identifying a plurality of directions in which the mobile automated system can navigate; and
for each identified navigable direction, generating a respective probability.
13. A non-transitory machine-readable medium comprising executable code which when executed by one or more processors associated with a computing device are adapted to cause the one or more processors to perform a method comprising:
receiving, at the one or more processors, a navigation instruction for instructing the mobile automated system to navigate an environment in which the mobile automated system is located;
receiving, at the one or more processors, visual information for the environment, the visual information comprising one or more images observed for the environment as the mobile automated system is navigated therethrough;
generating, at the one or more processors, an instruction grounding based at least in part on the navigation instruction, the instruction grounding identifying which part of the navigation instruction has been completed by the mobile automated system and which part of the navigation instruction is outstanding;
generating, at the one or more processors, a visual grounding based at least in part on the visual information, the visual grounding identifying a direction in which the mobile automated system should proceed; and
using the instruction grounding and the visual grounding, generating, at the one or more processors, an action for the mobile automated system to perform for navigating the
environment.
14. The non-transitory machine-readable medium of claim 13, wherein the executable code further causes the one or more processors to monitor progress of navigation of the automated system to ensure that the instruction grounding accurately reflects the navigation progress.
15. The non-transitory machine-readable medium of claim 13 or 14, wherein the executable code causes the one or more processors to:
generate an encoder context based on the instruction grounding and the visual grounding; and
generate the action for the mobile automated system using the encoder context.
16. The non-transitory machine-readable medium of any of claims 13-15, wherein the executable code causes the one or more processors to perform a natural language processing task on the navigation instruction.
17. The non-transitory machine-readable medium of any of claims 13-16, wherein the executable code causes the one or more processors to identify a navigable direction with the highest correlation to the instruction grounding.
18. The non-transitory machine-readable medium of any of claims 13-17, wherein the executable code causes the one or more processors to:
identify a plurality of directions in which the mobile automated system can navigate; and for each identified navigable direction, generate a respective probability.
</claims>
</document>
