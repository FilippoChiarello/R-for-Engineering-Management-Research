<document>

<filing_date>
2019-12-20
</filing_date>

<publication_date>
2020-07-02
</publication_date>

<priority_date>
2018-12-29
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N20/00,G06Q40/08
</ipc_classes>

<assignee>
ALIBABA GROUP
</assignee>

<inventors>
XU JUAN
</inventors>

<docdb_family_id>
68772503
</docdb_family_id>

<title>
COMPUTER-EXECUTED METHOD AND APPARATUS FOR ASSESSING VEHICLE DAMAGE
</title>

<abstract>
A method for assessing vehicle damage, includes: acquiring a to-be-identified vehicle damage image; acquiring damage object detection information in the image; acquiring vehicle component information for the vehicle damage image, the vehicle component information including a detected first component; generating a first comprehensive feature for the first component; determining a plurality of candidate prediction results for the first component, each of the candidate prediction results comprising a candidate component category and a candidate damage category; obtain a first prediction result including, for each of the candidate prediction results, a probability that the candidate damage category thereof is correct; obtaining a second prediction result including, for each of the candidate prediction results, a probability that the candidate component category thereof is correct; and determining the component category of the first component and the corresponding damage category thereof at least based on the first prediction result and the second prediction result.
</abstract>

<claims>
1. A computer-executed method for assessing vehicle damage, comprising: acquiring a to-be-identified vehicle damage image; acquiring damage object detection information using a pre-trained damage detection model, the damage object detection information comprising information of a plurality of damage detection frames framing a plurality of damage objects in the vehicle damage image; acquiring vehicle component information for the vehicle damage image using a pre-trained component model, the vehicle component information comprising component object detection information and component segmentation information, the component object detection information comprising a detected first component; generating a first comprehensive feature for the first component based on the damage object detection information and the vehicle component information, the first comprehensive feature comprising a component feature and a fused damage feature of the first component, the fused damage feature being obtained by fusing damage features of at least one damage detection frame belonging to the first component among the plurality of damage detection frames; determining a plurality of candidate prediction results for the first component, each of the candidate prediction results comprising a candidate component category and a candidate damage category; inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained first condition prediction model to obtain a first prediction result, the first prediction result comprising, for each of the candidate prediction results, a probability that the candidate damage category thereof is correct; inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained second condition prediction model to obtain a second prediction result, the second prediction result comprising, for each of the candidate prediction results, a probability that the candidate component category thereof is correct; and determining the component category of the first component and the corresponding damage category thereof at least based on the first prediction result and the second prediction result.
2. The method according to claim 1, wherein the damage detection model comprises a plurality of damage detection models, and the damage detection information comprises information of the plurality of damage detection frames from the plurality of damage detection models.
3. The method according to claim 1, wherein acquiring vehicle component information for the vehicle damage image using a pre-trained component model comprises: acquiring the component object detection information for the vehicle damage image using a component detection model, the component object detection information comprising at least one component detection frame framing a corresponding component and a predicted component category corresponding to each component detection frame; and acquiring a segmentation result for all components in the vehicle damage image using a component segmentation model.
4. The method according to claim 1, wherein the component model is implemented based on a convolutional neural network; and generating a first comprehensive feature for the first component based on the damage object detection information and the vehicle component information comprises: acquiring a feature associated with the first component in the vehicle damage image from a convolutional layer of the convolutional neural network for use as the component feature.
5. The method according to claim 1, wherein generating a first comprehensive feature for the first component based on the damage object detection information and the vehicle component information comprises: determining the at least one damage detection frame belonging to the first component based on the damage object detection information and the component segmentation information; acquiring the damage features of the at least one damage detection frame; and performing a fusion operation on the damage features of the at least one damage detection frame to obtain the fused damage feature.
6. The method according to claim 5, wherein determining the at least one damage detection frame belonging to the first component comprises: determining a first region covered by the first component based on the component segmentation information; determining whether the plurality of damage detection frames fall within the first region based on position information of the plurality of damage detection frames; and determining a damage detection frame falling within the first region as the at least one damage detection frame.
7. The method according to claim 5, wherein the at least one damage detection frame comprises a first damage detection frame; and acquiring the damage features of the at least one damage detection frame comprises acquiring a first damage feature corresponding to the first damage detection frame, by extracting an image convolutional feature associated with the first damage detection frame from a convolutional layer of a convolutional neural network corresponding to the damage detection model.
8. The method according to claim 7, wherein the damage object detection information comprises a predicted damage category corresponding to each damage detection frame of the plurality of damage detection frames; and acquiring a first damage feature corresponding to the first damage detection frame further comprises determining a first association feature based on an association relationship between the first damage detection frame and other damage detection frames of the plurality of damage detection frames for use as a portion of the first damage feature, the association relationship at least comprising one or more of: an association relationship among damage detection frame positions, an association relationship among predicted damage categories, or an association relationship among frame contents reflected by the image convolutional feature.
9. The method according to claim 5, wherein the fusion operation comprises one or more of: an operation to obtain a maximum, an operation to obtain a minimum, an operation to obtain an average, an operation to obtain a sum, or an operation to obtain a median.
10. The method according to claim 1, wherein the component object detection information comprises at least one component detection frame framing a corresponding component and a predicted component category corresponding to each component detection frame; and determining a plurality of candidate prediction results for the first component comprises: acquiring a first predicted component category for the first component, and using the first predicted component category as the candidate component category.
11. The method according to claim 1, wherein the damage object detection information comprises a predicted damage category corresponding to each damage detection frame of the plurality of damage detection frames; and determining a plurality of candidate prediction results for the first component comprises: acquiring at least one predicted damage category corresponding to at least one damage detection frame; and using, as the candidate damage category, one of: the damage category having the highest damage degree among the at least one predicted damage category; or the damage category accounting for the highest proportion among the at least one predicted damage category.
12. The method according to claim 1, wherein the first condition prediction model is trained based on at least one first training sample, the first training sample comprising a first training image and first annotation data, the first annotation data at least comprising a first damage category tag for a first damaged component in the first training image, wherein the first damage category tag is generated based on manually annotated damage annotation data.
13. The method according to claim 12, wherein the first damage category tag is generated by: acquiring the manually annotated damage annotation data, the damage annotation data comprising a plurality of damage annotation frames annotated in the first training image and a damage category tag annotated for each of the damage annotation frames; acquiring component contour information for the first training image; determining at least one damage annotation frame corresponding to the first damaged component based on the component contour information; and using the damage category tag having to the highest damage degree among the damage category tags corresponding to the at least one damage annotation frame as the first damage category tag.
14. The method according to claim 13, wherein acquiring component contour information for the first training image comprises: acquiring the component contour information based on manually annotated contour annotation data; or acquiring the component contour information through a component segmentation model.
15. The method according to claim 1, wherein the second condition prediction model is trained based on at least one second training sample, the second training sample comprising a second training image and second annotation data, and the second annotation data at least comprising a second component category tag manually annotated for a second damaged component in the second training image.
16. The method according to claim 1, wherein determining the component category of the first component and the corresponding damage category thereof at least based on the first prediction result and the second prediction result comprises: acquiring, for each candidate prediction result, a first probability from the first prediction result and corresponding to the candidate prediction result, and a second probability from the second prediction result and corresponding to the candidate prediction result; determining a comprehensive correctness probability for each candidate prediction result based on the first probability and the second probability; selecting at least one prediction result from the plurality of candidate prediction results based on the comprehensive correctness probability; and determining the component category of the first component and the corresponding damage category thereof based on the candidate component categories and the candidate damage categories comprised in the at least one prediction result.
17. The method according to claim 16, wherein determining a comprehensive correctness probability for each candidate prediction result comprises at least one of: using the maximum of the first probability and the second probability as the comprehensive correctness probability; or using the sum of the first probability and the second probability as the comprehensive correctness probability; or using the product of the first probability and the second probability as the comprehensive correctness probability.
18. The method according to claim 1, further comprising: inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained third prediction model to obtain a third prediction result, the third prediction result comprising, for each of the candidate prediction results, a probability that the candidate damage category and the candidate component category thereof are both correct.
19. The method according to claim 18, wherein the third prediction model is trained based on at least one third training sample, the third training sample comprising a third training image and third annotation data, and the third annotation data comprising a third component category tag and a third damage category tag that are manually annotated for a third damaged component in the third training image.
20. The method according to claim 18, wherein determining the component category of the first component and the corresponding damage category thereof at least based on the first prediction result and the second prediction result comprises: determining the component category of the first component and the corresponding damage category thereof based on the first prediction result, the second prediction result, and the third prediction result.
21. The method according to claim 20, wherein determining the component category of the first component and the corresponding damage category thereof based on the first prediction result, the second prediction result, and the third prediction result comprises: acquiring, for each candidate prediction result, a first probability from the first prediction result and corresponding to the candidate prediction result, a second probability from the second prediction result and corresponding to the candidate prediction result, and a third probability from the third prediction result and corresponding to the candidate prediction result; determining a comprehensive correctness probability for each candidate prediction result based on the first probability, the second probability, and the third probability; selecting at least one prediction result from the plurality of candidate prediction results based on the comprehensive correctness probability; and determining the component category of the first component and the corresponding damage category based on the candidate component categories and the candidate damage categories included in the at least one prediction result.
22. The method according to claim 1, further comprising: determining a replacement or repair scheme for the first component based on the component category of the first component and the corresponding damage category thereof.
23. A computer-executed method for assessing vehicle damage, comprising: acquiring a first to-be-identified vehicle damage image and a second to-be-identified vehicle damage image, the first vehicle damage image and the second vehicle damage image belonging to a same damage assessment case; acquiring first damage object detection information for the first vehicle damage image and second damage object detection information for the second vehicle damage image using a pre-trained damage detection model, the first damage object detection information comprising information of a plurality of first damage detection frames framing a plurality of damage objects in the first vehicle damage image, and the second damage object detection information comprising information of a plurality of second damage detection frames framing a plurality of damage objects in the second vehicle damage image; acquiring first vehicle component information for the first vehicle damage image and second vehicle component information for the second vehicle damage image using a pre-trained component model, the first vehicle component information comprising first component object detection information and first component segmentation information, and the second vehicle component information comprising second component object detection information and second component segmentation information; determining a common first component from the first component object detection information and the second component object detection information based on an association between the first vehicle damage image and the second vehicle damage image; generating a first comprehensive feature for the first component based on the first damage object detection information, the second damage object detection information, the first vehicle component information, and the second vehicle component information, the first comprehensive feature comprising a fused component feature and a fused damage feature of the first component, wherein the fused component feature is obtained by fusing a first component feature and a second component feature, the first component feature being generated based on the first vehicle damage image, and the second component feature being generated based on the second vehicle damage image, and the fused damage feature is obtained by fusing a first damage feature and a second damage feature, the first damage feature being generated based on damage features of at least one first damage detection frame belonging to the first component in the first vehicle damage image, and the second damage feature being generated based on damage features of at least one second damage detection frame belonging to the first component in the second vehicle damage image; determining a plurality of candidate prediction results for the first component, each of the candidate prediction results comprising a candidate component category and a candidate damage category; inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained first condition prediction model to obtain a first prediction result, the first prediction result comprising, for each of the candidate prediction results, a probability that the candidate damage category thereof is correct; inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained second condition prediction model to obtain a second prediction result, the second prediction result comprising, for each of the candidate prediction results, a probability that the candidate component category thereof is correct; and determining the component category of the first component and the corresponding damage category thereof at least based on the first prediction result and the second prediction result.
24. The method according to claim 23, further comprising: inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained third prediction model to obtain a third prediction result, the third prediction result comprising, for each of the candidate prediction results, a probability that the candidate damage category and the candidate component category thereof are both correct.
25. The method according to claim 24, wherein determining the component category of the first component and the corresponding damage category thereof at least based on the first prediction result and the second prediction result comprises: determining the component category of the first component and the corresponding damage category thereof based on the first prediction result, the second prediction result, and the third prediction result.
26. The method according to claim 25, wherein determining the component category of the first component and the corresponding damage category thereof based on the first prediction result, the second prediction result, and the third prediction result comprises: establishing a decision tree model by using the first condition prediction model, the second condition prediction model, and the third prediction model as tree nodes, and determining the component category of the first component and the corresponding damage category thereof using the decision tree model.
27. The method according to claim 26, wherein the decision tree model is trained using a damage assessment form of a damage assessment case as annotation data.
28. An apparatus for assessing vehicle damage, comprising: a memory storing computer-executable instructions; and a processor configured to, when executing the computer-executable instructions, perform: acquiring a to-be-identified vehicle damage image; acquiring damage object detection information using a pre-trained damage detection model, the damage object detection information comprising information of a plurality of damage detection frames framing a plurality of damage objects in the vehicle damage image; acquiring vehicle component information for the vehicle damage image using a pre-trained component model, the vehicle component information comprising component object detection information and component segmentation information, the component object detection information comprising a detected first component; generating a first comprehensive feature for the first component based on the damage object detection information and the vehicle component information, the first comprehensive feature comprising a component feature and a fused damage feature of the first component, and the fused damage feature being obtained by fusing damage features of at least one damage detection frame belonging to the first component among the plurality of damage detection frames; determining a plurality of candidate prediction results for the first component, each of the candidate prediction results comprising a candidate component category and a candidate damage category; inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained first condition prediction model to obtain a first prediction result, the first prediction result comprising, for each of the candidate prediction results, a probability that the candidate damage category thereof is correct; inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained second condition prediction model to obtain a second prediction result, the second prediction result comprising, for each of the candidate prediction results, a probability that the candidate component category thereof is correct; and determining the component category of the first component and the corresponding damage category thereof at least based on the first prediction result and the second prediction result.
29. An apparatus for assessing vehicle damage, comprising: a memory storing computer-executable instructions; and a processor configured to, when executing the computer-executable instructions, perform: acquiring a first to-be-identified vehicle damage image and a second to-be-identified vehicle damage image, the first vehicle damage image and the second vehicle damage image belonging to the same damage assessment case; acquiring first damage object detection information for the first vehicle damage image and second damage object detection information for the second vehicle damage image using a pre-trained damage detection model, the first damage object detection information comprising information of a plurality of first damage detection frames framing a plurality of damage objects in the first vehicle damage image, and the second damage object detection information comprising information of a plurality of second damage detection frames framing a plurality of damage objects in the second vehicle damage image; acquiring first vehicle component information for the first vehicle damage image and second vehicle component information for the second vehicle damage image using a pre-trained component model, the first vehicle component information comprising first component object detection information and first component segmentation information, and the second vehicle component information comprising second component object detection information and second component segmentation information; determining a common first component from the first component object detection information and the second component object detection information based on an association between the first vehicle damage image and the second vehicle damage image; generating a first comprehensive feature for the first component based on the first damage object detection information, the second damage object detection information, the first vehicle component information, and the second vehicle component information, the first comprehensive feature comprising a fused component feature and a fused damage feature of the first component, wherein the fused component feature is obtained by fusing a first component feature and a second component feature, the first component feature being generated based on the first vehicle damage image, and the second component feature being generated based on the second vehicle damage image; and the fused damage feature is obtained by fusing a first damage feature and a second damage feature, the first damage feature being generated based on damage features of at least one first damage detection frame belonging to the first component in the first vehicle damage image, and the second damage feature being generated based on damage features of at least one second damage detection frame belonging to the first component in the second vehicle damage image; determining a plurality of candidate prediction results for the first component, each of the candidate prediction results comprising a candidate component category and a candidate damage category; inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained first condition prediction model to obtain a first prediction result, the first prediction result comprising, for each of the candidate prediction results, a probability that the candidate damage category thereof is correct; inputting the first comprehensive feature and the plurality of candidate prediction results into a pre-trained second condition prediction model to obtain a second prediction result, the second prediction result comprising, for each of the candidate prediction results, a probability that the candidate component category thereof correct; and determining the component category of the first component and the corresponding damage category thereof at least based on the first prediction result and the second prediction result.
</claims>
</document>
