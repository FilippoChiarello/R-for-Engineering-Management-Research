<document>

<filing_date>
2020-04-21
</filing_date>

<publication_date>
2020-12-31
</publication_date>

<priority_date>
2019-06-26
</priority_date>

<ipc_classes>
G06F21/56,G06F8/41,G06K9/62,G06N3/04
</ipc_classes>

<assignee>
HRL LABORATORIES
</assignee>

<inventors>
HOFFMANN, HEIKO
KOLOURI, SOHEIL
</inventors>

<docdb_family_id>
70740745
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR DETECTING BACKDOOR ATTACKS IN CONVOLUTIONAL NEURAL NETWORKS
</title>

<abstract>
Described is a system for detecting backdoor attacks in deep convolutional neural networks (CNNs). The system compiles specifications of a pretrained CNN into an executable model, resulting in a compiled model. A set of Universal Litmus Patterns (ULPs) are fed through the compiled model, resulting in a set of model outputs. The set of model outputs are classified and used to determine presence of a backdoor attack in the pretrained CNN. The system performs a response based on the presence of the backdoor attack.
</abstract>

<claims>
1. A system for detecting backdoor attacks in deep convolutional neural networks, the system comprising: one or more processors and a non-transitory computer-readable medium having executable instructions encoded thereon such that when executed, the one or more processors perform an operation of: compiling specifications of a pretrained convolutional neural network (CNN) into an executable model, resulting in a compiled model; retrieving a set of Universal Litmus Patterns (ULPs); feeding the set of ULPs through the compiled model, resulting in a set of model outputs; classifying the set of model outputs; using the classified set of model outputs, determining presence of a backdoor attack in the pretrained CNN; and performing a response based on the presence of the backdoor attack.
2. The system as set forth in claim 1, where in performing the response, the one or more processors further perform an operation of transmitting an alert regarding the presence of the backdoor attack to a display.
3. The system as set forth in claim 1, wherein the set of ULPs is the result of optimizing the following:
description="In-line Formulae" end="lead"?argminz,hΣn=1N(h(g({fn(zm)}m=1M)),cn)+λΣm=1MR(zm),description="In-line Formulae" end="tail"? where argmin denotes a minimization operation, (., .) is a loss function, {zm}m=1M denotes the set of patterns, {f(zm)}m=1M denotes the set of model outputs, g(⋅) is a pooling operator applied on the set of model outputs, resulting in a pooled vector g({f(zm)}m=1M), M is the total number of ULPs, m is the index of the mth ULP, N is the total number of training networks, fn, n is the index of the nth network, h(⋅) is a classifier that receives the pooled vector as input, R(⋅) is a regularizer for the set of patterns, and λ is a regularization coefficient.
4. The system as set forth in claim 1, wherein the specifications comprise a plurality of weights and a description of an architecture of the pretrained CNN.
5. The system as set forth in claim 4, wherein the description of the architecture is a textual description of the architecture, and the plurality of weights comprises a binary file containing a table of numbers.
6. The system as set forth in claim 1, wherein the one or more processors further perform operations of: testing a new CNN by feeding the set ULPs through the compiled model; and determining whether the new CNN contains a backdoor attack.
7. A computer implemented method for detecting backdoor attacks in deep convolutional neural networks, the method comprising an act of: causing one or more processers to execute instructions encoded on a non-transitory computer-readable medium, such that upon execution, the one or more processors perform operations of: compiling specifications of a pretrained convolutional neural network (CNN) into an executable model, resulting in a compiled model; retrieving a set of Universal Litmus Patterns (ULPs); feeding the set of ULPs through the compiled model, resulting in a set of model outputs; classifying the set of model outputs; using the classified set of model outputs, determining presence of a backdoor attack in the pretrained CNN; and performing a response based on the presence of the backdoor attack.
8. The method as set forth in claim 7, where in performing the response, the one or more processors further perform an operation of transmitting an alert regarding the presence of the backdoor attack to a display.
9. The method as set forth in claim 7, wherein the set of ULPs is the result of optimizing the following:
description="In-line Formulae" end="lead"?argminz,hΣn=1N(h(g({fn(zm)}m=1M)),cn)+λΣm=1MR(zm),description="In-line Formulae" end="tail"? where argmin denotes a minimization operation, (., .) is a loss function, {zm}m=1M denotes the set of patterns, {f(zm)}m=1M denotes the set of model outputs, g(⋅) is a pooling operator applied on the set of model outputs, resulting in a pooled vector g({f(zm)}m=1M), M is the total number of ULPs, m is the index of the mth ULP, N is the total number of training networks, fn, n is the index of the nth network, h(⋅) is a classifier that receives the pooled vector as input, R(⋅) is a regularizer for the set of patterns, and λ is a regularization coefficient.
10. The method as set forth in claim 7, wherein the specifications comprise a plurality of weights and a description of an architecture of the pretrained CNN.
11. The method as set forth in claim 10, wherein the description of the architecture is a textual description of the architecture, and the plurality of weights comprises a binary file containing a table of numbers.
12. The method as set forth in claim 7, wherein the one or more processors further perform operations of: testing a new CNN by feeding the set of ULPs through the compiled model; and determining whether the new CNN contains a backdoor attack.
13. A computer program product for detecting backdoor attacks in deep convolutional neural networks, the computer program product comprising: computer-readable instructions stored on a non-transitory computer-readable medium that are executable by a computer having one or more processors for causing the processor to perform operations of: compiling specifications of a pretrained convolutional neural network (CNN) into an executable model, resulting in a compiled model; retrieving a set of Universal Litmus Patterns (ULPs); feeding the set of ULPs through the compiled model, resulting in a set of model outputs; classifying the set of model outputs; using the classified set of model outputs, determining presence of a backdoor attack in the pretrained CNN; and performing a response based on the presence of the backdoor attack.
14. The computer program product as set forth in claim 13, wherein the set of ULPs is the result of optimizing the following:
description="In-line Formulae" end="lead"?argminz,hΣn=1N(h(g({fn(zm)}m=1M)),cn)+λΣm=1MR(zm),description="In-line Formulae" end="tail"? where argmin denotes a minimization operation, (., .) is a loss function, {zm}m=1M denotes the set of patterns, {f (zm)}m=1M denotes the set of model outputs, g(⋅) is a pooling operator applied on the set of model outputs, resulting in a pooled vector g({f(zm)}m=1M), M is the total number of ULPs, m is the index of the mth ULP, N is the total number of training networks, fn, n is the index of the nth network, h(⋅) is a classifier that receives the pooled vector as input, R(⋅) is a regularizer for the set of patterns, and λ is a regularization coefficient.
15. The computer program product as set forth in claim 13, wherein the specifications comprise a plurality of weights and a description of an architecture of the pretrained CNN.
16. The computer program product as set forth in claim 15, wherein the description of the architecture is a textual description of the architecture, and the plurality of weights comprises a binary file containing a table of numbers.
17. The computer program product as set forth in claim 13, wherein the one or more processors further perform operations of: testing a new CNN by feeding the set of ULPs through the compiled model; and determining whether the new CNN contains a backdoor attack.
18. A set of Universal Litmus Patterns (ULPs) for detecting backdoor attacks in deep convolutional neural networks generated by a process comprising: instantiating a set of random images and a classifier; feeding the set of random images to a set of training networks labeled as poisoned or clean, resulting in a plurality of network outputs; pooling the plurality of network outputs; feeding the plurality of network outputs to the classifier, resulting in a classification decision; and updating the classifier and the set of random images based on the classification decision over a plurality of iterations until convergence is reached.
</claims>
</document>
