<document>

<filing_date>
2018-07-18
</filing_date>

<publication_date>
2020-08-06
</publication_date>

<priority_date>
2017-07-18
</priority_date>

<ipc_classes>
A61B3/00,A61B3/113,A61B3/14,A61B5/00,A61B5/11,G02C7/02,G06T7/70
</ipc_classes>

<assignee>
ESSILOR INTERNATIONAL
</assignee>

<inventors>
FRICKER, SEBASTIEN
LE CAIN, AURELIE
</inventors>

<docdb_family_id>
59569239
</docdb_family_id>

<title>
A METHOD FOR DETERMINING A POSTURAL AND VISUAL BEHAVIOR OF A PERSON
</title>

<abstract>
A method for determining a postural and visual behavior of a person, the method comprising:—a person image receiving step during which a plurality of images of the person are received,—a context determining step during which the plurality of images of the person are analyzed so as to determine context data representative of the context in which the person is on each image of the plurality of images,—an analyzing step during which the plurality of images of the person are analyzed so as to determine at least one oculomotor parameter of the person,—a postural and visual behavior determining step during which a postural and visual behavior of the person is determined based at least on the at least one oculomotor parameter and the context data.
</abstract>

<claims>
1. A method for determining a visual and postural behavior a person, the method comprising: a person image receiving step S1 during which a plurality of images of the person are received, a context determining step S2 during which the plurality of images of the person are analyzed so as to determine context data representative of the context in which the person is on each image of the plurality of images, an analyzing step S3 during which the plurality of images of the person are analyzed so as to determine at least one oculomotor parameter of the person, and a postural and visual behavior determining step S4 during which the optical and postural behavior of the person is determined based at least on the at least one oculomotor parameter and the context data.
2. The method according to claim 1, further comprising: a reference postural and visual behavior data receiving step S5 during which reference postural and visual behavior data are received, the reference postural and visual behavior data corresponding to the appropriate postural and visual behavior of a reference person wearing lenses of a specific prescription adapted to said reference person, and a comparison step S6 during which reference postural and visual behavior data and the postural and visual behavior of the person are compared so as to determine a lens utilization anomaly, the lens utilization anomaly referring to an inappropriate utilization of the lenses and/or the utilization of lenses not adapted for the person.
3. The method according to claim 1, further comprising: a prescription data receiving step S7 during which prescription data of the person are received, and an optical function determining step S8 during which an optical function adapted for the wearer is determined based at least on the prescription data and the postural and visual behavior of the person.
4. The method according to claim 1, wherein the optical function is adapted for the person in at least one context.
5. The method according to claim 3, wherein during the optical function determining step a dioptric function adapted for the person is determined.
6. The method according to claim 3, wherein during the optical function determining step an electrochromic function adapted for the person is determined.
7. The method according to claim 1, wherein the plurality of images of the person received during the person image receiving step are received from at least one distant image data base.
8. The method according to claim 1, wherein the plurality of images of the person received during the person image receiving step comprises at least part of the person's face, for example at least the person's eyes.
9. The method according to claim 1, wherein the plurality of images of the person received during the person image receiving step comprise static images and/or videos of the person.
10. The method according to claim 1, wherein the at least one oculomotor parameter relates at least to the gazing direction of the person.
11. The method according to claim 1, wherein the at least one oculomotor parameter relates at least to the gazing distance of the person.
12. The method according to claim 1, wherein the at least one oculomotor parameter relates at least to the position and orientation of the head of the person.
13. The method according to claim 1, wherein the context data relate to the activity carried out by the person on the images.
14. The method according to claim 1, wherein the context data relate to the visual environment of the person on the images.
15. The method according to claim 1, further comprising: prior to the context determining step a context data receiving step S20 during which context data representative of the at least one context are received, and further to the context determining step an image selection step S21 during which a plurality of images of the at least one person in the at least one context are selected, wherein during the analyzing step the selected plurality of images of the at least one person are analyzed.
16. The method according to claim 1, further comprising: prior to the context determining and analyzing steps an image selection step S 11 during which the images of the person wearing single vision ophthalmic lenses or no ophthalmic lenses are selected, wherein the context determining and analyzing steps are carried out on the selected images.
17. An optical lens adapted for a person having an optical function determined by the method according to claims 3.
18. A non-transitory computer program product comprising one or more stored sequences of instructions that are accessible to a processor and which, when executed by the processor, causes the processor to carry out the steps of the method according to claim 1.
19. (canceled)
</claims>
</document>
