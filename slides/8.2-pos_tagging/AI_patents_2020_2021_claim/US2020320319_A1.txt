<document>

<filing_date>
2019-09-03
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-08
</priority_date>

<ipc_classes>
A61B5/00,A61B5/024,A61B5/16,A61B5/18,G06K9/00
</ipc_classes>

<assignee>
NATIONAL CHIAO TUNG UNIVERSITY
</assignee>

<inventors>
WU, BING-FEI
CHEN, KUAN-HUNG
HUANG, PO-WEI
Tsai, Yin-Cheng
</inventors>

<docdb_family_id>
72663511
</docdb_family_id>

<title>
METHOD FOR ASSESSING DRIVER FATIGUE
</title>

<abstract>
A method for assessing driver fatigue is implemented by a processor and includes steps of: based on images of a driver captured by an image capturing device, obtaining an entry of physiological information that indicates a physiological state of the driver; based on one of the images of the driver, obtaining an entry of facial expression information that indicates an emotional state of the driver; based on one of the images of the driver, obtaining an entry of behavioral information that indicates driver behavior of the driver; and based on the entry of physiological information, the entry of facial expression information and the entry of behavioral information, obtaining a fatigue score that indicates a level of fatigue of the driver.
</abstract>

<claims>
1. A method for assessing driver fatigue, to be implemented by a processor, the processor being electrically connected to an image capturing device, the image capturing device continuously capturing a plurality of images of a driver, the method comprising: (A) based on the images of the driver captured by the image capturing device, obtaining an entry of physiological information that indicates a physiological state of the driver; (B) based on one of the images of the driver, obtaining an entry of facial expression information that indicates an emotional state of the driver; (C) based on one of the images of the driver, obtaining an entry of behavioral information that indicates driver behavior of the driver; and (D) based on the entry of physiological information, the entry of facial expression information and the entry of behavioral information, obtaining a fatigue score that indicates a level of fatigue of the driver.
2. The method as claimed in claim 1, wherein the entry of physiological information is in time domain.
3. The method as claimed in claim 2, wherein step (A) includes sub-steps of: (A-1) for each of the images, based on the image, obtaining a facial sub-image that corresponds to a facial region of the driver in the image; (A-2) based on the facial sub-images for the images, obtaining a time-domain waveform that is associated with heartbeat of the driver; and (A-3) based on the time-domain waveform, obtaining a heart rate that is a number of heartbeats of the driver per unit of time and that is included in the entry of physiological information, and a standard deviation of normal-to-normal intervals (SDNN) that is associated with the heartbeat of the driver and that is included in the entry of physiological information.
4. The method as claimed in claim 3, wherein step (A-2) includes sub-steps of: (A-2-1) based on the facial sub-images for the images, obtaining a photoplethysmography (PPG) signal; and (A-2-2) based on the PPG signal, obtaining the time-domain waveform.
5. The method as claimed in claim 3, wherein step (D) includes sub-steps of: (D-1) based on the heart rate of the entry of physiological information and a fuzzy model that is associated with heart rate, obtaining a heart-rate score that is associated with the driver; (D-2) based on the SDNN of the entry of physiological information and a fuzzy model that is associated with SDNN, obtaining an SDNN score that is associated with the driver; and (D-3) obtaining the fatigue score that indicates the level of fatigue of the driver based on the heart-rate score and the SDNN score by using a classification model for fatigue level assessment that is associated with heart rate, SDNN, facial expression information and behavioral information.
6. The method as claimed in claim 1, wherein the entry of physiological information is in frequency domain.
7. The method as claimed in claim 6, wherein step (A) includes sub-steps of: (A-1′) for each of the images, based on the image, obtaining a facial sub-image that corresponds to a facial region of the driver in the image; (A-2′) based on the facial sub-images for the images, obtaining a time-domain waveform that is associated with heartbeat of the driver; and (A-3′) based on the time-domain waveform and by using Fourier transform, obtaining a ratio of low frequency to high frequency power (LF/HF ratio) that is associated with sympathovagal balance of the driver and that is included in the entry of physiological information.
8. The method as claimed in claim 7, wherein step (A-2′) includes sub-steps of: (A-2′-1) based on the facial sub-images for the images, obtaining a photoplethysmography (PPG) signal; and (A-2′-2) based on the PPG signal, obtaining the time-domain waveform.
9. The method as claimed in claim 6, wherein step (D) includes sub-steps of: (D-1′) based on the LF/HF ratio of the entry of physiological information and a fuzzy model that is associated with LF/HF ratio, obtaining an LF/HF-ratio score that is associated with the driver; and (D-2′) obtaining the fatigue score that indicates the level of fatigue of the driver based on the LF/HF-ratio score by using a classification model for fatigue level assessment that is associated with LF/HF ratio, facial expression information and behavioral information.
10. The method as claimed in claim 1, wherein step (B) includes sub-steps of: (B-1) based on a last one of the images of the driver captured by the image capturing device, obtaining a facial portion of the driver in the last one of the images; and (B-2) based on the facial portion of the driver in the last one of the images by using a predetermined classification model of facial expression, obtaining the entry of facial expression information that corresponds to the facial expression of the driver in the last one of the images and that includes an anger score, a disgust score, a scare score, a happiness score, a sadness score and an amazement score.
</claims>
</document>
