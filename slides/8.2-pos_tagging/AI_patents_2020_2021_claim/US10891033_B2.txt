<document>

<filing_date>
2018-08-24
</filing_date>

<publication_date>
2021-01-12
</publication_date>

<priority_date>
2018-08-24
</priority_date>

<ipc_classes>
G06F3/0484,G06F3/0488
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
MANNBY, CLAES-FREDRIK U.
</inventors>

<docdb_family_id>
69583557
</docdb_family_id>

<title>
System and method for enhanced touch selection of content
</title>

<abstract>
Methods for enhancing touch selections for content are performed by systems and devices. Users apply a contact instrument such as a finger, stylus, or pen to a touch interface to select content displayed via a user interface. Different amounts of the content are selected based on the characteristics of the contact instrument application to the touch interface and displayed to the user. Additionally, selected portions of content can be expanded or reduced by altering the application of the contact instrument, such as changing pressure or orientation, and by receiving other selection modifying inputs from other input devices. Characteristics of interaction for contact instruments are determined and applied to selection commands by the systems and devices. Context information related to the content is also used in determining the scope of selections.
</abstract>

<claims>
1. A user interface (UI) system, comprising: a processing system comprising one or more processors; and a memory that stores program code to be executed by the processing system, the program code including: an input detector configured to: receive an input that is associated with content provided via a UI, and that is applied by a contact instrument via a touch interface; and determine characterization information of the contact instrument relative to the touch interface, the characterization information of the contact instrument including an orientation; a parameter generator configured to: generate a parameter of a selection command based at least in part on the orientation included in the characterization information, the parameter specifying a portion of the content; and an output manager configured to: cause the selection command to be executed with the parameter; and provide an output to the UI based on execution of the selection command, the output including an indication of the portion of the content that was selected.
2. The UI system of claim 1, wherein the characterization information includes a location of interaction between the contact instrument and the touch interface; wherein the input detector is configured to: determine that the contact instrument continues to interact with the touch interface at the location subsequent to the output being provided; and determine a change in the characterization information of the contact instrument relative to the touch interface; wherein the parameter generator is configured to: re-generate the parameter of the selection command based at least in part on the change in the characterization information; and wherein the output manager is configured to: cause the selection command to be re-executed with the re-generated parameter; and provide another output to the UI based on re-execution of the selection command, the other output including an indication of another portion of the content that was selected.
3. The UI system of claim 2, further comprising a context manager configured to: determine context information related to the content, the context information being based on at least one of semantics of the content, a type of application related to the content, a type of object in the content, or a delimiter in the content; and wherein the parameter generator is configured to: receive the context information related to the content; and generate or re-generate the parameter of the selection command also based on the context information.
4. The UI system of claim 2, wherein the characterization information comprises a first elevation angle of the orientation, and the change in the characterization information comprises a change in the first elevation angle to a second elevation angle, the second elevation angle being greater than the first elevation angle and indicating a decrease in the portion of content selected, or the second elevation angle being less than the first elevation angle and indicating an increase in the portion of content selected; wherein the characterization information comprises a first azimuth angle of the orientation, and the change in the characterization information comprises a change in the first azimuth angle to a second azimuth angle, the second azimuth angle being greater than the first azimuth angle and indicating a decrease in the portion of content selected, or the second azimuth angle being less than the first azimuth angle and indicating an increase in the portion of content selected; or wherein the characterization information includes a pressure that comprises a first pressure, and the change in the characterization information comprises a change in the first pressure to a second pressure, the second pressure being less than the first pressure and indicating a decrease in the portion of content selected, or the second pressure being greater than the first pressure and indicating an increase in the portion of content selected.
5. The UI system of claim 2, wherein the input detector is configured to: determine the change in the characterization information based on the change in the characterization information exceeding a hysteretic change limit; and maintain the characterization information based on the change in the characterization information not exceeding the hysteretic change limit.
6. The UI system of claim 1, wherein the content comprises at least one of typed characters, handwritten characters, images, photographs, diagrams, cells in a grid, audio data, video data, a virtual environment, or graphs.
7. The UI system of claim 1, wherein the touch interface comprises a touch screen configured to enable interaction by the contact instrument and to display the UI.
8. A computer-implemented method, comprising: receiving an input applied by a contact instrument at a location of a touch interface, the input corresponding to content of a software application; determining a characteristic of the contact instrument that includes an orientation of the contact instrument with reference to the touch interface; generating parameter information associated with a command configured to select a portion of the content based at least in part on the orientation of the contact instrument that comprises the characteristic of the contact instrument; and providing an output to a user interface (UI), the output including an indication of the portion of the content that was selected based on execution of the command.
9. The computer-implemented method of claim 8, the method further comprising: determining that the contact instrument continues to interact with the touch interface at the location subsequent to the output being provided; determining a change in the characteristic of the contact instrument relative to the touch interface; re-generating the parameter information based at least in part on the change in the characteristic of the contact instrument; and providing another output to the UI based on re-execution of the command with the re-generated parameter information, the other output including an indication of another portion of the content that was selected.
10. The computer-implemented method of claim 9, the method further comprising: receiving context information related to the content, the context information being based on at least one of semantics of the content, a type of application related to the content, a type of object in the content, or a delimiter in the content; wherein at least one of the generating the parameter information or the re-generating the parameter information is further based on the context information.
11. The computer-implemented method of claim 9, the method further comprising: performing an action on the other portion of the content that was selected; providing, subsequent to performing the action, information associated with at least one of the selection command, the characteristic, the change in the characteristic, the generated parameter information, the re-generated parameter information, the portion that was selected, or the other portion of the content that was selected to a machine learning host; and receiving update information for subsequent determinations of characteristics of the contact instrument.
12. The computer-implemented method of claim 8, wherein the characteristic of the contact instrument also includes a pressure of the contact instrument with reference to the touch interface; wherein the parameter information associated with the command configured to select the portion of the content is also based at least in part on the pressure of the contact instrument that comprises the characteristic of the contact instrument.
13. The computer-implemented method of claim 8, wherein the characteristic of the contact instrument has a default value and at least one other value associated therewith, the default value indicating a default portion amount for selection, and the at least one other value indicating an amount for selection that is different from the default portion amount.
14. The computer-implemented method of claim 8, further comprising: determining that the contact instrument continues to interact with the touch interface at the location subsequent to the output being provided; receiving an additional input from an input device while the contact instrument interacts with the touch interface; re-generating the parameter information based at least in part on the additional input; and providing another output to the UI based on re-execution of the command with the re-generated parameter information, the other output including an indication of another portion of the content that was selected.
15. A computer-readable storage medium having program instructions recorded thereon that, when executed by a processing device, perform a method, the method comprising: receiving an input that indicates a selection related to content and that is applied by a contact instrument via an input interface; determining characterization information related to interaction of the contact instrument with the input interface, the characterization information including an orientation of the contact instrument and indicating a scope for a selection command that is configured to select a portion of the content; generating a parameter for the selection command based at least in part on the orientation of the contact instrument included in the characterization information; selecting the portion of the content via execution of the selection command having the parameter; and providing an output to a user interface (UI), the output including an indication of the portion of the content that was selected.
16. The computer-readable storage medium of claim 15, wherein the characterization information includes a location of interaction between the contact instrument and the input interface; and wherein the method further comprises: determining that the contact instrument continues to interact with the input interface at the location subsequent to the output being provided; determining a change in the characterization information of the contact instrument relative to the input interface; re-generating the parameter of the selection command based at least in part on the change in the characterization information; selecting another portion of the content via re-execution of the command with the re-generated parameter; and providing another output to the UI, the other output including another indication of the other portion of the content that was selected.
17. The computer-readable storage medium of claim 15, wherein the content is textual characters; and wherein the portion and the other portion are respectively one of a proper name, a phrase, or a grammatical portion of a sentence.
18. The computer-readable storage medium of claim 15, wherein generating the parameter includes: determining context information related to the content, the context information being based on at least one of semantics of the content, a type of application related to the content, a type of object in the content, or a delimiter in the content; wherein the generating the parameter is also based at least in part on the context information.
19. The computer-readable storage medium of claim 15, wherein the characterization information also includes a pressure of the contact instrument with reference to the touch interface; wherein the parameter for the selection command is also based at least in part on the pressure of the contact instrument that comprises the characteristic of the contact instrument.
20. The computer-readable storage medium of claim 15, wherein the method further comprises: receiving an additional input from an input device while the contact instrument interacts with the touch interface; wherein the generating the parameter is also based at least in part on the additional input.
</claims>
</document>
