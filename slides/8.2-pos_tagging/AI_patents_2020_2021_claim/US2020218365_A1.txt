<document>

<filing_date>
2019-12-31
</filing_date>

<publication_date>
2020-07-09
</publication_date>

<priority_date>
2019-01-04
</priority_date>

<ipc_classes>
G06F3/01,G06F3/03,G06T7/73
</ipc_classes>

<assignee>
RED PILL LAB
</assignee>

<inventors>
LIN, TING-CHIEH
HUANG, YI-CHI
TODOROV, DOBROMIR
SHIH, CHIEN-HUNG
</inventors>

<docdb_family_id>
71403730
</docdb_family_id>

<title>
Method of Motion Capture
</title>

<abstract>
A method of motion capture includes: by multiple positioning devices located on a user, receiving scanning signals emitted by signal emitting devices to obtain detected coordinates, determining angular information, and generating and transmitting to a processor position signals that contain the angular information and the detected coordinates of the positioning devices; by the processor based on the position signals and data of a skeleton related to the user, determining estimated coordinates of a position of a body portion of the user; and generating an image of a virtual object based on the position signals, the estimated coordinates, the data of the skeleton related to the user and data of a skeleton related to a virtual object, and controlling a display to display the image.
</abstract>

<claims>
1. A method of motion capture adapted to record a posture of a user in a predefined space and translating the posture to a virtual object, the method to be implemented by a system that includes a processor, a display device, two signal emitting devices located at respective predetermined positions, and six positioning devices respectively located on a head, a waist, a left hand, a right hand, a left foot and a right foot of the user, said method comprising: (A) emitting, by one of the signal emitting devices, a two-dimensional (2D) scanning signal along a predetermined direction to scan the predefined space, and emitting, by another of the signal emitting devices, another 2D scanning signal along another predetermined direction to scan the predefined space; (B) by each of the positioning devices at an instant during performance of a target action by the user, receiving the 2D scanning signals emitted from the signal emitting devices so as to obtain detected spatial coordinates of a current position of the positioning device, determining angular information of an orientation of the positioning device, generating a position signal that contains the angular information of the orientation of the positioning device, and that contains the detected spatial coordinates of the current position of the positioning device, and transmitting the position signal to the processor based on wireless communication techniques; (C) determining, by the processor based on the position signals respectively received from the positioning devices and based on data of a skeleton related to the user, estimated spatial coordinates of a current position of a specific body portion of the user by using one of a machine learning model and a position estimating model that matches the skeleton related to the user; and (D) by the processor, generating an image of the virtual object at the instant during performance of the target action based on the position signals, the estimated spatial coordinates, the data of the skeleton related to the user, and data of a skeleton related to the virtual object, and controlling the display device to display the image of the virtual object at the instant during performance of the target action.
2. The method of motion capture as claimed in claim 1, prior to step (B), further comprising: (E) by each of the positioning devices, generating a posture signal that contains the detected spatial coordinates of a current position of the positioning device based on the 2D scanning signals received from the signal emitting devices when the user maintains a preset posture in the predefined space, and transmitting the posture signal to the processor based on the wireless communication techniques; (F) by the processor based on the posture signals generated respectively by the positioning devices, obtaining the data of the skeleton related to the user; and (G) by the processor, generating an image for preview based on the posture signals, the data of the skeleton related to the user and the data of the skeleton related to the virtual object, and controlling the display device to display the image for preview, wherein the image for preview contains the virtual object assuming the preset posture, the skeleton related to the user and the skeleton related to the virtual object.
3. The method of motion capture as claimed in claim 1, wherein in step (C), the specific body portion of the user is plural in number, and the specific body portions at least include a neck, a left shoulder, a right shoulder, a left elbow, a right elbow, a left knee and a right knee.
4. The method of motion capture as claimed in claim 3, wherein in step (C): the position estimating model is established based on triangulation and limitations conforming with principles of ergonomics; and the machine learning model is established by training an artificial neural network with plural pieces of position training data and plural pieces of skeleton training data, the pieces of position training data and the pieces of skeleton training data being derived from a training data set that is generated by a plurality of optical sensors worn by a plurality of testers having different body types and performing preset actions, each of the pieces of position training data containing spatial coordinates of positions of a head, a waist, a left hand, a right hand, a left foot and a right foot of one of the testers who is performing one of the preset actions for training the artificial neural network, each of the pieces of skeleton training data containing data of the skeleton related to a respective one of the testers who is performing one of the preset actions for training the artificial neural network.
5. The method of motion capture as claimed in claim 1, wherein the artificial neural network is a recurrent neural network (RNN).
</claims>
</document>
