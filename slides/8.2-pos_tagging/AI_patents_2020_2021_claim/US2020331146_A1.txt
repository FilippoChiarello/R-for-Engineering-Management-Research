<document>

<filing_date>
2020-07-02
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2017-02-07
</priority_date>

<ipc_classes>
B25J19/02,B25J9/16,G05B19/4061,G06F3/01,G06K9/62,G06T15/20,G06T19/20
</ipc_classes>

<assignee>
VU, CLARA
FELDMAN, ABRAHAM K.
DENENBERG, SCOTT
</assignee>

<inventors>
VU, CLARA
FELDMAN, ABRAHAM K.
DENENBERG, SCOTT
</inventors>

<docdb_family_id>
72833527
</docdb_family_id>

<title>
DYNAMIC, INTERACTIVE SIGNALING OF SAFETY-RELATED CONDITIONS IN A MONITORED ENVIRONMENT
</title>

<abstract>
Systems and methods for determining safe and unsafe zones in a workspace—where safe actions are calculated in real time based on all relevant objects (e.g., some observed by sensors and others computationally generated based on analysis of the sensed workspace) and on the current state of the machinery (e.g., a robot) in the workspace—may utilize a variety of workspace-monitoring approaches as well as dynamic modeling of the robot geometry. The future trajectory of the robot(s) and/or the human(s) may be forecast using, e.g., a model of human movement and other forms of control. Modeling and forecasting of the robot may, in some embodiments, make use of data provided by the robot controller that may or may not include safety guarantees.
</abstract>

<claims>
1. A system for perceptibly indicating information in a digitally represented three-dimensional (3D) workspace including industrial machinery, the system comprising: a plurality of sensors distributed about the workspace, each of the sensors being associated with a grid of pixels for recording images of a portion of the workspace within a sensor field of view, the workspace portions collectively covering the entire workspace; a computer memory for storing (i) a plurality of images from the sensors and (ii) a model of the machinery and its permitted movements during performance of the activity; a source for generating perceptible signals; and a processor configured to: computationally generate, from the stored images, a 3D spatial representation of the workspace; identify, from the images, at least one observed feature appearing in at least one of the images from the sensors, at least one computationally based feature not appearing in any of the images from the sensors; and operate the signal source to perceptibly indicate at least one observed feature and at least one computationally based feature.
2. The system of claim 1, wherein each observed feature is represented in the computer memory as a voxel cluster, a depth image, a mesh, a bounding box, or a line.
3. The system of claim 1, wherein: a first one of the observed features is machinery; a first one of the computationally based features is a 3D envelope around the machinery in the workspace and spanning permitted movements of the machinery in accordance with a stored model; and a second one of the computationally based features is space potentially occupied by a human or a human appendage.
4. The system of claim 2, wherein a third one of the computationally based features is a minimum distance between the first and second computationally based features, the signal source being operable by the processor to show the third computationally based feature as a line between the first and second computationally based features.
5. The system of claim 3, wherein the signal source is operable by the processor to show whether a slowdown or stop is necessary or is predicted to become necessary within a predetermined time based on a minimum distance between the first and second computationally based features.
6. The system of claim 1, wherein a first one of the observed features is a recognized physical object in the workspace and the signal source is operable by the processor to display a representation of the object with a color indicating its type.
7. The system of claim 6, wherein the signal source is operable by the processor to display contents of the workspace in grayscale as a background.
8. The system of claim 1, wherein a first one of the observed features is a recognized workpiece in the workspace and the signal source is operable by the processor to display a representation of the workpiece showing a deviation from an expected position thereof.
9. The system of claim 1, wherein a first one of the computationally generated features is a keep-out zone, the signal source being operable by the processor to display a representation of the keep-out zone in the workspace.
10. The system of claim 1, wherein a first one of the computationally generated features is a keep-in zone, the signal source being operable by the processor to display a representation of the keep-in zone in the workspace.
11. The system of claim 1, wherein a first one of the computationally generated features is a cluster of voxels corresponding to a spatial region in the workspace that none of the sensors can observe, the signal source being operable by the processor to display the cluster of voxels in a representation of the workspace.
12. The system of claim 1, the signal source is operable by the processor to display a representation of an object with a color indicating its state.
13. The system of claim 1, wherein the signal source is a VR headset.
14. The system of claim 1, wherein the signal source is a 2D display.
15. A method of perceptibly indicating information associated with voxel clusters in a digitally represented three-dimensional (3D) workspace including industrial machinery, the method comprising the steps of: monitoring the workspace with a plurality of sensors distributed thereabout, each of the sensors being associated with a grid of pixels for recording images of a portion of the workspace within a sensor field of view, the workspace portions collectively covering the entire workspace; registering the sensors with respect to each other so that the images obtained by the sensors collectively represent the workspace; storing, in a computer memory, (i) a plurality of images from the sensors and (ii) a model of the machinery and its permitted movements during performance of the activity; computationally generating, from the stored images, a 3D spatial representation of the workspace; computationally identifying, from the images, at least one observed feature appearing in at least one of the images from the sensors and at least one computationally based feature not appearing in any of the images from the sensors; and generating a signal to perceptibly indicate at least one observed feature and at least one computationally based feature.
16. The method of claim 15, wherein each observed feature is digitally represented as a voxel cluster, a depth image, a mesh, a bounding box, or a line.
17. The method of claim 15, wherein: a first one of the identified computationally based features is a 3D envelope around machinery in the workspace and spanning permitted movements of the machinery in accordance with a stored model; and a second one of the computationally based features is space potentially occupied by a human or a human appendage.
18. The method of claim 17, wherein a third one of the computationally based features is a minimum distance between the first and second computationally based features, the signal showing the third computationally based feature as a line between the first and second computationally based features.
19. The method of claim 17, wherein the signal shows whether a slowdown or stop is necessary or is predicted to become necessary within a predetermined time based on a minimum distance between the first and second computationally based features.
20. The method of claim 15, wherein a first one of the observed features is a recognized physical object in the workspace and the signal causes display of a representation of the object with a color overlay indicating its type.
21. The method of claim 15, wherein a first one of the observed features is a recognized workpiece and the signal causes display of a representation of the workpiece showing a deviation from an expected position thereof.
22. The method of claim 21, wherein a first one of the computationally generated features is a keep-out zone and the signal causes display of a representation of the keep-out zone in the workspace.
23. The method of claim 21, wherein a first one of the computationally generated features is a keep-in zone, the signal source causing display of a representation of the keep-in zone in the workspace.
24. The method of claim 21, wherein a first one of the computationally generated features is a cluster of voxels corresponding to a spatial region in the workspace that none of the sensors can observe, the signal causing display of the cluster of voxels in a representation of the workspace.
</claims>
</document>
