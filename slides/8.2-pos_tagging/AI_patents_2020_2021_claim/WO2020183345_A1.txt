<document>

<filing_date>
2020-03-09
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2019-03-08
</priority_date>

<ipc_classes>
G06Q10/08
</ipc_classes>

<assignee>
TESCAP
</assignee>

<inventors>
HADDON, Thomas Colin
PAUL, Clive
</inventors>

<docdb_family_id>
66380466
</docdb_family_id>

<title>
A MONITORING AND RECORDING SYSTEM
</title>

<abstract>
The present invention relates to a monitoring and recording system for monitoring street furniture or assets. There is a need to monitor, count and catalogue items of street furniture for accounting and maintenance purposes. An aim of the present invention is to provide a system that is able to in order to monitor the state of, record the location of and verify the status of items of street furniture in real time. The invention provides a system that is capable of being used in real time with existing monitoring systems and includes an asset register of items of street furniture derived from a vehicle mounted imager, typically comprising at least one camera and a LIDAR imager. These imagers obtain images of street furniture and generate street furniture digital identity data. A transmitter transmits digitised images, their associated GPS location data and the street furniture digital identity data to a database where the data is stored and from where data may be accessed for processing with GPS location data and labelled and stored.
</abstract>

<claims>
1. A monitoring and recording system for compiling an asset register of items of street furniture comprising: at least a first camera imager and a LIDAR imager, in use the imagers are vehicle mounted, the LIDAR imager derives point cloud image data corresponding to image data obtained from items of street furniture that are also imaged by the at least first camera imager; a global positioning system (GPS) provides GPS location data which is associated with each frame of image data; a memory stores digitised image data; and a transmitter transmits stored digitised image data files and associated GPS location data to at least one database, wherein a processor processes the point cloud image data and identifies cloud image points that are collinear with an imaged item of street furniture and the first camera imager to derive perspective data; and the processor operates in accordance with image recognition and pattern recognition software (MASK RCNN) to: process the perspective data of the imaged item of street furniture and to interpret the perspective data and the digitised image data, thereby to identify an item of street furniture; to provide labelled image data of the item of street furniture; and to combine the labelled image data with the GPS location data in order to produce a unique identifier for an item of street furniture at a specific GPS location.
2. A monitoring and recording system according to claim 1 wherein the point cloud image data is associated with the items of street furniture by performing a perspective shift to the digested point cloud image data.
3. A monitoring and recording system according to claim 1 wherein the transmitter transmits image data files and associated GPS location data via a wireless or hardwire connection.
4. A monitoring and recording system according to claim 1 wherein 360Â° stitching of digitised image data files from six separate camera imagers is performed by a processor operating in accordance with software instructions.
5. A monitoring and recording system according to claim 1 wherein the processor generates street furniture digital identity data from an operator defined name.
6. A system according to any preceding claim includes means for determining the distance of the imaged item of street furniture from a point on the vehicle using the perspective data.
7. A system according to claim 6 further includes at least one source of pulsed radiation, a detector arranged to receive a reflected radiation signal and a counter for determining from the source and the reflected signal the distance and bearing of the object of street furniture from the vehicle.
8. A system according to any preceding claim wherein a digital scanner scans historical image data and a comparator compares newly acquired image data in order to assess the status of an asset or if an asset is missing or damaged or faulty and to record the status, condition or presence of the item of street furniture.
9. A system according to any preceding claim includes a menu operable by an operator to provide a label for an item of street furniture.
10. A system according to claim 9 wherein an operator defined name includes a descriptor or word or code derived from an oral description provided by an automatic voice recognition system.
11. A system according to claim 10 wherein the operator defined name includes a digital image or other descriptor provided by the image identifier.
12. A system according to any of claims 9 to 11 wherein the menu is operable with a predictive text generator.
13. A system according to any preceding claim wherein the vehicle is an autonomous vehicle, such as a driverless vehicle or unmanned aerial vehicle (UAV) or a drone.
14. A system according to any of claims 7 to 13 wherein the means for determining the distance of the object from the vehicle includes a source of pulsed infra-red (IR) radiation, a detector arranged to receive a reflected signal and a counter for determining from the source and reflected signal a'time of flight' of a radiation.
15. A system to any preceding claim includes a facial recognition system.
16. A system to any preceding claim includes a means for post processing data and a neural network.
17. A system to any preceding claim includes a secure communication link that transmits data in an encrypted form to a remote location.
18. A system according to any preceding claim includes a reporting tool for generating a maintenance report or report for inspection of items of street furniture.
19. A method of using the system according to any preceding claim to compile an asset register of items of street furniture comprising the steps of: operating a vehicle mounted camera in order to derive a plurality of image frames; generating a continuous digital image of surroundings; associating the assets in the image with a location derived from a global position system (GPS); providing location data which is associated with each image frame; deriving from the images identity of items of street furniture and associating with each item of street furniture a unique identifier; and transmitting image frames, GPS data and the unique identifier as digital data to a remote database.
20. A method according claim 19 includes the steps of: enabling a user to access the data.
21. A method according to either claim 19 or 20 comprising the steps of: determining a distance of an object of street furniture from a point on the vehicle.
22. A method according to any of claims 19 to 21 comprising the steps of: employing a source of pulsed radiation and at least one receiver in order to determine the distance of the object of street furniture from the vehicle.
23. A method according to any of claims 19 to 22 comprising the steps of: scanning images and comparing one image with an earlier obtained image in order to determine if an asset is missing or damaged or faulty.
24. A method according to any of claims 19 to 23 comprising the steps of: enabling an operator to define a name by employing a voice recognition system.
25. A method according to any of claims 19 to 24 comprising the steps of: employing a neural network (CNN) to process image data so that frames of data are compared with a series of data derived from verified images.
26. A method according to claim 25 wherein the CNN determines if an object that cannot be readily identified is detected by matching the object with similar size objects in the tracking history using a series of histograms of previous detection events.
27. A method where according to claim 26 wherein the CNN finds an asset with a confidence score over a variable threshold set by either developer or customer and assigns details to the asset based on the information ascertained from the Al
28. A method according to claim 28 wherein a verification step of labelled image data is performed to check the location of the best match.
</claims>
</document>
