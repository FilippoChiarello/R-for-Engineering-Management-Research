<document>

<filing_date>
2018-09-28
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-28
</priority_date>

<ipc_classes>
G10L15/14,G10L15/16,G10L15/22,G10L15/30,G10L15/32
</ipc_classes>

<assignee>
SONOS
</assignee>

<inventors>
GIACOBELLO, DANIELE
HARTUNG, KLAUS
FAINBERG, JOACHIM
</inventors>

<docdb_family_id>
68165815
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR SELECTIVE WAKE WORD DETECTION USING NEURAL NETWORK MODELS
</title>

<abstract>
Systems and methods for media playback via a media playback system include capturing sound data via a network microphone device and identifying a candidate wake word in the sound data. Based on identification of the candidate wake word in the sound data, the system selects a first wake-word engine from a plurality of wake-word engines. Via the first wake-word engine, the system analyzes the sound data to detect a confirmed wake word, and, in response to detecting the confirmed wake word, transmits a voice utterance of the sound data to one or more remote computing devices associated with a voice assistant service.
</abstract>

<claims>
1. A method comprising: capturing sound data via a network microphone device; identifying, via the network microphone device, a candidate wake word in the sound data; based on identification of the candidate wake word in the sound data, selecting a first wake-word engine from a plurality of wake-word engines; with the first wake-word engine, analyzing the sound data to detect a confirmed wake word; and in response to detecting the confirmed wake word, transmitting a voice utterance of the sound data to one or more remote computing devices associated with a voice assistant service.
2. The method of claim 1, wherein identifying the candidate wake word comprises determining a probability that the candidate wake word is present in the sound data.
3. The method of claim 1, wherein the first wake-word engine is associated with the candidate wake word, and wherein another of the plurality of wake-word engines is associated with one or more additional wake words.
4. The method of claim 1, wherein identifying the candidate wake word comprises applying a neural network model to the sound data.
5. The method of claim 4, wherein the neural network model comprises a compressed neural network model.
6. The method of claim 1, further comprising, after transmitting the additional sound data, receiving, via the network microphone device, a selection of media content related to the additional sound data.
7. The method of claim 1, wherein the plurality of wake-word engines comprises: the first wake-word engine; and a second wake-word engine configured to perform a local function of the network microphone device.
8. A network microphone device, comprising: one or more processors; at least one microphone; and tangible, non-transitory, computer-readable media storing instructions executable by one or more processors to cause the network microphone device to perform operations comprising: capturing sound data via the network microphone device; identifying, via the network microphone device, a candidate wake word in the sound data; based on identification of the candidate wake word in the sound data, selecting a first wake-word engine from a plurality of wake-word engines; with the first wake-word engine, analyzing the sound data to detect a confirmed wake word; and in response to detecting the confirmed wake word, transmitting a voice utterance of the sound data to one or more remote computing devices associated with a voice assistant service.
9. The network microphone device of claim 8, wherein identifying the candidate wake word comprises determining a probability that the candidate wake word is present in the sound data.
10. The network microphone device of claim 8, wherein the first wake-word engine is associated with the candidate wake word, and wherein another of the plurality of wake-word engines is associated with one or more additional wake words.
11. The network microphone device of claim 8, wherein identifying the candidate wake word comprises applying a neural network model to the sound data.
12. The network microphone device of claim 11, wherein the neural network model comprises a compressed neural network model.
13. The network microphone device of claim 8, wherein the operations further comprise, after transmitting the additional sound data, receiving, via the network microphone device, a selection of media content related to the additional sound data.
14. The network microphone device of claim 8, wherein the plurality of wake-word engines comprises: the first wake-word engine; and a second wake-word engine configured to perform a local function of the network microphone device.
15. Tangible, non-transitory, computer-readable media storing instructions executable by one or more processors to cause a network microphone device to perform operations comprising: capturing sound data via the network microphone device; identifying, via the network microphone device, a candidate wake word in the sound data; based on identification of the candidate wake word in the sound data, selecting a first wake-word engine from a plurality of wake-word engines; with the first wake-word engine, analyzing the sound data to detect a confirmed wake word; and in response to detecting the confirmed wake word, transmitting a voice utterance of the sound data to one or more remote computing devices associated with a voice assistant service.
16. The tangible, non-transitory, computer-readable media of claim 15, wherein identifying the candidate wake word comprises determining a probability that the candidate wake word is present in the sound data.
17. The tangible, non-transitory, computer-readable media of claim 15, wherein the first wake-word engine is associated with the candidate wake word, and wherein another of the plurality of wake-word engines is associated with one or more additional wake words.
18. The tangible, non-transitory, computer-readable media of claim 15, wherein identifying the candidate wake word comprises applying a neural network model to the sound data.
19. The tangible, non-transitory, computer-readable media of claim 15, wherein the operations further comprise, after transmitting the additional sound data, receiving, via the network microphone device, a selection of media content related to the additional sound data.
20. The tangible, non-transitory, computer-readable media of claim 15, wherein the plurality of wake-word engines comprises: the first wake-word engine; and a second wake-word engine configured to perform a local function of the network microphone device.
</claims>
</document>
