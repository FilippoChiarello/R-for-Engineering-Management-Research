<document>

<filing_date>
2019-08-30
</filing_date>

<publication_date>
2020-11-24
</publication_date>

<priority_date>
2018-08-31
</priority_date>

<ipc_classes>
A61B5/00,A61B5/04,A61B5/0488,A61B5/11,A61B90/00,G06F3/01,G06K9/00,G06K9/62,G06N20/00,G06N5/04,G06T19/00,G06T7/70
</ipc_classes>

<assignee>
FACEBOOK TECHNOLOGY COMPANY
</assignee>

<inventors>
BERENZWEIG, ADAM
KAIFOSH, PATRICK
REARDON, THOMAS
JURMAN, BRETT
WETMORE, DANIEL
OSBORN, CHRISTOPHER
</inventors>

<docdb_family_id>
69639787
</docdb_family_id>

<title>
Camera-guided interpretation of neuromuscular signals
</title>

<abstract>
Computerized systems, methods, and computer-readable storage media storing code for implementing the methods are provided for training an inference model used to generate a musculoskeletal representation. One such system includes a processor programmed to: determine, based on information obtained from at least one image, position information describing a spatial relationship between two or more connected musculoskeletal segments of a user; determine, based on a plurality of neuromuscular signals, force information; associate the position information with the force information; train an inference model to output a musculoskeletal representation consistent with the position information and/or the force information when neuromuscular input signals provided to the inference model have at least one predetermined characteristic, to produce an updated inference model; and cause the updated inference model to be stored in a memory.
</abstract>

<claims>
1. A computerized system for training one or more inference models used to generate a musculoskeletal representation, the system comprising: one or more neuromuscular sensors configured to obtain one or more neuromuscular signals from a user, wherein the one or more neuromuscular sensors are arranged on one or more wearable devices; at least one camera configured to capture one or more images while the one or more neuromuscular signals are obtained; and at least one computer processor programmed to: determine image-based position information describing a spatial relationship between two or more connected musculoskeletal segments of the user based on the one or more images; determine neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments of the user based on the neuromuscular signals; associate the image-based position information with the neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments of the user; and train the one or more inference models to output the musculoskeletal representation based on the image-based position information and the neuromuscular-based position and/or force information when one or more additional neuromuscular signals obtained from the user have at least one predetermined characteristic.
2. The computerized system of claim 1, wherein the at least one computer processor provides as an output the musculoskeletal representation based on the image-based position information and the neuromuscular-based position and/or force information.
3. The computerized system of claim 1, wherein the one or more images comprise a series of time-sequenced images forming a video.
4. The computerized system of claim 1, wherein the musculoskeletal representation corresponds to any one or any combination of: a muscular activation state; a forearm or hand motion; a posture; a static gesture; a handstate; a pose; and a dynamic gesture.
5. The computerized system of claim 1, wherein the one or more images includes any one or any combination of: an image produced by visible light; an image produced by infrared light; an image produced by light of a predetermined range of wavelengths; and an image produced by light of two or more different predetermined ranges of wavelengths.
6. The computerized system of claim 1, wherein the at least one computer processor is programmed to: determine a first quality of the one or more neuromuscular signals and/or a second quality of the one or more images; and weight the one or more neuromuscular signals and/or the one or more images based on the first quality and/or the second quality, respectively.
7. The computerized system of claim 6, wherein the first quality of the one or more neuromuscular signals is determined by determining whether at least one of the one or more neuromuscular signals includes at least one signal artifact.
8. The computerized system of claim 6, wherein the second quality of the one or more images is determined by determining whether a hand of the user is fully included in a field of view of the at least one camera or whether the hand is fully occluded from the field of view of the at least one camera, or whether at least a portion of the hand of the user is occluded from the field of view of the at least one camera.
9. The computerized system of claim 6, wherein the at least one computer processor is further programmed to determine the first quality in response to a determination that the second quality is greater than a threshold value.
10. The computerized system of claim 1, wherein the at least one predetermined characteristic comprises any one or any combination of: a presence of an artifact of the one or more additional neuromuscular signals; a presence of a plurality of artifacts of the one or more additional neuromuscular signals; a relative position of a plurality of artifacts of the one or more additional neuromuscular signals; a range of amplitudes of the one or more additional neuromuscular signals; and a periodic frequency of artifacts of the one or more additional neuromuscular signals.
11. The computerized system of claim 1, further comprising at least one inertial measurement unit (IMU) sensor, wherein the at least one computer processor is further programmed to determine IMU-based position information based, at least in part, on IMU signals output from the at least one IMU sensor, and the least at least one computer processor is programmed to associate the IMU-based position information with the image-based position information and the neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments of the user.
12. The computerized system of claim 1, wherein: the one or more wearable devices includes at least one positional marker included thereon; and the image-based position information is determined based, at least in part, on the at least one positional marker captured in the one or more images.
13. A method of a computerized system for training one or more inference models used to generate a musculoskeletal representation, the method comprising: receiving, by at least one processor, one or more neuromuscular signals of a user, the one or more neuromuscular signals being obtained by one or more neuromuscular sensors arranged on one or more wearable devices worn by the user; receiving, by the at least one processor, one or more images captured by at least one camera while the one or more neuromuscular signals are obtained; determining, by the at least one processor based on information obtained from the one or more images, image-based position information describing a spatial relationship between two or more connected musculoskeletal segments of the user; determining, by the at least one processor based on the one or more neuromuscular signals, neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments; associating, by the at least one processor, the image-based position information with the neuromuscular-based position and/or force information; training, by the at least one processor, the one or more inference models to output the musculoskeletal representation based on the image-based position information and neuromuscular-based position and/or force information when one or more additional neuromuscular signals have at least one predetermined characteristic.
14. The method of claim 13, further comprising providing as output the musculoskeletal representation based on the image-based position information and the neuromuscular-based position and/or force information.
15. The method of claim 13, wherein the one or more images comprise a series of time-sequenced images forming a video.
16. The method of claim 13, wherein the musculoskeletal representation corresponds to any one or any combination of: a muscular activation state; a forearm or hand motion; a posture; a static gesture; a handstate; a still pose; and a dynamic gesture.
17. The method of claim 13, wherein the one or more images includes any one or any combination of: an image produced by visible light; an image produced by infrared light; an image produced by light of a predetermined range of wavelengths; and an image produced by light of two or more different predetermined ranges of wavelengths.
18. The method of claim 13, further comprising: determining, by the at least one processor, a first quality of the one or more neuromuscular signals and/or a second quality of the one or more images; and weighting, by the at least one processor, the one or more neuromuscular signals based on the first quality and/or weighting the one or more images based on the second quality, respectively.
19. The method of claim 18, wherein the first quality of the one or more neuromuscular signals is determined by determining whether at least one of the one or more neuromuscular signals includes at least one signal artifact.
20. The method of claim 18, wherein the second quality of the one or more images is determined by determining whether a hand of the user is fully included in a field of view of the at least one camera or whether the hand is fully occluded from the field of view of the at least one camera, or whether at least a portion of the hand of the user is occluded from the field of view of the at least one camera.
21. The method of claim 18, further comprising determining, by the at least one processor, the first quality in response to a determination that the second quality is greater than a threshold value.
22. The method of claim 13, wherein the at least one predetermined characteristic comprises any one or any combination of: a presence of an artifact of the one or more additional neuromuscular signals; a presence of a plurality of artifacts of the one or more additional neuromuscular signals; a relative position of a plurality of artifacts of the one or more additional neuromuscular signals; a range of amplitudes of the one or more additional neuromuscular signals; and a periodic frequency of artifacts of the one or more additional neuromuscular signals.
23. The method of claim 13, further comprising: receiving, by the at least one processor, inertial measurement unit (IMU) signals output from at least one IMU sensor; determining, by the at least one processor, IMU-based position information based, at least in part, on the IMU signals output from the at least one IMU sensor; and associating the IMU-based position information with the image-based position information and the neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments of the user.
24. The method of claim 13, wherein: the one or more wearable devices includes at least one positional marker included thereon; and the image-based position information is determined based, at least in part, on the at least one positional marker captured in the one or more images.
25. A non-transitory computer-readable storage medium storing code that, when executed by at least one computer, causes the at least one computer to perform a method for training one or more inference models used to generate a musculoskeletal representation, wherein the method comprises: receiving one or more neuromuscular signals of a user, the one or more neuromuscular signals being obtained by one or more neuromuscular sensors arranged on one or more wearable devices worn by the user; receiving one or more images captured by at least one camera while the one or more neuromuscular signals are obtained; determining, based on information obtained from the one or more images, image-based position information describing a spatial relationship between two or more connected musculoskeletal segments of the user; determining, based on the neuromuscular signals, neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments; associating the image-based position information with the neuromuscular-based position and/or force information; and training the one or more inference models to provide as output the musculoskeletal representation based on the image-based position information and the neuromuscular-based position information and/or force information when one or more additional neuromuscular signals have at least one predetermined characteristic.
26. The storage medium of claim 25, wherein the method further comprises providing the musculoskeletal representation as an output based on the image-based position information and the neuromuscular-based position information and/or force information.
27. The storage medium of claim 25, wherein the method further comprises: determining a first quality of the one or more neuromuscular signals and/or a second quality of the one or more images; and weighting the one or more neuromuscular signals based on the first quality and/or weighting the one or more images based on the second quality, respectively.
28. The storage medium of claim 27, wherein the method further comprises determining the first quality in response to a determination that the second quality is greater than a threshold value.
29. The storage medium of claim 25, wherein the at least one predetermined characteristic comprises any one or any combination of: a presence of an artifact of the one or more additional neuromuscular signals; a presence of a plurality of artifacts of the one or more additional neuromuscular signals; a relative position of a plurality of artifacts of the one or more additional neuromuscular signals; a range of amplitudes of the one or more additional neuromuscular signals; and a periodic frequency of artifacts of the one or more additional neuromuscular signals.
30. The storage medium of claim 25, wherein the method further comprises: receiving inertial measurement unit (IMU) signals output from at least one IMU sensor; determining IMU-based position information based, at least in part, on the IMU signals output from the at least one IMU sensor; and associating the IMU-based position information with the image-based position information and the neuromuscular-based position and/or force information for the two or more connected musculoskeletal segments of the user.
</claims>
</document>
