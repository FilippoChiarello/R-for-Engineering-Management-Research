<document>

<filing_date>
2019-11-07
</filing_date>

<publication_date>
2020-11-17
</publication_date>

<priority_date>
2018-11-07
</priority_date>

<ipc_classes>
G06K9/00,G10L17/00,H04L12/18,H04N7/15
</ipc_classes>

<assignee>
THETA LAKE
</assignee>

<inventors>
ANDERSON, JAMES E.
BRENNER, DEREK
CRESCI, ANTHONY
HÃœFFNER, SHARON
JAIN, ROHIT
REDMOND, DEVIN H.
SUTTON, RICHARD B.
</inventors>

<docdb_family_id>
70457941
</docdb_family_id>

<title>
Systems and methods for identifying participants in multimedia data streams
</title>

<abstract>
Methods of and systems for identifying a discrete participant among a plurality of participants in an audio/video communication (e.g., video content, digital video content, audio content, and audio-visual content) that include: receiving the audio/video communication; identifying from the audio/video communication content (e.g., using metadata from the broadcast content to identify each participant) multiple identification-related features for each participant; associating a first identification-related feature of a first participant to a second identification-related feature of the first participant; organizing the associated identification-related features of the first participant into a feature class(es); logically relating a first feature class to a second feature class; and attributing a grouping of logically-related feature classes to the discrete participant.
</abstract>

<claims>
What we claim is:
1. A method of identifying a discrete participant among a plurality of participants in an audio/video communication, the method comprising: receiving, by at least one processor, the audio/video communication; identifying from the audio/video communication content, by the processor, a plurality of identification-related features for each participant; associating, by the processor, a first identification-related feature of a first participant to a second identification-related feature of the first participant; organizing, by the processor, the associated identification-related features of the first participant into one of a plurality of feature classes, wherein the feature classes comprise a video metadata class, the video metadata class comprising a subclass selected from the groups consisting of: a frame scene subclass, a frame face subclass, a frame object subclass, a frame logo subclass, a frame display name subclass, a frame logo subclass, a frame contact information subclass, and a combination thereof; logically relating, by the processor, a first feature class to a second feature class; and attributing a grouping of logically-related feature classes to the discrete participant.
2. The method of claim 1, further comprising: associating, by the processor, a third identification-related feature of the first participant to at least one of the first identification-related feature of the first participant or the second identification-related feature of the first participant; and logically relating, by the processor, a third feature class to at least one of the first feature class or the second feature class.
3. The method of claim 1, wherein the audio/video communication is selected from the group comprising: video content, digital video content, audio content, and audio-visual content.
4. The method of claim 1, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant.
5. The method of claim 4, wherein using metadata comprises capturing metadata from at least one visual frame of the audio/video communication.
6. The method of claim 5, wherein the visual frame is selected from the group consisting of: a scene feature, an object feature, a text feature, a logo feature, a facial image feature, and a combination thereof.
7. The method of claim 4, wherein using metadata comprises capturing metadata from at least one audio stream of the audio/video communication.
8. The method of claim 7, wherein the audio stream is selected from the group consisting of: a voice feature, a spoken name feature, an audio transcript feature, and a combination thereof.
9. The method of claim 1, wherein the identification-related features are selected from the group comprising participant voices, screen names, or visual likenesses.
10. The method of claim 1, wherein the feature classes further comprise an audio metadata class, the audio metadata class further comprising a subclass selected from the groups consisting of: a voice audio subclass, a voice subclass, an audio transcript subclass, a spoken name subclass, and a combination thereof.
11. The method of claim 1, wherein the feature classes further comprise an application metadata class, the application metadata class further comprising a subclass selected from the groups consisting of: participant channel subclass, an account subclass, an email identification (ID) subclass, a chat identification (ID) subclass, a chat handle subclass, a network address subclass, and a combination thereof.
12. The method of claim 1, wherein organizing comprises relating the associated identification-related features as vertices in a graph based on a corresponding feature class.
13. The method of claim 12, wherein relating feature classes comprises: logically connecting a vertex of the first feature class to at least one of a vertex of the second feature class or a vertex of any additional feature class.
14. A system for identifying a discrete participant among a plurality of participants in an audio/video communication, the system comprising: one or more computer processors programmed to perform operations comprising: receiving the audio/video communication; identifying from the audio/video communication content a plurality of identification-related features for each participant; associating a first identification-related feature of a first participant to a second identification-related feature of the first participant; organizing the associated identification-related features of the first participant into one of a plurality of feature classes, wherein the feature classes comprise a video metadata class, the video metadata class comprising a subclass selected from the groups consisting of: a frame scene subclass, a frame face subclass, a frame object subclass, a frame logo subclass, a frame display name subclass, a frame logo subclass, a frame contact information subclass, and a combination thereof; logically relating a first feature class to a second feature class; and attributing a grouping of logically-related feature classes to the discrete participant.
15. The system of claim 14, wherein the one or more computer processors are further programmed to perform operations comprising: associating a third identification-related feature of the first participant to at least one of the first or the second identification-related feature of the first participant; and logically relating a third feature class to at least one of the first feature class or the second feature class.
16. The system of claim 14, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one visual frame of the audio/video communication.
17. The system of claim 16, wherein the visual frame is selected from the group consisting of: a scene feature, an object feature, a text feature, a logo feature, a facial image feature, and a combination thereof.
18. The system of claim 14, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one audio stream of the audio/video communication.
19. A method of identifying a discrete participant among a plurality of participants in an audio/video communication, the method comprising: receiving, by at least one processor, the audio/video communication; identifying from the audio/video communication content, by the processor, a plurality of identification-related features for each participant; associating, by the processor, a first identification-related feature of a first participant to a second identification-related feature of the first participant; organizing, by the processor, the associated identification-related features of the first participant into one of a plurality of feature classes, wherein the feature classes comprise an audio metadata class, the audio metadata class comprising a subclass selected from the groups consisting of: a voice audio subclass, a voice subclass, an audio transcript subclass, a spoken name subclass, and a combination thereof; logically relating, by the processor, a first feature class to a second feature class; and attributing a grouping of logically-related feature classes to the discrete participant.
20. The method of claim 19, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one visual frame of the audio/video communication.
21. The method of claim 20, wherein the visual frame is selected from the group consisting of: a scene feature, an object feature, a text feature, a logo feature, a facial image feature, and a combination thereof.
22. The method of claim 19, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one audio stream of the audio/video communication.
23. A system for identifying a discrete participant among a plurality of participants in an audio/video communication, the system comprising: one or more computer processors programmed to perform operations comprising: receiving the audio/video communication; identifying from the audio/video communication content a plurality of identification-related features for each participant; associating a first identification-related feature of a first participant to a second identification-related feature of the first participant; organizing the associated identification-related features of the first participant into one of a plurality of feature classes, wherein the feature classes comprise an audio metadata class, the audio metadata class comprising a subclass selected from the groups consisting of: a voice audio subclass, a voice subclass, an audio transcript subclass, a spoken name subclass, and a combination thereof; logically relating a first feature class to a second feature class; and attributing a grouping of logically-related feature classes to the discrete participant.
24. The system of claim 23, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one visual frame of the audio/video communication.
25. The system of claim 24, wherein the visual frame is selected from the group consisting of: a scene feature, an object feature, a text feature, a logo feature, a facial image feature, and a combination thereof.
26. The system of claim 23, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one audio stream of the audio/video communication.
27. A method of identifying a discrete participant among a plurality of participants in an audio/video communication, the method comprising: receiving, by at least one processor, the audio/video communication; identifying from the audio/video communication content, by the processor, a plurality of identification-related features for each participant; associating, by the processor, a first identification-related feature of a first participant to a second identification-related feature of the first participant; organizing, by the processor, the associated identification-related features of the first participant into one of a plurality of feature classes, wherein the feature classes comprise an application metadata class, the application metadata class comprising a subclass selected from the groups consisting of: participant channel subclass, an account subclass, an email identification (ID) subclass, a chat identification (ID) subclass, a chat handle subclass, a network address subclass, and a combination thereof; logically relating, by the processor, a first feature class to a second feature class; and attributing a grouping of logically-related feature classes to the discrete participant.
28. The method of claim 27, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one visual frame of the audio/video communication.
29. The method of claim 28, wherein the visual frame is selected from the group consisting of: a scene feature, an object feature, a text feature, a logo feature, a facial image feature, and a combination thereof.
30. The method of claim 27, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one audio stream of the audio/video communication.
31. A system for identifying a discrete participant among a plurality of participants in an audio/video communication, the system comprising: one or more computer processors programmed to perform operations comprising: receiving the audio/video communication; identifying from the audio/video communication content a plurality of identification-related features for each participant; associating a first identification-related feature of a first participant to a second identification-related feature of the first participant; organizing the associated identification-related features of the first participant into one of a plurality of feature, wherein the feature classes comprise an application metadata class, the application metadata class comprising a subclass selected from the groups consisting of: participant channel subclass, an account subclass, an email identification (ID) subclass, a chat identification (ID) subclass, a chat handle subclass, a network address subclass, and a combination thereof; logically relating a first feature class to a second feature class; and attributing a grouping of logically-related feature classes to the discrete participant.
32. The system of claim 31, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one visual frame of the audio/video communication.
33. The system of claim 32, wherein the visual frame is selected from the group consisting of: a scene feature, an object feature, a text feature, a logo feature, a facial image feature, and a combination thereof.
34. The system of claim 31, wherein identifying the plurality of identification-related features comprises using metadata from the audio/video communication to identify each participant, and wherein using metadata comprises capturing metadata from at least one audio stream of the audio/video communication.
</claims>
</document>
