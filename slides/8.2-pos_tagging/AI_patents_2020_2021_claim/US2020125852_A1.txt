<document>

<filing_date>
2019-11-12
</filing_date>

<publication_date>
2020-04-23
</publication_date>

<priority_date>
2017-05-15
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06K9/62,G06N3/04,G06N3/08,G06T7/269
</ipc_classes>

<assignee>
DEEPMIND TECHNOLOGIES
</assignee>

<inventors>
ZISSERMAN, ANDREW
CARREIRA, JOAO
</inventors>

<docdb_family_id>
62684734
</docdb_family_id>

<title>
Action recognition in videos using 3D spatio-temporal convolutional neural networks
</title>

<abstract>
Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing video data. An example system receives video data and generates optical flow data. An image sequence from the video data is provided to a first 3D spatio-temporal convolutional neural network to process the image data in at least three space-time dimensions and to provide a first convolutional neural network output. A corresponding sequence of optical flow image frames is provided to a second 3D spatio-temporal convolutional neural network to process the optical flow data in at least three space-time dimensions and to provide a second convolutional neural network output. The first and second convolutional neural network outputs are combined to provide a system output.
</abstract>

<claims>
1. A neural network system for processing video data, the neural network system comprising: a first data input to receive image data from a first sequence of frames of video data; a second data input to receive optical flow data from a second sequence of frames of the video data; a first 3D spatio-temporal convolutional neural network, coupled to the first data input and configured to process the image data in at least three space-time dimensions and to provide a first convolutional neural network output; a second 3D spatio-temporal convolutional neural network, coupled to the second data input and configured to process the optical flow data in at least three space-time dimensions and to provide a second convolutional neural network output; and a data combiner to combine data from the first and second convolutional neural network outputs to provide a combined processed video data output.
2. A neural network system as claimed in claim 1 wherein one or both of the first 3D spatio-temporal convolutional neural network and the second 3D spatio-temporal convolutional neural network has a modular sub-structure comprising successive sub-modules, wherein each said sub-module comprises a set of convolutional layers and at least one dimension-reduction layer to reduce a feature map-dimension of convolutional filters in an underlying layer.
3. A neural network system as claimed in claim 1 wherein one or both of the first 3D spatio-temporal convolutional neural network and the second 3D spatio-temporal convolutional neural network has a modular sub-structure comprising successive sub-modules, wherein each said sub-module comprises a set of convolutional layers and at least one parallel data path circumventing the set of convolutional layers.
4. A neural network system as claimed in claim 1 wherein one or both of the first 3D spatio-temporal convolutional neural network and the second 3D spatio-temporal convolutional neural network include 3D convolutional layers and 3D pooling layers each having kernels with at least 3D k×i×j receptive fields in which i and j label spatial dimensions and k labels a temporal dimension and in which i=j=k.
5. A neural network system as claimed in claim 1 wherein one or both of the first 3D spatio-temporal convolutional neural network and the second 3D spatio-temporal convolutional neural network include 3D pooling layers which pool only space dimensions of the space-time dimensions.
6. A neural network system as claimed in claim 1 wherein one or both of the first 3D spatio-temporal convolutional neural network and the second 3D spatio-temporal convolutional neural network comprises: at least two sub-modules each having at least two series-connected 3D convolutional layers, wherein the at least two series-connected 3D convolutional layers are connected in parallel with one another, a 3D pooling layer before a sub-module output, and at least one dimension-reducing layer between a sub-module input and the sub-module output.
7. A neural network system as claimed in claim 1 further comprising an optical flow determination system coupled between the first data input and the second data input to generate the optical flow data for the second data input from the video data.
8. A neural network system as claimed in claim 1 wherein the optical flow data comprises at least two optical flow channels and wherein the second 3D spatio-temporal convolutional neural network has at least two corresponding input channels.
9. A neural network system as claimed in claim 1 wherein the image data comprises color image data represented by at least two image data channels and wherein the first 3D spatio-temporal convolutional neural network has at least two corresponding input channels.
10. A neural network system as claimed in claim 1 wherein the data combiner is configured to average data from the first and second convolutional neural network outputs.
11. A neural network system as claimed in claim 1 wherein the combined processed video data output comprises a classification data output to provide classification data indicating a classification of motion within the video data.
12. A neural network system as claimed in claim 1 wherein one or both of the 3D spatio-temporal convolutional neural networks has an inflated 2D architecture.
13. A method of providing a neural network system, the method comprising: identifying a 2D neural network architecture for 2D image processing, wherein the 2D neural network architecture comprises a succession of convolutional layers and pooling layers each defined by a respective 2D kernel; inflating the 2D neural network architecture by adding a temporal dimension to the 2D kernels to convert the kernels to 3D kernels operating over space and time dimensions to provide an inflated neural network architecture; and training the inflated neural network architecture on video data to produce a trained neural network.
14. A method as claimed in claim 13 further comprising re-using weight parameters from a trained version of the 2D neural network architecture to pre-train the inflated neural network architecture prior to the training.
15. A method as claimed in claim 14 wherein the pre-training comprises repeating a scaled version of the weight parameters in a time dimension in the inflated neural network architecture.
16. A method as claimed in claim 13 wherein the training comprises two stages, a first training stage on a first data set and a second training stage on a second, different data set.
17. A method of processing video data, the method comprising: receiving image data from a first sequence of frames of video data; receiving optical flow data from a second sequence of frames of the video data; processing the image data using a first 3D spatio-temporal convolutional neural network configured to process the image data in at least three space-time dimensions and to provide a first convolutional neural network output; processing the optical flow data using a second 3D spatio-temporal convolutional neural network configured to process the optical flow data in at least three space-time dimensions and to provide a second convolutional neural network output; and combining data from the first and second convolutional neural network outputs to provide a combined processed video data output.
18. The method of claim 17 wherein one or both of the first 3D spatio-temporal convolutional neural network and the second 3D spatio-temporal convolutional neural network has a modular sub-structure comprising successive sub-modules, wherein each said sub-module comprises a set of convolutional layers and at least one dimension-reduction layer to reduce a feature map-dimension of convolutional filters in an underlying layer.
19. The method of claim 17 wherein one or both of the first 3D spatio-temporal convolutional neural network and the second 3D spatio-temporal convolutional neural network has a modular sub-structure comprising successive sub-modules, wherein each said sub-module comprises a set of convolutional layers and at least one parallel data path circumventing the set of convolutional layers.
20. The method of claim 17 wherein one or both of the first 3D spatio-temporal convolutional neural network and the second 3D spatio-temporal convolutional neural network include 3D convolutional layers and 3D pooling layers each having kernels with at least 3D k×i×j receptive fields in which i and j label spatial dimensions and k labels a temporal dimension and in which i=j=k.
</claims>
</document>
