<document>

<filing_date>
2018-11-27
</filing_date>

<publication_date>
2020-09-08
</publication_date>

<priority_date>
2018-11-27
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06T15/04,G06T17/00,G06T19/20,G06T7/70,G11B27/036,H04N13/117,H04N13/156
</ipc_classes>

<assignee>
AT&T INTELLECTUAL PROPERTY I (AMERICAN TELEPHONE AND TELEGRAPH COMPANY INTELLECTUAL PROPERTY I)
</assignee>

<inventors>
GIBBON, DAVID CRAWFORD
LIU ZHU
SHAHRARAY, BEHZAD
ZAVESKY, ERIC
XU, TAN
</inventors>

<docdb_family_id>
70771031
</docdb_family_id>

<title>
Volumetric video-based augmentation with user-generated content
</title>

<abstract>
A processing system having at least one processor may obtain a two-dimensional source video, select a volumetric video associated with at least one feature of the source video from a library of volumetric videos, identify a first object in the source video, and determine a location of the first object within a space of the volumetric video. The processing system may further obtain a three-dimensional object model of the first object, texture map the first object to the three-dimensional object model of the first object to generate an enhanced three-dimensional object model of the first object, and modify the volumetric video to include the enhanced three-dimensional object model of the first object in the location of the first object within the space of the volumetric video.
</abstract>

<claims>
1. A method comprising: obtaining, by a processing system including at least one processor, a source video, wherein the source video is a two-dimensional video; selecting, by the processing system, a volumetric video associated with at least one feature of the source video from a library of volumetric videos; identifying, by the processing system, a first object in the source video; performing, by the processing system, a spatial alignment of the source video to the volumetric video, by detecting key points in both the source video and the volumetric video and calculating a plurality of vectors between the first object and the key points; determining, by the processing system, a location of the first object within a space of the volumetric video, wherein the location of the first object is determined in accordance with the spatial alignment; obtaining, by the processing system, a three-dimensional object model of the first object; texture mapping, by the processing system, the first object to the three-dimensional object model of the first object to generate an enhanced three-dimensional object model of the first object; and modifying, by the processing system, the volumetric video to include the enhanced three-dimensional object model of the first object in the location of the first object within the space of the volumetric video.
2. The method of claim 1, wherein the alignment further comprises a time alignment of the source video and the volumetric video.
3. The method of claim 1, wherein the obtaining the source video further comprises: obtaining, by the processing system, the at least one feature of the source video, wherein the at least one feature comprises at least one of: location information; time information; an event tag; or a keyword.
4. The method of claim 3, wherein the selecting comprises: determining, by the processing system, that the volumetric video matches the at least one feature of the source video.
5. The method of claim 3, wherein the selecting is in accordance with a ranked list of volumetric videos from the library of volumetric videos based upon a level of matching to the at least one feature of the source video.
6. The method of claim 1, further comprising: detecting, by the processing system, a second object in the source video, wherein the at least one feature of the source video comprises the second object.
7. The method of claim 6, wherein the selecting the volumetric video associated with the at least one feature of the source video comprises: detecting, by the processing system, the second object in the volumetric video.
8. The method of claim 1, further comprising: presenting, by the processing system via an endpoint device, the volumetric video that is modified.
9. The method of claim 1, further comprising: generating, by the processing system, an output video comprising a two dimensional traversal of the volumetric video that is modified.
10. The method of claim 9, wherein the output video is generated in accordance with a selection by a user of at least one viewing perspective within the space of the volumetric video.
11. The method of claim 9, further comprising: presenting, by the processing system via an endpoint device, the output video.
12. The method of claim 11, wherein the source video is obtained from the endpoint device.
13. The method of claim 1, wherein the at least one feature is specified by a user associated with the source video.
14. The method of claim 1, wherein the obtaining the three-dimensional object model of the first object is in accordance with a catalog of two-dimensional objects and three-dimensional object models that are matched to the two-dimensional objects.
15. The method of claim 14, wherein the obtaining the three-dimensional object model comprises: matching, by the processing system, the first object to one of the two-dimensional objects in the catalog; and obtaining, by the processing system from the catalog, the three-dimensional object model that is matched to the one two-dimensional object.
16. The method of claim 15, wherein the matching is in accordance with a machine learning-based image detection model.
17. The method of claim 1, wherein the modifying comprises changing voxel data of the volumetric video that corresponds to the first object so that the voxel data corresponds to the enhanced three-dimensional object model.
18. The method of claim 1, wherein the selecting is based on a matching of visual features in the source video to visual features in the volumetric video.
19. A non-transitory computer-readable medium storing instructions which, when executed by a processing system including at least one processor, cause the processing system to perform operations, the operations comprising: obtaining a source video, wherein the source video is a two-dimensional video; selecting a volumetric video associated with at least one feature of the source video from a library of volumetric videos; identifying, by the processing system, a first object in the source video; performing, by the processing system, a spatial alignment of the source video to the volumetric video, by detecting key points in both the source video and the volumetric video and calculating a plurality of vectors between the first object and the key points; determining, by the processing system, a location of the first object within a space of the volumetric video, wherein the location of the first object is determined in accordance with the spatial alignment; obtaining a three-dimensional object model of the first object; texture mapping the first object to the three-dimensional object model of the first object to generate an enhanced three-dimensional object model of the first object; and modifying the volumetric video to include the enhanced three-dimensional object model of the first object in the location of the first object within the space of the volumetric video.
20. A device comprising: a processing system including at least one processor; and a computer-readable medium storing instructions which, when executed by the processing system, cause the processing system to perform operations, the operations comprising: obtaining a source video, wherein the source video is a two-dimensional video; selecting a volumetric video associated with at least one feature of the source video from a library of volumetric videos; identifying, by the processing system, a first object in the source video; performing, by the processing system, a spatial alignment of the source video to the volumetric video, by detecting key points in both the source video and the volumetric video and calculating a plurality of vectors between the first object and the key points; determining, by the processing system, a location of the first object within a space of the volumetric video, wherein the location of the first object is determined in accordance with the spatial alignment; obtaining a three-dimensional object model of the first object; texture mapping the first object to the three-dimensional object model of the first object to generate an enhanced three-dimensional object model of the first object; and modifying the volumetric video to include the enhanced three-dimensional object model of the first object in the location of the first object within the space of the volumetric video.
</claims>
</document>
