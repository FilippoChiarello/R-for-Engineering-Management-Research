<document>

<filing_date>
2019-08-27
</filing_date>

<publication_date>
2020-02-06
</publication_date>

<priority_date>
2019-08-05
</priority_date>

<ipc_classes>
G06F3/01,G06K9/00,G06T19/00
</ipc_classes>

<assignee>
LG ELECTRONICS
</assignee>

<inventors>
LEE, JIWOONG
</inventors>

<docdb_family_id>
67763963
</docdb_family_id>

<title>
XR DEVICE AND METHOD FOR CONTROLLING THE SAME
</title>

<abstract>
An extended reality (XR) device and a method for controlling the same are disclosed. The XR device is applicable to 5G communication technology, robot technology, autonomous driving technology, and Artificial Intelligence (AI) technology. The XR device includes a transparent display, a sensing unit configured to sense a relative position and gaze direction of a user with respect to the transparent display, and a processor configured to recognize at least one real-world external object that is located in a forward direction of the transparent display and is visible to the user through the transparent display, based on the relative position and gaze direction of the user sensed by the sensing unit.
</abstract>

<claims>
1. An extended reality (XR) device comprising: a transparent display; a sensing unit configured to sense a relative position and gaze direction of a user with respect to the transparent display; and a processor configured to recognize at least one real-world external object that is located in a forward direction of the transparent display and is visible to the user through the transparent display, based on the relative position and gaze direction of the user sensed by the sensing unit.
2. The XR device according to claim 1, wherein the sensing unit includes: a first camera configured to receive a forward-view image including the external objects; and a second camera configured to receive an image of the user.
3. The XR device according to claim 2, wherein: the processor senses the relative position and gaze direction of the user about the transparent display through the user image; and the processor recognizes the external object located in the gaze direction of the user at the relative position of the user from among a plurality of external objects included in the forward-view image.
4. The XR device according to claim 1, wherein: the transparent display includes a touchscreen: the processor, when a specific point on the touchscreen is touched, recognizes the external object, based on the touched point, the relative position of the user, and the gaze direction of the user.
5. The XR device according to claim 4, wherein the processor recognizes the external object that is located at a specific point where the touched point at the relative position meets the gaze direction.
6. The XR device according to claim 1, wherein: the processor, when recognition failure of the external object has occurred, displays information notifying of the recognition failure on the transparent display.
7. The XR device according to claim 6, wherein the recognition failure notification information includes specific information that guides movement of the user's relative position to successfully recognize the external object.
8. The XR device according to claim 1, wherein: the sensing unit is configured to sense a relative position and gaze direction of a first user about the transparent display and a relative position and gaze direction of a second user about the transparent display; and the processor is configured to: recognize a first real-world external object visible to the first user through the transparent display based on the relative position and gaze direction of the first user, and recognize a second real-world external object visible to the second user through the transparent display based on the relative position and gaze direction of the second user, divide a display region of the transparent display into a first region and a second region, display first information related to the first external object in the divided first region and display second information related to the second external object in the divided second region.
9. The XR device according to claim 1, wherein: the processor acquires augmented reality (AR) information about the recognized external object, and displays the acquired AR information around the recognized external object.
10. The XR device according to claim 9, wherein: when size change of the external object visible through the transparent display occurs in response to a change of the user's relative position about the transparent display, the processor changes a display format of the AR information to another format according to the size change.
11. The XR device according to claim 10, wherein: as the size of the external object is changed, the processor allows the display format of the AR information to be changed from a summarized display format to a gradually-detailed display format.
12. The XR device according to claim 3, wherein: the external objects include a product wearable by the user, the processor displays an image of the product and the user image on the transparent display in a manner that the user is able to control the user image to virtually wear the product.
13. The XR device according to claim 1, wherein: the external object includes an Internet of Things (IoT) device capable of communicating with the XR device in a home; and the processor displays a user interface (UI) for controlling the IoT device on the transparent display.
14. The XR device according to claim 1, wherein: the processor executes an application related to the external object from among a plurality of applications of the XR device.
15. The XR device according to claim 1, wherein: the external object includes a product; and the processor searches for shopping information related to the product on websites, and displays the searched shopping information on the transparent display.
16. A method for controlling an extended reality (XR) device provided with a transparent display, comprising: sensing, by a sensing unit, a relative position and gaze direction of a user with respect to the transparent display; and based on the relative position and gaze direction of the user sensed by the sensing unit, recognizing at least one real-world external object that is located in a forward direction of the transparent display and is visible to the user through the transparent display.
17. The method according to claim 16, wherein the sensing unit includes: a first camera configured to receive a forward-view image including the external objects; and a second camera configured to receive an image of the user.
18. The method according to claim 17, wherein the recognizing the real-world external object includes: sensing the relative position and gaze direction of the user about the transparent display through the user image; and recognizing the external object located in the gaze direction of the user at the relative position of the user from among a plurality of external objects included in the forward-view image.
19. The method according to claim 16 wherein: the transparent display includes a touchscreen; the recognizing the external object includes: when a specific point on the touchscreen is touched, recognizing the external object, based on the touched point, the relative position of the user, and the gaze direction of the user.
20. The method according to claim 19, wherein the recognizing the external object includes: recognizing the external object that is located at a specific point where the touched point at the relative position meets the gaze direction.
</claims>
</document>
