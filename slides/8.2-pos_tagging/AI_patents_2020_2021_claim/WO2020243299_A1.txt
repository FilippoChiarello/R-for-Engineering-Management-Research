<document>

<filing_date>
2020-05-28
</filing_date>

<publication_date>
2020-12-03
</publication_date>

<priority_date>
2019-05-29
</priority_date>

<ipc_classes>
A61B5/0488,G09B19/04
</ipc_classes>

<assignee>
CORNELL UNIVERSITY
</assignee>

<inventors>
DUNHAM, SIMON
WANG FEI
RAMEAU, Ana√Øs
</inventors>

<docdb_family_id>
73553912
</docdb_family_id>

<title>
DEVICES, SYSTEMS, AND METHODS FOR PERSONAL SPEECH RECOGNITION AND REPLACEMENT
</title>

<abstract>
The present disclosure describes approaches to voice restoration using personal devices that detect surface electromyographic (sEMG) signals from articulatory muscles for the recognition of silent speech in a patient (such as a patient with total laryngectomy, on voice rest, etc.). A personal device may comprise a cutaneous sensor unit and a control module that wirelessly transmits signals to a computing device capable of, for example, applying a predictive model to signals to generate text or synthesize speech. Methods and systems for training and applying predictive models, and fabricating personal devices, are disclosed.
</abstract>

<claims>
What is claimed is:
1. A system for recognizing speech by detecting surface electromyographic (sEMG) signals from a face and/or a neck of a subject, the system including a personal device comprising:
a cutaneous sensor unit comprising a set of electrodes configured to detect sEMG signals from a corresponding set of articulatory muscles during silent utterances by the subject; and
a control module coupled to the electrodes via a corresponding set of electrical pathways, the control module comprising:
a signal acquisition circuit for acquiring, via corresponding electrical pathways, sEMG signals detected by the electrodes; and
a wireless communication circuit configured to transmit data corresponding to the signals acquired via the signal acquisition circuit to a computing device for speech recognition.
2. The system of claim 1, wherein the personal device is configured to detect sEMG signals from a hemi-face of the subject.
3. The system of claim 1, wherein the cutaneous sensor unit includes a facial electrode tattoo comprising a membrane, the set of electrodes, and the set of electrical pathways.
4. The system of claim 1, wherein the cutaneous sensor unit comprises a polyurethane membrane with a thickness of no greater than about 300 microns.
5. The system of claim 1, wherein the electrical pathways comprise a metalized conducting film comprising polyethylene terephthalate (PET), polytetrafluoroethylene (PTFE), polyimides, and/or polyvinyl chloride (PVC).
6. The system of claim 1, wherein the personal device comprises a configurable array of redundant electrical pathways.
7. The system of claim 1, wherein the cutaneous sensor unit comprises a membrane configured to adhere to the face and/or neck of the subject.
8. The system of claim 1, wherein the signal acquisition circuit comprises an amplifier configured to amplify signals acquired from the electrodes.
9. The system of claim 1, wherein the personal device comprises at least six electrodes.
10. The system of claim 1, further comprising the computing device, wherein the computing device comprises a processor configured to receive data from the control module and generate predictions of words uttered by the subject.
11. The system of claim 10, wherein the processor of the computing device is configured to apply a predictive machine learning model to the data received from the control module, the predictive machine learning model trained using recordings corresponding to discrete words or phrases spoken by one or more subjects.
12. The system of claim 11, wherein the predictive model applies a cascaded machine learning model comprising global shape matching, local feature extraction, and classification.
13. The system of claim 11, wherein the predictive model uses one or more artificial neural networks.
14. A method for recognizing speech by a subject, the method comprising:
detecting, using a cutaneous sensor unit of a personal device, surface
electromyographic (sEMG) signals from articulatory muscles in a face and/or a neck of the subject during silent utterances by the subject, the cutaneous sensor unit comprising one or more electrodes positioned at each articulatory muscle, each electrode coupled to a control unit of the personal device via an electrical pathway;
applying, by a computing device, a predictive machine learning model to data based on the detected sEMG signals to generate predictions of words uttered by the subject, the predictive machine learning model trained using data collection recordings comprising discrete words or phrases spoken by one or more subjects; and
presenting, by the computing device, the predictions of words uttered by the subject as readable text on a display or as audible synthesized speech from an audio source.
15. The method of claim 14, wherein the electrodes and electrical pathways are embedded in a membrane that is adherable to a hemi-face of the subject.
16. The method of claim 14, further comprising positioning the personal device at a hemiface of the subject such that the electrodes make contact with the plurality of articulatory muscles at the hemi-face.
17. The method of claim 14, further comprising scanning the face of the subject to obtain facial geometry data, wherein the electrodes are positioned based on the facial geometry data.
18. A method for training a machine learning predictive model to predict words or phrases uttered by subjects during silent speech based on surface electromyographic (sEMG) signals, the method comprising:
detecting, using a cutaneous sensor unit of a personal device, sEMG signals from articulatory muscles in a hemi-face of a subject during silent utterances of a set of words or phrases, the cutaneous sensor unit comprising a set of electrodes positioned at articulatory muscles of the subject;
generating, via a computing device, a recording dataset comprising a plurality of words or phrases and, for each word or phrase, a set of signals corresponding to the set of electrodes of the cutaneous sensor unit;
identifying, via the computing device, differences between signals corresponding to the plurality of words or phrases and selecting distinct features of the words or phrases;
generating, via the computing device, a training dataset and a validation dataset from the recording dataset; and
selecting, via the computing device, based on the training dataset and the validation dataset, a classifier and training the predictive model to receive as inputs data based on sEMG signals detected during utterances by the subject and generate predicted words or phrases as outputs based on the classifier.
19. The method of claim 18, wherein the predictive model is a cascaded machine learning model comprising global shape matching, local feature extraction, and classification..
20. A method of manufacturing a personal device for detecting surface electromyographic (sEMG) signals from a face and/or a neck of a subject, the method comprising:
obtaining three-dimensional (3D) contour data acquired by scanning, using a 3D scanner, a face and/or a neck of a subject;
extracting, via a computing device, 3D geometry data from the contour data and identifying a set of positions corresponding to articulatory muscles of the subject;
generating, by the computing device, fabrication data for a membrane and a set of electrodes corresponding to the set of positions of the articulatory muscles, wherein generating the fabrication data comprises digitally flattening the contour data; and
fabricating the membrane and the set of electrodes using the fabrication data.
</claims>
</document>
