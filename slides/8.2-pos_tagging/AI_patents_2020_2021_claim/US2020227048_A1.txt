<document>

<filing_date>
2019-12-10
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2011-04-04
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06T7/00,G10L15/08,G10L15/20,G10L15/22,G10L15/28,G10L19/00,H04M1/725
</ipc_classes>

<assignee>
DIGIMARC CORPORATION
</assignee>

<inventors>
BAI YANG
RODRIGUEZ, TONY, F.
</inventors>

<docdb_family_id>
47914762
</docdb_family_id>

<title>
CONTEXT-BASED SMARTPHONE SENSOR LOGIC
</title>

<abstract>
Methods employ sensors in portable devices (e.g., smartphones) both to sense content information (e.g., audio and imagery) and context information. Device processing is desirably dependent on both. For example, some embodiments activate certain processor intensive operations (e.g., content recognition) based on classification of sensed content and context. The context can control the location where information produced from such operations is stored, or control an alert signal indicating, e.g., that sensed speech is being transcribed. Some arrangements post sensor data collected by one device to a cloud repository, for access and processing by other devices. Multiple devices can collaborate in collecting and processing data, to exploit advantages each may have (e.g., in location, processing ability, social network resources, etc.). A great many other features and arrangements are also detailed.
</abstract>

<claims>
1. 1-37. (canceled)
38. A portable user device comprising a processor, a memory and plural sensors, including at least a microphone or camera, the memory containing software instructions configuring the device to perform acts including: (a) applying a classification procedure to received audio and/or visual information, sensed by the microphone and/or camera, to determine a type of said information from among plural possible types; (b) determining a scenario type, based at least in part on one or more of time of day, day of week, location, calendar data, clock alarm status, motion sensor data, orientation sensor data, and information from a social networking service; and (c) based on a combination of (i) the determined type of the received audio and/or visual information, and (ii) the determined type of scenario, selecting a group of one or more recognition technologies from a set of available recognition technologies, and applying the selected group of one or more recognition technologies to the received audio and/or visual information; wherein configuration of said device by said software instructions enables the device to select and apply three or more different groups of recognition technologies to the received audio and/or visual information, in accordance with which of three or more different combinations of (i) information type, and (ii) scenario type, are respectively determined; configuration of said device by said software instructions enables the device to include two or more recognition technologies in one of said selected and applied groups of recognition technologies; and configuration of said device by said device instructions enables the device to include, in said two or more recognition technologies, at least one of a watermark-, fingerprint-, barcode-based, or optical character-recognition technology.
39. The device of claim 38, configured by the software instructions to apply said classification procedure to audio information.
40. The device of claim 38, configured by the software instructions to apply said classification procedure to visual information.
41. The device of claim 38, configured by the software instructions to determine a scenario type based at least on time of day.
42. The device of claim 38, configured by the software instructions to determine a scenario type based at least on day of week.
43. The device of claim 38, configured by the software instructions to determine a scenario type based at least on location.
44. The device of claim 38, configured by the software instructions to determine a scenario type based at least on calendar data.
45. The device of claim 38, configured by the software instructions to determine a scenario type based at least on clock alarm status.
46. The device of claim 38, configured by the software instructions to determine a scenario type based at least on motion sensor data.
47. The device of claim 38, configured by the software instructions to determine a scenario type based at least on orientation sensor data.
48. The device of claim 38, configured by the software instructions to determine a scenario type based at least on information from a social networking service.
49. The device of claim 38, in which configuration of said device by said software instructions enables the device to select and apply a group of one or more recognition technologies including a watermark recognition technology, based on said combination of the determined type of received audio and/or visual information, and the determined type of scenario.
50. The device of claim 38, in which configuration of said device by said software instructions enables the device to select and apply a group of one or more recognition technologies including a fingerprint recognition technology, based on said combination of the determined type of received audio and/or visual information, and the determined type of scenario.
51. The device of claim 38, in which configuration of said device by said software instructions enables the device to select and apply a group of one or more recognition technologies including a barcode-based recognition technology, based on said combination of the determined type of received audio and/or visual information, and the determined type of scenario.
52. The device of claim 38, in which configuration of said device by said software instructions enables the device to select and apply a group of one or more recognition technologies including an optical character recognition technology, based on said combination of the determined type of received audio and/or visual information, and the determined type of scenario.
53. A computer readable medium containing software instructions operative to configure a device, including a processor, memory and plural sensors, including at least a microphone or camera, to perform acts including: (a) applying a classification procedure to received audio and/or visual information, sensed by the microphone and/or camera, to determine a type of said information from among plural possible types; (b) determining a scenario type, based at least in part on one or more of time of day, day of week, location, calendar data, clock alarm status, motion sensor data, orientation sensor data, and information from a social networking service; and (c) based on a combination of (i) the determined type of the received audio and/or visual information, and (ii) the determined type of scenario, selecting a group of one or more recognition technologies from a set of available recognition technologies, and applying the selected group of one or more recognition technologies to the received audio and/or visual information; wherein: said software instructions enable a device configured thereby to select and apply three or more different groups of recognition technologies to the received audio and/or visual information, in accordance with which of three or more different combinations of (i) information type, and (ii) scenario type, are respectively determined; said software instructions enable a device configured thereby to include two or more recognition technologies in one of said selected and applied groups of recognition technologies; and said software instructions enable a device configured thereby to include, in said two or more recognition technologies, at least one of a watermark-, fingerprint-, barcode based-, or optical character-recognition technology.
</claims>
</document>
