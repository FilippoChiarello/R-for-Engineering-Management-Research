<document>

<filing_date>
2019-09-12
</filing_date>

<publication_date>
2020-03-19
</publication_date>

<priority_date>
2018-09-12
</priority_date>

<ipc_classes>
G06T7/33
</ipc_classes>

<assignee>
AUCKLAND UNISERVICES
</assignee>

<inventors>
VAGHEFI REZAEI, SEYED EHSAN
</inventors>

<docdb_family_id>
68296616
</docdb_family_id>

<title>
METHODS AND SYSTEMS FOR OCULAR IMAGING, DIAGNOSIS AND PROGNOSIS
</title>

<abstract>
Embodiments of the invention involve combining data representative of the eye obtained from multiple modalities into a virtual model of the eye. The multiple modalities indicate anatomical, physiological, and/or functional features of the eye. The data from different modalities is registered in order to combine the data into the virtual model. Further embodiments involve analysing eye data, for example in the form of the virtual model, using neural networks to obtain insights about medical conditions of the eye, for example the diagnosis or prognosis of conditions, and/or predicting how the eye will respond to certain treatments.
</abstract>

<claims>
1. A computer-implemented image processing method for generating data representative of a model of an eye, the method comprising:
receiving first eye image data representative of the eye, the first eye image data being obtained from a first imaging modality;
processing the first eye image data to generate first processed eye image data, wherein the first processed eye image data has identified therein one or more features of the eye;
receiving second eye image data representative of the eye, the second eye image data being obtained from a second imaging modality, wherein the second imaging modality is different from the first imaging modality;
processing the second eye image data to generate second processed eye image data, wherein the second processed eye image data has identified therein one or more features of the eye;
registering the first processed eye image data and the second processed eye image data; and
combining the registered first and second processed eye image data to generate data representative of a model of the eye.
2. A computer-implemented method as claimed in claim 1, wherein the first and second imaging modalities indicate features of the eye that are selected from the group consisting of: anatomical; physiological; and functional features.
3. A computer-implemented method as claimed in claim 1 or 2, wherein the first and second imaging modalities are selected from the group consisting of: magnetic resonance imaging (MRI); fundus photography; optical coherence tomography (OCT); optical coherence tomography angiography (OCTA); X-ray; computer tomography (CT); biometry; ultrasound; keratometry; corneal topography imaging; retinal perfusion mapping and laser speckle flowmetry.
4. A computer-implemented method as claimed in claim 2 or 3, wherein the first and second imaging modalities indicate features of the eye that are selected from different members of the group consisting of: anatomical; physiological; and functional features.
5. A computer-implemented method as claimed in claim 4, wherein:
the first imaging modality indicates anatomical features of the eye and is selected from the group consisting of: magnetic resonance imaging (MRI); fundus photography; optical coherence tomography (OCT); X-ray; computer tomography (CT); biometry; and ultrasound; and
the second imaging modality indicates physiological features of the eye and is selected from the group consisting of: magnetic resonance imaging (MRI); optical coherence tomography angiography (OCTA); and retinal perfusion mapping.
6. A computer-implemented method as claimed in claim 5, wherein the first imaging modality is fundus photography and the first eye image data is representative of anatomical features of the retina.
7. A computer-implemented method as claimed in claim 6, wherein processing the first eye image data to generate first processed eye image data comprises identifying blood vessels.
8. A computer-implemented method as claimed in any one of claims 5-7, wherein the second imaging modality is optical coherence tomography angiography (OCTA) and the second eye image data is representative of the blood flow in the retina.
9. A computer-implemented method as claimed in any one of claims 5-7, wherein the second imaging modality is magnetic resonance imaging (MRI).
10. A computer-implemented method as claimed in claim 5, wherein the first imaging modality is 3D magnetic resonance imaging (MRI) and the second imaging modality is 3D optical coherence tomography (OCT), optical coherence tomography angiography (OCTA) or laser speckle flowmetry.
11. A computer-implemented method as claimed in any one of claims 1-10, wherein the step of processing the first eye image data and/or the step of processing the second eye image data comprise(s) one or more of the following: identifying one or more features of the eye in the respective eye image data; enhancing clarity of one or more features of the eye in the respective eye image data; isolating image data representative of one or more features of the eye; and applying coordinate metadata to one or more features of the eye in the respective eye image data.
12. A computer-implemented method as claimed in any one of claims 1-11, wherein the step of registering the first processed eye image data and the second processed eye image data comprises registering the one or more features in the first processed eye image data and the respective one or more features in the second processed eye image data.
13. A computer-implemented method as claimed in any one of claims 1-12, wherein the one or more features in the first and second processed eye image data are any one or more features selected from the group consisting of: blood vessels; macula; fovea; optic disk; retina; eye boundary; vitreous humour; aqueous humour; ciliary muscles; and lens.
14. A computer-implemented method as claimed in any one of claims 1-13, wherein the first processed eye image data is representative of a first eye image and the second processed eye image data is representative of a second eye image, and wherein the step of registering the first processed eye image data and the second processed eye image data comprises manipulating the first processed eye image data and/or the second processed eye image data to achieve any one or more of: translational alignment of the first and second eye images; rotational alignment of the first and second eye images; common scaling of the first and second eye images; flattening data representative of a 3D image into data representative of a 2D image.
15. A computer-implemented method as claimed in any one of claims 1-14, wherein the method comprises: receiving third eye image data representative of the eye, the third eye image data being obtained from a third imaging modality, wherein the third imaging modality is different from the first and second imaging modalities;
processing the third eye image data to generate third processed eye image data, wherein the third processed eye image data has identified therein one or more features of the eye;
registering the third processed eye image data and the first and second processed eye image data; and
combining the registered first, second and third processed eye image data to generate data representative of the model of the eye.
16. A computer-implemented method as claimed in any one of claims 1-15, wherein the method further comprises outputting the data representative of the model of the eye.
17. A computer-implemented method as claimed in claim 16, wherein the step of
outputting the data representative of the model of the eye comprises displaying the model of the eye on a display device.
18. A computer-implemented method as claimed in any one of claims 1-17, wherein the first eye image data is representative of a 3D image of at least part of the eye and the second eye image data is representative of a 2D image of the eye.
19. A computer-implemented method for diagnosing disease in an eye, the method
comprising:
receiving first eye image data representative of the eye, the first eye image data being obtained from a first imaging modality;
receiving second eye image data representative of the eye, the second eye image data being obtained from a second imaging modality, wherein the second imaging modality is different from the first imaging modality;
analysing the first and second eye image data using an ensemble neural network to generate a diagnostic parameter for the eye, wherein the ensemble neural network comprises a first neural network to analyse the first eye image data and a second neural network to analyse the second eye image data, wherein the ensemble neural network comprises a fully connected layer receiving outputs from each of the first and second neural networks, the diagnostic parameter for the eye being output from the fully connected layer.
20. A computer-implemented method as claimed in claim 19, wherein the first and second imaging modalities indicate features of the eye that are selected from the group consisting of: anatomical; physiological; and functional features.
21. A computer-implemented method as claimed in claim 19 or 20, wherein the first and second imaging modalities are selected from the group consisting of: magnetic resonance imaging (MRI); fundus photography; optical coherence tomography (OCT); optical coherence tomography angiography (OCTA); X-ray; computer tomography (CT); biometry; ultrasound; keratometry; corneal topography imaging; retinal perfusion mapping and laser speckle flowmetry.
22. A computer-implemented method as claimed in claim 20 or 21, wherein the first and second imaging modalities indicate features of the eye that are selected from different members of the group consisting of: anatomical; physiological; and functional features.
23. A computer-implemented method as claimed in any one of claims 19-22, wherein the method comprises receiving the first eye image data and the second eye image data as a combined data set.
24. A computer-implemented method as claimed in claim 23, wherein the method
comprises receiving the first eye image data and the second eye image data in the form of data representative of a model of the eye.
25. A computer-implemented method as claimed in claim 24, wherein the data
representative of the model of the eye is generated using the method of any one of claims 1-18.
26. A computer-implemented method as claimed in any one of claims 19-25, wherein the method comprises weighting the outputs from each of the first and second neural networks in the fully connected layer.
27. A computer-implemented method as claimed in any one of claims 19-26, wherein the method comprises:
generating first and second feature maps using each of the first and second neural networks respectively;
generating first and second one dimensional arrays from each of the first and second feature maps respectively; and
combining the first and second one dimensional arrays in the fully connected layer with a weighting.
28. A computer-implemented method as claimed in any one of claims 19-27, wherein the method further comprises outputting the diagnostic parameter for the eye.
29. A computer-implemented method for prognosing disease in an eye, the method
comprising:
receiving present eye image data representative of the eye at a present time; analysing the present eye image data using a neural network to generate a prediction for future eye image data representative of the eye at a future time; and generating a prognostic parameter for the eye from the future eye image data, wherein the neural network is trained using past eye image data representative of a plurality of eyes at first and second past times to generate one or more eye image data change functions, wherein the eye image data change function is applied by the neural network to the present eye image data to generate the prediction for the future eye image data.
30. A computer-implemented method as claimed in claim 29, wherein the neural network is further trained using past eye image data representative of a plurality of eyes at a third past time to refine the eye image data change function.
31. A computer-implemented method as claimed in claim 29, wherein the past eye image data is first past eye image data and the present eye image data is first present eye image data, and the first past eye image data and the first present eye image data are obtained from a first imaging modality, and the method further comprises:
receiving second present eye image data representative of the eye at the present time, the second present eye image data being obtained from a second imaging modality, wherein the second imaging modality is different from the first imaging modality;
analysing the first and second present eye image data using the neural network to generate the prediction for future eye image data representative of the eye at the future time,
wherein the neural network is further trained using second past eye image data representative of the plurality of eyes at first and second past times in the second imaging modality to generate the eye image data change function.
32. A computer-implemented method as claimed in claim 31, wherein the first and second imaging modalities indicate features of the eye that are selected from the group consisting of: anatomical; physiological; and functional features.
33. A computer-implemented method as claimed in any one of claims 31-32, wherein the first and second imaging modalities are selected from the group consisting of: magnetic resonance imaging (MRI); fundus photography; optical coherence tomography (OCT); optical coherence tomography angiography (OCTA); X-ray; computer tomography (CT); biometry; ultrasound; keratometry; corneal topography imaging; retinal perfusion mapping and laser speckle flowmetry.
34. A computer-implemented method as claimed in any one of claims 32-33, wherein the first and second imaging modalities indicate features of the eye that are selected from different members of the group consisting of: anatomical; physiological; and functional features.
35. A computer-implemented method as claimed in any one of claims 29-34, wherein the eye image data change function comprises one or more matrices of change.
36. A computer-implemented method as claimed in any one of claims 29-35, wherein the neural network comprises a long short-term memory (LTSM) network.
37. A computer-implemented method as claimed in claim 36, wherein the neural network is an ensemble neural network comprising a first neural network to analyse past and/or present eye image data from the first imaging modality and a second neural network to analyse past and/or present eye image data from the second imaging modality, wherein the ensemble neural network comprises a fully connected layer receiving outputs from each of the first and second neural networks, the output of the fully connected layer being input to the long short-term memory (LTSM) network.
38. A computer-implemented method as claimed in any one of claims 31-37 when
dependent on claim 31, wherein the method comprises receiving the first past and/or present eye image data and the second past and/or present eye image data as a combined data set.
39. A computer-implemented method as claimed in claim 38, wherein the method
comprises receiving the first past and/or present eye image data and the second past and/or present eye image data in the form of data representative of a model of the eye.
40. A computer-implemented method as claimed in claim 39, wherein the data
representative of the model of the eye is generated using the method of any one of claims 1-18.
41. A computer-implemented method as claimed in any one of claims 29-40, wherein the neural network is trained using past eye treatment data representative of prior treatments undergone by the plurality of eyes, and the method comprises generating a treatment prediction parameter comprising the prognostic parameter for the eye on the assumption a treatment is used on the eye.
42. A computer-implemented method as claimed in any one of claims 29-41, wherein the method further comprises outputting the prognostic parameter for the eye.
43. A computer-implemented method for diagnosing disease in an eye, the method
comprising:
receiving an anisotropy ma p of retinal perfusion for the eye; and analysing the anisotropy map using a neural network to generate a diagnostic parameter for the eye.
44. A computer-implemented method as claimed in claim 43, wherein the method further comprises:
receiving a retinal perfusion map of retinal layers;
generating a flattened enface image of perfusion in the retinal layers;
determining perfusion in the flattened image using a pixel intensity threshold; determining the maximum pixel intensity in the un-flattened perfusion images in order to determine perfusion in a 3D image of the retinal layers; and
calculating the anisotropy map from the 3D image.
45. A computer-implemented method as claimed in claim 43 or 44, wherein the method further com prises calculating the anisotropy map using any one or more of the group consisting of: fractional anisotropy, relative anisotropy and volume ratio.
46. A computer-implemented method as claimed in any one of claims 43-45, wherein the method further comprises outputting the diagnostic parameter for the eye.
</claims>
</document>
