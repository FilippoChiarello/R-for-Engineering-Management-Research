<document>

<filing_date>
2019-05-13
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-13
</priority_date>

<ipc_classes>
G06Q10/06,G06Q10/10
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
RENNER, CHRISTOPH
BOTA, SILVIU
SCOTT-GREEN, Henry
</inventors>

<docdb_family_id>
66752177
</docdb_family_id>

<title>
METHODS, SYSTEMS, AND MEDIA FOR IDENTIFYING ABUSIVE CONTENT ITEMS
</title>

<abstract>
Methods, systems, and media for identifying abusive content items are provided. In some embodiments, the method comprises: receiving, at a server from a user device associated with a user, a request to provide user-generated content on a media content platform; in response to receiving the request, determining whether the user-generated content is to be reviewed by one or more reviewing users based on one or more bypass criterion; in response to determining that the user-generated content is to be reviewed based on the one or more bypass criterion, adding a review request to a queue of a reviewing user, wherein the review request includes the user-generated content and information associated with a user account corresponding to the user; and determining whether a decision responsive to the review request indicates that the user-generated content is to be provided on the media content platform, wherein: in response to determining that the decision indicates that the user-generated content item violates at least one policy associated with the media content platform, (i) a first message is transmitted to the user of the user device that indicates the at least one violated policy and a penalty to be administered to the user account corresponding to the user and (ii) a corresponding action is taken that inhibits the user-generated content from being provided on the media content platform; and in response to determining that the decision indicates that the user-generated content item does not violate the at least one policy associated with the media content platform, a second message is transmitted to the user of the user device that indicates that the user-generated content is eligible for providing on the media content platform.
</abstract>

<claims>
1. A method for identifying abusive content items, the method comprising:
receiving, at a server from a user device associated with a user, a request to provide user-generated content on a media content platform;
in response to receiving the request, determining whether the user-generated content is to be reviewed by one or more reviewing users based on one or more bypass criterion;
in response to determining that the user-generated content is to be reviewed based on the one or more bypass criterion, adding a review request to a queue of a reviewing user, wherein the review request includes the user-generated content and information associated with a user account corresponding to the user; and
determining whether a decision responsive to the review request indicates that the user-generated content is to be provided on the media content platform, wherein:
in response to determining that the decision indicates that the user generated content item violates at least one policy associated with the media content platform,
(i) a first message is transmitted to the user of the user device that indicates the at least one violated policy and a penalty to be administered to the user account corresponding to the user and (ii) a corresponding action is taken that inhibits the user-generated content from being provided on the media content platform; and
in response to determining that the decision indicates that the user generated content item does not violate the at least one policy associated with the media content platform, a second message is transmitted to the user of the user device that indicates that the user-generated content is eligible for providing on the media content platform.
2. The method of claim 1, wherein the user is a content creator and wherein the request to provide user-generated content includes an upload request to store the user-generated content on a storage device associated with the media content platform.
3. The method of claim 1, wherein the user is a content creator and wherein the request to provide user-generated content includes an initiation request to start a livestream using the media content platform.
4. The method of claim 1, wherein the user is a viewer and wherein the request to provide user-generated content includes a content feature that interacts with a content creator.
5. The method of claim 1, further comprising determining whether the user is eligible to provide the user-generated content on the media content platform by:
calculating a risk score that indicates a risk associated with the user account of the user based on other user-generated content that has been previously provided to the media content platform; and
comparing the risk score with a threshold risk score that corresponds to a content type of the of the user-generated content, wherein the user is deemed eligible to provide the user generated content based on the comparison of the risk score with the threshold risk score.
6. The method of claim 1, further comprising determining whether the user is eligible to provide the user-generated content on the media content platform based on audience information associated with the user account of the user.
7. The method of claim 1, further comprising determining whether the user is eligible to provide the user-generated content on the media content platform based on location information associated with the user account of the user.
8. The method of claim 1, further comprising determining whether the user is eligible to provide the user-generated content on the media content platform based on enforcement actions for previous policy violations that are associated with the user account.
9. The method of claim 1, further comprising determining whether the user is eligible to provide the user-generated content on the media content platform by transmitting a second review request to the queue of the reviewing user, wherein the second review request includes information associated with the user account corresponding to the user and prompts the reviewing user to determine whether the information associated with the user account violates at least one policy associated with the media content platform.
10. The method of claim 1, further comprising, in response to receiving the request to provide the user-generated content on the media content platform, causing a timing indication to be presented that indicates when the decision responsive to the review request is to be provided.
11. The method of claim 1, further comprising:
receiving a flag from a viewer of the user-generated content on the media content platform, wherein the flag indicates a potential policy violation; and
in response to receiving the subsequent review request, adding a subsequent review request to the queue of the reviewing user that previously reviewed the user-generated content, wherein the subsequent review request includes the user-generated content and the flag from the viewer and wherein the user-generated content is restricted from being provided on the media content platform until a decision responsive to the subsequent review request is received.
12. The method of claim 1, wherein determining whether the user-generated content is to be reviewed by one or more reviewing users based on one or more bypass criterion further comprises:
identifying second user-generated content that is similar to the user-generated content, wherein the second user-generated content has been previously reviewed; and
determining that the user-generated content is not to be reviewed by the one or more reviewing users based on a similarity of the user-generated content to the second user generated content.
13. The method of claim 12, further comprising:
determining that the second user-generated content was previously restricted from being made available on the media content platform; and
in response to determining that the second user-generated content was previously restricted from being made available on the media content platform, performing the
corresponding action that inhibits the user-generated content from being made available on the media content platform, wherein the first message indicates the restriction based on the second user-generated content.
14. The method of claim 1, wherein determining whether the user-generated content is to be reviewed by the one or more reviewing users further comprises determining whether at least one of the user-generated content and content related to the user-generated content has been previously flagged by a threshold number of viewers.
15. The method of claim 1, further comprising updating the user account associated with the user to indicate the at least one policy associated with the media content platform violated by the user-generated content.
16. The method of claim 1, wherein the penalty to be administered to the user account corresponding to the user is based on a number of previous policy violations by the content creator.
17. The method of claim 1, wherein the penalty to be administered to the user account corresponding to the user based on a severity of the at least one policy associated with the media content platform violated by the user-generated content.
18. The method of claim 1, further comprising:
receiving, from the user device, an appeal request of the decision, wherein the appeal request includes appeal text;
adding the appeal request that includes the appeal text and the user-generated content to the queue of a second reviewing user that is different from the reviewing user that provided the decision indicating that the user-generated content is to be restricted from being provided on the media content platform;
receiving, from a user device associated with the second reviewing user, an appeal decision corresponding to the appeal request; and
determining at least one corresponding action to be performed on the user generated content based on the decision and the appeal decision.
19. The method of claim 1, wherein, in response to determining that the decision indicates that the user-generated content item does not violate the at least one policy associated with the media content platform, the second message indicates a time that the user-generated content is automatically made available on the media content platform.
20. A system for identifying abusive content items, the system comprising:
a memory; and
a hardware processor that, when executing computer executable instructions stored in the memory, is configured to:
receive, from a user device associated with a user, a request to provide user-generated content on a media content platform;
in response to receiving the request, determine whether the user-generated content is to be reviewed by one or more reviewing users based on one or more bypass criterion;
in response to determining that the user-generated content is to be reviewed based on the one or more bypass criterion, add a review request to a queue of a reviewing user, wherein the review request includes the user-generated content and information associated with a user account corresponding to the user; and
determine whether a decision responsive to the review request indicates that the user-generated content is to be provided on the media content platform, wherein:
in response to determining that the decision indicates that the user generated content item violates at least one policy associated with the media content platform,
(i) a first message is transmitted to the user of the user device that indicates the at least one violated policy and a penalty to be administered to the user account corresponding to the user and (ii) a corresponding action is taken that inhibits the user-generated content from being provided on the media content platform; and
in response to determining that the decision indicates that the user generated content item does not violate the at least one policy associated with the media content platform, a second message is transmitted to the user of the user device that indicates that the user-generated content is eligible for providing on the media content platform.
21. A non-transitory computer-readable medium containing computer executable instructions that, when executed by a processor, cause the processor to perform a method for identifying abusive content items, the method comprising:
receiving, from a user device associated with a user, a request to provide user generated content on a media content platform;
in response to receiving the request, determining whether the user-generated content is to be reviewed by one or more reviewing users based on one or more bypass criterion;
in response to determining that the user-generated content is to be reviewed based on the one or more bypass criterion, adding a review request to a queue of a reviewing user, wherein the review request includes the user-generated content and information associated with a user account corresponding to the user; and
determining whether a decision responsive to the review request indicates that the user-generated content is to be provided on the media content platform, wherein:
in response to determining that the decision indicates that the user generated content item violates at least one policy associated with the media content platform,
(i) a first message is transmitted to the user of the user device that indicates the at least one violated policy and a penalty to be administered to the user account corresponding to the user and (ii) a corresponding action is taken that inhibits the user-generated content from being provided on the media content platform; and
in response to determining that the decision indicates that the user generated content item does not violate the at least one policy associated with the media content platform, a second message is transmitted to the user of the user device that indicates that the user-generated content is eligible for providing on the media content platform.
</claims>
</document>
