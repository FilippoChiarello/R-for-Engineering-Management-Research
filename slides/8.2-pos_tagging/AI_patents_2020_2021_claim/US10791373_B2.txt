<document>

<filing_date>
2017-12-29
</filing_date>

<publication_date>
2020-09-29
</publication_date>

<priority_date>
2017-12-29
</priority_date>

<ipc_classes>
G06T11/00,G06T3/40,H04N21/25,H04N21/2543,H04N21/258,H04N21/438,H04N21/44,H04N21/4728,H04N21/81,H04N5/232
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
BOYCE, JILL
CHOWDHURY, RAJNEESH
POORNACHANDRAN, RAJESH
VEERAMANI, KARTHIK
</inventors>

<docdb_family_id>
65231301
</docdb_family_id>

<title>
Generating 2D video from 360 video
</title>

<abstract>
A semiconductor package apparatus may include technology to aggregate region of interest information for omni-directional video content from two or more sources, select video information from the omni-directional video content based on the aggregated region of interest information, and generate one or more two-dimensional videos based on the selected video information. Other embodiments are disclosed and claimed.
</abstract>

<claims>
We claim:
1. An electronic processing system, comprising: a processor; memory communicatively coupled to the processor; and logic communicatively coupled to the processor to: gather point of interest information for omni-directional video content from two or more sources, group the gathered point of interest information into one or more clusters, select one or more candidate clusters from the one or more clusters, select video information from the omni-directional video content based on the selected candidate clusters, generate one or more two-dimensional videos based on the selected video information, provide one or more viewport clusters to a machine learning decision engine, select a frame centroid at the decision engine based on the one or more viewport clusters and user feedback, and generate a two-dimensional video from the omni-directional video content based on the selected frame centroid from the decision engine.
2. The system of claim 1, wherein the logic is further to: gather point of interest information from at least one content generator and at least one content consumer.
3. The system of claim 1, wherein the decision engine includes further logic to perform video analysis around a center of a candidate cluster, and process the cluster based on the video analysis to one or more of split the candidate into two different candidate frames, choose a different cluster center, pan from one frame to the next, and apply effects to smooth the transition between frames.
4. An electronic processing system, comprising: a processor; memory communicatively coupled to the processor; and logic communicatively coupled to the processor to: gather point of interest information for omni-directional video content from two or more sources; group the gathered point of interest information into one or more clusters; select one or more candidate clusters from the one or more clusters; select video information from the omni-directional video content based on the selected candidate clusters; generate one or more two-dimensional videos based on the selected video information; select multiple candidate clusters from the one or more clusters at a respective time points; fine tune one or more parameters of the selected multiple candidate clusters based on video analysis; queue each candidate frame of the selected multiple candidate clusters at the respective time points; and generate multiple versions of two-dimensional videos from the queued candidate frames for distribution to a content consumer.
5. The system of claim 4, wherein the logic is further to: receive a request for video content from the content consumer; determine if multiple versions of two-dimensional videos are available for the requested video content; select one version of the available multiple versions of the two-dimensional videos; and serve the selected version of the two-dimensional videos to the content consumer.
6. A semiconductor package apparatus, comprising: one or more substrates; and logic coupled to the one or more substrates, wherein the logic is at least partly implemented in one or more of configurable logic and fixed-functionality hardware logic, the logic coupled to the one or more substrates to: gather point of interest information for omni-directional video content from two or more sources, group the gathered point of interest information into one or more clusters, select one or more candidate clusters from the one or more clusters, select video information from the omni-directional video content based on the selected candidate clusters, generate one or more two-dimensional videos based on the selected video information, provide one or more viewport clusters to a machine learning decision engine, select a frame centroid at the decision engine based on the one or more viewport clusters and user feedback, and generate a two-dimensional video from the omni-directional video content based on the selected frame centroid from the decision engine.
7. The apparatus of claim 6, wherein the logic is further to: gather point of interest information from at least one content generator and at least one content consumer.
8. The apparatus of claim 6, wherein the decision engine includes further logic to perform video analysis around a center of a candidate cluster, and process the cluster based on the video analysis to one or more of split the candidate into two different candidate frames, choose a different cluster center, pan from one frame to the next, and apply effects to smooth the transition between frames.
9. A semiconductor package apparatus, comprising: one or more substrates; and logic coupled to the one or more substrates, wherein the logic is at least partly implemented in one or more of configurable logic and fixed-functionality hardware logic, the logic coupled to the one or more substrates to: gather point of interest information for omni-directional video content from two or more sources; group the gathered point of interest information into one or more clusters; select one or more candidate clusters from the one or more clusters; select video information from the omni-directional video content based on the selected candidate clusters; generate one or more two-dimensional videos based on the selected video information; select multiple candidate clusters from the one or more clusters at a respective time points; fine tune one or more parameters of the selected multiple candidate clusters based on video analysis; queue each candidate frame of the selected multiple candidate clusters at the respective time points; and generate multiple versions of two-dimensional videos from the queued candidate frames for distribution to a content consumer.
10. The apparatus of claim 9, wherein the logic is further to: receive a request for video content from the content consumer; determine if multiple versions of two-dimensional videos are available for the requested video content; select one version of the available multiple versions of the two-dimensional videos; and serve the selected version of the two-dimensional videos to the content consumer.
11. A method of generating video, comprising: gathering point of interest information for omni-directional video content from two or more sources; grouping the gathered point of interest information into one or more clusters; selecting one or more candidate clusters from the one or more clusters; selecting video information from the omni-directional video content based on the selected candidate clusters; generating one or more two-dimensional videos based on the selected video information; providing one or more viewport clusters to a machine learning decision engine; selecting a frame centroid at the decision engine based on the one or more viewport clusters and user feedback; and generating a two-dimensional video from the omni-directional video content based on the selected frame centroid from the decision engine.
12. The method of claim 11, further comprising: gathering point of interest information from at least one content generator and at least one content consumer.
13. The method of claim 11, further comprising: performing video analysis around a center of a candidate cluster; and processing the cluster based on the video analysis to one or more of split the candidate into two different candidate frames, choose a different cluster center, pan from one frame to the next, and apply effects to smooth the transition between frames.
14. A method of generating video, comprising: gathering point of interest information for omni-directional video content from two or more sources; grouping the gathered point of interest information into one or more clusters; selecting one or more candidate clusters from the one or more clusters; selecting video information from the omni-directional video content based on the selected candidate clusters; generating one or more two-dimensional videos based on the selected video information; selecting multiple candidate clusters from the one or more clusters at a respective time points; fine tuning one or more parameters of the selected multiple candidate clusters based on video analysis; queueing each candidate frame of the selected multiple candidate clusters at the respective time points; and generating multiple versions of two-dimensional videos from the queued candidate frames for distribution to a content consumer.
15. The method of claim 14, further comprising: receiving a request for video content from the content consumer; determining if multiple versions of two-dimensional videos are available for the requested video content; selecting one version of the available multiple versions of the two-dimensional videos; and serving the selected version of the two-dimensional videos to the content consumer.
16. At least one non-transitory computer readable medium, comprising a set of instructions, which when executed by a computing device, cause the computing device to: gather point of interest information for omni-directional video content from two or more sources; group the gathered point of interest information into one or more clusters; select one or more candidate clusters from the one or more clusters; select video information from the omni-directional video content based on the selected candidate clusters; generate one or more two-dimensional videos based on the selected video information; provide one or more viewport clusters to a machine learning decision engine; select a frame centroid at the decision engine based on the one or more viewport clusters and user feedback; and generate a two-dimensional video from the omni-directional video content based on the selected frame centroid from the decision engine.
17. The at least one non-transitory computer readable medium of claim 16, comprising a further set of instructions, which when executed by the computing device, cause the computing device to: gather point of interest information from at least one content generator and at least one content consumer.
18. The at least one non-transitory computer readable medium of claim 16, comprising a further set of instructions, which when executed by the computing device, cause the computing device to: perform video analysis around a center of a candidate cluster; and process the cluster based on the video analysis to one or more of split the candidate into two different candidate frames, choose a different cluster center, pan from one frame to the next, and apply effects to smooth the transition between frames.
19. At least one non-transitory computer readable medium, comprising a set of instructions, which when executed by a computing device, cause the computing device to: gather point of interest information for omni-directional video content from two or more sources; group the gathered point of interest information into one or more clusters; select one or more candidate clusters from the one or more clusters; select video information from the omni-directional video content based on the selected candidate clusters; generate one or more two-dimensional videos based on the selected video information; select multiple candidate clusters from the one or more clusters at a respective time points; fine tune one or more parameters of the selected multiple candidate clusters based on video analysis; queue each candidate frame of the selected multiple candidate clusters at the respective time points; and generate multiple versions of two-dimensional videos from the queued candidate frames for distribution to a content consumer.
20. The at least one non-transitory computer readable medium of claim 19, comprising a further set of instructions, which when executed by the computing device, cause the computing device to: receive a request for video content from the content consumer; determine if multiple versions of two-dimensional videos are available for the requested video content; select one version of the available multiple versions of the two-dimensional videos; and serve the selected version of the two-dimensional videos to the content consumer.
</claims>
</document>
