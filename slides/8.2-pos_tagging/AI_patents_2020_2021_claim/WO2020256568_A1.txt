<document>

<filing_date>
2020-06-21
</filing_date>

<publication_date>
2020-12-24
</publication_date>

<priority_date>
2019-06-21
</priority_date>

<ipc_classes>
A61B1/00,G06K9/00
</ipc_classes>

<assignee>
AUGERE MEDICAL AS
</assignee>

<inventors>
RIEGLER, Michael Alexander
NYGAARD ESPELAND, HÃ¥vard
</inventors>

<docdb_family_id>
71728853
</docdb_family_id>

<title>
METHOD FOR REAL-TIME DETECTION OF OBJECTS, STRUCTURES OR PATTERNS IN A VIDEO, AN ASSOCIATED SYSTEM AND AN ASSOCIATED COMPUTER READABLE MEDIUM
</title>

<abstract>
This application relates to a method (100, 120, 140, 160) and a system for the real-time detection of objects, structures and/or patterns in a video, such as the real-time detection of anatomical structures and/or anatomical landmarks in an endoscopic video of a subject, e.g. an endoscopic video of the gastrointestinal tract (Gl tract) of a subject.
</abstract>

<claims>
1. A method for real-time detection of one or more objects and/or one or more structures and/or one or more patterns in a video, the method comprising
a) receiving a sequence of frames of the video;
b) applying a sliding window to the sequence of frames and for each position of the sliding window extracting one or more visual features from said frames within the sliding window, thereby generating a plurality of time images;
c) applying a trained classifier to each time image, wherein the trained classifier determines one or more detection scores that indicate the likelihoods that the respective time image contains said one or more objects and/or one or more structures and/or one or more patterns; and
d) outputting in real-time the detection of said one or more objects and/or one or more structures and/or one or more patterns when the detection score is higher than a detection threshold of the trained classifier.
2. The method according to claim 1, wherein the video is an endoscopic video.
3. The method according to claim 2, wherein the one or more objects and/or one or more structures and/or one or more patterns are one or more anatomical structures and/or one or more anatomical landmarks.
4. The method of any of the preceding claims, wherein the size of the sliding window is fixed or dynamic.
5. The method of any of the preceding claims, wherein the sliding window is overlapping or non-overlapping.
6. The method of any of the preceding claims, wherein the sliding rate of the sliding window and frame rate of the input video are identical.
7. The method of any of the preceding claims, wherein the one or more visual features are extracted by employing algorithms for local feature extraction and/or global feature extraction and/or deep feature extraction.
8. The method of any of the preceding claims, wherein the visual features are deep features and such deep features are extracted through deep neural networks (DNN).
9. The method according to claim 8, wherein supervised methods are used for the DNN to extract such deep features.
10. The method according to claim 8, wherein unsupervised methods are used for the DNN to extract such deep features.
11. The method of any of the preceding claims, wherein the classifier is trained for multi-class classification.
12. The method of any of the preceding claims, wherein the classifier is a DNN or a capsule network adapted for analyzing images.
13. The method of any of the preceding claims, wherein the output is in the form of a detection signal, preferably a visual alert or an audio alert and/or in the form of data stored on a data storage unit.
14. The method of any of the preceding claims, wherein the output is in the form of a visual alert which is displayed on a monitor
15. The method according to claim 14, wherein the output is in the form of an overlay video, wherein the visual alert is overlaid over the video feed and the overlay video is displayed on a monitor.
16. The method of any of the preceding claims, further comprising one or more pre processing steps prior to step b). 17. The method according to claim 16, wherein said one or more pre-processing steps are selected from the group consisting of noise removal, removal of black borders, cropping, resizing, blurring the edges and removal of metadata.
18. The method according to any of claims 2 to 17, wherein the endoscopic video is of the gastrointestinal tract (GI tract).
19. The method according to claim 18, wherein the endoscopic video is a colonoscopic video.
20. The method according to claim 19, wherein the one or more anatomical structures are selected from the group consisting of healthy mucosa, stool, colonic fluid, blood vessels, inflamed mucosa, erosions, lesions and polyps.
21. The method according to claim 20, wherein the one or more anatomical structures are polyps.
22. A system for real-time detection of one or more objects and/or one or more structures and/or one or more patterns in a video, said system comprises (i) an input configured to receive a sequence of frames of a video, (ii) a processing system configured to access and process the sequence of frames and (iii) an output configured to output in real-time the detection of said one or more objects and/or one or more structures and/or one or more patterns, wherein the processing system is configured to process the sequence of frames with the steps comprising:
a) receiving a sequence of frames of the video;
b) applying a sliding window to the sequence of frames and for each position of the sliding window extracting one or more visual features from said frames within the sliding window, thereby generating a plurality of time images;
c) applying a trained classifier to each time image, wherein the trained classifier determines one or more detection scores that indicate the likelihoods that the respective time image contains said one or more objects and/or one or more structures and/or one or more patterns; and
d) outputting in real-time the detection of said one or more objects and/or one or more structures and/or one or more patterns when the detection score is higher than a detection threshold of the trained classifier.
23. The system according to claim 22, wherein the video is an endoscopic video.
24. The system according to claims 22 or 23, wherein the one or more objects and/or one or more structures and/or one or more patterns are one or more anatomical structures and/or one or more anatomical landmarks.
25. The system of any of the preceding claims 22 to 24, wherein the size of the sliding window is fixed or dynamic.
26. The system of any of the preceding claims 22 to 25, wherein the sliding window is overlapping or non-overlapping.
27. The system of any of the preceding claims 22 to 26, wherein the sliding rate of the sliding window and frame rate of the input video are identical.
28. The system of any of the preceding claims 22 to 27, wherein the one or more visual features are extracted by employing algorithms for local feature extraction and/or global feature extraction and/or deep feature extraction.
29. The system of any of the preceding claims 22 to 28, wherein the visual features are deep features and such deep features are extracted through deep neural networks (DNN).
30. The system according to claim 29, wherein supervised systems are used for the DNN to extract such deep features.
31. The system according to claim 29, wherein unsupervised systems are used for the DNN to extract such deep features.
32. The system of any of the preceding claims 22 to 31, wherein the classifier is trained for multi-class classification.
33. The system of any of the preceding claims 22 to 32, wherein the classifier is a DNN or a capsule network adapted for analyzing images.
34. The system of any of the preceding claims 22 to 33, wherein the output is in the form of a detection signal, preferably a visual alert or an audio alert and/or in the form of data stored on a data storage unit.
35. The system of any of the preceding claims 22 to 34, wherein the output is in the form of a visual alert which is displayed on a monitor
36. The system according to claim 35, wherein the output is in the form of an overlay video, wherein the visual alert is overlaid over the video feed and the overlay video is displayed on a monitor.
37. The system of any of the preceding claims 22 to 36, wherein the steps further comprise one or more pre-processing steps prior to step b).
38. The system according to claim 37, wherein said one or more pre-processing steps are selected from the group consisting of noise removal, removal of black borders, cropping, resizing, blurring the edges and removal of metadata.
39. The system according to any of claims 23 to 38, wherein the endoscopic video is of the gastrointestinal tract (GI tract).
40. The system according to claim 39, wherein the endoscopic video is a colonoscopic video. 41. The system according to claim 40, wherein the one or more anatomical structures are selected from the group consisting of healthy mucosa, stool, colonic fluid, blood vessels, inflamed mucosa, erosions, lesions and polyps.
42. The system according to claim 41, wherein the one or more anatomical structures are polyps.
43. The system according to any of the preceding claims 22 to 42, wherein the system further comprises graphics hardware comprising a video compositor configured to operate independently of the processing system ensuring that the video is displayed on a monitor in real-time, even if the system fails.
44. The system according to any of the preceding claims 22 to 43, comprising further one or more components of the group consisting of memory units, storage units, storage devices, graphics hardware, communication interfaces, display controllers, input devices, output devices and computer software.
45. The system according to claim 44, wherein the computer software is video overlay software.
46. A computer readable medium storing computer readable instructions for real-time detection of one or more objects and/or one or more structures and/or one or more patterns in a video, the computer program instructions, when executed by a processing system, perform operations comprising:
a) receiving a sequence of frames of the video;
b) applying a sliding window to the sequence of frames and for each position of the sliding window extracting one or more visual features from said frames within the sliding window, thereby generating a plurality of time images;
c) applying a trained classifier to each time image, wherein the trained classifier determines one or more detection scores that indicate the likelihoods that the respective time image contains said one or more objects and/or one or more structures and/or one or more patterns; and
d) outputting in real-time the detection of said one or more objects and/or one or more structures and/or one or more patterns when the detection score is higher than a detection threshold of the trained classifier.
47. The computer readable medium according to claim 46, wherein the video is an endoscopic video.
48. The computer readable medium according to claim 47, wherein the one or more objects and/or one or more structures and/or one or more patterns are one or more anatomical structures and/or one or more anatomical landmarks.
49. The computer readable medium of any of the preceding claims 46 to 48, wherein the size of the sliding window is fixed or dynamic.
50. The computer readable medium of any of the preceding claims 46 to 49, wherein the sliding window is overlapping or non-overlapping.
51. The computer readable medium of any of the preceding claims 46 to 50, wherein the sliding rate of the sliding window and frame rate of the input video are identical.
52. The computer readable medium of any of the preceding claims 46 to 51, wherein the one or more visual features are extracted by employing algorithms for local feature extraction and/or global feature extraction and/or deep feature extraction.
53. The computer readable medium of any of the preceding claims 46 to 52, wherein the visual features are deep features and such deep features are extracted through deep neural networks (DNN).
54. The computer readable medium according to claim 53, wherein supervised methods are used for the DNN to extract such deep features. 55. The computer readable medium according to claim 53, wherein unsupervised methods are used for the DNN to extract such deep features.
56. The computer readable medium of any of the preceding claims 46 to 55, wherein the classifier is trained for multi-class classification.
57. The computer readable medium of any of the preceding claims 46 to 56, wherein the classifier is a DNN or a capsule network adapted for analyzing images.
58. The computer readable medium of any of the preceding claims 46 to 57, wherein the output is in the form of a detection signal, preferably a visual alert or an audio alert and/or in the form of data stored on a data storage unit.
59. The computer readable medium of any of the preceding claims 46 to 58, wherein the output is in the form of a visual alert which is displayed on a monitor
60. The computer readable medium according to claim 59, wherein the output is in the form of an overlay video, wherein the visual alert is overlaid over the video feed and the overlay video is displayed on a monitor.
61. The computer readable medium of any of the preceding claims 46 to 60, wherein said operations further comprise one or more pre-processing steps prior to b).
62. The computer readable medium according to claim 61, wherein said one or more pre-processing steps are selected from the group consisting of noise removal, removal of black borders, cropping, resizing, blurring the edges and removal of metadata.
63. The computer readable medium according to any of claims 47 to 62, wherein the endoscopic video is of the gastrointestinal tract (GI tract).
64. The computer readable medium according to claim 63, wherein the endoscopic video is a colonoscopic video.
65. The computer readable medium according to claim 64, wherein the one or more anatomical structures are selected from the group consisting of healthy mucosa, stool, colonic fluid, blood vessels, inflamed mucosa, erosions, lesions and polyps.
66. The computer readable medium according to claim 65, wherein the one or more anatomical structures are polyps.
67. The computer readable medium according to any of the preceding claims 46 to 66, being a non-transitory computer readable medium or a transitory computer readable medium. 68. An endoscope system comprising a system as described in any of claims 23 to 45 and an endoscope connected to or in communication with the input of said system.
</claims>
</document>
