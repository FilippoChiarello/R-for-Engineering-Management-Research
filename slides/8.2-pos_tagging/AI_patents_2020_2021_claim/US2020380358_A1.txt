<document>

<filing_date>
2020-02-28
</filing_date>

<publication_date>
2020-12-03
</publication_date>

<priority_date>
2019-05-30
</priority_date>

<ipc_classes>
G06F16/23,G06F16/2457,G06N3/08
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
FAZLY, AFSANEH
DERPANIS, Konstantinos
KEMERTAS, Mete
PISHDAD, Leila
</inventors>

<docdb_family_id>
73550886
</docdb_family_id>

<title>
APPARATUS FOR DEEP REPRESENTATION LEARNING AND METHOD THEREOF
</title>

<abstract>
An apparatus for providing similar contents, using a neural network, includes a memory storing instructions, and a processor configured to execute the instructions to obtain a plurality of similarity values between a user query and a plurality of images, using a similarity neural network, obtain a rank of each the obtained plurality of similarity values, and provide, as a most similar image to the user query, at least one among the plurality of images that has a respective one among the plurality of similarity values that corresponds to a highest rank among the obtained rank of each of the plurality of similarity values. The similarity neural network is trained with a divergence neural network for outputting a divergence between a first distribution of first similarity values for positive pairs, among the plurality of similarity values, and a second distribution of second similarity values for negative pairs, among the plurality of similarity values.
</abstract>

<claims>
1. An apparatus for providing similar contents, using a neural network, the apparatus comprising: a memory storing instructions; and a processor configured to execute the instructions to: obtain a plurality of similarity values between a user query and a plurality of images, using a similarity neural network; obtain a rank of each the obtained plurality of similarity values; and provide, as a most similar image to the user query, at least one among the plurality of images that has a respective one among the plurality of similarity values that corresponds to a highest rank among the obtained rank of each of the plurality of similarity values, wherein the similarity neural network is trained with a divergence neural network for outputting a divergence between a first distribution of first similarity values for positive pairs, among the plurality of similarity values, and a second distribution of second similarity values for negative pairs, among the plurality of similarity values.
2. The apparatus of claim 1, wherein the similarity neural network is trained to maximize the divergence output by the divergence neural network.
3. The apparatus of claim 1, wherein the positive pairs are matching pairs among samples that are used to train the similarity neural network, and the negative pairs are non-matching pairs among the samples.
4. The apparatus of claim 1, wherein the similarity neural network is trained by obtaining a loss based on a loss function in which the divergence is input, and by updating parameters of the similarity neural network and the divergence neural network, based on the obtained loss.
5. The apparatus of claim 4, wherein the loss function comprises a first negative term of a lower bound on the divergence.
6. The apparatus of claim 5, wherein the loss function further comprises a second negative term that is obtained to maintain positive a derivative of a function that is represented by the divergence neural network.
7. The apparatus of claim 1, wherein the user query comprises a textual or spoken utterance of a user.
8. A method of providing similar contents, using a neural network, the method comprising: obtaining a plurality of similarity values between a user query and a plurality of images, using a similarity neural network; obtaining a rank of each the obtained plurality of similarity values; and providing, as a most similar image to the user query, at least one among the plurality of images that has a respective one among the plurality of similarity values that corresponds to a highest rank among the obtained rank of each of the plurality of similarity values, wherein the similarity neural network is trained with a divergence neural network for outputting a divergence between a first distribution of first similarity values for positive pairs, among the plurality of similarity values, and a second distribution of second similarity values for negative pairs, among the plurality of similarity values.
9. The method of claim 8, wherein the similarity neural network is trained to maximize the divergence output by the divergence neural network.
10. The method of claim 8, wherein the positive pairs are matching pairs among samples that are used to train the similarity neural network, and the negative pairs are non-matching pairs among the samples.
11. The method of claim 8, wherein the similarity neural network is trained by obtaining a loss based on a loss function in which the divergence is input, and by updating parameters of the similarity neural network and the divergence neural network, based on the obtained loss.
12. The method of claim 11, wherein the loss function comprises a first negative term of a lower bound on the divergence.
13. The method of claim 12, wherein the loss function further comprises a second negative term that is obtained to maintain positive a derivative of a function that is represented by the divergence neural network.
14. The method of claim 8, wherein the user query comprises a textual or spoken utterance of a user.
15. A non-transitory computer-readable storage medium storing instructions to cause a processor to: obtain a plurality of similarity values between a user query and a plurality of images, using a similarity neural network; obtain a rank of each the obtained plurality of similarity values; and provide, as a most similar image to the user query, at least one among the plurality of images that has a respective one among the plurality of similarity values that corresponds to a highest rank among the obtained rank of each of the plurality of similarity values, wherein the similarity neural network is trained with a divergence neural network for outputting a divergence between a first distribution of first similarity values for positive pairs, among the plurality of similarity values, and a second distribution of second similarity values for negative pairs, among the plurality of similarity values.
16. The non-transitory computer-readable storage medium of claim 15, wherein the similarity neural network is trained to maximize the divergence output by the divergence neural network.
17. The non-transitory computer-readable storage medium of claim 15, wherein the positive pairs are matching pairs among samples that are used to train the similarity neural network, and the negative pairs are non-matching pairs among the samples.
18. The non-transitory computer-readable storage medium of claim 15, wherein the similarity neural network is trained by obtaining a loss based on a loss function in which the divergence is input, and by updating parameters of the similarity neural network and the divergence neural network, based on the obtained loss.
19. The non-transitory computer-readable storage medium of claim 18, wherein the loss function comprises a first negative term of a lower bound on the divergence.
20. The non-transitory computer-readable storage medium of claim 19, wherein the loss function further comprises a second negative term that is obtained to maintain positive a derivative of a function that is represented by the divergence neural network.
</claims>
</document>
