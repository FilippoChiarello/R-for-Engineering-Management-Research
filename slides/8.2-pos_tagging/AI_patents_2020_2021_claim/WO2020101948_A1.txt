<document>

<filing_date>
2019-11-05
</filing_date>

<publication_date>
2020-05-22
</publication_date>

<priority_date>
2018-11-12
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
AMD (ADVANCED MICRO DEVICES)
</assignee>

<inventors>
DAS, SHOMIT N.
VISHNU, ABHINAV
</inventors>

<docdb_family_id>
70549918
</docdb_family_id>

<title>
DYNAMIC PRECISION SCALING AT EPOCH GRANULARITY IN NEURAL NETWORKS
</title>

<abstract>
A processor determines losses of samples within an input volume that is provided to a neural network during a first epoch, groups the samples into subsets based on losses, and assigns the subsets to operands in the neural network that represent the samples at different precisions. Each subset is associated with a different precision. The processor then processes the subsets in the neural network at the different precisions during the first epoch. In some cases, the samples in the subsets are used in a forward pass and a backward pass through the neural network. A memory configured to store information representing the samples in the subsets at the different precisions. In some cases, the processor stores information representing model parameters of the neural network in the memory at the different precisions of the subsets of the corresponding samples.
</abstract>

<claims>
1. A method comprising:
determining losses of samples within an input volume that is provided to a neural network during a first epoch;
grouping the samples into subsets based on the losses;
assigning the subsets to operands in the neural network that represent the samples at different precisions so that each subset is associated with a different precision; and
processing the subsets in the neural network at the different precisions during the first epoch. 2. The method of claim 1 , wherein assigning the subsets to the operands comprises assigning subsets having higher losses to operands having higher precisions.
3. The method of claim 1 or claim 2, wherein processing the subsets comprises determining sets of model parameters for the subsets during at least one of a forward pass and a backward pass through the neural network during the first epoch, wherein each set of model parameters for the subsets is represented at a different corresponding one of the different precisions.
4. The method of claim 3, wherein the sets of model parameters comprise at least one of connection weights for connections between nodes in the neural network, activations of neurons in the neural network, and gradients for steepest descent estimations.
5. The method of any preceding claim, further comprising:
modifying a number of the subsets during a second epoch that is subsequent to the first epoch; and
processing the modified number of the subsets in the neural network at the number of different precisions during the first epoch.
6. The method of claim 5, wherein modifying the number of the subsets comprises decreasing the number of the subsets during the second epoch, relative to the number of the subsets used during the first epoch. 7. The method of any preceding claim, further comprising:
modifying at least one of the different precisions during a second epoch that is subsequent to the first epoch.
8. The method of claim 7, wherein modifying the different precisions comprises decreasing the at least one of the different precisions during the second epoch, relative to the different precisions used during the first epoch.
9. The method of any preceding claim, further comprising:
determining a validation error based on a validation set in response to
completing the first epoch; and
setting the different precisions to a maximum precision for the subsets during a second epoch that is subsequent to the first epoch in response to the validation error increasing relative to a previously determined validation error.
10. An apparatus comprising:
a processor configured to:
determine losses of samples within an input volume that is provided to a neural network during a first epoch,
group the samples into subsets based on the losses,
assign the subsets to operands in the neural network that represent the samples at different precisions so that each subset is associated with a different precision, and
process the subsets in the neural network at the different precisions during the first epoch; and
a memory configured to store information representing the samples in the subsets at the different precisions.
1 1. The apparatus of claim 10, wherein the processor is configured to assign subsets having higher losses to operands having higher precisions.
12. The apparatus of claim 10 or claim 1 1 , wherein the processor is configured to determine sets of model parameters for the subsets during at least one of a forward pass and a backward pass through the neural network during the first epoch, wherein the sets of model parameters for the subsets are represented at the different precisions.
13. The apparatus of claim 12, wherein the sets of model parameters comprise at least one of connection weights for connections between nodes in the neural network, activations of neurons in the neural network, and gradients for steepest descent estimations.
14. The apparatus of claim 12 or claim 13, wherein the memory is configured to store the sets of model parameters at the different precisions associated with the subsets of the samples. 15. The apparatus of any preceding claim, wherein the processor is configured to modify a number of the subsets during a second epoch that is subsequent to the first epoch and process the modified number of the subsets in the neural network at the number of different precisions during the first epoch.
16. The apparatus of claim 15, wherein the processor is configured to decrease the number of the subsets during the second epoch, relative to the number of the subsets used during the first epoch.
17. The apparatus of any preceding claim, wherein the processor is configured to modify at least one of the different precisions during a second epoch that is subsequent to the first epoch. 18. The apparatus of claim 17, wherein the processor is configured to decrease the at least one of the different precisions during the second epoch, relative to the different precisions used during the first epoch.
19. The apparatus of any preceding claim, wherein the processor is configured to: determine a validation error based on a validation set in response to
completing the first epoch; and
set the different precisions to a maximum precision for the subsets during a second epoch that is subsequent to the first epoch in response to the validation error increasing relative to a previously determined validation error. 20. An apparatus comprising:
a memory; and
a processor configured to determine sets of model parameters for a neural network by providing samples in an input volume for a forward pass and a backward pass through the neural network during a first epoch, wherein the samples are represented at different precisions that are determined based on estimated losses for the samples in the input volume, and wherein the processor stores the sets of model parameters in the memory at the different precisions for corresponding samples.
</claims>
</document>
