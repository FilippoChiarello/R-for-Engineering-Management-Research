<document>

<filing_date>
2016-12-30
</filing_date>

<publication_date>
2020-06-16
</publication_date>

<priority_date>
2016-12-30
</priority_date>

<ipc_classes>
G06F16/248,G06F16/30,G06F16/58,G06F16/9535,G06F3/0482,G06N3/08,G06N7/00
</ipc_classes>

<assignee>
SHUTTERSTOCK
</assignee>

<inventors>
CHAVEZ, ALEXANDER KIKUTA
LI, GRACE MULAN
</inventors>

<docdb_family_id>
71075012
</docdb_family_id>

<title>
Style modification of images in search results
</title>

<abstract>
Methods for style modification of images in search results are provided. In one aspect, a method includes receiving user input identifying a search query from a client device, in which the search query indicates one or more predetermined search terms. The subject system determines a first collection of images that correspond to the one or more predetermined search terms and a second collection of images that exclude images that correspond to the one or more predetermined search terms. The subject system modifies images of the second collection to apply a keyword style that corresponds to the one or more predetermined search terms, and provides a listing of images to the client device. The listing of images includes both the first collection of images and the images of the second collection that are modified with the applied keyword style. Systems and machine-readable media are also provided.
</abstract>

<claims>
1. A computer-implemented method, comprising: receiving user input identifying a search query from a client device; identifying one or more predetermined search terms in the search query by determining search terms in the search query that match at least one search term in a set of predetermined search terms; identifying one or more standard search terms in the search query by determining search terms in the search query that do not match at least one search term in the set of predetermined search terms; accessing an image repository in a first search query, the first search query including the one or more standard search terms in the search query and the one or more predetermined search terms in the search query; based on the first search query, filtering through images in the image repository based on the one or more predetermined search terms in the search query; returning first images in a first collection of images from the filtered images, filtered based on the one or more predetermined search terms in the search query, that correspond to both the one or more standard search terms in the search query and the one or more predetermined search terms in the search query, the first collection of images including the returned first images; accessing the image repository in a second search query, the second search query including the one or more standard search terms in the search query and excluding the one or more predetermined search terms in the search query; based on the second search query, filtering through the images in the image repository based on the one or more standard search terms in the search query; returning second images in a second collection of images from the filtered images, filtered based on the one or more standard search terms in the search query, that correspond to the one or more standard search terms in the search query and are not associated with the one or more predetermined search terms in the search query, the second collection of images including the returned second images; determining a keyword style that corresponds to the one or more predetermined search terms in the search query; applying the keyword style to the images in the second collection of images that result in a visual modification of the images in the second collection of images; and providing a listing of images of the client device, the listing of images including the first collection of images and the images of the second collection of images that are modified with the applied keyword style.
2. The computer-implemented method of claim 1, wherein applying the keyword style to the images comprises encoding one or more pixels of an image with the keyword style for each image of the second collection of images.
3. The computer-implemented method of claim 1, further comprising: providing for display at least one image of the second collection of images in a first region of a user interface; obtaining a plurality of versions of the at least one image, each version of the plurality of versions of the at least one image corresponding to a different keyword style encoded into the at least one image; providing for display a listing of style-transferred images corresponding to the plurality of versions of the at least one image in a second region of the user interface; selecting one of the plurality of versions of the at least one image based on a user interaction with an style-transferred image from the listing of style-transferred images that corresponds to the selected one of the plurality of versions; determining a second keyword style that corresponds to the selected one of the plurality of versions; and applying the second keyword style to the displayed at least one image.
4. The computer-implemented method of claim 1, further comprising: selecting an image from the listing of images; providing for display the selected image in a first region of a user interface; obtaining a plurality of versions of the selected image, each version of the plurality of versions of the selected image corresponding to a different keyword style encoded into the selected image; providing for display a listing of style-transferred images corresponding to the plurality of versions of the selected image in a second region of the user interface; selecting one of the plurality of versions of the selected image based on a user interaction with an style-transferred image from the listing of style-transferred images that corresponds to the selected one of the plurality of versions; determining a second keyword style of the selected one of the plurality of versions; and applying the second keyword style to the displayed image.
5. The computer-implemented method of claim 1, wherein determining the second collection of images comprises: removing the one or more predetermined search terms from the search query to generate a new search query; and passing the new search query to an image search service for obtaining images that do not include style features that correspond to the one or more predetermined search terms.
6. The computer-implemented method of claim 1, further comprising: tagging each of the images of the second collection of images with metadata identifying the applied keyword style for the image.
7. The computer-implemented method of claim 1, wherein each image in the list of images includes the keyword style that corresponds to the one or more predetermined search terms, wherein each image of the second collection of images is encoded with the keyword style and each image of the first collection of images is not modified to include the keyword style.
8. The computer-implemented method of claim 1, further comprising: compiling a list of categories indicating categories that correspond to respective sets of style classes, each of the respective sets of style classes representing one of weather, time-of-day, and season; and compiling a list of terms for each category in the list of categories, the list of terms indicating terms that correspond to respective style classes for a corresponding set of style classes, wherein each of the one or more predetermined search terms corresponds to one of the terms of a compiled list of terms, and wherein the applied keyword style corresponds to one of the respective style classes of a corresponding set of style classes.
9. The computer-implemented method of claim 8, further comprising: training a computer-operated convolutional neural network to predict a probability distribution over the compiled list of terms for each category of the compiled list of categories using a first set of training images and a second set of training images, the first set of training images including images that correspond to the one or more predetermined search terms and the second set of training images excluding the images that correspond to the one or more predetermined search terms; and generating a computer-operated style transfer model configured to map an image to a modified version of itself utilizing an output of the trained convolutional neural network, wherein the images of the second collection are modified through the style transfer model.
10. The computer-implemented method of claim 9, wherein the computer-operated convolutional neural network processes the first set of training images and the second set of training images to learn to identify features relating to at least one of a plurality of style classes, and further comprising: generating feature vectors for each training image in the first set of training images and the second set of training images using the computer-operated convolutional neural network, wherein at least one of the feature vectors is associated with one of the one or more image identifiers.
11. The computer-implemented method of claim 10, further comprising: generating processed pixel data based on the feature vectors from the plurality of sets of training images; determining a probability for a style class of a set of style classes based on the processed pixel data, the determined probability indicating a likelihood that a subject image of the plurality of sets of training images corresponds to the style class; and providing an aggregate of style class probabilities in the probability distribution, the aggregate of style class probabilities including a style class probability for each style class in the set of style classes.
12. A system comprising: one or more processors; a computer-readable storage medium coupled to the one or more processors, the computer-readable storage medium including instructions that, when executed by the one or more processors, cause the one or more processors to: receive user input identifying a search query from a client device; identify one or more predetermined search terms in the search query by determining search terms in the search query that match at least one search term in a set of predetermined search terms; identify one or more standard search terms in the search query by determining search terms in the search query that do not match at least one search term in the set of predetermined search terms; access an image repository in a first search query, the first search query including the one or more standard search terms in the search query and the one or more predetermined search terms in the search query; based on the first search query, filter through images in the image repository based on the one or more predetermined search terms in the search query; return first images in a first collection of images from the filtered images, filtered based on the one or more predetermined search terms in the search query, that correspond to both the one or more standard search terms in the search query and the one or more predetermined search terms in the search query, the first collection of images including the returned first images; access the image repository in a second search query, the second search query including the one or more standard search terms in the search query and excluding the one or more predetermined search terms in the search query; based on the second search query, filter through the images in the image repository based on the one or more standard search terms in the search query; return second images in a second collection of images from the filtered images, filtered based on the one or more standard search terms in the search query, that correspond to the one or more standard search terms in the search query and are not associated with the one or more predetermined search terms in the search query, the second collection of images including the returned second images; determine a keyword style that corresponds to the one or more predetermined search terms in the search query; apply the keyword style to the images in the second collection of images that result in a visual modification of the images in the second collection of images; and provide a listing of images to the client device, the listing of images including the first collection of images and the images of the second collection of images that are modified with the applied keyword style.
13. The system of claim 12, wherein applying the keyword style to the images, comprises encoding one or more pixels of an image with the keyword style for each image of the second collection of images.
14. The system of claim 12, wherein the instructions further cause the one or more processors to: provide for display at least one image of the second collection of images in a first region of a user interface; obtain a plurality of versions of the at least one image, each version of the plurality of versions of the at least one image corresponding to a different keyword style encoded into the at least one image; provide for display a listing of style-transferred images corresponding to the plurality of versions of the at least one image in a second region of the user interface; select one of the plurality of versions of the at least one image based on a user interaction with an style-transferred image from the listing of style-transferred images that corresponds to the selected one of the plurality of versions; determine a second keyword style that corresponds to the selected one of the plurality of versions; and apply the second keyword style to the displayed at least one image; and modify the displayed at least one image to transfer a keyword style of the selected one of the plurality of versions to the displayed at least one image for processing.
15. The system of claim 12, wherein the instructions further cause the one or more processors to: compile a list of categories indicating categories that correspond to respective sets of style classes, each of the respective sets of style classes representing one of weather, time-of-day, and season; and compile a list of terms for each category in the list of categories, the list of terms indicating terms that correspond to respective style classes for a corresponding set of style classes, wherein each of the one or more predetermined search terms corresponds to one of the terms of a compiled list of terms, and wherein the applied keyword style corresponds to one of the respective style classes of a corresponding set of style classes.
16. The system of claim 15, wherein the instructions further cause the one or more processors to: train a computer-operated convolutional neural network to predict a probability distribution over the compiled list of terms for each category of the compiled list of categories using a first set of training images and a second set of training images, the first set of training images including images that correspond to the one or more predetermined search terms and the second set of training images excluding the images that correspond to the one or more predetermined search terms; and generate a computer-operated style transfer model configured to map an image to a modified version of itself utilizing an output of the trained convolutional neural network, wherein the images of the second collection are modified through the style transfer model.
17. The system of claim 16, wherein the computer-operated convolutional neural network processes the first set of training images and the second set of training images to learn to identify features relating to at least one of a plurality of style classes, wherein the instructions further cause the one or more processors to: generate feature vectors for each training image in the first set of training images and the second set of training images using the computer-operated convolutional neural network, wherein at least one of the feature vectors is associated with one of the one or more image identifiers.
18. The system of claim 17, wherein the instructions further cause the one or more processors to: generate processed pixel data based on the feature vectors from the plurality of sets of training images; determine a probability for a style class of a set of style classes based on the processed pixel data, the determined probability indicating a likelihood that a subject image of the plurality of sets of training images corresponds to the style class; and provide an aggregate of style class probabilities in the probability distribution, the aggregate of style class probabilities including a style class probability for each style class in the set of style classes.
19. A computer-implemented method, comprising: receiving user input via an application on a client device, the user input indicating a request to initiate an image search; generating, in response to the received user input, an image search query including one or more predetermined search terms from the user input; providing for transmission the image search query over a connection to a server, the server including an image search service configured to: identify one or more predetermined search terms in the search query by determining search terms in the search query that match at least one search term in a set of predetermined search terms; identify one or more standard search terms in the search query by determining search terms in the search query that do not match at least one search term in the set of predetermined search terms; access an image repository in a first search query, the first search query including the one or more standard search terms in the search query and the one or more predetermined search terms in the search query; based on the first search query, filter through images in the image repository based on the one or more predetermined search terms in the search query; return first images in a first collection of images from the filtered images, filtered based on the one or more predetermined search terms in the search query, that correspond to both the one or more standard search terms in the search query and the one or more predetermined search terms in the search query, the first collection of images including the returned first images; access the image repository in a second search query, the second search query including the one or more standard search terms in the search query and excluding the one or more predetermined search terms in the search query; based on the second search query, filter through the images in the image repository based on the one or more standard search terms in the search query; return second images in a second collection of images from the filtered images, filtered based on the one or more standard search terms in the search query, that correspond to the one or more standard search terms in the search query and are not associated with the one or more predetermined search terms in the search query, the second collection of images including the returned second images; determine a keyword style that corresponds to the one or more predetermined search terms in the search query; and apply the keyword style to the images in the second collection of images that result in a visual modification of the images in the second collection of images; receiving a listing of images over the connection in response to the image search query, the listing of images including the first collection of images and the images of the second collection of images that are modified with the applied keyword style; and providing for display the listing of images.
</claims>
</document>
