<document>

<filing_date>
2019-08-16
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2019-04-19
</priority_date>

<ipc_classes>
G06F8/41,G06F9/48,G06N3/04,G06N3/10
</ipc_classes>

<assignee>
EMC IP HOLDING COMPANY
</assignee>

<inventors>
LIU, JINPENG
WANG KUN
WU, PENGFEI
YING, ZHI
</inventors>

<docdb_family_id>
72832572
</docdb_family_id>

<title>
METHOD, DEVICE AND COMPUTER PROGRAM PRODUCT FOR PROCESSING MACHINE LEARNING MODEL
</title>

<abstract>
A method comprises obtaining an intermediate representation of a machine learning model written in a source language, the intermediate representation being independent of the source language and a target language and comprising a computation graph described by a structured text, a node in the computation graph representing a function associated with the machine learning model. The method comprises sending the intermediate representation to a scheduler to obtain indication information related to a plurality of dedicated processing resources for executing the machine learning model. The method further comprises generating a plurality of runtime libraries corresponding to the plurality of dedicated processing resources to process data related to the machine learning model based on the intermediate representation and the indication information, a runtime library comprising functions represented in the target language. General applicability of the compiler is increased, and assignment of the machine learning model on different dedicated processing resources is facilitated.
</abstract>

<claims>
1. A method of processing a machine learning model, comprising: obtaining an intermediate representation of a machine learning model written in a source language, the intermediate representation being independent of the source language and a target language and comprising a computation graph described by a structured text, a node in the computation graph representing a function associated with the machine learning model; sending the intermediate representation to a scheduler to obtain indication information related to a plurality of dedicated processing resources for executing the machine learning model; and generating a plurality of runtime libraries corresponding to the plurality of dedicated processing resources to process data related to the machine learning model based on the intermediate representation and the indication information, a runtime library comprising functions represented in the target language.
2. The method according to claim 1, wherein the indication information comprises information related to types of the plurality of dedicated processing resources, and wherein generating the plurality of runtime libraries corresponding to the plurality of dedicated processing resources comprises: determining the runtime library corresponding to the type of the dedicated processing resource based on the intermediate representation and the type of the dedicated processing resource.
3. The method according to claim 1, wherein the computation graph further comprises dependencies between the functions.
4. A computer program product being tangibly stored on a non-transient computer readable medium and comprising machine executable instructions which, when executed, causing a machine to perform steps of the method according to claim 1.
5. An electronic device for processing a machine learning model, comprising: a processor; and a memory storing computer program instructions, the processor running the computer program instructions in the memory to control the electronic device to perform acts, comprising: obtaining an intermediate representation of a machine learning model written in a source language, the intermediate representation being independent of the source language and a target language and comprising a computation graph described by a structured text, a node in the computation graph representing a function associated with the machine learning model; sending the intermediate representation to a scheduler to obtain indication information related to a plurality of dedicated processing resources for executing the machine learning model; and generating a plurality of runtime libraries corresponding to the plurality of dedicated processing resources to process data related to the machine learning model based on the intermediate representation and the indication information, a runtime library comprising functions represented in the target language.
6. The electronic device according to claim 5, wherein the indication information comprises information related to types of the plurality of dedicated processing resources, and wherein generating plurality of runtime libraries corresponding to the plurality of dedicated processing resources comprises: determining the runtime library corresponding to the type of the dedicated processing resource based on the intermediate representation and the type of the dedicated processing resource.
7. The electronic device according to claim 5, wherein the computation graph further comprises dependencies between the functions.
8. A method of executing a machine learning model, comprising: receiving, at a first device, data to be processed by the machine learning model; sending the received data to a first dedicated processing resource of the first device, so that the first dedicated processing resource processes the data by executing a first group of functions among a plurality of functions related to the machine learning model, the first group of functions being comprised in a first runtime library accessible to the first device; and sending the data which have been processed by the first dedicated processing resource to a second device for processing.
9. The method according to claim 8, wherein sending the received data to the first dedicated processing resource of the first device comprises: determining whether first indication information indicating completing the receiving of the data is received; and in response to determining that the first indication information is received, sending the received data to a first dedicated processing resource of the first device.
10. The method according to claim 8, wherein sending the received data to the first dedicated processing resource of the first device comprises: sending the received data to the first dedicated processing resource; and sending, to the first dedicated processing resource, second indication information related to the first group of functions, so that the first dedicated processing resource processes the data by executing the first group of functions.
11. The method according to claim 8, wherein receiving the data comprises: receiving the data from a third device, the data being determined by a second dedicated processing resource of the third device for executing a second group of functions among the plurality of functions, the second group of functions being comprised in a second runtime library accessible to the third device.
12. The method according to claim 8, wherein receiving the data comprises: allocating a storage resource for storing the data; and storing the received data in the storage resource.
13. The method according to claim 8, wherein sending the data which have been processed by the first dedicated processing resource to the second device for processing comprises: obtaining the processed data from the first dedicated processing resource; storing the processed data in the storage resource; sending the processed data to a second device; and in response to completing the sending of the processed data, sending, to the second device, second indication information indicating the completion.
14. A computer program product being tangibly stored on a non-transient computer readable medium and comprising machine executable instructions which, when executed, causing a machine to perform steps of the method according to claim 8.
15. An electronic device for executing a machine learning model, comprising: a processor; and a memory storing computer program instructions, the processor running the computer program instructions in the memory to control the electronic device to perform steps according to claim 8.
16. The electronic device according to claim 15, wherein sending the received data to the first dedicated processing resource of the first device comprises: determining whether first indication information indicating completing the receiving of the data is received; and in response to determining that the first indication information is received, sending the received data to a first dedicated processing resource of the first device.
17. The electronic device according to claim 15, wherein sending the received data to the first dedicated processing resource of the first device comprises: sending the received data to the first dedicated processing resource; and sending, to the first dedicated processing resource, second indication information related to the first group of functions, so that the first dedicated processing resource processes the data by executing the first group of functions.
18. The electronic device according to claim 15, wherein receiving the data comprises: receiving the data from a third device, the data being determined by a second dedicated processing resource of the third device for executing a second group of functions among the plurality of functions, the second group of functions being comprised in a second runtime library accessible to the third device.
19. The electronic device according to claim 15, wherein receiving the data comprises: allocating a storage resource for storing the data; and storing the received data in the storage resource.
20. The electronic device according to claim 15, wherein sending the data which have been processed by the first dedicated processing resource to the second device for processing comprises: obtaining the processed data from the first dedicated processing resource; storing the processed data in the storage resource; sending the processed data to a second device; and in response to completing the sending of the processed data, sending, to the second device, second indication information indicating the completion.
</claims>
</document>
