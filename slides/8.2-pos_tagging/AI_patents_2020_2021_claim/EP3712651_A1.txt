<document>

<filing_date>
2019-03-21
</filing_date>

<publication_date>
2020-09-23
</publication_date>

<priority_date>
2019-03-21
</priority_date>

<ipc_classes>
A61B8/08,G01S15/89,G01S7/52,G06N3/04,G06N3/063,G10K11/34
</ipc_classes>

<assignee>
PHILIPS ELECTRONICS
</assignee>

<inventors>
SCHMEITZ, HAROLD AGNES WILHELMUS
LUIJTEN, Ben
DE BRUIJN, Frederik Jan
VAN SLOUN, Ruud Johannes Gerardus
</inventors>

<docdb_family_id>
65904158
</docdb_family_id>

<title>
METHOD AND SYSTEM FOR ADAPTIVE BEAMFORMING OF ULTRASOUND SIGNALS
</title>

<abstract>
The invention relates to a method for adaptive beamforming of ultrasound signals, the method comprising the steps of a) Receiving time-aligned RF signals (45) acquired by multiple ultrasound transducer elements in response to an ultrasound transmission; b) Determining content-adaptive apodization weights for beamforming the time-aligned RF signals by applying a trained artificial neural network (16) to the time-aligned RF signals; and c) Applying (50) the content-adaptive apodization weights to the time-aligned RF signals to calculate (52) a beamformed output signal.The invention also relates to a method for training an artificial neural network (16) useful in adaptive beamforming of ultrasound signals, and a related computer program and system.
</abstract>

<claims>
1. A method for adaptive beamforming of ultrasound signals, the method comprising the steps of a) Receiving RF signals (18) acquired by multiple ultrasound transducer elements (4) in response to an ultrasound transmission; b) Determining content-adaptive apodization weights (12) for beamforming the RF signals (18) by applying a trained artificial neural network (16) to the RF signals.
2. The method of claim 1, wherein the number of input nodes (21) and the number of output nodes (34) of the trained artificial neural network (16) corresponds to the number of contributing RF signals.
3. The method of claim 1 or 2, comprising a further step of c) Applying the content-adaptive apodization weights (12) to the RF signals (18) to calculate a beamformed output signal.
4. The method of any one of the preceding claims, wherein the trained artificial neural network (16) comprises at least one activation layer (24, 28) including an activation function, which propagates both positive and negative input values with unbounded output values.
5. The method of any one of the preceding claims, wherein the neural network (16) comprises at least one activation layer (24, 28) including an activation function which concatenates the positive and the negative part of input values.
6. The method of any one of the preceding claims, wherein the artificial neural network (16) comprises at most four fully connected layers (20, 26, 32).
7. The method of any one of the preceding claims, wherein the artificial neural network (16) comprises at most three activation layers (24, 28).
8. The method of any one of the preceding claims, wherein the beamformed output signal is used to reconstruct an ultrasound image of a field-of-view, and wherein the RF signals (18) are rearranged (44) prior to applying the trained artificial neural network (16), so that the RF data relating to one or at most a few pixels (54) of the ultrasound image (51) are processed in one or more batches by the artificial neural network (16).
9. The method of any one of the preceding claims, wherein the artificial neural network (16) comprises at least one convolutional layer, in addition to or as an alternative to one or several fully-connected layer(s).
10. The method of any one of the preceding claims, wherein the artificial neural network (16) is part of a recurrent neural network.
11. The method of any one of the preceding claims, wherein some or all of the weights of the artificial neural network (16) are quantized, in particular quantized to 1 to 4 bits.
12. The method of one of the preceding claims, wherein the artificial neural network (16) comprises at least one hidden layer (28) having fewer nodes (27) than the input layer (20) and/or the output layer (36) of the artificial neural network (16).
13. A method for providing a trained artificial neural network (16) useful in content-adaptive beamforming of ultrasound signals, the method comprising: (a) Receiving input training data, namely RF signals (18) acquired by multiple ultrasound transducer elements (4) in response to an ultrasound transmission, (b) Receiving output training data, wherein the output training data are content-adaptive apodization weights (12), wherein such content-adaptive apodization weights have been calculated from the RF signals (18) by a content-adaptive beamforming algorithm (14), in particular a minimum variance algorithm; or wherein the output training data are beamformed output signals calculated from the RF signals by a content-adaptive beamforming algorithm (14); (c) training an artificial neural network (16) by using the input training data and the output training data; (d) providing the trained artificial neural network (16).
14. A computer program (110) comprising instruction, which, when the program is executed by a computational unit (104, 106), causes the computational unit to carry out the method of one of claim 1 to 13.
15. A system (102) for adaptive beamforming of ultrasound signals, the system comprising a) a first interface, configured for receiving RF signals (18) acquired by multiple ultrasound transducer elements (4) in response to an ultrasound transmission; b) a computational unit (104, 106) configured for - applying a trained artificial neural network (16) to the RF signals, whereby content-adaptive apodization weights (12) for beamforming the RF signals (18) are generated, and for - applying the content-adaptive apodization weights (12) to the RF signals to calculate a beamformed output signal; c) a second interface, configured for outputting the beamformed output signal.
</claims>
</document>
