<document>

<filing_date>
2018-04-02
</filing_date>

<publication_date>
2020-12-08
</publication_date>

<priority_date>
2018-04-02
</priority_date>

<ipc_classes>
G06F16/33,G06F16/332,G06N20/00,H04L12/58
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
GANGADHARAIAH, RASHMI
Elkan, Charles
Narayanaswamy, Balakrishnan
</inventors>

<docdb_family_id>
73653856
</docdb_family_id>

<title>
Task-oriented dialog systems utilizing combined supervised and reinforcement learning
</title>

<abstract>
Techniques for intelligent task-oriented multi-turn dialog system automation are described. A seq2seq ML model can be trained using a corpus of training data and a loss function that is based at least in part on a distance to a goal. The seq2seq ML model can be provided a user utterance as an input, and a vector of a plurality of values output by a plurality of hidden units of a decoder of the seq2seq ML model can be used to select one or more candidate responses to the user utterance via a nearest neighbor algorithm. In some embodiments, the specially adapted seq2seq ML model can be trained using unsupervised learning, and can be adapted to select intelligent, coherent agent responses that move a task-oriented dialog toward its completion.
</abstract>

<claims>
1. A computer-implemented method comprising: receiving a chat message provided by a user within a multi-turn chat dialog between the user and an agent; inputting at least the chat message or a representation of the chat message to a sequence-to-sequence (seq2seq) machine learning (ML) model, wherein the seq2seq ML model was retrained using a reward function that is based at least in part on a distance between a predicted response value and a goal value in a latent space, wherein the seq2seq ML model is at least partially based on an encoder-decoder architecture and comprises at least an encoder and at least a decoder, and wherein the goal value for each training sample used to train the seq2seq ML model is based at least in part on an output of the encoder and the decoder at a final turn of a training chat dialog that the training sample is from; obtaining a vector of a plurality of values generated by the seq2seq ML model, the plurality of values including a first embedding from a current turn of the chat dialog and a second embedding from a previous turn of the chat dialog; selecting one or more candidate responses to the chat message based on the obtained vector, the selecting comprising: performing a nearest neighbor search using the obtained vector to identify one or more other vectors, the one or more other vectors corresponding to one or more chat messages from one or more other chat dialogs; and selecting, as the one or more candidate responses, the one or more chat messages; and providing the one or more candidate responses to the user or the agent.
2. The computer-implemented method of claim 1, wherein providing the one or more candidate responses to the user or the agent comprises: transmitting the one or more candidate responses to an agent system to be presented to the agent via a graphical user interface (GUI).
3. The method of claim 1, wherein the first embedding comprises an output of the encoder of the current turn of the chat dialog, and wherein the second embedding comprises an output of the decoder from the previous turn of the chat dialog.
4. A computer-implemented method comprising: receiving a message from a user at an endpoint of a web-based service, wherein the message is part of a multi-turn chat dialog between the user and an agent; providing data based on the message to a machine learning (ML) model to generate a first embedding, the ML model comprising at least an encoder and a decoder, wherein the ML model was retrained using a loss function based at least in part on a distance between a predicted response value and a goal value in a latent space, wherein the goal value for each training sample used to train the ML model is based at least in part on an output of the encoder or an output of the decoder at a final turn of a training chat dialog that the training sample is from; selecting one or more responses to the message, the selecting comprising: obtaining a vector of a plurality of values including the first embedding and also a second embedding generated by the ML model during a previous turn of the chat dialog, identifying one or more other vectors based on a nearest neighbor search using the vector, and selecting, as the one or more responses, one or more chat messages corresponding to the identified one or more other vectors; and providing, by the web-based service, the one or more responses to the user or to an agent.
5. The computer-implemented method of claim 4, wherein the one or more responses are or are based on responses from one or more other chat dialogs.
6. The computer-implemented method of claim 4, wherein selecting the one or more chat messages comprises selecting a plurality of agent chat messages as the one or more responses.
7. The computer-implemented method of claim 4, wherein providing the one or more responses comprises: sending the one or more responses to an agent system to be presented via a graphical user interface (GUI) to the agent, wherein the one or more responses are selectable by the agent to indicate a response to be sent to an electronic device of the user that provided the message as part of the chat dialog.
8. The computer-implemented method of claim 7, wherein the selected one or more responses comprise a plurality of responses that are presented via the GUI to the agent, wherein the GUI allows the agent to select one of the plurality of responses to be provided to the user as a response to the message.
9. The computer-implemented method of claim 4, further comprising: causing one of the selected one or more responses to be sent to an electronic device of the user that provided the message.
10. The computer-implemented method of claim 4, wherein the ML model comprises an initial sequence to sequence (seq2seq) ML model that was re-trained to maximize a weighted sum of a negative cross entropy and a negative distance to a final goal.
11. The computer-implemented method of claim 4, wherein: the message is an alphanumeric message or an audio message; the message is a second or later message made by the user within the multi-turn chat dialog; and the one or more responses are selected based at least in part on two or more of the message, a previous message made by the user within the multi-turn dialog, or a previous response made by the agent in the multi-turn dialog.
12. The method of claim 4, wherein the first embedding comprises an output of the encoder of a current turn of the chat dialog, and wherein the second embedding comprises an output of the decoder from the previous turn of the chat dialog.
13. A system comprising: an agent system implemented by a first one or more electronic devices to engage in an agent-user chat dialog; and a chatbot system implemented by a second one or more electronic devices, the chatbot system including instructions that upon execution cause the chatbot system to: receive a representation of a chat message provided by a user as part of the agent-user chat dialog; generate a first embedding using at least the representation of the chat message and a machine learning (ML) model, wherein the ML model was retrained using a reward function that is based at least in part on a distance between a predicted response value and a goal value in a latent space, wherein the ML model comprises at least an encoder and at least a decoder, and wherein the goal value for each training sample used to train the ML model is based at least in part on an output of the encoder or an output of the decoder at a final turn of a training chat dialog that the training sample is from; and select one or more candidate responses to the chat message to be provided to the agent system as one or more recommendations for an agent response to the chat message within the agent-user chat dialog, wherein to select the one or more candidate responses the chatbot system is to: obtain a vector of a plurality of values including the first embedding and also a second embedding generated by the ML model during a previous turn of the chat dialog, identify one or more other vectors based on a nearest neighbor search using the vector, and select, as the one or more candidate responses, one or more chat messages corresponding to the identified one or more other vectors.
14. The system of claim 13, wherein the one or more candidate responses are from one or more other chat dialogs.
15. The system of claim 14, wherein the one or more other chat dialogs were used to train the ML model.
16. The system of claim 13, wherein the ML model comprises an initial ML model that was re-trained to maximize a weighted sum of a negative cross entropy and a negative distance to a goal.
17. The system of claim 13, wherein the reward function is further based on cross entropy.
18. The system of claim 13, wherein the first embedding comprises an output of the encoder of a current turn of the chat dialog, and wherein the second embedding comprises an output of the decoder from the previous turn of the chat dialog.
</claims>
</document>
