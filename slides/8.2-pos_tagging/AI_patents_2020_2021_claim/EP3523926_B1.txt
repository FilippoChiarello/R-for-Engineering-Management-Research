<document>

<filing_date>
2017-10-03
</filing_date>

<publication_date>
2020-07-29
</publication_date>

<priority_date>
2016-10-10
</priority_date>

<ipc_classes>
H04L12/28
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
ROBICHAUD, JEAN-PHILIPPE
</inventors>

<docdb_family_id>
60162258
</docdb_family_id>

<title>
DIGITAL ASSISTANT EXTENSION AUTOMATIC RANKING AND SELECTION
</title>

<abstract>
Representative embodiments disclose mechanisms to automatically rank and select extensions triggered in a digital assistant. A sample set of extensions are executed against a set of curated queries in order to extract a set of features and/or statistics. The system trains a machine learning model based on the features and/or statistics to rank and select extensions based on their response to a query. New extension incorporated into the system are executed against a second set of curated queries to obtain a set of extracted features and/or statistics which are saved for use at runtime. At runtime, a query phrase received by the system triggers one or more tasks from extensions. Extracted features for the triggered extensions are combined with stored features/statistics and at least a subset of the results presented to the trained ranking and selection model. The model ranks and selects appropriate tasks which are presented to the user.
</abstract>

<claims>
1. A method (700) for selecting and ranking service extensions, comprising: receiving (702) a query or an inference related to a user; identifying (708) any bots that activate in response to the query or inference; ranking the activated bots by performing acts for each activated bot comprising: identifying (714) a set of features corresponding to the activated bot; presenting (716) at least a portion of the set of features to a ranking and response selection model trained via a machine learning process; identifying (718) a rank for the activated bot using the ranking and response selection model and the portion of the set of features; and placing the activated bot in rank order compared to other activated bots to create a ranked list of bots; selecting (722) at least one bot from the ranked list of bots; and presenting (724) an output of at least one bot to the user.
2. The method of claim 1, further comprising converting the query from one format to another format for processing.
3. The method of claim 1, wherein the set of features comprises at least one of: features extracted from results of a language understanding model; features extracted from how well a conversation progress under the hypothesis that a specific response is accepted and presented to the user; features extracted from statistics collected for models used by tasks activities of the activated bot; features extracted from the activated bot configuration; and features extracted from an input source.
4. The method of claim 1, wherein the set of features further comprises at least one of: a correlation metric between a language understanding model of a bot and a built-in language understanding model; a list of tasks that the bot handles; and at least one metric describing at least one query that causes the bot to trigger.
5. The method of claim 1, 2, 3, or 4, further comprising: retrieving a set of curated queries; executing the set of curated queries against a submitted bot; gathering a set of features characterizing the submitted bot response to the set of curated queries; and storing the set of features.
6. The method of claim 5, further comprising:
extracting from the submitted bot a set of features comprising tasks handled by the bot.
7. The method of claim 5, further comprising:
identifying a set of positive trigger examples or a set of negative trigger examples or both based on the submitted bot response to the set of curated queries.
8. The method of claim 1, 2, 3 or 4, further comprising: identifying a set of representative bots; identifying a training set of curated queries; and using a machine learning process, creating the ranking and response selection process from the set of represented bots and the training set of curated queries.
9. A computing system (800) comprising:
a processor and executable instructions (824) accessible on a machine-readable medium that, when executed, cause the system to perform operations comprising: receiving (702) a query or an inference related to a user; identifying (708) any bots that activate in response to the query or inference; ranking the activated bots by performing operations for each activated bot comprising: identifying (714) a set of features corresponding to the activated bot; presenting (716) at least a portion of the set of features to a ranking and response selection model trained via a machine learning process; identifying (718) a rank for the activated bot using the ranking and response selection model and the portion of the set of features; and placing the activated bot in rank order compared to other activated bots to create a ranked list of bots; selecting (722) at least one bot from the ranked list of bots; and presenting (724) an output of at least one bot to the user.
10. The system of claim 9, wherein the set of features comprises features corresponding to the activated bot in the context of other activated bots and features calculated from a set of curated queries.
11. The system of claim 9, wherein the set of features comprises at least one of: a confidence score of a language understanding model; an indicator of entities detected by the language understanding model; a confidence score distribution; a frequency of triggering on top of an existing intent; and an indicator of the type of queries that cause triggering.
12. The system of claim 9, wherein the set of features further comprises at least one of: a correlation metric between a language understanding model of a bot and a built-in language understanding model; a list of tasks that the bot handles; and at least one metric describing at least one query that causes the bot to trigger.
13. The system of claim 9, 10, 11 or 12, further comprising: retrieving a set of curated queries; executing the set of curated queries against a submitted bot; gathering a set of features characterizing the submitted bot response to the set of curated queries; and storing the set of features.
14. The system of claim 13, further comprising:
extracting from the submitted bot a set of features comprising tasks handled by the bot.
15. The system of claim 13, further comprising: identifying a set of positive trigger examples or a set of negative trigger examples or both based on the submitted bot response to the set of curated queries. features extracted from statistics collected for models used by tasks activities of the activated bot; features extracted from the activated bot configuration; and features extracted from an input source.
</claims>
</document>
