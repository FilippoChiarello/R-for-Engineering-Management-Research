<document>

<filing_date>
2019-08-30
</filing_date>

<publication_date>
2020-03-12
</publication_date>

<priority_date>
2018-09-07
</priority_date>

<ipc_classes>
G10L17/04,G10L25/78
</ipc_classes>

<assignee>
CIRRUS LOGIC INTERNATIONAL SEMICONDUCTOR
</assignee>

<inventors>
LESSO, JOHN PAUL
</inventors>

<docdb_family_id>
65655874
</docdb_family_id>

<title>
SPEAKER RECOGNITION
</title>

<abstract>
A biometric is formed for at least one enrolled speaker by: obtaining a sample of speech of the enrolled speaker; obtaining a measure of a fundamental frequency of the speech of the enrolled speaker in each of a plurality of speech frames; and forming a first distribution function of the fundamental frequency of the speech of the enrolled speaker. Subsequently, for a speaker to be recognised, a sample of speech of the speaker to be recognised is obtained. Then, a measure of a fundamental frequency of the speech of the speaker to be recognised is obtained in each of a plurality of speech frames. A second distribution function of the fundamental frequency of the speech of the speaker to be recognised is formed, the second distribution function and the first distribution function are compared, and it is determined whether the speaker to be recognised is the enrolled speaker based on a result of comparing the second distribution function and the first distribution function.
</abstract>

<claims>
1. A method of speaker recognition, comprising, after forming a biometric for at least one enrolled speaker by: obtaining a sample of speech of the enrolled speaker; obtaining a measure of a fundamental frequency of the speech of the enrolled speaker in each of a plurality of speech frames; and forming a first distribution function of the fundamental frequency of the speech of the enrolled speaker, (i) during a verification: obtaining a sample of input speech; obtaining a measure of a fundamental frequency of the input speech in each of a plurality of speech frames; and forming a second distribution function of the fundamental frequency of the input speech, (ii) comparing the second distribution function and the first distribution function, and (iii) determining whether the verification is passed based on a result of comparing the second distribution function and the first distribution function.
2. A method according to claim 1, comprising: determining which frames of the sample of speech of the enrolled speaker contain voiced speech; and obtaining the measure of the fundamental frequency of the speech of the enrolled speaker from said frames that contain voiced speech; and determining which frames of the sample of input speech contain voiced speech; and obtaining the measure of the fundamental frequency of the input speech from said frames that contain voiced speech.
3. A method according to claim 1, wherein the first distribution function and the second distribution function are cumulative distribution functions.
4. A method according to claim 1, wherein the step of comparing the second distribution function and the first distribution function comprises calculating a value of a statistical distance between the second distribution function and the first distribution function.
5. A method according to claim 4, wherein the value of the statistical distance between the second distribution function and the first distribution function is calculated as:
description="In-line Formulae" end="lead"?dKS=max{|Fenroll−Ftest|}description="In-line Formulae" end="tail"? where Fenroll is the first distribution function and Ftest is the second distribution function, and hence |Fenroll−Ftest| is the vertical distance between the two functions at a given frequency.
6. A method according to claim 4, wherein the value of the statistical distance between the second distribution function and the first distribution function is calculated as:
description="In-line Formulae" end="lead"?dIN=∫|Fenroll−Ftest|df description="In-line Formulae" end="tail"? where Fenroll is the first distribution function and Ftest is the second distribution function, and hence Fenroll−Ftest| is the vertical distance between the two functions at a given frequency.
7. A method according to claim 4, wherein the value of the statistical distance between the second distribution function and the first distribution function is calculated as: where Fenroll is the first distribution function and Ftest is the second distribution function, and hence Fenroll−Ftest| is the vertical distance between the two functions at a given frequency.
8. A method according to claim 1, wherein the step of comparing the second distribution function and the first distribution function comprises using a machine learning system.
9. A method according to claim 8, wherein the machine learning system has been trained to distinguish between the enrolled speaker and other speakers.
10. A method according to claim 8, wherein the machine learning system is used to extract features from the first distribution function and the second distribution function.
11. A method according to claim 1, wherein determining whether the verification is passed comprises determining that the verification is not passed if a degree of similarity between the second distribution function and the first distribution function is below a first threshold value.
12. A method according to claim 1, wherein determining whether the verification is passed comprises determining that the verification is not passed if a degree of similarity between the second distribution function and the first distribution function is above a second threshold value.
13. A method as claimed in claim 1, wherein the step of determining whether the verification is passed comprises: comparing the sample of input speech with an alternative biometric, and fusing the result of comparing the second distribution function and the first distribution function with a result of comparing the sample of input speech with the alternative biometric.
14. A method as claimed in claim 13, wherein the alternative biometric uses features dependent on formants of the sample of the speech of the enrolled speaker.
15. A method as claimed in claim 14, wherein the alternative biometric uses or Mel-frequency cepstral coefficients, MFCCs, derived from the sample of the speech of the enrolled speaker.
16. A method as claimed in claim 14, wherein the alternative biometric uses Linear Predictive Coding, LPC, coefficients derived from the sample of the speech of the enrolled speaker.
17. A method as claimed in claim 13, wherein the alternative biometric uses at least one alternative feature of the fundamental frequency of the speech of the enrolled speaker.
18. A method as claimed in claim 17, wherein the at least one alternative feature of the fundamental frequency of the speech of the enrolled speaker comprises at least one of: jitter, shimmer, and fundamental frequency trajectory.
19. A method as claimed in claim 1, further comprising: in response to determining that the verification is passed, initiating an alternative method of speaker recognition.
20. A system comprising: an input for receiving an audio signal representing speech; and a processor configured to perform a method in accordance with claim 1.
21. A system according to claim 20, wherein the system is implemented in an electronic device, for example a smartphone or other communications device, a smart speaker, a tablet or laptop computer, a games console, a home control system, a home entertainment system, an in-vehicle entertainment system, or a domestic appliance.
22. A non-transitory storage medium having stored thereon software code which, when run on a suitable processor, performs a method in accordance with claim 1.
23. A method of speaker change detection, comprising: obtaining a sample of speech; in each of a plurality of time periods, obtaining a measure of a fundamental frequency of the speech; comparing the measure of the fundamental frequency of the speech with previously obtained measures of the fundamental frequency of the speech; and determining that a speaker may have changed in the event that the measure of the fundamental frequency of the speech differs from previously obtained measures of the fundamental frequency of the speech.
24. A system comprising: an input for receiving an audio signal representing speech; and a processor configured to perform a method in accordance with claim 23.
25. A system according to claim 24, wherein the system is implemented in an electronic device, for example a smartphone or other communications device, a smart speaker, a tablet or laptop computer, a games console, a home control system, a home entertainment system, an in-vehicle entertainment system, or a domestic appliance.
26. A non-transitory storage medium having stored thereon software code which, when run on a suitable processor, performs the method of claim 22.
</claims>
</document>
