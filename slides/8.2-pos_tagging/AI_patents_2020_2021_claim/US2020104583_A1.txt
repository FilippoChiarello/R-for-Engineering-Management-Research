<document>

<filing_date>
2018-09-27
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-27
</priority_date>

<ipc_classes>
G06K9/00,G06N3/08
</ipc_classes>

<assignee>
NCR CORPORATION
</assignee>

<inventors>
ZUCKER, BRENT VANCE
LIEBERMAN, ADAM JUSTIN
</inventors>

<docdb_family_id>
69945937
</docdb_family_id>

<title>
Tracking shoppers and employees
</title>

<abstract>
The system and method discussed herein can capture images from one or more video streams of a store area, can use deep learning to identify people in the images as being a store employee or a shopper, and can use the deep learning to track movement of the people within the store. The tracked movement can provide information that is useful to operators of the store, such as where store employees are, how long they have been in certain areas of the store, which areas of the store need more employees, where most shoppers are concentrated within the store, which areas of the store are popular, and so forth. The system and method can provide instructions to employees on mobile devices or kiosks, in response to the employee locations and activity in the store area. The system and method can also log the movement information, for downstream use.
</abstract>

<claims>
1. A system, comprising: a video camera positioned to capture a video stream of a confined area; a video interface configured to receive the video stream; and a processor coupled to the video interface and configured to execute computing instructions to perform data processing activities, the data processing activities comprising: receiving a series of images from the video stream; determining, from the series of images, locations of people in the confined area; determining, from the determined locations of people in the confined area, instructions for at least one of the people in the confined area; and directing the instructions to the at least of one of the people in the confined area.
2. The system of claim 1, wherein the processor is configured to use a first convolutional neural network to determine the locations of the people in the confined area.
3. The system of claim 1, wherein the confined area is a shopping area of a store.
4. The system of claim 3, wherein the data processing activities further comprise: automatically determining, from the series of images, whether each person in the confined area is a shopper or an employee of the store, based on clothing worn by the person.
5. The system of claim 4, wherein the processor is configured to use a second convolutional neural network to analyze the clothing worn by each person to automatically determine if the person is a shopper or an employee of the store.
6. The system of claim 5, wherein the second convolutional neural network computes a graham matrix for each person to determine whether the person is a shopper or an employee of the store.
7. The system of claim 6, wherein the graham matrix includes a two-dimensional vector of confidence values, the two-dimensional vector having a supremum, the supremum having an index in the two-dimensional vector, the index indicating whether the person is a shopper or an employee of the store.
8. The system of claim 4, wherein directing the instructions includes sending a message to an employee's smart phone instructing the employee to attend to an area of the store that requires more store clerks.
9. The system of claim 1, wherein the data processing activities further comprise: log people as entries in a database, such that an entry is created when a person is first detected within the confined area, and the entry is deleted when the person is determined to be absent from the confined area.
10. The system of claim 9, wherein the data processing activities further comprise: create entries only for one or more specified entry areas within the confined area; and delete entries only for one or more specified exit areas within the confined area.
11. The system of claim 1, further comprising a second video camera positioned to capture a second video stream of at least a portion of the confined area; wherein the video interface is further configured to receive the second video stream; and wherein the data processing activities further comprise: receiving a second series of images from the second video stream; and determining, from the series of images and the second series of images, the locations of people in the confined area.
12. The system of claim 11, wherein the processor does not rely on spatial coordinates of the plurality of video cameras to determine the locations of people in the confined area.
13. A method, comprising: receiving a series of images from at least one video stream of a confined area of a store; and for each image of the at least one video stream: using a first convolutional neural network to perform single shot objection detection for people and return all the people present in the image; and for each person present in the image, using a second convolutional neural network to analyze clothing worn by the person to automatically determine if the person is a shopper or an employee of the store; analyzing the received images to track motion of the employees of the store within the confined area; determining from the tracked motion that a first area of the store requires more store clerks; determining that a first employee is in the confined area but not in the first area; and automatically sending a message to the first employee's smart phone instructing the first employee to attend to the first area of the store.
14. The method of claim 13, further comprising logging people as entries in a database, such that an entry is created when a person is first detected within the confined area, and the entry is deleted when the person is determined to be absent from the confined area.
15. The method of claim 13, further comprising logging people as entries in a database, such that an entry is created when a person is first detected within one or more specified entry areas within the confined area, and the entry is deleted when the person is last detected to be within one or more specified exit areas within the confined area.
16. A system, comprising: a video camera positioned to capture a video stream of a confined area; a video interface configured to receive the video stream; and a processor coupled to the video interface and configured to execute computing instructions to perform data processing activities, the data processing activities comprising: receiving a series of images from at least one video stream of a confined area of a store; determining, from the series of images, locations of people in the confined area; automatically determining, from the series of images, whether each person in the confined area is a shopper or an employee of the store, based on clothing worn by the person; determining, from the determined locations of the shoppers and employees in the confined area, that an area of the store requires more store clerks; and sending a message to an employee's smart phone instructing the employee to attend to the area of the store that requires more store clerks.
17. The system of claim 16, wherein the data processing activities further comprise: logging people as entries in a database, such that an entry is created when a person is first detected within the confined area, and the entry is deleted when the person is determined to be absent from the confined area.
18. The system of claim 17, wherein the data processing activities further comprise: creating entries only for one or more specified entry areas within the confined area; and deleting entries only for one or more specified exit areas within the confined area.
19. The system of claim 16, further comprising a second video camera positioned to capture a second video stream of at least a portion of the confined area; wherein the video interface is further configured to receive the second video stream; and wherein the data processing activities further comprise: receiving a second series of images from the second video stream; and determining, from the series of images and the second series of images, the locations of people in the confined area.
20. The system of claim 16, wherein the at least one video stream includes a plurality of video streams; and further comprising a plurality of video cameras, coupled to the processor, and positioned to capture the plurality of video streams of the confined area, wherein the processor does not rely on spatial coordinates of the plurality of video cameras to determine the locations of people in the confined area.
</claims>
</document>
