<document>

<filing_date>
2018-11-15
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2018-11-15
</priority_date>

<ipc_classes>
G05D1/02,G06K9/00,G06K9/46,G06N20/00,G06T7/70
</ipc_classes>

<assignee>
DENSO INTERNATIONAL AMERICA
</assignee>

<inventors>
HUNT, SHAWN
</inventors>

<docdb_family_id>
70727752
</docdb_family_id>

<title>
Machine learning framework for visual tracking
</title>

<abstract>
A method of analyzing autonomous vehicle data comprising recording a video of a vehicle environment utilizing one or more vehicle cameras, identifying corner points of objects in the video, identifying a forward-tracked location of one or more corner points in each frame from an earlier frame to a later frame of the recorded video played in forward, identifying a reverse-tracked location of one or more corner points in each frame from the later frame to the earlier frame of the recorded video played in reverse, comparing the forward-tracked location of the earlier frame and reverse-tracked location of the later frame, and adjusting a descriptor defining characteristics of one or more pixels of the corner point in response the comparison indicating an error rate exceeding a threshold.
</abstract>

<claims>
1. An autonomous vehicle, comprising: a sensor configured to record video and identify one or more objects utilizing proximity data; and a controller in communication with the sensor and configured to perform the following functions: a. identify corner points in the recorded video of one or more objects utilizing the proximity data; b. identify a forward-tracked location of one or more corner points in each frame from an earlier first frame to a later frame of the recorded video played in forward; c. identify a reverse-tracked location of one or more corner points in each frame from the later frame to the earlier frame of the recorded video played in reverse; d. compare the forward-tracked location and reverse-tracked location of the one or more corner points; and e. adjust a descriptor defining characteristics of one or more pixels of the corner point in response to the comparison indicating an error rate exceeding a threshold.
2. The autonomous vehicle of claim 1, wherein the adjustment function includes changing an amount of pixels analyzed at the corner point.
3. The autonomous vehicle of claim 2, wherein the adjustment function includes increasing an amount of pixels analyzed at the corner point.
4. The autonomous vehicle of claim 2, wherein the adjustment function includes decreasing an amount of pixels analyzed at the corner point.
5. The autonomous vehicle of claim 1, wherein the adjustment function includes changing a shape of a region of the one or more pixels analyzed at the corner point
6. The autonomous vehicle of claim 5, wherein the shape of the region of the one or more pixels includes a square.
7. The autonomous vehicle of claim 5, wherein the shape of the region of the one or more pixels includes an annulus.
8. The autonomous vehicle of claim 5, wherein the shape of the region of the one or more pixels includes a circle.
9. The autonomous vehicle of claim 1, wherein the controller is further configured to translate the corner points from a first color space to a second color space.
10. The autonomous vehicle of claim 9, wherein the first color space is an red-green-blue (RGB) space and the second color space is a hue-saturation-value (HSV) color space or cielab color space.
11. An autonomous vehicle of claim 1, wherein the one or more objects include a moving vehicle.
12. The autonomous vehicle of claim 1, wherein the one or more objects include a stationary object.
13. A method of analyzing autonomous vehicle data, comprising: recording a video of a vehicle environment utilizing one or more vehicle cameras; identifying corner points of objects in the video; identifying a forward-tracked location of one or more corner points in each frame from an earlier first frame to a later frame of the recorded video played in forward; identifying a reverse-tracked location of one or more corner points in each frame from the later frame to the earlier frame of the recorded video played in reverse; comparing the forward-tracked location of the earlier frame and reverse-tracked location of the later frame; and adjusting a descriptor defining characteristics of one or more pixels of the corner point in response the comparison indicating an error rate exceeding a threshold.
14. The method of claim 13, further comprising translating the one or more corner points from a first color space to a second color space.
15. The method of claim 14, wherein the first color space is a red-green-blue (RGB) space and the second color space is a hue-saturation-value (HSV) color space.
16. The method of claim 13, wherein the adjusting step includes changing a shape of a region of the one or more pixels analyzed at the corner point
17. The autonomous vehicle of claim 16, wherein the shape of the region of the one or more pixels includes a circle.
18. The method of claim 16, wherein, wherein the shape of the region of the one or more pixels includes a square.
19. The method of claim 16, wherein the shape of the region of the one or more pixels includes an annulus.
20. A computer system, comprising: a storage medium including a recorded video collected from one or more vehicle sensors configured to identify one or more objects utilizing proximity data; and a processor in communication with the storage medium and programmed to: a. identify corner points in the recorded video of the one or more objects utilizing the proximity data; b. play the recorded video in forward and reverse; c. identify a forward-tracked location of one or more corner points in a earlier frame when the recorded video is played in forward from the earlier frame to a later frame; d. identify a reverse-tracked location of one or more corner points in the earlier frame when the recorded video is played in reverse from the later frame to the earlier frame; e. compare the forward-tracked location and reverse-tracked location of the one or more corner points; and f. adjust a descriptor defining a pixel of the corner point in response the comparison indicating a change of position of the one or more corner points.
</claims>
</document>
