<document>

<filing_date>
2018-10-31
</filing_date>

<publication_date>
2020-10-20
</publication_date>

<priority_date>
2018-10-31
</priority_date>

<ipc_classes>
B64C39/02,G06K9/00,G06K9/62,H04N13/239,H04N13/271
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
BECKER, GABOR SZEDO
Nambirajan, Anirudth
Cui, Chengwu Luke
</inventors>

<docdb_family_id>
72838795
</docdb_family_id>

<title>
Rolling shutter motion and depth sensing
</title>

<abstract>
Described is an imaging component that utilizes two rolling shutter sensors for motion detection of objects and for depth mapping of objects within an effective field of view of the imaging component. Unlike traditional stereo cameras that utilize global shutter sensors to avoid distortions, or attempting to remove distortions created by rolling shutter sensors, the disclosed implementations emphasize the distortions created by rolling shutters imaging moving objects and utilize that information to determine that the objects are moving and/or to determine a range or distance of the object from the imaging component. For example, a first rolling shutter sensor is oriented in a first orientation such that the scanlines generate the image from a top of the sensor to the bottom of the sensor, and a second rolling shutter sensor is oriented in a second orientation such that the scanlines generate the image from a bottom of the sensor to the top of the sensor. In other words, the two rolling shutter sensors have opposite orientations in the imaging component. As a result, the distortions of a moving object imaged by the two sensors are opposite and easily distinguished between the two images.
</abstract>

<claims>
1. An aerial vehicle, comprising: a frame; a plurality of propulsion mechanisms to aerially lift and navigate the aerial vehicle; an imaging component, including: a first rolling shutter sensor having a first plurality of scanlines, the first rolling shutter sensor having a first orientation such that the first plurality of scanlines produce image segments from a first top of the first rolling shutter sensor to a first bottom of the first rolling shutter sensor in a time sequence to produce a first image of a scene; a second rolling shutter sensor having a second plurality of scanlines, the second rolling shutter sensor having a second orientation such that the second plurality of scanlines produce image segments from a second bottom of the second rolling shutter sensor to a second top of the second rolling shutter sensor in the time sequence to produce a second image of the scene; and an image-processing component, configured to at least: receive the first image and the second image; compare the first image and the second image to at least: detect a first object represented in the first image having a first distortion caused by the first top to the first bottom generation of the first image by the first rolling shutter sensor; and detect the first object represented in the second image having a second distortion caused by the second bottom to the second top generation of the second image by the second rolling shutter sensor; determine a first distance between the imaging component and the first object; generate a depth map representative of at least the first distance; detect a second object represented in the first image; detect the second object represented in the second image; determine that there is no opposing distortion of the second object between the first image and the second image; determine that the aerial vehicle is moving; and determine based on the no opposing distortion of the second object and the aerial vehicle is moving, that the second object is moving with the aerial vehicle.
2. The aerial vehicle of claim 1, wherein the image-processing component is further configured to at least: determine that a difference between the first distortion and the second distortion exceeds a threshold; and assign a first depth map placement as representative of the first object; and include the first depth map placement in the depth map as representative of the scene.
3. The aerial vehicle of claim 2, wherein the first depth map placement corresponds to at least one of a foreground or a middle ground of the scene.
4. The aerial vehicle of claim 1, wherein the image-processing component is further configured to at least: compare the first image and the second image to at least: determine a second distance between the imaging component and the second object, wherein the second distance is greater than the first distance; and generate the depth map indicating that the first object is closer to the imaging component than the second object.
5. An image capture apparatus, comprising: a frame; a first rolling shutter sensor coupled to the frame at a first orientation such that imaging of a scene by a first plurality of scanlines of the first rolling shutter sensor proceeds in a first direction to produce a first image; a second rolling shutter sensor coupled to the frame at a second orientation that is different than the first orientation such that imaging of the scene by a second plurality of scanlines of the second rolling shutter sensor proceeds in a second direction to produce a second image, wherein the second direction is different than the first direction; and a processing component configured to at least: receive the first image and the second image; compare the first image and the second image to determine a first object having a first distortion in the first image and a second distortion in the second image; determine that the first distortion and the second distortion are not opposing distortions; in response to determination that the first distortion and the second distortion are not opposing distortions, determine that the first object is not moving with respect to the image capture apparatus; compare the first image and the second image to determine a second object having a third distortion in the first image and a fourth distortion in the second image; determine that the third distortion and the fourth distortion are opposing distortions; and in response to determination that the third distortion and the fourth distortion are opposing distortions, determine that the second object is moving with respect to the image capture apparatus.
6. The image capture apparatus of claim 5, wherein the processing component is further configured to at least: determine that the image capture apparatus is moving; adjust at least one of the third distortion or the fourth distortion to correct for the movement of the image capture apparatus; and determine, subsequent to adjusting, a difference between the adjusted third distortion and the adjusted fourth distortion; and determine based at least in part on the difference, that the second object is moving.
7. The image capture apparatus of claim 5, wherein the processing component is further configured to at least: determine that the image capture apparatus is moving; adjust at least one of the first distortion or the second distortion of to correct for the movement of the image capture apparatus; and determine, subsequent to adjusting, a difference between the adjusted first distortion and the adjusted second distortion; and determine based at least in part on the difference, that the first object is not moving.
8. The image capture apparatus of claim 5, wherein the processing component is further configured to at least: determine that the image capture apparatus is not moving; and determine based on the no opposing distortion between the first distortion and the second distortion and the image capture apparatus not moving, that the first object is not moving.
9. The image capture apparatus of claim 5, wherein the processing component is further configured to at least: determine that the image capture apparatus is moving; and determine based on the no opposing distortion between the first distortion and the second distortion and the image capture apparatus moving, that the first object is moving with the image capture apparatus.
10. The image capture apparatus of claim 5, wherein the processing component is further configured to at least: process the first image using one or more image processing algorithms to detect the first object represented in the first image.
11. The image capture apparatus of claim 5, wherein the image capture apparatus is coupled to an aerial vehicle, a ground based vehicle, or a water based vehicle.
12. A method to detect an object that is moving with respect to an image capture device, the method comprising: generating a first image of a scene with a first rolling shutter sensor of an image capture device, the first rolling shutter sensor oriented in a first direction such that imaging of the scene by a first plurality of scanlines of the first rolling shutter sensor proceeds in a first direction to produce a first image; generating a second image of a scene with a second rolling shutter sensor of the image capture device, the second rolling shutter sensor oriented in a second direction such that imaging of the scene by a second plurality of scanlines of the second rolling shutter sensor proceeds in a second direction to produce a second image; determining a first distortion of a first object represented in the first image; determining a second distortion of the first object represented in the second image; determining that the first distortion is different than the second distortion; determining, based at least in part on the determination that the first distortion is different than the second distortion, that the object is moving with respect to the image capture device; determining that there is no opposing distortion of a second object between the first image and second image, wherein the second object is represented in the first image and the second image; determining that the image capture device is not moving; and determining based on the no opposing distortion of the second object and the image capture device not moving, that the second object is not moving.
13. The method of claim 12, further comprising: adjusting for the movement of the first object with respect to the image capture device; and producing a depth map of the scene.
14. The method of claim 12, further comprising: determining, based at least in part on a magnitude of a difference between the first distortion and the second distortion, an approximate distance between the first object and a vehicle.
15. The method of claim 12, further comprising: providing the first image and the second image to a neural network; and wherein the neural network performs at least one of: determining a first distortion of a first object represented in the first image; determining a second distortion of the first object represented in the second image; determining that the first distortion is different than the second distortion; and determining, based at least in part on the determination that the first distortion is different than the second distortion, that the first object is moving with respect to the image capture device.
16. The method of claim 12, further comprising: altering a navigation of a vehicle, based at least in part on determining that the first object is moving with respect to the image capture device.
17. The image capture apparatus of claim 5, wherein the processing component is further configured to at least: determine that a first difference between the first distortion and the second distortion does not exceed a threshold; in response to determination that the first difference does not exceed the threshold, assign the first object to a background; and generate a depth map that represents the first object according to the assigned background.
18. The image capture apparatus of claim 17, wherein the processing component is further configured to at least: determine that a second difference between the third distortion and the fourth distortion exceeds the threshold; in response to determination that the second difference exceeds the threshold, assign the second object to a foreground; and generate the depth map that represents the first object according to the assigned background and represents the second object according to the assigned foreground.
19. The image capture apparatus of claim 18, wherein the first object assigned to the background is represented by a first color in the depth map and the second object assigned to the foreground is represented by a second color in the depth map, wherein the first color is different than the second color.
</claims>
</document>
