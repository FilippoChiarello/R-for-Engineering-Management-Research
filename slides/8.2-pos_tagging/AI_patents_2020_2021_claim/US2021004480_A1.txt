<document>

<filing_date>
2019-07-03
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2019-07-03
</priority_date>

<ipc_classes>
G06F21/62,G06N20/00,G16H10/60,G16H50/70
</ipc_classes>

<assignee>
HITACHI
</assignee>

<inventors>
TAKATA, MIKA
</inventors>

<docdb_family_id>
74065750
</docdb_family_id>

<title>
DATA MANAGEMENT METHOD, APPARATUS AND SYSTEM FOR MACHINE LEARNING SYSTEM
</title>

<abstract>
Example implementations described herein are directed to systems and methods for selecting appropriate data samples and features in an access and privacy restricted system. Example implementations involve selection of appropriate samples (e.g. patients) which have enough data sources bringing highly important factors based on the experienced risk factors at other facilities, which is stored as metadata. The risk factor management puts more prioritization on some patients which have more data in the required data source than the other patients among all data sample candidates. The similarity of the training data sample can be a criteria to select new sample sets. Further, the risk factor management selects valuable features effectively based on metadata derived from other facilities. Example implementations help improve machine learning accuracy as part of daily system management in a facility, and can be deployed across facilities without compromising access or privacy restrictions of the data.
</abstract>

<claims>
1. A method to generate a trained model for first privacy protected data associated with a first facility, the method comprising: determining metadata of a second privacy protected data associated with a second facility, the metadata associated with features from the first privacy protected data associated with the first facility; determining, based on the metadata, a sample of the first privacy protected data associated with the first facility to be utilized in training the model; and training the model based on the sample of the first privacy protected data associated with the first facility.
2. The method of claim 1, wherein the metadata is indicative of a relationship between the features, types of data sources associated with the features, and the model to be trained.
3. The method of claim 1, wherein the features are based on risk factors, wherein the features are selected based on an importance associated with the risk factors, and wherein the training the model is further based on the selected features.
4. The method of claim 1, wherein the determining the sample of the first privacy protected data associated with the first facility is based on a volume of the first privacy protected data.
5. The method of claim 1, wherein the model is trained to output risk factors, importance values for each of the risk factors, and a readmission risk score.
6. The method of claim 1, further comprising executing the trained model against the first privacy protected data periodically, and generating a visualization comprising the output of the trained model, the visualization being updated periodically.
7. A non-transitory computer readable medium, storing instructions to generate a trained model for first privacy protected data associated with a first facility, the instructions comprising: determining metadata of a second privacy protected data associated with a second facility, the metadata associated with features from the first privacy protected data associated with the first facility; determining, based on the metadata, a sample of the first privacy protected data associated with the first facility to be utilized in training the model; and training the model based on the sample of the first privacy protected data associated with the first facility.
8. The non-transitory computer readable medium of claim 7, wherein the metadata is indicative of a relationship between the features, types of data sources associated with the features, and the model to be trained.
9. The non-transitory computer readable medium of claim 7, wherein the features are based on risk factors, wherein the features are selected based on an importance associated with the risk factors, and wherein the training the model is further based on the selected features.
10. The non-transitory computer readable medium of claim 7, wherein the determining the sample of the first privacy protected data associated with the first facility is based on a volume of the first privacy protected data.
11. The non-transitory computer readable medium of claim 7, wherein the model is trained to output risk factors, importance values for each of the risk factors, and a readmission risk score.
12. The non-transitory computer readable medium of claim 7, the instructions further comprising executing the trained model against the first privacy protected data periodically, and generating a visualization comprising the output of the trained model, the visualization being updated periodically.
13. An apparatus configured to generate a trained model for first privacy protected data associated with a first facility, the apparatus comprising: a processor, configured to: determine metadata of a second privacy protected data associated with a second facility, the metadata associated with features from the first privacy protected data associated with the first facility; determine, based on the metadata, a sample of the first privacy protected data associated with the first facility to be utilized in training the model; and train the model based on the sample of the first privacy protected data associated with the first facility.
14. The apparatus of claim 13, wherein the metadata is indicative of a relationship between the features, types of data sources associated with the features, and the model to be trained.
15. The apparatus of claim 13, wherein the features are based on risk factors, wherein the features are selected based on an importance associated with the risk factors, and wherein the training the model is further based on the selected features.
16. The apparatus of claim 13, wherein the processor is configured to determine the sample of the first privacy protected data associated with the first facility based on a volume of the first privacy protected data.
17. The apparatus of claim 13, wherein the model is trained to output risk factors, importance values for each of the risk factors, and a readmission risk score.
18. The apparatus of claim 13, wherein the processor is further configured to execute the trained model against the first privacy protected data periodically, and generate a visualization comprising the output of the trained model, the visualization being updated periodically.
</claims>
</document>
