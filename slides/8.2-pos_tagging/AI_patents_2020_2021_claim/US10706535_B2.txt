<document>

<filing_date>
2017-09-08
</filing_date>

<publication_date>
2020-07-07
</publication_date>

<priority_date>
2017-09-08
</priority_date>

<ipc_classes>
G01N1/30,G06K9/00,G06K9/03,G06K9/46,G06K9/62,G06T7/00,G06T7/194
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
GABRANI MARIA
KAIGALA, GOVIND
ARAR, NURI MURAT
KASHYAP, ADITYA
PATI, PUSHPAK
KHARTCHENKO, ANNA FOMITCHEVA
</inventors>

<docdb_family_id>
65631869
</docdb_family_id>

<title>
Tissue staining quality determination
</title>

<abstract>
The invention relates to the automated determination of the staining quality of an IHC stained biological sample. A plurality of features is extracted from a digital IHC stained tissue image. The features are input into a first classifier configured to identify the extended tissue type of the depicted tissue as a function of the extracted features. An extended tissue type is a tissue type with a defined expression level of the tumor marker. In addition, the extracted features are input into a second classifier configured to identify a contrast level of the depicted tissue as a function of at least some second ones of the extracted features. The contrast level indicates the intensity contrast of pixels of the stained tissue. Then, a staining quality score of the image is computed as a function of the identified extended tissue type and the identified contrast level.
</abstract>

<claims>
1. An image analysis method for automatically determining the staining quality of an IHC stained biological sample, the method comprising: receiving a digital image of an IHC stained tissue sample of a patient, the pixel intensities of the image correlating with the amount of a tumor-marker-specific stain; extracting a plurality of features from the received digital image, wherein the extracted plurality of features comprises at least information relating to the pixel intensities of the digital image; inputting the extracted features into a first classifier, the first classifier being configured to identify an extended tissue type of the tissue depicted in the digital image as a function of at least some first ones of the extracted features, wherein the extended tissue type comprises a defined expression level of a presence of the tumor marker and the identification of the extended tissue type includes an identification of the defined expression level; inputting the extracted features into a second classifier, the second classifier being configured to identify a contrast level of the tissue depicted in the digital image as a function of at least some second ones of the extracted features, the contrast level indicating the intensity contrast of pixels of the stained tissue; computing a staining quality score for the tissue depicted in the digital image as a function of the identified extended tissue type from the first classifier and the identified contrast level from the second classifier.
2. The image analysis method of claim 1, the identification of the extended tissue type of the tissue depicted in each of the digital images comprising computing and outputting, for each of the extended tissue types and for each of a plurality of regions in the image, a probability being indicative of the probability that the tissue depicted in this region, if any, belongs to said extended tissue type; the identification of the contrast level of the tissue depicted in each of the digital images comprising computing and outputting, for each of a plurality of regions in the image, a probability that the tissue depicted in this region is a "HIGH CONTRAST" tissue and/or is a "LOW CONTRAST" tissue, the method further comprising: respectively representing the probabilities for extended tissue type membership and the probability for contrast level membership of the image regions as probability maps; the computing of the staining quality score comprising processing the probability maps.
3. The method of claim 1, further comprising generating the first classifier by: receiving a plurality of training images of IHC stained tissue samples of one or more patients, the pixel intensities of each image correlating with the amount of a tumor-marker-specific stain, the tissue samples depicted in the training images comprising tissue samples derived from the same patient and the same tissue type stained with the same tumor-marker-specific stain but with different staining durations and different concentrations of the tumor-marker-specific stain, each tissue depicted in the training images being annotated with one of the extended tissue types; extracting a plurality of features from each of the received training images; training a first machine-learning program logic with at least some first ones of the extracted features and tissue type annotations of the training images for generating the first classifier as a trained version of the first machine-learning logic.
4. The method of claim 1, further comprising generating the second classifier by: receiving a plurality of training images of IHC stained tissue samples of one or more patients, the pixel intensities of each image correlating with the amount of a tumor-marker-specific stain, the tissue samples depicted in the training images comprising tissue samples derived from the same patient and the same tissue type stained with the same tumor-marker-specific stain but with different staining durations and different concentrations of the tumor-marker-specific stain, each tissue depicted in the training images being annotated with one of a predefined set of contrast level labels comprising "HIGH CONTRAST" and "LOW CONTRAST"; extracting a plurality of features from each of the received training images; training a second machine-learning program logic with at least some second ones of the extracted features, and the contrast level annotations of the training images for generating the second classifier as the trained version of the second machine learning logic.
5. The method of claim 1, the computing of the staining quality score being performed by a prediction logic, the method further comprising generating the prediction logic, the generation comprising: receiving a plurality of training images of IHC stained tissue samples of one or more patients, the pixel intensities of each image correlating with the amount of a tumor-marker-specific stain, the depicted tissue samples having been stained with the same tumor-marker-specific stain but with different staining durations and different concentrations of the tumor-marker-specific stain, each tissue depicted in the training images being annotated with a staining quality score or a staining quality label; applying the first and the second classifier on each of the training images for computing, for each of the training images, a plurality of probability maps, the probability maps indicating the probabilities of respective image regions for depicting a tissue that belongs to one of the extended tissue types and of depicting a tissue in a particular one of the contrast levels; training a machine-learning logic on the probability maps of the training images such that an error between the annotated staining quality scores or labels and predicted quality scores or labels computed as a function of the probability maps is minimized.
6. The method of claim 3, further comprising generating the training images, the generation comprising: applying a plurality of IHC staining protocols differing from each other by at least one parameter value on a plurality of training tissue samples derived from the same patient, the plurality of IHC staining protocols being applied such that: at least a first series of IHC staining protocols using different staining durations are applied; at least a second series of IHC staining protocols using different concentrations of the tumor-marker-specific stain are applied; and for each of the staining durations of the first series at least two different stain concentrations are applied and for each of the stain concentrations of the second series at least two different staining durations are applied.
7. The method of claim 6, the training tissue samples belonging to different tissue types comprising: PT tissue, the PT tissue being tissue comprising or consisting of primary tumor tissue; MT tissue, the MT tissue being tissue comprising or consisting of metastatic tumor tissue; and HT tissue, the HT tissue being healthy tissue located in spatial proximity of the primary tumor or of a metastasis.
8. The method of claim 6, the at least one parameter value being a staining duration value or a concentration of a tumor-marker-specific stain.
9. The method of claim 6, the application of the plurality of staining protocols comprising applying the plurality of staining protocols on different regions of the same tissue section by using a vertical microfluidic probe system.
10. The method of claim 1, further comprising segmenting the received digital image, the segmentation comprising: identifying the primary background of the image, the primary background depicting tissue regions not brought in contact with the stain; identifying a footprint region in the image, the footprint region depicting a region in the image which was brought in contact with the stain, the footprint region being identified by subtracting the primary background from the received digital image; selectively analyzing the footprint region for identifying the foreground region within the footprint region, the foreground region depicting stained tissue regions expressing the tumor-marker; selectively analyzing the footprint region for identifying the secondary background within the footprint region, the secondary background depicting tissue regions not supposed to express the tumor-marker.
11. The method of claim 10, the identification of the primary background comprising: receiving the digital image as an RGB image, the stained tissue regions corresponding to low-intensity image regions and unstained tissue regions corresponding to high intensity image regions; converting the RGB image into a grayscale image; inverting the grayscale image such that stained tissue regions correspond to high-intensity image regions and unstained tissue regions correspond to low-intensity image regions; extracting a footprint mask by applying a non-parametric marker-based Watershed algorithm on the inverted grayscale image; and extracting the footprint region in the received digital image as the region of the digital image not masked by the footprint mask.
12. The method of claim 10, the identification of the foreground region comprising: calculating a histogram of the pixel intensities of the footprint region; identifying a highest-frequency-bin in the histogram, the highest-frequency-bin being the one of the histogram bins comprising the highest number of intensities observed in the image; identifying a highest-intensity bin in the histogram, the highest-intensity-bin being the one of the histogram bins that comprises the highest intensities observed in the image and which in addition comprises more than a predefined threshold of the total pixels in the histogram; identifying a first maximum intensity, the first maximum intensity being the maximum intensity of the highest-frequency-bin; identifying a second maximum intensity, the second maximum intensity being the maximum intensity of the highest-intensity-bin; computing the mean of the first and the second maximum intensities; generating a foreground mask by using the computed mean as threshold value, the foreground mask hiding all pixels in the footprint region whose intensity values is below said threshold value; identifying the foreground region by applying the foreground mask on the footprint region of the received digital image, whereby only the pixels of the footprint region which are not hidden by the foreground masks are used as foreground pixels.
13. The method of claim 1, the extraction of the features from the received digital image comprising extracting global features derived from all pixels in the image and extracting local features from patches within the images.
14. The method of claim 13, the extraction of the global features comprising: segmenting the received digital image, the segmentation comprising: identifying the primary background of the image, the primary background depicting tissue regions not brought in contact with the stain; identifying a footprint region in the image, the footprint region depicting a region in the image which was brought in contact with the stain, the footprint region being identified by subtracting the primary background from the received digital image; selectively analyzing the footprint region for identifying the foreground region within the footprint region, the foreground region depicting stained tissue regions expressing the tumor-marker; selectively analyzing the footprint region for identifying the secondary background within the footprint region, the secondary background depicting tissue regions not supposed to express the tumor-marker; and computing one or more segmentation statistics features from the image segments, the segmentation statistics features being selected from a group comprising: percentage of foreground pixels within the whole received image, percentage of foreground pixels within the footprint regions, percentage of footprint region pixels within the whole image; and/or: computing one or more intensity features from the image segments, the intensity features being selected from a group comprising: Mean intensity of foreground pixels; Mean intensity of footprint region pixels; Mean intensity of secondary background pixels; ratio of mean pixel intensity in the foreground region and mean pixel intensity in the secondary background, the ratio representing a signal-to-noise ratio and/or: computing one or more Scale-Invariant Feature Transform (SIFT) features by applying difference of Gaussian filters with different values selectively on the foreground region of the image to obtain multiple keypoints; and extracting Scale-Invariant Feature Transform (SIFT) features in spatial proximity to the keypoints.
15. The method of claim 13, the extraction of local features from an image comprising: dividing the image into overlapping patches of pixels; moving a window of patch-size across the image, the moving comprising, upon the sliding window covering a new current patch: determining if the pixels in the current patch meet a predefined criterion; selectively in case the criterion is fulfilled, processing the pixels of the current patch for extracting a local feature from the current patch.
16. The method of claim 13, the extraction of local features from an image comprising: segmenting the received digital image, the segmentation comprising: identifying the primary background of the image, the primary background depicting tissue regions not brought in contact with the stain; identifying a footprint region in the image, the footprint region depicting a region in the image which was brought in contact with the stain, the footprint region being identified by subtracting the primary background from the received digital image; selectively analyzing the footprint region for identifying the foreground region within the footprint region, the foreground region depicting stained tissue regions expressing the tumor-marker; selectively analyzing the footprint region for identifying the secondary background within the footprint region, the secondary background depicting tissue regions not supposed to express the tumor-marker, wherein the extraction of the local features comprising, for each of the patches fulfilling the criterion, computing a spatial feature selected from a group comprising: a Gabor wavelet transform feature; a dual-tree complex wavelet transform (DTCWT) feature; a discrete wavelet transform (DWT) feature; a texture feature.
17. The method of claim 13, further comprising combining the global features and local features such that a feature vector of predefined length is generated for the image, the length of the feature vector being identical for all images from which the features are extracted.
18. An image analysis method for automatically determining, for one or more staining protocol parameters of an IHC staining protocol, a respective parameter value range that will result in a staining of a tissue sample with a tumor-marker specific stain that fulfills predefined staining quality requirements, the method comprising: receiving a plurality of images of one or more IHC stained tissue samples belonging to multiple different extended tissue types, the pixel intensities of each image correlating with the amount of a tumor-marker-specific stain, the depicted tissue samples having been stained with the same tumor-marker-specific stain but with different values of each of the one or more staining protocol parameters; extracting a plurality of features from each of the received digital images, wherein the extracted plurality of features comprises at least information relating to the pixel intensities of the digital image; automatically analyzing the extracted features for identifying an extended tissue type using a first classifier and a contrast level of each of the tissue samples using a second classifier, wherein the extended tissue type comprises a defined expression level of a presence of the tumor marker and the identification of the extended tissue type includes an identification of the defined expression level by at least: inputting the extracted features of the respective received image into the first classifier, the first classifier being configured to identify the extended tissue type of the tissue depicted in the digital image as a function of at least some first ones of the extracted features of the respective received image; and inputting the extracted features of the respective received image into the second classifier, the second classifier being configured to identify the contrast level of the tissue depicted in the digital image as a function of at least some second ones of the extracted features of the respective received image, the contrast level indicating the intensity contrast of pixels of the stained tissue; for the tissue depicted in each of the received images, computing a staining quality score as a function of the identified extended tissue type from the first classifier and the identified contrast level of the tissue from the second classifier; performing, for each of the one or more staining protocol parameters: for each of the extended tissue types: identifying all images depicting a tissue of said extended tissue type for which a quality score that exceeds or meets an acceptable quality threshold was computed; identifying the minimum and maximum staining parameter value used in the staining protocols that were applied for staining the tissues depicted in said identified images; returning a staining parameter value range for the staining protocol parameter, the range being delimited by the identified minimum and maximum values.
19. The method of claim 18, further comprising: generating, for each of the extended tissue types depicted in the received digital images, a respective multi-dimensional staining quality plot, at least two plot dimensions respectively representing one of the staining protocol parameters used for staining the tissues depicted in the received images, the staining quality scores computed for each staining protocol value being graphically represented in the form of a grey-level scale or color scale or in the form of a further dimension of the staining quality plot; and presenting the staining quality plot on a display screen for enabling a user to manually select, selectively for the extended tissue type for which the plot was generated and for each of the staining protocol parameters, a parameter value range that corresponds to high quality tissue staining.
20. The method of claim 18, further comprising: generating, for each of the extended tissue types depicted in the received digital images, a respective multi-dimensional sensitivity plot, at least two plot dimensions of the sensitivity plot respectively representing one of the staining protocol parameters used for staining the tissues depicted in the received images, the degree of sensitivity of the staining quality from a staining protocol parameter combination being graphically represented in the form of a grey-level scale or color scale or in the form of a further dimension of the sensitivity plot; and presenting the sensitivity plot on a display screen for enabling a user to manually select, selectively for the extended tissue type for which the sensitivity plot was generated and for each of the staining protocol parameters, a parameter value range that is free of parameter values for which a sensitivity maximum is indicated by the sensitivity plot.
21. The method of claim 1, the extended tissue type being selected from a group comprising: PT+ tissue, the PT+ tissue being tissue comprising or consisting of primary tumor tissue that expresses the tumor-marker; PT− tissue, the PT− tissue being tissue comprising or consisting of primary tumor tissue that does not express the tumor-marker; MT+ tissue, the MT+ tissue being tissue comprising or consisting of metastatic tumor tissue that expresses the tumor-marker; MT− tissue, the MT− tissue being tissue comprising or consisting of metastatic tumor tissue that does not express the tumor-marker; HT tissue, the HT tissue being healthy tissue located in spatial proximity of the primary tumor or of a metastasis.
22. A computer readable storage medium comprising computer-interpretable instructions which, when executed by a processor, cause the processor to perform a method according to claim 1.
23. An image analysis system comprising: a storage medium comprising a first classifier and a second classifier; an interface configured for receiving a digital image of an IHC stained tissue, the pixel intensities of the image correlating with the amount of a tumor-marker-specific stain; a processor configured for: extracting a plurality of features from the received digital image, wherein the extracted plurality of features comprises at least information relating to the pixel intensities of the digital image; inputting the extracted features into the first classifier, the first classifier being configured to identify an extended tissue type of the tissue depicted in the digital image as a function of at least some first ones of the extracted features, wherein the extended tissue type comprises a defined expression level of a presence of the tumor marker and the identification of the extended tissue type includes an identification of the defined expression level; inputting the extracted features into the second classifier, the second classifier being configured to identify a contrast level of the tissue depicted in the digital image as a function of at least some second ones of the extracted features, the contrast level label indicating the intensity contrast of pixels of the stained tissue; computing a staining quality score for the tissue depicted in the digital image as a function of the identified extended tissue type from the first classifier and the identified contrast level from the second classifier.
24. An image analysis system comprising: a storage medium comprising a first classifier and a second classifier; an interface configured for receiving a plurality of images of one or more IHC stained tissue samples belonging to multiple different extended tissue types, the pixel intensities of each image correlating with the amount of a tumor-marker-specific stain, the depicted tissue samples having been stained with the same tumor-marker-specific stain but with different values of each of the one or more staining protocol parameters; a processor configured for: extracting a plurality of features from each of the received digital images, wherein the extracted plurality of features comprises at least information relating to the pixel intensities of the digital image; automatically analyzing the extracted features for identifying an extended tissue type using the first classifier and a contrast level of each of the tissue samples using the second classifier, wherein the extended tissue type comprises a defined expression level of a presence of the tumor marker and the identification of the extended tissue type includes an identification of the defined expression level by at least: inputting the extracted features of the respective received image into the first classifier, the first classifier being configured to identify the extended tissue type of the tissue depicted in the digital image as a function of at least some first ones of the extracted features of the respective received image; and inputting the extracted features of the respective received image into the second classifier, the second classifier being configured to identify the contrast level of the tissue depicted in the digital image as a function of at least some second ones of the extracted features of the respective received image, the contrast level indicating the intensity contrast of pixels of the stained tissue; for the tissue depicted in each of the received images, computing a staining quality score as a function of the identified extended tissue type from the first classifier and the identified contrast level of the tissue from the second classifier; performing, for each of the one or more staining protocol parameters: for each of the extended tissue types: identifying all images depicting a tissue of said extended tissue type for which a quality score that exceeds or meets an acceptable quality threshold was computed; identifying the minimum and maximum staining parameter value used in the staining protocols that were applied for staining the tissues depicted in said identified images; returning a staining parameter value range for the staining protocol parameter, the range being delimited by the identified minimum and maximum values, the range being a staining parameter range adapted to stain a biological sample with a tumor-marker specific stain such that predefined staining quality requirements are fulfilled.
</claims>
</document>
