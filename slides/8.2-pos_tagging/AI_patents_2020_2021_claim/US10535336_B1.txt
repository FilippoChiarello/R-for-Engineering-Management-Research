<document>

<filing_date>
2019-01-22
</filing_date>

<publication_date>
2020-01-14
</publication_date>

<priority_date>
2015-08-06
</priority_date>

<ipc_classes>
G10L13/033,G10L13/047,G10L15/26,G10L25/30
</ipc_classes>

<assignee>
OBEN
MOHAMMADI, SEYED HAMIDREZA
</assignee>

<inventors>
MOHAMMADI, SEYED HAMIDREZA
</inventors>

<docdb_family_id>
65011538
</docdb_family_id>

<title>
Voice conversion using deep neural network with intermediate voice training
</title>

<abstract>
A system and method of converting source speech to target speech using intermediate speech data is disclosed. The method comprises identifying intermediate speech data that match target voice training data based on acoustic features; performing dynamic time warping to match the second set of acoustic features of intermediate speech data and the first set of acoustic features of target voice training data; training a neural network to convert the intermediate speech data to target voice training data; receiving source speech data; converting the source speech data to an intermediate speech; converting the intermediate speech to a target speech sequence using the neural network; and converting the target speech sequence to target speech using the pitch from the target voice training data.
</abstract>

<claims>
I claim:
1. A method of converting source speech to target speech, the method comprising: receiving target voice training data and intermediate speech data, wherein the target voice training data is speech and the intermediate speech data is speech; extracting a first set of acoustic features and pitch from the target voice training data; identifying a second set of acoustic features from the identified intermediate speech data; identifying matches between the intermediate speech data and target voice training data based on the first set and second set of acoustic features; performing dynamic time warping to align the second set of acoustic features of intermediate speech data and the first set of acoustic features of target voice training data; training a neural network to convert the second set of acoustic features to the first set of acoustic features based on the matches after alignment by dynamic time warping; acquiring, with a mobile phone, source speech data from a source speaker; converting the source speech data to an intermediate speech; converting the intermediate speech to a target speech sequence using the neural network, wherein the target speech sequence is speech; converting the target speech sequence to target speech audio using the pitch from the target voice training data; and playing, with the mobile phone, target speech to the source speaker.
2. The method of converting source speech of claim 1, wherein the step of training the neural network is based on back propagation.
3. The method of converting source speech of claim 2, wherein the back propagation employs a cost function based, in part, on a mean square error and standard deviation of the target speech training data.
4. The method of converting source speech of claim 1, wherein the first set of acoustic features and a second set of acoustic features comprise mel-cepstrum coefficients.
5. The method of converting source speech of claim 1, wherein the first set of acoustic features and a second set of acoustic are selected from the group consisting of: Linear Predictive Coding (LPC) coefficients, Line Spectral Pairs (LSP), raw log-spectrum, and linguistic features.
6. The method of converting source speech of claim 1, wherein the steps of converting the source speech data to the intermediate speech comprises: identify words spoken by a source speaker using automatic speech recognition; and synthesizing the intermediate speech using the recognized words.
7. The method of converting source speech of claim 1, wherein the step of converting the target speech sequence to target speech using the pitch from the target voice training data comprises: generating spectra from the target speech sequence; generating an excitation signal from the pitch; and convolving the excitation signal with generated spectra.
8. The method of converting source speech of claim 1, wherein the intermediate speech data is selected from a plurality of speech corpora.
9. The method of converting source speech of claim 8, wherein the intermediate speech data is selected from the plurality of intermediate speech corpora based on similarity between the plurality of intermediate speech corpora and target speech training data.
10. The method of converting source speech of claim 9, wherein similarity is based on one or more of the following attributes: gender, age, ethnicity, native language or accent.
11. A method of converting source speech to target speech, the method comprising: receiving target voice training data, wherein the target voice training data is speech; extracting a first set of spectral features and pitch from the target voice training data; retrieving, based on the first set of spectral features, a second set of spectral features for an intermediate speaker that match target voice training data; perform dynamic time warping to match the second set of spectral features and the first set of spectral features; training a neural network to convert the second set of spectral features to the first set of spectral features; acquiring, with a mobile phone, source speech data from a source speaker, wherein the source speech data is speech; converting the source speech data to an intermediate speech, wherein the intermediate speech is speech; converting the intermediate speech to a target speech sequence using the neural network, wherein the target speech sequence is speech; converting the target speech sequence to target speech audio using the pitch from the target voice training data; and playing, with the mobile phone, the target speech audio to the source speaker.
12. A system for converting source speech to target speech, the system comprising a processor configured to: receive target voice training data, wherein the target voice training data is speech; recognize a plurality of words spoken by a target speaker from the target voice training data; retrieve intermediate speech based on the recognized words; perform dynamic time warping to align the retrieve intermediate speech with the corresponding target voice training data; train a neural network to convert the aligned intermediate speech to target speech training data; acquire, with a mobile phone, source speech data from a source speaker; convert the source speech data to an intermediate speech, wherein the intermediate speech is speech; convert the intermediate speech to a target speech sequence using the neural network, wherein the target speech sequence is speech; convert the target speech sequence to target speech audio; and playing, with the mobile phone, target speech audio to the source speaker.
</claims>
</document>
