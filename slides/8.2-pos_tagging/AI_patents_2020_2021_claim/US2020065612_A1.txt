<document>

<filing_date>
2019-08-26
</filing_date>

<publication_date>
2020-02-27
</publication_date>

<priority_date>
2018-08-27
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N3/02,G09B19/00,G10L15/26,G10L25/51
</ipc_classes>

<assignee>
TALKMEUP
</assignee>

<inventors>
ZHU, CHENCHEN
XU, JIAOJIAO
XU, YI
SPETTEL, MATTHEW THOMAS
</inventors>

<docdb_family_id>
69583764
</docdb_family_id>

<title>
INTERACTIVE ARTIFICIAL INTELLIGENCE ANALYTICAL SYSTEM
</title>

<abstract>
A method and system for an Al-based communication training system for individuals and organizations is disclosed. A video analyzer is used to convert a video signal into a plurality of human morphology features with an accompanying audio analyzer converting an audio signal into a plurality of human speech features. A transformation module transforms the morphology features and the speech features into a current multi-dimensional performance vector and combinatorial logic generates an integration of the current multi-dimensional performance vector and one or more prior multi-dimensional performance vectors to generate a multi-session rubric. Backpropagation logic applies a current multi-dimensional performance vector from the combinatorial logic to the video analyzer and the audio analyzer.
</abstract>

<claims>
1. A system comprising: a video analyzer to convert a video signal into a plurality of human morphology features; an audio analyzer to convert an audio signal into a plurality of human speech features; a transformation module to transform the morphology features and the speech features into a current multi-dimensional performance vector; combinatorial logic to generate an integration of the current multi-dimensional performance vector and one or more prior multi-dimensional performance vectors to generate a multi-session rubric; and backpropagation logic to apply the current multi-dimensional performance vector from the combinatorial logic to the video analyzer and the audio analyzer.
2. The system of claim 1, further comprising a model control to control the combinatorial logic.
3. The system of claim 1, wherein the video analyzer comprises one or more models embodied in a neural network.
4. The system of claim 3, wherein the neural network comprises at least one convolutional neural network.
5. The system of claim 3, wherein the neural network comprises at least one convolutional neural network coupled to at least one recurrent neural network.
6. The system of claim 1, further comprising a speech-to-text converter.
7. The system of claim 6, further comprising a natural language processor coupled to receive text from the speech-to-text converter.
8. The system of claim 1, the audio analyzer comprising a canny edge detector and a Fast Fourier Transform.
9. A method comprising: converting a video signal into a plurality of human morphology features; converting an audio signal into a plurality of human speech features; transforming the morphology features and the speech features into a current multi-dimensional performance vector; combining the current multi-dimensional performance vector and one or more prior multi-dimensional performance vectors to generate a multi-session rubric; and applying the current multi-dimensional performance vector as an adaptive feedback signal to a video analyzer and an audio analyzer.
10. The method of claim 9, wherein combining the current multi-dimensional performance vector and one or more prior multi-dimensional performance vectors uses combinatorial logic controlled by model control.
11. The method of claim 9, wherein converting a video signal into a plurality of human morphology features uses the video analyzer comprised of one or more models embodied in a neural network.
12. The method of claim 11, wherein the neural network comprises at least one convolutional neural network.
13. The method of claim 11, wherein the neural network comprises at least one convolutional neural network coupled to at least one recurrent neural network.
14. The method of claim 9, wherein transforming the speech features uses a speech-to-text converter.
15. The method of claim 14, further using a natural language processor coupled to receive text from the speech-to-text converter.
16. The method of claim 9, where converting an audio signal into a plurality of human speech features uses the audio analyzer comprising a canny edge detector and a Fast Fourier Transform.
17. A non-transitory computer-readable storage medium, the computer-readable storage medium including instructions that when executed by a processor, cause a machine comprising the processor to: convert a video signal into a plurality of human morphology features; convert an audio signal into a plurality of human speech features; transform the morphology features and the speech features into a current multi-dimensional performance vector; combine the current multi-dimensional performance vector and one or more prior multi-dimensional performance vectors to generate a multi-session rubric; and apply the current multi-dimensional performance vector as an adaptive feedback signal to a video analyzer and an audio analyzer.
18. The non-transitory computer-readable storage medium of claim 17, the computer-readable storage medium further including instructions that when executed by the processor, cause the machine comprising the processor to: apply a model control to control the combinatorial logic.
19. The non-transitory computer-readable storage medium of claim 17, the computer-readable storage medium further including instructions that when executed by the processor, cause the machine comprising the processor to: convert a video signal into a plurality of human morphology features uses the video analyzer comprised of one or more models embodied in a neural network; transform the speech features uses a speech-to-text converter; and convert an audio signal into a plurality of human speech features uses the audio analyzer comprising a canny edge detector and a Fast Fourier Transform.
20. The non-transitory computer-readable storage medium of claim 19, wherein: the neural network comprises at least one convolutional neural network; and the neural network comprises the convolutional neural network coupled to at least one recurrent neural network.
</claims>
</document>
