<document>

<filing_date>
2017-04-25
</filing_date>

<publication_date>
2020-11-04
</publication_date>

<priority_date>
2016-05-18
</priority_date>

<ipc_classes>
G06F1/16,G06F3/01,G06F3/0346,G06F3/038,G06F3/16,H04W52/02
</ipc_classes>

<assignee>
SONY CORPORATION
SONY MOBILE COMMUNICATIONS
</assignee>

<inventors>
AOYAMA, RYU
HIROSE, YOJI
MIZUKAMI, TOMOO
TAKAHASHI, KEI
YAMANO, IKUO
</inventors>

<docdb_family_id>
58709767
</docdb_family_id>

<title>
INFORMATION PROCESSING OF COMBINED VOICE AND GESTURE INPUT OPERATIONS
</title>

<abstract>
There is provided an information processing apparatus including: a process execution unit configured to execute processes relating to voice operations recognized by a voice operation recognition unit configured to recognize the voice operations on a basis of information from a voice receiving unit and gesture operations recognized by a gesture recognition unit configured to recognize user's gestures recognized on a basis of information from a sensor. The voice operation recognition unit enters a voice operation waiting state in parallel with a gesture waiting state of the gesture recognition unit.
</abstract>

<claims>
1. An information processing apparatus (200) comprising: a process execution unit (216) configured to execute processes relating to voice operations recognized by a voice operation recognition unit (214) configured to recognize the voice operations on a basis of information from a voice receiving unit (110) and gesture operations recognized by a gesture recognition unit (210) configured to recognize user's gestures recognized on a basis of information from an acceleration sensor (118) and/or a gyro sensor (120), wherein the voice operation recognition unit (214) enters a voice operation waiting state to wait for a voice operation of a user in parallel with a gesture waiting state to wait for a gesture operation of the user of the gesture recognition unit,
the apparatus being characterised in that the gesture recognition unit includes a machine learning determination unit configured to recognize the gesture on a basis of a result of learning with machine learning, and a rule determination unit configured to recognize the gesture on a basis of a predetermined rule, and the gesture recognition unit recognizes the gesture when both the machine learning determination unit and the rule determination unit recognize the gesture.
2. The information processing apparatus according to claim 1, wherein
the gesture recognition unit enters the gesture waiting state in synchronization with entering of the voice operation recognition unit into the voice operation waiting state.
3. The information processing apparatus according to claim 2, wherein
the process execution unit executes an application, and
the voice operation recognition unit enters the voice operation waiting state on a basis of a notification from the application being executed by the process execution unit.
4. The information processing apparatus according to claim 1, wherein
the process execution unit executes a process relating to an operation recognized by the voice operation recognition unit in preference to an operation recognized by the gesture recognition unit.
5. The information processing apparatus according to claim 1, further comprising
an operation-unit-operation recognition unit configured to recognize a user's operation to an operation unit, wherein
the operation-unit-operation recognition unit enters an operation-unit-operation waiting state in parallel with the gesture waiting state of the gesture recognition unit and the voice operation waiting state of the voice operation recognition unit.
6. The information processing apparatus according to claim 5, wherein
the process execution unit executes a process relating to an operation recognized by the operation-unit-operation recognition unit in preference to an operation recognized by the voice operation recognition unit.
7. The information processing apparatus according to claim 5, wherein
weighting is performed on each of an operation recognized by the gesture recognition unit, an operation recognized by the voice operation recognition unit, and an operation recognized by the operation-unit-operation recognition unit, and
the process execution unit determines a process to be executed preferentially in consideration of the weighting.
8. The information processing apparatus according to claim 5, wherein
the process execution unit executes a process combining at least two of an operation recognized by the gesture recognition unit, an operation recognized by the voice operation recognition unit, and an operation recognized by the operation-unit-operation recognition unit.
9. The information processing apparatus according to claim 3, wherein
a mode of said acceleration sensor and/or gyro sensor to be activated is selected in accordance with a notification from the application or a type of the application.
10. The information processing apparatus according to claim 3, wherein
said acceleration sensor and/or gyro sensor includes a plurality of sensors, and a sensor to be activated is selected in accordance with a notification from the application or a type of the application.
11. The information processing apparatus according to claim 1, wherein
the gesture recognition unit recognizes a first gesture when acceleration or angular velocity which is smaller than a predetermined value is detected, and recognizes a second gesture when acceleration or angular velocity which is larger than the predetermined value is detected.
12. The information processing apparatus according to claim 1, wherein
the gesture recognition unit recognizes a first gesture when a same gesture is recognized a smaller number of times than a predetermined number of times, and recognizes a second gesture when a same gesture is recognized a larger number of times than the predetermined number of times.
13. An information processing method to be executed by an information processing apparatus, the method comprising: executing processes relating to voice operations recognized on a basis of information from a voice receiving unit (110) and operations relating to gestures recognized on a basis of information from ; an acceleration sensor (118) and/or a gyro sensor (120), and allowing coexistence of a voice operation waiting state (S204) in which the voice operation is to be recognized, and a gesture waiting state (S206) in which the gesture is to be recognized,
the method being characterised in that the step of recognising gestures comprises the steps of: recognising the gesture on the basis of a result of learning with machine learning; recognising the gesture on the basis of a predetermined rule; and recognising the gesture when both the step of recognising the gesture on the basis of a result of learning with machine learning and the step of recognising the gesture on the basis of a predetermined rule recognise the gesture.
14. A computer program comprising computer readable instructions which, when loaded onto a computer, configure the computer to perform a method according to claim 13.
</claims>
</document>
