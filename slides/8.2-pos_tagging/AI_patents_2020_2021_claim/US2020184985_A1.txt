<document>

<filing_date>
2019-12-06
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-06
</priority_date>

<ipc_classes>
G10L15/22,G10L21/02,G10L25/60,G10L25/84,H04R1/40,H04R3/00,H04S3/00
</ipc_classes>

<assignee>
SYNAPTICS
</assignee>

<inventors>
NESTA, FRANCESCO
KASKARI, SAEED MOSAYYEBPOUR
</inventors>

<docdb_family_id>
70970205
</docdb_family_id>

<title>
MULTI-STREAM TARGET-SPEECH DETECTION AND CHANNEL FUSION
</title>

<abstract>
Audio processing systems and methods include an audio sensor array configured to receive a multichannel audio input and generate a corresponding multichannel audio signal and target-speech detection logic and an automatic speech recognition engine or VoIP application. An audio processing device includes a target speech enhancement engine configured to analyze a multichannel audio input signal and generate a plurality of enhanced target streams, a multi-stream target-speech detection generator comprising a plurality of target-speech detector engines each configured to determine a probability of detecting a specific target-speech of interest in the stream, wherein the multi-stream target-speech detection generator is configured to determine a plurality of weights associated with the enhanced target streams, and a fusion subsystem configured to apply the plurality of weights to the enhanced target streams to generate an enhancement output signal.
</abstract>

<claims>
1. A system comprising: a target speech enhancement engine configured to analyze a multichannel audio input signal and generate a plurality of enhanced target streams; a multi-stream target-speech detector generator comprising a plurality of target-speech detector engines each configured to determine a confidence of quality and/or presence of a specific target-speech in the stream, wherein the multi-stream target-speech detection generator is configured to determine a plurality of weights associated with the enhanced target streams; and a fusion subsystem configured to apply the plurality of weights to the enhanced target streams to generate a combined enhanced output signal.
2. The system of claim 1, further comprising an audio sensor array configured to sense human speech and environmental noise and generate a corresponding the multichannel audio input signal.
3. The system of claim 1, wherein the target speech enhancement engine comprises a plurality of speech enhancement modules, each speech enhancement module configured to analyze the multichannel audio input signal and output one of the enhanced target streams.
4. The system of claim 3, wherein the plurality of speech enhancement modules comprise an adaptive spatial filtering algorithm, a beamforming algorithm, a blind source separation algorithm, a single channel enhancement algorithm, and/or a neural network.
5. The system of claim 1, wherein the target-speech detector engines comprise Gaussian Mixture Models, Hidden Markov Models, and/or a neural network.
6. The system of claim 1, wherein each target speech detector engine is configured to produce a posterior weight correlated to a confidence that an input audio stream includes the specific target speech
7. The system of claim 6, wherein each target-speech detector engine is configured to produce a higher posterior with clean speech.
8. The system of claim 1, wherein the enhanced output signal is a weighted sum of the enhanced target streams.
9. The system of claim 1, wherein the multi-stream target-speech detection generator is further configured to determine a combined probability of detecting a specific target speech in the streams, and wherein the target-speech is detected if the combined probability exceeds a detection threshold.
10. The system of claim 9, further comprising an automatic speech recognition engine or a VoIP application, and wherein the enhanced output signal is forwarded to the automatic speech recognition engine or VoIP if the target-speech is detected.
11. A method comprising: analyzing, using a target speech enhancement engine, a multichannel audio input signal and generating a plurality of enhanced target streams; determining a probability of detecting a target-speech in the stream using a multi-stream target-speech detector generator; calculating a weight for each of the enhanced target streams; and applying the calculated weights to the enhanced target streams to generate an enhanced output signal.
12. The method of claim 11, further comprising sensing human speech and environmental noise, using an audio sensor array, and generating a corresponding the multichannel audio input signal.
13. The method of claim 11, wherein analyzing the multichannel audio input signal comprises applying a plurality of speech enhancement modalities, each speech enhancement modality outputting a separate one of the enhanced target streams.
14. The method of claim 13, wherein the plurality of speech enhancement modalities comprises an adaptive spatial filtering algorithm, a beamforming algorithm, a blind source separation algorithm, a single channel enhancement algorithm, and/or a neural network.
15. The method of claim 11, wherein determining the probability of detecting the target-speech in the stream comprises applying Gaussian Mixture Models, Hidden Markov Models, and/or a neural network.
16. The method of claim 11, wherein determining the probability of detecting the target-speech in the stream comprises producing a posterior weight correlated to a confidence that the input stream includes a keyword.
17. The method of claim 16, further comprising producing a higher posterior with clean speech.
18. The method of claim 11, wherein the enhanced output signal is a weighted sum of the enhanced target streams.
19. The method of claim 11, further comprising determining a combined probability of detecting the target-speech in the streams; and wherein the target-speech is detected if the combined probability exceeds a detection threshold.
20. The method of claim 19, further comprising performing automatic speech recognition on the enhanced output signal if the target-speech is detected.
</claims>
</document>
