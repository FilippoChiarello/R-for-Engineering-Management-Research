<document>

<filing_date>
2019-03-27
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-27
</priority_date>

<ipc_classes>
G06F3/16,G10L15/22
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
COHEN, EYAL
LIMONAD, LIOR
Abitbol, Roy
</inventors>

<docdb_family_id>
72607986
</docdb_family_id>

<title>
INTERACTION CONTEXT-BASED CONTROL OF OUTPUT VOLUME LEVEL
</title>

<abstract>
A method, apparatus and product for interaction context-based control of output volume level. The method comprising: obtaining a vocal input from a user, wherein the vocal input is part of an interaction between the user and the voice-based interaction agent; determining an interaction context of the interaction between the user and the voice-based interaction agent; determining an output volume level of the voice-based interaction agent based on the interaction context; and providing to the user an output of the voice-based interaction agent, wherein the output comprises a voice-based output having a volume level of the output volume level.
</abstract>

<claims>
1. A method comprising: obtaining a vocal input from a user, wherein the vocal input is part of an interaction between the user and the voice-based interaction agent; determining an interaction context of the interaction between the user and the voice-based interaction agent; determining an output volume level of the voice-based interaction agent based on the interaction context; and providing to the user an output of the voice-based interaction agent, wherein the output comprises a voice-based output having a volume level of the output volume level.
2. The method of claim 1, wherein said providing to the user the output is performed using a speaker; wherein said determining the interaction context comprises determining a distance of the user from the speaker; and wherein said determining the output level is performed based on the distance.
3. The method of claim 2, wherein said obtaining the vocal input is performed using a microphone; wherein the microphone is physically separated from the speaker, whereby a distance of the user from the speaker is potentially different than the distance of the user from the microphone.
4. The method of claim 1 further comprises: determining a vocal input level of the vocal input; wherein said determining the interaction context comprises determining a facial direction of the user while providing the vocal input; and wherein said determining the output volume level is performed based on the vocal input level and based on the facial direction of the user.
5. The method of claim 1, wherein the interaction context comprises a profile of the user, wherein said determining the output volume level is performed based on the profile of the user.
6. The method of claim 5, wherein the profile of the user comprises at least one of: a demographic attribute of the user; an interaction history of the user with the voice-based interaction agent; and a medical profile of the user.
7. The method of claim 1, wherein said determining the interaction context comprises: determining an input volume level of the vocal input; and comparing the input volume level of the vocal input with historic volume levels of vocals of the user, whereby determining a relative volume level of the vocal input; and wherein said determining the output volume level is performed based on the relative volume level of the vocal input.
8. The method of claim 1, wherein said determining the interaction context comprises analyzing a background noise; wherein said determining the output volume level is performed based on the background noise.
9. The method of claim 1, wherein the interaction context comprises a surrounding context, wherein the surrounding context is indicative of an existence of one or more additional people in a surrounding of the user; and wherein said determining the output volume level of the voice-based interaction agent is performed based on the surrounding context.
10. The method of claim 1, wherein said determining the interaction context comprises determining a layout context, wherein the layout context is indicative of an existence of audio-absorption items in a surrounding of the voice-based interaction agent; and wherein said determining the output volume level of the voice-based interaction agent is performed based on the layout context.
11. The method of claim 1, wherein said determining the interaction context comprises determining an expected absorption of an audio wave emitted by the voice-based interaction agent before the audio wave reaches the user; wherein said determining the output volume level of the voice-based interaction agent is performed based on the expected absorption.
12. The method of claim 1, wherein the output volume level is a muted volume level.
13. A non-transitory computer readable medium retaining program instructions, which program instructions when read by a processor, cause the processor to perform: determining an input volume level of a vocal input from a user, wherein the vocal input is part of an interaction between the user and a voice-based interaction agent; determining an output volume level of the voice-based interaction agent based on the input volume level, wherein the output volume level is determined in an inverse direction to the input volume level; and providing to the user an output of the voice-based interaction agent, wherein the output comprises a voice-based output having a volume level of the output volume level.
14. A non-transitory computer readable medium retaining program instructions, which program instructions when read by a processor, cause the processor to perform: obtaining a vocal input from a user, wherein the vocal input is part of an interaction between the user and the voice-based interaction agent; determining an interaction context of the interaction between the user and the voice-based interaction agent; determining an output volume level of the voice-based interaction agent based on the interaction context; and providing to the user an output of the voice-based interaction agent, wherein the output comprises a voice-based output having a volume level of the output volume level.
15. The non-transitory computer readable medium of claim 14, wherein said providing to the user the output is performed using a speaker; wherein said determining the interaction context comprises determining a distance of the user from the speaker; and wherein said determining the output level is performed based on the distance.
16. The non-transitory computer readable medium of claim 14, wherein the program instructions are further configured to cause the processor to determine a vocal input level of the vocal input; wherein said determining the interaction context comprises determining a facial direction of the user while providing the vocal input; and wherein said determining the output volume level is performed based on the vocal input level and based on the facial direction of the user.
17. The non-transitory computer readable medium of claim 14, wherein the interaction context comprises a profile element of the user, wherein said determining the output volume level is performed based on the profile of the user, wherein the profile element is at least one of: a demographic attribute of the user, an interaction history of the user with the voice-based interaction agent, and a medical profile of the user.
18. The non-transitory computer readable medium of claim 14, wherein said determining the interaction context comprises analyzing a background noise; wherein said determining the output volume level is performed based on the background noise.
19. The non-transitory computer readable medium of claim 14, wherein the interaction context comprises a surrounding context, wherein the surrounding context is indicative of an existence of one or more additional people in a surrounding of the user; and wherein said determining the output volume level of the voice-based interaction agent is performed based on the surrounding context.
20. The non-transitory computer readable medium of claim 14, wherein said determining the interaction context comprises determining a layout context, wherein the layout context is indicative of an existence of audio-absorption items in a surrounding of the voice-based interaction agent; and wherein said determining the output volume level of the voice-based interaction agent is performed based on the layout context.
</claims>
</document>
