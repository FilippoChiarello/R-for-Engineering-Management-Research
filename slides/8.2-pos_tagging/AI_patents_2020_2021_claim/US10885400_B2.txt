<document>

<filing_date>
2018-09-27
</filing_date>

<publication_date>
2021-01-05
</publication_date>

<priority_date>
2018-07-03
</priority_date>

<ipc_classes>
G06K9/00,G06K9/32,G06K9/66,G06N3/08
</ipc_classes>

<assignee>
GE (GENERAL ELECTRIC COMPANY)
</assignee>

<inventors>
AVINASH, GOPAL
ZHANG, MIN
ZHAO, QIAN
</inventors>

<docdb_family_id>
67297422
</docdb_family_id>

<title>
Classification based on annotation information
</title>

<abstract>
Systems and techniques for classification based on annotation information are presented. In one example, a system trains a convolutional neural network based on training data and a plurality of images. The plurality of images is associated with a plurality of masks, a plurality of image level labels, and/or a bounding box. The system also generates a first loss function based on the plurality of masks, a second loss function based on the plurality of image level labels, and a third loss function based on the bounding box. Furthermore, the system generates a fourth loss function based on the first loss function, the second loss function and the third loss function, where the fourth loss function is iteratively back propagated to tune parameters of the convolutional neural network. The system also predicts a classification label for an input image based on the convolutional neural network.
</abstract>

<claims>
1. A machine learning system, comprising: a memory that stores computer executable components; a processor that executes the computer executable components stored in the memory, wherein the computer executable components comprise: a training component that trains a convolutional neural network based on training data associated with a plurality of patients and a plurality of images, wherein the training data is received from at least one imaging device, wherein respective images of the plurality of images are associated with a plurality of masks, a plurality of image level labels, and a bounding box that links a region of interest to a class label and comprises a set of coordinates for a location of the region of interest within the respective images; a first loss function component that generates a first loss function based on the plurality of masks; a second loss function component that generates a second loss function based on the plurality of image level labels for the plurality of images; a third loss function component that generates a third loss function based on the bounding box that links the region of interest to the class label; a fourth loss function component that generates a fourth loss function based on the first loss function, the second loss function and the third loss function, wherein the fourth loss function is iteratively back propagated to tune parameters of the convolutional neural network; and a classification component that predicts a classification label for an input image based on the convolutional neural network.
2. The machine learning system of claim 1, wherein the convolutional neural network comprises a pretrained classifier network that outputs convolutional feature maps.
3. The machine learning system of claim 2, wherein the convolutional neural network comprises a classification/localization network that outputs corresponding localization maps based on the convolutional feature maps.
4. The machine learning system of claim 2, wherein a first size of the bounding box is matched with a second size of a convolutional feature map from the convolutional feature maps.
5. The machine learning system of claim 2, wherein a first size of a mask from the plurality of masks is matched with a second size of a convolutional feature map from the convolutional feature maps based on a mask pooling process.
6. The machine learning system of claim 1, wherein the first loss function component generates the first loss function based on a probability for a class associated with the plurality of masks.
7. The machine learning system of claim 1, wherein the second loss function component generates the second loss function based on a probability for a class associated with the plurality of image level labels.
8. The machine learning system of claim 1, wherein the fourth loss function component applies a first weight to the first loss function, applies a second weight to the second loss function, and applies a third weight to the third loss function.
9. The machine learning system of claim 1, wherein the computer executable components further comprise: a visualization component that generates a multi-dimensional visualization associated with the classification label for the input image.
10. A method, comprising using a processor operatively coupled to memory to execute computer executable components to perform the following acts: receiving, from at least one imaging device, a plurality of images associated with a plurality of patients; receiving a plurality of masks, wherein respective images of the plurality of images comprises at least one mask of the plurality of masks, wherein the at least one mask associates an object of interest with a corresponding class label, at least one image level label for the respective images, and a bounding box that links the object of interest to the corresponding class label, wherein the least one image level label comprises a description of a region of interest, and wherein the bounding box comprises a height value and a width value for a location associated with the region of interest; training a convolutional neural network based on the plurality of images, the plurality of masks, the bounding box, and the at least one image level label, wherein the convolutional neural network comprises a pretrained classifier network that outputs convolutional feature maps, and a classification/localization network that outputs corresponding localization maps; generating a first loss function based on the plurality of masks; generating a second loss function based on the at least one image level label for the respective images; generating a third loss function based on the bounding box that links the object of interest to the corresponding class label; generating a fourth loss function based on the first loss function, the second loss function and the third loss function; iteratively back propagating the fourth loss function to tune parameters of the convolutional neural network; and predicting a classification label for an input image based on the convolutional neural network.
11. The method of claim 10, further comprising matching a first size of the bounding box with a second size of a convolutional feature map from the convolutional feature maps.
12. The method of claim 10, further comprising matching a first size of a mask from the plurality of masks with a second size of a convolutional feature map from the convolutional feature maps based on a mask pooling process.
13. The method of claim 10, wherein the generating the first loss function comprises generating the first loss function based on a probability for a class associated with the plurality of masks.
14. The method of claim 10, wherein the generating the second loss function comprises generating the second loss function based on a probability for a class associated with the at least one image level label.
15. The method of claim 10, wherein the generating the fourth loss function comprises applying a first weight to the first loss function, applying a second weight to the second loss function, and applying a third weight to the third loss function.
16. The method of claim 10, further comprising generating a multi-dimensional visualization associated with the classification label for the input image.
17. A computer readable storage device comprising instructions that, in response to execution, cause a system comprising a processor to perform operations, the operations comprising: receiving, from at least one imaging device, a plurality of images associated with a plurality of patients; receiving a plurality of masks, wherein respective images of the plurality of images comprise at least one mask of the plurality of masks, wherein the at least one mask associates an object of interest with a corresponding class label, at least one image level label for the respective image, and a bounding box that links the object of interest to the corresponding class label, and wherein the bounding box comprises a set of coordinates that provide an indication of a location, within the respective images, for a region of interest; training a convolutional neural network based on the plurality of images, the plurality of masks, the bounding box, and the at least one image level label, wherein the convolutional neural network comprises a pretrained classifier network that outputs convolutional feature maps, and a classification/localization network that outputs corresponding localization maps; generating a first loss function based on the plurality of masks; generating a second loss function based on the at least one image level label for the image; generating a third loss function based on the bounding box that links the object of interest to the corresponding class label; generating a fourth loss function based on the first loss function, the second loss function and the third loss function; iteratively back propagating the fourth loss function to tune parameters of the convolutional neural network; and predicting a classification label for an input image based on the convolutional neural network.
18. The computer readable storage device of claim 17, wherein the generating the first loss function comprises generating the first loss function based on a probability for a class associated with the plurality of masks.
19. The computer readable storage device of claim 17, wherein the generating the second loss function comprises generating the second loss function based on a probability for a class associated with the at least one image level label.
20. The computer readable storage device of claim 17, wherein the operations further comprise generating a multi-dimensional visualization associated with the classification label for the input image.
</claims>
</document>
