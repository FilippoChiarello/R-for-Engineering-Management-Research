<document>

<filing_date>
2016-12-28
</filing_date>

<publication_date>
2020-09-08
</publication_date>

<priority_date>
2016-11-17
</priority_date>

<ipc_classes>
G06F16/28,G06F16/35,G06K9/62,G06N20/00,G06N5/04,G06N7/00,G06N99/00
</ipc_classes>

<assignee>
ITRI (INDUSTRIAL TECHNOLOGY RESEARCH INSTITUTE)
</assignee>

<inventors>
CHUEH, CHUANG-HUA
HSIEH, HSIN-LUNG
</inventors>

<docdb_family_id>
61728433
</docdb_family_id>

<title>
Ensemble learning prediction apparatus and method, and non-transitory computer-readable storage medium
</title>

<abstract>
The disclosure is directed to an ensemble learning prediction apparatus. The apparatus includes a loss module, a diversity module, a sample weight module, and an integrating weight module. The loss module, the diversity module and the sample weight module calculate a loss, a diversity and a sample weight, respectively. An ensemble weight is learned by an object function built by the loss, diversity and the sample weight. The integrating weight module calculates an adaptive ensemble weight by integrating the ensemble weight and previous ensemble weights at a plurality of previous time points.
</abstract>

<claims>
1. An ensemble learning prediction apparatus, comprising: a loss module receiving a sample data and calculating a loss according to a first prediction result of the sample data and an actual result; a diversity module receiving the sample data and calculating a diversity between at least one hypothesis according to a second prediction result of the sample data under the at least one hypothesis; a sample weighting module calculating a correctable value of the sample data according to the first prediction result and the actual result and assigning a sample weight according to the correctable value; and an integrating weighting module, interconnected with the loss module, the diversity module and the sample weighting module, creating an object function according to the loss, the diversity and the sample weight, and training an ensemble weight by use of the object function; wherein an adaptive ensemble weight is calculated by integrating the ensemble weight and the ensemble weight obtained at previous time points, and the correctable value is obtained according to a function having a high point from which the function descends to both sides on which the high point no more appears.
2. The apparatus according to claim 1, wherein the correctable value is obtained according to a difference between a target class and an erroneous class of the sample data.
3. The apparatus according to claim 1, wherein the function is a bilateral decreasing function, a quadratic function having a high point, a polynomial function having a high point, or a combination thereof.
4. The apparatus according to claim 1, wherein when at least one prediction of some of the sample data generated under the most of the at least one hypothesis is totally correct or erroneous, the correctable value which is small is provided; for other sample data, the correctable value which is large is provided.
5. The apparatus according to claim 1, wherein a product is obtained by multiplying the loss obtained by the loss module by the correctable value obtained by the sample weighting module for each sample of the sample data, a sum is obtained by summing up the products for all samples of the sample data, another product is obtained by multiplying the diversity obtained by the diversity module by a regularization parameter, and the ensemble weight obtained via the object function is obtained by subtracting the another product by the sum.
6. The apparatus according to claim 1, wherein the correctable value is calculated according to the sample weight and the first prediction result of the sample data observed at a previous time point and the actual result.
7. The apparatus according to claim 1, wherein for the adaptive ensemble weight, a larger weight is assigned to the sample data observed at a time point closer to a current time point and a smaller weight is assigned to the sample data observed at a time point farther away from the current time point.
8. The apparatus according to claim 1, wherein the adaptive ensemble weight is stored in a data medium.
9. The apparatus according to claim 1, wherein the diversity is calculated from a contingency table.
10. The apparatus according to claim 9, wherein the contingency table has binary classification.
11. The apparatus according to claim 9, wherein the contingency table has multi-class classification.
12. The apparatus according to claim 1, wherein the sample weight of each sample of the sample data is different.
13. An ensemble learning method, comprising: calculating a loss according to a first prediction result and an actual result of a sample data; calculating a diversity between at least one hypothesis according to a second prediction result of the sample data under the at least one hypothesis; calculating a correctable value of the sample data according to the first prediction result and the actual result, and assigning a sample weight according to the correctable value; and creating an object function according to the loss, the diversity and the sample weight, and training an ensemble weight by use of the object function; wherein an adaptive ensemble weight is calculated by integrating the ensemble weight and the ensemble weight obtained at previous time points, and the correctable value is obtained according to a function having a high point from which the function descends to both sides on which the high point no more appears.
14. The method according to claim 13, wherein the correctable value is obtained according to a difference between a target class and an erroneous class of the sample data.
15. The apparatus according to claim 13, wherein the function is a bilateral decreasing function, a quadratic function having a high point, a polynomial function having a high point, or a combination thereof.
16. The method according to claim 13, wherein when at least one of some of the sample data generated under most of the at least one the hypothesis is totally correct or erroneous, the correctable value which is small is provided; for other sample data, the correctable value which is large is provided.
17. The method according to claim 13, wherein the diversity is calculated from a contingency table.
18. The method according to claim 17, wherein the contingency table has binary classification.
19. The method according to claim 17, wherein the contingency table has multi-class classification.
20. The method according to claim 17, wherein the sample weight of each sample of the sample data is different.
21. The method according to claim 13, wherein the correctable value is calculated according to the sample weight and the first prediction result of the sample data observed at a previous time point and the actual result.
22. The method according to claim 13, wherein for the adaptive ensemble weight, a larger weight is assigned to the sample data observed at a time point closer to a current time point and a smaller weight is assigned to the sample data observed at a time point farther away from the current time point.
23. The method according to claim 13, wherein the adaptive ensemble weight is stored in a data medium.
24. The method according to claim 13, wherein a product is obtained by multiplying the loss by the correctable value for each sample of the sample data, a sum is obtained by summing up the products for all samples of the sample data, another product is obtained by multiplying the diversity by a regularization parameter, and the ensemble weight obtained via the object function is obtained by subtracting the another product by the sum.
25. A non-transitory computer-readable storage medium used in a computer program product comprising a plurality of instructions allocated to a computing device executing the method as claimed in claim 13.
</claims>
</document>
