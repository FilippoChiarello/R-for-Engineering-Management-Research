<document>

<filing_date>
2019-06-19
</filing_date>

<publication_date>
2020-08-25
</publication_date>

<priority_date>
2019-04-10
</priority_date>

<ipc_classes>
G01N21/88,G06T7/00,G06T7/521,G06T7/62,H04N7/18
</ipc_classes>

<assignee>
GRIFFYN ROBOTECH PRIVATE
</assignee>

<inventors>
WAROKAR, NIKHIL SUBHASH
ANAND, DEEPAK
ALHAT, VIDULA PREMANTH
BAGALKOTE, SAMIR SHRIRAM
MAHAJAN, AMIT ANIL
JATHAR, AMEYA ANIL
</inventors>

<docdb_family_id>
72140701
</docdb_family_id>

<title>
Inspection and cosmetic grading through image processing system and method
</title>

<abstract>
A system and method for inspection and cosmetic grading of objects is provided. Camera and lighting assemblies capture images of an object and create a 2D composite image which is processed by an image processing module with a deep learning machine algorithm to detect surface defects in the object. Detected defects are localized and measured for depth of defect by an advanced optical sensor, providing a 3D representation of defects. A cosmetic grading algorithm determines the cosmetic grade of the object and the optimal path of disposition for the item based on the grade.
</abstract>

<claims>
1. A device for inspecting and evaluating object surface defects, comprising: a computing device with one or more processors and memory; an automated control system controlled by a processor, operatively configured to receive instructions from a control module comprising computer-executable instructions which when executed by the processor direct the automated control system interaction with an object comprised of one or more materials; an image capture subsystem controlled by a processor, operatively configured to determine image capture conditions, direct lighting system adjustments, capture images of objects and transmit image signals to an image processing module; a lighting subsystem controlled by a processor and operatively configured to receive and follow instructions from the image capture subsystems regarding lighting conditions, wherein the lighting subsystem makes adjustments to illumination placement and intensity as directed by the image capture subsystem; an image processing module stored in computing device memory which when executed by a processor performs image processing steps comprising: (i) receiving a signal from the image capture subsystem (ii) processing the signal to capture an image of an object, (iii) determining the two-dimensional coordinate center of the object evaluation area, (iv) detecting, segmenting and classifying the type of each surface defect using deep learning algorithms, (v) measuring defect length and width, (vi) determining the point of highest reflective light intensity for each defect (vii) calculating coordinates for identified defects with respect to the coordinate center of the object evaluation area, (viii) transmitting the coordinates of a defect to the automated object control processor and (ix) storing images and data in memory; and an optical spot sensor subsystem controlled by a processor and operatively configured to measure the depth or protrusion height displacement of a defect at a surface location identified by the image processing module as the point of highest reflective light intensity, such spot sensor measuring depth when the automated control system aligns the object and optical spot sensor at the defect coordinates calculated by the image processing module with reference to the coordinate center of the object face.
2. The device for inspecting and evaluating object surface defects of claim 1, wherein the image processing system evaluating the image for defects further comprises a machine learning system comprising one or more deep learning algorithms and large data sets wherein a deep learning algorithm is chosen from the group: neural network, convolutional neural network, and support vector machine algorithms.
3. The device for inspecting and evaluating object surface defects of claim 1 wherein the computing device further comprises a cosmetic grading module comprising computer executable instructions that determine a cosmetic grade and recommended disposition for the object based on the number and type of defects and a severity for a defect determined by the length, width and depth of a defect and further directs the item to the appropriate bin or bucket for shipment to a final disposition.
4. The device for inspecting and evaluating object surface defects of claim 1, where the computing device further comprises a user interface configured to allow manual input, control and process observation.
5. The apparatus to inspect and evaluate object surface defects of claim 1, wherein the computing device further comprises a communications module providing access to external systems wherein the external systems may provide an object profile comprising identifiable information and attributes for an object.
6. A method for automating determination of a cosmetic grade for an object, comprising: capturing by an image processor, a signal from an image capture subsystem and processing the signal to capture an image of an object; determining, by the image processor, the coordinate location of the object evaluation area physical center and storing the information in a database; transmitting, by the processor, the coordinate location of the object evaluation area physical center to an automated object control system processor; positioning the object, by an automated object controller controlled by the control system processor, in front of a camera in multiple orientations; capturing, by the camera, an image for each of the orientations for which the object was placed by the automated object control system, combining the image for each orientation into a comprehensive image and storing the images in memory; applying one or more deep learning algorithms to the comprehensive image, the deep learning algorithm trained to recognize types of defects expected on the surface of the object and to determine and locate surface defects on the object from the comprehensive image and deep learning algorithm; calculating the coordinates of each identified defect relative to the object evaluation area physical center, the coordinates comprising at least the location of the defect pixel of highest light intensity; counting the number of defects; locating the defects on the object and measuring the length and width of the defects; measuring the depth of a defect by selecting one method from the group consisting of (i) aligning an advanced optical spot sensor with the defect based on the coordinates of the defect relative to the coordinate center of the object and sweeping the sensor spot across the point of highest reflected light intensity; and (ii) applying a machine learning algorithm trained with data collected from advanced optical spot sensor measurements of depth correlated with reflected light intensity at a surface location on the object assigning a cosmetic grade to the object based on applying pre-defined object-specific rules and logic for classifying the cosmetic condition of the object according to an evaluation of the located defects and their measurements; and conveying the object to its final disposition according to its cosmetic grade.
7. The method for automating determination of a cosmetic grade for an object of claim 6, wherein the locating step performed by one or more deep learning algorithms and large data sets wherein the deep learning algorithms are chosen from the group: neural network, convolutional neural network, and support vector machine algorithms.
8. The method for automating determination of a cosmetic grade and disposition for an object of claim 6, where the measuring step further comprises an image processing system to measure length and width.
9. A method for inspecting and evaluating the condition of an object by, comprising: capturing, by a processor, an image of an object; determining, by a processor the two-dimensional coordinate center of the object evaluation area; locating, by an image processing module comprising memory, a processor and computer executable instructions stored in memory, which when executed by the processor, (i) perform detection, location, segmentation and classification of defects on the surface of the object; (ii) the point of highest reflected light intensity for each defect; (iii) defect length and width, and (iv) the coordinates for identified defects with respect to the coordinate center of the object evaluation area; measuring the depth of a defect at the point of highest reflected light intensity, wherein depth is measured by selecting one method from the group consisting of: (i) sweeping an advanced optical spot laser sensor perpendicular to the defect at the point of highest reflected light intensity, and generating a vertical displacement signal and (ii) applying a machine learning algorithm trained with data collected from advanced optical spot sensor measurements of depth correlated with reflected light intensity at a surface location on the object; collecting and storing the data in memory; applying a cosmetic grade for the item based on pre-defined rules and logic and an evaluation of the located defects and their measurements.
10. The method for determining the depth of a surface defect claim 9, wherein the computing device further comprises a communications module providing access to external systems.
</claims>
</document>
