<document>

<filing_date>
2020-03-20
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-27
</priority_date>

<ipc_classes>
G06T7/246
</ipc_classes>

<assignee>
OCELOT LABORATORIES
</assignee>

<docdb_family_id>
70277513
</docdb_family_id>

<title>
PROCESSING OF SIGNALS USING A RECURRENT STATE ESTIMATOR
</title>

<abstract>
In one implementation, a method includes receiving pixel events output by an event sensor that correspond to a feature disposed within a field of view of the event sensor. Each respective pixel event is generated in response to a specific pixel within a pixel array of the event sensor detecting a change in light intensity that exceeds a comparator threshold. A characteristic of the feature is determined at a first time based on the pixel events and a previous characteristic of the feature at a second time that precedes the first time. Movement of the feature relative to the event sensor is tracked over time based on the characteristic and the previous characteristic.
</abstract>

<claims>
1. A method comprising:
receiving pixel events output by an event sensor, each respective pixel event generated in response to a specific pixel within a pixel array of the event sensor detecting a change in light intensity that exceeds a comparator threshold, the pixel events
corresponding to a feature disposed within a field of view of the event sensor;
determining a characteristic of the feature at a first time based on the pixel events and a previous characteristic of the feature at a second time that precedes the first time; and tracking movement of the feature relative to the event sensor over time based on the characteristic and the previous characteristic.
2. The method of claim 1, wherein tracking the movement of the feature excludes deriving image data from the pixel events.
3. The method of claim 1, wherein the previous characteristic is determined at the second time based on earlier pixel events output by the event sensor and an earlier characteristic of the feature determined at a third time that precedes the second time.
4. The method of claim 1, further comprising:
determining updated characteristics of the feature as subsequent pixel events are output by the event sensor.
5. The method of claim 1, further comprising:
generating input for a computing process based on the movement of the feature relative to the event sensor.
6. The method of claim 1, further comprising:
pulsing an optical source at a defined frequency to cause pixels within the pixel array to generate event data at a rate that is proportional to the defined frequency.
7. The method of claim 1, wherein the pixel events corresponding to the feature are spatially and temporally sparse, and wherein tracking the movement of the feature includes:
reconstructing the feature from the pixel events output by the event sensor.
8. A system comprising:
a processor;
an image pipeline; and
a computer-readable storage medium comprising instructions that upon execution by the processor cause the system to perform operations, the operations comprising:
receiving, by the image pipeline, pixel events output by an event sensor comprising a plurality of pixels positioned to receive light from a surface of an eye, each respective pixel event generated in response to a specific pixel within a pixel array of the event sensor detecting a change in light intensity that exceeds a comparator threshold;
determining a gaze characteristic at a first time based on the pixel events and a previous gaze characteristic at a second time that precedes the first time; and
tracking a gaze of the eye based on the gaze characteristic.
9. The system of claim 8, wherein the pixel events correspond to specular reflections of light from the surface of the eye.
10. The system of claim 8, wherein the pixel events correspond to infrared light emitted by an optical source towards the surface of the eye.
11. The system of claim 8, wherein the gaze characteristic is indicative of a center of a pupil of the eye, a contour of the pupil of the eye, or a glint generated using a light emitting diode.
12. The system of claim 8, wherein the instructions, when executed, further cause the system to perform additional operations, the additional operations comprising:
modifying content presented on a display based on the tracking of the gaze.
13. The system of claim 8, wherein the gaze characteristic is a first gaze characteristic indicative of a center of a pupil of the eye or a contour of the pupil of the eye, and wherein tracking the gaze of the eye further comprises:
providing the first gaze characteristic and a second gaze characteristic
corresponding to one or more glint locations as input to a gaze tracking model configured to determine a pose of the eye based on the first gaze characteristic and the second gaze characteristic.
14. The system of claim 13, wherein the gaze tracking model is a neural network.
15. A non-transitory computer-readable storage medium storing program instructions computer-executable on a computer to perform operations comprising:
receiving pixel events output by an event sensor comprising a plurality of pixels positioned to receive light from a scene disposed within a field of view of the event sensor, each respective pixel event generated in response to a specific pixel within the plurality of pixels detecting a change in light intensity that exceeds a comparator threshold;
determining, with a recurrent estimation process, a characteristic of a feature within the field of view at a first time based on the pixel events and a previous characteristic of the feature at a second time that precedes the first time; and
tracking movement of the feature within the field of view using the characteristic.
16. The non-transitory computer-readable storage medium of claim 15, wherein the recurrent estimation process is a recurrent neural network, an infinite input response filter, or a stochastic state estimator.
17. The non-transitory computer-readable storage medium of claim 16, wherein the stochastic state estimator is a Kalman filter or a Particle filter.
18. The non-transitory computer-readable storage medium of claim 15, wherein determining the characteristic of the feature comprises:
providing the pixel events as raw pixel events at an input of the recurrent estimation process.
19. The non-transitory computer-readable storage medium of claim 15, wherein the program instructions are computer-executable on the computer to perform operations comprising:
determining updated characteristics of the feature as subsequent pixel events are output by the event sensor.
20. The non-transitory computer-readable storage medium of claim 15, wherein the recurrent estimation process is configured to retain state information derived from earlier pixel events output by the event sensor.
21. The non-transitory computer-readable storage medium of claim 15, wherein the program instructions are computer-executable on the computer to perform operations comprising:
displaying movement of a graphical indicator on a display based on the movement of the feature.
</claims>
</document>
