<document>

<filing_date>
2019-05-16
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-16
</priority_date>

<ipc_classes>
H04L12/24,H04L12/26
</ipc_classes>

<assignee>
VERIZON PATENT AND LICENSING
</assignee>

<inventors>
CAMPBELL, KIRK
Sharma, Ravi
Parvataneni, Raghuram
</inventors>

<docdb_family_id>
73245218
</docdb_family_id>

<title>
SYSTEM AND METHODS FOR SERVICE POLICY OPTIMIZATION FOR MULTI-ACCESS EDGE COMPUTING SERVICES
</title>

<abstract>
Systems and methods provide a MEC policy optimization service. A network device applies, in a first edge cluster of the application service layer network, a policy for an application service that supports a customer application; receives network performance data related to execution of the application service; identifies, based on the network performance data, an improved policy to optimize the first policy for the customer application in the first edge cluster; and sends a model of the improved policy to a central network device for the application service layer network.
</abstract>

<claims>
1. A method, comprising: applying, by one or more network devices in a first edge cluster of an application service layer network, a first policy for an application service that supports a customer application; receiving, by the one or more network devices, network performance data related to execution of the application service at the first edge cluster; generating, by the one or more network devices and based on the network performance data, a first model of an improved policy, wherein the first model improves resource allocation in the first edge cluster over to optimize the first policy for the customer application in the first edge cluster; and sending, by the one or more network devices, the first model of the improved policy to a central network device for the application service layer network.
2. The method of claim 1, wherein identifying generating the first model of the improved policy includes maintaining performance metrics for the customer application while modifying the first policy to: increase a latency requirement, decrease a minimum number of service instances dedicated to the customer application; or reduce required throughput by the application service.
3. The method of claim 1, wherein generating the first model of the improved policy comprises applying machine learning to the network performance data and performance metrics for the customer application.
4. The method of claim 1, wherein the first model of the improved policy includes one or more of a minimum latency requirement, a minimum number of service instances dedicated to the customer application, a memory reservation, or required throughput.
5. The method of claim 1, wherein the network performance data includes edge cluster performance data for the application service.
6. The method of claim 1, wherein the network performance data includes one or more of an access network performance data, a core network performance data, or customer application performance data.
7. The method of claim 1, wherein the network performance data includes location data or security data.
8. The method of claim 1, further comprising: receiving, by the central network device and from the first edge cluster, the first model of the improved policy; receiving, by the central network device and from a second edge cluster of the application service layer network, a second model of the improved policy, wherein the second model improves resource allocation in the second edge cluster over the first policy for the customer application; and generating, by the central network device and based on the first model and the second model, a second policy for the customer application.
9. The method of claim 8, further comprising: receiving, from a customer, the first policy for the application service; and sending, to the customer, a notification of the second policy for the customer application.
10. The method of claim 8, further comprising: storing the second policy in a memory.
11. One or more network devices in an application service layer network, the one or more network devices comprising: a communications interface; a memory to store instructions; and one or more processors, wherein the one or more processors execute the instructions to: apply, in a first edge cluster of the application service layer network, a first policy for an application service that supports a customer application; receive network performance data related to execution of the application service; generate, based on the network performance data, a first model of an improved policy, wherein the first model improves resource allocation in the first edge cluster over the first policy for the customer application; and send the first model of the improved policy to a central network device for the application service layer network.
12. The one or more network devices of claim 11, wherein, when generating the first model of the improved policy, the one or more processors further execute the instructions to: apply machine learning to the network performance data.
13. The one or more network devices of claim 11, wherein the first model of the improved policy modifies the first policy by: increasing a latency requirement, decreasing a minimum number of service instances dedicated to the customer application; or reducing required throughput by the application service.
14. The one or more network device of claim 11, wherein the one or more processors further execute the instructions to: receive a second model of the improved policy, wherein the second model improves resource allocation in a second edge cluster of the application service layer network over the first policy for the customer application in the second edge cluster; and generate, based on the first model and the second model, an optimized policy for the customer application.
15. The one or more network devices of claim 14, wherein the one or more processors further execute the instructions to: send, to a customer, a notification of the optimized policy for the customer application.
16. The one or more network devices of claim 14, wherein the one or more processors further execute the instructions to: store the optimized policy.
17. The one or more network devices of claim 14, wherein when generating the optimized policy for the customer application, the one or more processors further execute the instructions to: apply machine learning to automatically resolve conflicts between the first model and the second model or incorporate non-conflicting features from the first model and the second model.
18. A non-transitory computer-readable storage medium storing instructions executable by a processor of a device, which when executed cause the device to: apply, in a first edge cluster of the application service layer network, a first policy for an application service that supports a customer application; receive network performance data related to execution of the application service; generate, based on the network performance data, a first model of an improved policy, wherein the first model improves resource allocation in the first edge cluster over the first policy for the customer application; and send the first model of the improved policy to a central network device for the application service layer network.
19. The non-transitory computer-readable storage medium of claim 18, further comprising instructions to: receive another model of another improved policy to optimize the first policy for the customer application in a second edge cluster of the application service layer network; and generate, based on the first model and the other model, an optimized policy for the customer application.
20. The non-transitory computer-readable storage medium of claim 19, further comprising instructions to: store in a memory the optimized policy; and send to a customer a notification of the optimized policy for the customer application.
</claims>
</document>
