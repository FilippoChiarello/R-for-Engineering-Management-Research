<document>

<filing_date>
2019-11-07
</filing_date>

<publication_date>
2020-06-23
</publication_date>

<priority_date>
2017-06-14
</priority_date>

<ipc_classes>
G06K9/62,G06N3/04,G06N3/08,G06T11/60,G06T5/00
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
SHECHTMAN, ELYA
SUNKAVALLI, KALYAN
HADAP, SUNIL
SHU, ZHIXIN
YUMER, MEHMET
</inventors>

<docdb_family_id>
64657524
</docdb_family_id>

<title>
Neural face editing with intrinsic image disentangling
</title>

<abstract>
Techniques are disclosed for performing manipulation of facial images using an artificial neural network. A facial rendering and generation network and method learns one or more compact, meaningful manifolds of facial appearance, by disentanglement of a facial image into intrinsic facial properties, and enables facial edits by traversing paths of such manifold(s). The facial rendering and generation network is able to handle a much wider range of manipulations including changes to, for example, viewpoint, lighting, expression, and even higher-level attributes like facial hair and ageâ€”aspects that cannot be represented using previous models.
</abstract>

<claims>
1. A neural network architecture for manipulating a facial image, the architecture comprising: a disentanglement portion that includes one or more first neural network layers, the disentanglement portion trained to disentangle at least one physical property captured in the facial image, the disentanglement portion receiving the facial image and outputting a disentangled representation of the facial image based on the at least one physical property; and a rendering portion that includes one or more second neural network layers, the rendering portion trained to perform a facial manipulation of the facial image based upon an image formation equation and the at least one physical property, thereby generating a manipulated facial image.
2. The neural network architecture of claim 1, wherein the rendering portion operates on the disentangled representation of the facial image to generate the manipulated facial image.
3. The neural network architecture of claim 1, wherein the rendering portion generates the manipulated facial image in response to receiving the disentangled representation of the facial image from the disentanglement portion.
4. The neural network architecture of claim 1, wherein the disentanglement portion includes a neural network layer that encodes a map that transforms the facial image to an intermediate result associated with the at least one physical property.
5. The neural network architecture of claim 1, wherein the rendering portion includes a neural network layer arranged according to the image formation equation.
6. The neural network architecture of claim 1, wherein: each of a plurality of intermediate disentanglement results generated by the disentanglement portion is associated with a respective intermediate disentanglement loss function; each of the intermediate disentanglement results corresponds to one of the physical properties; each of a plurality of intermediate rendering results generated by the rendering portion is associated with a respective intermediate rendering loss function; the disentanglement portion is trained by (a) imposing each of the intermediate disentanglement loss functions upon its respective intermediate disentanglement result to generate a plurality of disentanglement weights, and (b) assigning the plurality of disentanglement weights in the disentanglement portion; and the rendering portion is trained by (a) imposing each of the intermediate rendering loss functions upon its respective intermediate rendering result to generate a plurality of rendering weights, and (b) assigning the plurality of rendering weights in the rendering portion.
7. A computer program product including one or more nontransitory computer readable mediums encoded with instructions that when executed by one or more processors cause operations of a neural network architecture to be carried out, the operations comprising: receiving, by a disentanglement portion of the neural network architecture, a facial image; disentangling, by the disentanglement portion, at least one physical property captured in the facial image; outputting, by the disentanglement portion, a disentangled representation of the facial image based on the at least one physical property; receiving the disentangled representation of the facial image by a rendering portion of the neural network architecture, wherein the rendering portion is trained to perform a facial manipulation of the facial image based upon an image formation equation and the at least one physical property; and generating, by the rendering portion, a manipulated facial image.
8. The computer program product of claim 7, wherein the rendering portion generates the manipulated facial image in response to receiving the disentangled representation of the facial image from the disentanglement portion.
9. The computer program product of claim 7, wherein the rendering portion operates on the disentangled representation of the facial image to generated the manipulated facial image.
10. The computer program product of claim 7, wherein the disentanglement portion includes a layer that encodes a map that transforms the facial image to an intermediate result associated with the at least one physical property.
11. The computer program product of claim 7, wherein: each of a plurality of intermediate disentanglement results generated by the disentanglement portion is associated with a respective intermediate disentanglement loss function; and each of the intermediate disentanglement results corresponds to one of the physical properties.
12. The computer program product of claim 7, wherein: each of a plurality of intermediate disentanglement results generated by the disentanglement portion is associated with a respective intermediate disentanglement loss function; each of the intermediate disentanglement results corresponds to one of the physical properties; and each of a plurality of intermediate rendering results generated by the rendering portion is associated with a respective intermediate rendering loss function.
13. The computer program product of claim 7, wherein: each of a plurality of intermediate disentanglement results generated by the disentanglement portion is associated with a respective intermediate disentanglement loss function; each of the intermediate disentanglement results corresponds to one of the physical properties; the operations further comprise imposing each of the intermediate disentanglement loss functions upon its respective intermediate disentanglement result to generate a plurality of disentanglement weights; and the operations further comprise assigning the plurality of disentanglement weights in the disentanglement portion of the neural network.
14. The computer program product of claim 7, wherein each of a plurality of intermediate rendering results generated by the rendering portion is associated with a respective intermediate rendering loss function.
15. The computer program product of claim 7, wherein: each of a plurality of intermediate rendering results generated by the rendering portion is associated with a respective intermediate rendering loss function; the operations further comprise imposing each of the intermediate rendering loss functions upon its respective intermediate rendering result to generate a plurality of rendering weights; and the operations further comprise assigning the plurality of rendering weights in the rendering portion of the neural network.
16. A method for manipulating a facial image, the method comprising: receiving, by a disentanglement portion of a neural network architecture, a facial image; associating a respective intermediate loss function with each of a plurality of intermediate results generated by the disentanglement portion, wherein each of the intermediate results corresponds to a property of the facial image; providing the intermediate results to a rendering portion of the neural network architecture, the rendering portion arranged according to an image formation equation; imposing each of the intermediate loss functions upon its respective intermediate result to generate a plurality of weights; assigning the generated weights in the disentanglement portion; disentangling, by the disentanglement portion, the facial image into one or more disentangled facial image properties; and generating, by the rendering portion, a manipulated facial image.
17. The method of claim 16, wherein the rendering portion receives the one or more disentangled facial image properties from the disentanglement portion.
18. The method of claim 16, wherein the rendering portion generates the manipulated facial image in response to receiving the one or more disentangled facial image properties from the disentanglement portion.
19. The method of claim 16, wherein the rendering portion operates on the one or more disentangled facial image properties to generate the manipulated facial image.
20. The method of claim 16, wherein the generated weights are assigned in the disentanglement and rendering portions.
</claims>
</document>
