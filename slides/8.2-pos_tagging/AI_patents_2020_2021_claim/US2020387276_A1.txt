<document>

<filing_date>
2020-06-04
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-04
</priority_date>

<ipc_classes>
G06F3/0484,G06F40/169,G06F40/186,G06K9/00
</ipc_classes>

<assignee>
TANGIBLE PLAY
</assignee>

<inventors>
SCHOLLER, JEROME
SOLOMON, MARK
</inventors>

<docdb_family_id>
73650548
</docdb_family_id>

<title>
VIRTUALIZATION OF PHYSICAL ACTIVITY SURFACE
</title>

<abstract>
Various implementations for virtualization of physical activity scene include a method that includes capturing a video stream that includes an interactive sheet including an interactive area, identifying the interactive sheet, determining a virtual page based on the identity of the interactive sheet, displaying a graphical user interface embodying a virtual template, detecting an interaction on the interaction area of the interactive sheet, generating a virtual annotation based on the interaction in the interaction area, and updating the graphical user interface to include the virtual annotation.
</abstract>

<claims>
1. A method comprising: capturing, using a video capture device associated with a computing device, a video stream of a physical activity scene, the video stream including an interactive sheet, the interactive sheet including an interaction area; identifying, using a processor of the computing device, the interactive sheet; determining, using the processor of the computing device, a virtual template based on the identity of the interactive sheet; displaying, on a display of the computing device, a graphical user interface embodying the virtual template; detecting, using the processor of the computing device, an interaction on the interaction area of the interactive sheet; generating, using the processor of the computing device, a virtual annotation based on the detected interaction on the interaction area; and updating, on the display of the computing device, the graphical user interface to include the virtual annotation.
2. The method of claim 1, wherein the interaction further comprises a marking formed by a user in the interaction area.
3. The method of claim 2, further comprising: detecting, using the processor of the computing device, the marking formed by the user in the interaction area; and determining, using the processor of the computing device, whether the marking matches an expected marking for the interaction area.
4. The method of claim 3, further comprising: responsive to the marking matching the expected marking for the interaction area, generating a correct answer annotation and presenting the correct answer annotation on the graphical user interface; and responsive to the marking not matching the expected marking for the interaction area, generating an incorrect answer annotation and presenting the incorrect answer annotation on the graphical user interface.
5. The method of claim 4, wherein the incorrect answer annotation includes a graphical representation of steps to provide the correct answer annotation.
6. The method of claim 5, wherein the interaction on the interaction area is a marking on the interaction area and wherein the virtual annotation is a virtual representation of the marking.
7. The method of claim 1, wherein, displaying the graphical user interface embodying the virtual template further comprises: determining, using the processor of the computing device, a position of the interactive sheet in the physical activity scene; aligning, using the processor of the computing device, the virtual template to the interactive sheet using the position of the interactive sheet in the physical activity scene; and displaying, using the processor of the computing device, the aligned virtual template in the graphical user interface.
8. The method of claim 7, wherein aligning the virtual template to the interactive sheet signals to the processor of the computing device where the interaction area is located on the interactive sheet based on a mapping of an expected interaction area in the virtual template.
9. The method of claim 1, wherein displaying a graphical user interface embodying the virtual template further comprises: detecting, using the processor of the computing device, a color in the interaction area of the interactive sheet; determining a color adjustment for the virtual template by using the detected color in the interaction area as a color of a corresponding area of the virtual template; and displaying the virtual template in the graphical user interface with the detected color in the corresponding area of the virtual template.
10. A physical activity surface visualization system comprising: a video capture device coupled for communication with a computing device, the video capture device being adapted to capture a video stream of a physical activity scene, the video stream including an interactive sheet, the interactive sheet including an interaction area; a detector coupled to the computing device, the detector being adapted to identify the interactive sheet and an interaction on the interaction area of the interactive sheet; a processor of the computing device, the processor being adapted to determine a virtual template based on the identity of the interactive sheet and generate a virtual annotation based on the detected interaction in the interaction area; and a display coupled to the computing device, the display being adapted to display a graphical user interface embodying the virtual template and update the graphical user interface to include the virtual annotation.
11. The physical activity surface visualization system of claim 10, wherein the interaction further comprises a marking formed by a user in the interaction area.
12. The physical activity surface visualization system of claim 11 wherein the detector is further configured to detect the marking formed by the user in the interaction area wherein the processor is further configured to determine whether the marking matches an expected marking for the interaction area.
13. The physical activity surface visualization system of claim 12, further comprising: responsive to the marking matching the expected marking for the interaction area, the processor is further configured to generate a correct answer annotation and presenting the correct answer annotation on the graphical user interface; and responsive to the marking not matching the expected marking for the interaction area, the processor is further configured to generate an incorrect answer annotation and presenting the incorrect answer annotation on the graphical user interface.
14. The physical activity surface visualization system of claim 13, wherein the incorrect answer annotation includes a graphical representation of steps to provide the correct answer annotation.
15. The physical activity surface visualization system of claim 14, wherein the interaction on the interaction area is a marking on the interaction area and wherein the virtual annotation is a virtual representation of the marking.
16. The physical activity surface visualization system of claim 10, wherein: the processor is further configured to determine a position of the interactive sheet in the physical activity scene and align the virtual template to the interactive sheet using the position of the interactive sheet in the physical activity scene; and the display is further configured to present the aligned virtual template in the graphical user interface.
17. The physical activity surface visualization system of claim 16, wherein when the processor aligns the virtual template to the interactive sheet the processor identifies where the interaction area is located on the interactive sheet based on a mapping of an expected interaction area in the virtual template.
18. The physical activity surface visualization system of claim 10, wherein: the processor is further configured to detect a color in the interaction area of the interactive sheet and determine a color adjustment for the virtual template by using the detected color in the interaction area as a color of a corresponding area of the virtual template; and the display is further configured to display the virtual template in the graphical user interface with the detected color in the corresponding area of the virtual template.
19. A method comprising: capturing, using a video capture device associated with a computing device, a video stream of a physical activity scene, the video stream including an interactive sheet that includes one or more interaction areas and a visual marking; detecting, using a processor of the computing device, the visual marking from the video stream; identifying, using the processor of the computing device, the detected visual marking; retrieving, using the processor of the computing device, a virtual template based on the identified visual marking; aligning, using the processor of the computing device, the virtual template with a position of the interactive sheet; determining, using the processor of the computing device, an expected location of the one or more interaction areas from the virtual template based on the aligning of the virtual template; detecting, using the processor of the computing device, an interaction in the one or more interaction areas on the interactive sheet using the expected location of the one or more interaction areas; identifying, using the processor of the computing device, the interaction in the one or more interaction areas; generating, using the processor of the computing device, a virtual annotation based on the identity of the interaction; and displaying, on a display of the computing device, a graphical user interface that includes the virtual template and the virtual annotation.
20. The method of claim 19, wherein the interaction is a marking formed by a user in the one or more interaction areas.
</claims>
</document>
