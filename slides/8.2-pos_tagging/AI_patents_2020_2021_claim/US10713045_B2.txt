<document>

<filing_date>
2019-01-08
</filing_date>

<publication_date>
2020-07-14
</publication_date>

<priority_date>
2018-01-08
</priority_date>

<ipc_classes>
G06F12/1081,G06F15/80,G06F17/14,G06F7/499,G06F7/544,G06F9/30,G06F9/38
</ipc_classes>

<assignee>
ATLAZO
</assignee>

<inventors>
ALHAKIM, RSHDEE
EMARA, SALEM
JAFFARI, JAVID
</inventors>

<docdb_family_id>
67143772
</docdb_family_id>

<title>
Compact arithmetic accelerator for data processing devices, systems and methods
</title>

<abstract>
Disclosed are methods, devices and systems for all-in-one signal processing, linear and non-linear vector arithmetic accelerator. The accelerator, which in some implementations can operate as a companion co-processor and accelerator to a main system, can be configured to perform various linear and non-linear arithmetic operations, and is customized to provide shorter execution times and fewer task operations for corresponding arithmetic vector operation, thereby providing an overall energy saving. The compact accelerator can be implemented in devices in which energy consumption and footprint of the electronic circuits are important, such as in Internet of Things (IoT) devices, in sensors and as part of artificial intelligence systems.
</abstract>

<claims>
1. A configurable data processing accelerator for processing of a plurality of vector operations, comprising: a configure register to receive and store a command for a vector operation and associated information from a data processing unit of an electronic system, the associated information including read addresses of system memory where vector data is located, data length of the vector data, and write addresses of the system memory where to write an output of the vector operation; an address generator configured to generate an internal address for each vector of the vector data; an internal memory circuit configured to store the vector data based on the generated internal address; a compute unit comprising an arithmetic circuit including adders and multipliers, the compute unit configured to receive vector data from the internal memory circuit and to execute the vector operation in a single pass through the compute unit to produce an output that is a result of the vector operation, wherein the compute unit is configurable to activate only a subset of the adders and multipliers therein in accordance with the vector operation.
2. The configurable data processing accelerator of claim 1, wherein the address generator is configured to receive an opcode and generate the internal address based on the opcode.
3. The configurable data processing accelerator of claim 2, wherein the address generator is configured to produce one or more of a read signal, a write signal, a read address associated with the internal memory circuit, or a write address associated with the internal memory circuit.
4. The configurable data processing accelerator of claim 1, wherein the address generator is implemented using only combinational logic circuits.
5. The configurable data processing accelerator of claim 1, wherein the internal memory circuit includes a plurality of memory banks and a plurality of logic circuits, each logic circuit in communication with a corresponding memory bank to enable a read or a write operation from or to the corresponding memory bank in accordance with the vector operation.
6. The configurable data processing accelerator of claim 5, wherein the internal memory circuit includes four memory banks and four corresponding logic circuits.
7. The configurable data processing accelerator of claim 5, wherein: the vector operation is a first vector operation, and only a first set of logic gates, less than all of the logic gates, within at least one of the plurality of logic circuits is configured to be activated in accordance with the first vector operation.
8. The configurable data processing accelerator of claim 7, wherein only a second set of the logic gates, different than the first set of logic gates and less than all of the logic gates, within the at least one of the plurality of logic circuits is activated in accordance with a second vector operation.
9. The configurable data processing accelerator of claim 1, wherein: the compute unit includes a first and a second logic circuits in a cascade configuration, the first logic circuit is configured to receive the vector data on a first plurality of input lines, and to process the vector data to produce an intermediate data on a second plurality of lines that are fewer than the first plurality of input lines, and the second logic circuit is configured to receive the intermediate data and to process the intermediate data to produce the output.
10. The configurable data processing accelerator of claim 9, wherein the second logic circuit is further configured to receive at least some of the vector data depending on the vector operation.
11. The configurable data processing accelerator of claim 9, wherein the second logic circuit is configured to receive a modified version of the intermediate data.
12. The configurable data processing accelerator of claim 11, wherein the modified version of the intermediate data includes a sum of a portion of the intermediate data, or a rounded and shifted version of the intermediate data.
13. The configurable data processing accelerator of claim 10, wherein: each of the first and second logic circuits includes a plurality of gates; the vector operation is a first vector operation, and only a first set of gates, less than all of the plurality of gates, within the first and the second logic circuits is configured to be activated in accordance with the first vector operation.
14. The configurable data processing accelerator of claim 13, wherein only a second set of gates, different than the first set of gates and less than all of the plurality of gates, within the first and the second logic circuits is activated in accordance with a second vector operation.
15. The configurable data processing accelerator of claim 13, wherein the compute unit output includes an accumulator output and a set of data outputs.
16. The configurable data processing accelerator of claim 1, further including a controller in communication with the configure register, the address generator and the compute unit to control a flow of data and commands in the configurable data processing accelerator.
17. The configurable data processing accelerator of claim 16, further including a direct memory access (DMA) circuit in communication with the controller and with the internal memory circuit to enable transfer of data between the system memory and the internal memory.
18. The configurable data processing accelerator of claim 1, wherein the vector operation includes: a Fast Fourier Transform (FFT), a Finite Impulse Response (FIR) filtering operation, a sum of two vectors, a dot multiply of two vectors, an element-wise multiply of two vectors, a linear scaling and offset transfer of vector elements, a sum of all vector elements, a sum of squares of all vectors elements, a sum of power of two of two vectors, a weighted sum of two vectors, an exponentiation operation, a logarithm operation, a square root operation, or a direct memory access (DMA) transfer.
19. The configurable data processing accelerator of claim 1, wherein the accelerator is configured to process the vector operation using a pipeline protocol that includes the following four operations: an address generation, a memory read, a compute operation and a memory write.
20. The configurable data processing accelerator of claim 19, wherein the accelerator is operable to implement the pipeline protocol wherein at least two or more of the four operations are carried out concurrently.
21. The configurable data processing accelerator of claim 1, configured to provide an interrupt to a data processing unit informative of the result of the vector operation.
22. The configurable data processing accelerator of claim 1, further comprising: a special functions circuit in communication with the compute unit and configured to execute iteration steps associated with fixed point calculations including an exponentiation, a logarithm, or a square root vector operation.
23. A method for accelerating a vector processing operation, comprising: receiving, at an accelerator device in communication with a data processing unit of an electronic device, a command for a vector operation and associated information including read addresses in system memory where vector data is located, data length of the vector data, and write addresses in the system memory where to write an output of the vector operation; writing, by the accelerator device, the vector data in an internal memory based on an internal address generated for each vector of the vector data in the internal memory; computing, by the accelerator device, the vector operation in a single pass through a compute unit of the accelerator device to produce an output that is a result of the vector operation; and providing, by the accelerator device, the output for writing to the system memory according to the write address, including providing an interrupt for consumption by a data processing unit electronic device informative of the computed vector operation.
24. The method of claim 23, wherein the writing the vector data in the internal memory, the computing the vector operation, and providing the output for writing to the system memory is implemented in a pipeline protocol.
25. The method of claim 23, wherein the writing the vector data in the internal memory, the computing the vector operation, and providing the output for writing to the system memory of the pipeline protocol are implemented concurrently.
26. The method of claim 23, wherein the vector operation includes: a Fast Fourier Transform (FFT), a Finite Impulse Response (FIR) filtering operation, a sum of two vectors, a dot multiply of two vectors, an element-wise multiply of two vectors, a linear scaling and offset transfer of a vector element, a sum of all vector elements, a sum of squares of all vectors elements, a sum of power of two of two vectors, a weighted sum of two vectors, an exponentiation operation, a logarithm operation, a square root operation, or a direct memory access (DMA) transfer.
27. The method of claim 23, wherein the vector operation is a first operation that results in activation of only a first subset of logic gates, less than all logic gates in the accelerator device, the method further comprising: receiving another command for a second vector operation and associated information including read addresses in system memory where vector data for the second vector operation is located, data length of the vector data for the second vector operation, and write addresses in the system memory where to write an output of the second vector operation; writing, by the accelerator device, the vector data for the second vector operation in an internal memory; and computing the second vector operation in another single pass through the compute unit of the accelerator to produce an output that is a result of the vector operation, wherein for conducing the second vector operation, only a second subset of logic gates, different than the first set of logic gates and less than all logic gates, is activated in the accelerator device.
</claims>
</document>
