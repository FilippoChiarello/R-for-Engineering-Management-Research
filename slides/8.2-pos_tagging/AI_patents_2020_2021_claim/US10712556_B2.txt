<document>

<filing_date>
2015-12-31
</filing_date>

<publication_date>
2020-07-14
</publication_date>

<priority_date>
2015-12-31
</priority_date>

<ipc_classes>
B60R1/00,G02B27/01,G06K9/00,G06K9/34,G06K9/46,G06T7/73
</ipc_classes>

<assignee>
HUAWEI TECHNOLOGIES COMPANY
</assignee>

<inventors>
LIU HAIBO
YANG, MEIWEN
</inventors>

<docdb_family_id>
59224408
</docdb_family_id>

<title>
Image information processing method and augmented reality AR device
</title>

<abstract>
An image information processing method includes obtaining, by an AR device, a first image including an image of a target object. The method includes detecting an environmental parameter of the AR device based on the first image. The method includes determining a cropping ratio coefficient of the first image based on the environmental parameter. The method includes cropping the first image based on the cropping ratio coefficient, to obtain a second image. The method includes extracting M contour feature points in a remaining image of the target object from the second image, to generate an AR image of the target object. The method includes displaying the AR image on a front windshield of a car.
</abstract>

<claims>
1. An image information processing method, comprising: obtaining, by an augmented reality (AR) device, a first image comprising an image of a target object, wherein the AR device is disposed on a center console of a car, and wherein the target object is located in front of the car; detecting, by the AR device, an environmental parameter of the AR device based on the first image and one or more distances between a central point of the AR device and one or more other points; determining, by the AR device, a cropping ratio coefficient of the first image based on the environmental parameter of the AR device; cropping, by the AR device, the first image based on the cropping ratio coefficient to obtain a second image; extracting, by the AR device, M contour feature points in a remaining image of the target object from the second image to generate an AR image of the target object, wherein M is a positive integer; adding, by the AR device, the AR image to a third image according to locations of the M contour feature points in the second image, wherein the third image is a blank image, and wherein a size of the third image matches a size of the second image; determining, by the AR device, a projection angle of the AR image based on contour feature points in the AR image and the environmental parameter; and projecting, by the AR device, the third image on a front windshield of the car according to the projection angle.
2. The method of claim 1, wherein displaying the AR image on the front windshield of the car comprises: determining, by the AR device, a projection angle of the AR image based on contour feature points in the AR image and the environmental parameter; and projecting, by the AR device, the AR image on the front windshield according to the projection angle.
3. The method of claim 1, wherein the front windshield comprises a display screen, and wherein displaying the AR image on the front windshield of the car comprises: determining, by the AR device, locations of M projected points that correspond to the M contour feature points and are on the front windshield; and displaying, by the AR device, the AR image on the display screen of the front windshield of the car based on the locations of the M projected points.
4. The method of claim 1, wherein obtaining the first image comprises photographing, by the AR device, the target object using a ranging feature point on the target object as a focusing reference point to obtain the first image, and wherein a pixel that is in the first image and that corresponds to the focusing reference point is a focus of the first image.
5. The method of claim 4, wherein detecting the environmental parameter of the AR device comprises: detecting, by the AR device, a distance c0 between the ranging feature point and the central point of the AR device based on a relative location of the focus of the first image; determining an included angle q0 between the device view plane and a line segment corresponding to the distance c0, wherein the device view plane is a device view plane of the AR device; photographing, by the AR device, a driver image to obtain a reference image; detecting a first distance c1 between a driver-eye central point and the central point of the AR device based on a relative location of a driver-eye central point pixel of the reference image in the reference image; determining an included angle q1 between the device view plane and a line segment corresponding to the first distance c1; detecting, by the AR device, a second distance c2 between a feature point B′ on an upper edge of the front windshield and the central point of the AR device; determining an included angle q2 between the device view plane and a line segment corresponding to the second distance c2; detecting a third distance c3 between a feature point C′ on a lower edge of the front windshield and the central point of the AR device; and determining an included angle q3 between the device view plane and a line segment corresponding to the third distance c3.
6. The method of claim 5, wherein determining the cropping ratio coefficient of the first image comprises: indicating, by the AR device, the central point of the AR device as an origin O of a two-dimensional coordinate system XOY; indicating, as a straight line L, a straight line that passes through the ranging feature point on the target object and is perpendicular to the device view plane; determining a reference plane of the two-dimensional coordinate system XOY based on the origin O and the straight line L; indicating a projected straight line of the device view plane on the reference plane as an X axis; setting a direction of the X axis as a direction in which the origin O is away from the straight line L; indicating, by the AR device, a projected point of the driver-eye central point on the reference plane as a point A in the two-dimensional coordinate system XOY; indicating a projected point of the feature point B′ on the reference plane as a point B; indicating a projected point of the feature point C′ on the reference plane as a point C; indicating a projected straight line of a driver view plane on the reference plane as a straight line N, wherein a projection of the point A on the X axis is a point A1, wherein a projection of the point B on the straight line N is a point B1, wherein a projection of the point B on the X axis is a point B2, wherein a projection of the origin O on the straight line L is a point O1, wherein a projection of the point A on the straight line L is a point A2, wherein an intersection point between a straight line of a line segment OB and the straight line L is a point C1, wherein an intersection point between a straight line of a line segment AB and the straight line L is a point C2, and wherein an intersection point between a straight line of a line segment OC and the straight line L is a point C3; making, by the AR device, a length of a line segment OA from the origin O to the point A equivalent to the first distance c1; making an angle ∠AOA1 equivalent to the included angle q1, wherein the angle ∠AOA1 is formed by the point A, the origin O, and the point A1; making a length of the line segment OB equivalent to the distance c2; making an angle ∠BOO1 equivalent to the included angle q2, wherein the angle ∠BOO1 is formed by the point B, the origin O, and the point O1; making a length of the line segment OC equivalent to the distance c3; making an angle ∠COO1 equivalent to the included angle q3, wherein the angle ∠COO1 is formed by the point C, the origin O, and the point O1; determining, by the AR device, a length of a line segment OO1 and an expression of the straight line L according to the distance c0 and the included angle q0, wherein the line segment OO1 is a line segment from the origin O to the point O1; determining coordinates of the point A according to the length of the line segment OA and the angle ∠AOA1; determining coordinates of the point B according to the length of the line segment OB and the angle ∠BOO1; determining coordinates of the point C according to the length of the line segment OC and the angle ∠COO1; determining coordinates of the point C2 according to an expression of a straight line passing through the point A and the point B and the expression of the straight line L; determining coordinates of the point C3 according to an expression of a straight line passing through the point C and the origin O and the expression of the straight line L; determining coordinates of the point C1 according to an expression of a straight line passing through the point B and the origin O and the expression of the straight line L; and determining the cropping ratio coefficient of the first image according to the coordinates of the point C1, the coordinates of the point C2, and the coordinates of the point C3.
7. An augmented reality (AR) device, comprising: a processor; and memory coupled to the processor and storing instructions that, when executed by the processor, cause the AR device to be configured to: obtain a first image comprising an image of a target object, wherein the AR device is disposed on a center console of a car, and wherein the target object is located in front of the car; detect an environmental parameter of the AR device based on the first image and one or more distances between a central point of the AR device and one or more other points; determine a cropping ratio coefficient of the first image based on the environmental parameter of the AR device; crop the first image based on the cropping ratio coefficient to obtain a second image; extract M contour feature points in a remaining image of the target object from the second image to generate an AR image of the target object, wherein M is a positive integer; add the AR image to a third image according to locations of the M contour feature points in the second image, wherein the third image is a blank image, and wherein a size of the third image matches a size of the second image; determine a projection angle of the AR image based on contour feature points in the AR image and the environmental parameter; and project the third image on a front windshield of the car according to the projection angle.
8. The AR device of claim 7, wherein the instructions are configured to cause the AR device to be configured to display the AR image on the front windshield of the car by causing the AR device to be configured to: determine a projection angle of the AR image based on contour feature points in the AR image and the environmental parameter; and project the AR image on the front windshield according to the projection angle.
9. The AR device of claim 7, wherein the front windshield comprises a display screen, and wherein the instructions are configured to cause the AR device to be configured to display the AR image on the front windshield of the car by causing the AR device to: determine locations of M projected points that correspond to the M contour feature points and are on the front windshield; and display the AR image on the display screen of the front windshield of the car based on the locations of the M projected points.
10. The AR device of claim 7, wherein the instructions are further configured to cause the AR device to be configured to obtain the first image by causing the AR device to be configured to photograph the target object using a ranging feature point on the target object as a focusing reference point to obtain the first image, and wherein a pixel that is in the first image and that corresponds to the focusing reference point is a focus of the first image.
11. The AR device of claim 10, wherein the instructions are further configured to cause the AR device to be configured to detect the environmental parameter by causing the AR device to be configured to: detect a distance c0 between the ranging feature point and the central point of the AR device based on a relative location of the focus of the first; determine an included angle q0 between the device view plane and a line segment corresponding to the distance c0, wherein the device view plane is a device view plane of the AR device; photograph a driver image to obtain a reference image; detect a first distance c1 between a driver-eye central point and the central point of the AR device based on a relative location of a driver-eye central point pixel of the reference image; determine an included angle q1 between the device view plane and a line segment corresponding to the first distance c1; detect a second distance c2 between a feature point B′ on an upper edge of the front windshield and the central point of the AR device; determine an included angle q2 between the device view plane and a line segment corresponding to the second distance c2; detect a third distance c3 between a feature point C′ on a lower edge of the front windshield and the central point of the AR device; and determine an included angle q3 between the device view plane and a line segment corresponding to the third distance c3.
12. The AR device of claim 11, wherein the instructions are further configured to cause the AR device to be configured to determine the cropping ration coefficient by causing the AR device to be configured to: indicate the central point of the AR device as an origin O of a two-dimensional coordinate system XOY; indicate, as a straight line L, a straight line that passes through the ranging feature point on the target object and is perpendicular to the device view plane; determine a reference plane of the two-dimensional coordinate system XOY based on the origin O and the straight line L; indicate a projected straight line of the device view plane on the reference plane as an X axis; set a direction of the X axis as a direction in which the origin O is away from the straight line L; indicate a projected point of the driver-eye central point on the reference plane as a point A in the two-dimensional coordinate system XOY; indicate a projected point of the feature point B′ on the reference plane as a point B; indicate a projected point of the feature point C′ on the reference plane as a point C; indicate a projected straight line of a driver view plane on the reference plane as a straight line N, wherein a projection of the point A on the X axis is a point A1, wherein a projection of the point B on the straight line N is a point B1, wherein a projection of the point B on the X axis is a point B2, wherein a projection of the origin O on the straight line L is a point O1, wherein a projection of the point A on the straight line L is a point A2, wherein an intersection point between a straight line of a line segment OB and the straight line L is a point C1, wherein an intersection point between a straight line of a line segment AB and the straight line L is a point C2, and wherein an intersection point between a straight line of a line segment OC and the straight line L is a point C3; make a length of the line segment OA from the origin O to the point A equivalent to the first distance c1; make an angle ∠AOA1 equivalent to the included angle q1, wherein the angle ∠AOA1 is formed by the point A, the origin O, and the point A1; make a length of the line segment OB equivalent to the distance c2; make an angle ∠BOO1 equivalent to the included angle q2, wherein the angle ∠BOO1 is formed by the point B, the origin O, and the point O1; make a length of the line segment OC equivalent to the distance c3; and make an angle ∠COO1 equivalent to the included angle q3, wherein the angle ∠COO1 is formed by the point C, the origin O, and the point O1; determine a length of a line segment OO1 and an expression of the straight line L according to the distance c0 and the included angle q0, wherein the line segment OO1 is a line segment from the origin O to the point O1; determine coordinates of the point A according to the length of the line segment OA and the angle ∠AOA1; determine coordinates of the point B according to the length of the line segment OB and the angle ∠BOO1; determine coordinates of the point C according to the length of the line segment OC and the angle ∠COO1; determine coordinates of the point C2 according to an expression of a straight line passing through the point A and the point B and the expression of the straight line L; determine coordinates of the point C3 according to an expression of a straight line passing through the point C and the origin O and the expression of the straight line L; determine coordinates of the point C1 according to an expression of a straight line passing through the point B and the origin O and the expression of the straight line L; and determine the cropping ratio coefficient of the first image according to the coordinates of the point C1, the coordinates of the point C2, and the coordinates of the point C3.
13. A non-transitory computer-readable storage medium comprising instructions that, when executed by an augmented reality (AR) device, cause the AR device to be configured to: obtain a first image comprising an image of a target object, wherein the AR device is disposed on a center console of a car, and the target object is located in front of the car; detect an environmental parameter of the AR device based on the first image and one or more distances between a central point of the AR device and one or more other points; determine a cropping ratio coefficient of the first image based on the environmental parameter of the AR device; crop the first image based on the cropping ratio coefficient to obtain a second image; extract M contour feature points in a remaining image of the target object from the second image to generate an AR image of the target object, wherein M is a positive integer; add the AR image to a third image according to locations of the M contour feature points in the second image, wherein the third image is a blank image, and wherein a size of the third image matches a size of the second image; determine a projection angle of the AR image based on contour feature points in the AR image and the environmental parameter; and project the third image on a front windshield of the car according to the projection angle.
14. The non-transitory computer-readable storage medium of claim 13, wherein the instructions cause the AR device to be configured to display the AR image on the front windshield of the car by causing the AR device to be configured to: determine a projection angle of the AR image based on contour feature points in the AR image and the environmental parameter; and project the AR image on the front windshield according to the projection angle.
15. The non-transitory computer-readable storage medium of claim 13, wherein the front windshield comprises a display screen, and wherein the instructions cause the AR device to be configured to display the AR image on the front windshield of the car by causing the AR device to be configured to: determine locations of M projected points that correspond to the M contour feature points and that are on the front windshield; and display the AR image on the display screen of the front windshield of the car based on the locations of the M projected points.
16. The non-transitory computer-readable storage medium of claim 13, wherein the instructions cause the AR device to be configured to obtain the first image by causing the AR device to be configured to photograph the target object using a ranging feature point on the target object as a focusing reference point to obtain the first image, and wherein a pixel that is in the first image and that corresponds to the focusing reference point is a focus of the first image.
17. The non-transitory computer-readable storage medium of claim 16, wherein the instructions cause the AR device to be configured to detect the environmental parameter by causing the AR device to be configured to: detect a distance c0 between the ranging feature point and the central point of the AR device based on a relative location of the focus of the first image; determine an included angle q0 between the device view plane and a line segment corresponding to the distance c0, wherein the device view plane is a device view plane of the AR device; photograph a driver image to obtain a reference image; detect a first distance c1 between a driver-eye central point and the central point of the AR device based on a relative location of a driver-eye central point pixel of the reference image in the reference image; determine an included angle q1 between the device view plane and a line segment corresponding to the first distance c1; detect a second distance c2 between a feature point B′ on an upper edge of the front windshield and the central point of the AR device; determine an included angle q2 between the device view plane and a line segment corresponding to the second distance c2; detect a third distance c3 between a feature point C′ on a lower edge of the front windshield and the central point of the AR device; and determine an included angle q3 between the device view plane and a line segment corresponding to the third distance c3.
18. The non-transitory computer-readable storage medium of claim 16, wherein the instructions cause the AR device to be configured to detect the environmental parameter by causing the AR device to be configured to: indicate the central point of the AR device as an origin O of a two-dimensional coordinate system XOY; indicate, as a straight line L, a straight line that passes through the ranging feature point on the target object and is perpendicular to the device view plane; determine a reference plane of the two-dimensional coordinate system XOY based on the origin O and the straight line L; indicate a projected straight line of the device view plane on the reference plane as an X axis; set a direction of the X axis as a direction in which the origin O is away from the straight line L; indicate a projected point of the driver-eye central point on the reference plane as a point A in the two-dimensional coordinate system XOY; indicate a projected point of the feature point B′ on the reference plane as a point B; indicate a projected point of the feature point C′ on the reference plane as a point C; indicate a projected straight line of a driver view plane on the reference plane as a straight line N, wherein a projection of the point A on the X axis is a point A1, wherein a projection of the point B on the straight line N is a point B1, wherein a projection of the point B on the X axis is a point B2, wherein a projection of the origin O on the straight line L is a point O1, wherein a projection of the point A on the straight line L is a point A2, wherein an intersection point between a straight line of a line segment OB and the straight line L is a point C1, wherein an intersection point between a straight line of a line segment AB and the straight line L is a point C2, and wherein an intersection point between a straight line of a line segment OC and the straight line L is a point C3; make a length of a line segment OA from the origin O to the point A equivalent to the first distance c1; make an angle ∠AOA1 equivalent to the included angle q1, wherein the angle ∠AOA1 is formed by the point A, the origin O, and the point A1; make a length of the line segment OB equivalent to the distance c2; make an angle ∠BOO1 equivalent to the included angle q2, wherein the angle ∠BOO1 is formed by the point B, the origin O, and the point O1; make a length of the line segment OC equivalent to the distance c3; make an angle ∠COO1 equivalent to the included angle q3, wherein the angle ∠COO1 is formed by the point C, the origin O, and the point O1; determine a length of a line segment OO1 and an expression of the straight line L according to the distance c0 and the included angle q0, wherein the line segment OO1 is a line segment from the origin O to the point O1; determine coordinates of the point A according to the length of the line segment OA and the angle ∠AOA1; determine coordinates of the point B according to the length of the line segment OB and the angle ∠BOO1; determine coordinates of the point C according to the length of the line segment OC and the angle ∠COO1; determine coordinates of the point C2 according to an expression of a straight line passing through the point A and the point B and the expression of the straight line L; determine coordinates of the point C3 according to an expression of a straight line passing through the point C and the origin O and the expression of the straight line L; determine coordinates of the point C1 according to an expression of a straight line passing through the point B and the origin O and the expression of the straight line L; and determine the cropping ratio coefficient of the first image according to the coordinates of the point C1, the coordinates of the point C2, and the coordinates of the point C3.
</claims>
</document>
