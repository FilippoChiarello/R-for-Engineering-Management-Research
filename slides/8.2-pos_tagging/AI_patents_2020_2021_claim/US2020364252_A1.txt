<document>

<filing_date>
2019-05-16
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-16
</priority_date>

<ipc_classes>
G06F16/33,G06F16/34,G06N3/08
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
ZHANG, RUOFEI
CHANG, KENG-HAO
HUGHES, John Weston
</inventors>

<docdb_family_id>
70334036
</docdb_family_id>

<title>
GENERATING ELECTRONIC SUMMARY DOCUMENTS FOR LANDING PAGES
</title>

<abstract>
Described herein are technologies related to constructing supplemental content items that summarize electronic landing pages. A sequence to sequence model that is configured to construct supplemental content items is trained based upon a corpus of electronic landing pages and supplemental content items that have been constructed by domain experts, wherein each landing page has a respective supplemental content item assigned thereto. The sequence to sequence model is additionally trained using self critical sequence training, where estimated click through rates of supplemental content items generated by the sequence to sequence model are employed to train the sequence to sequence model.
</abstract>

<claims>
1. A computing system comprising: a processor; and memory storing instructions that, when executed by the processor, cause the processor to perform acts comprising: receiving an electronic landing page, wherein the electronic landing page comprises a landing page title that includes a first sequence of words and a landing page body that includes a second sequence of words; and generating, through use of a computer-implemented model, a supplemental content item that summarizes the electronic landing page, wherein the supplemental content item comprises a supplemental content item title that includes a third sequence of words and a supplemental content body that includes a fourth sequence of words, wherein the computer-implemented model generates the supplemental content item based upon the first sequence of words in the landing page title and the second sequence of words in the landing page body, and further wherein the computer-implemented model is trained based upon estimated likelihoods of supplemental content items being selected by end users if a search engine were to receive, from the end users, queries that are assigned to the supplemental content items.
2. The computing system of claim 1, wherein the search engine causes the supplemental content item to be included in a search engine results page in response to receipt of a query from a client computing device, wherein the query comprises a keyword that is assigned to the supplemental content item.
3. The computing system of claim 1, wherein the computer-implemented model is a sequence to sequence model.
4. The computing system of claim 3, wherein the sequence to sequence model comprises an encoder that is configured to encode the first sequence of words and the second sequence of words in parallel, and further wherein the sequence to sequence model comprises a decoder that is configured to output the supplemental content item based upon the parallel encoding of the first sequence of words and the second sequence of words.
5. The computing system of claim 4, wherein the encoder comprises a first encoder recurrent neural network (RNN) and a second encoder RNN, and further wherein the decoder comprises a first decoder RNN and a second decoder RNN.
6. The computing system of claim 5, wherein the first encoder RNN and the second encoder RNN encode the first sequence of words and the second sequence of words, respectively, in parallel.
7. The computing system of claim 1, wherein the supplemental content item has a predefined format, wherein a number of words in the supplemental content item title is less than a first predefined threshold, and further wherein a number of words in the supplemental content body is less than a second predefined threshold that is greater than the first predefined threshold.
8. The computing system of claim 1, wherein at least one word in the third sequence of words fails to exist in either the first sequence of words or the second sequence of words.
9. The computing system of claim 1, wherein the computer-implemented model is further trained based upon landing page/supplemental content item pairs, wherein each pair includes a respective landing page and a respective supplemental content item generated by a human to summarize the respective landing page.
10. The computing system of claim 1, the acts further comprising: mapping each word in the first sequence of words to a first one-hot encoded vector; mapping each word in the second sequence of words to a second one-hot encoded vector; multiplying the first one-hot encoded vector by an embedding matrix to generate a first sequence of vectors; multiplying the second one-hot encoded vector by the embedding matrix to generate a second sequence of vectors, wherein the computer-implemented model generates the third sequence of words and the fourth sequence of words based upon the first sequence of vectors and the second sequence of vectors.
11. A method performed by a computing system, the method comprising: receiving a landing page, wherein the landing page comprises a landing page title and a landing page body, wherein the landing page title comprises a first sequence of words and the landing page body comprises a second sequence of words; and responsive to receiving the landing page, and through use of a computer-implemented model, constructing supplemental content item based upon the first sequence of words and the second sequence of words, wherein the supplemental content item comprises a supplemental content item title that comprises a third sequence of words and a supplemental content item body that includes a fourth sequence of words, wherein the computer-implemented model generates the third sequence of words based upon the first sequence of words and the second sequence of words, and further wherein the computer-implemented model generates the fourth sequence of words based upon the first sequence of words and the second sequence of words.
12. The method of claim 11, wherein the computer-implemented model is a sequence to sequence model.
13. The method of claim 11, wherein the sequence to sequence model comprises an encoder and a decoder, wherein the encoder includes a first pair of recurrent neural networks (RNNs) and the decoder includes a second pair of RNNs.
14. The method of claim 13, wherein the first pair of RNNs and the second pair of RNNs are Long Short-Term Memory (LSTM) RNNs.
15. The method of claim 11, wherein the computer-implemented model is trained based upon estimated likelihoods of supplemental content items being selected by end users if a search engine were to receive, from the end users, queries that are assigned to the supplemental content items.
16. The method of claim 11, wherein the supplemental content item has a keyword assigned thereto, and further wherein a search engine includes the supplemental content item in a search engine results page in response to receiving a query that comprises the keyword.
17. The method of claim 11, further comprising: mapping each word in the first sequence of words to a first one-hot encoded vector; mapping each word in the second sequence of words to a second one-hot encoded vector; multiplying the first one-hot encoded vector by an embedding matrix to generate a first sequence of vectors; and multiplying the second one-hot encoded vector by the embedding matrix to generate a second sequence of vectors, wherein the computer-implemented model generates the third sequence of words and the fourth sequence of words based upon the first sequence of vectors and the second sequence of vectors.
18. A computer-readable storage medium comprising instructions that, when executed by a processor, cause the processor to perform acts comprising: receiving an electronic landing page, wherein the electronic landing page comprises a landing page title that includes a first sequence of words and a landing page body that includes a second sequence of words; and generating, through use of a computer-implemented model, a supplemental content item that summarizes the electronic landing page, wherein the supplemental content item comprises a supplemental content item title that includes a third sequence of words and a supplemental content item body that includes a fourth sequence of words, wherein the computer-implemented model generates the supplemental content item based upon the first sequence of words in the landing page title and the second sequence of words in the landing page body, wherein the computer-implemented model is trained based upon estimated likelihoods of supplemental content items being selected by end users if a search engine were to receive, from the end users, queries that include keywords that assigned to the supplemental content items, and further wherein the supplemental content item is presented on a search engine results page in response to the search engine receiving a query that comprises a keyword assigned to the supplemental content item.
19. The computer-readable storage medium of claim 18, wherein the computer-implemented model is a sequence to sequence model that comprises an encoder and a decoder, wherein the encoder encodes the first sequence of words and the second sequence of words in parallel.
20. The computer-readable storage medium of claim 19, wherein the encoder comprises a first RNN and a second RNN, wherein the first RNN encodes the first sequence of words and the second RNN encodes the second sequence of words.
</claims>
</document>
