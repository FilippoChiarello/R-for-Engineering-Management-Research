<document>

<filing_date>
2017-09-12
</filing_date>

<publication_date>
2020-06-24
</publication_date>

<priority_date>
2016-09-15
</priority_date>

<ipc_classes>
G06T15/20,G06T7/55
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
ANGELOVA, ANELIA
MAHJOURIAN, REZA
WICKE, MARTIN
</inventors>

<docdb_family_id>
59930804
</docdb_family_id>

<title>
IMAGE DEPTH PREDICTION NEURAL NETWORKS
</title>

<abstract>
A system includes an image depth prediction neural network implemented by one or more computers. The image depth prediction neural network is a recurrent neural network that is configured to receive a sequence of images and, for each image in the sequence: process the image in accordance with a current internal state of the recurrent neural network to (i) update the current internal state and (ii) generate a depth output that characterizes a predicted depth of a future image in the sequence.
</abstract>

<claims>
1. A system comprising: an image depth prediction neural network (102) implemented by one or more computers, wherein the image depth prediction neural network is a recurrent neural network that is configured to receive (302) a sequence of images (106) and, for each image in the sequence:
process (304) the image in accordance with a current internal state of the recurrent neural network to (i) update the current internal state and (ii) generate a depth output that characterizes a predicted depth of a future image in the sequence, wherein the depth output comprises a set of values defining the topology of a scene represented by the future image in a third, depth dimension; and an image generation subsystem configured to, for each image in the sequence: receive (306) the depth output that characterizes the predicted depth of the future image, and generate (308) a prediction of the future image using the depth output.
2. The system of any one of claim 1, wherein the depth output comprises a predicted depth value for each pixel of a plurality of pixels in the future image that represents a respective distance of a scene depicted at the pixel from a focal plane of the future image.
3. The system of any one of claims 1-2, wherein the future image immediately follows the image in the sequence of images.
4. The system of any one of claims 1-3, wherein the sequence of images are frames of video captured by a camera of a robotic agent.
5. The system of any one of claims 1-4, wherein the image depth prediction neural network comprises one or more convolutional long short-term memory (LSTM) neural network layers.
6. The system of any one of claims 1-5, wherein the image depth prediction neural network comprises one or more feedforward convolutional neural network layers.
7. The system of any one of claims 1-6, wherein the image depth prediction neural network comprises: a down-sampling recurrent sub-neural network followed by an up-sampling recurrent sub-network, wherein the down-sampling recurrent sub-neural network is configured to, for each image in the sequence:
process the image to generate a down-sampled output having a lower resolution than the image, and wherein the up-sampling recurrent sub-neural network is configured to, for each image in the sequence:
process the down-sampled output for the image to generate the depth output.
8. One or more computer storage media encoded with instructions that, when executed by one or more computers, cause the one or more computers to implement the system of any one of claims 1-7.
9. A method comprising: receiving a sequence of images (302); and for each image in the sequence, processing (304) the image using an image depth prediction neural network, wherein the image depth prediction neural network is a recurrent neural network that is configured to, for each image in the sequence: process the image in accordance with a current internal state of the recurrent neural network to (i) update the current internal state and (ii) generate a depth output that characterizes a predicted depth of a future image in the sequence; the method further comprising, for each image in the sequence: receiving (306) the depth output that characterizes the predicted depth of the future image; and generating (308) a prediction of the future image using the depth output, wherein the depth output comprises a set of values defining the topology of a scene represented by the future image in a third, depth dimension.
10. The method of claim 9, wherein the depth output comprises a predicted depth value for each pixel of a plurality of pixels in the future image that represents a respective distance of a scene depicted at the pixel from a focal plane of the future image.
11. The method of any one of claims 9 - 10, wherein the future image immediately follows the image in the sequence of images.
12. The method of any one of claims 9 -11, wherein the sequence of images are frames of video captured by a camera of a robotic agent.
13. The method of any one of claims 9 - 12, wherein the image depth prediction neural network comprises one or more convolutional long short-term memory (LSTM) neural network layers.
14. The method of any one of claims 9 -13, wherein the image depth prediction neural network comprises one or more feedforward convolutional neural network layers.
15. The method of any one of claims 9 - 14, wherein the image depth prediction neural network comprises: a down-sampling recurrent sub-neural network followed by an up-sampling recurrent sub-network, wherein the down-sampling recurrent sub-neural network is configured to, for each image in the sequence:
process the image to generate a down-sampled output having a lower resolution than the image, and wherein the up-sampling recurrent sub-neural network is configured to, for each image in the sequence:
process the down-sampled output for the image to generate the depth output.
16. One or more computer storage media encoded with instructions that, when executed by one or more computers, cause the one or more computers to perform the operations of the respective method of any one of claims 9 -15.
</claims>
</document>
