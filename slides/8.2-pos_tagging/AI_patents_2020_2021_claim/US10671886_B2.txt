<document>

<filing_date>
2019-01-22
</filing_date>

<publication_date>
2020-06-02
</publication_date>

<priority_date>
2018-03-08
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06K9/62
</ipc_classes>

<assignee>
CAPITAL ONE SERVICES
</assignee>

<inventors>
DAGLEY, GEOFFREY
HOOVER, JASON
PRICE, MICAH
TANG, QIAOCHU
WYLIE, STEPHEN
</inventors>

<docdb_family_id>
65496070
</docdb_family_id>

<title>
Object detection using image classification models
</title>

<abstract>
In one aspect, the present disclosure relates to a method for or performing single-pass object detection and image classification. The method comprises receiving image data for an image in a system comprising a convolutional neural network (CNN), the CNN comprising a first convolutional layer, a last convolutional layer, and a fully connected layer; providing the image data to an input of the first convolutional layer; extracting multi-channel data from the output of the last convolutional layer; and summing the extracted data to generate a general activation map; and detecting a location of an object within the image by applying the general activation map to the image data.
</abstract>

<claims>
1. A method for performing object detection comprising: providing an image to a single-pass convolutional neural network (CNN); extracting multi-channel data from a last convolutional layer of the CNN; generating a two-dimensional general activation map using the multi-channel data; and detecting a location of an object within the image by upscaling the general activation map and applying the upscaled general activation map to the image.
2. The method of claim 1 wherein generating the general activation map comprises generating the general activation map without using class-specific weights.
3. The method of claim 1 wherein detecting the location of an object within the image comprises identifying a bounding box within the image based on comparing values within the general activation map to a predetermined threshold value.
4. The method of claim 1 wherein detecting the location of an object within the image comprises: interpolating data within the general activation map; and identifying a bounding box within the image using the interpolated data.
5. The method of claim 1 wherein detecting the location of an object within the image comprises upscaling the general activation map based on dimensions of the image.
6. A method for augmenting an image using single-pass object detection and image classification, the method comprising: providing an image to a single-pass convolutional neural network (CNN); receiving, from the CNN, convolutional data and one or more classifications; generating a two-dimensional general activation map using the convolutional data; detecting a location of an object within the image by upscaling the general activation map and applying the upscaled general activation map to the image; displaying the image and a content overlay, wherein a position of the content overlay relative to the image is determined using the detected object location, wherein the content overlay comprises information determined by the one or more classifications.
7. The method of claim 6 wherein generating the general activation map comprises generating the general activation map without using class-specific weights.
8. The method of claim 6 wherein detecting the location of an object within the image comprises identifying a bounding box within the image based on comparing values within the general activation map to a predetermined threshold value.
9. The method of claim 6 wherein detecting the location of an object within the image comprises: interpolating data within the general activation map; and identifying a bounding box within the image using the interpolated data.
10. The method of claim 6 wherein detecting the location of an object within the image comprises upscaling the general activation map based on dimensions of the image.
11. A system for performing single-pass object detection and image classification, the system comprising: a processor; a non-volatile memory storing computer instructions that when executed on the processor cause the processor to: provide an image to a single-pass convolutional neural network (CNN); extract multi-channel data from a last convolutional layer of the CNN; generate a two-dimensional general activation map using the multi-channel data; and detect a location of an object within the image by upscaling the general activation map and applying the upscaled general activation map to the image.
12. The system of claim 11 wherein computer instructions that when executed on the processor cause the processor to: generate the general activation map without using class-specific weights.
13. The system of claim 11 wherein computer instructions that when executed on the processor cause the processor to: detect the location of an object within the image by identifying a bounding box within the image based on comparing values within the general activation map to a predetermined threshold value.
14. The system of claim 11 wherein the computer instructions that when executed on the processor cause the processor to: interpolate data within the general activation map; and identify a bounding box within the image using the interpolated data.
15. The system of claim 11 wherein the computer instructions that when executed on the processor cause the processor to: detect the location of an object within the image by upscaling the general activation map based on dimensions of the image.
</claims>
</document>
