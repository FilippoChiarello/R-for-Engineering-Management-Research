<document>

<filing_date>
2020-03-04
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2017-09-07
</priority_date>

<ipc_classes>
G06F7/544,G06N3/063,G06N3/08,G11C11/54,G11C16/08,G11C7/18
</ipc_classes>

<assignee>
PANASONIC CORPORATION
</assignee>

<inventors>
HAYATA, YURIKO
KOUNO, KAZUYUKI
MOCHIDA, REIJI
NAKAYAMA, MASAYOSHI
ONO TAKASHI
SUWA HITOSHI
</inventors>

<docdb_family_id>
65634134
</docdb_family_id>

<title>
NEURAL NETWORK COMPUTATION CIRCUIT INCLUDING SEMICONDUCTOR MEMORY ELEMENT, AND METHOD OF OPERATION
</title>

<abstract>
Connection weight coefficients to be used in a neural network computation are stored in a memory array. A word line drive circuit drives a word line corresponding to input data of a neural network. A column selection circuit connects to a computation circuit bit lines to which a connection weight coefficient to be computed is connected. The computation circuit determines the sum of cell currents flowing in the bit lines. A result of the determination made by the computation circuit is stored in an output holding circuit, and is set as an input of a neural network in the next layer, to the word line drive circuit. A control circuit instructs the word line drive circuit and the column selection circuit to select the word line and the bit line to be used in the neural network computation, based on information held in a network configuration information holding circuit.
</abstract>

<claims>
1. A semiconductor integrated circuit, comprising: a plurality of word lines; a plurality of bit lines arranged to cross the plurality of word lines; a plurality of memory cells that are disposed at cross points of the plurality of word lines and the plurality of bit lines, the plurality of memory cells each holding a connection weight coefficient of a neural network; a word line drive circuit capable of driving at least one of the plurality of word lines; a column selection circuit capable of selecting a bit line from among the plurality of bit lines; a computation circuit that determines a current flowing in the bit line selected by the column selection circuit, to perform a multiply-accumulate operation between the connection weight coefficients held in the plurality of memory cells connected to the bit line selected by the column selection circuit and input data indicated by drive states of the plurality of word lines; an output holding circuit that holds output data of the computation circuit; a network configuration information holding circuit that holds network configuration information including address information of each memory cell to which the connection weight coefficient of the neural network is assigned; and a control circuit having a function of setting to the word line drive circuit input data from an outside based on the network configuration information, a function of setting to the word line drive circuit data held in the output holding circuit, based on the network configuration information, and a function of specifying to the column selection circuit a bit line to be used for a computation, based on the network configuration information.
2. The semiconductor integrated circuit according to claim 1, wherein the semiconductor integrated circuit has a function of, after storing output data of the computation circuit in the output holding circuit in a word line drive state and a bit line selection state, changing a bit line to be selected while maintaining the word line drive state, storing another output data of the computation circuit in the output holding circuit, and setting combined data to the word line drive circuit.
3. The semiconductor integrated circuit according to claim 1, further comprising: a selector circuit that selects data to be connected to the word line drive circuit, based on the input data from the outside and the data held in the output holding circuit.
4. The semiconductor integrated circuit according to claim 1, further comprising: a selector circuit that selects data to be connected to the word line drive circuit, based on the input data from the outside and the output data of the computation circuit.
5. A method of operation for a neural network semiconductor integrated circuit, the method comprising the following performed using a semiconductor integrated circuit including: a plurality of word lines; a plurality of bit lines arranged to cross the plurality of word lines; a plurality of memory cells disposed at cross points of the plurality of word lines and the plurality of bit lines, the plurality of memory cells each holding a connection weight coefficient of a neural network; a word line drive circuit capable of driving at least one of the plurality of word lines; a column selection circuit capable of selecting a bit line from among the plurality of bit lines; a computation circuit that determines a current flowing in the bit line selected by the column selection circuit, to perform a multiply-accumulate operation between the connection weight coefficients held in the plurality of memory cells connected to the bit line selected by the column selection circuit and input data indicated by drive states of the plurality of word lines; an output holding circuit that holds output data of the computation circuit; a network configuration information holding circuit that holds network configuration information including address information of each memory cell to which the connection weight coefficient of the neural network is assigned; and a control circuit having a function of setting to the word line drive circuit input data from the outside based on the network configuration information, a function of setting to the word line drive circuit data held in the output holding circuit, based on the network configuration information, and a function of specifying to the column selection circuit a bit line to be used for a computation, based on the network configuration information: setting the input data from an outside based on the network configuration information so that a first word line area corresponding to first memory cells is driven, selecting at least one first bit line corresponding to the first memory cells, and connecting the at least one first bit line to the computation circuit, the first memory cells holding connection weight coefficients of an input layer and a first hidden layer of the neural network, the first hidden layer being a next layer of the input layer; holding a computational result from the computation circuit in the output holding circuit, setting, as input data of a second hidden layer, the data held in the output holding circuit so that a second word line area corresponding to second memory cells is driven, selecting at least one second bit line corresponding to the second memory cells, and connecting the at least one second bit line to the computation circuit, the second hidden layer being a next layer of the first hidden layer, the second memory cells holding connection weight coefficients of the first hidden layer and the second hidden layer; and holding a computational result from the computation circuit in the output holding circuit, and when an output of the computation circuit is not transmitted to an output layer, further repeating an operation identical to an operation performed on the second hidden layer, using memory cells corresponding to a next hidden layer.
6. The method according to claim 5, further comprising: repeating an operation of selecting the at least one first bit line or the at least one second bit line, connecting the at least one first bit line or the at least one second bit line to the computation circuit, and holding a computational result from the computation circuit in the output holding circuit, while changing a selected bit line until all computational results of nodes in a next layer are obtained.
</claims>
</document>
