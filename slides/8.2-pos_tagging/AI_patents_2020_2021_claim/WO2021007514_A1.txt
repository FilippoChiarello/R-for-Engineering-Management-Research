<document>

<filing_date>
2020-07-10
</filing_date>

<publication_date>
2021-01-14
</publication_date>

<priority_date>
2019-07-10
</priority_date>

<ipc_classes>
G01V99/00,G06K9/62,G09B23/40
</ipc_classes>

<assignee>
SCHLUMBERGER TECHNOLOGY
SCHLUMBERGER TECHNOLOGY
SERVICES PETROLIERS SCHLUMBERGER
SCHLUMBERGER CANADA
</assignee>

<inventors>
SALMAN, NADER
HAKOPIAN, VAHAGN
AMBLARD, Victor
</inventors>

<docdb_family_id>
71995056
</docdb_family_id>

<title>
ACTIVE LEARNING FOR INSPECTION TOOL
</title>

<abstract>
A method can include receiving labeled images; acquiring unlabeled images; performing active learning by training an inspection learner using at least a portion of the labeled images to generate a trained inspection learner that outputs information responsive to receipt of one of the unlabeled images by the trained inspection learner; based at least in part on the information, making a decision to call for labeling of the one of the unlabeled images; receiving a label for the one of the unlabeled images; and further training the inspection learner using the label.
</abstract>

<claims>
What is claimed is:
1. A method comprising:
receiving labeled images;
acquiring unlabeled images;
performing active learning by training an inspection learner using at least a portion of the labeled images to generate a trained inspection learner that outputs information responsive to receipt of one of the unlabeled images by the trained inspection learner;
making a decision to call for labeling of the one of the unlabeled images based at least in part on the information;
receiving a label for the one of the unlabeled images; and
further training the inspection learner using the label.
2. The method of claim 1, wherein the information comprises uncertainty information as to one or more features in the one of the unlabeled images.
3. The method of claim 1, comprising:
training a density learner that generates a density metric responsive to receipt of an image and comprising making the decision to label the one of the unlabeled images using at least the density metric.
4. The method of claim 1, comprising:
receiving a trained density learner that generates a density metric responsive to receipt of an image and comprising making the decision to label the one of the unlabeled images using at least the density metric.
5. The method of claim 1, comprising: training a typicality learner that generates a typicality metric responsive to receipt of an image and comprising making the decision to label the one of the unlabeled images using at least the typicality metric.
6. The method of claim 1, wherein the training the inspection learner comprises utilizing a density metric and a typicality metric.
7. The method of claim 1, wherein the label comprises a machine generated label.
8. The method of claim 1, wherein the label comprises a machine generated label that depends on receipt of a signal from a human input device.
9. The method of claim 1, comprising, after further training the inspection learner using the label, generating a deployable trained inspection learner.
10. The method of claim 9, comprising deploying the trained inspection learner to a machine vision system.
11. The method of claim 10, wherein the machine vision system comprises at least one subsea image acquisition unit.
12. The method of claim 1, comprising:
computing a relevance score, a density score, a typicality score and an uncertainty score using output of a density learner, a typicality learner and the inspection learner and, based at least in part on one or more of the scores, calling for analysis of one of the labeled images or analysis of one of the unlabeled images.
13. The method of claim 12, wherein the analysis of one of the unlabeled images calls for labeling of the one of the unlabeled images.
14. The method of claim 12, wherein the analysis of one of the labeled images calls for healing of the one of the unlabeled images.
15. The method of claim 1, wherein the inspection learner comprises an object detector that comprises at least one neural network.
16. The method of claim 1, wherein the inspection learner comprises an ensemble of object detectors and wherein the information comprises maximum entropy information as to relevance of the one of the unlabeled images.
17. The method of claim 1, comprising selecting one of the unlabeled images, extracting at least one feature from the selected one of the unlabeled images, and generating feature results for the one of the unlabeled images.
18. The method of claim 17, comprising:
selecting at least one other unlabeled image using the information and the feature results.
19. A system comprising:
a processor;
memory accessible to the processor;
instructions stored in the memory and executable by the processor to instruct the system to:
receive labeled images;
acquire unlabeled images;
perform active learning by training an inspection learner using at least a portion of the labeled images to generate a trained inspection learner that outputs information responsive to receipt of one of the unlabeled images by the trained inspection learner;
make a decision to call for labeling of the one of the unlabeled images based at least in part on the information; receive a label for the one of the unlabeled images; and
further train the inspection learner using the label.
20. One or more computer-readable storage media comprising computer-executable instructions executable to instruct a computing system to:
receive labeled images;
acquire unlabeled images;
perform active learning by training an inspection learner using at least a portion of the labeled images to generate a trained inspection learner that outputs information responsive to receipt of one of the unlabeled images by the trained inspection learner; based at least in part on the information, make a decision to call for labeling of the one of the unlabeled images;
receive a label for the one of the unlabeled images; and
further train the inspection learner using the label.
</claims>
</document>
