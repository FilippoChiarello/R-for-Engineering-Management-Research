<document>

<filing_date>
2019-07-02
</filing_date>

<publication_date>
2020-11-17
</publication_date>

<priority_date>
2015-09-22
</priority_date>

<ipc_classes>
G06F16/538,G06F16/583,G06K9/00,G08B13/196
</ipc_classes>

<assignee>
IMAGESLEUTH
</assignee>

<inventors>
FRIEDLAND, NOAH S.
</inventors>

<docdb_family_id>
68236494
</docdb_family_id>

<title>
Surveillance and monitoring system that employs automated methods and subsystems that identify and characterize face tracks in video
</title>

<abstract>
The present document is directed to automated and semi-automated surveillance and monitoring methods and systems that continuously record digital video, identify and characterize face tracks in the recorded digital video, store the face tracks in a face-track database, and provide query processing functionalities that allow particular face tracks to be quickly identified and used for a variety of surveillance and monitoring purposes. The currently disclosed methods and systems provide, for example, automated anomaly and threat detection, alarm generation, rapid identification of images of parameter-specified individuals within recorded digital video and mapping the parameter-specified individuals in time and space within monitored geographical areas or volumes, functionalities for facilitating human-witness identification of images of individuals within monitored geographical areas or volumes, and many additional functionalities.
</abstract>

<claims>
1. A surveillance-and-monitoring system comprising: multiple processors; multiple memories; multiple data-storage devices; a video-processing subsystem, executed by one or more of the multiple processors, that uses one or more of the multiple memories and data-storage devices to receive video streams from multiple video cameras, store frames of the video streams in a video store, and forward frames to a track-generator; the track-generator, executed by one or more of the multiple processors, that uses one or more of the multiple memories and data-storage devices to generate face tracks and store the face tracks in a face-track database, each face track containing attribute values, characteristic values, and an indication of multiple video frames spanned by the face track, the attributes and characteristics including gender, ethnicity, age, and other attributes associated with an individual; and a search-and-services subsystem, executed by one or more of the multiple processors, that uses one or more of the multiple memories and data-storage devices to receive requests that each includes an indication of a requested operation and one or more attribute and/or characteristic values, search the face-track database to identify face tracks corresponding to the one or more attribute values and/or one or more characteristic values, and use the identified face tracks to return responses to the received requests.
2. The surveillance-and-monitoring system of claim 1 wherein the search-and-services subsystem receives a request for face tracks corresponding to an individual specified, in the request, by one or more attribute values and/or one or more characteristic values; searches the face-track database to identify face tracks corresponding to the one or more attribute values and/or one or more characteristic values; and returns the identified face tracks as a response to the request.
3. The surveillance-and-monitoring system of claim 1 wherein the search-and-services subsystem receives a request for face tracks corresponding to multiple individuals, each individual specified, in the request, by one or more attribute values and/or one or more characteristic values; searches the face-track database to identify face tracks corresponding to the one or more attribute values and/or one or more characteristic values; selects one or more face tracks that correspond to a maximum number of the multiple individuals; and returns the selected face tracks as a response to the request.
4. The surveillance-and-monitoring system of claim 1 wherein the search-and-services subsystem receives a request to store alert rules for automatic application to newly generated face tracks; and stores the alert rules in an alert-rule store.
5. The surveillance-and-monitoring system of claim 1 wherein the search-and-services subsystem receives a request to store face-track-redaction rules for automatic application to newly generated face tracks and/or to stored face tracks; and stores the face-track-redaction rules in a face-track-redaction-rule store.
6. The surveillance-and-monitoring system of claim 1 wherein the search-and-services subsystem receives a request to mark a face track for redaction; and marks the face track for redaction.
7. The surveillance-and-monitoring system of claim 1 wherein the search-and-services subsystem receives a request for frame-by-frame face track redaction from a client-side application; returns, to the client-side application; requested frames; receives instructions to redact particular face tracks within the frames from the client-side application; and redacts the particular face tracks according to the received instructions.
8. The surveillance-and-monitoring system of claim 1 wherein the search-and-services subsystem receives a request for a lineup, from a client-side application, that includes one or more attribute values and/or one or more characteristic values; searches the searches the face-track database to identify face tracks corresponding to the one or more attribute values and/or one or more characteristic values; selects one or more face tracks according to lineup criteria; and returns, to the client-side application, the selected face tracks as a response to the request for display by the client-side application as a lineup.
9. The surveillance-and-monitoring system of claim 1 wherein the video-processing subsystem additionally stores state and configuration information; and wherein the video-processing subsystem is implemented as a distributed service.
10. The surveillance-and-monitoring system of claim 1 wherein the track-generator further comprises: a track-generator agent associated with each video camera that receives frames generated by the associated camera; launches, for each frame, a face-regions-detection agent to detect face regions within the frame and to launch face-attribute agents to assign attributes to the detected face regions; and a track-completion service that receives face regions and face attributes generated by the face-regions-detection agents and face-attribute agents; generates, from the received face regions and face attributes, face tracks; and forwards the face tracks to a face-track-storage service for storage in the face-track database.
11. A method that identifies, stores, and retrieves face tracks implemented in a computer system that includes multiple processors, multiple memories, and multiple data-storage devices, the method comprising: ingesting video streams by receiving and storing video streams from multiple video cameras, generating face tracks from the received video streams, storing the face tracks in a face-track database, each face track containing attribute values, characteristic values, and an indication of multiple video frames spanned by the face track, the attributes and characteristics including gender, ethnicity, age, and other attributes associated with an individual; and retrieving one or more face tracks by receiving a request that includes an indication of a requested operation and one or more attribute and/or characteristic values, searching the face-track database to identify and retrieve one or more face tracks corresponding to the one or more attribute values and/or one or more characteristic values from the face-track database, and using the one or more retrieved face tracks to prepare and return a response to the received request.
12. The method of claim 11 further including: after generating a face track, applying one or more alert rules to the face track to determine whether or not an alert condition is associated with the face track; and when an alert condition is associated with the face track, distribute one or more indications of the alert to processor-controlled devices designated to receive alert indications for the alert condition.
13. The method of claim 11 further including: after generating a face track, applying one or more redaction rules to the face track to determine whether or not the face track should be redacted; and when the face track should be redacted, redacting the face track.
14. The method of claim 11 wherein the face track includes references to multiple video frames that includes images of a particular individual; and wherein the face track is redacted by one or more of blurring, obscuring, or removing features from the face of the individual in the referenced video frames.
15. The method of claim 11 further including: after generating a face track, applying one or more redaction rules to the face track to determine whether or not the face track should be redacted; and when the face track should be redacted, marking the face track for redaction.
16. The method of claim 11 wherein the face track includes references to multiple video frames that includes images of a particular individual; and wherein, when the face track is retrieved from the face-track database and the video frames referenced by the face track are retrieved from the video store, redacting the face track by one or more of blurring, obscuring, or removing features from the face of the individual in the retrieved video frames prior to transmitting the retrieved video frames to a user device.
17. The method of claim 11 further including: receiving a request that requests redaction of one or more face tracks; searching the face-track database to identify and retrieve the one or more face tracks; retrieving the video frames referenced by the face track; redacting the one or more retrieved video frames; and and replacing the one or more retrieved video frames in the video store with the redacted face tracks.
18. The method of claim 11 further including: after generating a face track, using one or more attributes and/or characteristics in the face track to update time-associated cumulative statistics and characteristics for one or more of the multiple video cameras; and using the time-associated cumulative statistics and characteristics, by a temporal-characteristics monitor, to detect anomalous conditions.
19. The method of claim 11 further including: receiving a request that requests a lineup, for a specified location and time frame, that includes individuals with one or more specified attributes and, or characteristics; searching the face-track database to identify and retrieve multiple face tracks corresponding to the request; and returning all or a subset of the multiple face tracks.
20. A face-track database-management system comprising: multiple processors; one or more memories; one or more data-storage devices; face tracks, stored on one or more of the one or more data-storage devices, each face track comprising references to a sequence of video frames that include images of a particular individual, attribute and characteristic values, and additional information related to the face track; and a storage and retrieval subsystem that receives queries that each includes one or more attribute and/or characteristic values, the attribute and characteristic values including age, gender, and ethnicity; searches the face-track database to identify face tracks corresponding to the one or more attribute values and/or one or more characteristic values, and returns the identified face tracks as a query response.
</claims>
</document>
