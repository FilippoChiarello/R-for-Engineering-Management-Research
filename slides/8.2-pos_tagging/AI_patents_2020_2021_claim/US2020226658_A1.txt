<document>

<filing_date>
2019-10-25
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2019-01-16
</priority_date>

<ipc_classes>
G06F16/54,G06F3/01,G06K9/00,G06N20/00,G06Q30/00,G06Q30/06,G06T11/60
</ipc_classes>

<assignee>
CAPITAL ONE SERVICES
</assignee>

<inventors>
DAGLEY, GEOFFREY
HOOVER, JASON
PRICE, MICAH
TANG, QIAOCHU
WYLIE, STEPHEN
</inventors>

<docdb_family_id>
68466258
</docdb_family_id>

<title>
Generating a product recommendation based on a user reaction
</title>

<abstract>
A device may process, after obtaining an image that includes image data concerning a product, first audio data obtained concerning a first utterance of a user of a user device, and first video data obtained concerning a first eye gaze direction of the user, to determine a first reaction of the user to the image. The device may process, after causing display of the image and an overlay superimposed on the image by the user device, second audio data obtained concerning a second utterance of the user, and second video data obtained concerning a second eye gaze direction of the user, to determine a second reaction of the user to the image and the overlay. The device may retrain a product recommendation model using the first reaction and the second reaction, and may generate and cause display of a product recommendation based on the product recommendation model.
</abstract>

<claims>
1. A method, comprising: obtaining, via a first camera of a mobile device, image data concerning a product; causing, by the mobile device and after obtaining the image data, display of product information with the image data by the mobile device; obtaining, by a second camera of the mobile device and after causing display of the product information, first video data concerning a facial expression of a user, the first camera facing a different direction than the second camera; processing, by the mobile device, the first video data to cause a reaction of the user to the product information to be determined; and causing, by the mobile device, display of a product recommendation generated based on the reaction.
2. The method of claim 1, wherein causing display of the product information with the image data comprises: processing the image data to cause the product information to be determined; generating an AR overlay that represents the product information; and causing the AR overlay to be displayed as the product information.
3. The method of claim 2, wherein the AR overlay is superimposed on the image data when displayed.
4. The method of claim 2, wherein the product is a car, and wherein the AR overlay includes information that indicates at least one of: a make of the car; a model of the car; a model year of the car; a price of the car: a safety feature of the car; a condition of the car; a mileage of the car; a transmission type of the car; a seller of the car; an ownership history of the car; an accident report for the car; or an availability of the car.
5. The method of claim 1, wherein processing the first video data to cause the reaction of the user to the product to be determined comprises: processing the first video data using a facial analysis technique to identify the facial expression; and causing the reaction to be determined based on the facial expression.
6. The method of claim 1, wherein the first camera is on an opposite side of the mobile device than the second camera.
7. The method of claim 1, wherein processing the first video data to cause the reaction of the user to the product to be determined comprises: processing the first video data to identify one or more eyes of the user; tracking movement of the one or more eyes of the user; determining an eye gaze direction based on the movement of the one or more eyes of the user; determining an attribute of the product information observed by the user based on the eye gaze direction; and associating the reaction with the attribute of the product observed by the user.
8. A mobile device, comprising: a first camera; a second camera; one or more memories; and one or more processors, communicatively coupled to the one or more memories, to: obtain, via the first camera, image data concerning a product; cause, after the image data is obtained, display of product information with the image data by the mobile device; obtain, via the second camera and after causing display of the product information, first video data concerning a facial expression of a user, the first camera facing a different direction than the second camera; process the first video data to cause a reaction of the user to the product information to be determined; and cause display of a product recommendation generated based on the reaction.
9. The mobile device of claim 8, wherein the one or more processors, when causing display of the product information with the image data, are to: process the image data to cause the product information to be determined; generate an augmented reality (AR) overlay that represents the product information; and cause the AR overlay to be displayed as the product information.
10. The mobile device of claim 9, wherein the AR overlay is superimposed on the image data when displayed.
11. The mobile device of claim 9, wherein the product is a car, and wherein the AR overlay includes information that indicates at least one of: a make of the car; a model of the car; a model year of the car; a price of the car: a safety feature of the car; a condition of the car; a mileage of the car; a transmission type of the car; a seller of the car; an ownership history of the car; an accident report for the car; or an availability of the car.
12. The mobile device of claim 8, wherein the one or more processors, when processing the first video data to cause the reaction of the user to the product to be determined, are to: process the first video data using a facial analysis technique to identify the facial expression; and cause the reaction to be determined based on the facial expression.
13. The mobile device of claim 8, wherein the first camera is on an opposite side of the mobile device than the second camera.
14. The mobile device of claim 8, wherein the one or more processors, when processing the first video data to cause the reaction of the user to the product to be determined, are to: process the first video data to identify one or more eyes of the user; track movement of the one or more eyes of the user; determine an eye gaze direction based on the movement of the one or more eyes of the user; determine an attribute of the product information observed by the user based on the eye gaze direction; and associate the reaction with the attribute of the product observed by the user.
15. A non-transitory computer-readable medium storing instructions, the instructions comprising: one or more instructions that, when executed by one or more processors of a mobile device, cause the one or more processors to: obtain, via a first camera of the mobile device, image data concerning a product; cause, after the image data is obtained, display of product information with the image data by the mobile device; obtain, via a second camera of the mobile device and after causing display of the product information, first video data concerning a facial expression of a user, the first camera facing a different direction than the second camera; process the first video data to cause a reaction of the user to the product information to be determined; and cause display of a product recommendation generated based on the reaction.
16. The non-transitory computer-readable medium of claim 15, wherein the one or more instructions, that cause the one or more processors to cause display of the product information with the image data, cause the one or more processors to: process the image data to cause the product information to be determined; generate an augmented reality (AR) overlay that represents the product information; and cause the AR overlay to be displayed as the product information.
17. The non-transitory computer-readable medium of claim 16, wherein the AR overlay is superimposed on the image data when displayed.
18. The non-transitory computer-readable medium of claim 16, wherein the product is a car, and wherein the AR overlay includes information that indicates at least one of: a make of the car; a model of the car; a model year of the car; a price of the car: a safety feature of the car; a condition of the car; a mileage of the car; a transmission type of the car; a seller of the car; an ownership history of the car; an accident report for the car; or an availability of the car.
19. The non-transitory computer-readable medium of claim 15, wherein the one or more instructions, that cause the one or more processors to process the first video data to cause the reaction of the user to the product to be determined, cause the one or more processors to: process the first video data using a facial analysis technique to identify the facial expression; and cause the reaction to be determined based on the facial expression.
20. The non-transitory computer-readable medium of claim 15, wherein the first camera is on an opposite side of the mobile device than the second camera.
</claims>
</document>
