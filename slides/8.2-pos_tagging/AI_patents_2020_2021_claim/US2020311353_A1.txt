<document>

<filing_date>
2020-03-05
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-25
</priority_date>

<ipc_classes>
G06F40/30,G06F40/58,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
RICOH COMPANY
DONG BIN
JIANG SHANSHAN
TONG YIXUAN
LI YIHAN
LIU, Boyan
</assignee>

<inventors>
DONG BIN
JIANG SHANSHAN
TONG YIXUAN
LI YIHAN
LIU, Boyan
</inventors>

<docdb_family_id>
72605916
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR PROCESSING WORD VECTOR OF NEURAL MACHINE TRANSLATION MODEL, AND NON-TRANSITORY COMPUTER-READABLE RECORDING MEDIUM
</title>

<abstract>
A method and an apparatus for processing word vectors of a neural machine translation model, and a non-transitory computer-readable recording medium are provided. In the method, word vectors that are input to an encoder and a decoder of a neural machine translation model are updated using semantic information among head representations at the same time and semantic information among head representations at different times, and the model is trained or translation is performed using the updated word vectors, thereby improving the model performance of the neural machine translation model.
</abstract>

<claims>
1. A method for processing word vectors of a neural machine translation model, the method comprising: obtaining a word vector sequence that is input to an encoder and a decoder of the neural machine translation model, the word vector sequence including at least two word vectors; dividing each word vector in the word vector sequence into a plurality of head representations with the same dimension; calculating, for each head representation serving as a target head representation, a first vector representation of the target head representation in a target word vector to which the target head representation belongs, the first vector representation being a non-linear function of a first intermediate vector, and the first intermediate vector being obtained by calculating a weighted sum of the head representations in the target word vector based on correlation parameters between respective head representations in the target word vector and the target head representation; calculating a weighted sum of head representations corresponding to respective word vectors in a target word vector sequence to which the target head representation belongs, based on attention parameters between the target head representation and head representations corresponding to respective word vectors in the target word vector sequence, to obtain a second vector representation of the target head representation among word vectors of the target word vector sequence; combining the first vector representation and the second vector representation of each of the head representations to obtain third vector representations of the respective head representations, and merging the third vector representations of the head representations in the respective word vectors to obtain the updated word vectors; and training the neural machine translation model or translating using the updated word vectors.
2. The method for processing word vectors of the neural machine translation model as claimed in claim 1, wherein calculating the first vector representation of the target head representation in the target word vector to which the target head representation belongs includes calculating the weighted sum of the head representations in the target word vector based on the correlation parameters between the respective head representations in the target word vector and the target head representation, to obtain the first intermediate vector, the correlation parameters being model parameters updated by learning during a training process of the neural machine translation model; and converting the first intermediate vector into word vector representations with the same dimension using a preset non-linear function, to obtain the first vector representation of the target head representation in the target word vector.
3. The method for processing word vectors of the neural machine translation model as claimed in claim 2, wherein calculating the weighted sum of the head representations in the target word vector based on the correlation parameters between the respective head representations in the target word vector and the target head representation includes performing normalization processing on the correlation parameters between the respective head representations in the target word vector and the target head representation to obtain respective first weights of the head representations in the target word vector; and calculating the weighted sum of the head representations in the target word vector based on the respective first weights, to obtain the first intermediate vector.
4. The method for processing word vectors of the neural machine translation model as claimed in claim 2, wherein the non-linear function is a hyperbolic tangent (tanh) function, an S-shaped growth curve (Sigmoid) function, or a rectified linear (ReLU) function.
5. The method for processing word vectors of the neural machine translation model as claimed in claim 1, wherein calculating the weighted sum of the head representations corresponding to the respective word vectors in the target word vector sequence to which the target head representation belongs, based on the attention parameters between the target head representation and the head representations corresponding to the respective word vectors in the target word vector sequence includes calculating the attention parameters between the target head representation and the head representations corresponding to the respective word vectors in the target word vector sequence, based on a preset attention function; performing normalization processing on the attention parameters between the target head representation and the head representations corresponding to the respective word vectors in the target word vector sequence to obtain respective second weights of the head representations corresponding to the respective word vectors in the target word vector sequence; and calculating the weighted sum of the head representations corresponding to the respective word vectors in the target word vector sequence based on the respective second weights, to obtain the second vector representation of the target head representation among word vectors of the target word vector sequence.
6. The method for processing word vectors of the neural machine translation model as claimed in claim 1, wherein combining the first vector representation and the second vector representation of the head representation to obtain the third vector representation of the head representation includes calculating a first product of a first combination parameter and the first vector representation of the head representation, calculating a second product of a second combination parameter and the second vector representation of the head representation, and calculating a sum of the first product and the second product to obtain the third vector representation of the head representation, wherein the first combination parameter and the second combination parameter are model parameters updated by learning during a training process of the neural machine translation model.
7. An apparatus for processing word vectors of a neural machine translation model, the apparatus comprising: a memory storing computer-executable instructions; and one or more processors configured to execute the computer-executable instructions such that the one or more processors are configured to obtain a word vector sequence that is input to an encoder and a decoder of the neural machine translation model, the word vector sequence including at least two word vectors; divide each word vector in the word vector sequence into a plurality of head representations with the same dimension; calculate, for each head representation serving as a target head representation, a first vector representation of the target head representation in a target word vector to which the target head representation belongs, the first vector representation being a non-linear function of a first intermediate vector, and the first intermediate vector being obtained by calculating a weighted sum of the head representations in the target word vector based on correlation parameters between respective head representations in the target word vector and the target head representation; calculate a weighted sum of head representations corresponding to respective word vectors in a target word vector sequence to which the target head representation belongs, based on attention parameters between the target head representation and head representations corresponding to respective word vectors in the target word vector sequence, to obtain a second vector representation of the target head representation among word vectors of the target word vector sequence; combine the first vector representation and the second vector representation of each of the head representations to obtain third vector representations of the respective head representations, and merge the third vector representations of the head representations in the respective word vectors to obtain the updated word vectors; and train the neural machine translation model or translate using the updated word vectors.
8. The apparatus for processing word vectors of the neural machine translation model as claimed in claim 7, wherein the one or more processors are configured to calculate the weighted sum of the head representations in the target word vector based on the correlation parameters between the respective head representations in the target word vector and the target head representation, to obtain the first intermediate vector, the correlation parameters being model parameters updated by learning during a training process of the neural machine translation model; and convert the first intermediate vector into word vector representations with the same dimension using a preset non-linear function, to obtain the first vector representation of the target head representation in the target word vector.
9. The apparatus for processing word vectors of the neural machine translation model as claimed in claim 8, wherein the one or more processors are configured to perform normalization processing on the correlation parameters between the respective head representations in the target word vector and the target head representation to obtain respective first weights of the head representations in the target word vector; and calculate the weighted sum of the head representations in the target word vector based on the respective first weights, to obtain the first intermediate vector.
10. The apparatus for processing word vectors of the neural machine translation model as claimed in claim 8, wherein the non-linear function is a hyperbolic tangent (tanh) function, an S-shaped growth curve (Sigmoid) function, or a rectified linear (ReLU) function.
11. The apparatus for processing word vectors of the neural machine translation model as claimed in claim 7, wherein the one or more processors are configured to calculate the attention parameters between the target head representation and the head representations corresponding to the respective word vectors in the target word vector sequence, based on a preset attention function; perform normalization processing on the attention parameters between the target head representation and the head representations corresponding to the respective word vectors in the target word vector sequence to obtain respective second weights of the head representations corresponding to the respective word vectors in the target word vector sequence; and calculate the weighted sum of the head representations corresponding to the respective word vectors in the target word vector sequence based on the respective second weights, to obtain the second vector representation of the target head representation among word vectors of the target word vector sequence.
12. The apparatus for processing word vectors of the neural machine translation model as claimed in claim 7, wherein the one or more processors are configured to calculate a first product of a first combination parameter and the first vector representation of the head representation, calculate a second product of a second combination parameter and the second vector representation of the head representation, and calculate a sum of the first product and the second product to obtain the third vector representation of the head representation, wherein the first combination parameter and the second combination parameter are model parameters updated by learning during a training process of the neural machine translation model.
13. A non-transitory computer-readable recording medium having computer-executable instructions for execution by one or more processors, wherein, the computer-executable instructions, when executed, cause the one or more processors to carry out a method for processing word vectors of a neural machine translation model, the method comprising: obtaining a word vector sequence that is input to an encoder and a decoder of the neural machine translation model, the word vector sequence including at least two word vectors; dividing each word vector in the word vector sequence into a plurality of head representations with the same dimension; calculating, for each head representation serving as a target head representation, a first vector representation of the target head representation in a target word vector to which the target head representation belongs, the first vector representation being a non-linear function of a first intermediate vector, and the first intermediate vector being obtained by calculating a weighted sum of the head representations in the target word vector based on correlation parameters between respective head representations in the target word vector and the target head representation; calculating a weighted sum of head representations corresponding to respective word vectors in a target word vector sequence to which the target head representation belongs, based on attention parameters between the target head representation and head representations corresponding to respective word vectors in the target word vector sequence, to obtain a second vector representation of the target head representation among word vectors of the target word vector sequence; combining the first vector representation and the second vector representation of each of the head representations to obtain third vector representations of the respective head representations, and merging the third vector representations of the head representations in the respective word vectors to obtain the updated word vectors; and training the neural machine translation model or translating using the updated word vectors.
14. The non-transitory computer-readable recording medium as claimed in claim 13, wherein calculating the first vector representation of the target head representation in the target word vector to which the target head representation belongs includes calculating the weighted sum of the head representations in the target word vector based on the correlation parameters between the respective head representations in the target word vector and the target head representation, to obtain the first intermediate vector, the correlation parameters being model parameters updated by learning during a training process of the neural machine translation model; and converting the first intermediate vector into word vector representations with the same dimension using a preset non-linear function, to obtain the first vector representation of the target head representation in the target word vector.
15. The non-transitory computer-readable recording medium as claimed in claim 14, wherein calculating the weighted sum of the head representations in the target word vector based on the correlation parameters between the respective head representations in the target word vector and the target head representation includes performing normalization processing on the correlation parameters between the respective head representations in the target word vector and the target head representation to obtain respective first weights of the head representations in the target word vector; and calculating the weighted sum of the head representations in the target word vector based on the respective first weights, to obtain the first intermediate vector.
16. The non-transitory computer-readable recording medium as claimed in claim 14, wherein the non-linear function is a hyperbolic tangent (tanh) function, an S-shaped growth curve (Sigmoid) function, or a rectified linear (ReLU) function.
17. The non-transitory computer-readable recording medium as claimed in claim 13, wherein calculating the weighted sum of the head representations corresponding to the respective word vectors in the target word vector sequence to which the target head representation belongs, based on the attention parameters between the target head representation and the head representations corresponding to the respective word vectors in the target word vector sequence includes calculating the attention parameters between the target head representation and the head representations corresponding to the respective word vectors in the target word vector sequence, based on a preset attention function; performing normalization processing on the attention parameters between the target head representation and the head representations corresponding to the respective word vectors in the target word vector sequence to obtain respective second weights of the head representations corresponding to the respective word vectors in the target word vector sequence; and calculating the weighted sum of the head representations corresponding to the respective word vectors in the target word vector sequence based on the respective second weights, to obtain the second vector representation of the target head representation among word vectors of the target word vector sequence.
18. The non-transitory computer-readable recording medium as claimed in claim 13, wherein combining the first vector representation and the second vector representation of the head representation to obtain the third vector representation of the head representation includes calculating a first product of a first combination parameter and the first vector representation of the head representation, calculating a second product of a second combination parameter and the second vector representation of the head representation, and calculating a sum of the first product and the second product to obtain the third vector representation of the head representation, wherein the first combination parameter and the second combination parameter are model parameters updated by learning during a training process of the neural machine translation model.
</claims>
</document>
