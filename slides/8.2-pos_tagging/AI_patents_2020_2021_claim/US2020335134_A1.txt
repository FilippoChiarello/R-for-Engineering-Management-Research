<document>

<filing_date>
2020-06-10
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2017-03-02
</priority_date>

<ipc_classes>
G06F16/732,G06F16/738,G06F16/78,G06F16/783,G06K9/00,G11B27/031
</ipc_classes>

<assignee>
RICOH COMPANY
GONZALEZ-BANOS, HECTOR, H.
NARASIMHA, RAMYA
</assignee>

<inventors>
GONZALEZ-BANOS, HECTOR, H.
NARASIMHA, RAMYA
</inventors>

<docdb_family_id>
61226469
</docdb_family_id>

<title>
Decomposition of a Video Stream into Salient Fragments
</title>

<abstract>
The disclosure includes a system and method for decomposing a video to salient fragments and synthesizing a video composition based on the salient fragments. A computer-implemented method receives a first set of salient fragments and a first set of clusters extracted from a video, where each cluster includes related salient fragments connected by a connectivity graph. The method determines a weight associated with each of the salient fragments and each of the clusters based on an activity level associated with the respective salient fragment or cluster and determine a permissible zone of activity. The method determines a spatial-temporal distortion to be applied to each salient fragment and cluster and synthesizes a video composition based on the first set of salient fragments, the first set of clusters and non-salient portions of the video using weighted editing.
</abstract>

<claims>
1. A computer-implemented method comprising: receiving a first set of salient fragments and a first set of clusters extracted from a video, where each cluster includes related salient fragments connected by a connectivity graph connecting the related salient fragments of the video based on a spatial-temporal overlap or causality relationship between the salient fragments; receiving non-salient portions of the video; determining a weight associated with each of the salient fragments and each of the clusters based on an activity level associated with the respective salient fragment or cluster; determining a permissible zone of activity; determining a spatial-temporal distortion to be applied to each salient fragment and cluster; and synthesizing a video composition based on the first set of salient fragments, the first set of clusters and the non-salient portions of the video using weighted editing by assigning each salient fragment and cluster to an editing layer based on the weight corresponding to the respective salient fragment and cluster.
2. The computer-implemented method according to claim 1 further comprising: determining a permissible zone of activity based on the received salient fragments and clusters and the received non-salient portions of the video.
3. The computer-implemented method according to claim 1 further comprising: determining a permissible zone of activity based on an input from a user.
4. The computer-implemented method according to claim 1, further comprising: determining a time shift and a spatial shift based on the permissible zone of activity as the spatial-temporal distortion to be applied to each salient fragment and cluster.
5. The computer-implemented method of claim 1, further comprising extracting non-salient portions of the video; extracting a plurality of salient fragments of the video; determining a connectivity graph connecting related salient fragments of the video based on a spatial-temporal overlap or causality relationship between the plurality of salient fragments; grouping the plurality of salient fragments into a plurality of clusters, wherein the clusters include salient fragments having a spatial-temporal or causal relationship; building a database of the plurality of salient fragments based on the clusters; receiving a query; and retrieving, from the database of the plurality of salient fragments, the first set of salient fragments and the first set of clusters in response to the query.
6. The computer-implemented method of claim 5, further comprising: identifying a salient fragment based on at least one of motion detection, contrast, color, and semantic information.
7. The computer-implemented method of claim 5, wherein each salient fragment is a portion of the video for a single salient activity localized in time and space.
8. The computer-implemented method of claim 5, further comprising: identifying a first salient fragment related to the query; and retrieving the first set of salient fragments in response to the query by retrieving the salient fragments connected in the connectivity graph to the first salient fragment.
9. The computer-implemented method of claim 5, wherein the query includes at least one of: the first salient fragment of the plurality of salient fragments, the first salient fragment and a second salient fragment of the plurality of salient fragments, a time interval, or an attribute associated with salient fragments of the plurality of salient fragments.
10. The computer-implemented method of claim 5, further comprising building an index for the database of the plurality of salient fragments, wherein the index is used for fast retrieval of salient fragments within the database.
11. A system comprising: one or more processors; and a memory, the memory storing instructions, which when executed by the one or more processors cause the one or more processors to: receive a first set of salient fragments and a first set of clusters extracted from a video, where each cluster includes related salient fragments connected by a connectivity graph connecting the related salient fragments of the video based on a spatial-temporal overlap or causality relationship between the salient fragments; receive non-salient portions of the video; determine a weight associated with each of the salient fragments and each of the clusters based on an activity level associated with the respective salient fragment or cluster; determine a permissible zone of activity; determine a spatial-temporal distortion to be applied to each salient fragment and cluster; and synthesize a video composition based on the first set of salient fragments, the first set of clusters and the non-salient portions of the video using weighted editing by assigning each salient fragment and cluster to an editing layer based on the weight corresponding to the respective salient fragment and cluster.
12. The system of claim 11, wherein the instructions cause the one or more processors to determine a permissible zone of activity based on the received salient fragments and clusters and the received non-salient portions of the video.
13. The system of claim 11, wherein the instructions cause the one or more processors to determine a permissible zone of activity based on an input from a user.
14. The system of claim 11, wherein the instructions cause the one or more processors to determine a time shift and a spatial shift based on the permissible zone of activity as the spatial-temporal distortion to be applied to each salient fragment and cluster.
15. The system of claim 11, wherein the instructions cause the one or more processors to: extract non-salient portions of the video; extract a plurality of salient fragments of the video; determine a connectivity graph connecting related salient fragments of the video based on a spatial-temporal overlap or causality relationship between the plurality of salient fragments; group the plurality of salient fragments into a plurality of clusters, wherein the clusters include salient fragments having a spatial-temporal or causal relationship; build a database of the plurality of salient fragments based on the clusters; receive a query; and retrieve, from the database of the plurality of salient fragments, the first set of salient fragments and the first set of clusters in response to the query.
16. The system of claim 15, wherein the instructions cause the one or more processors to identify a salient fragment based on at least one of motion detection, contrast, color, and semantic information.
17. The system of claim 15, wherein each salient fragment is a portion of the video for a single salient activity localized in time and space.
18. The system of claim 15, wherein the instructions cause the one or more processors to: identify a first salient fragment related to the query; and retrieve the first set of salient fragments in response to the query by retrieving the salient fragments connected in the connectivity graph to the first salient fragment.
19. The system of claim 15, wherein the query includes at least one of the first salient fragment of the plurality of salient fragments, the first salient fragment and a second salient fragment of the plurality of salient fragments, a time interval, or an attribute associated with salient fragments of the plurality of salient fragments.
20. A computer program product comprising a non-transitory computer readable medium storing a computer readable program, wherein the computer readable program when executed causes a computer to: receive a first set of salient fragments and a first set of clusters extracted from a video, where each cluster includes related salient fragments connected by a connectivity graph connecting the related salient fragments of the video based on a spatial-temporal overlap or causality relationship between the salient fragments; receive non-salient portions of the video; determine a weight associated with each of the salient fragments and each of the clusters based on an activity level associated with the respective salient fragment or cluster; determine a permissible zone of activity; determine a spatial-temporal distortion to be applied to each salient fragment and cluster; and synthesize a video composition based on the first set of salient fragments, the first set of clusters and the non-salient portions of the video using weighted editing by assigning each salient fragment and cluster to an editing layer based on the weight corresponding to the respective salient fragment and cluster.
</claims>
</document>
