<document>

<filing_date>
2020-06-30
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2018-06-15
</priority_date>

<ipc_classes>
G06K9/46,G06K9/62
</ipc_classes>

<assignee>
TENCENT TECHNOLOGY (SHENZHEN) COMPANY
</assignee>

<inventors>
LIU WEI
CHEN, Weidong
WU, Baoyuan
</inventors>

<docdb_family_id>
67644968
</docdb_family_id>

<title>
METHOD , APPARATUS, AND STORAGE MEDIUM FOR ANNOTATING IMAGE
</title>

<abstract>
The present disclosure describes a method, apparatus, and storage medium for annotating image. The method includes extracting, by a device, a visual feature of an image through a generative adversarial network model, and sequentially inputting M pieces of random noise into the generative adversarial network model. In response to each of the M pieces of random noise being inputted into the generative adversarial network model, the method includes performing a determinantal point process (DPP) on the visual feature of the image and the each random noise through the generative adversarial network model to obtain N tag subsets, and selecting a distinct tag subset from the N tag subsets through the generative adversarial network model. The method also includes outputting M distinct tag subsets through the generative adversarial network model after the M pieces of random noise are inputted into the generative adversarial network model.
</abstract>

<claims>
1. A method for annotating image, the method comprising: extracting, by a device comprising a memory storing instructions and a processor in communication with the memory, a visual feature of an image from the image through a generative adversarial network model; sequentially inputting, by the device, M pieces of random noise into the generative adversarial network model, M being a positive integer; in response to each of the M pieces of random noise being inputted into the generative adversarial network model: performing, by the device, a determinantal point process (DPP) on the visual feature of the image and the each random noise through the generative adversarial network model to obtain N tag subsets, N being a positive integer, and selecting, by the device, a distinct tag subset from the N tag subsets through the generative adversarial network model; and outputting, by the device, M distinct tag subsets through the generative adversarial network model after the M pieces of random noise are inputted into the generative adversarial network model, the M distinct tag subsets being diverse from each other.
2. The method according to claim 1, wherein: the generative adversarial network model comprises a generative network model and an adversarial network model; and before the extracting the visual feature of the image from the image through the generative adversarial network model, the method further comprises: obtaining, by the device, a sample image from a sample database, extracting, by the device, a sample visual feature from the sample image through the generative network model, performing, by the device, the DPP on the sample visual feature and a single piece of random noise through the generative network model, to obtain N sample tag subsets, selecting, by the device, one distinct sample tag subset from the N sample tag subsets through the generative network model, and performing, by the device, alternate training on the generative network model and the adversarial network model by using the distinct sample tag subset and the sample visual feature of the image.
3. The method according to claim 2, wherein the performing alternate training on the generative network model and the adversarial network model by using the sample tag subset and the sample visual feature of the sample image comprises: obtaining, by the device in current training of the generative network model, a sampled tag outputted by the generative network model in previous training; obtaining, by the device through a reinforcement learning algorithm, a policy function used for measuring a possibility that the generative network model outputs a next tag based on the sample image and the sampled tag; updating, by the device, the generative network model according to a gradient value of the policy function; obtaining, by the device in current training of the adversarial network model, a distinct sample tag subset outputted by the generative network model on which the current training is completed; and performing, by the device, discrimination on the sample tag subset and the sample visual feature through the adversarial network model, and outputting a discrimination result.
4. The method according to claim 3, wherein the obtaining, through the reinforcement learning algorithm, the policy function used for measuring the possibility that the generative network model outputs the next tag based on the sample image and the sampled tag comprises: determining, by the device, a correlation function between the sampled tag and the sample image through the generative network model; obtaining, by the device, a timely reward function according to the correlation function between the sampled tag and the sample image; and obtaining, by the device, the policy function according to the timely reward function and a marginal probability of selecting the next tag.
5. The method according to claim 3, wherein the performing the discrimination on the sample tag subset and the sample visual feature through the adversarial network model comprises: vectorizing, by the device, all sample tags in the sample tag subset, to obtain a plurality of sample tag vectors; obtaining, by the device, correlation scores between the plurality of sample tag vectors and a feature vector corresponding to the sample visual feature; and obtaining, by the device, a correlation score between the sample tag subset and the visual feature of the image according to the correlation scores corresponding to the plurality of sample tag vectors.
6. The method according to claim 1, wherein the performing the DPP on the visual feature of the image and the each random noise through the generative adversarial network model to obtain N tag subsets comprises: concatenating, by the device, a feature vector corresponding to the visual feature and a noise vector corresponding to the each random noise, to obtain a hybrid vector; obtaining, by the device according to a candidate tag set, a correlation function unrelated to the visual feature; performing, by the device, the DPP on the correlation function and the hybrid vector through the generative adversarial network model, to obtain a probability distribution function; performing, by the device, sequential sampling according to the probability distribution function, to obtain a current tag; determining, by the device by using a weighted semantic path (WSP), whether the current tag and a sampled tag that is obtained before current sampling are from the same semantic path; in response to determining that that the current tag and the sampled tag are from the same semantic path, discarding, by the device, the current tag and performing sampling again; in response to determining that that the current tag and the sampled tag are not from the same semantic path, reserving, by the device, the current tag and sampling a next tag; performing, by the device, the above step of performing sequential sampling until a quantity of tags obtained through sampling reaches a maximum tag quantity of a tag subset; and continuing, by the device, to perform sampling in a case that the quantity of tags obtained through sampling reaches the maximum tag quantity of the tag subset, until the N tag subsets are collected.
7. The method according to claim 6, wherein the selecting the distinct tag subset from the N tag subsets through the generative adversarial network model comprises: respectively calculating, by the device, a sum of weights corresponding to all tags in each tag subset in the N tag subsets by using the WSP, to obtain total tag weights respectively corresponding to the N tag subsets; and selecting, by the device, a tag subset with a maximum weight as the distinct tag subset according to the total tag weights respectively corresponding to the N tag subsets.
8. An apparatus for annotating image, the apparatus comprising: a memory storing instructions; and a processor in communication with the memory, wherein, when the processor executes the instructions, the processor is configured to cause the apparatus to: extract a visual feature of an image from the image through a generative adversarial network model, sequentially input M pieces of random noise into the generative adversarial network model, M being a positive integer, in response to each of the M pieces of random noise being inputted into the generative adversarial network model: perform a determinantal point process (DPP) on the visual feature of the image and the each random noise through the generative adversarial network model to obtain N tag subsets, N being a positive integer, and select a distinct tag subset from the N tag subsets through the generative adversarial network model, and output M distinct tag subsets through the generative adversarial network model after the M pieces of random noise are inputted into the generative adversarial network model, the M distinct tag subsets being diverse from each other.
9. The apparatus according to claim 8, wherein, the generative adversarial network model comprises a generative network model and an adversarial network model; and before the processor is configured to cause the apparatus to extract the visual feature of the image from the image through the generative adversarial network model, the processor is configured to cause the apparatus to: obtain a sample image from a sample database, extract a sample visual feature from the sample image through the generative network model, perform the DPP on the sample visual feature and a single piece of random noise through the generative network model, to obtain N sample tag subsets, select one distinct sample tag subset from the N sample tag subsets through the generative network model, and perform alternate training on the generative network model and the adversarial network model by using the distinct sample tag subset and the sample visual feature of the image.
10. The apparatus according to claim 9, wherein, when the processor is configured to cause the apparatus to perform alternate training on the generative network model and the adversarial network model by using the sample tag subset and the sample visual feature of the sample image, the processor is configured to cause the apparatus to: obtain, in current training of the generative network model, a sampled tag outputted by the generative network model in previous training; obtain, through a reinforcement learning algorithm, a policy function used for measuring a possibility that the generative network model outputs a next tag based on the sample image and the sampled tag; update the generative network model according to a gradient value of the policy function; obtain, in current training of the adversarial network model, a distinct sample tag subset outputted by the generative network model on which the current training is completed; and perform discrimination on the sample tag subset and the sample visual feature through the adversarial network model, and outputting a discrimination result.
11. The apparatus according to claim 10, wherein, when the processor is configured to cause the apparatus to obtain, through the reinforcement learning algorithm, the policy function used for measuring the possibility that the generative network model outputs the next tag based on the sample image and the sampled tag, the processor is configured to cause the apparatus to: determine a correlation function between the sampled tag and the sample image through the generative network model; obtain a timely reward function according to the correlation function between the sampled tag and the sample image; and obtain the policy function according to the timely reward function and a marginal probability of selecting the next tag.
12. The apparatus according to claim 10, wherein, when the processor is configured to cause the apparatus to perform the discrimination on the sample tag subset and the sample visual feature through the adversarial network model, the processor is configured to cause the apparatus to: vectorize all sample tags in the sample tag subset, to obtain a plurality of sample tag vectors; obtain correlation scores between the plurality of sample tag vectors and a feature vector corresponding to the sample visual feature; and obtain a correlation score between the sample tag subset and the visual feature of the image according to the correlation scores corresponding to the plurality of sample tag vectors.
13. The apparatus according to claim 8, wherein, when the processor is configured to cause the apparatus to perform the DPP on the visual feature of the image and the each random noise through the generative adversarial network model to obtain N tag subsets, the processor is configured to cause the apparatus to: concatenate a feature vector corresponding to the visual feature and a noise vector corresponding to the each random noise, to obtain a hybrid vector; obtain, according to a candidate tag set, a correlation function unrelated to the visual feature; perform the DPP on the correlation function and the hybrid vector through the generative adversarial network model, to obtain a probability distribution function; perform sequential sampling according to the probability distribution function, to obtain a current tag; determine, by using a weighted semantic path (WSP), whether the current tag and a sampled tag that is obtained before current sampling are from the same semantic path; in response to determining that that the current tag and the sampled tag are from the same semantic path, discard the current tag and perform sampling again; in response to determining that that the current tag and the sampled tag are not from the same semantic path, reserve the current tag and sample a next tag; performing the above step of performing sequential sampling until a quantity of tags obtained through sampling reaches a maximum tag quantity of a tag subset; and continue to perform sampling in a case that the quantity of tags obtained through sampling reaches the maximum tag quantity of the tag subset, until the N tag subsets are collected.
14. The apparatus according to claim 13, wherein, when the processor is configured to cause the apparatus to select the distinct tag subset from the N tag subsets through the generative adversarial network model, the processor is configured to cause the apparatus to: respectively calculate a sum of weights corresponding to all tags in each tag subset in the N tag subsets by using the WSP, to obtain total tag weights respectively corresponding to the N tag subsets; and select a tag subset with a maximum weight as the distinct tag subset according to the total tag weights respectively corresponding to the N tag subsets.
15. A non-transitory computer readable storage medium storing computer readable instructions, wherein, the computer readable instructions, when executed by a processor, are configured to cause the processor to perform: extracting a visual feature of an image from the image through a generative adversarial network model; sequentially inputting M pieces of random noise into the generative adversarial network model, M being a positive integer; in response to each of the M pieces of random noise being inputted into the generative adversarial network model: performing a determinantal point process (DPP) on the visual feature of the image and the each random noise through the generative adversarial network model to obtain N tag subsets, N being a positive integer, and selecting a distinct tag subset from the N tag subsets through the generative adversarial network model; and outputting M distinct tag subsets through the generative adversarial network model after the M pieces of random noise are inputted into the generative adversarial network model, the M distinct tag subsets being diverse from each other.
16. The non-transitory computer readable storage medium according to claim 15, wherein, the generative adversarial network model comprises a generative network model and an adversarial network model; and before the computer readable instructions are configured to cause the processor to perform extracting the visual feature of the image from the image through the generative adversarial network model, the computer readable instructions are configured to cause the processor to perform: obtaining a sample image from a sample database, extracting a sample visual feature from the sample image through the generative network model, performing the DPP on the sample visual feature and a single piece of random noise through the generative network model, to obtain N sample tag subsets, selecting one distinct sample tag subset from the N sample tag subsets through the generative network model, and performing alternate training on the generative network model and the adversarial network model by using the distinct sample tag subset and the sample visual feature of the image.
17. The non-transitory computer readable storage medium according to claim 16, wherein, when the computer readable instructions are configured to cause the processor to perform alternate training on the generative network model and the adversarial network model by using the sample tag subset and the sample visual feature of the sample image, the computer readable instructions are configured to cause the processor to perform: obtaining, in current training of the generative network model, a sampled tag outputted by the generative network model in previous training; obtaining, through a reinforcement learning algorithm, a policy function used for measuring a possibility that the generative network model outputs a next tag based on the sample image and the sampled tag; updating the generative network model according to a gradient value of the policy function; obtaining, in current training of the adversarial network model, a distinct sample tag subset outputted by the generative network model on which the current training is completed; and performing discrimination on the sample tag subset and the sample visual feature through the adversarial network model, and outputting a discrimination result.
18. The non-transitory computer readable storage medium according to claim 17, wherein, when the computer readable instructions are configured to cause the processor to perform obtaining, through the reinforcement learning algorithm, the policy function used for measuring the possibility that the generative network model outputs the next tag based on the sample image and the sampled tag, the computer readable instructions are configured to cause the processor to perform: determining a correlation function between the sampled tag and the sample image through the generative network model; obtaining a timely reward function according to the correlation function between the sampled tag and the sample image; and obtaining the policy function according to the timely reward function and a marginal probability of selecting the next tag.
19. The non-transitory computer readable storage medium according to claim 17, wherein, when the computer readable instructions are configured to cause the processor to perform the discrimination on the sample tag subset and the sample visual feature through the adversarial network model, the computer readable instructions are configured to cause the processor to perform: vectorizing all sample tags in the sample tag subset, to obtain a plurality of sample tag vectors; obtaining correlation scores between the plurality of sample tag vectors and a feature vector corresponding to the sample visual feature; and obtaining a correlation score between the sample tag subset and the visual feature of the image according to the correlation scores corresponding to the plurality of sample tag vectors.
20. The non-transitory computer readable storage medium according to claim 15, wherein: when the computer readable instructions are configured to cause the processor to perform the DPP on the visual feature of the image and the each random noise through the generative adversarial network model to obtain N tag subsets, the computer readable instructions are configured to cause the processor to perform: concatenating a feature vector corresponding to the visual feature and a noise vector corresponding to the each random noise, to obtain a hybrid vector, obtaining, according to a candidate tag set, a correlation function unrelated to the visual feature, performing the DPP on the correlation function and the hybrid vector through the generative adversarial network model, to obtain a probability distribution function, performing sequential sampling according to the probability distribution function, to obtain a current tag, determining, by using a weighted semantic path (WSP), whether the current tag and a sampled tag that is obtained before current sampling are from the same semantic path, in response to determining that that the current tag and the sampled tag are from the same semantic path, discarding the current tag and performing sampling again, in response to determining that that the current tag and the sampled tag are not from the same semantic path, reserving the current tag and sampling a next tag, performing the above step of performing sequential sampling until a quantity of tags obtained through sampling reaches a maximum tag quantity of a tag subset, and continuing to perform sampling in a case that the quantity of tags obtained through sampling reaches the maximum tag quantity of the tag subset, until the N tag subsets are collected; and when the computer readable instructions are configured to cause the processor to perform selecting the distinct tag subset from the N tag subsets through the generative adversarial network model, the computer readable instructions are configured to cause the processor to perform: respectively calculating a sum of weights corresponding to all tags in each tag subset in the N tag subsets by using the WSP, to obtain total tag weights respectively corresponding to the N tag subsets, and selecting a tag subset with a maximum weight as the distinct tag subset according to the total tag weights respectively corresponding to the N tag subsets.
</claims>
</document>
