<document>

<filing_date>
2017-12-08
</filing_date>

<publication_date>
2020-02-26
</publication_date>

<priority_date>
2017-04-21
</priority_date>

<ipc_classes>
H04N19/103,H04N19/119,H04N19/159,H04N19/176,H04N19/52,H04N19/96
</ipc_classes>

<assignee>
TENCENT TECHNOLOGY (SHENZHEN) COMPANY
</assignee>

<inventors>
CHENG, XIMING
LIN, SIXIN
ZHANG, HONGSHUN
</inventors>

<docdb_family_id>
63856188
</docdb_family_id>

<title>
CODING UNIT DEPTH DETERMINATION METHOD AND DEVICE
</title>

<abstract>
This application discloses a coding unit CU depth determining method and apparatus. In this application, a predictive model is pre-trained by using a training sample marked with a classification result. The training sample includes a coding information feature of a specific type. When it is determined that a residual coefficient of a current optimal mode of a to-be-processed coding unit (CU) is not 0, it is determined that coding depth prediction needs to be performed. Coding information features of the specific type are obtained from the to-be-processed CU and a neighboring coding tree unit (CTU) of a CTU in which the to-be-processed CU is located, to form prediction feature vector samples. The prediction feature vector samples are input to the predictive model, and the machine learning predictive model is used to predict whether depth division needs to be performed on the to-be-processed CU. In this application, when the prediction result indicates that depth division does not need to be performed on the to-be-processed CU, depth division and rdcost calculation and comparison do not need to be performed on the to-be-processed CU. Compared with the existing technology, coding prediction time of this application is significantly reduced and calculation resources are reduced.
</abstract>

<claims>
1. A coding unit (CU) depth determining method, comprising: determining a residual coefficient of a current optimal mode of a to-be-processed CU; respectively obtaining, when the residual coefficient is not 0, a coding information feature of a specific type from the to-be-processed CU and a coding information feature of a specific type from a neighboring coding tree unit (CTU) of a CTU in which the to-be-processed CU is located, to form prediction feature vector samples; and inputting the prediction feature vector samples to a pre-trained predictive model, to obtain a prediction result output from the predictive model, the prediction result being used for indicating whether depth division needs to be performed on the to-be-processed CU, the predictive model being obtained through pre-training by using a training sample marked with a classification result, and the training sample comprising a coding information feature of the specific type.
2. The method according to claim 1, wherein the to-be-processed CU belongs to a non-I-frame video image.
3. The method according to claim 1, wherein before the respectively obtaining a coding information feature of a specific type from the to-be-processed CU and a coding information feature of a specific type from a neighboring CTU of a CTU in which the to-be-processed CU is located, the method further comprises:
determining whether a coding depth of the to-be-processed CU is 0, and if the coding depth of the to-be-processed CU is 0, performing the step of respectively obtaining a coding information feature of a specific type from the to-be-processed CU and a coding information feature of a specific type from a neighboring CTU of a CTU in which the to-be-processed CU is located.
4. The method according to claim 3, further comprising: when it is determined that the coding depth of the to-be-processed CU is not 0, determining an average cost of CUs that are in the neighboring CTU of the CTU in which the to-be-processed CU is located and that have the same coding depth as that of the to-be-processed CU, and using the average cost as a first average cost; determining an average cost of coded CUs that are in the CTU in which the to-be-processed CU is located and that have the same coding depth, and using the average cost as a second average cost; and determining whether depth division needs to be performed on the to-be-processed CU according to the first average cost and the second average cost.
5. The method according to any one of claims 1 to 4, wherein the predictive model comprises a P-frame predictive model and a B-frame predictive model, a training sample used during pre-training of the P-frame predictive model is a coding information feature of the specific type extracted from a CU belonging to a P-frame video image, and a training sample used during pre-training of the B-frame predictive model is a coding information feature of the specific type extracted from a CU belonging to a B-frame video image; and
the inputting the prediction feature vector samples to a pre-trained predictive model, to obtain a prediction result output from the predictive model comprises: determining whether a type of a video frame to which the to-be-processed CU belongs is P-frame or B-frame; and if the type of the video frame to which the to-be-processed CU belongs is P-frame, inputting the prediction feature vector samples to the P-frame predictive model, to obtain a prediction result output from the P-frame predictive model; or if the type of the video frame to which the to-be-processed CU belongs is B-frame, inputting the prediction feature vector sample to the B-frame predictive model, to obtain a prediction result output from the B-frame predictive model.
6. The method according to any one of claims 1 to 4, wherein the respectively obtaining a coding information feature of a specific type from the to-be-processed CU and a coding information feature of a specific type from a neighboring CTU of a CTU in which the to-be-processed CU is located comprises: obtaining a cost, a quantized coefficient, a distortion, and a variance of the to-be-processed CU; and obtaining a cost and depth information of the neighboring CTU of the CTU in which the to-be-processed CU is located.
7. The method according to claim 4, wherein the determining an average cost of CUs that are in the neighboring CTU of the CTU in which the to-be-processed CU is located and that have the same coding depth as that of the to-be-processed CU, and using the average cost as a first average cost comprises: determining an average cost of CUs that are in each neighboring CTU of the CTU in which the to-be-processed CU is located and that have the same coding depth as that of the to-be-processed CU; determining a weight value of each neighboring CTU according to a direction relation between each neighboring CTU and the CTU in which the to-be-processed CU is located; and determining a weighted average cost of all the neighboring CTUs according to the weight value and the average cost of each neighboring CTU, and using the weighted average cost as a first average cost.
8. The method according to claim 4 or 7, wherein the determining whether depth division needs to be performed on the to-be-processed CU according to the first average cost and the second average cost comprises: determining a cost threshold according to the first average cost and the second average cost; determining whether a cost of the current optimal mode of the to-be-processed CU is less than the cost threshold; and determining that depth division does not need to be performed on the to-be-processed CU if the cost of the current optimal mode of the to-be-processed CU is less than the cost threshold; or determining that depth division needs to be performed on the to-be-processed CU if the cost of the current optimal mode of the to-be-processed CU is not less than the cost threshold.
9. A coding unit (CU) depth determining apparatus, comprising: a residual coefficient determining unit, configured to determine a residual coefficient of a current optimal mode of a to-be-processed CU; a feature obtaining unit, configured to respectively obtain, when the residual coefficient is not 0, a coding information feature of a specific type from the to-be-processed CU and a coding information feature of a specific type from a neighboring coding tree unit (CTU) of a CTU in which the to-be-processed CU is located, to form prediction feature vector samples; and a model prediction unit, configured to input the prediction feature vector samples to a pre-trained predictive model, to obtain a prediction result output from the predictive model, the prediction result being used for indicating whether depth division needs to be performed on the to-be-processed CU, the predictive model being obtained through pre-training by using a training sample marked with a classification result, and the training sample comprising a coding information feature of the specific type.
10. The apparatus according to claim 9, wherein the residual coefficient determining unit is specifically configured to determine a residual coefficient of a current optimal mode of a to-be-processed CU belonging to a non-I-frame video image.
11. The apparatus according to claim 9, further comprising: a coding depth judging unit, configured to determine whether a coding depth of the to-be-processed CU is 0, the feature obtaining unit being specifically configured to: when a judging result of the coding depth judging unit is that the coding depth of the to-be-processed CU is 0, respectively obtain a coding information feature of a specific type from the to-be-processed CU and a coding information feature of a specific type from a neighboring CTU of a CTU in which the to-be-processed CU is located.
12. The apparatus according to claim 11, further comprising: a neighbor average cost determining unit, configured to: when it is determined that the coding depth of the to-be-processed CU is not 0, determine an average cost of CUs that are in the neighboring CTU of the CTU in which the to-be-processed CU is located and that have the same coding depth as that of the to-be-processed CU, and use the average cost as a first average cost; a self average cost determining unit, configured to determine an average cost of coded CUs that are in the CTU in which the to-be-processed CU is located and that have the same coding depth, and use the average cost as a second average cost; and a depth division judging unit, configured to determine whether depth division needs to be performed on the to-be-processed CU according to the first average cost and the second average cost.
13. The apparatus according to any one of claims 9 to 12, wherein the predictive model comprises a P-frame predictive model and a B-frame predictive model, a training sample used during pre-training of the P-frame predictive model is a coding information feature of the specific type extracted from a CU belonging to a P-frame video image, and a training sample used during pre-training of the B-frame predictive model is a coding information feature of the specific type extracted from a CU belonging to a B-frame video image; and
the model prediction unit comprises: a frame type determining unit, configured to determine whether a type of a video frame to which the to-be-processed CU belongs is P-frame or B-frame; a P-frame model prediction unit, configured to: when the frame type determining unit determines that the type of the video frame to which the to-be-processed CU belongs is P-frame, input the prediction feature vector samples to the P-frame predictive model, to obtain a prediction result output from the P-frame predictive model; and a B-frame model prediction unit, configured to: when the frame type determining unit determines that the type of the video frame to which the to-be-processed CU belongs is B-frame, input the prediction feature vector samples to the B-frame predictive model, to obtain a prediction result output from the B-frame predictive model.
14. The apparatus according to any one of claims 9 to 12, wherein the feature obtaining unit comprises: a first feature obtaining unit, configured to obtain a cost, a quantized coefficient, a distortion, and a variance of the to-be-processed CU; and a second feature obtaining unit, configured to obtain a cost and depth information of the neighboring CTU of the CTU in which the to-be-processed CU is located.
15. The apparatus according to claim 12, wherein the neighbor average cost determining unit comprises: a first neighbor average cost determining subunit, configured to determine an average cost of CUs that are in each neighboring CTU of the CTU in which the to-be-processed CU is located and that have the same coding depth as that of the to-be-processed CU; a second neighbor average cost determining subunit, configured to determine a weight value of each neighboring CTU according to a direction relation between each neighboring CTU and the CTU in which the to-be-processed CU is located; and a third neighbor average cost determining subunit, configured to determine a weighted average cost of all the neighboring CTUs according to the weight value and the average cost of each neighboring CTU, and use the weighted average cost as a first average cost.
16. A computer readable storage medium, storing a program instruction, a processor performing the method according to any one of claims 1 to 8 when executing the stored program instruction.
</claims>
</document>
