<document>

<filing_date>
2017-06-19
</filing_date>

<publication_date>
2020-09-22
</publication_date>

<priority_date>
2017-06-19
</priority_date>

<ipc_classes>
G06K9/18,G06K9/46,G06K9/62,G06K9/66,G06K9/68,G06N3/02,G06N3/04,G06N3/08,G06T7/11
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
JIN, HAILIN
PAO, I-MING
KONG, SARAH AYE
ERICKSON, ALAN LEE
WANG, ZHAOWEN
</inventors>

<docdb_family_id>
64658152
</docdb_family_id>

<title>
Identification of fonts in an application
</title>

<abstract>
Systems and techniques for identification of fonts include receiving a selection of an area of an image including text, where the selection is received from within an application. The selected area of the image is input to a font matching module within the application. The font matching module identifies one or more fonts similar to the text in the selected area using a convolutional neural network. The one or more fonts similar to the text are displayed within the application and the selection and use of the one or more fonts is enabled within the application.
</abstract>

<claims>
1. A computer-implemented method for identification of fonts within an application, the method comprising: receiving a selection of an area of an image including text, the selection received from within the application; inputting the selected area of the image to a font matching module within the application; identifying one or more fonts similar to the text in the selected area using the font matching module, wherein the font matching module uses both a convolutional neural network and a font similarity module to identify the one or more fonts and the identifying includes: generating, by the convolutional neural network, a probability distribution as a similarity measure of trained fonts, selecting, by the convolutional neural network, one or more trained fonts that are similar to the text in the selected area using the probability distribution, generating, by the font similarity module using a mathematical model, a scalar as a similarity measure of untrained fonts, comparing the scalar with scalars of the one or more trained fonts, and selecting one or more untrained fonts that are similar to the text in the selected area based on the comparison; and displaying the one or more trained fonts and the one or more untrained fonts as the one or more fonts identified as similar to the text within the application.
2. The computer-implemented method as in claim 1, further comprising: receiving a subsequent selection of a different area of the image including text, the subsequent selection received from within the application; responsive to receiving the subsequent selection automatically: inputting the selected different area of the image to the font matching module within the application; identifying one or more fonts similar to the text in the selected different area using the font matching module; and displaying the one or more fonts identified as similar to the text in the selected different area within the application.
3. The computer-implemented method as in claim 1, wherein receiving the selection of the area of the image comprises using a bounding box to surround the area of the image including the text and to select the text within the bounding box by automatically adjusting a top line of the bounding box to match a top glyph of the text within the bounding box and a bottom line of the bounding box to match a bottom glyph of the text within the bounding box.
4. The computer-implemented method as in claim 1, wherein: identifying the one or more fonts similar to the text comprises identifying both one or more resident fonts similar to the text and one or more non-resident fonts similar to the text; and displaying the one or more fonts identified as similar to the text comprises rendering both the one or more resident fonts identified as similar to the text and the one or more non-resident fonts identified as similar to the text for display within the application.
5. The computer-implemented method as in claim 4, further comprising: enabling selection and use of the one or more identified fonts within the application; and responsive to receiving a selection of one of the one or more non-resident fonts, synchronizing the selected non-resident font for use within the application.
6. The computer-implemented method as in claim 1, wherein identifying the one or more fonts similar to the text comprises: inputting a grayscale image of the area of the image including text to the convolution neural network; generating the probability distribution using fonts trained as part of the convolution neural network; and selecting the one or more similar fonts for display within the application using the fonts with a highest probability distribution.
7. A computer program product for identification of fonts within an application, the computer program product being tangibly embodied on a non-transitory computer-readable storage medium and comprising instructions that, when executed by at least one computing device, are configured to cause the at least one computing device to: receive a selection of an area of an image including text; input the selected area of the image to a font matching module; and identify one or more fonts similar to the text in the selected area using the font matching module, wherein the font matching module uses both a convolutional neural network and a font similarity module to identify the one or more fonts and the instructions that cause the at least one computing device to identify the one or more fonts include instructions that, when executed by the at least one computing device, cause the at least one computing device to: generate, by the convolutional neural network, a probability distribution as a similarity measure of trained fonts, select, by the convolutional neural network, one or more trained fonts that are similar to the text in the selected area using the probability distribution, generate, by the font similarity module using a mathematical model, a scalar as a similarity measure of untrained fonts, compare the scalar with scalars of the one or more trained fonts, and select one or more untrained fonts that are similar to the text in the selected area based on the comparison.
8. The computer program product of claim 7, further comprising instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to: display the one or more trained fonts and the one or more untrained fonts as the one or more fonts identified as similar to the text.
9. The computer program product of claim 8, further comprising instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to: enable selection and use of the one or more identified fonts.
10. The computer program product of claim 7, wherein the instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to identify the fonts similar to the text in the selected area include instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to: identify both one or more resident fonts similar to the text and one or more non-resident fonts similar to the text.
11. The computer program product of claim 10, further comprising instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to: render both the one or more resident fonts identified as similar to the text and the one or more non-resident fonts identified as similar to the text for display.
12. The computer program product of claim 11, further comprising instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to: synchronize the selected non-resident font for use responsive to receiving a selection of one of the one or more non-resident fonts.
13. The computer program product of claim 7, wherein the instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to identify the fonts similar to the text in the selected area include instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to: input a grayscale image of the area of the image including text to the convolution neural network; generate the probability distribution using fonts trained as part of the convolution neural network; and select the one or more similar fonts for display using the fonts with a highest probability distribution.
14. The computer program product of claim 13, wherein the instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to receive the selection of the area of the image include instructions that, when executed by the at least one computing device, are configured to cause the at least one computing device to: use a bounding box to surround the area of the image including the text and to select the text within the bounding box by automatically adjusting a top line of the bounding box to match a top glyph of the text within the bounding box and a bottom line of the bounding box to match a bottom glyph of the text within the bounding box.
15. A system for identification of fonts within an application, the system comprising: at least one memory including instructions; and at least one processor that is operably coupled to the at least one memory and that is arranged and configured to execute instructions that, when executed, cause the at least one processor to implement an application, the application comprising: a user interface including a selection tool to select an area of an image including text; a font matching module configured to receive the area of the image including the text from the selection tool and to identify one or more fonts similar to the text using both a convolutional neural network and a font similarity module, wherein: the convolutional neural network generates a probability distribution as a similarity measure of trained fonts, the convolutional neural network selects one or more trained fonts that are similar to the text in the selected area using the probability distribution, the font similarity module uses a mathematical model to generate a scalar as a similarity measure of untrained fonts, the font similarity module compares the scalar with scalars of the one or more trained fonts, and the font similarity module selects one or more untrained fonts that are similar to the text in the selected area based on the comparison; and a display window within the user interface to display the one or more trained fonts and the one or more untrained fonts as the one or more fonts identified as similar to the text.
16. The system of claim 15, wherein the user interface includes a font selection tool to select one of the one or more fonts for use in the application.
17. The system of claim 15, wherein: the selection tool is configured to select a different area of the image including text; the font matching module is configured to automatically receive the different area of the image and to identify one or more fonts similar to the text in the different area; and the display window is configured to display the one or more fonts identified as similar to the text in the different area.
18. The system of claim 15, wherein: the font matching module is configured to identify both one or more resident fonts similar to the text and one or more non-resident fonts similar to the text; and the display window is configured to render both the one or more resident fonts identified as similar to the text and the one or more non-resident fonts identified as similar to the text for display.
</claims>
</document>
