<document>

<filing_date>
2018-08-24
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2017-08-25
</priority_date>

<ipc_classes>
G06T7/73,G06T7/80
</ipc_classes>

<assignee>
LIU, CHIRIS HSINLAI
</assignee>

<inventors>
Liu, Chris Hsinlai
</inventors>

<docdb_family_id>
65438801
</docdb_family_id>

<title>
STEREO MACHINE VISION SYSTEM AND METHOD FOR IDENTIFYING LOCATIONS OF NATURAL TARGET ELEMENTS
</title>

<abstract>
This document disclose stereo machine vision systems and methods for determining locations of surfaces of natural objects within the field of view of the stereo machine vision system whereby these natural objects are used as the target elements for the vision system.
</abstract>

<claims>
1. A system for determining, in a first and a second optical devices' common three-dimensional (x, y, z) coordinate system, positions of a surface located within the first and second optical devices' field of view, the system comprising: a first sensor array of the first optical device and a second sensor array of the second optical device being configured to: capture an image of the surface located within the first and second optical devices' field of view whereby sensor readings at each two-dimensional location of the first and second sensor arrays are generated based on the captured image; a computing device communicatively coupled to the first and second optical devices, the computing device being configured to: determine, for each two-dimensional location (s, t) in the first sensor array, if a sensor reading at the location (s, t) in the first sensor array matches the sensor reading at a two-dimensional location (u, v) in the second sensor array, whereby the location (s, t) at the first sensor array and the location (u, v) at the second sensor array are both associated with a same position in the (x, y, z) coordinate system, whereby the position in the (x, y, z) coordinate system associated with the locations (s, t) (u, v) at the first and second sensors comprises a position of a point on the surface when the sensor readings of the locations (s, t) (u, v) at the first and second sensor arrays match, wherein the association between the location (s, t) at the first sensor array and its position in the (x, y, z) coordinate system and the association between the (u, v) location at the second sensor and its position in the (x, y, z) coordinate system is defined in each sensor's calibration table, wherein each sensor's calibration table was pre-generated by, positioning the pair of first and second optical devices at a plurality of calibration positions from a target screen comprising a plurality of target centres, whereby at each calibration position, for each of the target centres on the target screen, the pair of optical devices: captures an image of the target centre and associates, in each sensor's calibration table, a two-dimensional location of the captured image of the target centre on each of the sensors, with a location of the target centre relative to the pair of optical devices, the location being defined as a position in the pair of optical devices' three dimensional (x, y, z) coordinate system.
2. The system according to claim 1 wherein the determining if the sensor reading at the location (s, t) in the first sensor array matches the sensor reading at the location (u, v) in the second sensor array comprises: the computing device being configured to: select, an (x, y, z) position and its associated (s, t) location from the first sensor array's calibration table and its associated (u, v) location from the second sensor array's calibration table; and determine if the sensor reading at the location (s, t) matches with the sensor reading at the location (u, v).
3. The system according to claim 2 wherein the computing device is further configured to: identify at least three non-collinear (x, y, z) positions that each have a sensor reading at an associated location (s, t) that matches with a sensor reading at an associated location (u, v), whereby the three non-collinear (x, y, z) positions define a surface of a plane.
4. The system according to claim 3 whereby the computing device is further configured to: specify a manner in which a set of (x, y, z) positions are to be selected from the identified (x, y, z) positions; plot the set of selected (x, y, z) positions; whereby based on the specified manner of selection and the plot of the set of selected (x, y, z) positions, the computing device is configured to: derive a first order of approximation of an object's surface in a form of a plane having a two dimensional orientation and distance that is relative to an origin of the (x, y, z) coordinate system.
5. The system according to claim 1 wherein the determining if the sensor reading at the location (s, t) in the first sensor array matches the sensor reading at the location (u, v) in the second sensor array comprises: the computing device being configured to: generate a surface comprising of positions in the (x, y, z) coordinate system whereby for each (x, y, z) position on the surface, the computing device is configured to: obtain a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identify sensor readings that match from the selected positions.
6. The system according to claim 5 wherein the computing device is further configured to: generate a plurality of surfaces whereby each surface comprises positions in the (x, y, z) coordinate system, whereby for each (x, y, z) position on each of the plurality of surfaces, the computing device is configured to: obtain a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identify sensor readings that match from the selected positions.
7. The system according to claim 1 wherein the determining if the sensor reading at the location (s, t) in the first sensor array matches the sensor reading at the location (u, v) in the second sensor array comprises: the computing device being configured to: generate a spherical surface centred at a location within the three-dimensional (x, y, z) coordinate system, whereby the spherical surface comprises positions in the (x, y, z) coordinate system, and whereby for each (x, y, z) position on the spherical surface, the computing device is configured to: obtain a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identify sensor readings that match from the selected positions.
8. The system according to claim 7 wherein the computing device is further configured to: generate a plurality of spherical surfaces centred at the location within the three-dimensional (x, y, z) coordinate system, whereby each of the plurality of spherical surface comprises positions in the (x, y, z) coordinate system, and whereby for each (x, y, z) position on each of the plurality of spherical surfaces, the computing device is configured to: obtain a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identify sensor readings that match from the selected positions.
9. The system according to claim 1 whereby the computing device is further configured to: generate, from the (x, y, z) positions associated with the matched sensor readings,â€”two-dimensional histograms whereby columns of the histogram define a frequency of occurrence of matched sensor readings along an axis of the three-dimensional (x, y, z) coordinate system and a two dimensional base of the histogram defines a parameter that is a function of a distance of an occurrence of one a remaining axis of the three-dimensional (x, y, z) coordinate system.
10. The system according to claim 2 whereby the computing device is further configured to: generate a spherical surface centred at a first (x, y, z) position associated with a matched sensor reading, whereby the spherical surface comprises positions in the (x, y, z) coordinate system, and whereby for each (x, y, z) position on the spherical surface, the computing device is configured to: obtain a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identify sensor readings that match from the selected positions.
11. The system according to claim 10 whereby the computing device is further configured to: verify that the first (x, y, z) position is a point on the surface located within the first and second optical devices' field of view when (x, y, z) positions associated with identified sensor readings combine to form an equator of the spherical surface.
12. The system according to claim 4 whereby the computing device is further configured to: specify a spherical surface in which a set of (x, y, z) positions are to be selected from the identified (x, y, z) positions; filter noises from the set of selected (x, y, z) positions and plot the set of selected (x, y, z) positions; whereby based on the plot of the set of selected (x, y, z) positions, the computing device is configured to: derive a plane of an object's surface, the plane having a two dimensional orientation and distance that is relative to an origin of the (x, y, z) coordinate system.
13. The system according to claim 4 whereby the computing device is further configured to: specify a spherical surface in which a set of (x, y, z) positions are to be selected from the identified (x, y, z) positions; filter noises from the set of selected (x, y, z) positions and plot the set of selected (x, y, z) positions; cluster a portion of the plotted positions into an arc and identify a circle on the spherical surface that contains the arc; derive a plane of an object's surface based on the clustered portion of the plotted positions, the plane having a two dimensional orientation and distance that is relative to an origin of the (x, y, z) coordinate system.
14. The system according to claim 4 whereby the computing device is further configured to: specify a first set of (x, y, z) positions that are known to be non-noise matching positions; select a second set of (x, y, z) positions comprising a selection of neighbouring (x, y, z) positions of the (x, y, z) positions in the first set whereby the selection comprises at least a number of (x, y, z) positions from the first set; derive, based on the second set of (x, y, z) positions, a plane as the first order of approximation of the object's surface, with a two dimensional orientation and distance that is relative to an origin of the (x, y, z) coordinate system.
15. The system according to claim 14 whereby the computing device is further configured to: derive a plurality of planes as the first order of approximation of the object's surfaces, with their two dimensional orientations and distance relative to the (x, y, z) coordinate system, whereby, for each pair of derived planes, detect an intersecting line segment contained in a vicinity of the second set of (x, y, z) positions.
16. A method for determining, in a first and a second optical devices' common three-dimensional (x, y, z) coordinate system, positions of a surface located within the first and second optical devices' field of view, the first optical device having a first sensor array and the second optical device having a second sensor array and a computing device communicatively coupled to the first and second optical devices, the method comprising: capturing, using the first and second sensor arrays, an image of the surface located within the first and second optical devices' field of view whereby sensor readings at each two-dimensional location of the first and second sensor arrays are generated based on the captured image; determining, using the computing device, for each two-dimensional location (s, t) in the first sensor array, if a sensor reading at the location (s, t) in the first sensor array matches the sensor reading at a two-dimensional location (u, v) in the second sensor array, whereby the location (s, t) at the first sensor array and the location (u, v) at the second sensor array are both associated with a same position in the (x, y, z) coordinate system, whereby the position in the (x, y, z) coordinate system associated with the locations (s, t) (u, v) at the first and second sensors comprises a position of a point on the surface when the sensor readings of the locations (s, t) (u, v) at the first and second sensor arrays match, wherein the association between the location (s, t) at the first sensor array and its position in the (x, y, z) coordinate system and the association between the (u, v) location at the second sensor and its position in the (x, y, z) coordinate system is defined in each sensor's calibration table, wherein each sensor's calibration table was pre-generated by, positioning the pair of first and second optical devices at a plurality of calibration positions from a target screen comprising a plurality of target centres, whereby at each calibration position, for each of the target centres on the target screen, the pair of optical devices: captures an image of the target centre and associates, in each sensor's calibration table, a two-dimensional location of the captured image of the target centre on each of the sensors, with a location of the target centre relative to the pair of optical devices, the location being defined as a position in the pair of optical devices' three dimensional (x, y, z) coordinate system.
17. The method according to claim 16 wherein the determining if the sensor reading at the location (s, t) in the first sensor array matches the sensor reading at the location (u, v) in the second sensor array comprises: selecting, using the computing device, an (x, y, z) position and its associated (s, t) location from the first sensor array's calibration table and its associated (u, v) location from the second sensor array's calibration table; and determining if the sensor reading at the location (s, t) matches with the sensor reading at the location (u, v).
18. The method according to claim 17 wherein the method further comprises the step of: identifying, using the computing device, at least three non-collinear (x, y, z) positions that each have a sensor reading at an associated location (s, t) that matches with a sensor reading at an associated location (u, v), whereby the three non-collinear (x, y, z) positions define a surface of a plane.
19. The method according to claim 18 whereby the method further comprises the steps of: specifying, using the computing device, a manner in which a set of (x, y, z) positions are to be selected from the identified (x, y, z) positions; plotting the set of selected (x, y, z) positions; whereby based on the specified manner of selection and the plot of the set of selected (x, y, z) positions, deriving a first order of approximation of an object's surface in a form of a plane having a two dimensional orientation and distance that is relative to an origin of the (x, y, z) coordinate system.
20. The method according to claim 16 wherein the determining if the sensor reading at the location (s, t) in the first sensor array matches the sensor reading at the location (u, v) in the second sensor array comprises: generating, using the computing device, a surface comprising of positions in the (x, y, z) coordinate system whereby for each (x, y, z) position on the surface, obtaining a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identifying sensor readings that match from the selected positions.
21. The method according to claim 20 wherein the method further comprises the step of: generating, using the computing device, a plurality of surfaces whereby each surface comprises positions in the (x, y, z) coordinate system, whereby for each (x, y, z) position on each of the plurality of surfaces, obtaining a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identifying sensor readings that match from the selected positions.
22. The method according to claim 16 wherein the determining if the sensor reading at the location (s, t) in the first sensor array matches the sensor reading at the location (u, v) in the second sensor array comprises: generating, using the computing device, a spherical surface centred at a location within the three-dimensional (x, y, z) coordinate system, whereby the spherical surface comprises positions in the (x, y, z) coordinate system, and whereby for each (x, y, z) position on the spherical surface, obtaining a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identifying sensor readings that match from the selected positions.
23. The method according to claim 22 wherein the method further comprises the steps of: generating, using the computing device, a plurality of spherical surfaces centred at the location within the three-dimensional (x, y, z) coordinate system, whereby each of the plurality of spherical surface comprises positions in the (x, y, z) coordinate system, and whereby for each (x, y, z) position on each of the plurality of spherical surfaces, obtaining a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identifying sensor readings that match from the selected positions.
24. The method according to claim 16 whereby the method further comprises the step of: generating, from the (x, y, z) positions associated with the matched sensor readings,â€”using the computing device, two-dimensional histograms whereby columns of the histogram define a frequency of occurrence of matched sensor readings along an axis of the three-dimensional (x, y, z) coordinate system and a two dimensional base of the histogram defines a parameter that is a function of a distance of an occurrence of one a remaining axis of the three-dimensional (x, y, z) coordinate system.
25. The method according to claim 17 whereby the method further comprises the steps of: generating, using the computing device, a spherical surface centred at a first (x, y, z) position associated with a matched sensor reading, whereby the spherical surface comprises positions in the (x, y, z) coordinate system, and whereby for each (x, y, z) position on the spherical surface, obtaining a reading of the first sensor at a (s, t) location associated with the (x, y, z) position using the first sensor array's calibration table and a reading of the second sensor at a (u, v) location associated with the (x, y, z) position using the second sensor array's calibration table; and identifying sensor readings that match from the selected positions.
26. The method according to claim 25 whereby the method further comprises the step of: verifying, using the computing device, that the first (x, y, z) position is a point on the surface located within the first and second optical devices' field of view when (x, y, z) positions associated with identified sensor readings combine to form an equator of the spherical surface.
27. The method according to claim 19 whereby the method further comprises the step of: specifying, using the computing device, a spherical surface in which a set of (x, y, z) positions are to be selected from the identified (x, y, z) positions; filtering noises from the set of selected (x, y, z) positions and plot the set of selected (x, y, z) positions; whereby based on the plot of the set of selected (x, y, z) positions, deriving a plane of an object's surface, the plane having a two dimensional orientation and distance that is relative to an origin of the (x, y, z) coordinate system.
28. The method according to claim 19 whereby the method further comprises the steps of: specifying, using the computing device, a spherical surface in which a set of (x, y, z) positions are to be selected from the identified (x, y, z) positions; filter noises from the set of selected (x, y, z) positions and plot the set of selected (x, y, z) positions; clustering a portion of the plotted positions into an arc and identify a circle on the spherical surface that contains the arc; deriving a plane of an object's surface based on the clustered portion of the plotted positions, the plane having a two dimensional orientation and distance that is relative to an origin of the (x, y, z) coordinate system.
29. The method according to claim 19 whereby the method further comprises the steps of: specifying, using the computing device, a first set of (x, y, z) positions that are known to be non-noise matching positions; selecting a second set of (x, y, z) positions comprising a selection of neighbouring (x, y, z) positions of the (x, y, z) positions in the first set whereby the selection comprises at least a number of (x, y, z) positions from the first set; deriving, based on the second set of (x, y, z) positions, a plane as the first order of approximation of the object's surface, with a two dimensional orientation and distance that is relative to an origin of the (x, y, z) coordinate system.
30. The method according to claim 29 whereby the method further comprises the step of: deriving, using the computing device, a plurality of planes as the first order of approximation of the object's surfaces, with their two dimensional orientations and distance relative to the (x, y, z) coordinate system, whereby, for each pair of derived planes, detect an intersecting line segment contained in a vicinity of the second set of (x, y, z) positions.
</claims>
</document>
