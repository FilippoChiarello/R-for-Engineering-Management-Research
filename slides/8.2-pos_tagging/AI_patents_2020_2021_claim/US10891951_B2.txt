<document>

<filing_date>
2018-10-17
</filing_date>

<publication_date>
2021-01-12
</publication_date>

<priority_date>
2018-10-17
</priority_date>

<ipc_classes>
G06N3/04,G10L15/06,G10L15/16,G10L15/22,G10L15/30
</ipc_classes>

<assignee>
FORD GLOBAL TECHNOLOGIES
</assignee>

<inventors>
CHARETTE, FRANCOIS
SCARIA, LISA
NARAYANAN, PRAVEEN
BURKE, RYAN
</inventors>

<docdb_family_id>
70280831
</docdb_family_id>

<title>
Vehicle language processing
</title>

<abstract>
A computing system can translate a spoken natural language command into an intermediate constructed language command with a first deep neural network and determine a vehicle command and an intermediate constructed language response with a second deep neural network based on receiving vehicle information. The computing system can translate the intermediate constructed language response into a spoken natural language response with a third deep neural network and operate a vehicle based on the vehicle command.
</abstract>

<claims>
We claim:
1. A method, comprising: translating a spoken natural language command into an intermediate constructed language command with a first deep neural network; determining a vehicle command and an intermediate constructed language response with a second deep neural network based on receiving vehicle information; translating the intermediate constructed language response into a spoken natural language response with the third deep neural network; and operating a vehicle based on the vehicle command; wherein the first deep neural network, the second deep neural network and the third deep neural network are trained to input the spoken natural language command, output the vehicle command, input vehicle information and output the spoken natural language response using ground truth vehicle commands and vehicle information, sample spoken natural language commands and sample spoken natural language responses.
2. The method of claim 1, wherein the constructed language is a latent constructed language.
3. The method of claim 1, wherein the spoken natural language command is text data corresponding to a command spoken in a natural language by a vehicle user and transformed from acquired audio spectrum data into the spoken natural language command by a fourth deep neural network.
4. The method of claim 3, wherein the spoken natural language response is text data and is transformed into audio spectrum data corresponding to a response spoken in a natural language by a fifth deep neural network.
5. The method of claim 1, wherein the spoken natural language command and the spoken natural language response are each in different ones of a plurality of natural languages.
6. The method of claim 5, wherein the first and third deep neural networks are trained independently to add natural languages from the plurality of natural languages.
7. The method of claim 1, wherein operating the vehicle includes determining a cognitive map based on map data and vehicle sensor data.
8. The method of claim 7, wherein operating the vehicle includes determining a path polynomial in the cognitive map based on the constructed language command and vehicle sensor data.
9. A system, comprising: a processor; and a memory, the memory including instructions to be executed by the processor to: translate a spoken natural language command into an intermediate constructed language command with a first deep neural network; determine a vehicle command and an intermediate constructed language response with a second deep neural network based on receiving vehicle information; translate the intermediate constructed language response into a spoken natural language response with a third deep neural network; and operate a vehicle based on the vehicle command; wherein the first deep neural network, the second deep neural network and the third deep neural network are trained to input the spoken natural language command, output the vehicle command, input vehicle information and output the spoken natural language response using ground truth vehicle commands and vehicle information, sample spoken natural language commands and sample spoken natural language responses.
10. The system of claim 9, wherein the constructed language is a latent constructed language.
11. The system of claim 9, wherein the spoken natural language command is text data corresponding to a command spoken in a natural language by a vehicle user and transformed from acquired audio spectrum data into the spoken natural language command by a fourth deep neural network.
12. The system of claim 11, wherein the spoken natural language response is text data and is transformed into audio spectrum data corresponding to a response spoken in a natural language by a fifth deep neural network.
13. The system of claim 9, wherein the spoken natural language command and the spoken natural language response are each in different ones of a plurality of natural languages.
14. The system of claim 13, wherein the first and third deep neural networks are trained independently to add natural languages from the plurality of natural languages.
15. The system of claim 9, wherein operating the vehicle includes determining a cognitive map based on map data and vehicle sensor data.
16. The system of claim 15, wherein operating the vehicle includes determining a path polynomial in the cognitive map based on the spoken language command and vehicle sensor data.
17. A system, comprising: means for controlling vehicle steering, braking and powertrain; and means for: translating a spoken natural language command into an intermediate constructed language command with a first deep neural network; determining a vehicle command and an intermediate constructed language response with a second deep neural network based on receiving vehicle information; translating the intermediate constructed language response into a spoken natural language response with a third deep neural network; and operating a vehicle based on the vehicle command and the means for controlling vehicle steering, braking and powertrain; wherein the first deep neural network, the second deep neural network and the third deep neural network are trained to input the spoken natural language command, output the vehicle command, input vehicle information and output the spoken natural language response using ground truth vehicle commands and vehicle information, sample spoken natural language commands and sample spoken natural language responses.
18. The system of claim 17, wherein the constructed language is a latent constructed language.
</claims>
</document>
