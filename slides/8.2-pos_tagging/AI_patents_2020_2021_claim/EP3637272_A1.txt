<document>

<filing_date>
2018-06-26
</filing_date>

<publication_date>
2020-04-15
</publication_date>

<priority_date>
2017-06-26
</priority_date>

<ipc_classes>
G06F12/0875,G06F15/167
</ipc_classes>

<assignee>
SHANGHAI CAMBRICON INFORMATION TECHNOLOGY COMPANY
</assignee>

<inventors>
DU, ZIDONG
LIU, SHAOLI
HU, SHUAI
ZHOU, SHENGYUAN
GAO, YUFENG
WANG, ZAI
HAO, YIFAN
CHEN, TIANSHI
ZHOU, XUDA
</inventors>

<docdb_family_id>
64741150
</docdb_family_id>

<title>
DATA SHARING SYSTEM AND DATA SHARING METHOD THEREFOR
</title>

<abstract>
A data sharing system may include a storage module and at least two processing modules. The at least two processing modules may share the storage module and the at least two processing modules communicate to implement data sharing. A data sharing method for the data sharing system is provided. According to the disclosure, a storage communication overhead may be reduced, and a data access delay may be effectively reduced.
</abstract>

<claims>
1. A data sharing system, comprising: a storage module; and at least two processing modules configured to share the storage module and to communicate through a preset rule to implement data sharing.
2. The data sharing system of claim 1, wherein the preset rule includes a communication protocol, a transport protocol, a handshake protocol and/or a bus protocol.
3. The data sharing system of claims 1 or 2, wherein the at least two processing modules are configured to communicate through the preset rule as follows:
the at least two processing modules including a first processing module and a second processing module, where the first processing module is configured to send a request signal and a corresponding data address to the second processing module, and the second processing module may be configured to return a valid signal and data to the first processing module according to the request signal and the corresponding data address to implement data sharing.
4. The data sharing system of any of claims 1 to 3, wherein the at least two processing modules include a physical processor.
5. The data sharing system of claim 4, wherein the physical processor includes a neutral network processor.
6. The data sharing system of claim 5, wherein the neural network processor includes a device configured to perform an artificial neural network forward computation.
7. The data sharing system of claim 6, wherein the device configured to perform the artificial neural network forward computation includes an instruction caching unit and a Direct Memory Access (DMA), wherein
the instruction caching unit is configured to read an instruction in through the DMA and cache the read-in instruction.
8. The data sharing system of claim 7, wherein the device configured to perform an artificial neural network forward computation further includes:
a controlling unit configured to read an instruction from the instruction caching unit and decode the instruction into a microinstruction.
9. The data sharing system of claims 7 or 8, wherein the device configured to perform the artificial neural network forward computation further includes an H tree module, a primary computation module, and multiple secondary computation modules, wherein
the primary computation module is configured to transmit an input neuron vector of this layer to all the secondary computation modules through the H tree module, in a stage where computation for reverse training of each layer of a neural network is started;
the H tree module is configured to merge an output neuron value of each secondary computation module into an intermediate result vector step by step, after a computation process of the secondary computation modules is completed; and
the primary computation module is further configured to complete subsequent computation by use of the intermediate result vector.
10. The data sharing system of claim 9, wherein the DMA is further configured to write data into corresponding data caching units of the primary computation module and each secondary computation module from an external address space, or read data into the external address space from the data caching units.
</claims>
</document>
