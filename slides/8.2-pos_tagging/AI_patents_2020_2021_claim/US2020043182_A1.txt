<document>

<filing_date>
2018-07-31
</filing_date>

<publication_date>
2020-02-06
</publication_date>

<priority_date>
2018-07-31
</priority_date>

<ipc_classes>
G06T15/08,G06T17/00,G06T3/40,G06T7/262,G06T7/30
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
CHIU, YI-JEN
BISWAL, NARAYAN
XU QIAN
OH, JONG DAE
LEE, SANG-HEE
DAS, BARNAN
CILINGIR, GOKCEN
JANUS, SCOTT
HOLLAND, JAMES
VARERKAR, MAYURESH
POTLURI, SRIKANTH
BARAN, STANLEY
MADDIPATLA, MARUTHI SANDEEP
LABBE, HUGUES
ROSS, JASON
</inventors>

<docdb_family_id>
69168113
</docdb_family_id>

<title>
POINT CLOUD VIEWPOINT AND SCALABLE COMPRESSION/DECOMPRESSION
</title>

<abstract>
Embodiments described herein provide an apparatus comprising a processor to divide a first point cloud data set frame representing a three dimensional space at a first point in time into a matrix of blocks, determine at least one three dimensional (3D) motion vector for at least a subset of blocks in the matrix of blocks, generate a predicted second point cloud data set frame representing a prediction of the three dimensional space at a second point in time by applying the at least one 3D motion vector to the subset of blocks in the matrix of blocks, compare the predicted second point cloud data set frame to a second point cloud data set frame representing a prediction of the three dimensional space at a second point in time to generate a prediction error parameter, and encode the second point cloud data set frame as a function of the first point cloud data set frame and the at least one three dimensional (3D) motion vector when the prediction error factor is beneath an error threshold to produce an encoded second point cloud data set frame. Other embodiments may be described and claimed.
</abstract>

<claims>
1. A method, comprising: dividing a first point cloud data set frame representing a three dimensional space at a first point in time into a matrix of blocks; determining at least one three dimensional (3D) motion vector for at least a subset of blocks in the matrix of blocks; generating a predicted second point cloud data set frame representing a prediction of the three dimensional space at a second point in time by applying the at least one 3D motion vector to the subset of blocks in the matrix of blocks; comparing the predicted second point cloud data set frame to a second point cloud data set frame representing a prediction of the three dimensional space at a second point in time to generate a prediction error parameter; and encoding the second point cloud data set frame as a function of the first point cloud data set frame and the at least one three dimensional (3D) motion vector when the prediction error factor is beneath an error threshold to produce an encoded second point cloud data set frame.
2. The method of claim 1, wherein: each block in the matrix of blocks comprises at least one voxel.
3. The method of claim 1, further comprising: storing the encoded point cloud data set frame in a memory.
4. The method of claim 1, further comprising: applying a three dimensional (3D) discrete cosine transform to further compress the encoded second point cloud data set.
5. A non-transitory machine readable medium storing instructions which, when executed by one or more processors, cause the one or more processors to perform operations comprising: dividing a first point cloud data set frame representing a three dimensional space at a first point in time into a matrix of blocks; determining at least one three dimensional (3D) motion vector for at least a subset of blocks in the matrix of blocks; generating a predicted second point cloud data set frame representing a prediction of the three dimensional space at a second point in time by applying the at least one 3D motion vector to the subset of blocks in the matrix of blocks; comparing the predicted second point cloud data set frame to a second point cloud data set frame representing a prediction of the three dimensional space at a second point in time to generate a prediction error parameter; and encoding the second point cloud data set frame as a function of the first point cloud data set frame and the at least one three dimensional (3D) motion vector when the prediction error factor is beneath an error threshold to produce an encoded second point cloud data set frame.
6. The non-transitory machine readable medium of claim 5, wherein: each block in the matrix of blocks comprises at least one voxel.
7. The non-transitory machine readable medium of claim 5, the operations additionally comprising: storing the encoded point cloud data set frame in a memory.
8. The non-transitory machine readable medium of claim 5, the operations additionally comprising: applying a three dimensional (3D) discrete cosine transform to further compress the encoded second point cloud data set.
9. An apparatus, comprising: a processor to divide a first point cloud data set frame representing a three dimensional space at a first point in time into a matrix of blocks, determine at least one three dimensional (3D) motion vector for at least a subset of blocks in the matrix of blocks, generate a predicted second point cloud data set frame representing a prediction of the three dimensional space at a second point in time by applying the at least one 3D motion vector to the subset of blocks in the matrix of blocks, compare the predicted second point cloud data set frame to a second point cloud data set frame representing a prediction of the three dimensional space at a second point in time to generate a prediction error parameter, and encode the second point cloud data set frame as a function of the first point cloud data set frame and the at least one three dimensional (3D) motion vector when the prediction error factor is beneath an error threshold to produce an encoded second point cloud data set frame; and a memory communicatively coupled to the processor.
10. The apparatus of claim 9, wherein: each block in the matrix of blocks comprises at least one voxel.
11. The apparatus of claim 9, the processor to store the encoded point cloud data set frame in a memory.
12. The apparatus of claim 9, the processor to apply a three dimensional (3D) discrete cosine transform to further compress the encoded second point cloud data set.
</claims>
</document>
