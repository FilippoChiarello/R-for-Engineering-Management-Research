<document>

<filing_date>
2019-11-22
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-04
</priority_date>

<ipc_classes>
G10L15/26,G10L15/32,H04M1/247,H04M3/42
</ipc_classes>

<assignee>
SORENSON IP HOLDINGS
</assignee>

<inventors>
THOMSON, DAVID
ROYLANCE, SHANE
ADAMS, JADIE
SKAGGS, JONATHAN
MCCLELLAN, JOSHUA
</inventors>

<docdb_family_id>
69528939
</docdb_family_id>

<title>
TRANSCRIPTION GENERATION FROM MULTIPLE SPEECH RECOGNITION SYSTEMS
</title>

<abstract>
A method may include obtaining first audio data originating at a first device during a communication session between the first device and a second device. The method may also include obtaining a first text string that is a transcription of the first audio data, where the first text string may be generated using automatic speech recognition technology using the first audio data. The method may also include obtaining a second text string that is a transcription of second audio data, where the second audio data may include a revoicing of the first audio data by a captioning assistant and the second text string may be generated by the automatic speech recognition technology using the second audio data. The method may further include generating an output text string from the first text string and the second text string and using the output text string as a transcription of the speech.
</abstract>

<claims>
1. A method comprising:
obtaining first audio data originating at a first device during a communication session between the first device and a second device, the communication session configured for verbal communication such that the first audio data includes speech;
obtaining a first text string that is a transcription of the first audio data, the first text string generated using automatic speech recognition technology using the first audio data;
obtaining a second text string that is a transcription of second audio data, the second audio data including a revoicing of the first audio data and the second text string generated by automatic speech recognition technology using the second audio data;
generating an output text string from the first text string and the second text string; and providing the output text string as a transcription of the speech to the second device for presentation during the communication session concurrently with the presentation of the first audio data by the second device.
2. The method of claim 1, wherein the output text string includes one or more first words from the first text string and one or more second words from the second text string.
3. The method of claim 2, wherein generating the output text string further includes: selecting the one or more second words based on the first text string and the second text string both including the one or more second words; and
selecting the one or more first words from the first text string based on the second text string not including the one or more first words.
4. The method of any proceeding claim, further comprising correcting at least one word in one or more of: the output text string, the first text string, and the second text string based on input obtained from a device associated with the revoicing of the first audio data.
5. The method of any proceeding claim, further comprising obtaining a third text string that is a transcription of the first audio data or the second audio data, the third text string generated by automatic speech recognition technology, wherein the output text string is generated from the first text string, the second text string, and the third text string.
6. The method of claim 1, further comprising correcting at least one word in one or more of: the output text string, the first text string, and the second text string based on a third text string generated by automatic speech recognition technology using the first audio data.
7. The method of claim 6, wherein the first text string and the third text string are both hypothesis generated by automatic speech recognition technology for the substantially same portion of the first audio data.
8. The method of any proceeding claim, wherein the output text string is generated from the first text string and the second text string based on an alignment between the first text string and the second text string.
9. The method of any proceeding claim, wherein the automatic speech recognition technology used to generate the first text string is a first automatic speech recognition system that includes a first model trained for a plurality of individuals and the automatic speech recognition technology used to generate the second text string is a second automatic speech recognition system that includes a second model adapted to a person that re voices the audio.
10. At least one non-transitory computer-readable media configured to store one or more instructions that in response to being executed by at least one computing system cause performance of the method of any proceeding claim.
11. A system comprisingione or more non-transitory computer readable media configured to store one or more instructions; and
one or more processor communicatively coupled to the one or more non-transitory computer readable media, the one or more processors configured to execute the one or more instructions to cause or direct the system to perform operations, the operations comprising:
obtain first audio data originating at a first device during a communication session between the first device and a second device, the communication session configured for verbal communication such that the first audio data includes speech;
obtain a first text string that is a transcription of the first audio data, the first text string generated using automatic speech recognition technology using the first audio data;
obtain a second text string that is a transcription of second audio data, the second audio data including a revoicing of the first audio data and the second text string generated by automatic speech recognition technology using the second audio data;
generate an output text string from the first text string and the second text string; and provide the output text string as a transcription of the speech to the second device for presentation during the communication session concurrently with the presentation of the first audio data by the second device. 12. The system of claim 11 , wherein the output text string includes one or more first words from the first text string and one or more second words from the second text string and generating the output text string further includes:
selecting the one or more second words based on the first text string and the second text string both including the one or more second words; and
selecting the one or more first words from the first text string based on the second text string not including the one or more first words.
13. The system of claims 11 and 12, wherein the operations further comprise obtaining a third text string that is a transcription of the first audio data or the second audio data, the third text string generated by automatic speech recognition technology, wherein the output text string is generated from the first text string, the second text string, and the third text string.
14. The system of claim 11 , wherein the operations further comprise correcting at least one word in one or more of: the output text string, the first text string, and the second text string based on a third text string generated by automatic speech recognition technology using the first audio data.
15. The system of any of claims 11-14, wherein the automatic speech recognition technology used to generate the first text string is a first automatic speech recognition system that includes a first model trained for a plurality of individuals and the automatic speech recognition technology used to generate the second text string is a second automatic speech recognition system that includes a second model adapted to a person that re voices the audio.
</claims>
</document>
