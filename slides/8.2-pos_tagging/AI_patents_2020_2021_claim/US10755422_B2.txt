<document>

<filing_date>
2018-07-24
</filing_date>

<publication_date>
2020-08-25
</publication_date>

<priority_date>
2017-07-24
</priority_date>

<ipc_classes>
G06T7/00,G06T7/238,G06T7/73
</ipc_classes>

<assignee>
HTC CORPORATION
</assignee>

<inventors>
CHEN, YUAN-TUNG
YU, TZU-CHIEH
</inventors>

<docdb_family_id>
64959070
</docdb_family_id>

<title>
Tracking system and method thereof
</title>

<abstract>
The present disclosure provides a tracking system and method thereof. The tracking system comprises a trackable device with an appearance including a feature pattern and a tracking device. The tracking device comprises an optical sensor module configured to capture a first image which covers the trackable device. The tracking device further comprises a processor coupled to the optical sensor module. The processor is configured to retrieve a region of interest (ROI) of the first image based on the feature pattern, and locate a position of each of a plurality of feature blocks in the ROI, where each feature block contains a portion of the feature pattern. The processor further calculates a pose data of the trackable object according to the positions of the feature blocks.
</abstract>

<claims>
1. A tracking system, comprising: a trackable device comprising at least one feature pattern on an appearance of the trackable device; a tracking device, comprising: an optical sensing circuit, configured to capture a first image comprising the trackable device; and a processor coupled to the optical sensing circuit, the processor being configured to: acquire, based on the feature pattern, in the first image a first region of interest corresponding to the feature pattern; locate in the first region of interest a plurality of block positions of a plurality of feature blocks, wherein each of the plurality of feature blocks comprises part of the feature pattern and the part of the feature pattern of each of the plurality of feature block is different from each other; and calculate a first pose data of the trackable device according to the plurality of block positions.
2. The tracking system of claim 1, wherein the processor acquires in the first image the first region of interest based on a skeleton of the feature pattern.
3. The tracking system of claim 1, wherein the processor is further configured to process a deep learning algorithm based on the first region of interest in order to generate a rough pose data of the trackable device in the first region of interest.
4. The tracking system of claim 1, wherein when the processor acquires the first region of interest, the processor is further configured to: obtain a second image captured before the first image by the optical sensing circuit and a second region of interest corresponding to the feature pattern in the second image; obtain a motion signal generated by the trackable device between time points when the second image and the first image are captured respectively; predict in the first image a partial region based on the motion signal and the second region of interest; and search in the partial region of the first image the first region of interest based on the feature pattern.
5. The tracking system of claim 4, wherein the processor calculates a rough pose data of the trackable device in the first region of interest based on a second pose data of the trackable device in the second region of interest and the motion signal.
6. The tracking system of claim 5, wherein the tracking device further comprises: a pose database configured to store a plurality of pose data of the trackable device and a plurality of reference images corresponding to the plurality of pose data, wherein the processor is further configured to: find in the pose database a corresponding reference image based on the rough pose data of the trackable device, wherein the corresponding reference image comprises the plurality of feature blocks; and locate the plurality of block positions of the plurality of feature blocks based on the corresponding reference image.
7. The tracking system of claim 4, wherein the trackable device further comprises: an inertial measurement unit configured to generate the motion signal of the trackable device; and a communication circuit to the inertial measurement unit, configured to transmit the motion signal to the tracking device.
8. The tracking system of claim 1, wherein the trackable device comprises a light emitting circuit configured to cause the first image captured by the optical sensing circuit having a light pattern corresponding to the feature pattern, wherein when the processor acquires the first region of interest, the processor is further configured to: threshold the first image to obtain a thresholded image; and acquire in the thresholded image the first region of interest, wherein the first region of interest comprises the light pattern.
9. The tracking system of claim 1, wherein the first pose data comprises at least one of a three-axis position, a yaw value, a pitch value, and a roll value.
10. The tracking system of claim 1, wherein when the processor calculates the first pose data of the trackable device, the processor executes a pose estimation algorithm to calculate the first pose data based on an image coordinate of each of the plurality of block positions of the plurality of feature blocks in the first image.
11. A tracking method, suitable for a trackable device comprising at least a feature pattern on an appearance of the trackable device, the method comprising: capturing a first image comprising the trackable device; acquiring, based on the feature pattern, in the first image a first region of interest corresponding to the feature pattern; locating in the first region of interest a plurality of block positions of a plurality of feature blocks, wherein each of the plurality of feature blocks comprises part of the feature pattern and the part of the feature pattern of each of the plurality of feature block is different from each other; and calculating a first pose data of the trackable device according to the plurality of block positions.
12. The tracking method of claim 11, wherein the step of acquiring the first region of interest comprises: acquiring in the first image the first region of interest based on a skeleton of the feature pattern.
13. The tracking method of claim 11, further comprising: processing a deep learning algorithm based on the first region of interest, in order to generate a rough pose data of the trackable device in the first region of interest.
14. The tracking method of claim 11, wherein the step of acquiring the first region of interest comprises: obtaining a second image captured before the first image and a second region of interest corresponding to the feature pattern in the second image; obtaining a motion signal generated by the trackable device between time points when the second image and the first image are captured respectively; predicting in the first image a partial region based on the motion signal and the second region of interest; and searching in the partial region of the first image the first region of interest based on the feature pattern.
15. The tracking method of claim 14, further comprising: calculating a rough pose data of the trackable device in the first region of interest based on a second pose data of the trackable device in the second region of interest and the motion signal.
16. The tracking method of claim 15, further comprising: generating a pose database configured to store a plurality of pose data of the trackable device and a plurality of reference images corresponding to the plurality of pose data; wherein the step of locating the plurality of block positions comprises: finding in the pose database a corresponding reference image based on the rough pose data of the trackable device, wherein the corresponding reference image comprises the plurality of feature blocks; and locating the plurality of block positions of the plurality of feature blocks based on the corresponding reference image.
17. The tracking method of claim 14, wherein the motion signal is generated by an inertial measurement unit of the trackable device.
18. The tracking method of claim 11, wherein the trackable device comprises a light emitting circuit that the first image comprises a light pattern corresponding to the feature pattern, wherein the step of acquiring the first region of interest further comprises: thresholding the first image to obtain a thresholded image; and acquiring in the thresholded image the first region of interest, wherein the first region of interest comprises the light pattern.
19. The tracking method of claim 11, wherein the first pose data comprises at least one of a three-axis position, a yaw value, a pitch value, and a roll value.
20. The tracking method of claim 11, wherein the step of calculating the first pose data of the trackable device comprises: executing a pose estimation algorithm to calculate the first pose data based on an image coordinate of each of the plurality of block positions of the plurality of feature blocks in the first image.
</claims>
</document>
