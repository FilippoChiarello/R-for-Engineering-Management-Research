<document>

<filing_date>
2018-08-03
</filing_date>

<publication_date>
2020-09-22
</publication_date>

<priority_date>
2018-02-05
</priority_date>

<ipc_classes>
G06F12/00,G06F12/0811,G06F13/16,G06F3/06,G06N3/08
</ipc_classes>

<assignee>
MICRON TECHNOLOGY
</assignee>

<inventors>
RAY, ANIRBAN
ANAND, GURPREET
MITTAL, SAMIR
</inventors>

<docdb_family_id>
67475108
</docdb_family_id>

<title>
Predictive data orchestration in multi-tier memory systems
</title>

<abstract>
A computing system having memory components of different tiers. The computing system further includes a controller, operatively coupled between a processing device and the memory components, to: receive from the processing device first data access requests that cause first data movements across the tiers in the memory components; service the first data access requests after the first data movements; predict, by applying data usage information received from the processing device in a prediction model trained via machine learning, second data movements across the tiers in the memory components; and perform the second data movements before receiving second data access requests, where the second data movements reduce third data movements across the tiers caused by the second data access requests.
</abstract>

<claims>
1. A computing system, comprising: a processing device; a plurality of memory components of different tiers; and a controller, operatively coupled between the processing device and the plurality of memory components, to at least: receive first data access requests from the processing device, the first data access requests causing first data movements across the tiers in the memory components; perform the first data movements responsive to the first data access requests; service the first data access requests after the first data movements; receive data usage information from the processing device; predict, based on the data usage information and a prediction model trained via machine learning, second data movements across the tiers in the memory components; and perform the second data movements before receiving second data access requests, the second data movements reducing third data movements caused by the second data access requests.
2. The computing system of claim 1, wherein the data usage information identifies: a sequence of data blocks being used in a period of time; instances of requests to load data blocks from the second memory to the first memory; content attributes of data blocks loaded from the second memory to the first memory; ownership attributes of data blocks loaded from the second memory to the first memory; identifications of users of data blocks loaded from the second memory to the first memory; identifications of applications that cause data blocks to be loaded from the second memory to the first memory; an identification of data blocks that are accessed in a sequential mode in a virtual machine; an identification of data blocks that are accessed in a sequential mode in a user account; and an identification of data accesses that are in a steady state.
3. The computing system of claim 1, wherein the controller is further operatively to: adjust the prediction model based on a performance measurement of the plurality of memory components in servicing data access requests from the processing device.
4. The computing system of claim 3, wherein the plurality of memory components include first memory and second memory; the first memory functions as cache of the second memory.
5. The computing system of claim 4, wherein the performance measurement is a cache hit ratio of data access requests; and requests of the processing device for data in the second memory causes movements of the requested data from the second memory to the first memory.
6. The computing system of claim 5, wherein the controller adjusts the prediction model using a hybrid reinforcement learning technique by adjusting an artificial neural network to generate predictions that improves the cache hit ratio measured at the controller for the requests of the processing device.
7. The computing system of claim 6, wherein the controller communicates with the processing device over a memory bus; and the controller is disposed on a memory module.
8. The computing system of claim 7, wherein the plurality of memory components are disposed on the memory module.
9. The computing system of claim 7, wherein the first data movements and the second data movement do not go through the memory bus.
10. The computing system of claim 9, wherein a portion of the plurality of memory components is not on the memory module.
11. The computing system of claim 4, wherein the first memory is volatile dynamic random-access memory and the second memory is non-volatile cross-point memory.
12. The computing system of claim 4, wherein the controller comprises a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC).
13. The computing system of claim 1, wherein the controller is further operatively to: identify a mapping between data blocks in the plurality of memory components and data objects as organized in applications running in the processing device.
14. A method, comprising: receiving, in a computing device, first data access requests from a processing device coupled to a plurality of memory components of different tiers, the first data access requests causing first data movements across the tiers in the memory components; performing, by the computing device, the first data movements responsive to the first data access requests; servicing the first data access requests after the first data movements; receiving, in the computing device, data usage information from the processing device; predicting, by the computing device based on the data usage information and a prediction model trained via machine learning, second data movements across the tiers in the memory components; and performing, by the computing device, the second data movements before receiving second data access requests, the second data movements reducing third data movements caused by the second data access requests.
15. The method of claim 14, wherein the prediction model comprises an artificial neural network; and the method further comprises: training the prediction model based on the first data movements and data usage information associated with the first data access requests.
16. The method of claim 15, further comprising: providing the prediction model after the training that is performed offline, wherein the predicting is performed in real time for the second data access requests.
17. The method of claim 15, further comprising: further training the prediction model based on the third data movements caused by the second data access requests and the data usage information used to predict the second data movements.
18. The method of claim 14, further comprising: analyzing data usage information to group data blocks that are used together to identify a mapping between data blocks and data objects, wherein the predicting is based at least in part on the mapping.
19. A non-transitory computer storage medium storing instructions which, when executed by a computing system, cause the computing system to perform a method, the method comprising: receiving first data access requests from a processing device coupled to a plurality of memory components of different tiers, the first data access requests causing first data movements across the tiers in the memory components; performing, by the cache controller, the first data movements responsive to the first data access requests; servicing the first data access requests based on the first data movements; predicting, based on data usage information and a prediction model trained via machine learning, second data movements across the tiers in the memory components; and performing, by the cache controller, the second data movements before receiving second data access requests, the second data movements reducing third data movements caused by the second data access requests.
20. The non-transitory computer storage medium of claim 19, wherein the prediction model includes an artificial neural network; and the method further comprises: training the prediction model to generate predictions matching the first data movements and the third data movements.
</claims>
</document>
