<document>

<filing_date>
2019-10-21
</filing_date>

<publication_date>
2020-07-14
</publication_date>

<priority_date>
2019-10-21
</priority_date>

<ipc_classes>
A61B5/00,A61B5/08,A61B7/00,A61B7/04,G06K9/62,G06N3/08
</ipc_classes>

<assignee>
SONAVI LABS
</assignee>

<inventors>
MCLANE, IAN MITRA
</inventors>

<docdb_family_id>
71519823
</docdb_family_id>

<title>
Detecting a respiratory abnormality using a convolution, and applications thereof
</title>

<abstract>
Embodiments disclosed herein improve digital stethoscopes and their application and operation. A first method detects of a respiratory abnormality using a convolution. A second method counts coughs for a patient. A third method predicts a respiratory event based on a detected trend. A fourth method forecasts characteristics of a future respiratory event. In a fifth embodiment, a base station is provided for a digital stethoscope.
</abstract>

<claims>
1. A computer-implemented method for detection of a respiratory abnormality comprising: receiving, from a microphone, an auditory signal; generating an auditory spectrogram based on the auditory signal; performing a spatial convolution procedure on the auditory spectrogram to generate one or more convolution values, wherein the convolution values represent a compressed version of a matrix portion of the auditory spectrogram, and wherein the spatial convolution procedure is trained to generate one or more features for detecting the respiratory abnormality; applying one or more weights to the convolution values, wherein the weights are trained for detection of the respiratory abnormality; generating a classification value based on applying the weights to the convolution values, wherein the classification value indicates whether the auditory signal includes the respiratory abnormality; and transmitting the classification value to a display device for outputting the classification value.
2. The method of claim 1 wherein performing the spatial convolution procedure enables the classification value to be output in real time after the auditory signal is received from the microphone.
3. The method of claim 1 further comprising: receiving a further auditory signal collected contemporaneously with the auditory signal, from a further microphone, wherein the further auditory signal represents a background noise; and adjusting, before generating the auditory spectrogram, the auditory signal based on the further auditory signal to reduce the background noise.
4. The method of claim 1 further comprising: receiving an accelerometer data, from an accelerometer coupled to the microphone, wherein the accelerometer data is collected contemporaneously with the auditory signal; and adjusting, before generating the auditory spectrogram, the auditory signal based on the accelerometer data to reduce noise from movement of the microphone from a patient's breathing.
5. The method of claim 1 further comprising: receiving an accelerometer data, from an accelerometer coupled to the microphone, wherein the accelerometer data is collected contemporaneously with the auditory signal, and wherein the accelerometer data represents a chest motion; analyzing the accelerometer data to extract a respiratory cycle based on the chest motion; and adjusting, before generating the auditory spectrogram, the auditory signal based on the respiratory cycle.
6. The method of claim 1 further comprising filtering, before generating the auditory spectrogram, the auditory signal according to a cochlear model.
7. The method of claim 6 further comprising: dividing the auditory signal into one or more frequency bands; and wherein filtering the auditory signal according to the cochlear model is based on filtering the frequency bands.
8. The method of claim 1 wherein performing the spatial convolution procedure is performed repeatedly to successively compress the auditory spectrogram into a convolutional matrix to generate the convolution values.
9. The method of claim 8 wherein performing the spatial convolution procedure includes one or more convolution functions, wherein the convolution functions are trained to generate a value indicative of whether a portion of the convolutional matrix includes the respiratory abnormality.
10. The method of claim 9 further comprising: calculating the convolutional matrix, with a field programmable gate array (FPGA), based on the auditory spectrogram, wherein the FPGA has hard coded logic to calculate the convolutional matrix, and wherein the hard coded logic is trained to generate the features for detecting the respiratory abnormality; and storing, on a dynamic random access memory (DRAM), the convolutional matrix, wherein the convolutional matrix is an intermediate value used in successive calculations.
11. A non-transitory computer readable medium including instructions for detection of a respiratory abnormality comprising: receiving, from a microphone, an auditory signal; generating an auditory spectrogram based on the auditory signal; performing a spatial convolution procedure on the auditory spectrogram to generate one or more convolution values, wherein the convolution values represent a compressed version of a matrix portion of the auditory spectrogram, and wherein the spatial convolution procedure is trained to generate one or more features for detecting the respiratory abnormality; applying one or more weights to the convolution values, wherein the weights are trained for detection of the respiratory abnormality; generating a classification value based on applying the weights to the convolution values, wherein the classification value indicates whether the auditory signal includes the respiratory abnormality; and transmitting the classification value to a display device for outputting the classification value.
12. The non-transitory computer readable medium of claim 11 with instructions wherein performing the spatial convolution procedure enables the classification value to be output in real time after the auditory signal is received from the microphone.
13. The non-transitory computer readable medium of claim 11 with instructions further comprising: receiving a further auditory signal collected contemporaneously with the auditory signal, from a further microphone, wherein the further auditory signal represents a background noise; and adjusting, before generating the auditory spectrogram, the auditory signal based on the further auditory signal to reduce the background noise.
14. The non-transitory computer readable medium of claim 11 with instructions further comprising: receiving an accelerometer data, from an accelerometer coupled to the microphone, wherein the accelerometer data is collected contemporaneously with the auditory signal; and adjusting, before generating the auditory spectrogram, the auditory signal based on the accelerometer data to reduce noise from movement of the microphone from a patient's breathing.
15. The non-transitory computer readable medium of claim 11 with instructions further comprising: receiving an accelerometer data, from an accelerometer coupled to the microphone, wherein the accelerometer data is collected contemporaneously with the auditory signal, and wherein the accelerometer data represents a chest motion; analyzing the accelerometer data to extract a respiratory cycle based on the chest motion; and adjusting, before generating the auditory spectrogram, the auditory signal based on the respiratory cycle.
16. The non-transitory computer readable medium of claim 11 with instructions further comprising filtering, before generating the auditory spectrogram, the auditory signal according to a cochlear model.
17. The non-transitory computer readable medium of claim 16 with instructions further comprising: dividing the auditory signal into one or more frequency bands; and wherein filtering the auditory signal according to the cochlear model is based on filtering the frequency bands.
18. The non-transitory computer readable medium of claim 11 with instructions wherein performing the spatial convolution procedure is performed repeatedly to successively compress the auditory spectrogram into a convolutional matrix to generate the convolution values.
19. The non-transitory computer readable medium of claim 18 with instructions further comprising: calculating the convolutional matrix, with a field programmable gate array (FPGA), based on the auditory spectrogram, wherein the FPGA has hard coded logic to calculate the convolutional matrix, and wherein the hard coded logic is trained to generate the features for detecting the respiratory abnormality; and storing, on a dynamic random access memory (DRAM), the convolutional matrix, wherein the convolutional matrix is an intermediate value used in successive calculations.
20. The method of claim 1 wherein performing the spatial convolution procedure is performed on a digital stethoscope.
</claims>
</document>
