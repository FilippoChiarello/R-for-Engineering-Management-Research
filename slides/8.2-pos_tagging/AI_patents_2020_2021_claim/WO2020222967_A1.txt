<document>

<filing_date>
2020-04-01
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2019-04-30
</priority_date>

<ipc_classes>
G06F40/30,G10L15/183,G10L15/22
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
WANAS, NAYER
MANSOUR, Riham
EMARA, Basma
YOUSEF, Kareem
HANNA, Carol
SHAHIN, Youssef
</inventors>

<docdb_family_id>
70476332
</docdb_family_id>

<title>
USING DIALOG CONTEXT TO IMPROVE LANGUAGE UNDERSTANDING
</title>

<abstract>
Described herein is a mechanism for improving the accuracy of a language model interpreting short input utterances. A language model operates in a stateless manner, only ascertaining the intents and/or entities associated with a presented input utterance. To increase the accuracy, two language understanding models are trained. One is trained using only input utterances. The second is trained using input utterance-prior dialog context pairs. The prior dialog context is previous intents and/or entities already determined from the utterances in prior turns of the dialog. When input is received, the language understanding model decides whether the input comprises only an utterance or an utterance and prior dialog context. The appropriate trained machine learning model is selected and the intents and/or entities associated with the input determined by the selected machine learning model.
</abstract>

<claims>
1. A method for language recognition, comprising:
receiving an input utterance;
determining whether prior dialog context information was received in conjunction with the input utterance;
responsive to determining that prior dialog context information was received:
selecting a first trained language understanding model;
determining a first intent from the input utterance and the prior dialog context information using the first trained language understanding model;
returning the first intent;
responsive to determining that prior dialog context information was not received:
selecting a second trained language understanding model;
determining a second intent from the input utterance using the second trained language understanding model;
returning the second intent.
2. The method of claim 1 further comprising:
responsive to determining that prior dialog context information was received:
determining a first entity from the input utterance using the first trained language understanding model; and
returning the first entity along with the first intent.
3. The method of claim 1 further comprising:
responsive to determining that prior dialog context information was not received:
determining a second entity from the input utterance using the second trained language understanding model; and
returning the second entity along with the second intent.
4. The method of claim 1 wherein:
the first trained language understanding model is trained using example utterances and associated prior dialog context; and
the second trained language understanding model is trained using example utterances without associated prior dialog context pairs.
5. The method of claim 1 further comprising:
receiving a plurality of example utterances;
identify at least one example prior dialog context;
creating a plurality of utterance-context pairs, each pair comprising an example utterance and an example dialog context;
extracting a first set of features from the utterance-context pairs; and
training the first language understanding model with training data comprising the first set of features.
6. The method of claim 5 further comprising:
extracting a second set of features from the example utterances; and
training the second language understanding model with training data comprising the second set of features.
7. The method of claim 5 wherein the plurality of example utterances is derived from requests used by a dialog system to elicit entity information from a user.
8. The method of claim 7 wherein the at least one example prior dialog context comprises at least one intent and wherein the entity information is associated with the at least one intent.
9. The method of claim 1 further comprising:
responsive to determining that prior dialog context information was received:
determining a first likelihood score associated with the first intent using the first trained language understanding model;
determining a third intent and an associated likelihood score using the first trained language understanding model;
returning the first likelihood score along with the first intent and returning the third intent and its associated likelihood score along with the first intent and the first likelihood score.
10. The method of claim 1 further comprising:
responsive to determining that prior dialog context information was not received:
determining a second likelihood score associated with the second intent using the second trained language understanding model;
determining a fourth intent and an associated likelihood score using the second trained language understanding model;
returning the second likelihood score along with the second intent and returning the fourth intent and its associated likelihood score along with the second intent and the second likelihood score.
11. A system comprising a processor and computer executable instructions, that when executed by the processor, cause the system to perform operations comprising: receiving a plurality of example utterances;
identify at least one example prior dialog context;
creating a plurality of utterance-context pairs, each pair comprising an example utterance and an example dialog context;
extracting a first set of features from the utterance-context pairs;
training a first language model with training data comprising the first set of features;
receiving an utterance;
determining whether prior dialog context was received along with the utterance; responsive to determining that prior dialog context was received along with the utterance:
determining at least one intent based on the utterance and prior dialog context using the first language model; and
returning the at least one intent.
12. The system of claim 11 further comprising determining a likelihood score associated with each intent of the at least one intent using the first language model.
13. The system of claim 11 wherein further comprising:
responsive to determining that prior dialog context was received along with the utterance, selecting the first language model from among a plurality of language models.
14. The system of claim 11 wherein the at least one example prior dialog context comprises an intent and wherein the operations further comprise:
deriving the plurality of example utterances from requests used by a dialog system to elicit entity information from a user.
15. The system of claim 11 further comprising:
extracting a second set of features from the plurality of utterances; and training a second language model with training data comprising the second set of features.
</claims>
</document>
