<document>

<filing_date>
2018-06-28
</filing_date>

<publication_date>
2020-04-16
</publication_date>

<priority_date>
2017-06-28
</priority_date>

<ipc_classes>
A01K61/13,A01K61/80,G06K9/00,G06K9/62,G06N3/04,G06N3/08,G06T7/20
</ipc_classes>

<assignee>
OBSERVE TECHNOLOGIES
</assignee>

<inventors>
SLOAN, CHARCHRIS
RISHI, HEMANG RAVI
MAKEEV, IVAN
FABRY, PIETER JAN
</inventors>

<docdb_family_id>
59523595
</docdb_family_id>

<title>
DATA COLLECTION SYSTEM AND METHOD FOR FEEDING AQUATIC ANIMALS
</title>

<abstract>
The present invention relates to a method and apparatus for collecting and/or pre-processing data related to feeding animals in water. More particularly, the present invention relates to a method and apparatus for minimising wasted feed used in a fish farm. According to an aspect, there is a provided a computer-implemented method for detecting motion in relation to one or more aquatic animals, the method comprising the steps of: receiving sensor data; determining from the sensor data one or more moving objects using one or more learned functions; and generating output data in relation to the determined one or more moving objects.
</abstract>

<claims>
1. A computer-implemented method for detecting motion in relation to one or more aquatic animals, the method comprising: receiving sensor data; determining from the sensor data one or more moving objects using one or more learned functions, wherein the one or more learned functions comprise one or more trained neural networks, the one or more trained neural networks comprising one or more feedback loops; and generating output data in relation to the determined one or more moving objects through analysis of the sensor data comprising one or more analysis in relation to any or any combination of: feed provided to the one or more aquatic animals; activity level of the one or more aquatic animals; wasted feed pellets; and/or environmental data, wherein the analysis is performed using the one or more feedback loops, further wherein the output data is based on temporal information provided by the one or more feedback loops.
2. The method of claim 1, wherein said one or more moving objects comprises any or any combination of: feed; feed pellets; faeces; aquatic animals; groups of aquatic animals.
3. The method of claim 1, wherein the sensor data is obtained from one or more enclosed spaces containing water; optionally wherein the one or more enclosed spaces comprise one or more cages and/or one or more aquatic animal farms.
4. The method of claim 1, wherein the sensor data comprises any or any combination of: image data; a plurality of image frames; video data; acoustic data; sonar data; light data; biomass data; environmental data; stereo vision data; acoustic camera data; and/or fish activity data: optionally wherein said sensor data comprises any or a combination of: fish type; feed type; past and present feed conversion ratio; biological feed conversion ratio; economical feed conversion ratio; past and present standard growth rate; past and present specific growth rate; mortality data; feed input data comprising amount and/or rate and/or intensity; and/or optionally wherein said fish activity data comprises any or a combination of: reaction of fish towards feed; fish schooling data; surface feeding activity; fish density; fish speed; sound of fish eating; sound of fish moving; and/or distance of fish from sensors; and/or optionally wherein said environmental data comprises any or a combination of: dissolved oxygen level; state of the tide; pH of the water; visibility through the water; intensity of light incident on the water; biomass data; mass of feed being consumed; air and/or water temperature; sunlight; cleanliness of water; salinity; saturation; rainfall; tide level; state of nets; treatments; sea lice count; oxygen input data; current or wind data; fish genetic data; and/or fish vaccination.
5. (canceled)
6. (canceled)
7. The method of claim 1, wherein the one or more trained neural networks comprise any or a combination of: one or more neural networks; one or more convolutional neural networks (CNNs); one or more deep learning functions and/or models; one or more CNNS comprising one or more architectural models such as ResNet, InseptionNet and/or SqueezeNet; Long Short Term Memory (LSTM) neural networks; Recurrent neural networks (RNN); and/or Gated Recurrent Unit (GRU); optionally wherein the sensor data is an input into said one or more trained neural networks; and/or optionally wherein the one or more trained neural networks are updated over a time period and/or using reinforcement learning techniques and/or are arranged to continuously learn in real time.
8. The method of claim 7, wherein motion of the one or more moving objects is monitored over all or a sequential portion of said sensor data; optionally wherein any localization and/or tracking of the aquatic animals is performed through the use of one or more CNNs; and/or optionally wherein an activity level is monitored over a plurality of individual image frames.
9. The method of claim 1, wherein an activity level of one or more aquatic animals is determined by the one or more trained neural networks; optionally wherein the sensor data is labelled to extract features which optimise feeding; and/or optionally wherein the activity level is labelled within a range between low to high; and/or optionally wherein the activity level of one or more aquatic animals comprises speed, schooling behaviour, movement and/or distance from a sensor.
10. The method of claim 1, wherein feeding data is determined by the one or more trained neural networks; optionally wherein the feeding data comprises any or any combination of: detected feed pellets; wasted feed pellets; faeces; and/or determining the one or more moving objects comprises distinguishing between feed and waste; and/or determining the one or more moving objects comprises feed pellets at a depth below that at which the one or more aquatic animals normally feed; and/or optionally wherein feeding data comprises a determination of a proportion of the feed not consumed by the animals by distinguishing between feed pellets and waste products of the animals in the sensor data.
11. The method of claim 1, wherein data regarding the one or more aquatic animals is determined; said data comprising one or more of: feeding pellets not consumed; feed conversion rate; biomass; animal mortality; animal growth; instructing placement of a derived amount of feed; and/or animal activity; optionally wherein in response to determining said data of the method includes triggering an alarm in response to any or any combination of: overfeeding, underfeeding, detected levels of dissolved oxygen dropping, the presence of other species of animal in the enclosed space, detected health anomalies, and/or detected net holes.
12. The method of claim 1, wherein the output in relation to the determined one or more moving objects is generated through correlation analysis of the sensor data comprising one or more analysis in relation to any or any combination of: feed provided to the one or more aquatic animals; activity level of the one or more aquatic animals; wasted feed pellets; and/or environmental data.
13. The method of claim 12, wherein the correlation analysis is performed using the one or more feedback loops; optionally wherein the one or more feedback loops comprises a circular buffer and/or a state buffer.
14. The method of claim 13, wherein an optimised level of feed is determined by using the one or more feedback loops optimising for one or more variables; optionally wherein the one or more variables comprises any one or more of growth rate to feed conversion ratio, minimal pellet loss, and/or sea lice.
15. (canceled)
16. (canceled)
17. The method of claim 12, wherein determining the one or more features of the system comprises a step of correlating one or more signals to the one or more features; optionally wherein the step of correlating the one or more signals to the one or more features comprises multi-task learning; and/or further optionally wherein the step of correlating the one or more signals to the one or more features comprises converging the one or more signals to the one or more features.
18. The method of claim 17, wherein the optimised level of feed is generated through the use of one or more neural networks to form a model; optionally wherein the one or more neural networks comprise one or more convolutional neural networks (CNNs); and/or optionally wherein the model is trained and formed to: analyse real time image data to perform feed detection and localisation; analyse previous image frames to identify movement and/or warping of pellets relative to current real time image data frames; and enhance the distinction of feed and waste for future image frames; and/or further optionally wherein localization is performed using one or more blob detectors; and/or still further optionally wherein the one or more neural networks uses the one or more feedback loops to provide the temporal information: optionally wherein the one or more neural networks comprises any of: Long Short Term Memory (LSTM) neural networks; Recurrent neural networks (RNN); Gated Recurrent Unit (GRU); internal state machines; and/or circular buffers; and/or further optionally wherein the one or more neural networks is used to create a feature set from the sensor data by correlating two or more feature signals obtained from the sensor data; and/or further optionally the method comprising determining, from a portion of stored data, at least one new parameter for deriving the amount of feed using a deep learning (DL) algorithm; and/or further optionally wherein the model is arranged to continuously learn in real time.
19. (canceled)
20. The method of claim 1, wherein the sensor data comprises a plurality of substantially real time sensor data streams that are received individually and/or simultaneously; optionally wherein the plurality of substantially real time sensor data streams are learned simultaneously using multi-task learning; and/or further optionally wherein the multi-task learning is implemented for simultaneous detection, motion estimation, feed/waste classification, characteristic regressions, and/or bounding box regression; and/or further optionally wherein the plurality of real time sensor data streams are mapped in real time.
21. The method of claim 1, wherein the sensor data is mapped on any one or more of: probability maps; heat maps; motion maps; flow maps; and/or unified maps; optionally wherein the sensor data is mapped in relation to feed and/or waste, and/or further optionally wherein the sensor data is mapped as an optical flow.
22. The method of claim 1, further comprising determining feed to be provided to the one or more aquatic animals; optionally wherein determining feed comprises any one or more of: determining whether to increase/decrease the amount of feed; determining whether to continue/cease feeding; determining an area feed is to be provided; and/or determining whether to start/stop providing feed to the one or more aquatic animals.
23. The method of claim 1, wherein the output data in relation to the determined one or more moving objects is provided to one or more learned decision-making models.
24. The method of claim 1, further comprising: receiving first real time image data from the confined space during a first time period; determining, from at least the real time image data, an activity level for the animals prior to and/or during feeding; deriving an amount of feed required in response, at least to the activity level; instructing placement of the derived amount and rate of feed in the confined space; receiving second real time image data from the confined space during a second time period; determining, from at least the second real time image data, what proportion of the feed is not consumed by the animals and/or an activity response of the animals to the feed; receiving third real time image data from the enclosed space during a third time period; calculating a degree of satiety of the animals from at least the third real time image data; and storing at least a portion of the data in respect of at least one of the time periods.
25. 25-39. (canceled)
40. The method of claim 1, further comprising: showing data regarding the animals to an operator via a user interface; and/or instructing placement of the derived amount of feed comprises signalling to feed distribution apparatus.
41. The method of claim 40, wherein the data regarding the animals includes data relating to one or more of: feeding pellets not consumed, animal mortality, instructing placement of the derived amount of feed, and/or animal activity.
42. The method of claim 40, wherein the data regarding the animals is transmitted to an operator via the Internet.
43. 43-45. (canceled)
46. The method of claim 1, wherein the sensor data includes video data that is provided by a pan-tilt-zoom camera and the method further comprises adjusting the camera prior to at least one of the steps of receiving video data.
47. The method of claim 1, further comprising: triggering an alarm in response to at least one of: overfeeding, underfeeding detected levels of dissolved oxygen dropping, and/or the presence of other species of animal in the confined space.
48. 48-60. (canceled)
61. The method of claim 1, wherein the sensor data includes a signal from at least one video sensor, the method comprising processing video data from the at least one video sensor, the video data capturing at least two distinct confined spaces, wherein the video data from the at least two distinct confined spaces is processed in parallel.
62. 62-65. (canceled)
</claims>
</document>
