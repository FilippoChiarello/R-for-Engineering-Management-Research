<document>

<filing_date>
2019-07-26
</filing_date>

<publication_date>
2021-01-28
</publication_date>

<priority_date>
2019-07-26
</priority_date>

<ipc_classes>
G05D1/00,G08G1/0965
</ipc_classes>

<assignee>
ZOOX
</assignee>

<inventors>
GOGNA, RAVI
Goldman, Meredith James
</inventors>

<docdb_family_id>
74189792
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR CONTROLLING AN AUTONOMOUS VEHICLE
</title>

<abstract>
The present disclosure is directed to systems and techniques for controlling an autonomous vehicle. While the autonomous vehicle is travelling to a destination, the autonomous vehicle may encounter a situation preventing the autonomous vehicle from travelling to the destination. A control center may receive information from the autonomous device and use a graphical user interface to provide instructions with limited controls for the autonomous vehicle to navigate to an intermediate position. In such an intermediate position, the vehicle may make way for an emergency vehicle, obtain additional sensor data for continued autonomous planning, signal intent to other objects in the environment, and the like.
</abstract>

<claims>
1. A method, comprising: receiving at least a portion of sensor data from a sensor on an autonomous vehicle, traversing an environment to a destination; causing a display to display a first representation of the autonomous vehicle in the environment; causing the display to display a second representation of the sensor data; receiving input indicating an intermediate location to which the autonomous vehicle is to travel, the indication being limited to a radius of the autonomous vehicle in the first representation and comprising one or more of a position or an orientation; and transmitting, based at least in part on the input, an instruction to the autonomous vehicle to cause the autonomous vehicle to travel to the intermediate location.
2. The method of claim 1, wherein the first representation comprises a map of the environment proximate the autonomous vehicle and a bounding box representing an object in the environment.
3. The method of claim 2, wherein the object comprises an emergency vehicle, and wherein the intermediate location comprises a location in the environment to enable the emergency vehicle to pass from behind the autonomous vehicle.
4. The method of claim 1, wherein the portion of sensor data comprises information indicative of the autonomous vehicle encountering a situation that prevents the autonomous vehicle from reaching the destination.
5. The method of claim 1, wherein the instruction further provide an indication for the autonomous vehicle to move at less than or equal to a threshold speed while moving to the intermediate location.
6. The method of claim 1, further comprising: causing the display to display a plurality of arrows, an arrow of the plurality of arrows associated with a cardinal direction, wherein the input is associated with the plurality of arrows, and wherein the intermediate location is determined, based at least in part, on the input.
7. A system, comprising: one or more processors; and non-transitory computer readable memory including instructions that, when executed by the one or more processors, cause the system to perform operations comprising: receive, at a display, at least a portion of sensor data from a sensor of a device, the sensor data reflecting a state of an environment surrounding the device en route to a destination; receive input indicating an intermediate destination that is a distance within a specific radius of a current position of the device in accordance to a speed threshold to which the device is to travel; and transmit an instruction to the device to cause the device to use a plan to travel to the intermediate destination en route to the destination.
8. The system of claim 7, wherein the display is a graphical user interface (GUI) comprising a representation of the state of the environment surrounding the device and wherein the representation comprising a map of the environment and a bounding box representing an object in the environment.
9. The system of claim 8, wherein the object comprising an emergency vehicle, and wherein the intermediate destination comprises a location in the environment to enable the emergency vehicle to pass from behind the device.
10. The system of claim 7, wherein the portion of sensor data comprises information indicative of the device encountering a situation that prevents the device from reaching the destination.
11. The system of claim 7, wherein the instructions, when executed by the one or more processors, further cause the system to perform the operations comprising: cause the display to display a plurality of arrows, an arrow of the plurality of arrows associated with a cardinal direction, wherein the input is associated with the plurality of arrows, and wherein the intermediate destination is determined, based at least in part, on the input.
12. The system of claim 7, wherein the instruction further provides an indication for the device to move at less than or equal to the speed threshold while moving to the intermediate destination.
13. The system of claim 7, wherein the instruction indicates to the device to use four-wheel steering to perform the instruction to the intermediate destination.
14. A non-transitory computer-readable storage medium having stored thereon executable instructions that, as a result of being executed by one or more processors of a computer system, cause the computer system to at least: receive, at a graphical user interface, at least a portion of sensor data from a sensor of a device, the sensor data reflecting a state of an environment surrounding the device en route to a destination; receive input indicating an intermediate destination that is a distance within a specific radius of a current position of the device in accordance with a speed threshold to which the device is to travel; and transmit an instruction to the device to cause the device to use a plan to travel to the intermediate destination en route to the destination.
15. The non-transitory computer-readable storage medium of claim 14, wherein the executable instructions, as a result of being executed by one or more processors of the computer system, further cause the computer system to at least cause the graphical user interface to display: a first representation of the state of the environment surrounding the device, wherein the first representation comprises a map of the environment and a bounding box representing an object in the environment; and a second representation of the sensor data, wherein the second representation comprises raw image streams.
16. The non-transitory computer-readable storage medium of claim 15, wherein the object comprises an emergency vehicle, and wherein the intermediate destination comprises a location in the environment to enable the emergency vehicle to pass from behind the device.
17. The non-transitory computer-readable storage medium of claim 14, wherein the portion of sensor data comprises information indicative of the device encountering a situation that prevents the device from reaching the destination.
18. The non-transitory computer-readable storage medium of claim 14, wherein the speed threshold further provides an indication for the device to move at less than or equal to a threshold speed while moving to the intermediate destination.
19. The non-transitory computer-readable storage medium of claim 14, wherein the executable instructions, as a result of being executed by one or more processors of the computer system, further cause the computer system to at least: cause the graphical user interface to display a plurality of arrows, an arrow of the plurality of arrows associated with a cardinal direction, wherein the input is associated with the plurality of arrows, and wherein the intermediate destination is determined, based at least in part, on the input.
20. The non-transitory computer-readable storage medium of claim 14, wherein the instruction indicates to the device to use four-wheel steering to perform the instruction to the intermediate destination.
</claims>
</document>
