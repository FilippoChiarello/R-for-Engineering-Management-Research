<document>

<filing_date>
2020-03-30
</filing_date>

<publication_date>
2020-12-09
</publication_date>

<priority_date>
2019-06-03
</priority_date>

<ipc_classes>
G08G1/005,G08G1/16
</ipc_classes>

<assignee>
SONY CORPORATION
SONY EUROPE
</assignee>

<inventors>
LEE, Shaun
EXNER, Peter
THÃ–RN, Ola
</inventors>

<docdb_family_id>
70058137
</docdb_family_id>

<title>
MONITORING VEHICLE MOVEMENT FOR TRAFFIC RISK MITIGATION
</title>

<abstract>
A monitoring system detects and mitigates traffic risks among a group of vehicles. The group of vehicles comprises a ground-based vehicle (GBV), e.g. an automotive vehicle, and an air-based vehicle (ABV), e.g. a drone, which is operated to track a ground-based object (GBO), e.g. an unprotected road user or an animal. The monitoring system performs a method comprising: obtaining (301) predicted navigation data for the ground-based vehicle and the air-based vehicle, processing (302) the predicted navigation data to obtain one or more future locations of the ground based-object and to detect an upcoming spatial proximity between the ground-based object and the ground-based vehicle, and causing (305), upon detection of the upcoming spatial proximity, an alert signal to be provided to at least one of the ground-based object and the ground-based vehicle.
</abstract>

<claims>
1. A method of mitigating traffic risks among a group of vehicles comprising an air-based vehicle (30) and a ground-based vehicle (20), the air-based vehicle (30) being operated to track a ground-based object (10), said method comprising, at a current time point: obtaining (301) predicted navigation data for the ground-based vehicle (20) and the air-based vehicle (30), processing (302) the predicted navigation data to obtain one or more future locations of the ground based-object (10) and to detect an upcoming spatial proximity between the ground-based object (10) and the ground-based vehicle (20), and causing (305), upon detection of the upcoming spatial proximity, an alert signal (AS) to be provided to at least one of the ground-based object (10) and the ground-based vehicle (20).
2. The method of claim 1, wherein the predicted navigation data is indicative of a first predicted trajectory (T20) for the ground-based vehicle (20), and a second predicted trajectory (T10) for the ground-based object (10) that is tracked by the air-based vehicle (30).
3. The method of claim 2, wherein the predicted navigation data comprises a predicted trajectory for the air-based vehicle (30), said processing (302) comprising: determining (311) location data of the ground-based object (10) in relation to the air-based vehicle (30), and converting (312) the predicted trajectory for the air-based vehicle (30) into the second predicted trajectory (T10) for the ground-based object (10) based on the location data.
4. The method of claim 2 or 3, wherein the first predicted trajectory (T20) comprises a sequence of first locations and associated first time points in relation to a reference time point, and the second predicted trajectory (T10) comprises a sequence of second locations and associated second time points in relation to the reference time point.
5. The method of claim 4, wherein said processing (302) comprises: mapping (313) the first locations and the associated first time points of the first predicted trajectory (T20) to the second locations and the associated second time points of the second predicted trajectory (T10), and detecting (314) the upcoming spatial proximity based on the mapping.
6. The method of claims 5, wherein the upcoming spatial proximity is detected when a distance (D3, D4, D5) between a first location and a second location is below a spatial limit and when a time difference between a first time point associated with the first location and a second time point associated with the second location is below a temporal limit.
7. The method of claim 5 or 6, wherein at least one of the spatial and temporal limits are set as a function of a velocity vector of the ground-based vehicle (20) and/or a velocity vector of the ground-based object (10).
8. The method of any preceding claim, further comprising: analysing (304), upon the detection of the upcoming spatial proximity, the predicted navigation data and/or sensor data for determination of an occluded line-of-sight (LOS) between the ground-based object (10) and the ground-based vehicle (20), wherein said sensor data is obtained by a vision sensor (22; 12; 32) on at least one of the ground-based vehicle (20), the ground-based object (10) and the air-based vehicle (30).
9. The method of claim 8, wherein the group of vehicles comprises at least one further ground-based vehicle (20'), wherein said analysing (304) comprises: determining (332) an LOS between the ground-based vehicle (20) and the ground-based object (10) at one or more time points, mapping (333) a location of the at least one further ground-based vehicle (20') to the LOS (L1, L2, L3) at said one or more time points, and detecting (334) the occluded LOS when the at least one further ground-based vehicle (20') blocks the LOS (L1, L2, L3) at at least one of said one or more time points.
10. The method of claim 9, wherein said determining (332) the LOS comprises: determining an LOS vector (LOSV1) between the air-based vehicle (30) and the ground based-vehicle (20), obtaining a location vector (LV) between the air-based vehicle (30) and the ground based-object (10), and computing the LOS between the ground-based object (10) and the ground-based vehicle (20) as a function of the LOS vector (LOSV1) and location vector (LV).
11. The method of any one of claims 8-10, wherein said analysing (304) comprises: determining (321) a predicted location of the ground-based object (10) or the ground-based vehicle (20), and operating (322) the vision sensor (22; 12; 32) of the ground-based vehicle (20), the ground-based object (10) or the air-based vehicle (30) to capture the sensor data with the predicted location positioned within a field of view (24; 34) of the vision sensor (22; 12; 32).
12. The method of claim 11, wherein said analysing (304) further comprises: processing (323) the sensor data for detection of an occluding object (40) between a reference point and the predicted location, the reference point being located on the ground-based vehicle (20) or on the ground-based object (10), respectively.
13. The method of any preceding claim, wherein the alert signal (AS) is provided to the ground-based object (10) via the air-based vehicle (30).
14. The method of any preceding claim, further comprising: determining the group of vehicles among a larger plurality of vehicles by clustering based on respective locations of the larger plurality of vehicles at one or more time points.
15. A monitoring system for mitigating traffic risks among a group of vehicles comprising an air-based vehicle (30) and a ground-based vehicle (20), the air-based vehicle (30) being operable to track a ground-based object (10), said monitoring system being configured to, at a current time point: obtain predicted navigation data for the ground-based vehicle (20) and the air-based vehicle (30), process the predicted navigation data to determine one or more future locations of the ground based-object (10) and to detect an upcoming spatial proximity between the ground-based object (10) and the ground-based vehicle (20), and cause, upon detection of the upcoming spatial proximity, an alert signal (AS) to be provided to at least one of the ground-based object (10) and the ground-based vehicle (20).
</claims>
</document>
