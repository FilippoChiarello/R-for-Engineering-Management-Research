<document>

<filing_date>
2019-03-14
</filing_date>

<publication_date>
2020-09-17
</publication_date>

<priority_date>
2019-03-14
</priority_date>

<ipc_classes>
G06K9/00,G06N5/04,G06T15/00,G06T7/246
</ipc_classes>

<assignee>
DISNEY ENTERPRISES
</assignee>

<inventors>
GOSLIN, MICHAEL
BAUMBACH, Elliott
</inventors>

<docdb_family_id>
72423480
</docdb_family_id>

<title>
TECHNIQUES FOR INFERRING THE CONFIGURATION OF A ROOM FROM SKELETON TRACKING
</title>

<abstract>
In various embodiments, a map inference application automatically maps a user space. A camera is positioned within the user space. In operation, the map inference application determines a path of a first moving object within the user space based on a tracking dataset generated from images captured by the camera. Subsequently, the map inference application infers a walking space within the user space based on the path. The map inference application then generates a model of at least a portion of the user space based on the walking space. One or more movements of a second object within the user space are based on the model. Advantageously, unlike prior art solutions, the map inference application enables a model of a user space to be automatically and efficiently generated based on images from a single stationary camera.
</abstract>

<claims>
1. A computer-implemented method for mapping a user space, comprising determining a path of a first moving object within the user space based on a tracking dataset generated from images captured by a camera positioned within the user space; inferring a walking space within the user space based on the path; and generating a model of at least a portion of the user space based on the walking space, wherein one or more movements of a second object within the user space are based on the model.
2. The computer-implemented method of claim 1, wherein generating the model comprises: inferring a location and a size of a third stationary object within the user space based on an occlusion associated with the first moving object; generating an obstacle based on the location and the size of the third stationary object; and representing a spatial relationship between the walking space and the obstacle in the model.
3. The computer-implemented method of claim 1, wherein generating the model comprises: inferring a wall based on the path; and representing the walking space as a horizontal surface area and the wall as a vertical surface area in the model.
4. The computer-implemented method of claim 1, wherein the model comprises a three-dimensional (3D) model of the at least a portion of the user space or a two-dimensional (2D) model of at least a portion of the walking space.
5. The computer-implemented method of claim 1, wherein the tracking dataset comprises a sequence of skeleton objects that represent the first moving object a different points in time.
6. The computer-implemented method of claim 5, wherein each skeleton object included in the sequence of skeleton objects comprises a plurality of positions for a plurality of joints.
7. The computer-implemented method of claim 1, wherein the camera comprises a video camera or a still camera.
8. The computer-implemented method of claim 1, further comprising performing one or more tracking operations on the images captured by the camera to generate the tracking dataset.
9. The computer-implemented method of claim 1, wherein the first moving object comprises a person, and the tracking dataset comprises one or more sets of locations for one or more facial features associated with the person.
10. The computer-implemented method of claim 1, wherein the second object comprises a person or an inanimate object.
11. One or more non-transitory computer readable media including instructions that, when executed by one or more processors, cause the one or more processors to map a user space by performing the steps of: determining a path of a first moving object within the user space based on a tracking dataset generated from images captured by a camera positioned within the user space; inferring a walking space within the user space based on the path; and generating a model of at least a portion of the user space based on the walking space, wherein one or more movements of a second object within the user space are based on the model.
12. The one or more non-transitory computer readable media of claim 11, wherein generating the model comprises: detecting an occlusion of the first moving object based on a partial skeleton included in the tracking dataset; generating an obstacle based on the occlusion; and representing a spatial relationship between the walking space and the obstacle in the model.
13. The one or more non-transitory computer readable media of claim 11, wherein generating the model comprises: inferring a wall based on the path; and representing the walking space as a horizontal surface area and the wall as a vertical surface area in the model.
14. The one or more non-transitory computer readable media of claim 11, wherein the model comprises a 3D model of the at least a portion of the user space or a 2D model of at least a portion of the walking space.
15. The one or more non-transitory computer readable media of claim 11, wherein the tracking dataset comprises a sequence of skeleton objects that represent the first moving object a different points in time.
16. The one or more non-transitory computer readable media of claim 15, wherein each skeleton object included in the sequence of skeleton objects comprises a plurality of positions for a plurality of joints.
17. The one or more non-transitory computer readable media of claim 11, wherein the camera is at a fixed position and a fixed orientation within the user space.
18. The one or more non-transitory computer readable media of claim 11, further comprising performing one or more tracking operations on the images captured by the camera to generate the tracking dataset.
19. The one or more non-transitory computer readable media of claim 11, further comprising performing one or more facial recognition operations on the images captured by the camera to generate the tracking dataset.
20. A system, comprising: one or more memories storing instructions; and one or more processors that are coupled to the one or more memories and, when executing the instructions, are configured to: determine a path of a first moving object within the user space based on a tracking dataset generated from images captured by a camera positioned within the user space; infer a walking space within the user space based on the path; and generate a model of at least a portion of the user space based on the walking space, wherein one or more movements of a second object within the user space are based on the model.
</claims>
</document>
