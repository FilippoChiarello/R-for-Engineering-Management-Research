<document>

<filing_date>
2020-05-05
</filing_date>

<publication_date>
2020-11-12
</publication_date>

<priority_date>
2019-05-06
</priority_date>

<ipc_classes>
G01C21/20,G05D1/02
</ipc_classes>

<assignee>
Rugged Robotics Inc.
</assignee>

<inventors>
Diniz, Giovani
Morse, Derrick
</inventors>

<docdb_family_id>
70919036
</docdb_family_id>

<title>
MOBILITY PLATFORM FOR AUTONOMOUS NAVIGATION OF CONSTRUCTION SITES
</title>

<abstract>
An autonomous tool including a multi-sensor package enabling identification of the position of the tool in a construction site so that the tool may navigate to locations where tasks are performed. The tool may include at least one sensor from the group of a drive system encoder, stereo camera, inertial measurement unit, optical flow sensor, and LiDAR. The tool may include a holonomic drive allowing at least one tool of the mobility platform to reach the extremities of a construction site. The platform may be used as part of a system that receives design information relating to the construction site and tasks to be performed by the tool and then generates commands that control the tool to navigate along a path generated to include landmarks within range of and therefore detectable by the sensors for a large percentage of the path.
</abstract>

<claims>
1. A method for operating a mobility platform in a construction site based on an indication of one or more tasks to be performed at one or more task locations in the construction site and a design file representing in at least two dimensions the construction site, wherein the design file comprises one or more landmarks in the construction site, wherein the mobility platform includes at least one tool mounting location, the method comprising, with at least one processor: generating a path for the mobility platform based on the locations of one or more of the landmarks and the one or more task locations by iteratively adjusting the path to increase a projected position accuracy of the mobility platform based on projected errors in position estimation from continuous displacement and/or sensing position relative to one or more landmarks along the path; and providing task commands to a controller disposed on the mobility platform based on the generated path and one or more tasks.
2. The method of claim 1, further comprising, with the controller, based on executing the task commands, generating control signals to move the mobility platform along the generated path and perform the one or more tasks.
3. The method of claim 1, wherein the one or more landmarks are control points or control lines.
4. The method of claim 1, wherein increasing projected position accuracy includes iteratively adjusting the path to increase an amount of the path disposed within a threshold distance of the one or more landmarks.
5. The method of claim 4, wherein the threshold distance is based on the detectability of the one or more landmarks by at least one sensor selected from the group of a stereo camera, mono camera, and LiDAR unit, wherein the threshold distance is set where the one or more landmarks are detectable by the at least one sensor.
6. The method of claim 1, further comprising outputting the path on a graphical user interface.
7. The method of claim 6, wherein: generating the path comprises ending the iteratively adjusting based on a trigger condition; and the trigger condition comprises receiving input from a human user at the graphical user interface accepting the path.
8. The method of claim 6, further comprising: re-generating the path based on the locations of the one or more landmarks and the one or more task locations based on a trigger condition; and the trigger condition comprises receiving input from a human user at the graphical user interface rejecting the path.
9. The method of claim 1, further comprising, with the controller, controlling the mobility platform to move along the path based on the path and the task commands.
10. The method of claim 9, further comprising sensing the one or more landmarks with at least one sensor selected from the group of a stereo camera, mono camera, and LiDAR unit when the mobility platform is moved along the path.
11. The method of claim 10, further comprising correcting the movement of the mobility platform based on information received from the at least one sensor.
12. The method of claim 11, wherein correcting the movement of the mobility platform comprises using the information provided by the at least one sensor in feedback control.
13. The method of claim 10, wherein the at least one sensor comprises a stereo camera, mono camera, inertial measurement unit, optical flow sensor, and LiDAR unit.
14. The method of claim 13, further comprising integrating information from the stereo camera, inertial measurement unit, and optical flow sensor to compute a first position of the mobility platform in the construction site.
15. The method of claim 14, further comprising; continuously detecting the one or more landmarks with the LiDAR unit to compute a second position of the mobility platform in the construction site; and comparing the first position to the second position to compute a position accuracy value.
16. The method of claim 15, further comprising moving the mobility platform to one of the one or more known landmarks when the position accuracy value falls below a predetermined threshold.
17. The method of claim 16, further comprising changing one or more parameters of the controller based on the position accuracy value for integrating information from the stereo camera, mono camera, inertial measurement unit, and optical flow sensor to increase the position accuracy value above the predetermined threshold.
18. A method for operating a mobility platform in a construction site, wherein the platform comprises a plurality of sensors having an operational range within which the sensors are capable of detecting landmarks, the method comprising: identifying locations of the one or more landmarks in the construction site; identifying one or more tasks to be performed at one or more task locations in the construction site; and generating a path for the mobility platform based on the locations of one or more of the landmarks and the one or more task locations by iteratively adjusting the path to increase a projected position accuracy of the mobility platform based on projected errors in position estimation from continuous displacement and/or sensing position relative to one or more landmarks along the path.
19. The method of claim 18, wherein increasing the projected position accuracy includes iteratively adjusting the path to increase an amount of the path disposed within a threshold distance of the one or more landmarks, wherein the threshold distance is based on the operational range of the sensors.
20. The method of claim 18, further comprising outputting the path on a graphical user interface.
21. The method of claim 20, wherein: generating the path comprises ending the iteratively adjusting based on a trigger condition; and the trigger condition comprises receiving input from a human user at the graphical user interface accepting the path.
22. The method of claim 20, further comprising: re-generating the path based on the locations of the one or more landmarks and the one or more task locations based on a trigger condition; and the trigger condition comprises receiving input from a human user at the graphical user interface rejecting the path.
23. The method of claim 18, wherein the one or more landmarks are control points or control lines.
24. A method for operating a mobility platform in a construction site, comprising: identifying locations of the one or more landmarks in the construction site; moving the mobility platform along a navigational path based at least partly on the locations of the one or more landmarks; sensing the one or more landmarks with at least one selected from the group of a stereo camera, mono camera, and LiDAR unit when the mobility platform is moved along the path; and correcting the movement of the mobility platform based on information provided by the at least one selected from the group of a drive system encoder, stereo camera, mono camera, inertial measurement unit, optical flow sensor, and LiDAR unit.
25. The method of claim 24, wherein the one or more landmarks are sensed with each of a stereo camera, mono camera, and LiDAR unit.
26. The method of claim 25, wherein correcting the movement of the mobility platform includes using the information provided by the at least one sensor in feedback control.
27. The method of claim 26, further comprising integrating information from the drive system encoder, stereo camera, inertial measurement unit, and optical flow sensor to compute a first position of the mobility platform in the construction site.
28. The method of claim 27, further comprising detecting the one or more landmarks with the stereo camera, mono camera, or LiDAR unit to compute a second position of the mobility platform in the construction site.
29. The method of claim 28, further comprising comparing the first position to the second position to compute a position accuracy value.
30. The method of claim 29, further comprising moving the mobility platform to one of the one or more known landmarks when the position accuracy value falls below a predetermined threshold.
31. The method of claim 30, further comprising changing one or more parameters based on the position accuracy value for integrating information from the drive system encoder, stereo camera, mono camera, inertial measurement unit, and optical flow sensor to increase the position accuracy value above the predetermined threshold.
32. The method of claim 24, wherein the one or more landmarks are control points or control lines.
</claims>
</document>
