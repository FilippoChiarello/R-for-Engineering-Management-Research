<document>

<filing_date>
2020-08-12
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2018-06-11
</priority_date>

<ipc_classes>
G06K9/00,G06N3/04,G06T5/20
</ipc_classes>

<assignee>
TENCENT TECHNOLOGY (SHENZHEN) COMPANY
</assignee>

<inventors>
LI JILIN
CAO YUN
DING, SHOUHONG
WANG, CHENGJIE
LI, SHAOXIN
TAI, Ying
</inventors>

<docdb_family_id>
64211497
</docdb_family_id>

<title>
IMAGE PROCESSING METHOD AND APPARATUS, FACIAL RECOGNITION METHOD AND APPARATUS, AND COMPUTER DEVICE
</title>

<abstract>
This application relates to an image processing method and apparatus, a facial recognition method and apparatus, a computer device, and a readable storage medium. The image processing method includes: obtaining a target image comprising an object wearing glasses; inputting the target image to a glasses-removing model comprising a plurality of sequentially connected convolution squeeze and excitation networks; obtaining feature maps of feature channels of the target image through convolution layers of the convolution squeeze and excitation networks; obtaining global information of the feature channels according to the feature maps through squeeze and excitation layers of the convolution squeeze and excitation networks, learning the global information, and generating weights of the feature channels; weighting the feature maps of the feature channels according to the weights through weighting layers of the convolution squeeze and excitation networks, respectively, and generating weighted feature maps; and generating a glasses-removed image corresponding to the target image according to the weighted feature maps through the glasses-removing model. The glasses in the image can be effectively removed using the method.
</abstract>

<claims>
1. An image processing method, comprising: obtaining a target image comprising an object wearing glasses; inputting the target image to a glasses-removing model trained based on a generative adversarial network and comprising a plurality of sequentially connected convolution squeeze and excitation networks; obtaining feature maps of feature channels of the target image through convolution layers of the convolution squeeze and excitation networks; obtaining global information of the feature channels according to the feature maps through squeeze and excitation layers of the convolution squeeze and excitation networks, learning the global information, and generating weights of the feature channels; weighting the feature maps of the feature channels according to the weights through weighting layers of the convolution squeeze and excitation networks, respectively, and generating weighted feature maps; and generating a glasses-removed image corresponding to the target image according to the weighted feature maps through the glasses-removing model.
2. The method according to claim 1, wherein the glasses-removing model is trained by: obtaining a first training sample set formed by at least one first training image and a second training sample set formed by at least one second training image, an object in the at least one first training image wearing glasses, and an object in the at least one second training image wearing no glasses; performing an iteration comprising: inputting the first training sample set to a generative network model in the generative adversarial network to obtain a glasses-removed generative sample set; inputting the glasses-removed generative sample set and the second training sample set to a discriminative network model in the generative adversarial network, and obtaining a generative network loss coefficient according to an output of the discriminative network model; and updating a parameter of the generative network model according to the generative network loss coefficient to obtain an updated generative network model, and if the iteration satisfies an end condition, then using the updated generative network model as the glasses-removing model and ending the iteration, otherwise repeating the iteration.
3. The method according to claim 2, wherein inputting the glasses-removed generative sample set and the second training sample set to the discriminative network model in the generative adversarial network comprises: inputting the glasses-removed generative sample set and the second training sample set to the discriminative network model in the generative adversarial network, and obtaining a discriminative network loss coefficient according to the output of the discriminative network model; updating a parameter of the discriminative network model according to the discriminative network loss coefficient and obtaining an updated discriminative network model; and inputting the glasses-removed generative sample set to the updated discriminative network model and obtaining the generative network loss coefficient according to an output of the updated discriminative network model.
4. The method according to claim 3, wherein inputting the glasses-removed generative sample set and the second training sample set to the discriminative network model in the generative adversarial network, and obtaining a discriminative network loss coefficient according to the output of the discriminative network model comprises: inputting the generative sample set and the second training sample set to the discriminative network model and obtaining a first probability corresponding to the generative sample set and a second probability corresponding to the second training sample set; and obtaining the discriminative network loss coefficient according to the first probability, the second probability, and a discriminative network loss function.
5. The method according to claim 3, wherein inputting the glasses-removed generative sample set to the updated discriminative network model comprises: inputting the glasses-removed generative sample set to the updated discriminative network model and obtaining a third probability corresponding to the glasses-removed generative sample set; and obtaining the generative network loss coefficient according to the third probability and a generative network loss function.
6. The method according to claim 2, wherein: before updating the parameter of the generative network model, the method further comprises: inputting the glasses-removed generative sample set and the second training sample set to a feature network model and obtaining a feature error between the glasses-removed generative sample set and the second training sample set; and updating the parameter of the generative network model according to the generative network loss coefficient to obtain the updated generative network model comprises: updating the parameter of the generative network model according to the generative network loss coefficient and the feature error to obtain the updated generative network model.
7. The method according to claim 2, wherein: before updating the parameter of the generative network model, the method further comprises: analyzing a pixel of the glasses-removed generative sample set and pixels of the second training sample set and obtaining a pixel error between the glasses-removed generative sample set and the second training sample set; and updating the parameter of the generative network model according to the generative network loss coefficient to obtain the updated generative network model comprises: updating the parameter of the generative network model according to the generative network loss coefficient and the pixel error to obtain the updated generative network model.
8. The method according to claim 2, wherein the end condition comprises a number of the iteration reaching a preset iteration count threshold.
9. The method according to claim 1, wherein: obtaining the target image comprises: obtaining a face image, a face in the face image wearing glasses; and performing division according to a location of an eye portion in the face image to obtain an eye portion image, and obtaining the target image; and the method further comprises: fusing the face image and the glasses-removed image to obtain a glasses-removed face image.
10. A facial recognition method, comprising: obtaining a target image from a to-be-recognized face image, a face in the target image wearing glasses; inputting the target image to a glasses-removing model trained based on a generative adversarial network and comprising a plurality of sequentially connected convolution squeeze and excitation networks; obtaining feature maps of feature channels of the target image through convolution layers of the convolution squeeze and excitation networks; obtaining global information of the feature channels according to the feature maps through squeeze and excitation layers of the convolution squeeze and excitation networks, learning the global information, and generating weights of the feature channels; weighting the feature maps of the feature channels according to the weights through weighting layers of the convolution squeeze and excitation networks, respectively, and generating weighted feature maps; obtaining a glasses-removed face image corresponding to the target image according to the weighted feature maps through the glasses-removing model; and performing matching between the glasses-removed face image and a predetermined face image library to generate a matching result and generating a facial recognition result according to the matching result.
11. The method according to claim 10, wherein obtaining the target image from the to-be-recognized face image comprises: obtaining a to-be-recognized face image; performing glasses recognition and detection on the to-be-recognized face image; and obtaining the target image according to a result of the glasses recognition and detection.
12. The method according to claim 11, wherein: obtaining the target image according to the result of the glasses recognition and detection comprises: in response to detecting that a face in the to-be-recognized face image wears glasses, performing division according to a location of an eye portion in the to-be-recognized face image to obtain an eye portion image to obtain the target image; and obtaining the glasses-removed face image corresponding to the target image according to the weighted feature maps through the glasses-removing model comprises: generating the glasses-removed image corresponding to the target image according to the weighted feature graphs through the glasses-removing model; and fusing the to-be-recognized face image and the glasses-removed image and obtaining the glasses-removed face image.
13. The method according to claim 10, wherein a manner of training the glasses-removing model comprises: obtaining a first training sample set formed by at least one first training image and a second training sample set formed by at least one second training image, an object in the at least one first training image wearing glasses, and an object in the at least one second training image wearing no glasses; performing an iteration comprising: inputting the glasses-removed generative sample set and the second training sample set to a discriminative network model in the generative adversarial network, and obtaining a generative network loss coefficient according to an output of the discriminative network model; and updating a parameter of the generative network model according to the generative network loss coefficient to obtain an updated generative network model, if the iteration satisfies an end condition, then using the updated generative network model as the glasses-removing model and ending the iteration, otherwise repeating the iteration.
14. The method according to claim 13, wherein inputting the glasses-removed generative sample set and the second training sample set to the discriminative network model in the generative adversarial network comprises: inputting the glasses-removed generative sample set and the second training sample set to the discriminative network model in the generative adversarial network, respectively, and obtaining a discriminative network loss coefficient according to the output of the discriminative network model; updating a parameter of the discriminative network model according to the discriminative network loss coefficient and obtaining an updated discriminative network model; and inputting the glasses-removed generative sample set to the updated discriminative network model and obtaining the generative network loss coefficient according to an output of the updated discriminative network model.
15. The method according to claim 14, wherein inputting the glasses-removed generative sample set and the second training sample set to the discriminative network model in the generative adversarial network, and obtaining a discriminative network loss coefficient according to the output of the discriminative network model comprises: inputting the glasses-removed generative sample set and the second training sample set to the discriminative network model and obtaining a first probability corresponding to the glasses-removed generative sample set and a second probability corresponding to the second training sample set; and obtaining the discriminative network loss coefficient according to the first probability, the second probability, and a discriminative network loss function.
16. The method according to claim 14, wherein inputting the glasses-removed generative sample set to the updated discriminative network model comprises: inputting the glasses-removed generative sample set to the updated discriminative network model and obtaining a third probability corresponding to the glasses-removed generative sample set; and obtaining the generative network loss coefficient according to the third probability and a generative network loss function.
17. The method according to claim 13, wherein: before updating the parameter of the generative network model, the method further comprises: inputting the glasses-removed generative sample set and the second training sample set to a feature network model and obtaining a feature error between the glasses-removed generative sample set and the second training sample set; and updating the parameter of the generative network model according to the generative network loss coefficient to obtain the updated generative network model comprises: updating the parameter of the generative network model according to the generative network loss coefficient and the feature error to obtain the updated generative network model.
18. The method according to claim 13, wherein: before the updating the parameter of the generative network model, the method further comprises: analyzing a pixel of the glasses-removed generative sample set and a pixel of the second training sample set and obtaining a pixel error between the glasses-removed generative sample set and the second training sample set; and updating the parameter of the generative network model according to the generative network loss coefficient to obtain the updated generative network model comprises: updating the parameter of the generative network model according to the generative network loss coefficient and the pixel error to obtain the updated generative network model.
19. The method according to claim 13, wherein the end condition comprises a number of the iteration.
20. An apparatus for image processing, comprising a memory for storing computer readable instructions and a processor in communication with the memory, wherein the processor is configured to execute the computer readable instructions to cause the apparatus to: obtain a target image comprising an object wearing glasses; input the target image to a glasses-removing model trained based on a generative adversarial network and comprising a plurality of sequentially connected convolution squeeze and excitation networks; obtain feature maps of feature channels of the target image through convolution layers of the convolution squeeze and excitation networks; obtain global information of the feature channels according to the feature maps through squeeze and excitation layers of the convolution squeeze and excitation networks, learn the global information, and generate weights of the feature channels; weight the feature maps of the feature channels according to the weights through weighting layers of the convolution squeeze and excitation networks, respectively, and generate weighted feature maps; and generate a glasses-removed image corresponding to the target image according to the weighted feature maps through the glasses-removing model.
</claims>
</document>
