<document>

<filing_date>
2020-03-06
</filing_date>

<publication_date>
2020-09-10
</publication_date>

<priority_date>
2019-03-06
</priority_date>

<ipc_classes>
A61B8/00,A61B8/08
</ipc_classes>

<assignee>
PIUR IMAGING
</assignee>

<inventors>
BAUER, ROBERT
BENDER, FREDERIK
</inventors>

<docdb_family_id>
65717911
</docdb_family_id>

<title>
APPARATUS AND METHOD FOR DETERMINING MOTION OF AN ULTRASOUND PROBE INCLUDING A FORWARD-BACKWARD DIRECTEDNESS
</title>

<abstract>
A method and an apparatus for determining a three-dimensional directedness-determined motion are provided, including a forward-backward directedness, characterizing the motion of a movable ultrasound probe (10) during acquisition of an ultrasound image of a volume portion (2) by the ultrasound probe. The method comprises determining, by a machine-learning module (50), a motion indicator (60) indicating a three-dimensional motion between the ultrasound image frames (22); and determining, by a directedness-determining system (56), a directedness indicator (66) of the three-dimensional motion between the ultrasound image frames (22). The method further comprises determining a directedness-determined motion indicator (96) indicating the three-dimensional directedness-determined motion, including a determined the forward-backward directedness of the motion, between the ultrasound image frames (22) from the motion indicator (60) and the directedness indicator (66).
</abstract>

<claims>
1. Method of determining a three-dimensional directedness-determined motion, including a forward-backward directedness, characterizing the motion of a movable ultrasound probe
(10) during acquisition of an ultrasound image of a volume portion (2) by the ultrasound probe, the method comprising:
- Receiving a stream of ultrasound image data (20) from the ultrasound probe (10) while the ultrasound probe is moved along the volume portion (2);
- Inputting at least a subset of the ultrasound image data (20, 40) representing a plurality of ultrasound image frames (22) into a machine-learning module (50), wherein the machine learning module (50) has been trained to determine a three-dimensional motion between ultrasound image frames;
- Determining, by the machine-learning module (50), a motion indicator (60) indicating a three-dimensional motion between the ultrasound image frames (22);
- Receiving directedness-indicative data (26) being indicative of the forward-backward directedness of the motion;
- Inputting at least a sub-set of the directedness-indicative data (26, 46) into a directedness-determining system (56); and
- Determining, by the directedness-determining system (56), a directedness indicator (66) of the three-dimensional motion between the ultrasound image frames (22); and
- Determining a directedness-determined motion indicator (96) indicating the threedimensional directedness-determined motion, including a determined forwardbackward directedness of the motion, between the ultrasound image frames (22) from the motion indicator (60) and the directedness indicator (66).
2. Method according to claim 1, wherein the directedness-indicative data (26) is received as a stream of data, at least partially synchronized with the stream of ultrasound image data (20).
3. Method according to any one of the preceding claims, wherein the directedness indicator (66) is a binary variable with a first and a second value, wherein the first value indicates a forward directedness of the motion and the second value indicates a backward directedness of the motion.
4. Method according to any one of the preceding claims, wherein the steps of receiving a stream of ultrasound image data, inputting at least a sub-set of the ultrasound image data and determining a motion indicator defines a first submethod and the steps of receiving directedness-indicative data, inputting at least a sub-set of the directednessindicative data and determining a directedness indicator defines a second submethod; and wherein the first submethod and the second submethod run parallel to each other and substantially decoupled from each other.
5. Method according to any one of the preceding claims, wherein the motion indicator (60), the directedness indicator (66) and the directedness-determined motion indicator (96) are repetitiously determined for consecutive pairs of ultrasound images, respectively, while the ultrasound probe is moved along the volume portion (2).
6. Method according to any one of the preceding claims, wherein the directednessindicative data is received by the ultrasound probe (10), and wherein the step of inputting at least a sub-set of the directedness-indicative data (26, 46) into a directedness-determining system (56) comprises inputting the sub-set of the ultrasound image data (20, 40 (26) into a second machine-learning module (58), wherein the second machine learning module (58) has been trained to determine a forwardbackward directedness of a motion.
7. Method according to any one of the preceding claims, wherein the subset of the directedness-indicative data comprises a global sequence of the ultrasound image data having a number of ultrasound image frames permitting the identification of characteristic features, particularly anatomical features, of the volume portion.
8. Method according to any one of the preceding claims, wherein the ultrasound probe (10) includes a multi-row ultrasound array and wherein the directedness-indicative data (26) is received from raw ultrasound data received from individual rows of the array.
9. Method according to any one of the preceding claims, wherein the directednessindicative data is received from an external sensor while the ultrasound probe is moved along the volume portion (2); wherein the external sensor detects position, velocity, acceleration and/or displacement of the ultrasound probe (10), in particular, between the ultrasound image frames.
10. Method according to any one of the preceding claims, wherein the directednessindicative data is received from an external tracking system tracking a position of the ultrasound probe.
11. Method according to any one of the preceding claims, wherein the external tracking system is an optical tracking system, particularly an optical camera, used in combination with a marker set, particularly, wherein the optical tracking system is stationary and tracks a marker set fixed to the ultrasound probe (10) or wherein the optical tracking system is attached to the ultrasound probe (10) and tracks marker sets in an environment.
12. Method according to any one of the preceding claims, wherein the directednessindicative data is received from at least one of the following:
- an external sensor attached to the ultrasound probe (10), wherein the external sensor is adapted to detect a motion, in particular a oneor two-dimensional motion, relative to an underlying surface delimiting the volume portion;
- an optoelectronic sensor used in combination with a light emitter, wherein the optoelectronic sensor receives pattern images (94) from an underlying surface delimiting the volume portion;
- an external sensor detecting the angular motion of a rotating element, particularly a sphere or wheel; wherein the rotating element is driven in rotation due to the motion of the ultrasound probe (10) on an underlying surface delimiting the volume portion.
13. Method according to any one of the preceding claims, wherein the directednessindicative data is acceleration data received by an accelerometer, wherein the acceleration data represents the acceleration corresponding to the at least two ultrasound image frames, and wherein the step of determining the directedness indicator (66) comprises integration of the acceleration data.
14. Method according to any one of the preceding claims, further comprising inputting further sensor data (24, 44) into the machine-learning module (50), wherein the further sensor data (24, 44) is synchronized with the ultrasound image data (20, 40) and, wherein the machine learning module (50) comprises a convolutional neural network, and wherein the sensor data (24, 44) is inputted after a plurality of convolutional and max pooling layers, and before final output layers and/or final fully connected layers.
15. Apparatus for determining a three-dimensional motion, including a forward -backward directedness of the motion, of a movable ultrasound probe (10) during acquisition of an ultrasound image of a volume portion by the ultrasound probe, the apparatus comprising:
- a probe input interface for receiving a stream of ultrasound image data (20) from the ultrasound probe (10) while the ultrasound probe is moved along the volume portion;
- a tracing system (16) configured to receive directedness-indicative data (26) being indicative of the forward-backward directedness of the motion;
- a machine-learning module (50) having
(a) an input section adapted for receiving, as an input, at least a sub-set of the ultrasound image data (20, 40) representing a plurality of ultrasound image frames
(22),
(b) a training memory section containing a training memory having been trained to determine the relative three-dimensional motion between ultrasound image frames, wherein the machine-learning module (50) is adapted for determining, from the input and using the training memory, a three-dimensional motion indicator indicating the relative three-dimensional motion between the ultrasound image frames;
- a directedness-determining system (56) configured to determine a directedness indicator (66) of the three-dimensional motion between the ultrasound image frames (22) by using at least a sub-set of the directedness-indicative data (26);
- a motion-determining system (56) configured to determine a directedness-determined motion indicator (96) indicating the three-dimensional motion between the ultrasound image frames (22) by using the motion indicator (60) and the directedness indicator (66) of the three-dimensional motion between the ultrasound image frames (22).
</claims>
</document>
