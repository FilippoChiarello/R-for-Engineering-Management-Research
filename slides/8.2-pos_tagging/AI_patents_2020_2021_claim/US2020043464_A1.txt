<document>

<filing_date>
2019-10-10
</filing_date>

<publication_date>
2020-02-06
</publication_date>

<priority_date>
2019-09-16
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08,G10L13/047
</ipc_classes>

<assignee>
LG ELECTRONICS
</assignee>

<inventors>
CHAE, JONGHOON
</inventors>

<docdb_family_id>
68422342
</docdb_family_id>

<title>
SPEECH SYNTHESIZER USING ARTIFICIAL INTELLIGENCE AND METHOD OF OPERATING THE SAME
</title>

<abstract>
Disclosed herein is a speech synthesizer using artificial intelligence including a memory, a communication processor configured to receive utterance information of words uttered by a user from a terminal, and a processor configured to acquire a plurality of utterance intonation phrase (IP) ratios respectively corresponding to a plurality of words uttered by the user based on the utterance information, compare a plurality of IP ratio tables respectively corresponding to a plurality of voice actors with the plurality of utterance IP ratios, acquire a plurality of non-utterance IP ratios respectively corresponding to a plurality of unuttered words based on a result of comparison, and generate a personalized synthesized speech model based on the plurality of utterance IP ratios and the plurality of non-utterance IP ratios.
</abstract>

<claims>
1. A speech synthesizer using artificial intelligence, comprising: a memory; a communication processor configured to receive utterance information of words uttered by a user from a terminal; and a processor configured to acquire a plurality of utterance intonation phrase (IP) ratios respectively corresponding to a plurality of words uttered by the user based on the utterance information, compare a plurality of IP ratio tables respectively corresponding to a plurality of voice actors with the plurality of utterance IP ratios, acquire a plurality of non-utterance IP ratios respectively corresponding to a plurality of unuttered words based on a result of comparison, and generate a personalized synthesized speech model based on the plurality of utterance IP ratios and the plurality of non-utterance IP ratios, wherein a plurality of classes indicating reading break of a word includes a first class corresponding to first reading break, a second class corresponding to second reading break greater than the first reading break and a third class corresponding to third reading break greater than the second reading break, wherein a minor class has a smallest count among the first to third classes, and wherein each of the utterance IP ratios and the non-utterance IP ratios is a ratio in which a word is classified as the minor class.
2. The speech synthesizer according to claim 1, wherein the utterance information includes reading break of each uttered word, a part of speech of each uttered word, and a position of each uttered word in a sentence.
3. The speech synthesizer according to claim 2, wherein the processor acquires the utterance IP ratio of each uttered word, using the number of times that the user reads each uttered word with break corresponding to the minor class.
4. The speech synthesizer according to claim 3, wherein the processor: sums up differences between IP ratios of the uttered words respectively included in the plurality of IP ratio tables and the plurality of utterance IP ratios, and determines, as a closest IP ratio table, an IP ratio table having a smallest summed result value among the plurality of IP ratio tables.
5. The speech synthesizer according to claim 4, wherein the processor acquires each of the plurality of non-utterance IP ratios as an IP ratio of each unuttered word included in the closest IP ratio table.
6. The speech synthesizer according to claim 1, wherein the personalized synthesized speech model is a model for outputting a synthesized speech, to which reading break of words uttered by the user is applied, and is an artificial neural network based model trained by a deep learning algorithm or a machine learning algorithm.
7. The speech synthesizer according to claim 6, wherein the personalized synthesized speech model is a model for inferring a probability that each word is classified as the minor class, using, as training data, text data corresponding to a plurality of words, an IP ratio of each word, and a probability of being classified as the minor class labeled in each word.
8. The speech synthesizer according to claim 7, wherein the processor transmits the personalized synthesized speech model to the terminal through the communication processor.
9. A method of operating a speech synthesizer using artificial intelligence, the method comprising: receiving utterance information of words uttered by a user from a terminal; acquiring a plurality of utterance intonation phrase (IP) ratios respectively corresponding to a plurality of words uttered by the user based on the utterance information; comparing a plurality of IP ratio tables respectively corresponding to a plurality of voice actors with the plurality of utterance IP ratios; acquiring a plurality of non-utterance IP ratios respectively corresponding to a plurality of unuttered words based on a result of comparison; and generating a personalized synthesized speech model based on the plurality of utterance IP ratios and the plurality of non-utterance IP ratios, wherein a plurality of classes indicating reading break of a word includes a first class corresponding to first reading break, a second class corresponding to second reading break greater than the first reading break and a third class corresponding to third reading break greater than the second reading break, wherein a minor class has a smallest count among the first to third classes, and wherein each of the utterance IP ratios and the non-utterance IP ratios is a ratio in which a word is classified as the minor class.
10. The method according to claim 9, wherein the utterance information includes reading break of each uttered word, a part of speech of each uttered word, and a position of each uttered word in a sentence.
11. The method according to claim 10, wherein the acquiring of the plurality of utterance IP ratios includes acquiring the utterance IP ratio of each uttered word, using the number of times that the user reads each uttered word with break corresponding to the minor class.
12. The method according to claim 11, further comprising: summing up differences between IP ratios of the uttered words respectively included in the plurality of IP ratio tables and the plurality of utterance IP ratios, and determining, as a closest IP ratio table, an IP ratio table having a smallest summed result value among the plurality of IP ratio tables.
13. The method according to claim 12, wherein the acquiring the plurality of non-utterance IP ratios includes acquiring each of the plurality of non-utterance IP ratios as an IP ratio of each unuttered word included in the closest IP ratio table.
14. The method according to claim 9, wherein the personalized synthesized speech model is a model for outputting a synthesized speech, to which reading break of words uttered by the user is applied, and is an artificial neural network based model trained by a deep learning algorithm or a machine learning algorithm.
15. The method according to claim 14, wherein the personalized synthesized speech model is a model for inferring a probability that each word is classified as the minor class, using, as training data, text data corresponding to a plurality of words, an IP ratio of each word, and a probability of being classified as the minor class labeled in each word.
16. The method according to claim 14, wherein the processor transmits the personalized synthesized speech model to the terminal through the communication processor.
</claims>
</document>
