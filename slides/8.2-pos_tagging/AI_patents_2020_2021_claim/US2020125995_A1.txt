<document>

<filing_date>
2018-10-19
</filing_date>

<publication_date>
2020-04-23
</publication_date>

<priority_date>
2018-10-19
</priority_date>

<ipc_classes>
G06N99/00
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
WANG, YU YING YY
JIA, ZHI YONG
HE, RONG FU
WU, JING
</inventors>

<docdb_family_id>
70281213
</docdb_family_id>

<title>
MACHINE LEARNING WITH SEGMENT-ALIGNED MULTISENSOR TRACE DATA
</title>

<abstract>
A machine-learning system receives from multiple sensors a set of trace-data time series. Each time series contains a chronological sequence of sensor measurements of one attribute of one instance of a manufacturing product or process. The system partitions each series into a set of contiguous segments and selects one received series to be a standard series for each attribute. The starting and ending measurements of each non-standard time series are then time-aligned to the starting and ending points of the non-standard series' corresponding standard series, using a dynamic time-warping procedure. One or more segments of each aligned non-standard series are then aligned to each segment of the corresponding standard series. The resulting time-aligned, segmented time series are then incorporated into a corpus that is used by a machine-learning module to train a self-learning application.
</abstract>

<claims>
1. A machine-learning system comprising a processor, a memory coupled to the processor, and a computer-readable hardware storage device coupled to the processor, the storage device containing program code configured to be run by the processor via the memory to implement a method for machine learning with segment-aligned multisensor trace data, the method comprising: the machine-learning system receiving, from a set of sensors, a set of time series that each comprises a chronological sequence of measurements of an attribute, of a set of attributes, of an instance, of a set of instances of measured entities; the machine-learning system selecting for each received time series a corresponding initial segmentation method of a set of segmentation methods, where a first selected initial segmentation method partitions measurements comprised by a corresponding first time series of the received time series into a first sequence of contiguous segments, and where the first selected initial segmentation method determines a number of segments in the first sequence and the number of measurements comprised by each segment of the first sequence; the machine-learning system designating one series of the received time series to be a first standard series for a first attribute of the set of attributes, where the first standard series comprises measurements of the first attribute; the machine-learning system aligning, to the first standard series, target series of the set of received time series, where each target series comprises measurements of the first attribute; and the machine-learning system segment-aligning one or more segments of each target series to each segment of the first standard series.
2. The system of claim 1, further comprising: the machine-learning system directing a machine-learning training component to incorporate each segment-aligned series into a corpus configured to train a self-learning application.
3. The system of claim 1, where the machine-learning system uses a method of Lavielle to select each initial segmentation method.
4. The system of claim 1, where the machine-learning system uses a method of dynamic time warping (DTW) to align each target series to the first standard series.
5. The system of claim 1, where the aligning a first target series to the first standard series further comprises: time-aligning a chronologically earliest measurement of the first target series to a chronologically earliest measurement of the first standard series, and time-aligning a chronologically last measurement of the first target series to a chronologically last measurement of the first standard series.
6. The system of claim 4, where the machine-learning system determines that a first target segment of a first target series should be segment-aligned to a first standard segment of the first standard series by determining that a number of measurement points of the first target segment that have been aligned by the DTW procedure to a measurement point of the first standard segment is at least as large as a number of measurement points of any other segment of the first target series that have been aligned by the DTW procedure to a measurement point of the first standard segment.
7. The system of claim 1, where the designating the one series to be a first standard series for a first attribute further comprises: the processor selecting a subset of the received time series, where each time series of the subset comprises a chronological sequence of measurements of the first attribute; the processor tabulating a number of segments into which each time series of the subset is divided by a corresponding initial segmentation method selected for that time series; the processor identifying a mode of the first attribute, where the mode of the first attribute is a number of segments most often identified by the tabulated numbers of segments; the processor associating each instance of the set of instances with a corresponding group of time series, where each series of a group corresponding to a first instance of the set of instances: i) comprises measurements of an attribute, of the set of attributes, of the first instance, and ii) is segmented by a corresponding initial segmentation method into the number of segments identified by the mode of the first attribute; the processor identifying a standard instance of the first attribute to be an instance, of the set of instances, that is associated with a corresponding group that comprises a largest number of time series; and the processor choosing the first standard series to be a time series of the received time series that comprises measurements of the first attribute of the standard instance.
8. The system of claim 1, where each measured entity is selected from the group consisting of: a physical object and a manufacturing process
9. A method for machine learning with segment-aligned multisensor trace data, the method comprising: a machine-learning system receiving, from a set of sensors, a set of time series from a set of sensors that each comprises a chronological sequence of measurements of an attribute, of a set of attributes, of an instance, of a set of instances of measured entities; the machine-learning system selecting for each received time series a corresponding initial segmentation method of a set of segmentation methods, where a first selected initial segmentation method partitions measurements comprised by a corresponding first time series of the received time series into a first sequence of contiguous segments, and where the first selected initial segmentation method determines a number of segments in the first sequence and the number of measurements comprised by each segment of the first sequence; the machine-learning system designating one series of the received time series to be a first standard series for a first attribute of the set of attributes, where the first standard series comprises measurements of the first attribute; the machine-learning system aligning, to the first standard series, target series of the set of received time series, where each target series comprises measurements of the first attribute; the machine-learning system segment-aligning one or more segments of each target series to each segment of the first standard series; and the machine-learning system directing a machine-learning training component to incorporate each segment-aligned series into a corpus configured to train a self-learning application.
10. The method of claim 9, where the machine-learning system uses a method of Lavielle to select each initial segmentation method.
11. The method of claim 9, where the aligning a first target series to the first standard series further comprises: the machine-learning system using a method of dynamic time warping (DTW) to time-align a chronologically earliest measurement of the first target series to a chronologically earliest measurement of the first standard series, and the machine-learning system using a method of dynamic time warping (DTW) to time-align a chronologically last measurement of the first target series to a chronologically last measurement of the first standard series.
12. The method of claim 11, where the machine-learning system determines that a first target segment of a first target series should be segment-aligned to a first standard segment of the first standard series by determining that a number of measurement points of the first target segment that have been aligned by the DTW procedure to a measurement point of the first standard segment is at least as large as a number of measurement points of any other segment of the first target series that have been aligned by the DTW procedure to a measurement point of the first standard segment.
13. The method of claim 9, where the designating the one series to be a first standard series for a first attribute further comprises: the processor selecting a subset of the received time series, where each time series of the subset comprises a chronological sequence of measurements of the first attribute; the processor tabulating a number of segments into which each time series of the subset is divided by a corresponding initial segmentation method selected for that time series; the processor identifying a mode of the first attribute, where the mode of the first attribute is a number of segments most often identified by the tabulated numbers of segments; the processor associating each instance of the set of instances with a corresponding group of time series, where each series of a group corresponding to a first instance of the set of instances: i) comprises measurements of an attribute, of the set of attributes, of the first instance, and ii) is segmented by a corresponding initial segmentation method into the number of segments identified by the mode of the first attribute, the processor identifying a standard instance of the first attribute to be an instance, of the set of instances, that is associated with a corresponding group that comprises a largest number of time series; and the processor choosing the first standard series to be a time series of the received time series that comprises measurements of the first attribute of the standard instance.
14. The method of claim 9, further comprising providing at least one support service for at least one of creating, integrating, hosting, maintaining, and deploying computer-readable program code in the computer system, wherein the computer-readable program code in combination with the computer system is configured to implement the receiving, the selecting, the designating, the aligning, the segment-aligning, and the directing.
15. A computer program product, comprising a computer-readable hardware storage device having a computer-readable program code stored therein, the program code configured to be executed by a machine-learning system comprising a processor, a memory coupled to the processor, and a computer-readable hardware storage device coupled to the processor, the storage device containing program code configured to be run by the processor via the memory to implement a method for machine learning with segment-aligned multisensor trace data, the method comprising: the machine-learning system receiving, from a set of sensors, a set of time series from a set of sensors that each comprises a chronological sequence of measurements of an attribute, of a set of attributes, of an instance, of a set of instances of measured entities; the machine-learning system selecting for each received time series a corresponding initial segmentation method of a set of segmentation methods, where a first selected initial segmentation method partitions measurements comprised by a corresponding first time series of the received time series into a first sequence of contiguous segments, and where the first selected initial segmentation method determines a number of segments in the first sequence and the number of measurements comprised by each segment of the first sequence; the machine-learning system designating one series of the received time series to be a first standard series for a first attribute of the set of attributes, where the first standard series comprises measurements of the first attribute; the machine-learning system aligning, to the first standard series, target series of the set of received time series, where each target series comprises measurements of the first attribute; and the machine-learning system segment-aligning one or more segments of each target series to each segment of the first standard series.
16. The computer program product of claim 15, further comprising: the machine-learning system directing a machine-learning training component to incorporate each segment-aligned series into a corpus configured to train a self-learning application.
17. The computer program product of claim 15, where the machine-learning system uses a method of Lavielle to select each initial segmentation method.
18. The computer program product of claim 15, where the aligning a first target series to the first standard series further comprises: the machine-learning system using a method of dynamic time warping (DTW) to time-align a chronologically earliest measurement of the first target series to a chronologically earliest measurement of the first standard series, and the machine-learning system using a method of dynamic time warping (DTW) to time-align a chronologically last measurement of the first target series to a chronologically last measurement of the first standard series.
19. The computer program product of claim 18, where the machine-learning system determines that a first target segment of a first target series should be segment-aligned to a first standard segment of the first standard series by determining that a number of measurement points of the first target segment that have been aligned by the DTW procedure to a measurement point of the first standard segment is at least as large as a number of measurement points of any other segment of the first target series that have been aligned by the DTW procedure to a measurement point of the first standard segment.
20. The computer program product of claim 15, where the designating the one series to be a first standard series for a first attribute further comprises: the processor selecting a subset of the received time series, where each time series of the subset comprises a chronological sequence of measurements of the first attribute; the processor tabulating a number of segments into which each time series of the subset is divided by a corresponding initial segmentation method selected for that time series; the processor identifying a mode of the first attribute, where the mode of the first attribute is a number of segments most often identified by the tabulated numbers of segments; the processor associating each instance of the set of instances with a corresponding group of time series, where each series of a group corresponding to a first instance of the set of instances: i) comprises measurements of an attribute, of the set of attributes, of the first instance, and ii) is segmented by a corresponding initial segmentation method into the number of segments identified by the mode of the first attribute; the processor identifying a standard instance of the first attribute to be an instance, of the set of instances, that is associated with a corresponding group that comprises a largest number of time series; and the processor choosing the first standard series to be a time series of the received time series that comprises measurements of the first attribute of the standard instance.
</claims>
</document>
