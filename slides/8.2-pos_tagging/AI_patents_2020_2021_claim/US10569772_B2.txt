<document>

<filing_date>
2018-04-06
</filing_date>

<publication_date>
2020-02-25
</publication_date>

<priority_date>
2017-04-12
</priority_date>

<ipc_classes>
B60W30/095,G05D1/00,G06K9/00
</ipc_classes>

<assignee>
HRL LABORATORIES
</assignee>

<inventors>
BHATTACHARYYA, RAJAN
LEBIERE, CHRISTIAN
VINOKUROV, JERRY
KIM, HYUN (TIFFANY) J.
</inventors>

<docdb_family_id>
63791544
</docdb_family_id>

<title>
Cognitive behavior prediction system for autonomous systems
</title>

<abstract>
Described is a system for predicting the behavior of an autonomous system. The system identifies a taxonomic state of a motion condition of an autonomous vehicle based on a spatiotemporal location of the autonomous vehicle and elements of a driving scenario. Behavior of the autonomous vehicle is predicted based on the taxonomic state of the motion condition. The autonomous vehicle makes and implements a driving operation decision based on the predicted behavior.
</abstract>

<claims>
1. A system for predicting autonomous vehicle behavior, the system comprising: one or more processors and a non-transitory computer-readable medium having executable instructions encoded thereon such that when executed, the one or more processors perform operations of: using a cognitive architecture, identifying a taxonomic state of a motion condition of an autonomous vehicle based on a spatiotemporal location of the autonomous vehicle and a plurality of elements of a driving scenario; predicting behavior of the autonomous vehicle based on the taxonomic state of the motion condition; making a driving operation decision based on the predicted behavior; and using the autonomous vehicle, implementing the driving operation decision.
2. The system as set forth in claim 1, wherein the plurality of elements of the driving scenario comprises at least one of a vehicle, a traffic sign, a traffic signal, and a pedestrian.
3. The system as set forth in claim 1, wherein the autonomous vehicle uses a generated behavior trace to make the driving operation decision.
4. The system as set forth in claim 1, wherein the taxonomic state of the autonomous vehicle is identified using an Adaptive Control of Thought-Rational (ACT-R) cognitive architecture.
5. The system as set forth in claim 4, wherein the ACT-R cognitive architecture is trained on driving data for which taxonomic states are known.
6. The system as set forth in claim 4, wherein the ACT-R cognitive architecture comprises a driving operation intention for the autonomous vehicle, a plurality of rule sets each corresponding to the driving operation intention, and taxonomic states of the plurality of elements of the driving scenario.
7. The system as set forth in claim 6, wherein the plurality of rule sets specifies a set of actions, wherein the set of actions is at least one of generating a trace message, scheduling the driving operation decision, and changing the taxonomic state of the motion condition.
8. The system as set forth in claim 6, wherein the one or more processors further perform operations of: testing the taxonomic state of the motion condition; selecting a rule set that matches the driving scenario, wherein the rule set is selected using a combination of symbolic matching and statistical optimization; and triggering the driving operation decision.
9. The system as set forth in claim 1, wherein behavior of the autonomous vehicle is predicted using positional information of the autonomous vehicle and the plurality of elements of the driving scenario, and at least one of a velocity, a relative distance, and an angular location of the autonomous vehicle relative to the plurality of elements.
10. The system as set forth in claim 1, wherein the implemented driving operation is a turn.
11. The system as set forth in claim 1, wherein the one or more processors further perform an operation of utilizing blended recall to retrieve a matching taxonomic state.
12. A computer implemented method for predicting autonomous vehicle behavior, the method comprising an act of: causing one or more processers to execute instructions encoded on a non-transitory computer-readable medium, such that upon execution, the one or more processors perform operations of: using a cognitive architecture, identifying a taxonomic state of a motion condition of an autonomous vehicle based on a spatiotemporal location of the autonomous vehicle and a plurality of elements of a driving scenario; predicting behavior of the autonomous vehicle based on the taxonomic state of the motion condition; making a driving operation decision based on the predicted behavior; and using the autonomous vehicle, implementing the driving operation decision.
13. The method as set forth in claim 12, wherein the plurality of elements of the driving scenario comprises at least one of a vehicle, a traffic sign, a traffic signal, and a pedestrian.
14. The method as set forth in claim 12, wherein the autonomous vehicle uses a generated behavior trace to make the driving operation decision.
15. The method as set forth in claim 12, wherein the taxonomic state of the autonomous vehicle is identified using an Adaptive Control of Thought-Rational (ACT-R) cognitive architecture.
16. The method as set forth in claim 15, wherein the ACT-R cognitive architecture comprises a driving operation intention for the autonomous vehicle, a plurality of rule sets each corresponding to the driving operation intention, and taxonomic states of the plurality of elements of the driving scenario.
17. The method as set forth in claim 12, wherein behavior of the autonomous vehicle is predicted using positional information of the autonomous vehicle and the plurality of elements of the driving scenario, and at least one of a velocity, a relative distance, and an angular location of the autonomous vehicle relative to the plurality of elements.
18. A computer program product for predicting autonomous vehicle behavior, the computer program product comprising: computer-readable instructions stored on a non-transitory computer-readable medium that are executable by a computer having one or more processors for causing the processor to perform operations of: using a cognitive architecture, identifying a taxonomic state of a motion condition of an autonomous vehicle based on a spatiotemporal location of the autonomous vehicle and a plurality of elements of a driving scenario; predicting behavior of the autonomous vehicle based on the taxonomic state of the motion condition; making a driving operation decision based on the predicted behavior; and using the autonomous vehicle, implementing the driving operation decision.
19. The computer program product as set forth in claim 18, wherein the plurality of elements of the driving scenario comprises at least one of a vehicle, a traffic sign, a traffic signal, and a pedestrian.
20. The computer program product as set forth in claim 18, wherein the autonomous vehicle uses a generated behavior trace to make the driving operation decision.
21. The computer program product as set forth in claim 18, wherein the taxonomic state of the autonomous vehicle is identified using an Adaptive Control of Thought-Rational (ACT-R) cognitive architecture.
22. The computer program product as set forth in claim 21, wherein the ACT-R cognitive architecture comprises a driving operation intention for the autonomous vehicle, a plurality of rule sets each corresponding to the driving operation intention, and taxonomic states of the plurality of elements of the driving scenario.
23. The computer program product as set forth in claim 18, wherein behavior of the autonomous vehicle is predicted using positional information of the autonomous vehicle and the plurality of elements of the driving scenario, and at least one of a velocity, a relative distance, and an angular location of the autonomous vehicle relative to the plurality of elements.
</claims>
</document>
