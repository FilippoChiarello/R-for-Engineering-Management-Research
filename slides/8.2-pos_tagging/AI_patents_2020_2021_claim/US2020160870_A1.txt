<document>

<filing_date>
2018-11-15
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2018-11-15
</priority_date>

<ipc_classes>
G06N20/00,G10L15/18,G10L15/26,G10L15/30,G10L17/00,G10L17/04,G10L17/22,G10L17/26,H04L12/58,H04M3/22,H04M3/493
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
MARZORATI, MAURO
BAUGHMAN, AARON, K.
RAKSHIT, SARBAJIT K.
DIAMANTI, GARY FRANCIS
</inventors>

<docdb_family_id>
70726711
</docdb_family_id>

<title>
DISTRIBUTED MACHINE-LEARNED EMPHATIC COMMUNICATION FOR MACHINE-TO-HUMAN AND MACHINE-TO-MACHINE INTERACTIONS
</title>

<abstract>
A system determines if a call participant of a call between the call participant and a voice response system is a human or a machine. Responsive to determining that the call participant is a human, an emotional state of the call participant is determined. Environmental information of an environment associated with the call participant is receiving. A receptiveness level of the call participant is determined based upon the emotional state and the environmental information. A message to the call participant is determined based upon the receptiveness level and one or more machine-learning models.
</abstract>

<claims>
1. A computer-implemented method, comprising: determining if a call participant of a call between the call participant and a voice response system is a human or a machine; responsive to determining that the call participant is a human, determining an emotional state of the call participant; receiving environmental information of an environment associated with the call participant; determining a receptiveness level of the call participant based upon the emotional state and the environmental information; and determining a message to the call participant based upon the receptiveness level and one or more machine-learning models.
2. The computer-implemented method of claim 1, further comprising: receiving metadata associated with the call participant, wherein determining the receptiveness level is further based upon the metadata.
3. The computer-implemented method of claim 2, wherein the metadata includes one or more of a location associated with the call participant or a time of day associated with the call.
4. The computer-implemented method of claim 1, further comprising: providing the message to the call participant.
5. The computer-implemented method of claim 4, further comprising: receiving a response to the message from the call participant.
6. The computer-implemented method of claim 5, further comprising: updating the one or more machine-learning models based upon the response.
7. The computer-implemented method of claim 1, wherein the emotional state of the call participant includes one or more of a mood, an emotion, a social propensity or a language style of the call participant.
8. The computer-implemented method of claim 1, wherein the environmental information is received from one or more sensor devices located in the environment of the call participant.
9. The computer-implemented method of claim 8, wherein the one or more sensor devices includes one or more of a wearable device associated with the call participant, an audio sensing device, or a visual sensing device.
10. The computer-implemented method of claim 1, further comprising: responsive to determining that the call participant is a machine, determining a physical state of the call participant.
11. The computer-implemented method of claim 1, wherein the message is configured to likely increase the receptiveness level of the call participant.
12. The computer-implemented method of claim 11, wherein configuring the message includes one or more of modifying a word or phrase of an original message, modifying a volume level of the message, or modifying a tone of the message.
13. A computer usable program product comprising one or more computer-readable storage devices, and program instructions stored on at least one of the one or more storage devices, the stored program instructions comprising: program instructions to determine if a call participant of a call between the call participant and a voice response system is a human or a machine; program instructions to, responsive to determining that the call participant is a human, determine an emotional state of the call participant; program instructions to receive environmental information of an environment associated with the call participant; program instructions to determine a receptiveness level of the call participant based upon the emotional state and the environmental information; and program instructions to determine a message to the call participant based upon the receptiveness level and one or more machine-learning models.
14. The computer usable program product of claim 13, further comprising: program instructions to receive metadata associated with the call participant, wherein determining the receptiveness level is further based upon the metadata.
15. The computer usable program product of claim 14, wherein the metadata includes one or more of a location associated with the call participant or a time of day associated with the call.
16. The computer usable program product of claim 13, further comprising: program instructions to provide the message to the call participant.
17. The computer usable program product of claim 13, wherein the computer usable code is stored in a computer readable storage device in a data processing system, and wherein the computer usable code is transferred over a network from a remote data processing system.
18. The computer usable program product of claim 13, wherein the computer usable code is stored in a computer readable storage device in a server data processing system, and wherein the computer usable code is downloaded over a network to a remote data processing system for use in a computer readable storage device associated with the remote data processing system.
19. A computer system comprising one or more processors, one or more computer-readable memories, and one or more computer-readable storage devices, and program instructions stored on at least one of the one or more storage devices for execution by at least one of the one or more processors via at least one of the one or more memories, the stored program instructions comprising: program instructions to determine if a call participant of a call between the call participant and a voice response system is a human or a machine; program instructions to, responsive to determining that the call participant is a human, determine an emotional state of the call participant; program instructions to receive environmental information of an environment associated with the call participant; program instructions to determine a receptiveness level of the call participant based upon the emotional state and the environmental information; and program instructions to determine a message to the call participant based upon the receptiveness level and one or more machine-learning models.
20. The computer system of claim 19, the stored program instructions further comprising: program instructions to receive metadata associated with the call participant, wherein determining the receptiveness level is further based upon the metadata.
</claims>
</document>
