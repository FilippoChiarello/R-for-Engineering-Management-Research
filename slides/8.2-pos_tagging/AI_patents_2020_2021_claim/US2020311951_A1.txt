<document>

<filing_date>
2020-01-06
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-29
</priority_date>

<ipc_classes>
G06F3/01,G06F3/16,G06T7/246,G06T7/73,H04W4/029,H04W4/38
</ipc_classes>

<assignee>
CALTECH (CALIFORNIA INSTITUTE OF TECHNOLOGY)
YAMAHA MOTOR COMPANY
CHANGIZI, MARK
</assignee>

<inventors>
MOCHIZUKI, HIROFUMI
SHIMOJO, SHINSUKE
Suegami, Takashi
Changizi, Mark
Berger, Christopher C.
Wu, Daw-An
</inventors>

<docdb_family_id>
72603837
</docdb_family_id>

<title>
ASSISTING VISUAL MOTION PERCEPTION IN THE EXTREME PERIPHERY
</title>

<abstract>
Disclosed herein include systems, devices, computer readable media, and methods for enhancing human visual motion perception in the periphery (e.g., the far periphery, or the extreme periphery) or improving user safety using, for example, at least one auditory stimulus with a falling pitch.
</abstract>

<claims>
1. A system for improving visual motion perception comprising: non-transitory memory configured to store executable instructions; an audio output device; and a hardware processor in communication with the non-transitory memory, the image capture device, and the audio output device, the hardware processor programmed by the executable instructions to: receive a plurality of images captured by an image capture device; determine a location and a trajectory of an object with respect to a user at a first time using the plurality of images, wherein the location and the trajectory of the object with respect to the user at the first time indicate the object has a likelihood above a likelihood threshold to pass by the user at a passing-by time, and wherein the object is not in a visual field of the user or is in a far periphery of the visual field of the user at the first time and/or the passing-by time; determine an auditory stimulus and an output time to output the auditory stimulus based on the location and the trajectory of the object with respect to the user at the first time, wherein the output time is the passing-by time, or the output time is between the first time and the passing-by time, and wherein a characteristic of the auditory stimulus is selected from a group comprising a falling pitch; and cause the audio output device to output the auditory stimulus to the user at the output time, thereby increasing a likelihood of the user to visually perceive the object in the far periphery of the visual field of the user at the output time or a time immediately after the output time.
2. (canceled)
3. The system of claim 1, wherein to receive the plurality of images, the hardware processor is programmed by the executable instructions to: receive sensory data comprising the plurality of images captured by one or more sensors, wherein the one or more sensors comprise the image capture device, a Radio Detection and Ranging (Radar), a Light Detection and Ranging (Lidar), an audio capture device, or a combination thereof, wherein to determine the location and the trajectory of the object with respect to the user at the first time, the hardware processor is programmed by the executable instructions to: determine the location and the trajectory of the object with respect to the user at the first time using the sensor data, or wherein to determine the object is passing by, or has the likelihood above the likelihood threshold to pass by, the user at the passing-by time, the hardware processor is programmed by the executable instructions to: determine the object is passing by, or has the likelihood above the likelihood threshold to pass by, the user at the passing-by time using the sensor data.
4. The system of claim 3, wherein the system comprises the one or more sensors or one or more of the one or more sensors.
5. (canceled)
6. The system of claim 3, wherein to receive the sensor data, the hardware processor is programmed by the executable instructions to: receive the sensor data captured by the one or more sensors from a second system.
7. The system of claim 3, wherein the hardware processor is programmed by the executable instructions to: transmit the sensor data, the location and the trajectory of the object with respect to the user at the first time, and/or an indication that the object is passing by, or has the likelihood above the likelihood threshold to pass by, the user at the passing-by time to a third system.
8. The system of claim 1, wherein a helmet, a car audio system, or a wearable speaker system or device, is associated with, comprises, or comprised in, the system, or a portion thereof.
9. The system of claim 1, wherein the object is a first motor vehicle.
10. The system of claim 1, wherein the user is in a second motor vehicle or is riding the second motor vehicle.
11. The system of claim 1, wherein the hardware processor is programmed by the executable instructions to: determine the object has the likelihood above the likelihood threshold to pass by the user at the passing-by time based on the location and the trajectory of the object with respect to the user at the first time.
12. The system of claim 1, wherein the likelihood threshold of to the object to pass by the user at the passing-by time is at least 50%.
13. The system of claim 1, wherein the location and the trajectory of the object with respect to the user at the first time indicate the object has the likelihood above the likelihood threshold to pass by the user at the passing-by time within at most 10 meters of the user.
14. The system of claim 1, wherein the object is in an extreme periphery of the visual field of the user at the first time.
15. The system of claim 1, wherein the far periphery of the visual field of the user comprises about 60° to about 110° temporally away from a nose and towards a temple of the user, and/or wherein the extreme periphery of the visual field of the user comprises about 90° to 110° temporally away from the nose and towards the temple of the user.
16. The system of claim 1, wherein the characteristic of the auditory stimulus is selected from a group comprising a falling pitch, increasing loudness, a higher number of frequencies, a higher frequency, a regularity in angular difference, a peculiarity in angular difference, a sound shadow, a larger angular size, a loudness asymmetry for ears of the user, a head related transfer function of about 90°, a vertical location below a horizon of the user, or a combination thereof.
17. The system of claim 1, wherein a change in the characteristic of the auditory stimulus is at a fastest or highest at, or at about, the passing-by time.
18. The system of claim 1, wherein the auditory stimulus comprises a narrow range of frequencies or a pure tone.
19. The system of claim 1, wherein the auditory stimulus comprises music, speech, or a combination thereof.
20. The system of claim 1, wherein the first time is a time the plurality of images, or a portion thereof, is captured, wherein the first time is a time after the plurality of images, or a portion thereof, is captured, or wherein the first time is a time immediately after the plurality of images, or a portion thereof, is captured.
21. The system of claim 1, wherein the location and the trajectory of the object with respect to the user indicate the object is likely to pass by the user on a left side or a right side of the user at the passing-by time, wherein the audio output device comprises a left audio output device and a right audio output device configured to output the auditory stimulus to a left ear and a right ear of the user, respectively, and wherein to cause the audio output device to output the auditory stimulus to the user at the output time, the hardware processor is programmed by the executable instructions to: cause the left audio output device or the right audio output device to output the auditory stimulus to the left ear or the right ear of the user, respectively, at the output time.
22. The system of claim 1, wherein the output time is the passing-by time, the output time is immediately prior to the passing-by time, or the output time is between the first time and the passing-by time.
23. The system of claim 1, thereby increasing the likelihood of the user to visually perceive the object in the far periphery of the visual field of the user at the output time or the time immediately after the output time by at least 10%.
24. A method for improving visual motion perception comprising: under control of a hardware processor: receiving sensor data captured by one or more sensors; determining a location and a trajectory of an object with respect to a subject at a first time using the sensor data, wherein the location and the trajectory of the object with respect to the subject at the first time indicate the object has a likelihood above a likelihood threshold to be moving relative to the subject within a threshold distance of the subject at a second time, and wherein the object is not in a visual field of the subject or is in a periphery of the visual field of the subject at the first time; determining an auditory stimulus based on the location and the trajectory of the object with respect to the subject at the first time, wherein a characteristic of the auditory stimulus corresponds to an auditory characteristic of the object moving relative to the subject within the threshold distance of the subject; and causing the auditory stimulus to be outputted to the subject at an output time, thereby increasing a likelihood of the subject to visually perceive the object in the periphery of the visual field of the subject at the output time or a time immediately after the output time.
25. 25.-27. (canceled)
28. The system of claim 24, wherein the sensor data comprises a location, a speed, and a direction of the object captured by one or more telemetry and location sensors associated with the object, wherein the one or more sensors comprise the one or more telemetry and location sensors associated with the object, wherein the one or more telemetry and location sensors associated with the object comprises a first global positioning system (GPS) sensor associated with the object, and wherein the one or more telemetry and location sensors associated with the subject comprise a second global positioning system (GPS) sensor associated with the subject.
29. 29.-48. (canceled)
49. A system for user safety comprising: non-transitory memory configured to store executable instructions; one or more sensors associated with a helmet, or a wearable device, for capturing different types of sensor data; a plurality of audio output devices for outputting auditory stimuli that mimic sounds from (1a) the horizon and (1b) below the horizon of a user and from (2a) the left side of, (2b) directly behind, and (2c) the right side of the user; and a hardware processor in communication with the non-transitory memory, the hardware processor programmed by the executable instructions to: receive first sensor data captured by the one or more sensors; determine a first location of an object with respect to the user at a first time using the first sensor data, wherein the first location of the object with respect to the user is within a first threshold distance of the user; determine one or more first auditory stimuli and corresponding one or more first audio output devices of the plurality of output devices for outputting the one or more first auditory stimuli using the first location of the object with respect to the user at the first time, wherein a characteristic of the first auditory stimulus is related to a property of the object; and cause each of the one or more first audio output devices to output the corresponding first auditory stimulus of the one or more first auditory stimuli.
50. The system of claim 49, wherein the characteristic of the first auditory stimulus is a pitch of the first auditory stimulus, wherein the characteristic of the first auditory stimulus is related to the property of the object comprising a size of the object, and wherein the pitch of the first auditory stimulus correlates positively, or negatively, with the size of the object.
51. 51.-78. (canceled)
</claims>
</document>
