<document>

<filing_date>
2020-03-30
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-30
</priority_date>

<ipc_classes>
G06F40/166,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
UNIVERSITY OF CALIFORNIA
</assignee>

<inventors>
Petrusca, Alexandru
Chaturvedi, Snigdha
Brahman, Faeze
</inventors>

<docdb_family_id>
72605943
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR ARTIFICIAL INTELLIGENCE STORY GENERATION ALLOWING CONTENT INTRODUCTION
</title>

<abstract>
Techniques for artificial intelligence assisted story generation includes training a neural network with first training data that indicates text for one or more portions of a training story and second training data that indicates text for a subset of text for an immediately following portion and third training data that indicates full text for the same portion. First data is retrieved that indicates text for a first one or more portions of a different new story. Second data is also received that indicates text for a cued subset of a next portion of the new story. Third data is generated that indicates full text for the next portion of the new story based on the first data and the second data and the neural network. The third data is concatenated to the first data to produce output data that is stored.
</abstract>

<claims>
1. A non-transitory computer-readable medium carrying one or more sequences of instructions, wherein execution of the one or more sequences of instructions by one or more processors causes the one or more processors to perform the steps of: retrieving from a computer-readable medium first data that indicates text for a first one or more portions of a story; receiving second data that indicates text for a cued subset of a next portion of the story; generating third data that indicates full text for the next portion of the story based on the first data and the second data and a neural network trained with first training data that indicates text for a second one or more portions of a different second story and second training data that indicates text for a subset of text for an immediately following portion of the second story and third training data that indicates full text for the immediately following portion of the second story; and concatenating the third data to the first data and writing to the computer-readable medium.
2. The non-transitory computer readable medium as recited in claim 1, wherein the text for the cued subset is received from a human user.
3. The non-transitory computer readable medium as recited in claim 1, wherein the first data for a next iteration of the method is set equal to the output data.
4. The non-transitory computer readable medium as recited in claim 1, wherein each portion of the first one or more portions and the next portion and the second one or more portions and the immediately following portion is a sentence.
5. The non-transitory computer readable medium as recited in claim 1, wherein the neural network includes: a first attention based encoding network that generates a context-sensitive query vector and context-sensitive key vector and context-sensitive value vector based on a first matrix of vectors that are based on the first data; a second attention based encoding network that generates a cue-sensitive query vector and cue-sensitive key vector and cue-sensitive value vector based on a second matrix of vectors that are based on the second data; and a combination decoding network that generates a third matrix of vectors based at least in part on the context-sensitive key vector and the context-sensitive value vector and the cue-sensitive key vector and the cue-sensitive value vector, wherein the third data is based on the third matrix of vectors.
6. An apparatus comprising: at least one processor; and at least one memory including one or more sequences of instructions, the at least one memory and the one or more sequences of instructions configured to, with the at least one processor, cause the apparatus to perform at least the following, retrieving from a computer-readable medium first data that indicates text for a first one or more portions of a story; receiving second data that indicates text for a cued subset of a next portion of the story; generating third data that indicates full text for the next portion of the story based on the first data and the second data and a neural network trained with first training data that indicates text for a second one or more portions of a different second story and second training data that indicates text for a subset of text for an immediately following portion of the second story and third training data that indicates full text for the immediately following portion of the second story; and adding the third data to the first data and writing to the computer-readable medium.
7. The apparatus as recited in claim 6, wherein the text for the cued subset is received from a human user.
8. The apparatus as recited in claim 6, wherein the first data for a next iteration of the method is set equal to the output data.
9. The apparatus as recited in claim 6, wherein each portion of the first one or more portions and the next portion and the second one or more portions and the immediately following portion is a sentence.
10. The apparatus as recited in claim 6, wherein the neural network includes: a first attention based encoding network that generates a context-sensitive query vector and context-sensitive key vector and context-sensitive value vector based on a first matrix of vectors that are based on the first data; a second attention based encoding network that generates a cue-sensitive query vector and cue-sensitive key vector and cue-sensitive value vector based on a second matrix of vectors that are based on the second data; and a combination decoding network that generates a third matrix of vectors based at least in part on the context-sensitive key vector and the context-sensitive value vector and the cue-sensitive key vector and the cue-sensitive value vector, wherein the third data is based on the third matrix of vectors.
11. A method for artificial intelligence assisted generation of a story, comprising: training automatically on a processor a neural network with first training data that indicates text for a one or more portions of a training story and second training data that indicates text for a subset of text for an immediately following portion of the training story and third training data that indicates full text for the immediately following portion of the training story; retrieving automatically on the processor from a computer-readable medium first data that indicates text for a first one or more portions of a different new story; receiving second data that indicates text for a cued subset of a next portion of the new story; generating automatically on the processor third data that indicates full text for the next portion of the new story based on the first data and the second data and the neural network; and adding automatically on the processor the third data to the first data and writing to the computer-readable medium.
12. The method as recited in claim 11, wherein the text for the cued subset is received from a human user.
13. The method as recited in claim 11, wherein the first data for a next iteration of the method is set equal to the output data.
14. The method as recited in claim 11, wherein each portion of the first one or more portions and the next portion and the second one or more portions and the immediately following portion is a sentence.
15. The method as recited in claim 11, wherein the neural network includes: a first attention based encoding network that generates a context-sensitive query vector and context-sensitive key vector and context-sensitive value vector based on a first matrix of vectors that are based on the first data; a second attention based encoding network that generates a cue-sensitive query vector and cue-sensitive key vector and cue-sensitive value vector based on a second matrix of vectors that are based on the second data; and a combination decoding network that generates a third matrix of vectors based at least in part on the context-sensitive key vector and the context-sensitive value vector and the cue-sensitive key vector and the cue-sensitive value vector, wherein the third data is based on the third matrix of vectors.
</claims>
</document>
