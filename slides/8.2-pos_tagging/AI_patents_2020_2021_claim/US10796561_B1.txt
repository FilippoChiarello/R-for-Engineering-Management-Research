<document>

<filing_date>
2019-09-10
</filing_date>

<publication_date>
2020-10-06
</publication_date>

<priority_date>
2019-09-10
</priority_date>

<ipc_classes>
G08B25/00,G08B25/01,G08B25/10,H04M1/725,H04W4/80,H04W4/90
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
EBERWEIN, JAMES P.
GROVER, VIVEK
WILLIS, DANIEL B.
Bien, Thomas L.
</inventors>

<docdb_family_id>
72664242
</docdb_family_id>

<title>
Cognitive safety alert generation
</title>

<abstract>
Aspects of the disclosure provide for a computer-implemented method. Examples of the method include receiving internal data points from a plurality of sensors associated with a person, the internal data points including at least situational data and biological data, receiving external data points, and comparing the internal data points to the external data points and a profile of the person. The method further includes analyzing the internal data points, the external data points, the profile of the person, and a result of the comparison by applying weighting rules to determine at least one weighted value, where the weighted value is determined according to a first cognitive dimension of an emotional and biological condition of the person and a second cognitive dimension of a situational and contextual condition surrounding the person, comparing the weighted value to a threshold value, and providing an alert when the weighted value exceeds the threshold value.
</abstract>

<claims>
1. A computer program product for determining a cognitive safety alert, the computer program product comprising a computer readable storage medium having program instructions embodied therewith that when executed by a processor cause the processor to: receive internal data points from a plurality of sensors, wherein the plurality of sensors are configured proximate to the person and configured to send the internal data points comprising one or more of voice data, image data, position data, fingerprint data, or biological data associated with at least one of the person, a mobile electronic device proximate to the person, or surroundings of the person, and activation status and battery level information of the mobile electronic device, the internal data points including at least situational data and biological data; receive external data points; compare the internal data points to the external data points and to a profile of a person; analyze the internal data points, the external data points, the profile of the person, and a result of the comparison by applying weighting rules to determine at least one weighted value, where the weighted value is determined according to a first cognitive dimension of an emotional and biological condition of the person and a second cognitive dimension of a situational and contextual condition surrounding the person; compare the weighted value to a configurable threshold value; and provide an alert when the weighted value exceeds the threshold value.
2. The computer program product of claim 1, wherein the external data points are selected from a group of Internet accessible sources comprising a social media source, a news source, a blog, an online communication system, an online bulletin board, a weather data source, a traffic data source, a geographic data source, criminal database source, and an image feed.
3. The computer program product of claim 2, wherein the profile of the person is selected from a group of stored sources of information about the person comprising an image of the person, biological data of the person, voice data of the person, and fingerprint data of the person.
4. The computer program product of claim 2, wherein the weighting rules vary depending on the first and second cognitive dimensions.
5. The computer program product of claim 2, wherein the alert is provided automatically to a third-party without providing the alert to the person and without intervention by the person after the alert is provided.
6. The computer program product of claim 2, wherein the alert is provided to the person via an audible or visual indicator and the person is presented an option for forwarding the alert to a third-party.
7. The computer program product of claim 6, wherein the alert is automatically provided to a third-party without intervention by the person when a predefined period of time after the alert is provided to the person has expired without input from the person.
8. A computer implemented method, comprising: receiving internal data points from a plurality of sensors associated with a person, wherein the plurality of sensors are configured proximate to the person and configured to send the internal data points comprising one or more of voice data, image data, position data, fingerprint data, or biological data associated with the person, a mobile electronic device proximate to the person, or surroundings of the person and activation status and battery level of the mobile electronic device, the internal data points including at least situational data and biological data; receiving external data points; comparing the internal data points to the external data points and to a profile of the person; analyzing the internal data points, the external data points, the profile of the person, and a result of the comparison by applying weighting rules to determine at least one weighted value, where the weighted value is determined according to a first cognitive dimension of an emotional and biological condition of the person and a second cognitive dimension of a situational and contextual condition surrounding the person; comparing the weighted value to a configurable threshold value; and providing an alert when the weighted value exceeds the threshold value.
9. The computer implemented method of claim 8, wherein the external data points are selected from a group of Internet accessible sources comprising a social media source, a news source, a blog, an online communication system, an online bulletin board, a weather data source, a traffic data source, a geographic data source, criminal database source, and an image feed.
10. The computer implemented method of claim 8, wherein the profile of the person is selected from a group of stored sources of information about the person comprising an image of the person, biological data of the person, voice data of the person, and fingerprint data of the person.
11. The computer implemented method of claim 8, wherein the weighting rules vary depending on the first and second cognitive dimensions, and wherein the internal and external data points comprise a combination of structured or unstructured textual data and visual data.
12. The computer implemented method of claim 8, wherein the alert is provided automatically to a third-party without providing the alert to the person and without intervention by the person after the alert is provided or wherein the alert is provided to the person via an audible or visual indicator and the person is presented an option for forwarding the alert to a third-party.
13. A system comprising a processor configured to: receive internal data points from a plurality of sensors associated with a person, wherein the plurality of sensors are configured proximate to the person and configured to send the internal data points comprising one or more of voice data, image data, position data, fingerprint data, or biological data associated with the person, a mobile electronic device proximate to the person, or surroundings of the person, and activation status and battery level of the mobile electronic device, the internal data points including at least situational data and biological data; receive external data points from; compare the internal data points to the external data points and to a profile of the person; analyze the internal data points, the external data points, the profile of the person, and a result of the comparison by applying weighting rules to determine at least one weighted value, where the weighted value is determined according to a first cognitive dimension of an emotional and biological condition of the person and a second cognitive dimension of a situational and contextual condition surrounding the person; compare the weighted value to a configurable threshold value; and provide an alert when the weighted value exceeds the threshold value.
14. The system of claim 13, wherein the external data points are selected from a group of Internet accessible sources comprising a social media source, a news source, a blog, an online communication system, an online bulletin board, a weather data source, a traffic data source, a geographic data source, criminal database source, and an image feed.
15. The system of claim 13, wherein the profile of the person is selected from a group of stored sources of information about the person comprising an image of the person, biological data of the person, voice data of the person, and fingerprint data of the person.
16. The system of claim 13, wherein the weighting rules vary depending on the first and second cognitive dimensions.
17. The system of claim 13, wherein the internal and external data points comprise a combination of structured or unstructured textual data and visual data.
</claims>
</document>
