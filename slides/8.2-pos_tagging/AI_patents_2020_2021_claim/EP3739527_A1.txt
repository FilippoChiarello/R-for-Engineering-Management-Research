<document>

<filing_date>
2018-04-26
</filing_date>

<publication_date>
2020-11-18
</publication_date>

<priority_date>
2017-08-11
</priority_date>

<ipc_classes>
G06F9/445,G06N20/00
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
GRIESKAMP, Wolfgang
ARADHYE, Hrishikesh
SANKETI, Pannag
RAMAGE, Daniel
HU, Shiyu
</inventors>

<docdb_family_id>
62152682
</docdb_family_id>

<title>
ON-DEVICE MACHINE LEARNING PLATFORM
</title>

<abstract>
The present disclosure provides systems and methods for on-device machine learning. In particular, the present disclosure is directed to an on-device machine learning platform and associated techniques that enable on-device prediction, training, example collection, and/or other machine learning tasks or functionality. The on-device machine learning platform can manage a centralized example database and can receive training examples from applications. Each application can have its own enclave for certain functionalities offered by the on-device machine learning platform, such as receiving training examples. Thus, the on-device machine learning platform can enable centralized training example collection, model training, and usage of machine-learned models as a service to applications or other clients.
</abstract>

<claims>
1. A computing device, comprising: one or more processors; and one or more non-transitory computer-readable media that store: a plurality of applications implemented by the one or more processors; a centralized example database that stores training examples received from the applications; a machine-learned model operable to provide inferences to the plurality of applications, and instructions that, when executed by the one or more processors, cause the computing device to implement an on-device machine learning platform that performs operations, the operations comprising: receiving a first training example from a first application of the plurality of applications via a collection application programming interface; storing the first training example in the centralized example database for use in training the machine-learned model such that the first training example is not accessible to the other applications of the plurality of applications; receiving input data from a second application of the plurality of applications via a prediction application programming interface; employing at least the machine-learned model to generate at least one inference based at least in part on the input data; and
providing the at least one inference generated by the machine-learned model to the second application via the prediction application programming interface.
2. The computing device of claim 1, wherein:
the operations further comprise: receiving an instruction from the first application via a training application programming interface to re-train the machine-learned model based at least in part on one or more training examples stored by the centralized example database; and in response to the instruction, causing the machine-learned model to be re-trained based at least in part on the first training example.
3. The computing device of claim 1 or claim 2, wherein the operations further comprise: prior to storing the first training example, determining one or more context features descriptive of a context associated with the computing device; and wherein storing the first training example comprises storing the first training example together with the one or more context features in the centralized example database.
4. The computing device of claim 3, wherein the operations further comprise: prior to storing the first training example, determining a permission status for the first application relative to each of one or more context types, wherein the permission status for the first application and each context type is descriptive of whether the first application has permission to access such context type; wherein storing the first training example together with the one or more context features comprises storing first training example together with only context features that are included in context types that the first application has permission to access.
5. The computing device of claim 3 or claim 4, wherein the operations further comprise: registering as a listener to one or more context updates; and maintaining a context feature cache of context features based on the one or more context updates; wherein determining the one or more context features descriptive of the context associated with the computing device comprises accessing the one or more context features from the context feature cache.
6. The computing device of any of claims 3 to 5, wherein the centralized example database is not directly accessible by the one or more applications, such that the one or more context features are not accessible to the first application.
7. The computing device of any of claims 3-6, wherein: storing the new training example together with the one or more context features in the centralized example database comprises assigning an expiration period to at least a first context feature of the one or more context features; and the operations further comprise deleting the first context feature or the entire new training example from the centralized example database at a conclusion of the expiration period assigned to the first context feature.
8. The computing device of any of claims 3-7, wherein the operations further comprise: receiving an indication of a change to a permission status for the first application relative to at least one context type; and in response to the change to the permission status, deleting from the centralized example database any context features of the at least one context type that are associated with training examples associated with the first application.
9. The computing device of claim 8, wherein the operations further comprise, after deleting the context features, re-training one or more machine-learned models associated with the first application using the training examples associated with the first application in the centralized example database.
10. A computer-implemented method, the method comprising: receiving, by a computing device via a collection application programming interface, a first training example from a first application of a plurality of applications stored by the computing device; storing, by the computing device, the first training example in a centralized example database of the computing device that contains training examples received from the plurality of applications for use in training a machine-learned model stored by the computing device such that the first training example is not accessible to the other applications of the one or more applications, wherein the machine-learned model is operable to provide inferences to the plurality of applications; receiving, by the computing device via a prediction application programming interface, input data from a second application of the plurality of applications; employing, by the computing device, the machine-learned model to generate at least one inference based at least in part on the input data; and providing, by the computing device via the prediction application programming interface, the at least one inference generated by the machine-learned model to the second application.
11. The computer-implemented method of claim 10, further comprising: prior to storing the first training example, determining one or more context features descriptive of a context associated with the computing device; and wherein storing the first training example comprises storing the first training example together with the one or more context features in the centralized example database.
12. The computer-implemented method of claim 11, further comprising: prior to storing the first training example, determining, by the computing device, a permission status for the first application relative to each of one or more context types, wherein the permission status for the first application and each context type is descriptive of whether the first application has permission to access such context type; wherein storing, by the computing device, the first training example together with the one or more context features comprises storing, by the computing device, the first training example together with only context features that are included in context types that first application has permission to access.
13. The computer-implemented method of any one of claims 10 to 12, further comprising: receiving, by the computing device via a training application programming interface, an instruction from the first application to re-train the machine-learned model based at least in part on one or more training examples included in the centralized example database; and in response to the instruction, causing, by the computing device, the machine-learned model to be re-trained based at least in part on the first training example.
14. A computer program product comprising instructions which, when the program is executed by a computer, cause the computer to perform the steps of the method of any of claims 10-132.
15. A computer-readable storage medium comprising instructions which, when executed by a computer, cause the computer to perform the steps of the method of any of claims 10-13.
</claims>
</document>
