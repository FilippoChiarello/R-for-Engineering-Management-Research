<document>

<filing_date>
2018-06-07
</filing_date>

<publication_date>
2020-11-03
</publication_date>

<priority_date>
2018-05-11
</priority_date>

<ipc_classes>
G06F16/78,G11B27/028,H04N7/18
</ipc_classes>

<assignee>
AXON ENTERPRISE
</assignee>

<inventors>
BELLIA, DANIEL
HERSHFIELD, JACOB
WILSON, MICHAEL
</inventors>

<docdb_family_id>
68464123
</docdb_family_id>

<title>
Systems and methods for cross-redaction
</title>

<abstract>
Systems and methods for analyzing recorded data from one recording device, or a subset of recording devices to identify redactions that should be made to the recorded data. The identified redactions may be in accordance with a redaction policy. The identified redactions may be applied to recorded data recorded by other devices that recorded data the same incident. The redactions may be made to recorded data that was not analyzed prior to performing the redactions, so the redactions identified in one recorded data are performed in other recorded data that was not used to identify the types of redactions that should be made. Applying redactions to data that was not analyzed to determine what types of redactions should be made reduces the amount of time required to analyze recorded data for redaction.
</abstract>

<claims>
1. A method for redacting video data recorded by a plurality of cameras, the video data recorded at a same incident, the method comprising: receiving a first recorded video data and a second recorded video data, the first recorded video data recorded at the same incident by a first camera of the plurality of cameras, and the second recorded video data recorded at the same incident by a second camera of the plurality of cameras; identifying information in the first recorded video data to be redacted; identifying one or more first frames of video data in the first recorded video data associated with the identified information to be redacted; performing a respective first redaction on each first frame of video data of the one or more first frames of video data in the first recorded video data; and for each first frame of video data of the one or more first frames of video data: finding a respective second frame of video data in the second recorded video data, the respective second frame of video data aligned in time with the first frame of video data, wherein the respective second frame of video data in the second recorded video data is found after the first frame of video data in the first recorded video data is identified; and performing the respective first redaction on the respective second frame of video data.
2. The method of claim 1 wherein performing the respective first redaction on the respective second frame of video data comprises performing the first redaction on the second recorded video data only on the respective second frame of video data.
3. The method of claim 1 further comprising not performing the respective first redaction on the second recorded video data on any frame of video data in the second recorded video data that does not align in time with the one or more first frames of video data in the first recorded video data.
4. The method of claim 1 wherein the one or more first frames of video data are identified by at least one of a location identifier, a start identifier, and an end identifier.
5. The method of claim 1 wherein performing the respective first redaction comprises performing one or more redaction tasks and electronically storing the one or more redaction tasks.
6. The method of claim 1 further comprising electronically storing the one or more first frames of video data in redaction criteria, wherein each respective second frame of video data in the second recorded video data is found using the one or more first frames of video data stored in the redaction criteria.
7. The method of claim 1 wherein performing the respective first redaction on the respective second frame of video data comprises searching for the identified information at the respective second frame of video data after the respective second frame of video data has been found in accordance with the first frame of video data.
8. The method of claim 1 comprising identifying a type of redaction that should be done for each first frame of video data of the one or more first frames of video data, wherein performing the respective first redaction on the respective second frame of video data includes performing the respective identified type of redaction on the respective second frame of video data.
9. The method of claim 1 wherein the first camera of the plurality of cameras and the second camera of the plurality of cameras are each selected from the group consisting of body-worn cameras and vehicle cameras.
10. The method of claim 1, wherein the first recorded video data comprises a first plurality of portions; the second recorded video data comprises a second plurality of portions aligned in time with the first plurality of portions; identifying the one or more first frames of video data comprises analyzing each portion of the first plurality of portions; and performing the respective first redaction on the respective second frame of video data for each first frame of video data of the one or more first frames of video data comprises analyzing less than all of the second plurality of portions in accordance with the one or more first frames of video data.
11. A system for redacting video data recorded by a plurality of cameras, the video data recorded at a same incident, the system comprising: a processing circuit; and a data store; wherein: the data store stores the video data recorded by the plurality of cameras; the processing circuit identifies information in a first stored video data to be redacted in accordance with a redaction policy, the first stored video data recorded at the same incident by a first camera of the plurality of cameras; the processing circuit identifies one or more first video frames in the first stored video data associated with the identified information to be redacted; and for each first video frame of the one or more first video frames, the processing circuit: identifies a respective first redaction task that when performed redacts the first stored video data at the first video frame in accordance with the redaction policy; finds a respective second video frame in a second stored video data that aligns in time with the first video frame, the second stored video data recorded at the same incident by a second camera of the plurality of cameras; and performs the respective first redaction task on the second stored video data at the respective second video frame.
12. The system of claim 11 wherein the processing circuit uses alignment data recorded by at least one of the first camera and the second camera at the same incident to determine that each first video frame of the one or more first video frames aligns in time with the respective second video frame.
13. The system of claim 12 wherein the alignment data comprises one or more time stamps.
14. The system of claim 12 wherein the alignment data comprises: information transmitted by the first camera and received by the second camera; and information transmitted by the second camera and received by the first camera.
15. The system of claim 11 wherein the one or more first video frames includes multiple frames comprising a range of the first stored video data, the range includes a start of the range in the first stored video data and an end of the range in the first stored video data.
16. A method, performed by a processing circuit, for redacting video data recorded by a plurality of cameras, the video data recorded at a same incident, the method comprising: selecting a first recorded video data recorded at the same incident by a first camera of the plurality of cameras, the first recorded video data associated with a first redaction criteria; selecting a second recorded video data recorded at the same incident by a second camera of the plurality of cameras, the second recorded video data associated with a second redaction criteria; for a first video frame identified in the first redaction criteria: finding a first corresponding video frame in the second recorded video data that aligns in time with the first video frame; and redacting the second recorded video data at the first corresponding video frame in accordance with one or more redaction tasks identified for the first video frame; and for a second video frame identified in the second redaction criteria: finding a second corresponding video frame in the first recorded video data that aligns in time with the second video frame; and redacting the first recorded video data at the second corresponding video frame in accordance with one or more second redaction tasks identified for the second video frame.
17. The method of claim 16 further comprising aligning the first recorded video data with the second recorded video data in accordance with alignment information recorded by at least one of the first camera and the second camera at the same incident.
18. The method of claim 16 wherein the first redaction criteria and the second redaction criteria are generated by the processing circuit in accordance with a same redaction policy.
19. The method of claim 16 wherein the first redaction criteria and the second redaction criteria are generated in accordance with a first redaction policy and a second redaction policy respectively.
20. The method of claim 16 wherein the first redaction criteria are generated after the first recorded video data is recorded by the first video camera and the second redaction criteria are generated after the second recorded video data is recorded by the second video camera.
</claims>
</document>
