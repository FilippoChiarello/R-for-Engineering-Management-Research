<document>

<filing_date>
2019-03-28
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-28
</priority_date>

<ipc_classes>
G06N3/08,G10L15/06,G10L15/065,G10L15/16,G10L15/183
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
Polovets, George Ion
</inventors>

<docdb_family_id>
70110322
</docdb_family_id>

<title>
Modular Language Model Adaptation
</title>

<abstract>
Systems and techniques for modular language model adaptation are described herein. A set of adaptation training data and a set of parameters may be received from a recurrent neural network model. A set of adaptation parameters may be determined using the set of adaptation training data. A set of outputs of the recurrent neural network model may be modified using output of an evaluation of the set of adaptation training data using the set of adaptation parameters. An adaptation module may be generated that includes a set of adaptation module parameters based on the modified set of outputs. The adaptation module may be added to the recurrent neural network model for evaluation of inputs corresponding to the set of adaptation parameters.
</abstract>

<claims>
1. A system for language model adaptation, the system comprising: at least one processor; and memory including instructions that, when executed by the at least one processor, cause the at least one processor to perform operations to: receive a set of adaptation training data and a set of parameters from a recurrent neural network model; determine a set of adaptation parameters using the set of adaptation training data; modify a set of outputs of the recurrent neural network model using output of an evaluation of the set of adaptation training data using the set of adaptation parameters; generate an adaptation module that includes a set of adaptation module parameters based on the modified set of outputs, wherein generating the adaptation module includes backpropagating a set of errors determined by an objective function between the modified set of outputs and a set of true labels to determine the set of adaptation module parameters; and add the adaptation module to the recurrent neural network model for evaluation of inputs corresponding to the set of adaptation module parameters.
2. The system of claim 1, further comprising instructions that, when executed by the at least one processor, further cause the at least one processor to perform operations to: evaluate a set of input data using a base model of the recurrent neural network; select the adaptation module based on the evaluation of the set of input data; and determine a set of output values for the set of input data by evaluating a set of base model outputs generated by the base model using the set of parameters and a set of adaptation outputs generated by the adaptation module using the set of adaptation module parameters.
3. The system of claim 2, wherein the instructions to select the adaptation module include instructions to train a gate over a hidden layer output of the base model of the recurrent neural network.
4. The system of claim 2, wherein the instructions to determine the set of output values further comprises instructions to: set an initial value of each parameter of the set of adaptation parameters, wherein the initial value preserves the initial output of the recurrent neural network model; apply a composition function to the set of base outputs and the set of adaptation outputs; and evaluate output of the composition function using a softmax function to determine the set of output values.
5. The system of claim 2, wherein the set of base model outputs are received from a first softmax layer of the base model and the set of adaptation outputs is received from a second softmax layer of the adaptation module.
6. The system of claim 2, wherein the base model is a long short-term memory network comprising an embedding layer, a hidden layer, and a projection layer.
7. The system of claim 2, further comprising instructions that, when executed by the at least one processor, further cause the at least one processor to perform operations to: receive a set of pretraining data; and train a gate using the set of pretraining data and the set of adaptation training data, wherein the trained gate predicts whether input data corresponds to the set of pretraining data or the set of adaptation training data.
8. The system of claim 7, wherein the instructions to select the adaptation module further comprises instructions to evaluate the set of input data using the gate.
9. The system of claim 1, further comprising instructions that, when executed by the at least one processor, further cause the at least one processor to perform operations to: transmit the recurrent neural network model including the adaptation module to a machine learning processor to evaluate a set of language inputs, wherein a set of language outputs are generated by the recurrent neural network model that includes the adaptation module.
10. The system of claim 1, wherein the instructions to generate the adaptation module further comprises instructions to: generate a bottleneck layer using a subset of the set of adaptation module parameters; and add the bottleneck layer to the adaptation module.
11. The system of claim 1, wherein the set of parameters are received from the base model of the recurrent neural network.
12. The system of claim 1, further comprising instructions that, when executed by the at least one processor, further cause the at least one processor to perform operations to: evaluate a set of input data using a base model of the recurrent neural network; select the adaptation module for evaluating a first subset of the set of input data and another adaptation module for evaluating a second subset of the set of input data based on the evaluation of the set of input data; and determine a set of output values for the set of input data by applying a composition function to a set of base model outputs generated by the base model using the set of parameters, a first set of adaptation outputs generated by the adaptation module using the set of adaptation module parameters, and a second set of adaptation outputs generated by the other adaptation module using another set of adaptation module parameters.
13. The system of claim 12, wherein the instructions to determine the set of output values further comprises instructions to: set an initial value of each parameter of the set of adaptation module parameters and the other set of adaptation module parameters, wherein the initial value preserves the initial output of the recurrent neural network model; and evaluate output of the composite function using a softmax function to determine the set of output values.
14. A method for language model adaptation, the method comprising: receiving a set of adaptation training data and a set of parameters from a recurrent neural network model; determining a set of adaptation parameters using the set of adaptation training data; modifying a set of outputs of the recurrent neural network model using output of an evaluation of the set of adaptation training data using the set of adaptation parameters; generating an adaptation module including a set of adaptation module parameters based on the modified set of outputs, wherein generating the adaptation module includes backpropagating a set of errors determined by an objective function between the modified set of outputs and a set of true labels to determine the set of adaptation module parameters; and adding the adaptation module to the recurrent neural network model for evaluating inputs corresponding to the set of adaptation module parameters.
15. The method of claim 14, further comprising: evaluating a set of input data using a base model of the recurrent neural network; selecting the adaptation module based on the evaluation of the set of input data; and determining a set of output values for the set of input data by evaluating a set of base model outputs generated by the base model using the set of parameters and a set of adaptation outputs generated by the adaptation module using the set of adaptation module parameters.
16. The method of claim 15, further comprising: receiving a set of pretraining data; and training a gate using the set of pretraining data and the set of adaptation training data, wherein the training allows the gate to predict whether input data corresponds to the set of pretraining data or the set of adaptation training data.
17. The method of claim 14, wherein generating the adaptation module further comprises: generating a bottleneck layer using a subset of the set of adaptation module parameters; and adding the bottleneck layer to the adaptation module.
18. At least one machine-readable storage medium including instructions for language model adaptation that, when executed by at least one processor, cause the at least one processor to perform operations to: receive a set of adaptation training data and a set of parameters from a recurrent neural network model; determine a set of adaptation parameters using the set of adaptation training data; modify a set of outputs of the recurrent neural network model using output of an evaluation of the set of adaptation training data using the set of adaptation parameters; generate an adaptation module that includes a set of adaptation module parameters based on the modified set of outputs, wherein generating the adaptation module includes backpropagating a set of errors determined by an objective function between the modified set of outputs and a set of true labels to determine the set of adaptation module parameters; and add the adaptation module to the recurrent neural network model for evaluation of inputs corresponding to the set of adaptation module parameters.
19. The at least one machine-readable storage medium of claim 18, further comprising instructions that, when executed by the at least one processor, further cause the at least one processor to perform operations to: evaluate a set of input data using a base model of the recurrent neural network; select the adaptation module based on the evaluation of the set of input data; and determine a set of output values for the set of input data by evaluating a set of base model outputs generated by the base model using the set of parameters and a set of adaptation outputs generated by the adaptation module using the set of adaptation module parameters.
20. The at least one machine-readable storage medium of claim 19, further comprising instructions that, when executed by the at least one processor, further cause the at least one processor to perform operations to: receive a set of pretraining data; and train a gate using the set of pretraining data and the set of adaptation training data, wherein the trained gate predicts whether input data corresponds to the set of pretraining data or the set of adaptation training data.
</claims>
</document>
