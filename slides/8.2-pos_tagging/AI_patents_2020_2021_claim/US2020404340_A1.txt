<document>

<filing_date>
2019-01-28
</filing_date>

<publication_date>
2020-12-24
</publication_date>

<priority_date>
2018-02-08
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,H04N19/154,H04N19/172,H04N19/51,H04N19/86,H04N9/87
</ipc_classes>

<assignee>
BEIHANG UNIVERSITY
</assignee>

<inventors>
LI, TIANYI
LIU TIE
Xu, Mai
Yang, Ren
Fang, Zhaoji
</inventors>

<docdb_family_id>
62864400
</docdb_family_id>

<title>
MULTI-FRAME QUALITY ENHANCEMENT METHOD AND DEVICE FOR LOSSY COMPRESSED VIDEO
</title>

<abstract>
The present application provides a multi-frame quality enhancement method and device for a lossily compressed video. The method comprises: performing quality enhancement on the i-th frame of a decompressed video stream using m frames correlated with the i-th frame to play the i-th frame with enhanced quality. The m frames are frames in the video stream. The number of the same pixels or corresponding pixels of each of the m frames and the i-th frame is greater than a preset threshold. m is a natural number greater than 1. In an implementation, a non-peak-quality frame positioned between two peak quality frames may be enhanced using the peak quality frames. The method may mitigate the quality fluctuation across a plurality of frames for providing playback of the video stream and may improve the quality of all frames in the video after the lossy compression.
</abstract>

<claims>
1. A method of multi-frame quality enhancement for lossily compressed video, comprising: performing quality enhancement on a current frame of a lossily compressed video stream using a plurality of frames of the lossily compressed video stream that are correlated with the current frame for playback of the current frame with enhanced quality, wherein the number of the same pixels or corresponding pixels of each of the plurality of frames and the current frame is greater than a preset threshold, and wherein performing quality enhancement on the current frame using the plurality of frames correlated with the current frame of the lossily compressed video stream comprises: identifying peak quality frames and non-peak-quality frames in the lossily compressed video stream; determining that the current frame is a non-peak-quality frame, and performing quality enhancement on the current frame using a first peak quality frame Fp1 and a second peak quality frame Fp2 of the peak quality frames, wherein the first peak quality frame Fp1 is a previous frame of the current frame, and wherein the second peak quality frame Fp2 is a subsequent frame of the current frame.
2. (canceled)
3. The method according to claim 1, wherein identifying the peak quality frames and the non-peak-quality frames in the lossily compressed video stream comprises: identifying the peak quality frames and the non-peak-quality frames in the lossily compressed video stream using a trained support vector machine (SVM).
4. The method according to claim 3, further comprising: providing a plurality of training videos, wherein each frame in each of the training videos is a training sample; performing lossy compression on the training videos to generate a plurality of compressed training videos, and calculating a peak signal-to-noise ratio for each frame in each of the compressed training videos with respect to a corresponding frame in one of the training videos; determining whether each frame in each of the training videos is a peak quality frame based on the peak signal-to-noise ratio corresponding to the frame; extracting a plurality of pixel distribution features from each frame in each of the training videos; and training the SVM using a plurality of training features and a plurality of labels of the training samples, wherein the training features of an i-th training sample of the training samples comprise the pixel distribution features of the i-th frame in one of the training videos and adjacent frames of the i-th frame, and wherein the i-th training sample is associated with one of the plurality of labels indicating whether the i-th training sample is a peak quality frame.
5. The method according to claim 1, wherein performing quality enhancement on the current frame using the first peak quality frame Fp1 and the second peak quality frame Fp2 of the peak quality frames comprises: inputting the current frame, the first peak quality frame Fp1, and the second peak quality frame Fp2 into a multi-frame convolutional neural network structure, performing motion compensation on the first peak quality frame Fp1, and the second peak quality frame Fp2 using a motion compensation subnet in the multi-frame convolutional neural network structure to obtain a first compensated peak quality frame Fp1′ and a second compensated peak quality frame Fp2′; performing quality enhancement on the current frame using a quality enhancement subnet in the multi-frame convolutional neural network structure; and outputting, by the quality enhancement subnet, a quality enhanced frame representing the current frame with enhanced quality, wherein the quality enhanced frame is represented as Fnp+Rnp(θqe), wherein Fnp represents the current frame, and wherein Rnp(θqe) represents a residual reconstructed according to a trainable parameter θqe.
6. The method according to claim 5, wherein the multi-frame convolutional neural network structure comprises: the motion compensation subnet configured to compensate temporal motion between adjacent frames and the quality enhancement subnet configured to fuse features of temporal-motion-compensated frames produced by the motion compensation subnet.
7. The method according to claim 6, comprising: training the motion compensation subnet and the quality enhancement subnet in the multi-frame convolutional neural network structure before inputting the current frame, the first peak quality frame Fp1, and the second peak quality frame Fp2 into the multi-frame convolutional neural network structure.
8. The method according to claim 4, wherein determining whether each frame in each of the training videos is a peak quality frame based on the peak signal-to-noise ratio corresponding to the frame comprises: in response to determining that a first peak signal-to-noise ratio of a first frame in a first compressed training video of the compressed training videos with respect to a first frame in a first training video of the training videos is greater than a second peak signal-to-noise ratio of a second frame in the first compressed video with respect to a second frame in the first training video and that the first peak signal-to-noise ratio is greater than a third peak signal-to-noise ratio of a third frame in the first compressed video with respect to a third frame in the first training video, determining that the first frame in the first compressed video is a peak quality frame, wherein the second frame is a previous frame of the first frame, and wherein the third frame is a subsequent frame of the first frame; and identifying non-peak-quality frames of the training videos in view of a determination that the non-peak-quality frames are not peak quality frames.
9. An apparatus for multi-frame enhancement for lossily compressed video, comprising: a memory, and a processor communicably coupled to the memory, the processor to: perform quality enhancement on a current frame of a lossily compressed video stream using a plurality of frames of the lossily compressed video stream that are correlated with the current frame for playback of the current frame with enhanced quality, wherein the number of the same pixels or corresponding pixels of each of the plurality of frames and the current frame is greater than a preset threshold, and wherein, to perform quality enhancement on the current frame using the plurality of frames correlated with the current frame of the lossily compressed video stream, the processor is further to: identify peak quality frames and non-peak-quality frames in the lossily compressed video stream; determine that the current frame is a non-peak-quality frame, and perform quality enhancement on the current frame using a first peak quality frame Fp1 and a second peak quality frame Fp2 of the peak quality frames, wherein the first peak quality frame Fp1 is a previous frame of the current frame, and wherein the second peak quality frame Fp2 is a subsequent frame of the current frame.
10. A non-transitory computer storage medium storing a computer program, wherein the program, when executed by a processor, cause the processor to: perform quality enhancement on a current frame of a lossily compressed video stream using a plurality of frames of the lossily compressed video stream that are correlated with the current frame for playback of the current frame with enhanced quality, wherein the number of the same pixels or corresponding pixels of each of the plurality of frames and the current frame is greater than a preset threshold, and wherein, to perform quality enhancement on the current frame using the plurality of frames correlated with the current frame of the lossily compressed video stream, the processor is further to: identify peak quality frames and non-peak-quality frames in the lossily compressed video stream; determine that the current frame is a non-peak-quality frame, and perform quality enhancement on the current frame using a first peak quality frame Fp1 and a second peak quality frame Fp2 of the peak quality frames, wherein the first peak quality frame Fp1 is a previous frame of the current frame, and wherein the second peak quality frame Fp2 is a subsequent frame of the current frame.
11. The apparatus of claim 9, wherein to identify the peak quality frames and the non-peak-quality frames in the lossily compressed video stream, the processor is further to: identify the peak quality frames and the non-peak-quality frames in the lossily compressed video stream using a trained support vector machine (SVM).
12. The apparatus of claim 9, wherein the processor is further to: provide a plurality of training videos, wherein each frame in each of the training videos is a training sample; perform lossy compression on the training videos to generate a plurality of compressed training videos, and calculating a peak signal-to-noise ratio for each frame in each of the compressed training videos with respect to a corresponding frame in one of the training videos; determine whether each frame in each of the training videos is a peak quality frame based on the peak signal-to-noise ratio corresponding to the frame; extract a plurality of pixel distribution features from each frame in each of the training videos; and train the SVM using a plurality of training features and a plurality of labels of the training samples, wherein the training features of an i-th training sample of the training samples comprise the pixel distribution features of the i-th frame in one of the training videos and adjacent frames of the i-th frame, and wherein the i-th training sample is associated with one of the plurality of labels indicating whether the i-th training sample is a peak quality frame.
13. The apparatus of claim 9, wherein to perform quality enhancement on the current frame using the first peak quality frame Fp1 and the second peak quality frame Fp2 of the peak quality frames, the processor is further to: input the current frame, the first peak quality frame Fp1, and the second peak quality frame Fp2 into a multi-frame convolutional neural network structure, perform motion compensation on the first peak quality frame Fp1 and the second peak quality frame Fp2 using a motion compensation subnet in the multi-frame convolutional neural network structure to obtain a first compensated peak quality frame Fp1′ and a second compensated peak quality frame Fp2′; perform quality enhancement on the current frame using a quality enhancement subnet in the multi-frame convolutional neural network structure; and output, by the quality enhancement subnet, a quality enhanced frame representing the current frame with enhanced quality, wherein the quality enhanced frame is represented as Fnp+Rnp(θqe), wherein Fnp represents the current frame, and wherein Rnp(θqe) represents a residual reconstructed according to a trainable parameter.
14. The apparatus of claim 13, wherein the multi-frame convolutional neural network structure comprises: the motion compensation subnet configured to compensate temporal motion between adjacent frames and the quality enhancement subnet configured to fuse features of temporal-motion-compensated frames produced by the motion compensation subnet.
15. The apparatus of claim 14, wherein the processor is further to: train the motion compensation subnet and the quality enhancement subnet in the multi-frame convolutional neural network structure before inputting the current frame, the first peak quality frame Fp1, and the second peak quality frame Fp2 into the multi-frame convolutional neural network structure.
16. The apparatus of claim 12, wherein, to determine whether each frame in each of the training videos is a peak quality frame based on the peak signal-to-noise ratio corresponding to the frame, the processor is further to: in response to determining that a first peak signal-to-noise ratio of a first frame in a first compressed training video of the compressed training videos with respect to a first frame in a first training video of the training videos is greater than a second peak signal-to-noise ratio of a second frame in the first compressed video with respect to the a second frame in the first training video and that the first peak signal-to-noise ratio is greater than a third peak signal-to-noise ratio of a third frame in the first compressed video with respect to a third frame in the first training video, determine that the first frame in the first compressed video is a peak quality frame, wherein the second frame is a previous frame of the first frame, and wherein the third frame is a subsequent frame of the first frame; and identify non-peak-quality frames of the training videos in view of a determination that the non-peak-quality frames are not peak quality frames.
17. The non-transitory computer storage medium of claim 10, wherein to identify the peak quality frames and the non-peak-quality frames in the lossily compressed video stream, the processor is further to: identify the peak quality frames and the non-peak-quality frames in the lossily compressed video stream using a trained support vector machine (SVM).
18. The non-transitory computer storage medium of claim 10, wherein the processor is further to: provide a plurality of training videos, wherein each frame in each of the training videos is a training sample; perform lossy compression on the training videos to generate a plurality of compressed training videos, and calculating a peak signal-to-noise ratio for each frame in each of the compressed training videos with respect to a corresponding frame in one of the training videos; determine whether each frame in each of the training videos is a peak quality frame based on the peak signal-to-noise ratio corresponding to the frame; extract a plurality of pixel distribution features from each frame in each of the training videos; and train the SVM using a plurality of training features and a plurality of labels of the training samples, wherein the training features of an i-th training sample of the training samples comprise the pixel distribution features of the i-th frame in one of the training videos and adjacent frames of the i-th frame, and wherein the i-th training sample is associated with one of the plurality of labels indicating whether the i-th training sample is a peak quality frame.
19. The non-transitory computer storage medium of claim 10, wherein to perform quality enhancement on the current frame using the first peak quality frame Fp1 and the second peak quality frame Fp2 of the peak quality frames, the processor is further to: input the current frame, the first peak quality frame Fp1, and the second peak quality frame Fp2 into a multi-frame convolutional neural network structure, perform motion compensation on the first peak quality frame Fp1 and the second peak quality frame Fp2 using a motion compensation subnet in the multi-frame convolutional neural network structure to obtain a first compensated peak quality frame Fp1′ and a second compensated peak quality frame Fp2′; perform quality enhancement on the current frame using a quality enhancement subnet in the multi-frame convolutional neural network structure; and output, by the quality enhancement subnet, a quality enhanced frame representing the current frame with enhanced quality, wherein the quality enhanced frame is represented as Fnp+Rnp(θqe), wherein Fnp represents the current frame, and wherein Rnp(θqe) represents a residual reconstructed according to a trainable parameter.
20. The non-transitory computer storage medium of claim 19, wherein the multi-frame convolutional neural network structure comprises: the motion compensation subnet configured to compensate temporal motion between adjacent frames and the quality enhancement subnet configured to fuse features of temporal-motion-compensated frames produced by the motion compensation subnet.
21. The non-transitory computer storage medium of claim 20, wherein the processor is further to: train the motion compensation subnet and the quality enhancement subnet in the multi-frame convolutional neural network structure before inputting the current frame, the first peak quality frame Fp1, and the second peak quality frame Fp2 into the multi-frame convolutional neural network structure.
</claims>
</document>
