<document>

<filing_date>
2018-11-15
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2017-11-30
</priority_date>

<ipc_classes>
G06F16/53,G06F16/55,G06F16/56,G06K9/46,G06K9/62,G06N20/00,G06N5/04,G06T7/00,G06T7/73
</ipc_classes>

<assignee>
3M INNOVATIVE PROPERTIES COMPANY (MINNESOTA MINING AND MANUFACTURING INNOVATIVE PROPERTIES COMPANY)
</assignee>

<inventors>
LORENTZ ROBERT D.
SCHUMACHER, JENNIFER F.
AFRIDI, MUHAMMAD JAMAL
ASENDORF, NICHOLAS A.
SNYDER, JAMES B.
GOLNARI, GOLSHAN
</inventors>

<docdb_family_id>
66664382
</docdb_family_id>

<title>
IMAGE BASED COUNTERFEIT DETECTION
</title>

<abstract>
Systems and methods for authenticating material samples are provided. Digital images of the samples are processed to extract computer-vision features, which are used to train a classification algorithm along with location and optional time information. The extracted features/information of a test sample are evaluated by the trained classification algorithm to identify the test sample. The results of the evaluation are used to track and locate counterfeits or authentic products.
</abstract>

<claims>
1. A computer-implemented method of identifying, tracking and locating a counterfeit product, the method comprising: extracting, via a processor, computer-vision features from a digital image of a test sample; obtaining location information of the test sample; and evaluating, via a trained classification algorithm associated with the processor, the computer-vision features and the location information of the test sample to identify the test sample.
2. The method of claim 1, wherein the trained classification algorithm is obtained by: extracting computer-vision features from one or more digital images of each of a plurality of material samples; obtaining location information and optional time information of the material samples and training a classification algorithm with the computer-vision features, the location information and the optional time information.
3. The method of claim 1, wherein extracting the computer-vision features includes converting the digital image to a matrix of feature vectors representing a material property of the test sample.
4. The method of claim 1, wherein the location information is extracted from Global Navigation Satellite System (GNSS) data.
5. The method of claim 4, wherein the GNSS data is evaluated by the trained classification algorithm by inputting the GNSS data as a feature dimension of a feature vector.
6. The method of claim 1, further comprising obtaining time information of the test sample, wherein the time information is extracted from metadata of the digital image.
7. The method of claim 1, further comprising identifying the test sample to be authentic or counterfeit.
8. The method of claim 1, further comprising logging a result of the evaluation in a database.
9. The method of claim 8, further comprising receiving a query to the database and providing related information according to the query.
10. The method of claim 8, further comprising visualizing the result of the evaluation in a map.
11. The method of claim 8, further comprising detecting at least one of a distribution network of counterfeit products and a distribution network of authentic products based on the database.
12. A system of identifying, tracking and locating a counterfeit product, the system comprising: a graphical user interface (GUI) provided to a mobile device, the mobile device being capable of obtaining, via the GUI, one or more digital images for a sample to be tested; a computation component functionally connected to the mobile device, configured to receive the images from the GUI, and process the images to extract computer-vision features from the digital image, the computation component further configured to receive location information of the sample; and a trained classification algorithm associated with the computation component, the trained classification algorithm being configured to evaluate the computer-vision features and the location information of the sample to identify the sample.
13. The system of claim 12, wherein the computation component is configured to convert the digital image to a matrix of feature vectors representing a material property of the sample.
14. The system of claim 12, wherein the location information is extracted by the computation component from Global Navigation Satellite System (GNSS) data.
15. The system of claim 14, wherein the GNSS data is evaluated by the trained classification algorithm by inputting the GNSS data as a feature dimension of a feature vector.
16. The system of claim 12, wherein the computation component is further configured to extract time information from metadata of the digital image.
17. The system of claim 12, further comprising a database functionally connected to the computation component, a result of the evaluation of the sample being logged in the database.
18. The system of claim 17, wherein the GUI is configured to receive a query to the database and provide related information according to the query.
19. The system of claim 18, wherein the GUI is configured to visualize the result of the evaluation in a map.
20. The system of claim 12, wherein the trained classification algorithm is further configured to identify the sample to be authentic or counterfeit.
21. 21-22. (canceled)
</claims>
</document>
