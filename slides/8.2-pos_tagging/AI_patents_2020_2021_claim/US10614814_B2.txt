<document>

<filing_date>
2017-06-02
</filing_date>

<publication_date>
2020-04-07
</publication_date>

<priority_date>
2016-06-02
</priority_date>

<ipc_classes>
G10L15/02,G10L15/28,G10L17/00,G10L17/02,G10L17/04,G10L17/06,G10L17/22,G10L21/038,G10L25/12
</ipc_classes>

<assignee>
INTERACTIVE INTELLIGENCE GROUP
</assignee>

<inventors>
DACHIRAJU, RAJESH
GANAPATHIRAJU, ARAVIND
IYER, ANANTH NAGARAJA
WYSS, FELIX IMMANUEL
</inventors>

<docdb_family_id>
60479161
</docdb_family_id>

<title>
Technologies for authenticating a speaker using voice biometrics
</title>

<abstract>
Technologies for authenticating a speaker in a voice authentication system using voice biometrics include a speech collection computing device and a speech authentication computing device. The speech collection computing device is configured to collect a speech signal from a speaker and transmit the speech signal to the speech authentication computing device. The speech authentication computing device is configured to compute a speech signal feature vector for the received speech signal, retrieve a speech signal classifier associated with the speaker, and feed the speech signal feature vector to the retrieved speech signal classifier. Additionally, the speech authentication computing device is configured to determine whether the speaker is an authorized speaker based on an output of the retrieved speech signal classifier. Additional embodiments are described herein.
</abstract>

<claims>
1. A method for authenticating a speaker in a voice authentication system using voice biometrics, the method comprising: receiving, by a speech authentication computing device, a speech signal of a speaker collected by a speech collection computing device; computing, by the speech authentication computing device, a speech signal feature vector for the received speech comprising segmenting the speech signal into a plurality of glottal pulses; computing a glottal pulse future vector for each of the plurality of glottal pulses comprising decomposing each of the glottal pulses into a plurality of sub-band pulses, performing a metric-based clustering as a function of the glottal pulses and the corresponding plurality of sub-band pulses, and computing the glottal pulse feature vectors as a function of a result of the metric-based clustering; and computing the speech signal feature vector as a function of the glottal pulse feature vectors; retrieving, by the speech authentication computing device, a speech signal classifier associated with the speaker; feeding, by the speech authentication computing device, the speech signal feature vector to the retrieved speech signal classifier; and determining, by the speech authentication computing device, whether the speaker is an authorized speaker based on an output of the retrieved speech signal classifier.
2. The method of claim 1, wherein segmenting the speech signal into the plurality of glottal pulses comprises: pre-emphasizing the speech signal; extracting a plurality of linear prediction coefficients from the pre-emphasized speech signal; forming an inverse filter from the extracted linear prediction coefficients; filtering the speech signal using the inverse filter to obtain an inverse filtered signal; and segmenting the inverse filtered signal into the plurality of glottal pulses.
3. The method of claim 2, wherein segmenting the inverse filtered signal into the plurality of glottal pulses comprises segmenting the inverse filtered signal into the plurality of glottal pulses using zero frequency filtering.
4. The method of claim 1, wherein decomposing each of the glottal pulses comprises decomposing each of the glottal pulses into three sub-band pulses and wherein the metric-based clustering is performed as a function of the glottal pulses and the corresponding three sub-band pulses.
5. The method of claim 4, wherein decomposing each of the glottal pulses into three sub-band pulses comprises: transforming each glottal pulse into the frequency domain using a discrete cosine transform (DCT); determining two cut-off points of each DCT signal as a function of two identified sharp change points of each DCT signal; splitting each DCT signal into three sub-bands as a function of the determined cut-off points; and converting the three sub-bands into the time domain to determine the three sub-band pulses for each of the glottal pulses.
6. The method of claim 4, wherein performing the metric-based clustering comprises performing the metric-based clustering using a modified k-means clustering algorithm.
7. The method of claim 1, wherein computing the speech signal feature vector as a function of the glottal pulse feature vectors comprises (i) performing a principal component analysis on the glottal pulse feature vectors to obtain eigenvectors for each glottal pulse feature vector and (ii) determining the speech signal feature vector as a function of each eigenvalue of the obtained eigenvectors.
8. The method of claim 7, wherein determining the speech signal feature vector as a function of each eigenvalue of the obtained eigenvectors comprises determining the speech signal feature vector as a function of an eigenvector of the obtained eigenvectors having the highest eigenvalue.
9. The method of claim 1, further comprising enrolling, by a speech authentication computing device, a speaker in the voice authentication system, wherein enrolling the speaker comprises: collecting a requisite number of speech signals from the speaker; computing an authenticated speech signal feature vector for each of the collected requisite number of speech signals; classifying each of the authenticated speech signal feature vectors as being authenticated; and training the speech signal classifier to be associated with speaker as a function of the classification of the authenticated speech signal feature vectors and other speech signal feature vectors of the voice authentication system which have been previously classified as rejected during a background data collection phase for the voice authentication system.
10. The method of claim 9, wherein training the speech signal classifier comprises training the speech signal classifier using a two-class support vector machine classifier with a cosine similarity metric.
11. The method of claim 1, further comprising providing, by a speech authentication computing device, an indication to the speaker indicating whether the speaker was authenticated as a function of the output of the retrieved speech signal classifier.
12. A speech authentication computing device for authenticating a speaker in a voice authentication system using voice biometrics, the speech authentication computing device comprising: one or more computer-readable medium comprising instructions; and one or more processors coupled with the one or more computer-readable medium and configured to execute the instructions to: receive a speech signal of a speaker collected by a speech collection computing device; compute a speech signal feature vector for the received speech signal comprising segment the speech signal into a plurality of glottal pulses; compute a glottal pulse future vector for each of the plurality of glottal pulses by decomposing each of the glottal pulses into a plurality of sub-band pulses, performing a metric-based clustering as a function of the glottal pulses and the corresponding plurality of sub-band pulses and computing the glottal pulse feature vectors as a function of a result of the metric-based clustering; and compute the speech signal feature vector as a function of the glottal pulse feature vectors; retrieve a speech signal classifier associated with the speaker; feed the speech signal feature vector to the retrieved speech signal classifier; and determine whether the speaker is an authorized speaker based on an output of the retrieved speech signal classifier.
13. The speech authentication computing device of claim 12, wherein to segment the speech signal into the plurality of glottal pulses comprises to: pre-emphasize the speech signal; extract a plurality of linear prediction coefficients from the pre-emphasized speech signal; form an inverse filter from the extracted linear prediction coefficients; filter the speech signal using the inverse filter to obtain an inverse filtered signal; and segment the inverse filtered signal into the plurality of glottal pulses.
14. The speech authentication computing device of claim 13, wherein to segment the inverse filtered signal into the plurality of glottal pulses comprises to segment the inverse filtered signal into the plurality of glottal pulses using zero frequency filtering.
15. The speech authentication computing device of claim 12, wherein the decomposing each of the glottal pulses comprises decomposing each of the glottal pulses into three sub-band pulses and wherein the metric-based clustering is performed as a function of the glottal pulses and the corresponding three sub-band pulses.
16. The speech authentication computing device of claim 15, wherein to decompose each of the glottal pulses into three sub-band pulses comprises to: transform each glottal pulse into the frequency domain using a discrete cosine transform (DCT); determine two cut-off points of each DCT signal as a function of two identified sharp change points of each DCT signal; split each DCT signal into three sub-bands as a function of the determined cut-off points; and convert the three sub-bands into the time domain to determine the three sub-band pulses for each of the glottal pulses.
17. The speech authentication computing device of claim 15, wherein to perform the metric-based clustering comprises to perform the metric-based clustering using a modified k-means clustering algorithm.
18. The speech authentication computing device of claim 12, wherein to compute the speech signal feature vector as a function of the glottal pulse feature vectors comprises to (i) perform a principal component analysis on the glottal pulse feature vectors to obtain eigenvectors for each glottal pulse feature vector and (ii) determine the speech signal feature vector as a function of each eigenvalue of the obtained eigenvectors.
19. The speech authentication computing device of claim 18, wherein to determine the speech signal feature vector as a function of each eigenvalue of the obtained eigenvectors comprises to determine the speech signal feature vector as a function of an eigenvector of the obtained eigenvectors having the highest eigenvalue.
20. The speech authentication computing device of claim 12, wherein the one or more processors are further configured to execute the instructions to enroll a speaker in the voice authentication system, wherein to enroll the speaker comprises to: collect a requisite number of speech signals from the speaker; compute an authenticated speech signal feature vector for each of the collected requisite number of speech signals; classify each of the authenticated speech signal feature vectors as being authenticated; and train the speech signal classifier to be associated with speaker as a function of the classification of the authenticated speech signal feature vectors and other speech signal feature vectors of the voice authentication system which have been previously classified as rejected during a background data collection phase for the voice authentication system.
21. The speech authentication computing device of claim 20, wherein to train the speech signal classifier comprises to train the speech signal classifier using a two-class support vector machine classifier with a cosine similarity metric.
22. The speech authentication computing device of claim 12, wherein the one or more processors are further configured to execute the instructions to provide an indication to the speaker indicating whether the speaker was authenticated as a function of the output of the retrieved speech signal classifier.
</claims>
</document>
