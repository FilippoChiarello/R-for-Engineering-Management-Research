<document>

<filing_date>
2019-02-25
</filing_date>

<publication_date>
2020-08-27
</publication_date>

<priority_date>
2019-02-25
</priority_date>

<ipc_classes>
G06K9/00,G06Q30/06,H04N5/225,H04N5/247,H04N7/18
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
MCMAHON, NICHOLAS
DE BONET, JEREMY SAMUEL
MARON, ODED
COHN, JONATHAN
</inventors>

<docdb_family_id>
70166117
</docdb_family_id>

<title>
ITEM-IDENTIFYING CARTS
</title>

<abstract>
This disclosure is directed to an item-identifying cart that may be utilized by a user in a materials handling facility to automatically identify items that the user places in their cart, and update a virtual shopping cart to include items taken by the user. The mobile cart may include four capture assemblies that are disposed proximate to each of the four corners of a basket of the cart, and oriented such that their respective optical axes are directed towards an interior of a perimeter of the top of the basket, and above the top of the basket. The capture assemblies may include proximity sensors that are used to detect movement above the top of the basket, LEDs that illuminate items, and cameras that generate image data representing the items as they are placed in, or removed from, the cart.
</abstract>

<claims>
1. A mobile cart configured for travel on a surface, the mobile cart comprising: at least one wheel caster configured to cause the mobile cart to travel on the surface; a frame comprising: a bottom defining a quadrilateral shape; four sides protruding upward from the bottom according to the quadrilateral shape, the bottom and four sides defining an interior cavity of the frame to hold items; and a top having a perimeter defining an opening to the interior cavity to receive items placed in the interior cavity, the top of the frame being disposed in a substantially horizontal plane; a first capture assembly coupled to the frame proximate to a first corner of the perimeter and having a first viewing frustum directed upward from the substantially horizontal plane and towards an interior of the perimeter, the first capture assembly comprising a first time-of-flight (ToF) sensor, a first camera, and a first light emitting diode (LED); a second capture assembly coupled to the frame proximate to a second corner of the perimeter and having a second viewing frustum directed upward from the substantially horizontal plane and towards the interior of the perimeter, the second capture assembly comprising a second ToF sensor, a second camera, and a second LED; a third capture assembly coupled to the frame proximate to a third corner of the perimeter and having a third viewing frustum directed upward from the substantially horizontal plane and towards the interior of the perimeter, the third capture assembly comprising a third ToF sensor, a third camera, and a third LED; a fourth capture assembly coupled to the frame proximate to a fourth corner of the perimeter and having a fourth viewing frustum directed upward from the substantially horizontal plane and towards the interior of the perimeter, the fourth capture assembly comprising a fourth ToF sensor, a fourth camera, and a fourth LED, wherein: the first ToF sensor, the second ToF sensor, the third ToF sensor, and the fourth ToF sensor are configured to generate sensor data indicating movement of items through the perimeter of the top of the frame; the first camera, the second camera, the third camera, and the fourth camera are configured to generate image data representing items moved through the perimeter of the top of the frame; and the first LED, second LED, third LED, and fourth LED are configured, when activated, to emit light towards the interior of the perimeter; one or more processors; and one or more computer-readable media storing computer-executable instructions that, when executed, cause the one or more processors to: receive sensor data generated by at least one of the first ToF sensor, the second ToF sensor, the third ToF sensor, or the fourth ToF sensor; detect, based at least in part on the sensor data, an item moving through the perimeter of the top of the frame; at least partly responsive to detecting the movement of the item: cause at least one of the first LED, the second LED, the third LED, or the fourth LED to emit light; and cause at least one of the first camera, the second camera, the third camera, or the fourth camera to generate image data; determine, using the image data, an item identifier associated with the item; and store an association between the item identifier and a listing of previously stored item identifiers for the mobile cart.
2. The mobile cart of claim 1, wherein: the first camera has a first field-of-view (FOV), the second camera has a second FOV, the third camera has a third FOV, and the fourth camera has a fourth FOV; and the first FOV, second FOV, third FOV, and fourth FOV at least partially overlap at a location associated with a centroid of the quadrilateral.
3. The mobile cart of claim 1, comprising further computer-executable instructions that, when execute by the one or more processors, cause the one or more processors to: cause a camera shutter associated with the first camera to open and close at a first frequency; and cause the first LED to activate and deactivate at a second frequency, wherein the second frequency is at least three times that of the first frequency.
4. A mobile apparatus comprising: a frame comprising: a bottom having a perimeter; one or more sides coupled to and extending up from at least a portion of the perimeter of the bottom, the bottom and the one or more sides defining a receptacle; and a top having a perimeter that defines an opening to the receptacle; a proximity sensor coupled to the frame and configured to detect objects above the top of the frame; a light source coupled to the frame and configured to, when activated, emit light toward an interior of the perimeter of the top of the frame; and an imaging device coupled to the frame and having a viewing frustum directed above the top of the frame and towards an interior of the perimeter.
5. The mobile apparatus of claim 4, wherein the imaging device comprises a first imaging device having a first viewing frustum, further comprising: a second imaging device coupled to the frame and having a second viewing frustum directed above the top of the frame and towards the interior of the perimeter; a third imaging device coupled to the frame and having a third viewing frustum directed above the top of the frame and towards the interior of the perimeter; and a fourth imaging device coupled to the frame and having a fourth viewing frustum directed above the top of the frame and towards the interior of the perimeter, wherein: the first imaging device has a first field-of-view (FOV), the second imaging device has a second FOV, the third imaging device has a third FOV, and the fourth imaging device has a fourth FOV; and the first FOV, second FOV, third FOV, and fourth FOV at least partially overlap at a location above a centroid of a shape defined by the perimeter of the top of the frame.
6. The mobile apparatus of claim 4, further comprising: a vertical member extending downward from the bottom of the frame to a top of a wheel frame; at least one wheel caster coupled to a bottom of the wheel frame; and a battery pack assembly coupled to the top of the wheel frame and disposed below the bottom of the frame, the battery pack assembly comprising one or more batteries that provide power to the proximity sensor, the light source, and the imaging device.
7. The mobile apparatus of claim 6, further comprising at least one power cable disposed in at least one channel of the frame, wherein the at least one power cable provides power to at least one of the proximity sensor, the light source, or the imaging device.
8. The mobile apparatus of claim 4, further comprising: one or more processors; and one or more computer-readable media storing computer-executable instructions that, when executed, cause the one or more processors to: detect, at least partly using the proximity sensor, an item above the top of the frame; cause the light source to emit light; cause the imaging device to generate image data representing the item; determine, using the image data, an item identifier associated with the item; and store an indication of the item identifier.
9. The mobile apparatus of claim 8, further comprising computer-executable instructions that, when executed by the one or more processors, cause the one or more processors to: cause a camera shutter associated with the imaging device to open and close at a first frequency; and cause the light source to activate and deactivate at a second frequency, wherein the second frequency is greater than the first frequency.
10. The mobile apparatus of claim 9, wherein the second frequency is greater than or equal to 90 Hz.
11. The mobile apparatus of claim 8, further comprising: a display coupled to the frame; and further executable instructions that, when executed by the one or more processors, cause the one or more processors to: determine, using the image data, a plurality of possible item identifiers of the item; present, on the display, a user interface comprising at least a portion of the plurality of possible item identifiers; and receive response data indicative of a selection of one of the plurality of possible item identifiers, the one of the plurality of possible item identifiers corresponding to the item identifier.
12. The mobile apparatus of claim 8, further comprising: a microphone; a loudspeaker; and further executable instructions that, when executed by the one or more processors, cause the one or more processors to: determine, using the image data, a plurality of possible item identifiers of the item; cause the loudspeaker to output audio that includes a request to identify the item; generate, using the microphone, audio data represent an utterance of a user; determine, using the audio data, that the utterance indicates the item identifier.
13. A mobile apparatus comprising: a frame comprising: a bottom having a perimeter; one or more sides coupled to and extending up from at least a portion of the perimeter of the bottom, the bottom and the one or more sides defining a receptacle; and a top having a perimeter that defines an opening to the receptacle; a light source coupled to the frame and configured to, when activated, emit light toward an interior of the perimeter of the top of the frame; an imaging device coupled to the frame and having a viewing frustum directed above the top of the frame and towards an interior of the perimeter; one or more processors; and one or more computer-readable media storing computer-executable instructions that, when executed, cause the one or more processors to: cause the imaging device to generate image data representing an item; determine, using the image data, an item identifier associated with the item; and store an indication of the item identifier.
14. The mobile apparatus of claim 13, further comprising: a proximity sensor coupled to the frame and configured to detect objects above the top of the frame; and further computer-executable instructions that, when executed, cause the one or more processors to: receive sensor data generated by the proximity sensor; and detect, at least partly using the sensor data, the item above the top of the frame, wherein causing the imaging device to generate image data is performed at least partly responsive to detecting the item above the top of the frame.
15. The mobile apparatus of claim 13, wherein causing the imaging device to generate the image data includes causing a camera shutter of the imaging device to open and close at a first frequency, comprising further computer-executable instructions that, when executed, cause the one or more processors to causing the light source to activate and deactivate at a second frequency, wherein the second frequency is greater than the first frequency.
16. The mobile apparatus of claim 15, wherein the second frequency is greater than or equal to 90 Hz.
17. The mobile apparatus of claim 13, wherein the imaging device comprises a first imaging device having a first viewing frustum, further comprising: a second imaging device coupled to the frame and having a second viewing frustum directed above the top of the frame and towards the interior of the perimeter; wherein: the first imaging device has a first field-of-view (FOV) and the second imaging device has a second FOV; and the first FOV and the second FOV at least partially overlap at a location above a centroid of a shape defined by the perimeter of the top of the frame.
18. The mobile apparatus of claim 13, further comprising: a vertical member extending downward from the bottom of the frame to a top of a wheel frame; at least one wheel caster coupled to a bottom of the wheel frame; and a battery pack assembly coupled to the top of the wheel frame and disposed below the bottom of the frame, the battery pack assembly comprising one or more batteries that provide power to the one or more processors, the light source, and the imaging device.
19. The mobile apparatus of claim 13, further comprising: a weight sensor configured to generate weight data associated with the item; and further computer executable instructions that, when executed by the one or more processors, cause the one or more processors to: determine, using the weight data, that the item was placed into the frame of the mobile apparatus, wherein storing the indication of the item identifier is based at least in part on determining that the item was placed into the frame.
20. The mobile apparatus of claim 13, further comprising: a display coupled to the frame; and further executable instructions that, when executed by the one or more processors, cause the one or more processors to: determine, using the image data, a plurality of possible item identifiers of the item; present, on the display, a user interface comprising at least a portion of the plurality of possible item identifiers; and receive response data indicative of a selection of one of the plurality of possible item identifiers, the one of the plurality of possible item identifiers corresponding to the item identifier.
</claims>
</document>
