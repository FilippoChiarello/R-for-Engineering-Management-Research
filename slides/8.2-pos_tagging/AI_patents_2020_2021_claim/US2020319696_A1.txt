<document>

<filing_date>
2020-06-21
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2020-06-21
</priority_date>

<ipc_classes>
G06F1/3234,G06F1/3287,G06F12/0804,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
BERNAT, FRANCESC GUIM
KUMAR, KARTHIK
WILLHALM, THOMAS
</assignee>

<inventors>
BERNAT, FRANCESC GUIM
KUMAR, KARTHIK
WILLHALM, THOMAS
</inventors>

<docdb_family_id>
72663011
</docdb_family_id>

<title>
PLATFORM AMBIENT DATA MANAGEMENT SCHEMES FOR TIERED ARCHITECTURES
</title>

<abstract>
Methods and apparatus for platform ambient data management schemes for tiered architectures. A platform including one or more CPUs coupled to multiple tiers of memory comprising various types of DIMMs (e.g., DRAM, hybrid, DCPMM) is powered by a battery subsystem receiving input energy harvested from one or more green energy sources. Energy threshold conditions are detected, and associated memory reconfiguration is performed. The memory reconfiguration may include but is not limited to copying data between DIMMs (or memory ranks on the DIMMS in the same tier, copying data between a first type of memory to a second type of memory on a hybrid DIMM, and flushing dirty lines in a DIMM in a first memory tier being used as a cache for a second memory tier. Following data copy and flushing operations, the DIMMs and/or their memory devices are powered down and/or deactivated. In one aspect, machine learning models trained on historical data are employed to project harvested energy levels that are used in detecting energy threshold conditions.
</abstract>

<claims>
1. A method implemented on a platform including one or more central processing units (CPUs) operatively coupled to a plurality of Dual Inline Memory Modules (DIMMs) comprising: employing multiple DIMMs to store data associated with software executing on the one or more CPUs; and perform at least one of, a) copying data from one or more first DIMMs to one or more second DIMMs and putting at least one first DIMM into a deactivated or reduced power state or putting at least memory module on a first DIMM into a reduced power state; b) for one or more DIMMs comprising hybrid DIMMs, copying data from memory modules having a first type of memory to memory modules having a second type of memory and reducing a power state or deactivating memory modules from which data are copied; and c) flushing dirty lines in a DIMM in a first memory tier being used as a cache for a second memory tier and reducing a power state of or deactivating the DIMM in the first memory tier.
2. The method of claim 1, further comprising, partitioning memory on each of multiple DIMMs into a plurality of ranks, each rank having a respective memory address space and a power state that is individually controllable; storing data across two or more of the multiple DIMMs in at least one of a striped or interleaved manner; the data being stored in the address spaces of a multiple ranks; copying data from one or more ranks on a first DIMM to one or more ranks on a second DIMM; and at least one of, reducing a power state of the one or more ranks on the first DIMM from which data was copied; putting the first DIMM in a reduced power state; and deactivating the first DIMM.
3. The method of claim 1, wherein data are stored in a plurality of memory tiers including a first tier and a second tier, further comprising: copying data from one or more DIMMs in the first tier to one or more DIMMs in the second tier; and putting the one or more DIMMs in the first tier from which data were copied into a reduced power or deactivated state.
4. The method of claim 3, wherein the platform includes a Network Interface Controller (NIC) and the plurality of memory tiers include a virtual tier on the platform under which the physical memory associated with the virtual tier is located in a remote platform in communication with the platform, further comprising: copying data from one or more DIMMs in the second tier or a third tier to the virtual tier by employing Remote Direct Memory Access (RDMA) operations using the NIC to copy the data to the remote platform; and employing RDMA operations using the NIC to access data from the remote platform.
5. A method implemented of claim 1, wherein the platform is powered by a battery subsystem receiving input energy harvested from one or more green energy sources, and the method for comprises: detecting an energy threshold condition under which a current or a projected available battery power level from the battery subsystem in view of a current or projected platform power consumption level crosses a threshold; and, in response thereto, perform at least one of a), b), and c).
6. The method of claim 5, further comprising: implementing a machine learning model to project an amount of harvested energy from the one or more green energy sources to be received by the battery subsystem; detecting a current power level in the battery subsystem; determining at least one of a current platform power consumption level and a projected platform power consumption level; and detecting the energy threshold condition as a function of the projected amount of harvested energy to be received by the battery subsystem, the current power level in the battery subsystem, and the at least one of the current platform power consumption level and the projected platform power consumption level.
7. The method of claim 6, wherein the machine learning model is one of a Long Short-Term Memory (LSTM) model and a machine learning model employing a plurality of Gated Recurrent Units (GRUs), further comprising: training the machine learning model with time-based historical harvested energy data and time-based historical ambient sensor data; employing a trained machine learning model to project a harvested energy level using input data comprising at least one of a current harvested energy level, current ambient sensor data, and forecast weather data.
8. The method of claim 1, further comprising: for one or more software applications executing on a CPU, identifying one or more DIMMs storing data for the application; determining latency requirements for the application; and in view of the latency requirements and the one or more DIMMs that are identified, determining whether data should be copied from at least one of the one or more DIMMs.
9. The method of claim 1, further comprising: implementing platform address decoders to map virtual memory addresses to physical addresses on the plurality of DIMMs; and in response to copying data from a first DIMM to a second DIMM, reprogramming at least one platform address decoder to map virtual addresses for the copied data to new physical memory addresses on the second DIMM.
10. The method of claim 1, further comprising: detecting an event invoked or enunciated by an operator of the platform or software running on the platform; and in response thereto, perform at least one of a), b), and c).
11. A platform, comprising: one or more central processing units (CPUs); a plurality of Dual Inline Memory Modules (DIMMs), operatively coupled to the one or more CPUs; logic configured to at least one of, a) copy data from one or more first DIMMs to one or more second DIMMs and put at least one first DIMM into a deactivated or reduced power state or put at least one memory module on a first DIMM into a reduced power state; b) for one or more DIMMs comprising hybrid DIMMs, copy data from memory modules having a first type of memory to memory modules having a second type of memory and reduce a power state or deactivate memory modules for which data are copied; and c) flush dirty lines in a DIMM in a first memory tier being used as a cache for a second memory tier and reduce a power state of or deactivate the DIMM in the first memory tier.
12. The platform of claim 11, wherein memory on each of multiple DIMMs are partitioned into a plurality of ranks, each rank having a respective memory address space and a power state that is individually controllable, further comprising logic to, store data across two or more of the plurality of DIMMs in at least one of a striped or interleaved manner; the data being stored in the address spaces of a multiple ranks; copy data from one or more ranks on a first DIMM to one or more other ranks on the first DIMM or to one or more ranks on a second DIMM; and at least one of, reduce a power state of the one or more ranks on the first DIMM from which data was copied; put the first DIMM in a reduced power state; and deactivate the first DIMM.
13. The platform of claim 11, wherein data are stored in a plurality of memory tiers including a first tier and a second tier, further comprising logic to: copy data from one or more DIMMs in the first tier to one or more DIMMs in the second tier; and put the one or more DIMMs in the first tier from which data were copied into a reduced power or deactivated state.
14. The method of claim 13, wherein the platform further includes a Network Interface Controller (NIC) operatively coupled to a CPU and the plurality of memory tiers include a virtual tier on the platform under which the physical memory associated with the virtual tier is located in a remote platform in communication with the platform, further comprising logic to: copy data from one or more DIMMs in the second tier or a third tier to the virtual tier by employing Remote Direct Memory Access (RDMA) operations using the NIC to copy the data to the remote platform; and employ RDMA operations using the NIC to access data from the remote platform.
15. A platform of claim 11, wherein the platform is powered by a battery subsystem receiving input energy harvested from one or more green energy sources, further comprising logic to: detect an energy threshold condition under which a current or a projected available battery power level from the battery subsystem in view of a current or projected platform power consumption level crosses a threshold; and, in response thereto, perform at least one of a), b), and c).
16. The platform of claim 15, further comprising logic to: implement a machine learning model to project an amount of harvested energy from the green energy source to be received by the battery subsystem; detect a current power level in the battery subsystem; determine at least one of a current platform power consumption level and a projected platform power consumption level; and detect the energy threshold condition as a function of the projected amount of harvested energy to be received by the battery subsystem, the current power level in the battery subsystem, and the at least one of the current platform power consumption level and the projected platform power consumption level.
17. The platform of claim 16, wherein the machine learning model is one of a Long Short-Term Memory (LSTM) model and a machine learning model employing a plurality of Gated Recurrent Units (GRUs) that is trained with historical harvested energy data and historical ambient sensor data, and the compute platform is configured to employ the machine learning model to project a harvested energy level using input data comprising at least one of a current harvested energy level and current ambient sensor data.
18. The platform of claim 11, wherein the platform is configured to execute software applications on the one or more CPUs, further comprising logic to: for one or more software applications executing on a CPU, identify one or more DIMMs storing data for the application; determine latency requirements for the application; and in view of the latency requirements and the one or more DIMMs that are identified, determine whether data should be copied from at least one of the one or more DIMMs.
19. The platform of claim 11, further comprising logic to: detect an event invoked or enunciated by an operator of the platform or software running on the platform; and in response thereto, perform at least one of a), b), and c).
20. A green edge appliance comprising: one or more solar panels; a battery subsystem to receive energy harvested by the one or more solar panels; and a first platform configured to be powered by the battery subsystem and comprising: one or more central processing units (CPUs); a plurality of Dual Inline Memory Modules (DIMMs), operatively coupled to the one or more CPUs; and logic configured to: detect an energy threshold condition under which a current or a projected available battery power level crosses a threshold; and in response thereto, perform at least one of, a) copy data from one or more first DIMMs to one or more second DIMMs, and put at least one first DIMM into a deactivated or reduced power state or put at least one memory module on a first DIMM into a reduced power state; b) for one or more DIMMs comprising hybrid DIMMs, copy data from memory modules having a first type of memory to memory modules having a second type of memory and reduce a power state or deactivate memory modules from which data are copied; and c) flush dirty lines in a DIMM in a first memory tier being used as a cache for a second memory tier and reduce a power state of or deactivate the DIMM in the first memory tier.
21. The green energy edge appliance of claim 20, further comprising a plurality of platforms having a configuration similar to the first platform.
22. The green energy edge appliance of claim 20, further comprising: a storage class memory (SCM) node comprising a plurality of DIMMs coupled to the first platform via a fabric, wherein the plurality of DIMMs are implemented as a second or third memory tier.
23. The green energy edge appliance of claim 20, wherein the first platform includes further logic to: implement a machine learning model to project an amount of harvested energy from the one or more solar panels to be received by the battery subsystem; detect a current power level in the battery subsystem; determine at least one of a current platform power consumption level and a projected platform power consumption level; and detect the energy threshold condition as a function of the projected amount of harvested energy to be received by the battery subsystem, the current power level in the battery subsystem, and the at least one of the current platform power consumption level and the projected platform power consumption level.
24. The green energy edge appliance of claim 20, wherein the first platform is configured to execute software applications on the one or more CPUs, further comprising logic to: for one or more software applications executing on a CPU, identify one or more DIMMs storing data for the application; determine latency requirements for the application; and in view of the latency requirements and the one or more DIMMs that are identified, determine whether data should be copied from at least one of the one or more DIMMs.
25. The green energy edge appliance of claim 20, wherein the first platform further includes a Network Interface Controller (NIC) operatively coupled to a CPU and DIMMs from the plurality of DIMMs are implemented in a plurality of memory tiers including at least a first and second tier and a virtual tier under which the physical memory associated with the virtual tier is located in a remote platform in communication with the first platform, further comprising logic to: copy data from one or more DIMMs in the second tier or a third tier to the virtual tier by employing Remote Direct Memory Access (RDMA) operations using the NIC to copy the data to the remote platform; and employ RDMA operations using the NIC to access data from the remote platform.
</claims>
</document>
