<document>

<filing_date>
2019-04-19
</filing_date>

<publication_date>
2020-07-23
</publication_date>

<priority_date>
2019-01-18
</priority_date>

<ipc_classes>
G05D1/00,G05D1/02,G06K9/00,G06K9/62
</ipc_classes>

<assignee>
TOYOTA RESEARCH INSTITUTE
</assignee>

<inventors>
DOUILLARD, BERTRAND
GAIDON, ADRIEN
LEE, KUAN-HUI
PAN, JIA-EN M.
TAGAWA, TAKAAKI
</inventors>

<docdb_family_id>
71608938
</docdb_family_id>

<title>
ATTENTION-BASED RECURRENT CONVOLUTIONAL NETWORK FOR VEHICLE TAILLIGHT RECOGNITION
</title>

<abstract>
A method for performing vehicle taillight recognition is described. The method includes extracting spatial features from a sequence of images of a real-world traffic scene during operation of an ego vehicle. The method includes selectively focusing a convolutional neural network (CNN) of a CNN-long short-term memory (CNN-LSTM) framework on a selected region of the sequence of images according to a spatial attention model for a vehicle taillight recognition task. The method includes selecting, by an LSTM network of the CNN-LSTM framework, frames within the selected region of the sequence of images according to a temporal attention model for the vehicle taillight recognition task. The method includes inferring, according to the selected frames within the selected region of the sequence of images, an intent of an ado vehicle according to a taillight state. The method includes planning a trajectory of the ego vehicle from the intent inferred from the ado vehicle.
</abstract>

<claims>
1. A method for performing vehicle taillight recognition, comprising: extracting spatial features from a sequence of images of a real-world traffic scene during operation of an ego vehicle; selectively focusing a convolutional neural network (CNN) of a CNN-long short-term memory (CNN-LSTM) framework on a selected region of the sequence of images according to a spatial attention model for a vehicle taillight recognition task; selecting, by an LSTM network of the CNN-LSTM framework, frames within the selected region of the sequence of images according to a temporal attention model for the vehicle taillight recognition task; inferring, according to the selected frames within the selected region of the sequence of images, an intent of an ado vehicle according to a taillight state of the ado vehicle, as determined from the selected frames within the selected region; and planning a trajectory of the ego vehicle according to the intent inferred from the ado vehicle.
2. The method of claim 1, further comprising: selectively focusing on focal regions of the sequence of images; and identifying more critical time steps of the sequence of images.
3. The method of claim 2, further comprising: identifying regions of interest in the sequence of images; and selectively focusing on the identified regions of interest.
4. The method of claim 2, further comprising selectively focusing on time steps of the sequence of images identified as having greater importance to the vehicle taillight recognition task.
5. The method of claim 1, further comprising recognizing the taillight state of the ado vehicle during autonomous operation of the ego vehicle.
6. The method of claim 5, further comprising adjusting the trajectory of the ego vehicle to avoid a collision based on the intent inferred from the ado vehicle according to the taillight state.
7. The method of claim 6, further comprising stopping the ego vehicle based on the intent inferred from the ado vehicle according to the taillight state.
8. A non-transitory computer-readable medium having program code recorded thereon for performing vehicle taillight recognition, the program code being executed by a processor and comprising: program code to extract spatial features from a sequence of images of a real-world traffic scene during operation of an ego vehicle; program code to selectively focus a convolutional neural network (CNN) of a CNN-long short-term memory (CNN-LSTM) framework on a selected region of the sequence of images according to a spatial attention model for a vehicle taillight recognition task; program code to select, by an LSTM network of the CNN-LSTM framework, frames within the selected region of the sequence of images according to a temporal attention model for the vehicle taillight recognition task; program code to infer, according to the selected frames within the selected region of the sequence of images, an intent of an ado vehicle according to a taillight state of the ado vehicle determined from the selected frames within the selected region; and program code to plan a trajectory of the ego vehicle according to the intent inferred from the ado vehicle.
9. The non-transitory computer-readable medium of claim 8, further comprising: program code to selectively focusing on focal regions of the sequence of images; and program code to identify critical time steps of the sequence of images.
10. The non-transitory computer-readable medium of claim 9, further comprising program code to identify regions of interest in the sequence of images; and program code to selectively focusing on the identified regions of interest.
11. The non-transitory computer-readable medium of claim 9, further comprising: program code to selectively focus on time steps of the sequence of images identified as having greater importance to the vehicle taillight recognition task.
12. The non-transitory computer-readable medium of claim 11, further comprising: program code to recognize the taillight state of the ado vehicle during autonomous operation of the ego vehicle.
13. The non-transitory computer-readable medium of claim 12, further comprising: program code to adjust the trajectory of the ego vehicle to avoid a collision based on the intent inferred from the ado vehicle according to the taillight state.
14. The non-transitory computer-readable medium of claim 13, further comprising: program code to stop the ego vehicle based on the intent inferred from the ado vehicle according to the taillight state.
15. A vehicle taillight recognition system, comprising: a taillight recognition module configured to extract spatial features from a sequence of images of a real-world traffic scene during operation of an ego vehicle, the taillight recognition module comprising: a convolutional neural network (CNN) of a CNN-long short-term memory (CNN-LSTM) framework configured to selectively focus on a selected region of the sequence of images according to a spatial attention model for a vehicle taillight recognition task; and an LSTM network of the CNN-LSTM framework configured to select frames within the selected region of the sequence of images according to a temporal attention model for the vehicle taillight recognition task; an intent inference module configured to infer, according to the selected frames within the selected region of the sequence of images, an intent of an ado vehicle according to a taillight state of the ado vehicle determined from the selected frames within the selected region; and a trajectory planner module configured to plan a trajectory of the ego vehicle according to the intent inferred from the ado vehicle.
16. The vehicle taillight recognition system of claim 15, further comprising a controller configured to control operation of the ego vehicle according to the trajectory selected by the trajectory planner module.
17. The vehicle taillight recognition system of claim 16, in which the controller is configured to stop the ego vehicle according to the trajectory selected by the trajectory planner module.
18. The vehicle taillight recognition system of claim 16, in which the controller is further configured to direct the ego vehicle to avoid a collision based on the intent inferred from the ado vehicle according to the taillight state of the ado vehicle.
19. The vehicle taillight recognition system of claim 15, in which the LSTM network of the of the CNN-LSTM framework is further configured to identify regions of interest in the sequence of images, and to selectively focus on the identified regions of interest.
20. The vehicle taillight recognition system of claim 15, in which the CNN of the of the CNN-LSTM framework is further configured to selectively focus on focal regions of the sequence of images, and to identify critical time steps of the sequence of images.
</claims>
</document>
