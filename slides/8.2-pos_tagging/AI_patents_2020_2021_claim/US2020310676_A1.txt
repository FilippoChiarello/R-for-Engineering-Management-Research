<document>

<filing_date>
2019-10-10
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-04-01
</priority_date>

<ipc_classes>
G06F12/02,G06F3/06,G06F5/10
</ipc_classes>

<assignee>
SK HYNIX
</assignee>

<inventors>
PARK, YONG SANG
</inventors>

<docdb_family_id>
72606054
</docdb_family_id>

<title>
BUFFER MEMORY, AND COMPUTATION DEVICE AND SYSTEM USING THE SAME
</title>

<abstract>
A computation device includes a buffer memory which provides first to b input feature sets to the computation unit. The buffer memory includes first to nth memories, and configured to divide and store the first to nth input feature sets each including a plurality of features in the first to nth memories, respectively. The plurality of features of one input feature set is divided and stored into the first to nth memories. Features having the same turn in the first to nth input feature sets are stored one by one in the first to nth memories.
</abstract>

<claims>
1. A computation device comprising: a buffer memory comprising first to nth memories, and configured to store first to nth input feature sets each including a plurality of features in the first to nth memories, and divisionally store the plurality of features of one input feature set into the first to nth memories, wherein features having the same turn in the first to nth input feature sets are stored one by one in the first to nth memories, where n is an integer equal to or larger than two; and a computation unit configured to receive the first to nth input feature sets stored in the buffer memory, and perform a computation operation on the received input feature sets.
2. The computation device according to claim 1, wherein the buffer memory stores a first feature among the plurality of features of a kh input feature set in a kth memory, where k is an integer between 1 and n.
3. The computation device according to claim 2, wherein the buffer memory stores an (n+1)th feature among the plurality of features of the kth input feature set, in the kth memory.
4. The computation device according to claim 1, wherein the buffer memory stores first to Ith features of the first input feature set in the first to Ith memories, respectively, at the same time, where I is an integer between 2 and n.
5. The computation device according to claim 1, wherein the buffer memory outputs the features having the same turn in the first to nth input feature sets at the same time, during a single read operation.
6. A computation device comprising: a buffer memory comprising first to fourth memories, and configured to store first to fourth input feature sets each having at least first to fourth features in the first to fourth memories, and divide and store first to fourth features of one input feature set in the first to fourth memories, wherein features having the same turn in the first to fourth input feature sets are divided and stored in the first to fourth memories so as not to overlap one another; and a computation unit configured to receive the first to fourth input feature sets stored in the buffer memory, and perform a computation operation on the received input feature sets.
7. The computation device according to claim 6, wherein the first feature of the first input feature set is stored in a first storage region of the first memory, the second feature of the first input feature set is stored in a first storage region of the second memory, the third feature of the first input feature set is stored in a first storage region of the third memory, and the fourth feature of the first input feature set is stored in a first storage region of the fourth memory.
8. The computation device according to claim 7, wherein the first feature of the second input feature set is stored in a second storage region of the second memory, the second feature of the second input feature set is stored in a second storage region of the third memory, the third feature of the second input feature set is stored in a second storage region of the fourth memory, and the fourth feature of the second input feature set is stored in a second storage region of the first memory.
9. The computation device according to claim 8, wherein the first feature of the third input feature set is stored in a third storage region of the third memory, the second feature of the third input feature set is stored in a third storage region of the fourth memory, the third feature of the third input feature set is stored in a third storage region of the first memory, and the fourth feature of the third input feature set is stored in a third storage region of the second memory.
10. The computation device according to claim 9, wherein the first feature of the fourth input feature set is stored in a fourth storage region of the fourth memory, the second feature of the fourth input feature set is stored in a fourth storage region of the first memory, the third feature of the fourth input feature set is stored in a fourth storage region of the second memory, and the fourth feature of the fourth input feature set is stored in a fourth storage region of the third memory.
11. The computation device according to claim 6, wherein the buffer memory outputs the first features of the first to fourth input feature sets at the same time, during a first read operation.
12. The computation device according to claim 11, wherein the buffer memory outputs the second features of the first to fourth input feature sets at the same time, during a second read operation.
13. The computation device according to claim 12, wherein the buffer memory outputs the third features of the first to fourth input feature sets at the same time, during a third read operation,
14. The computation device according to claim 13, wherein the buffer memory outputs the fourth features of the first to fourth input feature sets at the same time, during a fourth read operation.
15. A system comprising: a host device configured to transfer first input data through a system bus; and a computation device configured to receive the first input data and perform a computation operation on the first input data, wherein the computation device comprises: a buffer configured to classify the first input data into first to nth input feature sets each having at least first to nth features and store the first to nth input feature sets, where n is an integer equal to or more than two; a buffer memory comprising first to nth memories, and configured to store the first to nth features of the first to nth input feature sets in the first to nth memories, wherein the first to nth features of one input feature set are divisionally stored in the first to nth memories; and a computation unit configured to receive the first to nth input feature sets stored in the buffer memory, and perform a computation operation on the first to nth input feature sets.
16. The system according to claim 15, wherein the buffer comprises n FIFO (First-In First-Out) circuits configured to store the first to nth input feature sets, respectively.
17. The system according to claim 15, wherein the buffer memory stores features having the same turn in the first to nth input feature sets, evenly in the first to nth memories.
18. The system according to claim 15, wherein each of the first to nth input feature sets further comprises an (n+1)th feature, wherein the buffer memory stores each (n+1)th feature of the first to nth input feature sets in the memories in which the first features of the first to nth input feature sets are stored, respectively.
19. The system according to claim 15, wherein the buffer memory outputs the features having the same turn in the first to nth input feature sets at the same time, during a single read operation.
20. The system according to claim 15, wherein the host device further transfers second input data through the system bus, and wherein the computation device further comprises a memory configured to store the second input data and output the second input data as weight data to the computation unit.
21. An operation method of a system, comprising: classifying first input data transferred from a host into first to nth input feature sets each having first to nth features to temporarily store the first to nth input feature sets, where n is an integer equal to or more than two; storing the first to nth features of the first to nth input feature sets in first to nth memories, wherein the first to nth features of one input feature set are divisionally stored in the first to nth memories, and features having the same turn in the first to nth input feature sets are stored evenly in the first to nth memories; outputting the features having the same turn in the first to nth input feature sets at the same time; and performing a computation operation on the outputted features of the first to nth input feature sets.
22. The operation method according to claim 15, wherein each of the first to nth memories includes a dual port SRAM (Static Random Access Memory), and wherein n FIFO (First-In First-Out) circuits are used to temporarily store the first to nth input feature sets.
</claims>
</document>
