<document>

<filing_date>
2018-03-23
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2018-03-23
</priority_date>

<ipc_classes>
G06K9/62,G06T7/246,G06T7/73
</ipc_classes>

<assignee>
NEC CORPORATION
</assignee>

<inventors>
AKIYAMA TATSUO
</inventors>

<docdb_family_id>
67988309
</docdb_family_id>

<title>
OBJECT TRACKING DEVICE, OBJECT TRACKING METHOD, AND OBJECT TRACKING PROGRAM
</title>

<abstract>
An object tracking device includes an image buffer configured to store a plurality of images included in a video, a detection part configured to detect an object position by executing a detection process with respect to an object reflected in the plurality of images, a tracking part configured to execute a tracking process with respect to a tracking-image string representing a scope of images ranging from an image producing an object-detection result and an image producing a next object-detection process, and an integration part configured to calculate an integrative object position by integrating a detection result and a tracking result. Herein, the scope of images is determined based on an execution timing or a termination timing of the detection process, thus executing the detection process and the tracking process in parallel.
</abstract>

<claims>
1. An object tracking device comprising: an image buffer configured to store a plurality of images included in a video; a detection part configured to detect an object position by executing a detection process with respect to an object reflected in the plurality of images; a tracking part configured to track the object among the plurality of images by executing a tracking process based on a detection result of the detection process; an integration part configured to calculate an integrative object position by integrating the detection result of the detection process and a tracking result of the tracking process; and a control part configured to execute the detection process and the tracking process in parallel upon determining a scope of the plurality of images in the video based on an execution timing or a termination timing of the detection process.
2. The object tracking device according to claim 1, further comprising a matching part configured to determine an object type by executing a matching process with respect to the object reflected in the plurality of images, wherein the integration part is configured to calculate the integrative object position with reference to a matching result of the matching process in addition to the detection result and the tracking result in association with the object type.
3. The object tracking device according to claim 1, further comprising a reverse tracking part configured to carry out a reverse tracking process in reverse chronological order conversely to the tracking process for the object reflected in the plurality of images, wherein the tracking result of the tracking process is corrected using a result of the reverse tracking process.
4. The object tracking device according to claim 2, wherein the tracking part is configured to assign an object-tracking identifier to the object, the matching part is configured to assign an object-type identifier to the object, and the integration part is configured to calculate the integrative object position upon associating the object-tracking identifier with the object-type identifier.
5. An object tracking method comprising: detecting an object position by executing a detection process with respect to an object reflected in a plurality of images included in a video; tracking the object among the plurality of images by executing a tracking process based on a detection result of the detection process; calculating an integrative object position upon integrating the detection result of the detection process and a tracking result of the tracking process; and determining a scope of the plurality of images in the video based on an execution timing or a termination timing of the detection process, thus executing the detection process and the tracking process in parallel.
6. The object tracking method according to claim 5, further comprising: determining an object type by executing a matching process with respect to the object reflected in the plurality of images, wherein the integrative object position is calculated with reference to a matching result of the matching process in addition to the detection result and the tracking result in association with the object type.
7. The object tracking method according to claim 5, further comprising: carrying out a reverse tracking process in reverse chronological order conversely to the tracking process of the object reflected in the plurality of images, wherein the tracking result of the tracking process is corrected using a result of the reverse tracking process.
8. An object tracking program comprising: detecting an object position by executing a detection process with respect to an object reflected in a plurality of images included in a video; tracking the object among the plurality of images by executing a tracking process based on a detection result of the detection process; calculating an integrative object position upon integrating the detection result of the detection process and a tracking result of the tracking process; and determining a scope of the plurality of images in the video based on an execution timing or a termination timing of the detection process, thus executing the detection process and the tracking process in parallel.
9. The object tracking program according to claim 8, further comprising: determining an object type by executing a matching process with respect to the object reflected in the plurality of images, wherein the integrative object position is calculated with reference to a matching result of the matching process in addition to the detection result and the tracking result in association with the object type.
10. The object tracking program according to claim 8, further comprising: carrying out a reverse tracking process in reverse chronological order conversely to the tracking process of the object reflected in the plurality of images, wherein the tracking result of the tracking process is corrected using a result of the reverse tracking process.
</claims>
</document>
