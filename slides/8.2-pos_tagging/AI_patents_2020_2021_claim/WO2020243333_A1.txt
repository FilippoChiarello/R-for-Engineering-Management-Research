<document>

<filing_date>
2020-05-28
</filing_date>

<publication_date>
2020-12-03
</publication_date>

<priority_date>
2019-05-30
</priority_date>

<ipc_classes>
G06K9/00,G06N99/00
</ipc_classes>

<assignee>
STATE UNIVERSITY OF NEW YORK
</assignee>

<inventors>
DMITRIEV, KONSTANTIN
KAUFMAN, ARIE
</inventors>

<docdb_family_id>
73553530
</docdb_family_id>

<title>
SYSTEM, METHOD, AND COMPUTER-ACCESSIBLE MEDIUM FOR GENERATING MULTI-CLASS MODELS FROM SINGLE-CLASS DATASETS
</title>

<abstract>
The exemplary system, method, and computer-accessible medium for generating a multiclass image segmentation model(s) can include receiving multiple single-class image datasets, receiving a target mask for each of the single-class image datasets, receiving a condition of an object associated with each of the single-class image datasets, and generating the multiclass image segmentation model(s) based on the single-class image datasets, the target masks, and the identification of the target objects. The single-class image datasets can include computer tomography images of abdominal organs. The single-class image datasets can be non-overlapping single-class image datasets. The single-class image datasets can include medical imaging datasets or cityscape datasets. The condition can include (i) an identification of a target object associated with each image in each single-class image dataset, (ii) a classification of each image associated with each single-class image dataset or (iii) an identifiable detail regarding each image in each single-class image datasets.
</abstract>

<claims>
1. A non-transitory computer-accessible medium having stored thereon computer-executable instructions for generating at least one multiclass image segmentation model, wherein, when a computer arrangement executes the instructions, the computer arrangement is configured to perform procedures comprising:
receiving multiple single-class image datasets;
receiving a target mask for each of the single-class image datasets;
receiving a condition of an object associated with each of the single-class image datasets; and
generating the at least one multiclass image segmentation model based on the singleclass image datasets, the target masks, and the identification of the target objects. 2. The computer-accessible medium of claim 1, wherein the single-class image datasets include computer tomography images of abdominal organs. 3. The computer-accessible medium of claim 1, wherein the single-class image datasets are non-overlapping single-class image datasets. 4. The computer-accessible medium of claim 1, wherein the single-class image datasets include medical imaging datasets or cityscape datasets. 5. The computer-accessible medium of claim 1, wherein the condition includes at least one of (i) an identification of a target object associated with each image in each single-class image dataset, (ii) a classification of each image associated with each single-class image dataset or (iii) an identifiable detail regarding each image in each single-class image datasets. 6. The computer-accessible medium of claim 1, wherein the target mask is a segmentation mask. 7. The computer-accessible medium of claim 1, wherein the computer arrangement is configured to generate the at least one multiclass image segmentation model using at least one convolutional neural network (CNN).
8. The computer-accessible medium of claim 7, wherein the computer arrangement is configured to generate the at least one multiclass image segmentation model using the condition as an input into the at least one CNN. 9. The computer-accessible medium of claim 7, wherein the computer arrangement is configured to generate the at least one multiclass image segmentation model using the condition in an encoder stage of the at least one CNN. 10. The computer-accessible medium of claim 9, wherein the encoder includes (i) at least one convolutional layer and (ii) at least six DenseBlock+MaxPooling layers. 11. The computer-accessible medium of claim 10, wherein a number of feature channels in each of the DenseBlock+MaxPooling layers is proportional to a depth of each of the
DenseBlock+MaxPooling layers. 12. The computer-accessible medium of claim 7, wherein the computer arrangement is configured to generate the at least one multiclass image segmentation model using the condition in a decoder stage of the at least one CNN. 13. The computer-accessible medium of claim 12, wherein the decoder includes (i) at least two convolutional layers and (ii) at least six Transposed Convolutions + DenseBlock layers. 14. The computer-accessible medium of claim 13, wherein the Transposed Convolutions include strides as upsampling layers. 15. The computer-accessible medium of claim 7, wherein the at least one CNN includes at least one skip connection. 16. The computer-accessible medium of claim 1, wherein the computer arrangement is configured to generate the at least one multiclass image segmentation model by training the at least one multiclass image segmentation model separately on (i) each class of the single-class image datasets, (ii) the target mask associated with each of the single-class image datasets, and (iii) the condition associated with each of the single-class image datasets.
17. The computer-accessible medium of claim 1, wherein the computer arrangement is further configured to obtain the condition from a lookup table containing an entry for each of the single-class image datasets. 18. The computer-accessible medium of claim 1, wherein the computer arrangement is further configured to:
receive a further single-class image dataset;
receive a further target mask for the further single-class image dataset;
receive a further condition associated with the further single-class image dataset; and update the at least one multiclass image segmentation model based on the further single-class image dataset, the further target mask, and the further condition. 19. A system for generating at least one multiclass image segmentation model, comprising: a computer hardware arrangement configured to:
receive multiple single-class image datasets;
receive a target mask for each of the single-class image datasets; receive a condition of an object associated with each of the single-class image datasets; and
generate the at least one multiclass image segmentation model based on the single-class image datasets, the target masks, and the identification of the target objects. 20. The system of claim 19, wherein the single-class image datasets include computer tomography images of abdominal organs. 21. The system of claim 19, wherein the single-class image datasets are non-overlapping single-class image datasets. 22. The system of claim 19, wherein the single-class image datasets include medical imaging datasets or cityscape datasets.
23. The system of claim 19, wherein the condition includes at least one of (i) an identification of a target object associated with each image in each single-class image dataset, (ii) a classification of each image associated with each single-class image dataset or (iii) an identifiable detail regarding each image in each single-class image datasets. 24. The system of claim 19, wherein the target mask is a segmentation mask. 25. The system of claim 19, wherein the computer hardware arrangement is configured to generate the at least one multiclass image segmentation model using at least one
convolutional neural network (CNN). 26. The system of claim 25, wherein the computer hardware arrangement is configured to generate the at least one multiclass image segmentation model using the condition as an input into the at least one CNN. 27. The system of claim 25, wherein the computer hardware arrangement is configured to generate the at least one multiclass image segmentation model using the condition in an encoder stage of the at least one CNN. 28. The system of claim 27, wherein the encoder includes (i) at least one convolutional layer and (ii) at least six DenseBlock+MaxPooling layers. 29. The system of claim 10, wherein a number of feature channels in each of the
DenseBlock+MaxPooling layers is proportional to a depth of each of the
DenseBlock+MaxPooling layers. 30. The system of claim 28, wherein the computer hardware arrangement is configured to generate the at least one multiclass image segmentation model using the condition in a decoder stage of the at least one CNN. 31. The system of claim 30, wherein the decoder includes (i) at least two convolutional layers and (ii) at least six Transposed Convolutions + DenseBlock layers.
32. The system of claim 31, wherein the Transposed Convolutions include strides as upsampling layers. 33. The system of claim 25, wherein the at least one CNN includes at least one skip connection. 34. The system of claim 19, wherein the computer hardware arrangement is configured to generate the at least one multiclass image segmentation model by training the at least one multiclass image segmentation model separately on (i) each class of the single-class image datasets, (ii) the target mask associated with each of the single-class image datasets, and (iii) the condition associated with each of the single-class image datasets. 35. The system of claim 19, wherein the computer hardware arrangement is further configured to obtain the condition from a lookup table containing an entry for each of the single-class image datasets. 36. The system of claim 19, wherein the computer hardware arrangement is further configured to:
receive a further single-class image dataset;
receive a further target mask for the further single-class image dataset;
receive a further condition associated with the further single-class image dataset; and update the at least one multiclass image segmentation model based on the further single-class image dataset, the further target mask, and the further condition. 37. A method for generating at least one multiclass image segmentation model, comprising: receiving multiple single-class image datasets;
receiving a target mask for each of the single-class image datasets;
receiving a condition of an object associated with each of the single-class image datasets; and
using a computer arrangement, generating the at least one multiclass image segmentation model based on the single-class image datasets, the target masks, and the identification of the target objects.
38. The method of claim 37, wherein the single-class image datasets include computer tomography images of abdominal organs. 39. The method of claim 37, wherein the single-class image datasets are non-overlapping single-class image datasets. 40. The method of claim 37, wherein the single-class image datasets include medical imaging datasets or cityscape datasets. 41. The method of claim 37, wherein the condition includes at least one of (i) an
identification of a target object associated with each image in each single-class image dataset, (ii) a classification of each image associated with each single-class image dataset or (iii) an identifiable detail regarding each image in each single-class image datasets. 42. The method of claim 37, wherein the target mask is a segmentation mask. 43. The method of claim 37, further comprising generating the at least one multiclass image segmentation model using at least one convolutional neural network (CNN). 44. The method of claim 43, further comprising generating the at least one multiclass image segmentation model using the condition as an input into the at least one CNN. 45. The method of claim 43, further comprising generating the at least one multiclass image segmentation model using the condition in an encoder stage of the at least one CNN. 46. The method of claim 45, wherein the encoder includes (i) at least one convolutional layer and (ii) at least six DenseBlock+MaxPooling layers. 47. The method of claim 46, wherein a number of feature channels in each of the
DenseBlock+MaxPooling layers is proportional to a depth of each of the
DenseBlock+MaxPooling layers.
48. The method of claim 43, further comprising generating the at least one multiclass image segmentation model using the condition in a decoder stage of the at least one CNN. 49. The method of claim 48, wherein the decoder includes (i) at least two convolutional layers and (ii) at least six Transposed Convolutions + DenseBlock layers. 50. The method of claim 49, wherein the Transposed Convolutions include strides as upsampling layers. 51. The method of claim 43, wherein the at least one CNN includes at least one skip connection. 52. The method of claim 37, further comprising generating the at least one multiclass image segmentation model by training the at least one multiclass image segmentation model separately on (i) each class of the single-class image datasets, (ii) the target mask associated with each of the single-class image datasets, and (iii) the condition associated with each of the single-class image datasets. 53. The method of claim 37, further comprising obtaining the condition from a lookup table containing an entry for each of the single-class image datasets. 54. The method of claim 37, further comprising:
receiving a further single-class image dataset;
receiving a further target mask for the further single-class image dataset;
receiving a further condition associated with the further single-class image dataset; and
updating the at least one multiclass image segmentation model based on the further single-class image dataset, the further target mask, and the further condition.
</claims>
</document>
