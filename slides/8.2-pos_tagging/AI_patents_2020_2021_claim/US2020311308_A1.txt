<document>

<filing_date>
2020-03-27
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-03-27
</priority_date>

<ipc_classes>
G06F21/62,G06N20/00
</ipc_classes>

<assignee>
PRIVACY ANALYTICS
</assignee>

<inventors>
EL EMAM, KHALED
Collins, Jordan Elijah
El Abidine, Khaldoun Zine
Arbuckle, Lon Michel Luk
</inventors>

<docdb_family_id>
70056970
</docdb_family_id>

<title>
SYSTEMS AND METHODS OF DATA TRANSFORMATION FOR DATA POOLING
</title>

<abstract>
A data anonymization pipeline system for managing holding and pooling data is disclosed. The data anonymization pipeline system transforms personal data at a source and then stores the transformed data in a safe environment. Furthermore, a re-identification risk assessment is performed before providing access to a user to fetch the de-identified data for secondary purposes.
</abstract>

<claims>
1. A method for providing a data anonymization pipeline, comprising: capturing raw confidential data at a data source; applying one or more transformation processes to the raw confidential data to remove unique data principals to thereby generate de-identified data; and transferring the de-identified data to a pool.
2. The method of claim 1 further including assessing a value of a risk that unique data principals remain in the de-identified data subsequent to application of the one or more transformation processes.
3. The method of claim 1 in which population statistics are generated for the pooled de-identified data according to one or more statistical models, and wherein the method further comprises receiving the generated population statistics as feedback to the one or more transformation processes, in which the feedback is utilized by the one or more transformation processes to increase accuracy of the de-identified data.
4. The method of claim 2 further including comparing the risk value against a predetermined threshold.
5. The method of claim 4 further including permitting or denying access to the pooled de-identified data based on a result of the comparing.
6. The method of claim 1 further including linking the pooled de-identified data across one of record, event, or common element.
7. The method of claim 6 in which the linking is provided as feedback to the one or more transformation processes to enable further de-identification.
8. One or more computer-readable media storing instructions which, when executed by one or more processors disposed in a computing device, cause the computing device to: receive de-identified data from one or more data custodians, each data custodian performing a first phase of de-identification by applying transformations to confidential data in custody to remove unique data principals in view of sample statistics that are applicable to the confidential data in custody; hold the received de-identified data in a pool; generate population statistics based on the pooled de-identified data; provide the generated population statistics as feedback to the one or more data custodians, in which the one or more data custodians adjust the transformations applied to the confidential data in custody to reduce re-identification risk to a first predetermined threshold; prior to publication from the pool of one or more subsets of de-identified data, perform a second phase of de-identification by applying transformations to the one or more subsets to reduce re-identification risk to a second predetermined threshold.
9. The one or more computer-readable storage media of claim 8 in which the de-identified data is received as one of a stream of data or as incremental data.
10. The one or more computer-readable storage media of claim 8 in which received de-identified data is encrypted using a cryptographic key.
11. The one or more computer-readable storage media of claim 10 in which the executed instructions cause the cryptographic key to be destroyed to thereby implement irreversible pseudonymization.
12. The one or more computer-readable storage media of claim 8 in which the executed instructions cause the computing device to expose mitigating controls configured to control one or more of access to the de-identified data, disclosure of the de-identified data, retention of the de-identified data, disposition of the de-identified data, or safeguarding of the de-identified data.
13. The one or more computer-readable storage media of claim 8 in which the executed instructions further cause the computing device to perform one of utilize frequency statistics in which measurements of distinct values for indirect identifiers are performed, or augment the frequency statistics with one or more of measures of correlation between indirect identifiers or pointwise mutual information.
14. The one or more computer-readable storage media of claim 8 in which the executed instructions further cause the computing device to link one or more of records, events, or common elements from the data custodians and use the linkages in the generated population statistics.
15. A computing device arranged as a data source, comprising: one or more processors; a network interface operably coupled to the one or more processors that provides access to a communications network; and one or more computer-readable storage media storing instructions which, when executed by the one or more processors, cause the computing device to integrate the data source into a data anonymization pipeline configured to provide non-identifiable data; perform clustering of identifying information in confidential data through application of a statistical model to thereby de-identify the confidential data; compare a risk of re-identification for each cluster through application of a statistical model against a threshold; adjust a cluster size responsively to the comparison of the risk of re-identification against the threshold to thereby improve the de-identification; and provide de-identified confidential data, over the communications network using the network interface, to a data pool in the data anonymization pipeline.
16. The computing device of claim 15 in which the identifying information comprise one of direct identifiers or indirect identifiers, the direct identifiers comprising one or more of name, address, gender, occupation, and contact information, and the indirect identifiers comprise one or more of demographic data and socio-economic data.
17. The computing device of claim 15 in which the executed instructions further cause the adjustment of cluster size to be implemented by applying one or more transformations to the confidential data.
18. The computing device of claim 17 in which a risk of re-identification is compared against a second threshold and one or more additional transformations are applied to de-identified data in the pool upon extraction from the pool.
19. The computing device of claim 15 in which the executed instructions further cause the clustering of identifying information to be performed using a machine learning model.
20. The computing device of claim 15 in which the executed instructions further cause the confidential data to be pseudonymized.
</claims>
</document>
