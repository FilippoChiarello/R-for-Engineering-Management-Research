<document>

<filing_date>
2017-12-19
</filing_date>

<publication_date>
2020-01-07
</publication_date>

<priority_date>
2017-12-19
</priority_date>

<ipc_classes>
A63B24/00,G06K9/00,G06K9/62,G06N3/04,G06N3/08,G06T7/246,G06T7/292
</ipc_classes>

<assignee>
CANON
</assignee>

<inventors>
MEHRSERESHT, NAGITA
</inventors>

<docdb_family_id>
66814587
</docdb_family_id>

<title>
System and method for detecting interaction
</title>

<abstract>
A system and method of detecting an interaction between a plurality of objects. The method comprises receiving tracking information for the plurality of objects in a scene; generating a plurality of frames, each of the plurality of frames comprising an activation for each of the plurality of objects and representing a relative spatial relationship between the plurality objects in the scene determined from the received tracking information, the frames encoding properties of the objects using properties of the corresponding activations; determining, using a trained neural network, features associated with the plurality of objects from the generated plurality of frames using the activations and the relative spatial relationship between the objects, the features representing changes in the relative spatial relationship between the objects over time relating to the interaction; and detecting time localization of the interaction in the plurality of frames using the determined features.
</abstract>

<claims>
1. A method of detecting an interaction between a plurality of objects, the method comprising: receiving tracking information for the plurality of objects in a scene, the tracking information tracking the objects over a period of time; obtaining properties of interest of the objects; converting locations of the plurality of objects at different times in the tracking information to corresponding locations in spatial representations; generating a temporal sequence of spatial representations from the tracking information as a sequence of frames, each of the frames comprising an activation for each of the plurality of objects and representing a relative spatial relationship between the plurality of objects in the scene based on the properties of the objects; generating, using a trained neural network, interaction scores associated with the sequence of objects frames over the time period from the generated sequence of frames using the activations and the relative spatial relationship between the objects, the interaction scores representing changes in the relative spatial relationship between the objects over time relating to the interaction; and detecting time localization of the interaction in the sequence of frames using the generated interaction scores.
2. The method according to claim 1, further comprising determining the tracking information of the plurality of objects from video data capturing the scene.
3. The method according to claim 1, wherein generating the sequence of frames comprises determining a mapping between video data of the scene and dimensions of the frames, and converting a location of each of the plurality of objects in the scene to a location in the dimensions of the frames.
4. The method of claim 3, wherein obtaining properties of interest of the objects comprises determining properties of each of the plurality of objects from the video data using an automated supervised search method.
5. The method according to claim 1, wherein determining the features associated with the plurality of objects relates to determining interaction scores associated with the plurality of frames over the time period.
6. The method according to claim 1, wherein detecting the time localisation comprises determining peaks in the interaction scores over a predefined threshold.
7. The method according to claim 1, further comprising classifying the interaction by determining a play agent of the interaction.
8. The method according to claim 7, wherein classifying the interaction further comprises determining attributes of the play agent.
9. The method according to claim 1, wherein the scene relates to a playing field, the plurality of objects relate to players of a team sport and a ball, and the interaction relates to interaction between the players and ball.
10. The method according to claim 1, further comprising generating an encoding for the properties of interest of the objects using properties of corresponding activations.
11. The method according to claim 10, wherein the properties of the plurality of objects are encoded using a size of the activation.
12. The method according to claim 10, wherein the properties of the plurality of objects are encoded using a shape of the activation.
13. The method according to claim 10, wherein the properties of the objects are encoded using a colour of the activation.
14. The method according to claim 10, wherein the sequence of frames are associated with a number of channels and the properties of the plurality of objects are encoded by mapping the corresponding activation to one or more of the channels.
15. The method according to claim 14, wherein the number of channels is three, represented by red, green and blue channels, such that the sequence of frames provides a visual representation of the plurality of objects, the visual representation being devoid of visual characteristics of the objects.
16. A method of detecting time localisation in an interaction between a plurality of objects, the method comprising: receiving tracking information for the plurality of objects in a scene, the tracking information tracking the objects over a time period; generating a temporal sequence of frames, each frame containing a visual representation of the received tracking information for each of the plurality of objects; generating, using a trained neural network, interaction scores associated with the interaction from the generated sequence of frames using pixel information representing the relative spatial relationship between the plurality of objects in the generated sequence of frames; and detecting time localization in the interaction between the plurality of objects in the sequence of frames using the generated interaction scores.
17. A non-transitory computer readable storage medium storing program instructions for performing the method according to claim 15.
18. Apparatus for detecting an interaction between a plurality of objects, comprising: a processor; and a memory device storing a software program for directing the processor to perform a method comprising the steps of: receiving tracking information for the plurality of objects in a scene, the tracking information tracking the objects over a period of time; obtaining properties of interest of the objects; converting locations of the plurality of objects at different times in the tracking information to corresponding locations in spatial representations; generating a temporal sequence of spatial representations from the tracking information as a sequence of frames, each of the frames comprising an activation for each of the plurality of objects and representing a relative spatial relationship between the plurality of objects in the scene based on the properties of the objects; generating, using a trained neural network, interaction scores associated with the sequence of frames over the time period from the generated sequence of frames using the activations and the relative spatial relationship between the objects, the interaction scores representing changes in the relative spatial relationship between the objects over time relating to the interaction; and detecting time localization of the interaction in the sequence of frames using the generated interaction scores.
19. A system comprising: a plurality of image capture devices for capturing video of a scene over a time period; a processor; and a memory device storing a software program for directing the processor to perform a method comprising the steps of: receiving the video data of the scene; determining tracking information for a plurality of objects in the scene from the video data, the tracking information tracking the objects over a period of time; obtaining properties of interest of the objects; converting locations of the plurality of objects at different times in the tracking information to corresponding locations in spatial representations; generating a temporal sequence of spatial representations from the tracking information as a sequence of frames, each of the frames comprising an activation for each of the plurality of objects and representing a relative spatial relationship between the plurality of objects in the scene based on the properties of the objects; generating, using a trained neural network, interaction scores associated with the sequence of frames over the time period from the generated sequence of frames using the activations and the relative spatial relationship between the objects, the interaction scores representing changes in the relative spatial relationship between the objects over time relating to the interaction; and detecting time localization of the interaction in the sequence of frames using the generated interaction scores.
</claims>
</document>
