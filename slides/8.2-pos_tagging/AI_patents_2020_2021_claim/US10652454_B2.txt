<document>

<filing_date>
2017-06-29
</filing_date>

<publication_date>
2020-05-12
</publication_date>

<priority_date>
2017-06-29
</priority_date>

<ipc_classes>
G06K9/00,H04N5/225,H04N5/232
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
BARROS, RUBERTH ANDRE AMARAL
BORREL, PAUL
BUORO, ALVARO BUENO
</inventors>

<docdb_family_id>
64738277
</docdb_family_id>

<title>
Image quality evaluation
</title>

<abstract>
A method of evaluating image quality includes capturing a first digital image of a target object using a first digital camera of a smart device. A second digital image of a user of the smart device is captured using a second digital camera of the smart device. The second digital image includes an image of the user's facial expression. A quality index is generated for the first digital image by analyzing one or more features of the second digital image. Analyzing the second digital image includes determining the user's sentiment. The quality index is then associated with the first digital image.
</abstract>

<claims>
1. A computer-implemented method of evaluating a quality level of a first digital image of a target object, comprising: generating the first digital image of the target object using a first digital camera of a smart device; generating a second digital image of a user of the smart device using a second digital camera of the smart device, wherein the second digital image is generated after the generation of the first digital image and includes an image of the user's facial expression when viewing the generated first digital image; generating a third digital image of the user using the second digital camera of the smart device, wherein the third digital image is generated prior to generating the first digital image; generating an assessment of an interaction between the user and the target object by analyzing the first digital image, the second digital image and the third digital image; generating a quality index for the first digital image by analyzing the user's sentiment related to the first digital image, wherein analyzing the user's sentiment related to the first digital image includes evaluating the user's facial expression in the second digital image; and associating the quality index with the first digital image to provide a quality level for the first digital image.
2. The computer-implemented method of claim 1, further comprising capturing an audio recording of the user, wherein capturing the audio recording of the user comprises recording the user's voice, and wherein the user's sentiment related to the first digital image is further analyzed using the audio recording of the user.
3. The computer-implemented method of claim 1, wherein the quality index is associated with the first digital image as metadata of the first digital image.
4. The computer-implemented method of claim 1, wherein the user's facial expression is captured as a video recorded for a first predetermined time period before capturing the first digital image and for a second predetermined time period after capturing the first digital image.
5. The computer-implemented method of claim 1, further comprising: receiving a query for identifying at least one first digital image of a plurality of first digital images, wherein the query includes a request to retrieve an image based on a corresponding quality index of the at least one first digital image of the plurality of first digital images; and identifying at least one first digital image of the plurality of first digital images based on the corresponding quality index associated with the at least one first digital image of the plurality of first digital images.
6. A method of evaluating a quality level of a first digital image of a target object, comprising: generating the first digital image of the target object using a first digital camera of a smart device; generating a second digital image of a user of the smart device using a second digital camera of the smart device, wherein the second digital image is generated after the generation of the first digital image and includes an image of the user's facial expression when viewing the generated first digital image; generating a third digital image of the user using the second digital camera of the smart device, wherein the third digital image is generated prior to generating the first digital image; determining if there was an interaction between the user and the target object by analyzing the first digital image, the second digital image and the third digital image; generating a quality index for the first digital image by analyzing the user's sentiment related to the first digital image, wherein analyzing the user's sentiment related to the first digital image includes evaluating the user's facial expression in the second digital image; and associating the quality index with the first digital image to provide a quality level for the first digital image.
7. The method of claim 6, further comprising capturing an audio recording of the user, wherein capturing the audio recording of the user comprises recording the user's voice, and wherein the user's sentiment related to the first digital image is further analyzed using the audio recording of the user.
8. The method of claim 6, wherein the user's facial expression is captured as a video recorded for a first predetermined time period before capturing the first digital image and for a second predetermined time period after capturing the first digital image.
9. The method of claim 8, further comprising: receiving a query for identifying at least one first digital image of a plurality of first digital images, wherein the query includes a request to retrieve an image based on a corresponding quality index of the at least one first digital image of the plurality of first digital images, and wherein the query includes a request to retrieve the image based on an identified interaction between the user and the target object; and identifying at least one first digital image of the plurality of first digital images based on the corresponding quality index associated with the at least one first digital image of the plurality of first digital images, and based on the identified interaction between the user and the target object.
10. The method of claim 9, further comprising displaying the identified at least one first digital image to the user.
11. A non-transitory computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processor to cause the processor to: generate a first digital image of a target object using a first digital camera of a smart device; generate a second digital image of a user of the smart device using a second digital camera of the smart device, wherein the second digital image is generated after the generation of the first digital image and includes an image of the user's facial expression when viewing the generated first digital image; generate a third digital image of the user using the second digital camera of the smart device, wherein the third digital image is generated prior to generating the first digital image; generate an assessment of an interaction between the user and the target object by analyzing the first digital image, the second digital image and the third digital image; generate a quality index for the first digital image by analyzing the user's sentiment related to the first digital image, wherein analyzing the user's sentiment related to the first digital image includes evaluating the user's facial expression in the second digital image; and associate the quality index with the first digital image.
12. The computer program product of claim 11, further comprising causing the processor to capture an audio recording of the user, wherein capturing the audio recording of the user comprises recording the user's voice, and wherein the user's sentiment related to the first digital image is further analyzed using the audio recording of the user.
13. The computer program product of claim 11, wherein the quality index is associated with the first digital image as metadata of the first digital image.
14. The computer program product of claim 11, wherein the user's facial expression is captured as a video recorded for a first predetermined time period before capturing the first digital image and for a second predetermined time period after capturing the first digital image.
15. The computer-implemented method of claim 11, further comprising causing the processor to: receive a query for identifying at least one first digital image of a plurality of first digital images, wherein the query includes a request to retrieve an image based on a corresponding quality index of the at least one first digital image of the plurality of first digital images; and identify at least one first digital image of the plurality of first digital images based on the corresponding quality index associated with the at least one first digital image of the plurality of first digital images.
</claims>
</document>
