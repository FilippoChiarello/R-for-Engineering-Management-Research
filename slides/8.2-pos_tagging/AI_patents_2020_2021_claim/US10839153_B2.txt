<document>

<filing_date>
2017-05-24
</filing_date>

<publication_date>
2020-11-17
</publication_date>

<priority_date>
2017-05-24
</priority_date>

<ipc_classes>
G06F17/21,G06F17/24,G06F17/27,G06F40/211,G06F40/253,G06F40/289,G06F40/35
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
KULKARNI, PRIYANKA SUBHASH
ZHANG, WENLEI
MENEZES, ERIKA DEBRA
GAUR, NAVEEN
</inventors>

<docdb_family_id>
64401513
</docdb_family_id>

<title>
Unconscious bias detection
</title>

<abstract>
The discussion relates to unconscious bias detection. One example can detect potential bias words in a text sample and suggest alternative phrasing to eliminate the potential bias words from the text sample.
</abstract>

<claims>
1. A system, comprising: storage storing computer-executable instructions for: obtaining text that includes words arranged as phrases or sentences; identifying unconscious bias candidate words from the text by determining that a gender-specific pro-form does not have a corresponding expression in the text that the gender-specific pro-form refers to; selecting a bias score for an individual unconscious bias candidate word from a table of known bias words and associated bias severities for the known bias words; determining a particular class from an ontological classification that the individual unconscious bias candidate word belongs to, the ontological classification including a plurality of classes and acceptable bias thresholds associated with the plurality of classes; determining a particular acceptable bias threshold associated with the determined particular class to which the individual unconscious bias candidate word belongs; in an instance when the bias score exceeds a flagging threshold and also exceeds the particular acceptable bias threshold, flagging the individual unconscious bias candidate word and suggesting one or more non-biased words that are gender-neutral to replace the individual unconscious bias candidate word; and presenting the flagged individual unconscious bias candidate word and the one or more non-biased words on a graphical user interface by displaying, in a first subset of the graphical user interface, a portion of the text containing the flagged individual unconscious bias candidate word and highlighting the flagged individual unconscious bias candidate word, and further displaying, in a second subset of the graphical user interface, a listing of suggested alternative language choices using the one or more non-biased words in association with the flagged individual unconscious bias candidate word, wherein selection of one of the suggested alternative language choices automatically replaces the flagged individual unconscious bias candidate word in the text; and, a processor that executes the computer-executable instructions.
2. The system of claim 1, embodied on a user device.
3. The system of claim 1, embodied on cloud-based resources.
4. The system of claim 1, wherein highlighting the flagged individual unconscious bias candidate word includes bolding the flagged individual unconscious bias candidate word.
5. The system of claim 1, wherein highlighting the flagged individual unconscious bias candidate word includes underlining the flagged individual unconscious bias candidate word.
6. The system of claim 1, wherein the listing of suggested alternative language choices is displayed in association with the flagged individual unconscious bias candidate word by being displayed in proximity to the flagged individual unconscious bias candidate word.
7. At least one computer-readable storage medium having instructions stored thereon that, when executed by a processor of a computing device, cause the computing device to perform acts, comprising: identifying a potential bias word that indicates a gender bias and relationships between the potential bias word and other words of user text based at least in part on determining that the potential bias word is a gender-specific pro-form that does not correspond to an expression in the other words of the user text that the gender-specific pro-form refers to; determining a bias score of the potential bias word by accessing a listing of bias words and associated bias scores; determining a particular class and a particular acceptable bias threshold from an ontological classification that the potential bias word belongs to, the ontological classification including a plurality of classes and acceptable bias thresholds associated with the plurality of classes; indicating when the bias score of the potential bias word exceeds the particular acceptable bias threshold by displaying, on a first subset portion of a graphical user interface, the potential bias word being highlighted and further displaying, on a second subset portion of the graphical user interface, a non-biased word alternative in association with the potential bias word, the non-biased word alternative being a gender-neutral word alternative; and replacing the potential bias word with the non-biased word alternative in the user text upon receiving a selection of the displayed non-biased word alternative via the graphical user interface of the computing device.
8. The at least one computer-readable storage medium of claim 7, wherein the determining the bias score comprises comparing the potential bias word to the listing of bias words.
9. The at least one computer-readable storage medium of claim 7, wherein the highlighting comprises bolding or underlining the potential bias word in the first subset portion of the graphical user interface.
10. The at least one computer-readable storage medium of claim 7, wherein the indicating comprises providing the non-biased word alternative to a user that generated the user text.
11. The at least one computer-readable storage medium of claim 7, wherein the indicating comprises providing an explanation to a user that generated the user text in a third subset portion of the graphical user interface.
12. The at least one computer-readable storage medium of claim 7, wherein the indicating comprises providing an explanation about the potential bias word in a third subset portion of the graphical user interface, and providing the non-biased word alternative to a user that generated the user text in the second subset portion of the graphical user interface.
13. The at least one computer-readable storage medium of claim 7, wherein the determining the bias score comprises comparing the potential bias word to a static listing of known bias words and a dynamic listing of known bias words.
14. The at least one computer-readable storage medium of claim 7, wherein the acts further comprise: removing one or more stop words from the user text; or stemming the potential bias word.
15. The at least one computer-readable storage medium of claim 7, wherein the acts further comprise: using a natural language processing module to extract syntactic features from the user text, wherein the syntactic features include parts of speech and/or co-references.
16. A method, comprising: identifying a gender-specific pro-form that does not have a corresponding expression in a text sample that the gender-specific pro-form refers to; determining a bias score for the gender-specific pro-form, the bias score indicating a severity of bias; determining a particular class from an ontological classification that the gender-specific pro-form belongs to, the ontological classification including a plurality of classes and bias thresholds associated with the plurality of classes; flagging the gender-specific pro-form as an unconscious bias word in response to determining that the bias score for the gender-specific pro-form exceeds a particular bias threshold associated with the particular class to which the gender-specific pro-form belongs; displaying a graphical user interface having first and second subset portions, the first subset portion displaying the unconscious bias word highlighted, and the second subset portion displaying a listing of suggested alternative phrasing to eliminate the unconscious bias word from the text sample, the listing of suggested alternative phrasing being displayed in association with the unconscious bias word, wherein the alternative phrasing is a gender-neutral phrasing that can be selected via the graphical user interface; and replacing the unconscious bias word with the alternative phrasing in the text sample upon receiving a selection of the alternative phrasing via the graphical user interface.
17. The method of claim 16, wherein identifying the gender-specific pro-form comprises evaluating words of the text sample and contexts of the unconscious bias word.
18. The method of claim 17, wherein the bias score for the gender-specific pro-form is determined based at least on the evaluating.
19. The method of claim 16, further comprising: looking up synonyms of the unconscious bias word to generate the listing of suggested alternative phrasing.
20. The method of claim 19, further comprising: scoring the synonyms based at least on similarity in meaning of the synonyms to the unconscious bias word and/or bias severities associated with the synonyms.
</claims>
</document>
