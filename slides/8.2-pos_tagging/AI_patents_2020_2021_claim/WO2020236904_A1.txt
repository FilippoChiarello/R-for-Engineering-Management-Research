<document>

<filing_date>
2020-05-20
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2019-05-21
</priority_date>

<ipc_classes>
G06N3/04,G06N3/10
</ipc_classes>

<assignee>
APPLE
</assignee>

<inventors>
SHARMA VINAY
ROSSI FRANCESCO
POULAIN BENJAMIN
SHI XIAOJIN
JAGADEESH VIGNESH
ZULIANI MARCO
</inventors>

<docdb_family_id>
73456902
</docdb_family_id>

<title>
MACHINE LEARNING MODEL WITH CONDITIONAL EXECUTION OF MULTIPLE PROCESSING TASKS
</title>

<abstract>
A method includes receiving input data at a trained machine learning model that includes a common part and task-specific parts, receiving an execution instruction that identifies one or more processing tasks to be performed, processing the input data using the common part of the trained machine learning model to generate intermediate data, and processing the intermediate data using one or more of the task-specific parts of the trained machine learning model based on the execution instruction to generate one or more outputs.
</abstract>

<claims>
What is claimed is:
1. A method, comprising:
receiving input data at a trained machine learning model that includes a common part and task-specific parts;
receiving an execution instruction that identifies one or more processing tasks to be performed;
processing the input data using the common part of the trained machine learning model to generate intermediate data; and
processing the intermediate data using one or more of the task-specific parts of the trained machine learning model based on the execution instruction to generate one or more outputs.
2. The method of claim 1, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes evaluating a conditional instruction for each of the task-specific parts of the trained machine learning model to determine whether to initiate execution of each of the task-specific parts of the trained machine learning model.
3. The method of claim 1, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes causing execution of one or more of the task-specific parts of the trained machine learning model based on the execution instruction.
4. The method of claim 1, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes suppressing execution of one or more of the task-specific parts of the trained machine learning model based on the execution instruction.
5. The method of claim 1, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes loading only the one or more or the task-specific parts of the trained machine learning model that are identified by the execution instruction.
6. The method of claim 1, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes unloading at least some of the task-specific parts of the trained machine learning model.
7. The method of claim 1, further comprising:
defining a linear execution order including the common part of the trained machine learning model and the one or more of the task-specific parts of the trained machine learning model based on the execution instruction, wherein processing the input data using the common part of the trained machine learning model and processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model is performed according to the linear execution order.
8. The method of claim 1, wherein the one or more of the task-specific parts of the trained machine learning model include a first task-specific part of the trained machine learning model and a second task-specific part of the trained machine learning model, and processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes executing the first taskspecific part of the trained machine learning model and the second task-specific part of the trained machine learning model in series.
9. The method of claim 1, wherein the one or more of the task-specific parts of the trained machine learning model include a first task-specific part of the trained machine learning model and a second task-specific part of the trained machine learning model, and processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes executing the first taskspecific part of the trained machine learning model and the second task-specific part of the trained machine learning model in parallel.
10. A non-transitory computer-readable storage device including program instructions executable by one or more processors that, when executed, cause the one or more processors to perform operations, the operations comprising: receiving input data at a trained machine learning model that includes a common part and task-specific parts;
receiving an execution instruction that identifies one or more processing tasks to be performed;
processing the input data using the common part of the trained machine learning model to generate intermediate data; and
processing the intermediate data using one or more of the task-specific parts of the trained machine learning model based on the execution instruction to generate one or more outputs.
11. The non-transitory computer-readable storage device of claim 10, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes evaluating a conditional instruction for each of the task-specific parts of the trained machine learning model to determine whether to initiate execution of each of the task-specific parts of the trained machine learning model.
12. The non-transitory computer-readable storage device of claim 10, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes causing execution of one or more of the task-specific parts of the trained machine learning model based on the execution instruction and suppressing execution of one or more of the task-specific parts of the trained machine learning model based on the execution instruction.
13. A system, comprising:
a memory; and
a processor that is configured to execute instructions that are stored in the memory, wherein the instructions, when executed by the processor, cause the processor to:
receive input data at a trained machine learning model that includes a common part and task-specific parts;
receive an execution instruction that identifies one or more processing tasks to be performed;
process the input data using the common part of the trained machine learning model to generate intermediate data; and process the intermediate data using one or more of the task-specific parts of the trained machine learning model based on the execution instruction to generate one or more outputs.
14. The system of claim 13, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes evaluating a conditional instruction for each of the task-specific parts of the trained machine learning model to determine whether to initiate execution of each of the task-specific parts of the trained machine learning model.
15. The system of claim 13, wherein processing the intermediate data using the one or more of the task-specific parts of the trained machine learning model based on the execution instruction includes causing execution of one or more of the task-specific parts of the trained machine learning model based on the execution instruction and suppressing execution of one or more of the task-specific parts of the trained machine learning model based on the execution instruction.
</claims>
</document>
