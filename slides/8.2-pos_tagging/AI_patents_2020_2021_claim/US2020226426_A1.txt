<document>

<filing_date>
2020-03-26
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2020-03-26
</priority_date>

<ipc_classes>
G06K9/62,G06N3/08
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
JARQUIN ARROYO, JULIO
SCHOLL, KAY-ULRICH
</inventors>

<docdb_family_id>
71516714
</docdb_family_id>

<title>
DEVICE AND METHOF FOR TRAINING AN OBJECT DETECTION MODEL
</title>

<abstract>
A training device may include one or more processors configured to generate, using a data augmentation model, augmented sensor data for sensor data, the sensor data provided by a plurality of sensors, wherein the augmented sensor data comprise error states of one or more sensors of the plurality of sensors providing the sensor data, and to train an object detection model based on the augmented sensor data.
</abstract>

<claims>
1. A training device, comprising: one or more processors, configured to: generate, using a data augmentation model, augmented sensor data for sensor data, the sensor data provided by a plurality of sensors, wherein the augmented sensor data comprise error states of one or more sensors of the plurality of sensors providing the sensor data; and train an object detection model based on the augmented sensor data.
2. The training device of claim 1, wherein the error states comprise one or more of: weather conditions, an occlusion, sensor data noise, a sensor saturation, a sensor bias, a drift, and/or a scaling.
3. The training device of claim 1, wherein the object detection model comprises a plurality of feature extraction models, and wherein the one or more processors are configured to: determine, based on the plurality of feature extraction models, a plurality of features for the augmented sensor data; and train the object detection model based on the plurality of features.
4. The training device of claim 3, wherein the one or more processors are configured to train the object detection model by suppressing one or more selected features of the plurality of features.
5. The training device of claim 4, wherein the one or more selected features comprises all features associated to one or more selected sensors.
6. The training device of claim 4, wherein the one or more processors are configured to randomly select the one or more selected features of the plurality of features.
7. The training device of claim 1, wherein the sensor data comprise information about at least one object, wherein each sensor data item of the plurality of sensor data items comprises a plurality of elements, and wherein one or more elements of the plurality of elements are associated with the at least one object.
8. The training device of claim 7, wherein the object detection model comprises a plurality of feature extraction models, and wherein the one or more processors are configured to determine, based on the plurality of feature extraction models, a plurality of features for the augmented sensor data, and to train the object detection model based on the plurality of features, wherein the features describe the at least one object.
9. The training device of claim 8, wherein the one or more processors are configured to fuse the plurality of features to fused features, and to train the object detection model using the fused features.
10. The training device of claim 8, wherein the one or more processors are configured to train the object detection model by suppressing one or more selected features of the plurality of features, to fuse the plurality of features except for the selected features to fused features, and to train the object detection model using the fused features.
11. The training device of claim 9, wherein the one or more processors are configured to: generate, based on the object detection model, a class probability map using the fused features, wherein the class probability map comprises for each element of the plurality of elements of at least one sensor data item of the sensor data a probability of each class of a plurality of classes; and train the object detection model using the generated class probability map.
12. The training device of claim 11, the one or more processors are configured to: generate training data, wherein the training data comprise a training class for each element of the plurality of elements of the at least one sensor data item; train the object detection model using the generated training data and the generated class probability map.
13. The training device of claim 9, wherein the one or more processors are configured to: generate, based on the object detection model, at least one bounding box for at least one augmented sensor data item using the fused features, wherein the at least one bounding box comprises one or more elements of the one or more elements associated to the at least one object in the associated sensor data item; and train the object detection model using the at least one bounding box.
14. The training device of claim 13, wherein the one or more processors are configured to: generate training data, wherein the training data comprise at least one training bounding box, wherein the at least one training bounding box comprises each element of the one or more elements associated to the at least one object; train the object detection model using the generated training data and the generated at least one bounding box.
15. The training device of claim 10, wherein the one or more processors are configured to: generate, based on the object detection model, a class probability map using the fused features, wherein the class probability map comprises for each element of the plurality of elements of at least one sensor data item of the sensor data a probability of each class of a plurality of classes; generate, based on the object detection model, at least one bounding box for at least one augmented sensor data item using the fused features, wherein the at least one bounding box comprises one or more elements of the one or more elements associated to the at least one object in the associated sensor data item; and train the object detection model using the generated class probability map and the generated at least one bounding box.
16. The training device of claim 8, wherein the one or more processors are configured to: determine, based on the object detection model, a detection uncertainty of the at least one object; and train the object detection model using the determined detection uncertainty.
17. The training device of claim 16, wherein the one or more processors are configured to: generate training data, wherein the training data comprise information about the at least one object; determine a training detection uncertainty for the at least one object using the training data; train the object detection model using the determined training detection uncertainty and the determined detection uncertainty.
18. The training device of claim 1, wherein the object detection model comprises a neural network.
19. A device, comprising one or more processors, the one or more processors configured to: generate, using a data augmentation model, augmented sensor data for sensor data, the sensor data provided by a plurality of sensors, wherein the augmented sensor data comprise error states of one or more sensors of the plurality of sensors providing the sensor data; train an object detection model based on the augmented sensor data; generate training data using the trained object detection model; and train an additional model using the training data.
20. A computer program element comprising instructions which, when executed by one or more processors, cause the one or more processors to: generate, using a data augmentation model, augmented sensor data for sensor data, the sensor data provided by a plurality of sensors, wherein the augmented sensor data comprise error states of one or more sensors of the plurality of sensors providing the sensor data; and train an object detection model based on the augmented sensor data.
21. A computer-readable medium having instructions recorded thereon which, when executed by one or more processors, cause the one or more processors to: generate, using a data augmentation model, augmented sensor data for sensor data, the sensor data provided by a plurality of sensors, wherein the augmented sensor data comprise error states of one or more sensors of the plurality of sensors providing the sensor data; and train an object detection model based on the augmented sensor data; generate training data using the trained object detection model; and train an additional model using the training data.
</claims>
</document>
