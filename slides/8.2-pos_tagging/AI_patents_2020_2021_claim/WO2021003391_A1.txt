<document>

<filing_date>
2020-07-02
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2019-07-02
</priority_date>

<assignee>
INSURANCE SERVICES OFFICE
</assignee>

<inventors>
SINGH, MANEESH KUMAR
PRABHU, Ameya
DOGNIN, Charles
</inventors>

<docdb_family_id>
74065222
</docdb_family_id>

<title>
MACHINE LEARNING SYSTEMS AND METHODS FOR EVALUATING SAMPLING BIAS IN DEEP ACTIVE CLASSIFICATION
</title>

<abstract>
Machine learning systems and methods for evaluating sampling bias in deep active classification are provided. The system generates an acquisition function based on an uncertainty based query strategy. The system utilizes the Least Confidence and the Entropy uncertainty based query strategies. The system acquires at least one data sample from the input data based on the acquisition function. The input data can include, but is not limited to, large datasets widely utilized for text classification. The system labels the data sample via an oracle and generates a training dataset with the labeled data sample. The system generates a sequence of training datasets by sampling b queries from the input data, each of size K. The system evaluates an efficiency and bias of sample datasets obtained by different query strategies. The system also trains a network with the generated training dataset(s).
</abstract>

<claims>
What is claimed is:
1. A machine learning system for evaluating sampling bias in deep active text classification comprising:
a memory; and
a processor in communication with the memory, the processor:
generating an acquisition function based on an uncertainty-based query strategy,
selecting data samples from a pool of unlabeled data based on the generated acquisition function,
labeling the selected data samples,
generating a training dataset with the labeled data samples, and training a model with the generated training dataset, the training dataset being indicative of a compressed dataset of the pool of unlabeled data.
2. The system of Claim 1, wherein the processor:
generates a sequence of training datasets by sampling b queries from the pool of unlabeled data, each of size K, and
excludes an initially generated training dataset from the sequence of training datasets.
3. The system of Claim 2, wherein the processor determines an efficiency and bias of the sequence of training datasets ^ ^-·· — <¾ obtained by different uncertainty based query strategies .
4. The system of Claim 1, wherein the processor generates the acquisition function based on a Least Confidence uncertainty based query strategy computed with a single or ensemble model or an Entropy uncertainty based query strategy computed with a single or ensemble model.
5. The system of Claim 1, wherein the pool of unlabeled data comprises at least one of AG News (AGN), DBPedia (DBP), Amazon Review Polarity (AMZP), Amazon Review Full (AMZF), Yelp Review Polarity (YRP), Yelp Review Full (YRF), Yahoo Answers (YHA), and Sogou News (SGN).
6. The system of Claim 1, wherein the model is one of FastText.zip (FTZ) or Multinomial Naive Bayes (MNB) with term frequency-inverse document frequency (TFIDF).
7. A machine learning method for evaluating sampling bias in deep active text classification, comprising the steps of:
generating an acquisition function based on an uncertainty-based query strategy; selecting data samples from a pool of unlabeled data based on the generated acquisition function;
labeling the selected data samples;
generating a training dataset with the labeled data samples; and
training a model with the generated training dataset, the training dataset being indicative of a compressed dataset of the pool of unlabeled data.
8. The method of Claim 7, further comprising:
generating a sequence of training datasets by sampling b queries from the pool of unlabeled data, each of size K, and
excluding an initially generated training dataset from the sequence of training datasets.
9. The method of Claim 8, further comprising determining an efficiency and bias of the sequence of training datasets - <¾ obtained by different uncertainty based query strategies
10. The method of Claim 7, wherein the generating the acquisition function is based on a Least Confidence uncertainty based query strategy computed with a single or ensemble model or an Entropy uncertainty based query strategy computed with a single or ensemble model.
11. The method of Claim 7, wherein the pool of unlabeled data comprises at least one of AG News (AGN), DBPedia (DBP), Amazon Review Polarity (AMZP), Amazon Review Full (AMZF), Yelp Review Polarity (YRP), Yelp Review Full (YRF), Yahoo Answers (YHA), and Sogou News (SGN).
12. The method of Claim 7, wherein the model is one of FastText.zip (FTZ) or Multinomial Naive Bayes (MNB) with term frequency-inverse document frequency (TFIDF).
13. A non-transitory computer readable medium having instructions stored thereon for evaluating sampling bias in deep active text classification which, when executed by a processor, causes the processor to carry out the steps of:
generating an acquisition function based on an uncertainty-based query strategy; selecting data samples from a pool of unlabeled data based on the generated acquisition function;
labeling the selected data samples;
generating a training dataset with the labeled data samples; and
training a model with the generated training dataset, the training dataset being indicative of a compressed dataset of the pool of unlabeled data.
14. The non-transitory computer readable medium of Claim 13, the processor further carrying out the steps of:
generating a sequence of training datasets by sampling b queries from the pool of unlabeled data, each of size K, and
excluding an initially generated training dataset from the sequence of training datasets.
15. The non-transitory computer readable medium of Claim 14, the processor further carrying out the step of evaluating an efficiency and bias of the sequence of training datasets ·¾ <¾' · · · > ·¾ obtained by different uncertainty based query strategies
QSQ . - Q*.
16. The non-transitory computer readable medium of Claim 13, wherein the generating the acquisition function is based on a Least Confidence uncertainty based query strategy computed with a single or ensemble model or an Entropy uncertainty based query strategy computed with a single or ensemble model.
17. The non-transitory computer readable medium of Claim 13, wherein the pool of unlabeled data comprises at least one of AG News (AGN), DBPedia (DBP), Amazon Review Polarity (AMZP), Amazon Review Full (AMZF), Yelp Review Polarity (YRP), Yelp Review Full (YRF), Yahoo Answers (YHA), and Sogou News (SGN).
18. The non-transitory computer readable medium of Claim 13, wherein the model is one of FastText.zip (FTZ) or Multinomial Naive Bayes (MNB) with term frequencyinverse document frequency (TF-IDF).
</claims>
</document>
