<document>

<filing_date>
2019-12-19
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2018-12-19
</priority_date>

<ipc_classes>
G06K9/34,G06K9/62,G06N3/04,G06T7/00,G06T7/50,G06T7/90
</ipc_classes>

<assignee>
AQUIFI
</assignee>

<inventors>
HAYES, ROBERT
DAL MUTTO, CARLO
PERUCH, FRANCESCO
Ou, Alexander
</inventors>

<docdb_family_id>
71102913
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR JOINT LEARNING OF COMPLEX VISUAL INSPECTION TASKS USING COMPUTER VISION
</title>

<abstract>
A method for performing automatic visual inspection includes: capturing visual information of an object using a scanning system including a plurality of cameras; extracting, by a computing system including a processor and memory, one or more feature maps from the visual information using one or more feature extractors; classifying, by the computing system, the object by supplying the one or more feature maps to a complex classifier to compute a classification of the object, the complex classifier including: a plurality of simple classifiers, each simple classifier of the plurality of simple classifiers being configured to compute outputs representing a characteristic of the object; and one or more logical operators configured to combine the outputs of the simple classifiers to compute the classification of the object; and outputting, by the computing system, the classification of the object as a result of the automatic visual inspection.
</abstract>

<claims>
1. A method for performing automatic visual inspection, comprising: capturing visual information of an object using a scanning system comprising a plurality of cameras; extracting, by a computing system comprising a processor and memory, one or more feature maps from the visual information using one or more feature extractors; classifying, by the computing system, the object by supplying the one or more feature maps to a complex classifier to compute a classification of the object, the complex classifier comprising: a plurality of simple classifiers, each simple classifier of the plurality of simple classifiers being configured to compute outputs representing a characteristic of the object; and one or more logical operators configured to combine the outputs of the simple classifiers to compute the classification of the object; and outputting, by the computing system, the classification of the object as a result of the automatic visual inspection.
2. The method of claim 1, wherein the one or more feature extractors comprise one or more convolutional neural networks.
3. The method of claim 1, wherein the plurality of simple classifiers comprises one or more neural network.
4. The method of claim 3, wherein the plurality of simple classifiers comprises one or more support vector machines, and wherein at least one logical operation is configured to combine an output of the neural network and an output of the support vector machine.
5. The method of claim 1, wherein the plurality of simple classifiers comprises one or more regression model.
6. The method of claim 1, wherein the plurality of simple classifiers comprises one or more label-based classifier configured to perform on text detection.
7. The method of claim 1, wherein each simple classifier of the plurality of simple classifiers is configured by a corresponding threshold parameter of a plurality of threshold parameters, wherein the threshold parameters are jointly trained.
8. The method of claim 7, wherein the threshold parameters are jointly trained by: sampling a parameter space to select a plurality of sets of threshold parameters to configure the simple classifiers; computing a True Positive rate (TPr) and a False Positive rate (FPr) for each set of threshold parameters of the plurality of sets of threshold parameters by: configuring the complex classifier by configuring the simple classifiers based on the set of threshold parameters; and computing the TPr and the FPr for the configuration by supplying the configured complex classifier with a validation set of data; and identifying a Pareto front comprising best performing sets of configuration parameters in accordance with the TPr and FPr for each set of the sets of configuration parameters; and selecting a set of configuration parameters from the Pareto front in accordance with a rule set in accordance with a domain.
9. The method of claim 1 wherein the visual information comprises color images, grayscale images, or depth maps.
10. The method of claim 9, wherein the visual information comprises at least one depth map, wherein the at least one depth map is captured by a depth camera system of the plurality of cameras.
11. The method of claim 10, wherein the depth camera system comprises: a time-of-flight depth camera; a structured light depth camera; a stereo depth camera comprising: at least two color cameras; a stereo depth camera comprising: at least two color cameras; and a color projector; a stereo depth camera comprising: at least two infrared cameras; or a stereo depth camera comprising: at least two infrared cameras; an infrared projector; and a color camera.
12. The method of claim 10, wherein the plurality of simple classifiers comprises a classifier based on mathematical modeling of the depth map.
13. The method of claim 1, wherein a feature map of the one or more feature maps is provided as input to at least two of the plurality of simple classifiers.
14. The method of claim 1, wherein the classification of the object comprises an identification of a category of a plurality of categories of objects.
15. The method of claim 1, wherein the classification of the object comprises an identification of one or more properties of the object based on the visual information.
16. A visual inspection system comprising: a scanner system comprising a plurality of cameras; a computing system connected to the scanner system over a computer network, the computing system comprising a processor and memory storing instructions that, when executed by the processor, cause the processor to: control the scanner system to capture visual information of an object; extract one or more feature maps from the visual information using one or more feature extractors; classify, by the computing system, the object by supplying the one or more feature maps to a complex classifier to compute a classification of the object, the complex classifier comprising: a plurality of simple classifiers, each simple classifier of the plurality of simple classifiers being configured to compute outputs representing a characteristic of the object; and one or more logical operators configured to combine the outputs of the simple classifiers to compute the classification of the object; and output, by the computing system, the classification of the object as a result of an automatic visual inspection of the object.
17. The visual inspection system of claim 16, wherein the scanner system comprises at least one color camera.
18. The visual inspection system of claim 16, wherein the scanner system comprises at least one depth camera.
19. The visual inspection system of claim 16, further comprising a user device comprising a display device, the user device being configured to display: the classification of the object; and at least one characteristic of the object computed by at least one simple classifier of the plurality of simple classifiers.
20. The visual inspection system of claim 16, wherein the computing system is configured to control a conveyor system to redirect movement of the object in accordance with the classification.
</claims>
</document>
