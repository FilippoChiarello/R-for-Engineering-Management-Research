<document>

<filing_date>
2019-03-28
</filing_date>

<publication_date>
2020-01-23
</publication_date>

<priority_date>
2018-07-23
</priority_date>

<ipc_classes>
G06F13/16,G06F13/24
</ipc_classes>

<assignee>
SK HYNIX
</assignee>

<inventors>
KIM, SUN WOONG
LIM, EUI CHEOL
</inventors>

<docdb_family_id>
69163035
</docdb_family_id>

<title>
MEMORY SYSTEM
</title>

<abstract>
A memory system is disclosed, which relates to technology for an accelerator of a high-capacity memory device. The memory system includes a plurality of memories configured to store data therein, and a pooled memory controller (PMC) configured to perform map computation by reading the data stored in the plurality of memories and storing resultant data produced by the map computation in the plurality of memories.
</abstract>

<claims>
1. A memory system, comprising: a plurality of memories configured to store data therein; and a pooled memory controller configured to perform a map computation by reading input data from the plurality of memories and storing resultant data produced by performing the map computation in the plurality of memories.
2. The memory system according to claim 1, wherein the pooled memory controller includes: an interface configured to perform packet relay between at least one processor and at least one memory through a fabric network; and an accelerator configured to perform the map computation on the input data to produce the resultant data.
3. The memory system according to claim 2, wherein the interface is coupled to the accelerator through a plurality of channels and the accelerator receives the input data through the plurality of channels and provides the resultant data to the interface through the plurality of channels.
4. The memory system according to claim 3, wherein a number of links of the plurality of channels is higher than a number of links between the interface and any one of the processors.
5. The memory system according to claim 2, wherein the pooled memory controller is configured to receive a map computation request packet from the at least one processor through the interface.
6. The memory system according to claim 5, wherein the map computation request packet includes at least one of information about an address of the input data, information about a size of the input data, and information about an address to be used to store the resultant data.
7. The memory system according to claim 2, wherein the pooled memory controller is configured to transmit a map computation response packet to the at least one processor through the interface.
8. The memory system according to claim 2, wherein the pooled memory controller reads the input data from the plurality of memories, and transmits the read input data to the accelerator.
9. The memory system according to claim 2, wherein the interface receives the resultant data computed by the accelerator, and stores the received resultant data in the plurality of memories.
10. The memory system according to claim 2, wherein the pooled memory controller is configured to transmit an interrupt packet to the at least one processor through the interface in response to completion of the map computation.
11. The memory system according to claim 2, wherein the pooled memory controller reads the resultant data stored in the plurality of memories, and transmits the read resultant data to the at least one processor.
12. The memory system according to claim 2, wherein the pooled memory controller communicates with the one or more processors through a fabric network.
13. The memory system according to claim 1, wherein the pooled memory controller is configured to perform interleaving of data among the plurality of memories.
14. The memory system according to claim 1, wherein the pooled memory controller is configured to perform address remapping for the plurality of memories.
15. A memory system comprising: a fabric network coupled to at least one processor; and a pooled memory having a plurality of memories and a pooled memory controller, the pooled memory being configured to perform packet relay to the processor through the fabric network, and transmit data stored in at least one memory in response to a request from the processor, wherein the pooled memory controller is configured to perform off-loading of a map computation by reading input data stored in the at least one memory and storing in the at least one memory resultant data produced by the map computation.
16. The memory system according to claim 15, wherein the pooled memory controller includes: an interface configured to perform packet relay between the at least one processor and the pooled memory controller through the fabric network; and an accelerator configured to perform off-loading of the map computation by receiving the input data through the interface, performing the map computation on the input data, and storing the resultant data in the at least one memory through the interface.
17. The memory system according to claim 16, wherein the pooled memory controller receives a map computation request packet from the at least one processor through the interface, and transmits a map computation response packet to the at least one processor through the interface.
18. The memory system according to claim 16, wherein the pooled memory controller reads input data needed for the map computation from the at least one memory, transmits the read input data to the accelerator, and stores the resultant data produced by the accelerator in the at least one memory.
19. The memory system according to claim 16, wherein the pooled memory controller transmits an interrupt packet to the at least one processor through the interface in response to completion of the map computation, reads the resultant data stored in the at least one memory, and transmits the read resultant data to the at least one processor through the interface.
20. The memory system according to claim 15, wherein the pooled memory controller is configured to perform at least one of interleaving and address remapping for the at least one memory.
</claims>
</document>
