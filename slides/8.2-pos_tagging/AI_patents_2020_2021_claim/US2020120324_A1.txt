<document>

<filing_date>
2018-10-15
</filing_date>

<publication_date>
2020-04-16
</publication_date>

<priority_date>
2018-10-15
</priority_date>

<ipc_classes>
G06N3/08,G06T5/00,G06T5/20,H04N13/111,H04N13/122,H04N13/161
</ipc_classes>

<assignee>
CITY UNIVERSITY OF HONG KONG
</assignee>

<inventors>
KWONG, TAK WU SAM
ZHU, LINWEI
ZHANG, YUN
</inventors>

<docdb_family_id>
70161001
</docdb_family_id>

<title>
CONVOLUTIONAL NEURAL NETWORK BASED SYNTHESIZED VIEW QUALITY ENHANCEMENT FOR VIDEO CODING
</title>

<abstract>
Systems and methods which provide Convolutional Neural Network (CNN) based synthesized view quality enhancement for video coding are described. Embodiments may comprise an encoder configured for CNN based synthesized view quality enhancement configured to provide improved coding efficiency while maintaining synthesized view quality. Additionally or alternatively, embodiments may comprise a virtual viewpoint generator configured for CNN based synthesized view quality enhancement configured provide post-processing of the synthesized view at the decoder side to reduce the artifacts. CNN based synthesized view quality enhancement may, for example, be provided for 3D video coding to improve its coding efficiency, which can be utilized in 3D scenarios, such as 3DTV.
</abstract>

<claims>
1. A method for video coding configured for enhanced synthesized view quality, the method comprising: providing Convolutional Neural Network (CNN) based reference synthesized view enhancement logic having learned CNN models configured for considering geometric and compression distortions according to specific characteristics of synthesized views; and processing, by the CNN based reference synthesized view enhancement logic implementing one or more of the learned CNN models, input texture video data and depth video data by considering geometric and compression distortions according to characteristics of synthesized views of the input texture video data and depth video data to configure the input texture video data and depth video data for distortion elimination in a synthesized view.
2. The method of claim 1, wherein the processing of the input texture video data and depth video data by the CNN based reference synthesized view enhancement logic is formulated as an image restoration task for reconstructing latent distortion free synthesized images.
3. The method of claim 1, wherein the processing of the input texture video data and depth video data by the CNN based reference synthesized view enhancement logic provides a CNN based synthesized view quality enhancement changed distortion (Dn) with respect to processed texture video data and depth video data.
4. The method of claim 3, wherein the CNN based synthesized view quality enhancement changed distortion (Dn) is changed linearly with respect to an original Synthesized View Distortion Change (SVDC) (Ds) for the input texture video data and depth video data.
5. The method of claim 3, further comprising: replacing, in a View Synthesis Optimization (VSO) process, an original synthesized view from the input texture video data and depth video data with a reference synthesized view derived from the CNN based reference synthesized view enhancement logic.
6. The method of claim 5, further comprising: providing Lagrange multiplier logic configured for adapting the VSO process for use with respect to the CNN based synthesized view quality enhancement changed distortion; and processing, by the Lagrange multiplier logic, video data output by the CNN based reference synthesized view enhancement logic to derive a Rate Distortion (RD) cost function adapting the VSO process performed for depth coding performance optimization for using the CNN based synthesized view quality enhancement changed distortion.
7. The method of claim 6, wherein the processing video data output by the CNN based reference synthesized view enhancement logic comprises: adjusting a trade-off between synthesized view distortion and a coding bit in the RD cost function.
8. The method of claim 6, further comprising: providing texture and depth encoding logic for joint texture and depth encoding of texture video data and video depth data; and encoding, by the texture and depth encoding logic, video data output by the Lagrange multiplier logic to provide CNN based synthesized view quality enhancement encoded video data.
9. The method of claim 8, wherein the encoding of video data by the texture and depth encoding logic is in accordance with three dimensional extensions of High Efficiency Video Coding (3D HEVC).
10. The method of claim 8, wherein the CNN based synthesized view quality enhancement encoded video data is provided with improved coding efficiency while maintaining synthesized view quality.
11. The method of claim 10, wherein the improved coding efficiency comprises bit rate saving in terms of Peak-Signal-to-Noise Ratio (PSNR).
12. The method of claim 8, further comprising: providing CNN based post-processing logic having learned CNN models configured to remediate mixed distortions with both warping distortion and compression distortion; and processing, by the CNN based post-processing logic, texture video data and depth video data decoded from the CNN based synthesized view quality enhancement encoded video data to reduce artifacts in a synthesized view.
13. The method of claim 12, wherein the synthesized view comprises a cross synthesized view synthesized from the decoded CNN based synthesized view quality enhancement encoded video data.
14. A system for video coding configured for enhanced synthesized view quality, the system comprising: Convolutional Neural Network (CNN) based reference synthesized view enhancement logic having learned CNN models configured for considering geometric and compression distortions according to specific characteristics of synthesized views to provide distortion elimination in a synthesized view; and Lagrange multiplier logic, coupled to the CNN based reference synthesized view enhancement logic, configured for adapting a View Synthesis Optimization (VSO) process for use with respect to the distortion elimination in the synthesized view.
15. The system of claim 14, wherein the CNN based reference synthesized view enhancement logic implements one or more of the learned CNN models to process the input texture video data and depth video data by considering geometric and compression distortions according to characteristics of synthesized views of the input texture video data and depth video data to configure the input texture video data and depth video data for the distortion elimination in the synthesized view.
16. The system of claim 14, wherein processing by the CNN based reference synthesized view enhancement logic provides CNN based synthesized view quality enhancement changed distortion with respect to input texture video data and depth video data.
17. The system of claim 16, wherein the CNN based synthesized view quality enhancement changed distortion is changed linearly with respect to an original Synthesized View Distortion Change (SVDC) for the input texture video data and depth video data.
18. The system of claim 17, wherein the Lagrange multiplier logic processes video data output by the CNN based reference synthesized view enhancement logic to derive a Rate Distortion (RD) cost function adapting the VSO process performed for depth coding performance optimization for using the CNN based synthesized view quality enhancement changed distortion.
19. The system of claim 18, further comprising: texture and depth encoding logic for joint texture and depth encoding of texture video data and video depth data provided by the CNN based reference synthesized view enhancement logic and the Lagrange multiplier logic.
20. The system of claim 19, wherein the texture and depth encoding logic encodes video data output by the Lagrange multiplier logic to provide CNN based synthesized view quality enhancement encoded video data.
21. The system of claim 19, wherein the texture and depth encoding logic comprises a three dimensional extensions of High Efficiency Video Coding (3D HEVC) codec.
22. The system of claim 19, further comprising: CNN based post-processing logic having learned CNN models configured to remediate mixed distortions with both warping distortion and compression distortion.
23. The system of claim 22, wherein the CNN based post-processing logic processes texture video data and depth video data decoded from the CNN based synthesized view quality enhancement encoded video data to reduce artifacts in a synthesized view.
24. A method for video decoding configured for enhanced synthesized view quality, the method comprising: providing CNN based post-processing logic having learned Convolutional Neural Network (CNN) models configured to remediate mixed distortions with both warping distortion and compression distortion; and processing, by the CNN based post-processing logic, texture video data and depth video data decoded from encoded video data to reduce artifacts in a synthesized view.
25. The method of claim 24, wherein the encoded video data comprises CNN based synthesized view quality enhancement encoded video data.
26. The method of claim 25, further comprising: providing CNN based reference synthesized view enhancement logic having learned CNN models configured for considering geometric and compression distortions according to specific characteristics of synthesized views; processing, by the CNN based reference synthesized view enhancement logic implementing one or more of the learned CNN models, input texture video data and depth video data by considering geometric and compression distortions according to characteristics of synthesized views of the input texture video data and depth video data to configure the input texture video data and depth video data for distortion elimination in a synthesized view; providing Lagrange multiplier logic configured for adapting a View Synthesis Optimization (VSO) process for use with respect to the distortion elimination in the synthesized view; and processing, by the Lagrange multiplier logic, video data output by the CNN based reference synthesized view enhancement logic to derive a Rate Distortion (RD) cost function adapting the VSO process performed for depth coding performance optimization for using video data having the distortion elimination in the synthesized view; providing texture and depth encoding logic for joint texture and depth encoding of texture video data and video depth data; and encoding, by the texture and depth encoding logic, video data output by the Lagrange multiplier logic to provide the CNN based synthesized view quality enhancement encoded video data.
</claims>
</document>
