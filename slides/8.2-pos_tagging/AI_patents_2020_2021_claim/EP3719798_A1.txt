<document>

<filing_date>
2019-01-25
</filing_date>

<publication_date>
2020-10-07
</publication_date>

<priority_date>
2018-02-12
</priority_date>

<ipc_classes>
G10L17/02,G10L17/18,G10L25/24,G10L25/30
</ipc_classes>

<assignee>
ALIBABA GROUP
</assignee>

<inventors>
ZHOU, JUN
LI, Xiaolong
WANG, Zhiming
</inventors>

<docdb_family_id>
63192672
</docdb_family_id>

<title>
VOICEPRINT RECOGNITION METHOD AND DEVICE BASED ON MEMORABILITY BOTTLENECK FEATURE
</title>

<abstract>
Implementations of the present specification provide a voiceprint recognition method and device. The method includes: extracting a first spectral feature from speaker audio; inputting the speaker audio to a memory deep neural network (DNN), and extracting a bottleneck feature from a bottleneck layer of the memory DNN, where the memory DNN includes at least one temporal recurrent layer and the bottleneck layer, an output of the at least one temporal recurrent layer is connected to the bottleneck layer; forming an acoustic feature of the speaker audio based on the first spectral feature and the bottleneck feature; extracting an identity authentication vector corresponding to the speaker audio based on the acoustic feature; and performing speaker recognition by using a classification model and based on an identity authentication vector (i-vector).
</abstract>

<claims>
1. A voiceprint recognition method, comprising: extracting a first spectral feature from speaker audio; inputting the speaker audio to a memory deep neural network (DNN), and extracting a bottleneck feature from a bottleneck layer of the memory DNN, the memory DNN including at least one temporal recurrent layer and the bottleneck layer, an output of the at least one temporal recurrent layer being connected to the bottleneck layer, and the number of dimensions of the bottleneck layer being less than the number of dimensions of any other hidden layer in the memory DNN; forming an acoustic feature of the speaker audio based on the first spectral feature and the bottleneck feature; extracting an identity authentication vector corresponding to the speaker audio based on the acoustic feature; and performing speaker recognition by using a classification model and based on the identity authentication vector.
2. The method according to claim 1, wherein the first spectral feature comprises a Mel frequency cepstral coefficient (MFCC) feature, and a first order difference feature and a second order difference feature of the MFCC feature.
3. The method according to claim 1, wherein the at least one temporal recurrent layer comprises a hidden layer based on a long-short term memory (LSTM) model, or a hidden layer based on an LSTMP model, the LSTMP model being an LSTM model with a recurrent projection layer.
4. The method according to claim 1, wherein the at least one temporal recurrent layer comprises a hidden layer based on a feedforward sequence memory FSMN model, or a hidden layer based on a cFSMN model, the cFSMN model being a compact FSMN model.
5. The method according to claim 1, wherein inputting the speaker audio to a memory deep neural network (DNN) comprises: extracting a second spectral feature from a plurality of consecutive speech frames of the speaker audio, and inputting the second spectral feature to the memory DNN
6. The method according to claim 5, wherein the second spectral feature is a Mel scale filter bank (FBank) feature.
7. The method according to claim 1, wherein the forming an acoustic feature of the speaker audio comprises: concatenating the first spectral feature and the bottleneck feature to form the acoustic feature.
8. A voiceprint recognition device, comprising: a first extraction unit, configured to extract a first spectral feature from speaker audio; a second extraction unit, configured to: input the speaker audio to a memory deep neural network (DNN), and extract a bottleneck feature from a bottleneck layer of the memory DNN, the memory DNN including at least one temporal recurrent layer and the bottleneck layer, an output of the at least one temporal recurrent layer is connected to the bottleneck layer, and the number of dimensions of the bottleneck layer is less than the number of dimensions of any other hidden layer in the memory DNN; a feature concatenation unit, configured to form an acoustic feature of the speaker audio based on the first spectral feature and the bottleneck feature; a vector extraction unit, configured to extract an identity authentication vector corresponding to the speaker audio based on the acoustic feature; and a classification recognition unit, configured to perform speaker recognition by using a classification model and based on the identity authentication vector.
9. The device according to claim 8, wherein the first spectral feature extracted by the first extraction unit comprises a Mel frequency cepstral coefficient (MFCC) feature, and a first order difference feature and a second order difference feature of the MFCC feature.
10. The device according to claim 8, wherein the at least one temporal recurrent layer comprises a hidden layer based on a long-short term memory (LSTM) model, or a hidden layer based on an LSTMP model, the LSTMP model being an LSTM model with a recurrent projection layer.
11. The device according to claim 8, wherein the at least one temporal recurrent layer comprises a hidden layer based on a feedforward sequence memory FSMN model, or a hidden layer based on a cFSMN model, the cFSMN model being a compact FSMN model.
12. The device according to claim 8, wherein the second extraction unit is configured to: extract a second spectral feature from a plurality of consecutive speech frames of the speaker audio, and input the second spectral feature to the memory DNN
13. The device according to claim 12, wherein the second spectral feature is a Mel scale filter bank (FBank) feature.
14. The device according to claim 8, wherein the feature concatenation unit is configured to concatenate the first spectral feature and the bottleneck feature to form the acoustic feature.
15. A computer readable storage medium, wherein the medium stores a computer program, and when the computer program is executed on a computer, the computer is enabled to perform a method according to any one of claims 1 to 7.
16. A computing device, comprising a memory and a processor, wherein the memory stores executable code, and when the processor executes the executable code, a method according to any one of claims 1 to 7 is implemented.
</claims>
</document>
