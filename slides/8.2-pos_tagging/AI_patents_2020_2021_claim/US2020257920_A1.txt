<document>

<filing_date>
2019-09-12
</filing_date>

<publication_date>
2020-08-13
</publication_date>

<priority_date>
2019-02-11
</priority_date>

<ipc_classes>
G06K9/34,G06K9/46,G06T1/00,G16H10/60,G16H30/40
</ipc_classes>

<assignee>
INNOVACCER
</assignee>

<inventors>
SAXENA, MUDIT
ZALPURI, RIJUL
MAHESHWARI, ANKIT
KUMAR, KRISHNA
</inventors>

<docdb_family_id>
71945227
</docdb_family_id>

<title>
AUTOMATIC VISUAL DISPLAY OVERLAYS OF CONTEXTUALLY RELATED DATA FROM MULTIPLE APPLICATIONS
</title>

<abstract>
Systems and methods for automatic visual display overlays of contextually related data from multiple applications are provided. The method includes: capturing an image of at least a portion of a graphical user interface (GUI) of a first application visually displayed on a computerized display device; identifying at least one primary contextual data point within the captured image; searching for at least one secondary data point in at least a second application, wherein the at least one secondary data point is contextually relevant to the primary contextual data point; fetching the at least one secondary data point from the second application; and visually displaying a panel on the computerized display device concurrently with at least a portion of the GUI of the first application, wherein the panel includes the at least one secondary data point.
</abstract>

<claims>
1. A method for automatically overlaying computerized visual displays based on contextually related data from multiple applications, the method comprising the steps of: capturing an image of at least a portion of a graphical user interface (GUI) of a first application visually displayed on a computerized display device; identifying at least one primary contextual data point within the captured image, wherein the captured image is destroyed after identification of the at least one primary contextual data point; searching for at least one secondary data point in at least a second application, wherein the at least one secondary data point is contextually relevant to the primary contextual data point; fetching the at least one secondary data point from the second application; and visually displaying a panel on the computerized display device concurrently with at least a portion of the GUI of the first application, wherein the panel includes the at least one secondary data point.
2. The method of claim 1, wherein capturing the image of at least the portion of the GUI of the first application further comprises using a computer vision technique to capture a plurality of images over a period of time.
3. The method of claim 2, wherein the computer vision technique captures a plurality of images at predetermined intervals within the period of time.
4. The method of claim 1, wherein identifying the at least one primary contextual data point within the captured image further comprises at least one of: neural network-enabled optical character recognition; pixel comparison and matching; or feature extraction.
5. The method of claim 1, wherein the primary contextual data point further comprises at least one of: an identity, an ID number, a name, or a date of birth.
6. The method of claim 1, wherein the second application is a distinct computer program from the first application.
7. The method of claim 1, wherein at least one of searching for the at least one secondary data point in the second application or fetching the at least one secondary data point from the second application is done without a user logging into the second application.
8. The method of claim 1, wherein visually displaying the panel on the computerized display device concurrently with at least the portion of the GUI of the first application further comprises outsliding the panel from a side of the GUI, whereby the panel displays at least one visual feature and at least one actionable feature.
9. A computer-implemented system for automatically overlaying computerized visual displays based on contextually related data from multiple applications comprising: a processor of the computer-implemented system, the processor configured to execute the steps of: capture an image of at least a portion of a graphical user interface (GUI) of a first application visually displayed on a computerized display device; identify at least one primary contextual data point within the captured image, wherein the captured image is destroyed after identification of the at least one primary contextual data point; search for at least one secondary data point in at least a second application, wherein the at least one secondary data point is contextually relevant to the primary contextual data point; fetch the at least one secondary data point from the second application; and visually display a panel on the computerized display device concurrently with at least a portion of the GUI of the first application, wherein the panel includes the at least one secondary data point.
10. The computer-implemented system of claim 9, wherein capturing the image of at least the portion of the GUI of the first application further comprises using a computer vision technique to capture a plurality of images over a period of time.
11. The computer-implemented system of claim 10, wherein the computer vision technique captures a plurality of images at predetermined intervals within the period of time.
12. The computer-implemented system of claim 9, wherein identifying the at least one primary contextual data point within the captured image further comprises at least one of: neural network-enabled optical character recognition; pixel comparison and matching; or feature extraction.
13. The computer-implemented system of claim 9, wherein the primary contextual data point further comprises at least one of: an identity, an ID number, a name, or a date of birth.
14. The computer-implemented system of claim 9, wherein the second application is a distinct computer program from the first application.
15. The computer-implemented system of claim 9, wherein at least one of searching for the at least one secondary data point in the second application or fetching the at least one secondary data point from the second application is done without a user logging into the second application.
16. The computer-implemented system of claim 9, wherein visually displaying the panel on the computerized display device concurrently with at least the portion of the GUI of the first application further comprises outsliding the panel from a side of the GUI, whereby the panel displays at least one visual feature and at least one actionable feature.
17. A system for automatically overlaying computerized visual displays based on contextually related data from multiple, separate computerized applications, the system comprising: a computerized device having a graphical user interface (GUI) visually displaying a first application; a captured image of at least a portion of the GUI of the first application, wherein at least one primary contextual data point within the captured image is identified, wherein the captured image is destroyed after identification of the at least one primary contextual data point; at least one secondary data point in at least a second application, the second application separate from the first application, wherein the at least one secondary data point is contextually relevant to the primary contextual data point, wherein the at least one secondary data point is fetched from the second application; and a panel visually displayed on the GUI of the computerized device concurrently with at least a portion of the visually displayed first application, wherein the panel visually displays the at least one secondary data point.
18. The system of claim 17, wherein the at least one primary contextual data point within the captured image is identified using at least one of: neural network-enabled optical character recognition; pixel comparison and matching; or feature extraction.
19. The system of claim 17, wherein the panel visually displayed on the GUI concurrently with at least the portion of the first application further comprises a panel outslid from a side of the GUI, whereby the panel displays at least one visual feature and at least one actionable feature.
20. The system of claim 17, wherein the at least one primary contextual data point further comprises at least one of: an identity, an ID number, a name, or a date of birth, and the at least one secondary contextual data point further comprises electronic medical record (EMR) data associated with an individual associated with the identity, the ID number, the name, or the date of birth.
</claims>
</document>
