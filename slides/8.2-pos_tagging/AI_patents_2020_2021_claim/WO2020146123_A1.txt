<document>

<filing_date>
2019-12-20
</filing_date>

<publication_date>
2020-07-16
</publication_date>

<priority_date>
2019-01-11
</priority_date>

<ipc_classes>
G06K9/00,G06K9/32
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
CASHMAN, THOMAS JOSEPH
FITZGIBBON, ANDREW WILLIAM
SHEN, JINGJING
SHOTTON, JAMIE DANIEL JOSEPH
WOOD, ERROLL WILLIAM
</inventors>

<docdb_family_id>
71516100
</docdb_family_id>

<title>
DETECTING POSE USING FLOATING KEYPOINT(S)
</title>

<abstract>
In various examples there is an apparatus for detecting position and orientation of an object. The apparatus comprises a memory storing at least one frame of captured sensor data depicting the object. The apparatus also comprises a trained machine learning system configured to receive the frame of the sensor data and to compute a plurality of two dimensional positions in the frame. Each predicted two dimensional position is a position of sensor data in the frame depicting a keypoint, where a keypoint is a pre-specified 3D position relative to the object. At least one of the keypoints is a floating keypoint depicting a pre-specified position relative to the object, lying inside or outside the object's surface. The apparatus comprises a pose detector which computes the three dimensional position and orientation of the object using the predicted two dimensional positions and outputs the computed three dimensional position and orientation.
</abstract>

<claims>
1. An apparatus for detecting three dimensional position and orientation of an object, the apparatus comprising:
a memory storing at least one frame of captured sensor data depicting the object; a trained machine learning system configured to receive the frame of the sensor data and to compute a plurality of two dimensional positions in the frame, each predicted two dimensional position being of sensor data in the frame depicting a keypoint, where a keypoint is a pre-specified 3D position relative to the object, at least one of the keypoints being a floating keypoint depicting a pre-specified position relative to the object, lying inside or outside the object's surface;
a pose detector which computes the three dimensional position and orientation of the object using the predicted two dimensional positions and outputs the computed three dimensional position and orientation.
2. The apparatus of claim 1 comprising an object tracker for tracking position and orientation of the object from a stream of captured sensor data by using the trained machine learning system to predict two dimensional positions of the keypoints in each of a plurality of frames of the stream of captured sensor data.
3. The apparatus of claim 2 wherein the apparatus is configured to compute the three dimensional position and orientation of the object at a rate substantially equal to a frame rate at which the sensor data is captured.
4. The apparatus of any preceding claim wherein the trained machine learning system is a random decision forest.
5. The apparatus of any preceding claim wherein the trained machine learning system is a neural network.
6. The apparatus of any preceding claim wherein the trained machine learning system has been trained with frames of sensor data for which two dimensional positions of points depicting the keypoints are known.
7. The apparatus of any preceding claim wherein the trained machine learning system has been trained with frames of sensor data captured from real world objects having a physical marker extending from the object to denote a floating keypoint.
8. The apparatus of any preceding claim wherein the trained machine learning system has been trained with synthetic frames of sensor data generated by rendering from a 3D model of the object in different positions and orientations.
9. The apparatus of any preceding claim wherein the trained machine learning system has been trained with frames of sensor data depicting the object as partially occluded.
10. The apparatus of any preceding claim wherein there are at least four keypoints per frame and the pose detector is configured to compute the position and orientation using a closed form solution.
11. The apparatus of any preceding claim wherein there are a plurality of keypoints per frame and the pose detector is configured to compute the position and orientation by minimizing an energy function.
12. The apparatus of any preceding claim further comprising an articulated object tracker, for tracking position, orientation and additional parameters of the object, where the object is an articulated object, and wherein the computed three dimensional position and orientation is used to initialize a 3D model of the articulated object prior to fitting the frame of sensor data to the 3D model.
13. The apparatus of any preceding claim wherein the object is a hand and wherein the floating keypoint is spaced over the side of the hand opposite the palm and generally perpendicular to a center of mass of the hand.
14. The apparatus of any preceding claim wherein the object is a human body and wherein the floating keypoint is spaced in front of a torso of the body and generally perpendicular to a center of mass of the body.
15. A computer-implemented method of detecting three dimensional position and orientation of an object, the method comprising:
storing, at a memory, at least one frame of captured sensor data depicting the object;
using a trained machine learning system to compute a plurality of two dimensional positions in the frame, each predicted two dimensional position being of sensor data in the frame depicting a keypoint, where a keypoint is a pre-specified 3D position relative to the object, at least one of the keypoints being a floating keypoint depicting a pre-specified position relative to the object, lying inside or outside the object's surface;
computing the three dimensional position and orientation of the object using the predicted two dimensional positions and outputting the computed position and orientation.
</claims>
</document>
