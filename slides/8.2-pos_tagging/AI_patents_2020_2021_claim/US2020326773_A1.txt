<document>

<filing_date>
2019-04-09
</filing_date>

<publication_date>
2020-10-15
</publication_date>

<priority_date>
2019-04-09
</priority_date>

<ipc_classes>
G06F3/01,G06K9/00,H04N5/232,H04N5/247
</ipc_classes>

<assignee>
FOTONATION
</assignee>

<inventors>
BIGIOI, PETRONEL
STEC, PIOTR
</inventors>

<docdb_family_id>
72747865
</docdb_family_id>

<title>
SYSTEM FOR PERFORMING EYE DETECTION AND/OR TRACKING
</title>

<abstract>
This disclosure describes, in part, systems and techniques for performing eye tracking. For instance, a system may include a first imaging device that generates first image data. The system may then analyze the first image data to determine a location of a face of a user. Using the location, the system may cause an actuator to move from a first position to a second position in order to direct a second imaging device towards the face of the user. While in the second position, the second imaging device may generate second image data representing at least the face of the user. The system may then analyze the second image data to determine a gaze direction of the user. In some instances, the first imaging device may include a first field of view (FOV) that is greater than a second FOV of the second imaging device.
</abstract>

<claims>
1. A method comprising: generating, using a first imaging device having a first field of view, first image data representing a user; determining, using at least the first image data, a location of a face of the user; causing, based at least in part on the location, an actuator associated with a second imaging device having a second field of view smaller than the first field of view, to move the second imaging device from a first position to a second position; emitting, from a light source associated with the second imaging device, light to illuminate an area proximate the second field of view; generating, using the second imaging device, second image data representing at least an eye of the user; determining, using at least the second image data, a gaze direction of the user; and outputting data representing the gaze direction of the user.
2. The method as recited in claim 1, wherein determining the location of the face of the user comprises: analyzing the first image data using one or more algorithms associated with facial detection; determining, based at least in part on analyzing the first image data, that a portion of the first image data represents the face of the user; and determining, based at least in part on the portion of the first image data, the location of the face of the user relative to the second imaging device.
3. The method as recited in claim 1, wherein determining the gaze direction of the user comprises: analyzing the second image data using one or more algorithms associated with eye tracking; determining, based at least in part on analyzing the second image data, an eye position of the user; and determining, based at least in part on the eye position, the gaze direction of the user.
4. 4-5. (canceled)
6. The method as recited in claim 1, wherein: generating the first image data comprises generating, using the first imaging device, the first image data using a first frame rate; generating the second image data comprises generating, using the second imaging device, the second image data using a second frame rate; and the first frame rate is different than the second frame rate.
7. The method as recited in claim 1, wherein: generating the first image data comprises generating, using the first imaging device, the first image data at a first resolution; generating the second image data comprises generating, using the second imaging device, the second image data at a second resolution; and the second resolution is lower than the first resolution.
8. The method as recited in claim 1, further comprising determining the second position for the actuator based at least in part on the location of the face of the user and a position of the second imaging device relative to a position of the first imaging device.
9. A method comprising: generating, using a first imaging device having a first field of view, first image data representing a user; determining that a portion of the first image data represents a face of the user; causing, based at least in part on the portion of the first image data, an actuator associated with a second imaging device having a second field of view smaller than the first field of view, to move from a first position to a second position; emitting, from a light source associated with the second imaging device, light to illuminate an area proximate the second field of view; generating, using the second imaging device, second image data representing at least an eye of the user; determining, based at least in part the second image data, an eye position of the user; and outputting data associated with the eye position of the user.
10. The method as recited in claim 9, further comprising: determining, based at least in part on the portion of the first image data, a direction of the face of the user, wherein causing the actuator to move from the first position to the second position is based at least in part on the direction.
11. The method as recited in claim 9, further comprising: determining, based at least in part on the second image data, a gaze direction of the user, wherein the data associated with the eyes position of the user comprises data representing the gaze direction of the user.
12. (canceled)
13. The method as recited in claim 9, further comprising determining the second position for the actuator based at least in part on the portion of the first image data.
14. (canceled)
15. The method as recited in claim 9, wherein: generating the first image data comprises generating, using the first imaging device, the first image data using a first frame rate; generating the second image data comprises generating, using the second imaging device, the second image data using a second frame rate; and the first frame rate is different than the second frame rate.
16. The method as recited in claim 9, further comprising: generating, using the first imaging device, third image data representing the user; determining that a portion of the third image data represents the face of the user; causing, based at least in part on the portion of the third image data, the actuator associated with the second imaging device to move from the second position to a third position; generating, using the second imaging device, fourth image data representing at least the eye of the user; determining, based at least in part the fourth image data, an additional eye position of the user; and outputting additional data associated with the additional eye position of the user.
17. A system comprising: a first imaging device having a first field of view; a second imaging device having a second field of view smaller than the first field of view; a light source associated with the second imaging device; an actuator for positioning the second imaging device; one or more processors; and one or more computer-readable media storing instructions that, when executed by the one or more processors, cause the one or more processors to perform operations comprising: generating, using the first imaging device, first image data representing a user; determining, using the first image data, a location of a face of the user; causing, based at least in part on the location, the actuator to move from a first position to a second position; emitting, from the light source associated with the second imaging device, light to illuminate an area proximate the second field of view; generating, using the second imaging device, second image data representing at least an eye of the user; determining, using the second image data, at least one of an eye position or a gaze direction of the user; and outputting data representing at least the one of the eye position or the gaze direction of the user.
18. (canceled)
19. The system as recited in claim 17, wherein: the first imaging device includes a first resolution; the second imaging device includes a second resolution; and the second resolution is lower than the first resolution.
20. (canceled)
21. The method of claim 1, wherein the light source associated with the second imaging device comprises an infrared light source.
22. The method of claim 1, wherein the emitting comprises emitting light from the light source associated with the second imaging device to illuminate a limited area proximate the second field of view and smaller than the first field of view.
23. The method of claim 1, wherein determining the gaze direction of the user comprises: detecting a corneal reflection of the light emitted from the light source; and determining a center of the corneal reflection.
24. The system of claim 17, wherein the light source associated with the second imaging device comprises an infrared light source.
25. The system of claim 17, wherein the emitting comprises emitting light from the light source associated with the second imaging device to illuminate a limited area proximate the second field of view and smaller than the first field of view.
26. The system of claim 17, wherein determining the at least one of the eye position or the gaze direction of the user comprises: detecting a corneal reflection of the light emitted from the light source; and determining a center of the corneal reflection.
</claims>
</document>
