<document>

<filing_date>
2020-03-13
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-03-29
</priority_date>

<ipc_classes>
G01S13/72,G01S7/41,G06K9/62
</ipc_classes>

<assignee>
ROBIN RADAR FACILITIES
</assignee>

<inventors>
HAMMINGA, SIETE
WESTRA, Hylke Jurjen Lijsbert
PORTEGIJS, Bart
</inventors>

<docdb_family_id>
66041262
</docdb_family_id>

<title>
DETECTION AND CLASSIFICATION OF UNMANNED AERIAL VEHICLES
</title>

<abstract>
A method and system for real-time and automated detection and classification of aerial objects (102,106), such as e.g. UAVs (102,106), on a radar plot level from digital radar images (103.202), wherein the digital radar images (103,202) are created from radar return signals obtained by a conventional radar such as e.g. a continuous wave radar (e.g. FMCW radar), a phased-array radar, or a pulse radar, as opposed to using specialized micro-Doppler radars for classifying UAVs based on the Doppler effect created by the rotors or propellers of the UAVs (102,106). Further, the method and system allow for tracking the UAVs (102,106) based on the digital radar images (103.202).
</abstract>

<claims>
1. A computer-implemented method for classifying an aerial object (102, 106) represented on a digital radar image (103, 202), said aerial object (102, 106) being an aerial object that may pose a collision risk for air traffic (105), said method comprising: receiving at least one digital radar image (103, 202) originating from a radar system (201), said at least one digital radar image (103, 202) having a total area formed by individual pixels, said at least one digital radar image (103, 202) comprising a radar plot of said aerial object (102, 106) , selecting a sub-area (104, 208) of said total area, said subarea (104, 208) comprising said radar plot of said aerial object (102, 106), and subjecting said sub-area (104, 208) to a deep learning model (209) for determining whether said radar plot represents an aerial object belonging to one class of aerial objects.
2. A method according to claim 1, comprising: receiving a chronological series of said digital radar images (103, 202), concluding that said aerial object (102, 106) belongs to said one class when it is determined for a plurality of said digital radar images (103, 202) that the radar plot in the sub-areas (104, 208) of said plurality of said digital radar images (103, 202) subjected to said deep learning model (209) belongs to said one class.
3. A method according to any one of claims 1 to 2, comprising receiving a chronological series of said digital radar images (103, 202), wherein each of said digital radar images (103, 202) comprises a radar plot of said aerial object (102, 106), combining said radar plots of said aerial object (102, 106) into a sequence of radar plots of said aerial object (102, 106) , obtaining from said sequence of radar plots of said aerial object (102, 106) a track for said aerial object (102, 106), concluding that said track represents an aerial object belonging to said one class when it is determined for a plurality of said radar plots in said sequence that the radar plot subjected to said deep learning model (209) belongs to said one class.
4. A method according to any one of claims 1 to 3, comprising creating said at least one digital radar image (103, 202) from a signal received from a radar system (201) .
5. A method according to any one of claims 1 to 4 , wherein said radar system (201) comprises at least one of a phasedarray radar, a pulse radar, and a FMCW radar.
6. A method according to any one of claims 1 to 5, wherein said step of selecting a sub-area of said total area comprises applying a detection algorithm (207) to said at least one digital radar image (103, 202) for detecting and locating in said at least one digital radar image (103, 202) a radar plot of said aerial object (102, 106) .
7. A method according to claim 6, wherein said step of applying said detection algorithm (207) for detecting and locating said radar plot comprises filtering static clutter
(204) and dynamic clutter (203) .
8. A method according to any one of claims 1 to 7, comprising applying at least one of a distance correction (206), a static clutter filtration (216), and a long-term average correction
(205) to said at least one digital radar image (103, 202) , preferably only to said sub-area (104, 208) of said at least one digital radar image (103, 202), prior to applying said deep learning model (209) .
9. A method according to any one of claims 1 to 8, wherein said sub-area (104, 208) comprises a lesser number of pixels compared to said total area, preferably a substantially lesser number of pixels compared to said total area, more preferably said sub-area (104, 208) has a size of 32 by 32 pixels, most preferably said sub-area (104, 208) has a size of 16 by 16 pixels .
10. A method according to any of claims 1 to 9, wherein said subarea has a rectangular outline.
11. A method according to any one of claims 1 to 10, wherein said one class is a class of unmanned aerial vehicles (UAVs) .
12. A method according to any one of claims 1 to 11, wherein said deep learning model (209) is trained for classifying radar plots in sub-areas according to said one class.
13. A method according to any one of claims 1 to 12, wherein said deep learning model (209) is a trained deep learning model, preferably a trained deep learning model that has been trained by assigning to each of a plurality of sub-areas a label correctly indicating whether said radar plot represents said aerial object in said one class of aerial objects, and subjecting said plurality of correctly labelled sub-areas to said deep learning model (209) .
14. A method according to any one of claims 1 to 13, wherein said deep learning model (209) is a trained convolutional neural network, preferably a trained convolutional neural network that has been obtained by training a pre-trained convolutional neural network by assigning to each of a plurality of sub-areas a label correctly indicating whether said radar plot represents said aerial object in said one class of aerial objects, and subjecting said plurality of correctly labelled sub-areas to said pre-trained convolutional neural network.
15. A method according to any one of claims 1 to 14, wherein said step of selecting in said at least one digital radar image (103, 202) a sub-area (104, 208) of said total area comprises cutting out said sub-area (104, 208) from said digital radar image (103, 202) and generating an image cutout comprising said sub-area (104, 208) .
16. A computer system for classifying an aerial object (102, 106) represented on a digital radar image (103, 202), said aerial object (102, 106) being an aerial object that may pose a collision risk for air traffic (105), said computer system comprising a deep learning model (209) and a processor configured to: receive at least one digital radar image (103, 202) originating from a radar system (201), said at least one digital radar image (103, 202) having a total area formed by individual pixels, said at least one digital radar image (103, 202) comprising a radar plot of said aerial object (102, 106) , select a sub-area (104 , 208) of said total area, said subarea (104, 208) comprising said radar plot of said aerial object ( 102 , 106 ) , subject said sub-area (104, 208) to said deep learning model (209) on said computer system to thereby determine whether said radar plot represents an aerial object belonging to one class of aerial objects.
17. A computer system according to claim 16, wherein said deep learning model (209) is a trained deep learning model, preferably a deep learning model that has been trained by subjecting a plurality of correctly labeled sub-areas to said deep learning model (209) .
18. Use of the method according to any one of claims 1 to 15 or of the computer system of claim 16 or 17, to determine if an aerial object (102, 106) represented in a radar plot in a digital radar image (103, 202) is an unmanned aerial vehicle, in particular a small unmanned aerial vehicle, even more in particular a small unmanned aerial vehicle with one or more rotors .
</claims>
</document>
