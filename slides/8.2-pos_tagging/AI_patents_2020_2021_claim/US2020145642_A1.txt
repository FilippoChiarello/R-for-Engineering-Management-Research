<document>

<filing_date>
2019-11-08
</filing_date>

<publication_date>
2020-05-07
</publication_date>

<priority_date>
2017-06-02
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08,G06T5/50,H04N13/00,H04N13/156,H04N13/271,H04N13/395
</ipc_classes>

<assignee>
SHANGHAI TECH UNIVERSITY
</assignee>

<inventors>
YU, JINGYI
</inventors>

<docdb_family_id>
64454255
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR ESTIMATING DEPTH OF FIELD INFORMATION
</title>

<abstract>
A method and apparatus for extracting depth information from a focal stack is disclosed. The method may include processing the focal stack through a focus convolutional neural network (Focus-Net) to generate a plurality of feature maps, stacking the plurality of feature maps together, and fusing the plurality of feature maps by a plurality of first convolutional layers to obtain a depth image. The Focus-Net includes a plurality of branches, and each branch includes a downsampling convolutional layer having a different stride for downsampling the focal stack and a deconvolutional layer for upsampling the focal stack.
</abstract>

<claims>
1. A method for extracting depth information from a focal stack, comprising: processing the focal stack through a focus convolutional neural network (Focus-Net) comprising a plurality of branches to obtain a plurality of feature maps, each branch comprising a downsampling convolutional layer having a different stride for downsampling the focal stack and a deconvolutional layer for upsampling the focal stack; stacking the plurality of feature maps together; and fusing the plurality of feature maps by a plurality of first convolutional layers to obtain a depth image.
2. The method of claim 1, wherein the Focus-Net comprises a parametric rectified linear unit (PreLU) layer.
3. The method of claim 1, wherein the Focus-Net comprises four branches.
4. The method of claim 1, further comprising: processing the focal stack through an extended depth-of-field convolutional neural network (EDoF-Net) to obtain an extended depth-of-field (EDoF) image.
5. The method of claim 4, wherein the EDoF-Net comprises a plurality of second convolutional layers and a PreLU layer.
6. The method of claim 4, further comprising: concatenating the depth image and the EDoF image; and fusing the depth image and the EDoF image using a plurality of third convolutional layers to refine the depth image.
7. A method for extracting depth information from a stereo image, comprising: processing the stereo image through a stereo convolutional neural network (Stereo-Net) to obtain a second depth image, the Stereo-Net comprising a plurality of rounds of a downsampling part and an upsampling part, wherein each downsampling part comprising a plurality of max pooling layers interleaved with a plurality of first residual modules, each upsampling part comprising a plurality of deconvolutional layers interleaved with a plurality of second residual modules.
8. The method of claim 7, wherein the downsampling part is connected to the upsampling part through a connection layer comprising a third residue module.
9. The method of claim 7, wherein the Stereo-Net comprises two rounds of downsampling part and upsampling part.
10. The method of claim 7, further comprising: processing a first focal stack through a focus convolutional neural network (Focus-Net) comprising a plurality of branches to obtain a plurality of feature maps, each branch comprising a downsampling convolutional layer having a different stride to downsample the focal stack and a deconvolutional layer configured to upsample the focal stack; stacking the plurality of feature maps together; and fusing the plurality of feature maps by a plurality of first convolutional layers to obtain a first depth image.
11. The method of claim 10, wherein the FocusNet comprises a PreLU layer.
12. The method of claim 10, wherein the FocusNet comprises four branches.
13. The method of claim 10, further comprising: processing the first focal stack and a second focal stack through an extended depth-of-field convolutional neural network (EDoF-Net) to obtain the stereo image comprising a first EDoF image and a second EDoF image.
14. The method of claim 10, further comprising: concatenating the first depth image and the first EDoF image; and fusing the first depth image and the first EDoF image using a plurality of third convolutional layers to refine the first depth image.
15. The method of claim 14, further comprising: concatenating the first depth image and the second depth image; and fusing the first depth image and the second depth image using a plurality of fourth convolutional layers to obtain a third depth image.
16. An apparatus for extracting depth information from a focal stack, comprising: a data capture unit comprising a first digital camera configured to generate a first focal stack; and a data processing unit comprising a processor and a memory, the memory embodying instructions that when executed by the processor cause the processor to: process the first focal stack through a focus convolutional neural network (Focus-Net) comprising a plurality of branches to obtain a plurality of feature maps, each branch comprising a downsampling convolutional layer having a different stride for downsampling the focal stack and a deconvolutional layer for upsampling the focal stack; stack the plurality of feature maps together; and fuse the plurality of feature maps by a plurality of first convolutional layers to obtain a first depth image.
17. The apparatus of claim 16, wherein the FocusNet comprises four branches.
18. The apparatus of claim 16, wherein the processor is further configured to: process the first focal stack through an extended depth-of-field convolutional neural network (EDoF-Net) to obtain a first EDoF image, the EDoF-Net comprising a plurality of second convolutional layers and a PreLU layer.
19. The apparatus of claim 18, wherein the processor is further configured to: concatenate the first depth image and the first EDoF image; and fuse the first depth image and the first EDoF image using a plurality of third convolutional layers to refine the first depth image.
20. The apparatus of claim 19, wherein the data capture unit comprises a second digital camera configured to generate a second focal stack.
21. The apparatus of claim 20, wherein the processor is further configured to: process the second focal stack through the extended depth-of-field convolutional neural network (EDoF-Net) to obtain a second EDoF image; and process the first EDoF image and the second EDoF image through a stereo convolutional neural network (Stereo-Net) to obtain a second depth image, the Stereo-Net comprising a plurality of rounds of a downsampling part and an upsampling part, wherein each downsampling part comprises a plurality of max pooling layers interleaved with a plurality of first residual modules, each upsampling part comprises a plurality of deconvolutional layers interleaved with a plurality of second residual modules.
22. The apparatus of claim 21, wherein the downsampling part is connected to the upsampling part through a connection layer comprising a third residue module.
23. The apparatus of claim 22, wherein the Stereo-Net comprises two rounds of downsampling part and upsampling part.
24. The apparatus of claim 22, wherein the processor is further configured to: concatenate the first depth image and the second depth image; and fuse the first depth image and the second depth image using a plurality of fourth convolutional layers to obtain a third depth image.
</claims>
</document>
