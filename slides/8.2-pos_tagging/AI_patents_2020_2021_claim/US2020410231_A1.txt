<document>

<filing_date>
2019-06-28
</filing_date>

<publication_date>
2020-12-31
</publication_date>

<priority_date>
2019-06-28
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06K9/72
</ipc_classes>

<assignee>
EYGS
</assignee>

<inventors>
DUFFY, NIGEL PAUL
CHUA, Freddy Chongtat
ISHKHANOV, Tigran
</inventors>

<docdb_family_id>
71670419
</docdb_family_id>

<title>
APPARATUS AND METHODS FOR EXTRACTING DATA FROM LINELESS TABLES USING DELAUNAY TRIANGULATION AND EXCESS EDGE REMOVAL
</title>

<abstract>
A method for extracting data from lineless tables includes storing an image including a table in a memory. A processor operably coupled to the memory identifies a plurality of text-based characters in the image, and defines multiple bounding boxes based on the characters. Each of the bounding boxes is uniquely associated with at least one of the text-based characters. A graph including multiple nodes and multiple edges is generated based on the bounding boxes, using a graph construction algorithm. At least one of the edges is identified for removal from the graph, and removed from the graph to produce a reduced graph. The reduced graph can be sent to a neural network to predict row labels and column labels for the table.
</abstract>

<claims>
1. A method, comprising: storing, in a memory, an image including a table; identifying, via a processor operably coupled to the memory, a plurality of text-based characters in the table; defining, via the processor, a plurality of bounding boxes based on the plurality of text-based characters, each bounding box from the plurality of bounding boxes uniquely associated with at least one text-based character from the plurality of text-based characters; generating, via the processor, a graph including a plurality of nodes and a plurality of edges, based on the bounding boxes, using a graph construction algorithm; identifying, via the processor, at least one edge from the plurality of edges for removal from the graph; removing the at least one edge from the graph, via the processor, to produce a reduced graph; and sending the reduced graph to a neural network to predict a plurality of row labels and a plurality of column labels for the table.
2. The method of claim 1, wherein the graph construction algorithm includes Delaunay triangulation.
3. The method of claim 1, wherein the generating the graph includes generating each node from the plurality of nodes based on a midpoint of an associated bounding box from the plurality of bounding boxes.
4. The method of claim 1, further comprising receiving, from the neural network, the predicted plurality of row labels and the predicted plurality of column labels for the table.
5. The method of claim 4, further comprising generating at least one format line for the table based on the predicted plurality of row labels and the predicted plurality of column labels.
6. The method of claim 1, wherein the neural network is a multilayer perceptron (MLP).
7. A method, comprising: receiving, at a processor, a scanned image including lineless formatted data; detecting, via optical character recognition (OCR), a plurality of boundary boxes associated with the lineless formatted data; generating a graph based on the plurality of boundary boxes and using Delaunay triangulation, the graph including a plurality of edges, each edge from the plurality of edges representing a relationship between exactly two boundary boxes from the plurality of boundary boxes; performing, via the processor, a first refinement of the graph to eliminate redundant representations of relationships, to produce a first refined graph; performing, via the processor, a second refinement of the first refined graph to remove a longest edge from each triangular region from a plurality of triangular regions produced by the Delaunay triangulation, to produce a second refined graph; and predicting row data and column data for the lineless formatted data using a neural network and based on the second refined graph.
8. The method of claim 7, further comprising generating at least one format line for the scanned image based on the predicted row data and column data.
9. The method of claim 7, wherein the predicting the row data and column data for the lineless formatted data includes predicting a row of the lineless formatted data based on a property of at least one horizontally-oriented edge from the plurality of edges.
10. The method of claim 7, wherein the predicting the row data and column data for the lineless formatted data includes predicting a column of the lineless formatted data based on a property of at least one vertically-oriented edge from the plurality of edges.
11. The method of claim 7, further comprising generating a pair of format classification labels for each edge from the plurality of edges based on the predicted row data and column data, each pair of format classification labels representing whether or not the two boundary boxes associated with that edge are in a common row or a common column.
12. The method of claim 7, further comprising generating format classification labels for each edge from the plurality of edges using statistical prediction, the format classification labels representing whether or not the two boundary boxes associated with that edge are in a common row or a common column.
13. The method of claim 7, further comprising generating format classification labels for each edge from the plurality of edges based at least on a length of that edge.
14. The method of claim 7, further comprising generating format classification labels for each edge from the plurality of edges based at least on a neighborhood of that edge, wherein the neighborhood is defined based on an overlap between that edge and another edge from the plurality of edges.
15. A method, comprising: obtaining, at a processor, a portable document format (PDF) file including formatted data; converting the PDF file, via the processor, to an image file; performing optical character recognition (OCR) on the image file, via the processor, to produce a scanned file; generating, via the processor, a plurality of character-level bounding boxes for the formatted data based on the scanned file; generating, via the processor, a plurality of word-level bounding boxes for the formatted data based on the PDF file, the plurality of character-level bounding boxes and the plurality of word-level bounding boxes forming a synthetic dataset, and training a neural network using the synthetic dataset.
16. The method of claim 15, further comprising: comparing the plurality of character-level bounding boxes to the plurality of word-level bounding boxes; generating a plurality of row labels for the formatted data based on the comparison of the plurality of character-level bounding boxes to the plurality of word-level bounding boxes; and generating a plurality of column labels for the formatted data based on the comparison of the plurality of character-level bounding boxes to the plurality of word-level bounding boxes.
17. The method of claim 15, further comprising predicting at least one of a row membership or a column membership for each word from a plurality of words associated with the word-level bounding boxes of the synthetic dataset, using a machine learning classifier.
18. The method of claim 15, further comprising generating a graph including a plurality of nodes and a plurality of edges, based on at least one of the plurality of character-level bounding boxes or the plurality of word-level bounding boxes, using a graph construction algorithm.
19. The method of claim 18, wherein the graph construction algorithm includes Delaunay triangulation.
20. The method of claim 15, further comprising: generating a graph including a plurality of nodes and a plurality of edges; and generating format classification labels for each edge from the plurality of edges based at least on a neighborhood of that edge, the neighborhood being defined based on an overlap between that edge and another edge from the plurality of edges.
</claims>
</document>
