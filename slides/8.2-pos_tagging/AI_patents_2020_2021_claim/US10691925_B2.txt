<document>

<filing_date>
2018-04-03
</filing_date>

<publication_date>
2020-06-23
</publication_date>

<priority_date>
2017-10-28
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06N5/04,G06T7/70
</ipc_classes>

<assignee>
ALTUMVIEW SYSTEMS
</assignee>

<inventors>
NG, HIM WAI
WANG, XING
LU, YE
MA, RUI
GAO, YU
</inventors>

<docdb_family_id>
66245571
</docdb_family_id>

<title>
Enhanced face-detection and face-tracking for resource-limited embedded vision systems
</title>

<abstract>
Embodiments described herein provide various examples of a real-time face-detection, face-tracking, and face-pose-selection subsystem within an embedded vision system. In one aspect, a process for identifying near-duplicate-face images using this subsystem is disclosed. This process includes the steps of: receiving a determined best-pose-face image associated with a tracked face when the tracked face is determined to be lost; extracting an image feature from the best-pose-face image; computing a set of similarity values between the extracted image feature and each of a set of stored image features in a feature buffer, wherein the set of stored image features are extracted from a set of previously transmitted best-pose-face images; determining if any of the computed similarity values is above a predetermined threshold; and if no computed similarity value is above the predetermined threshold, transmitting the best-pose-face image to a server and storing the extracted image feature into the feature buffer.
</abstract>

<claims>
1. A computer-implemented method for identifying near-duplicate face images and selectively transmitting best-pose-face images to a server, the method comprising: receiving a determined best-pose-face image associated with a tracked face when the tracked face is determined to be lost; extracting an image feature from the best-pose-face image; computing a set of similarity values between the extracted image feature and each of a set of stored image features in a feature buffer, wherein the set of stored image features are extracted from a set of previously transmitted best-pose-face images; determining if any of the computed similarity values is above a predetermined threshold; and if no computed similarity value is above the predetermined threshold, transmitting the best-pose-face image to a server; and storing the extracted image feature into the feature buffer.
2. The computer-implemented method of claim 1, wherein the tracked face is determined to be lost when the tracked face is blocked by an object for a predetermined number of video frames.
3. The computer-implemented method of claim 1, wherein the image feature is one of or a combination of: a histogram of oriented gradients (HoG) feature, a Harr-like feature, a scale-invariant-feature transform (SIFT)-feature, and a deep-learning-based face feature.
4. The computer-implemented method of claim 1, wherein the set of stored image features is the same type of feature as the extracted image feature.
5. The computer-implemented method of claim 1, wherein computing a similarity value between the extracted image feature and a stored image feature in the set of stored image features includes computing a cosine similarity between the extracted image feature and the stored image feature.
6. The computer-implemented method of claim 1, wherein if the image feature is a deep learning (DL)-based face feature, comparing the extracted image feature with the set of stored image features allows for determining if the tracked face is a duplicated face of a stored face of the same person but having a different pose from the stored face.
7. The computer-implemented method of claim 1, wherein if any of the computed similarity values is above the predetermined threshold, the method further comprises preventing transmitting the best-pose-face image to the server.
8. An embedded system capable of identifying near-duplicate-face images and selectively transmitting best-pose-face images to a server, the embedded system comprising: a processor; and a memory coupled to the processor, wherein the memory storing instructions that, when executed by the one or more processors, cause the system to: receive a determined best-pose-face image associated with a tracked face when the tracked face is determined to be lost; extract an image feature from the best-pose-face image; compute a set of similarity values between the extracted image feature and each of a set of stored image features in a feature buffer, wherein the set of stored image features are extracted from a set of previously transmitted best-pose-face images; determine if any of the computed similarity values is above a predetermined threshold; and if no computed similarity value is above the predetermined threshold, transmit the best-pose-face image to a server; and store the extracted image feature into the feature buffer.
9. The embedded system of claim 8, wherein the tracked face is determined to be lost when the tracked face is blocked by an object for a predetermined number of video frames.
10. The embedded system of claim 8, wherein the image feature is one or a combination of: a histogram of oriented gradients (HoG) feature, a Harr-like feature, a scale-invariant-feature transform (SIFT)-feature, and a deep-learning-based face feature.
11. The embedded system of claim 8, wherein computing a similarity value between the extracted image feature and a stored image feature in the set of stored image features includes computing a cosine similarity between the extracted image feature and the stored image feature.
12. The embedded system of claim 8, where if the image feature is a DL-based face feature, comparing the extracted image feature with the set of stored image features allows for determining if the tracked face is a duplicated face of a stored face of the same person but having a different pose from the stored face.
13. The embedded system of claim 8, wherein if any of the computed similarity values is above the predetermined threshold, the system prevents transmitting the best-pose-face image to the serve.
14. The embedded system of claim 8, wherein the embedded system is one of: a surveillance camera system, a machine vision system, a drone system, a robotic system, a self-driving vehicle, and a mobile device.
</claims>
</document>
