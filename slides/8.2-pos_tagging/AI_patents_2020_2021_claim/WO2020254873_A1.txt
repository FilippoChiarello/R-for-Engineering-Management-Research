<document>

<filing_date>
2020-06-15
</filing_date>

<publication_date>
2020-12-24
</publication_date>

<priority_date>
2019-06-17
</priority_date>

<ipc_classes>
A61F11/00,A61N1/05,A61N1/36,H04R25/00
</ipc_classes>

<assignee>
COCHLEAR
</assignee>

<inventors>
GILMOUR, JUSTIN
POPOVAC, IVANA
VON BRASCH, ALEXANDER
DAVIES, James
WADHWANI, Rishi
ZYGORDIMOS, Matthew
</inventors>

<docdb_family_id>
74040139
</docdb_family_id>

<title>
IMPROVING MUSICAL PERCEPTION OF A RECIPIENT OF AN AUDITORY DEVICE
</title>

<abstract>
Treatment actions can be taken based on an analysis of the ability of a recipient of an auditory prosthesis to perceive musical activities. The occurrence of musical activities and the recipient's response thereto can be determined based on transducers. The recipient's musical perception can be determined by analyzing the signals from the transducers as stand-alone measures or by comparing the signals against known music. The treatment actions can relate to the treatment of a hearing-impairment of the recipient of the auditory prosthesis, such as by modifying the settings of the auditory prosthesis to affect the ongoing operation of the auditory prosthesis.
</abstract>

<claims>
1. A computer-implemented process (200) comprising:
determining (210) an occurrence of a musical activity (10) proximate a recipient of an auditory device (110) using first transducer signals (162) from one or more first transducers (152);
determining (220) an indication (222) of the recipient's ability to perceive the musical activity (10) using second transducer signals (164) from one or more second transducers (154);
generating (230) an analysis (232) of the recipient's musical perception using the indication (222); and
taking (240) a treatment action (242) relating to the recipient based on the
analysis (232).
2. The computer-implemented process (200) of claim 1, wherein determining the occurrence of the musical activity (10) proximate the recipient of the auditory device (110) includes:
responsive to detecting (212) a musical data stream (214) provided to the auditory device (110) from a computing device (120), determining that the musical activity (10) occurred.
3. The computer-implemented process (200) of claim 1 or 2,
wherein determining (220) the indication (222) of the recipient's ability to perceive the musical activity (10) includes:
identifying (224) a repetitive behavior having a frequency as being a
musical behavior responsive to the frequency being within a typical musical tempo range; and
wherein the computer-implemented process (200) further comprises: responsive (226) to the repetitive behavior being identified as a musical behavior, determining that the indication (222) is that the recipient is able to perceive the musical activity (10).
4. The computer-implemented process (200) of any one of claims 1 -3, wherein the second transducer signals (164) include movement sensor signals.
5. The computer-implemented process (200) of claim 4, wherein the second transducer signals (164) further include microphone signals.
6. The process of any one of claims 1 -5, wherein taking (240) the treatment action (242) includes:
modifying (244) a treatment operation of the auditory device (110) by changing one or more settings of the auditory device (110).
7. A process comprising:
maintaining (310), at a server (170), a template (180) defining an association
between transducer signals (160) and musical perception;
receiving (320), at the server (170), recipient transducer signals (160) associated with a recipient of an auditory prosthesis (110);
using (330) the template (180) and the recipient transducer signals (160) to generate an analysis (232) of the recipient's musical perception; and
taking (340) a treatment action (242) relating to the auditory prosthesis based on the analysis (232).
8. The process of claim 7, wherein maintaining (310) the template (180) includes: generating or updating (312) the template using transducer signals (160) received from a plurality of individuals.
9. The process of claim 7 or 8,
wherein the template (180) includes a trained machine-learning framework (184) configured to receive the transducer signals (160) as input and provide an indication of an ability to perceive music as output; and
wherein using (330) the template (180) and the recipient transducer signals (160) to generate the analysis (232) includes:
providing (332) the recipient transducer signals (160) to the trained machine-learning framework (184) as input; and
receiving (334) an indication of the recipient's ability to receive music as output from the trained machine-learning framework (184).
10. The process of claim 9, wherein the trained machine-learning framework (184) includes a neural network.
11. The process of any one of claims 7-10,
wherein the template (180) includes a threshold (182); and
wherein using (330) the template (180) and the recipient transducer signals (160) to generate the analysis (232) includes:
comparing (336) the recipient transducer signals (160) to the
threshold (182); and
responsive (338) to the recipient transducer signals (160) satisfying the threshold (182), determining that the recipient is able to perceive music.
12. The process of any one of claims 7-11, wherein taking (240) the treatment action includes:
modifying (244) a treatment operation of the auditory prosthesis (110) by changing one or more settings of the auditory prosthesis (110).
13. A computer-implemented process comprising:
collecting (410) transducer signals (160) from one or more transducers (150) associated with a recipient of an auditory prosthesis (110);
generating (420) indications (222) of the recipient's musical perception using the transducer signals (160);
generating (430) an analysis (232) of the recipient's musical perception using the indications (222); and
taking (240) a treatment action (242) relating to the recipient using the
analysis (232).
14. The process of claim 13, wherein collecting (410) the transducer signals (160) from the one or more transducers (150) includes:
receiving movement sensor signals from one or more movement sensors;
receiving body noise sensor signals from an implanted microphone;
receiving implanted electrode sensor signals from an implanted electrode;
receiving external electrode sensor signals from an external electrode; or receiving external microphone signals from an external microphone.
15. The process of claim 14,
wherein collecting (410) the transducer signals (160) from one or more
transducers (150) includes:
receiving movement sensor signals from one or more movement sensors; and wherein receiving the movement sensor signals includes:
receiving accelerometer signals from an accelerometer of the auditory
prosthesis;
receiving gyroscope signals from a gyroscope of the auditory prosthesis; receiving accelerometer signals from an accelerometer of a mobile device of the recipient; or
receiving gyroscope signals from a gyroscope of a mobile device of the recipient.
16. The process of any one of claims 14 or 15, wherein generating (420) indications (222) of the recipient's ability to perceive music using the collected transducer signals (160) includes:
generating an indication of blood flow activity using the body noise sensor signals; generating an indication of respiratory activity using the body noise sensor signals; generating an indication of recipient voice activity using the body noise sensor signals;
generating an indication of brainstem activation using the implanted or external electrode sensor signals;
generating an indication of midbrain activation using the implanted or external electrode sensor signals;
generating an indication of cortical activation using the implanted or external
electrode sensor signals;
generating an indication of recipient voice activity using the external microphone signals;
generating an indication of head motion from the movement sensor signals; or generating an indication of hand motion from the movement sensor signals.
17. The process of any one of claims 13-16, wherein the treatment action (242) includes:
modifying one or more settings of the auditory prosthesis;
reporting a performance quality of the auditory prosthesis with respect to music; recommending corrective actions;
providing a metric estimating the recipient's ability to engage with music; or recommending one or more pieces of music relative to recipient's ability to engage with music and a musical preference of the recipient.
18. The process of any one of claims 13-17, wherein generating the analysis includes:
comparing the indications to one or more templates;
comparing the indications to features of a piece of music; and
comparing the indications to other indications taken from other individuals.
19. The process of any one of claims 13-18, wherein the analysis (232) includes at least one metric selected from the group of metrics consisting of:
a metric describing a number engagements with music;
a metric describing a rate of missed engagements; and
a metric describing an average grade of engagement.
20. The process of any one of claims 19, wherein the at least one metric is classified according to a quality selected from the group of qualities consisting of:
dominant musical frequencies;
a musical tempo;
a music volume; a music genre; and
a musical vocalist type.
21. A system (100) comprising: a server (170) comprising:
a processing unit (802)
a memory (804)
a template (180) stored in the memory (804) that defines an association between transducer signals (160) and musical perception; instructions (172) stored in the memory (804) that, when executed by the processing unit (802) cause the processer to:
receive (320), from an auditory prosthesis application (124),
recipient transducer signals (160) associated with a recipient of an auditory prosthesis (110);
generate (330) an analysis (232) of the recipient's musical
perception using the template (180) and the recipient transducer signals (160); and
take (340) a treatment action (242) relating to the auditory prosthesis based on the analysis (232).
22. The system (100) of claim 21, wherein the template (180) includes a trained machine-learning framework (184) configured to receive the recipient transducer signals (160) as input and provide an indication of an ability to perceive music as output.
23. The system (100) of claim 21, wherein taking (340) the treatment action (242) includes transmitting a settings modification to the auditory prosthesis application (124) for application to the auditory prosthesis (110).
24. The system (100) of claim 21, further comprising: the auditory prosthesis (110), wherein the auditory prosthesis (110) comprises a transceiver selected from the group consisting of: a gyroscope, an accelerometer, an implantable microphone, and an implantable electrode.
25. The system (100) of claim 21, further comprising: the auditory prosthesis application (124), wherein the auditory prosthesis
application (124) is stored in memory (804) of a computing device (120).
</claims>
</document>
