<document>

<filing_date>
2018-11-02
</filing_date>

<publication_date>
2020-10-29
</publication_date>

<priority_date>
2017-11-07
</priority_date>

<ipc_classes>
A01M21/04,A01M7/00,G06K9/00,G06N20/00,G06T7/70
</ipc_classes>

<assignee>
UNIVERSITY OF FLORIDA
</assignee>

<inventors>
SCHUMANN, ARNOLD W.
Boyd, Nathan S.
Yu, Jialin
</inventors>

<docdb_family_id>
66438601
</docdb_family_id>

<title>
Detection and Management of Target Vegetation Using Machine Vision
</title>

<abstract>
Various embodiments detect and manage target vegetation in vegetation areas, including crop beds, between crop beds, and turfgrasses. In one embodiment, a machine learning model is trained to detect target vegetation in captured images. An information processing system is programmed utilizing the machine learning model. One or more images of a particular area are captured, and target vegetation is detected within the one or more images. A position of the detected target vegetation is determined within the one or more images. An applicator disposed on an agrochemical applicator system that is mapped to the position of the detected target vegetation within the one or more images is determined. The applicator is activated based on a current speed of a vehicle coupled to the agrochemical applicator system, and further based on configuration data associated with the applicator. Activating the applicator selectively applies an agrochemical to the detected target vegetation.
</abstract>

<claims>
1. A system for detecting and managing target vegetation, the system comprising: a moveable entity; and an agrochemical applicator system mechanically coupled to the moveable entity, the agrochemical applicator system comprising: a computing device; an imaging system in data communication with the computing device; at least one applicator for applying an agrochemical to the target vegetation, the at least one applicator being in data communication with the computing device; and at least one application executable by the computing device, wherein when executed, the at least one application causes the computing device to at least: detect target vegetation within one or more images captured by the imaging system, the target vegetation being detected using a trained machine learning model; determine a position of the detected target vegetation within the one or more images; and activate the at least one applicator according to a current speed of the moveable entity, activating the at least one applicator selectively applies an agrochemical to the detected target vegetation.
2. The system of claim 1, further comprising a database, and wherein, when executed, the at least one application further causes the computing device to at least: store in the database at least one of: a date of application of the agrochemical to the detected target vegetation, a location of an application of the agrochemical to the detected target vegetation, the current speed, the one or more images, an amount of agrochemical used on the detected target vegetation, and identified object names within the one or more images.
3. The system of claim 2, further comprising a geographic information system (GIS), the GIS being configured to generate one or more maps associated with the targeted vegetation based at least in part on data stored in the database.
4. The system of claim 1, wherein the at least one applicator further comprises a plurality of applicators, and wherein, when executed, the at least one application causes the computing device to at least select a particular applicator from the plurality of applicators based at least in part on a location of the detected vegetation and a position of the particular applicator, activating the at least one applicator comprises activating the particular applicator.
5. The system of claim 1, wherein determining the position of the detected targeted vegetation is based at least in part on a location determining system data and pixel coordinates of the detected vegetation.
6. The system of claim 1, wherein the agrochemical applicator system further comprises one or more tanks holding the agrochemical.
7. The system of claim 1, wherein the one or more images are of a vegetation area comprising at least one of: a crop bed, an area between two crop beds, or turfgrass.
8. A method for detecting and managing target vegetation within a vegetation area, the method comprising: capturing one or more images of the vegetation area via an imaging device; detecting target vegetation within the one or more images; determining a position of the detected target vegetation within the one or more images; determining an applicator disposed on an agrochemical applicator system that is mapped to the position of the detected target vegetation within the one or more images; and activating the applicator based on a current speed of a vehicle coupled to the agrochemical applicator system, wherein activating the applicator selectively applies an agrochemical to the detected target vegetation.
9. The method of claim 8, wherein the vegetation area comprises at least one of turf grass, a crop bed, or an area between crop beds.
10. The method of claim 8, further comprising training a machine learning model to detect the target vegetation within the one or more images.
11. The method of claim 10, further comprising: programming an information processing system utilizing the machine learning model; and wherein the information processing system comprises one or more object detectors trained to identify the target vegetation within the one or more images and detect the target vegetation within the one or more images.
12. The method of claim 8, wherein activating the activator is further based at least in part on configuration data associated with the applicator.
13. The method of claim 12, wherein the configuration data comprises at least one of: a position of applicator relative to a position of the imaging device, a distance between the applicator and the imaging device, a dispensing angle of the applicator, a coverage area of the applicator, an actuation speed of the applicator, a field-of-view of the imaging device, a distance of the applicators from the ground, a location of the applicator on the agrochemical applicator system, or a mapping of the applicator to a portion of the field-of-view of the imaging device.
14. The method of claim 13, wherein the agrochemical applicator system comprises a motorized track, the applicator is coupled to the motorized track, and the configuration data further comprises at least one of: a speed of travel of the motorized track the applicator or a current position of the applicator on the track.
15. The method of claim 8, wherein the agrochemical applicator system comprises a global positioning system (GPS) module, and further comprising determining the speed of the vehicle via data obtained from the GPS module.
16. An agrochemical applicator system for detecting targeted vegetation, the agrochemical applicator system comprises: one or more applicators configured to dispense an agrochemical; an imaging system comprising at least one imaging device; and at least one application executable in a computing device, wherein, when executed, the at least one application causes the computing device to at least: detect target vegetation within one or more images utilizing a trained machine learning model, the one or more images being captured by the imaging system; determine a position of the detected target vegetation within the one or more images; determine that an applicator from the one or more applicators is mapped to the position of the detected target vegetation within the one or more images; and activating the applicator based at least in part on configuration data associated with the applicator, wherein activating the applicator selectively applies an agrochemical to the detected target vegetation.
17. The agrochemical applicator system of claim 16, wherein the agrochemical applicator system is coupled to a moveable vehicle, and activating the applicator is further based at least in part on a current speed of the moveable vehicle.
18. The agrochemical applicator system of claim 16, wherein, when executed, the at least one application further causes the computing device to at least train a machine learning model to detect target vegetation, the machine learning model being trained using training images of at least one of: a crop bed, an area between two crop beds, or turf grass.
19. The agrochemical applicator system of claim 16, further comprising a location determining system, the position of the detected target vegetation within the one or more images being determined based at least in part on based on data received from the location determining system.
20. The agrochemical applicator system of claim 16, further comprising a geographic information system (GIS), the GIS being configured to generate one or more maps associated with the targeted vegetation.
</claims>
</document>
