<document>

<filing_date>
2019-09-04
</filing_date>

<publication_date>
2020-12-29
</publication_date>

<priority_date>
2019-09-04
</priority_date>

<ipc_classes>
G06T17/20,G06T7/50,H04R5/033,H04S7/00
</ipc_classes>

<assignee>
FACEBOOK TECHNOLOGY COMPANY
</assignee>

<inventors>
Faundez Hoffmann, Pablo Francisco
Cho, Sang-Ik Terry
Mirbagheri, Majid
Ithapu, Vamsi Krishna
</inventors>

<docdb_family_id>
72243268
</docdb_family_id>

<title>
Personalized equalization of audio output using 3D reconstruction of an ear of a user
</title>

<abstract>
A method for generating an individualized audio output response for a headset based on a representation of a user's ear. One or more images of a portion of a user's head including at least the user's ear are received. A representation of the user's ear is generated based in part on the one or more images. A simulation of sound propagation from an audio source to the user's ear is performed based on the representation. An individualized audio output response is generated for the user based on the simulation, the individualized audio output response configured to adjust one or more acoustic parameters of audio content provided to the user by the headset.
</abstract>

<claims>
1. A method comprising: receiving an image including an ear of a user; generating a three-dimensional (3-D) representation of the ear of the user based in part on the received image; performing a simulation of sound propagation from an audio source to the ear of the user based on the 3-D representation, the simulating generating a simulated frequency response of audio output from the audio source at the ear of the user; and generating an equalization filter for the user based on a ratio between the simulated frequency response of audio output from the audio source at the ear of the user and a target frequency response, the equalization filter configured to adjust one or more acoustic parameters of audio content provided to the user.
2. The method of claim 1, wherein the user is wearing a headset in the image of the ear of the user, and wherein generating the 3-D representation of the ear of the user further comprises generating a 3-D representation that includes the headset.
3. The method of claim 1, wherein the audio source is a speaker array of a headset.
4. The method of claim 1, wherein generating the 3-D representation comprises processing the image of the ear of the user using a machine learning model to obtain the 3-D representation.
5. The method of claim 4, wherein the 3-D representation is generated using a principal component analysis (PCA) model describing the ear of the user as a combination of representative three-dimensional shapes of test subjects' ears.
6. The method of claim 5, wherein the PCA model is generated by: receiving ear images of test subjects and measured audio output responses of the test subjects; determining PCA-based 3-D representations of the test subjects' ear images based on an initial PCA model; performing simulation on the PCA-based 3-D representation to determine simulated audio output responses of the test subjects; determining differences between the simulated audio output responses and the measured audio output responses; generating, based on the determined differences, an updated PCA model by modifying the initial PCA model or by updating one or more intermediate PCA models derived from the initial PCA model; and determining the updated PCA model as the PCA model for representing the ear of the user when the determined differences is below a threshold.
7. The method of claim 6, further comprising: training the machine learning model using the ear images of the test subjects and PCA-based 3-D representations of the test subjects' ear images according to the PCA model.
8. The method of claim 1, wherein the image of the ear of the user is captured by a depth camera assembly of a headset.
9. The method of claim 1, wherein the generated 3-D representation comprises a three-dimensional mesh of the ear of the user.
10. The method of claim 1, further comprising: providing the generated equalization filter to a headset configured to employ the equalization filter to provide audio content to the user.
11. The method of claim 1, further comprising: providing the generated equalization filter to an online system, wherein the online system stores the generated equalization filter in association with an online profile of the user.
12. A non-transitory computer readable storage medium storing instructions thereon, the instructions when executed by a processor cause the processor to perform steps comprising: receiving an image including an ear of a user; generating a 3-D representation of the ear of the user based in part on the received image; performing a simulation of sound propagation from an audio source to the ear of the user based on the 3-D representation, the simulation generating a simulated frequency response of audio output from the audio source at the ear of the user; and generating an equalization filter for the user based on a ratio between the simulated frequency response of audio output from the audio source at the ear of the user and a target frequency response, the equalization filter adjusting one or more acoustic parameters of audio content provided to the user.
13. The non-transitory computer readable storage medium of claim 12, wherein the user is wearing a headset in the image of the ear of the user, and wherein generating the 3-D representation of the ear of the user further comprises generating a 3-D representation of the headset.
14. The non-transitory computer readable storage medium of claim 12, wherein the audio source is a speaker array of a headset.
15. The non-transitory computer readable storage medium of claim 12, wherein the simulation is based on one of a finite element method (FEM), a boundary element method (BEM), and a finite-difference time-domain (FDTD) method, and wherein the simulation of sound propagation from the audio source to the ear of the user simulates an audio output at the ear of the user.
16. The non-transitory computer readable storage medium of claim 12, the steps further comprising: providing the generated equalization filter to a headset configured to use the equalization filter to provide audio content to the user.
17. The non-transitory computer readable storage medium of claim 12, the steps further comprising: providing the generated equalization filter to an online system configured to append the generated equalization filter to an online profile of the user.
</claims>
</document>
