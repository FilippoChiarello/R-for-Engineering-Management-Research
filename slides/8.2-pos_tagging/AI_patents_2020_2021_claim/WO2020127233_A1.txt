<document>

<filing_date>
2019-12-17
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2018-12-20
</priority_date>

<ipc_classes>
A61B3/00,A61B3/10,A61B3/18,A61B5/00,G06K9/00,G06K9/62
</ipc_classes>

<assignee>
OPTOS
</assignee>

<inventors>
SWAN, DEREK
VAN HEMERT, JANO
</inventors>

<docdb_family_id>
64755198
</docdb_family_id>

<title>
DETECTION OF PATHOLOGIES IN OCULAR IMAGES
</title>

<abstract>
A computer-implemented method of searching for a region (410) indicative of a pathology in an image (400) of a portion of an eye acquired by an ocular imaging system (420), the method comprising: receiving (S10) image data defining the image; searching (S12) for the region in the image by processing the received image data using a learning algorithm; and in case a region in the image that is indicative of the pathology is found: determining (S14) a location of the region in the image; generating (S16) an instruction for an eye measurement apparatus to perform a measurement on the portion of the eye to generate measurement data, using a reference point based on the determined location for setting a location of the measurement on the portion of the eye; and receiving (S18) the measurement data from the eye measurement apparatus.
</abstract>

<claims>
1. A computer-implemented method of searching for a region (410) indicative of a pathology in an image (400) of a portion of an eye acquired by an ocular imaging system (520), the method comprising: receiving (S10) image data defining the image (400); searching (S12) for the region (410) in the image (400) by processing the received image data using a learning algorithm (530; 630) trained on image data (502; 604) defining images of the portion of healthy eyes, and image data (601, 602, 603; 501) defining images of the portion of unhealthy eyes each having at least one region that is indicative of the pathology; and in case a region (410) in the image (400) that is indicative of the pathology is found in the searching: determining (S14) a location of the region (410) in the image (400); generating (S16) an instruction for an eye measurement apparatus (300) to perform a measurement on the portion of the eye to generate measurement data, using a reference point based on the determined location for setting a location of the measurement on the portion of the eye; and receiving (S18) the measurement data from the eye measurement apparatus (300).
2. The computer-implemented method of claim 1, wherein searching (S12) for the region (410) in the image (400) comprises searching for a region (410) in the image (400) that is indicative of one of a plurality of different types of pathology by processing the received image data using the learning algorithm (630), the learning algorithm being trained on image data (601, 602, 603) defining images of the portion of unhealthy eyes each having a respective one of the different types of pathology, and in case a region (410) in the image (400) that is indicative of one of the plurality of different types of pathology is found in the searching (S12): the method further comprises selecting, for the one of the plurality of different types of pathology, a respective one of a plurality of different types of measurement modality for a measurement to be performed on the eye; and the method comprises generating (S16), as the instruction for the eye measurement apparatus (300) to perform the measurement on the portion of the eye, an instruction for an eye measurement apparatus (300) of the selected measurement modality to perform the measurement on the portion of the eye, using the reference point for setting the location of the measurement on the portion of the eye.
3. The computer-implemented method of claim 1, wherein the received image data is image data of a first imaging modality, the eye measurement apparatus (300) is configured to perform, as the measurement on the portion of the eye, an image capture process of a second imaging modality to image a region in the portion of the eye, and to acquire, as the measurement data, image data of the second imaging modality, the second imaging modality being different than the first imaging modality, and in the case that a region (410) in the image (400) that is indicative of the pathology is found in the searching (S12), the method comprises: generating (S16), as the instruction for the eye measurement apparatus (300) to perform the measurement on the portion of the eye, an instruction for the eye measurement apparatus (300) to perform the image capture process using the reference point for setting, as the location of the measurement, a location of a region in the portion of the eye to be imaged in the image capture process; and receiving (S18) from the eye measurement apparatus (300), as the measurement data, image data of the second imaging modality defining an image of the region in the portion of the eye.
4. The computer-implemented method of claim 3, wherein searching (S12) for the region (410) in the image (400) comprises searching for a region (410) in the image (400) that is indicative of one of a plurality of different types of pathology by processing the received image data using the learning algorithm (630), the learning algorithm being trained on the image data (601, 602, 603) defining images of the portion of unhealthy eyes each having a respective one of the different types of pathology, and in case a region (410) in the image (400) that is indicative of one of the plurality of different types of pathology is found in the searching (S12), the method further comprises selecting, for the one of the plurality of different types of pathology and as the second imaging modality, a respective one of a plurality of different types of imaging modality which is to be used to perform the image capture process on the portion of the eye.
5. The computer-implemented method of claim 4, wherein: in a case where the one of the plurality of different types of pathology is glaucoma, the method comprises generating (S16) an instruction for the eye measurement apparatus to perform, as the image capture process of the second imaging modality, an optical coherence tomography, OCT, scan of the region in the portion of the eye, and to acquire, as the measurement data, image data of the OCT scan; in a case where the one of the plurality of different types of pathology is severe diabetic retinopathy, the method comprises generating (S16) an instruction for the eye measurement apparatus to perform, as the image capture process of the second imaging modality, an optical coherence tomography, OCT, scan of a region of a retina of the eye, and to acquire, as the measurement data, image data of the OCT scan; in a case where the one of the plurality of different types of pathology is a tumour, the method comprises generating (S16) an instruction for the eye measurement apparatus to perform, as the image capture process of the second imaging modality, a high-density optical coherence tomography, OCT, B-scan of the region in the portion of the eye, and to acquire, as the measurement data, image data of the high-density OCT B-scan; in a case where the one of the plurality of different types of pathology is drusen, the method comprises generating (S16) an instruction for the eye measurement apparatus to perform, as the image capture process of the second imaging modality, an optical coherence tomography, OCT, B-scan of the region in the portion of the eye, and to acquire, as the measurement data, image data of the OCT B-scan; in a case where the one of the plurality of different types of pathology is oedema or atrophy, the method comprises generating (S16) an instruction for the eye measurement apparatus to perform, as the image capture process of the second imaging modality, an optical coherence tomography, OCT, scan of the region in the portion of the eye, and to acquire, as the measurement data, image data of the OCT scan.
6. The computer-implemented method of claim 1, wherein, in case the region (410) in the image (400) that is indicative of the pathology is found in the searching, the method comprises generating (S16), as the instruction for the eye measurement apparatus to perform the measurement on the portion of the eye, an instruction for the eye measurement apparatus to measure a functional response of the eye to light stimulation, using the reference point for setting the location of the measurement which is based on the determined location.
7. The computer-implemented method of claim 1, wherein the received image data represents a result of imaging the portion of the eye using a first value of an imaging parameter, the imaging parameter being one of an imaging resolution, an aperture size and wavelength used in the imaging, the eye measurement apparatus is configured to perform, as the measurement on the portion of the eye, an image capture process using a second value of the imaging parameter to image a region in the portion of the eye, and to acquire, as the measurement data, image data representing a result of imaging the region using the second value of the imaging parameter, wherein the second value of the imaging parameter is different from the first value of the imaging parameter, and the received image data and the acquired image data are of the same imaging modality, and in the case that a region (410) in the image (400) that is indicative of the pathology is found in the searching, the method comprises: generating (S16), as the instruction for the eye measurement apparatus to perform the measurement on the portion of the eye, an instruction for the eye measurement apparatus to perform the image capture process, using the reference point for setting, as the location of the measurement, a location of a region in the portion of the eye to be imaged in the image capture process; and receiving (S18) from the eye measurement apparatus, as the measurement data, the image data representing the result of imaging the region (410) in the portion of the eye using the second value of the imaging parameter.
8. The computer-implemented method of any one of claims 1 to 7, further comprising generating instructions for controlling a display unit (215) to display the location of the region (410) in the image (400) of the portion of the eye and a representation of the received measurement data.
9. The computer-implemented method of any one of claims 1 to 8, wherein the learning algorithm (530; 630) is a supervised learning algorithm.
10. The computer-implemented method of claim 9, wherein the supervised learning algorithm comprises a neural network, and the region (410) indicative of the pathology is searched for in the image (400) by deconstructing the neural network.
11. The computer-implemented method of claim 10, wherein the neural network is a convolutional neural network, and the neural network is deconstructed by: performing, for each of a plurality of different sections of the image (400) that is defined by the received image data, processes of: masking (S122) the section of the image (400) to generate a masked image; searching (S124) for the region in the masked image by processing image data defining the masked image using the learning algorithm; and determining (S126) a difference between a result of the search performed using the image data defining the masked image and a result of a search performed using the received image data; and determining (S128), as the location of the region (410) in the image (400), a location of a section for which the determined difference is largest.
12. The computer-implemented method of claim 10, wherein the neural network is a convolutional neural network, and the convolutional neural network is deconstructed by: determining a relevance of each input variable of the neural network to an output of the neural network by applying a Taylor decomposition to each layer of the neural network, from a top layer of the neural network to an input layer of the neural network; and determining the location of the region (410) in the image (400) based on at least one section of the received image data corresponding to the most relevant input variables of the neural network. IB. The computer-implemented method of claim 10, wherein the neural network is a convolutional neural network, and the convolutional neural network is deconstructed by determining a deconvolution of the convolutional neural network.
14. A computer-implemented method of searching for the presence of a pathology in an image (400) of a portion of an eye acquired by an ocular imaging system (520), the method comprising: receiving (S20) image data defining the image (400); searching (S22) for the presence of at least one of a plurality of different types of pathology in the image (400) by processing the received image data using a learning algorithm (630) trained on image data defining images (502) of healthy eyes, and images (601, 602, 603) of unhealthy eyes each having a respective one of the different types of pathology; and in case at least one of the plurality of different types of pathology is found to be present in the image (400): selecting (S24), for each of at least one type of pathology found to be present in the image (400), a respective one of a plurality of different types of measurement modality which is to be used to perform a measurement on the portion of the eye; generating (S26), for each of the at least one type of pathology found to be present in the image (400), a respective instruction for an eye measurement apparatus (300) of the respective selected measurement modality to perform the measurement on the portion of the eye; and receiving (S28) measurement data of the measurement performed by the eye measurement apparatus (300) of each selected measurement modality.
15. The computer-implemented method of claim 14, further comprising, in case at least one of the plurality of different types of pathology is found to be present in the image (400): for each of the at least one of the different types of pathology found to be present in the image, searching for a respective region (410) in the image (400) that is indicative of the respective type of pathology, by processing the received image data using the learning algorithm (630), and recording a location of the respective region (410) in the image (400), wherein a respective instruction for the eye measurement apparatus (300) of each selected measurement modality to perform a measurement on the eye using a reference point for locating the measurement which is based on the respective recorded location is generated.
16. The computer-implemented method of claim 15, wherein, in case at least one of the plurality of different types of pathology is found to be present in the image (400), for each of the at least one of the different types of pathology found to be present in the image (400): a respective one of a plurality of different types of imaging modality which is to be used to image the portion of the eye is selected as the respective one of the plurality of different types of measurement modality; a respective instruction for an eye measurement apparatus (BOO) of the selected imaging modality to image the portion of the eye, using a reference point for locating a region of the eye to be imaged which is based on the respective recorded location, is generated as the respective instruction for the eye measurement apparatus (300) of the selected measurement modality; and respective image data of the imaging performed by the eye measurement apparatus (300) of the selected imaging modality is received as the measurement data of the measurement performed by the eye measurement apparatus (300).
17. The computer-implemented method of claim 16, wherein: in a case where one of the plurality of different types of pathology found to be present in the image (400) is glaucoma, the method comprises generating (S26), as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an optical coherence tomography, OCT, scan of the region in the portion of the eye, and to acquire, as the measurement data, image data of the OCT scan; in a case where one of the plurality of different types of pathology found to be present in the image (400) is severe diabetic retinopathy, the method comprises generating (S26), as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an optical coherence tomography, OCT, scan of a region of a retina of the eye, and to acquire, as the measurement data, image data of the OCT scan; in a case where one of the plurality of different types of pathology found to be present in the image (400) is a tumour, the method comprises generating (S26), as the respective instruction for the eye measurement apparatus (BOO) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform a high-density optical coherence tomography, OCT, B-scan of the region in the portion of the eye, and to acquire, as the measurement data, image data of the high-density OCT B-scan; in a case where the one of the plurality of different types of pathology found to be present in the image (400) is drusen, the method comprises generating (S26), as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an optical coherence tomography, OCT, B-scan of the region in the portion of the eye, and to acquire, as the measurement data, image data of the OCT B-scan; and in a case where the one of the plurality of different types of pathology found to be present in the image (400) is oedema or atrophy, the method comprises generating (S26), as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an optical coherence tomography, OCT, scan of the region in the portion of the eye, and to acquire, as the measurement data, image data of the OCT scan.
18. The computer-implemented method of claim 14, wherein, in case at least one of the plurality of different types of pathology is found to be present in the image (400), at least one of the instructions generated is an instruction for an eye measurement apparatus (300) of a selected measurement modality to measure a functional response of the eye to light stimulation. 19. The computer-implemented method of any one of claims 15 to 17, further comprising generating instructions for controlling a display unit (215) to display the recorded location of the region (410) in the image (400) of the portion of the eye and a representation of the received measurement data.
20. The computer-implemented method of any one of claims 15 to 17, wherein the learning algorithm (630) is a supervised learning algorithm.
21. The computer-implemented method of claim 20, wherein the supervised learning algorithm comprises a neural network, and a region indicative of one of the different types of pathology found to be present in the image (400) is searched for in the image by deconstructing the neural network.
22. The computer-implemented method of claim 21, wherein the neural network is a convolutional neural network, and the neural network is deconstructed by: performing, for each of a plurality of different sections of the image (400) that is defined by the received image data, processes of: masking (S122) the section of the image (400) to generate a masked image; searching (S124) for the region in the masked image by processing image data defining the masked image using the learning algorithm; and determining (S126) a difference between a result of the search performed using the image data defining the masked image and a result of a search performed using the received image data; and determining (S128), as the location to be recorded, a location of a section for which the determined difference is largest.
23. The computer-implemented method of claim 21, wherein the neural network is a convolutional neural network, and the convolutional neural network is deconstructed by: determining a relevance of each input variable of the neural network to an output of the neural network by applying a Taylor decomposition to each layer of the neural network, from a top layer of the neural network to an input layer of the neural network; and determining the location to be recorded based on at least one section of the received image data corresponding to the most relevant input variables of the neural network.
24. The computer-implemented method of claim 21, wherein the neural network is a convolutional neural network, and the convolutional neural network is deconstructed by determining a deconvolution of the convolutional neural network.
25. A computer program which, when executed by a computer, causes the computer to perform a method as set out in at least one of claims 1 to 24.
26. A computer-readable storage medium (250) storing the computer program of claim 25.
27. A signal (260) carrying the computer program of claim 25.
28. An apparatus (100) for searching for a region indicative of a pathology in an image (400) of a portion of an eye acquired by an ocular imaging system (520; 720), the apparatus (100) comprising: a receiver module (110) configured to receive image data defining the image (400); a search module (120) configured to search for the region in the image (400) by processing the received image data using a learning algorithm (530; 630) trained on image data (502; 604) defining images of the portion of healthy eyes, and image data (601, 602, 603; 501) defining images of the portion of unhealthy eyes each having at least one region that is indicative of the pathology; and an instruction generating module (130) configured to perform, in response to a region (410) in the image (400) that is indicative of the pathology being found by the search module (120), processes of: determining a location of the region (410) in the image (400); and generating an instruction for an eye measurement apparatus (300) to perform a measurement on the portion of the eye to generate measurement data, using a reference point based on the determined location for setting a location of the measurement on the portion of the eye, wherein the receiver module (110) is further configured to receive the measurement data from the eye measurement apparatus (300).
29. The apparatus (100) of claim 28, wherein the search module (120) is configured to search for the region (410) in the image (400) by searching for a region (410) in the image (400) that is indicative of one of a plurality of different types of pathology by processing the received image data using the learning algorithm (630), the learning algorithm (630) being trained on image data (601, 602, 603) defining images of the portion of unhealthy eyes each having a respective one of the different types of pathology, the instruction generating module (130) is configured to perform, in response to a region (410) in the image (400) that is indicative of one of the plurality of different types of pathology being found by the search module (120), processes of: selecting, for the one of the plurality of different types of pathology, a respective one of a plurality of different types of measurement modality for a measurement to be performed on the eye; and generating, as the instruction for the eye measurement apparatus (300) to perform the measurement on the portion of the eye, an instruction for an eye measurement apparatus (300) of the selected measurement modality to perform the measurement on the portion of the eye, using the reference point for setting the location of the measurement on the portion of the eye.
30. The apparatus (100) of claim 28, wherein the receiver module (110) is configured to receive, as the image data, image data of a first imaging modality, the instruction generating module (130) is configured to generate, in response to a region (410) in the image (400) that is indicative of the pathology being found by the search module (120), and as the instruction for the eye measurement apparatus (300) to perform the measurement on the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an image capture process of a second imaging modality to image a region in the portion of the eye, using the reference point for setting, as the location of the measurement, a location of a region in the portion of the eye to be imaged in the image capture process, the second imaging modality being different to the first imaging modality, and the receiver module (110) is configured to receive from the eye measurement apparatus (300), as the measurement data, image data of the second imaging modality acquired by the eye measurement apparatus (300).
31. The apparatus (100) of claim 30, wherein the search module (120) is configured to search for a region (410) in the image (400) that is indicative of one of a plurality of different types of pathology by processing the received image data using the learning algorithm (630), the learning algorithm being trained on the image data (601, 602, 603) defining images of the portion of unhealthy eyes each having a respective one of the different types of pathology, and the instruction generating module (130) is configured to perform, in response to a region (410) in the image (400) that is indicative of one of the plurality of different types of pathology being found by the search module (120), a process of selecting, for the one of the plurality of different types of pathology and as the second imaging modality, a respective one of a plurality of different types of imaging modality which is to be used to perform the image capture process on the portion of the eye.
32. The apparatus (100) of claim 31, wherein the instruction generating module (130) is configured to generate, in a case where the one of the plurality of different types of pathology is glaucoma, an instruction for the eye measurement apparatus (300) to perform, as the image capture process of the second imaging modality, an optical coherence tomography, OCT, scan of the region in the portion of the eye, and the receiver module (110) is configured to receive, as the measurement data, image data of the OCT scan; the instruction generating module (130) is configured to generate, in a case where the one of the plurality of different types of pathology is severe diabetic retinopathy, an instruction for the eye measurement apparatus (300) to perform, as the image capture process of the second imaging modality, an optical coherence tomography, OCT, scan of a region of a retina of the eye, and the receiver module (110) is configured to receive, as the measurement data, image data of the OCT scan; the instruction generating module (130) is configured to generate, in a case where the one of the plurality of different types of pathology is a tumour, an instruction for the eye measurement apparatus (300) to perform, as the image capture process of the second imaging modality, a high-density optical coherence tomography, OCT, B-scan of the region in the portion of the eye, and the receiver module (110) is configured to receive, as the measurement data, image data of the high-density OCT B-scan; the instruction generating module (130) is configured to generate, in a case where the one of the plurality of different types of pathology is drusen, an instruction for the eye measurement apparatus (300) to perform, as the image capture process of the second imaging modality, an optical coherence tomography, OCT, B-scan of the region in the portion of the eye, and the receiver module (110) is configured to receive, as the measurement data, image data of the OCT B-scan; and the instruction generating module (130) is configured to generate, in a case where the one of the plurality of different types of pathology is oedema, an instruction for the eye measurement apparatus (300) to perform, as the image capture process of the second imaging modality, an optical coherence tomography, OCT, scan of the region in the portion of the eye, and the receiver module (110) is configured to receive, as the measurement data, image data of the OCT scan.
33. The apparatus (100) of claim 28, wherein, the instruction generating module (130) is configured to generate, in response to the region (410) in the image (400) that is indicative of the pathology being found by the search module (120), and as the instruction for the eye measurement apparatus (300) to perform the measurement on the portion of the eye, an instruction for the eye measurement apparatus (300) to measure a functional response of the eye to light stimulation, using the reference point for setting the location of the measurement which is based on the determined location.
34. The apparatus (100) of claim 28, wherein the receiver module (110) is configured to receive image data representing a result of imaging the portion of the eye using a first value of an imaging parameter, the imaging parameter being one of an imaging resolution, an aperture size and wavelength used in the imaging, the instruction generating module (130) is configured to perform, in response to a region (410) in the image (400) that is indicative of the pathology being found by the search module (120), a processes of generating, as the instruction for the eye measurement apparatus (300) to perform the measurement on the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an image capture process using a second value of the imaging parameter to image a region in the portion of the eye, using the reference point for setting, as the location of the measurement, a location of a region in the portion of the eye to be imaged in the image capture process, wherein the second value of the imaging parameter is different from the first value of the imaging parameter, and the receiver module (110) is configured to receive from the eye measurement apparatus (300), as the measurement data, the image data representing the result of imaging the region in the portion of the eye using the second value of the imaging parameter and the received image data and the received measurement data are of the same imaging modality.
35. The apparatus (100) of any one of claims 28 to 34, wherein the instruction generating module (130) is further configured to generate instructions for controlling a display unit (215) to display the determined location of the region (410) in the image (400) of the portion of the eye and a representation of the received measurement data.
36. The apparatus (100) of any of claims 28 to 35, wherein the learning algorithm (630) is a supervised learning algorithm.
37. The apparatus (100) of claim 36, wherein the supervised learning algorithm comprises a neural network, and the search module (120) is configured to search for the region indicative of the pathology in the image by deconstructing the neural network.
38. The apparatus (100) of claim 37, wherein the neural network is a convolutional neural network, and the search module (120) is configured to deconstruct the neural network by: performing, for each of a plurality of different sections of the image (400) that is defined by the received image data, processes of: masking the section of the image (400) to generate a masked image; searching for the region in the masked image by processing image data defining the masked image using the learning algorithm; and determining a difference between a result of the search performed using the image data defining the masked image and a result of a search performed using the received image data; and determining, as the location of the region (410) in the image (400), a location of a section for which the determined difference is largest.
39. The apparatus (100) of claim 37, wherein the neural network is a convolutional neural network, and the search module (120) is configured to deconstruct the convolutional neural network by: determining a relevance of each input variable of the neural network to an output of the neural network by applying a Taylor decomposition to each layer of the neural network, from a top layer of the neural network to an input layer of the neural network; and determining the location of the region (410) in the image (400) based on at least one section of the received image data corresponding to the most relevant input variables of the neural network.
40. The apparatus (100) of claim 37, wherein the neural network is a convolutional neural network, and the search module (120) is configured to deconstruct the convolutional neural network by determining a deconvolution of the convolutional neural network.
41. An apparatus (800) for searching for the presence of a pathology in an image (400) of a portion of an eye acquired by an ocular imaging system (520), the apparatus (800) comprising: a receiver module (810) configured to receive image data defining the image (400); a search module (820) configured to search for the presence of at least one of a plurality of different types of pathology in the image (400) by processing the received image data using a learning algorithm (630) trained on image data defining images (604) of healthy eyes, and images (601, 602, 603) of unhealthy eyes each having a respective one of the different types of pathology; and an instruction generating module (830) configured to perform, in response to at least one of the plurality of different types of pathology being found to be present in the image (400) by the search module (820), processes of: selecting, for each of at least one type of pathology found to be present in the image (400), a respective one of a plurality of different types of measurement modality which is to be used to perform a measurement on the portion of the eye; and generating, for each of the at least one type of pathology found to be present in the image (400), a respective instruction for an eye measurement apparatus (300) of the respective selected measurement modality to perform the measurement on the portion of the eye, wherein the receiver module (810) is further configured to receive measurement data of the measurement performed by the eye measurement apparatus (300) of each selected measurement modality.
42. The apparatus (800) of claim 41, wherein the search module (820) is further configured to perform, in response to finding at least one of the plurality of different types of pathology to be present in the image (400), a process of: for each of the at least one of the different types of pathology found to be present in the image (400), searching for a respective region (410) in the image (400) that is indicative of the respective type of pathology, by processing the received image data using the learning algorithm (630), and recording a location of the respective region (410) in the image (400), and the instruction generating module (830) is configured to generate a respective instruction for the eye measurement apparatus (300) of each selected measurement modality to perform a measurement on the eye using a reference point for locating the measurement which is based on the respective location.
43. The apparatus (800) of claim 42, wherein the instruction generating module (830) is configured to perform, in response to at least one of the plurality of different types of pathology being found to be present in the image (400) by the search module (820), and for each of the at least one of the different types of pathology found to be present in the image (400), processes of: selecting a respective one of a plurality of different types of imaging modality which is to be used to image the portion of the eye as the respective one of the plurality of different types of measurement modality; and generating, as the respective instruction for the eye measurement apparatus (300) of the selected measurement modality, a respective instruction for an eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, using a reference point for locating a region of the eye to be imaged which is based on the respective recorded location, and wherein the receiver module (810) is configured to receive respective image data of the imaging performed by the eye measurement apparatus (300) of the selected imaging modality as the measurement data of the measurement performed by the eye measurement apparatus (300).
44. The apparatus (800) of claim 43, wherein: the instruction generating module (830) is configured to generate, in a case where one of the plurality of different types of pathology found to be present in the image (400) is glaucoma, and as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an optical coherence tomography, OCT, scan of the region in the portion of the eye, and the receiver module (810) is configured to receive, as the measurement data, image data of the OCT scan; the instruction generating module (830) is configured to generate, in a case where one of the plurality of different types of pathology found to be present in the image (400) is severe diabetic retinopathy, and as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an optical coherence tomography, OCT, scan of a region of a retina of the eye, and the receiver module (810) is configured to receive, as the measurement data, image data of the OCT scan; the instruction generating module (830) is configured to generate, in a case where one of the plurality of different types of pathology found to be present in the image (400) is a tumour, and as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform a high-density optical coherence tomography, OCT, B-scan of the region in the portion of the eye, and the receiver module (810) is configured to receive, as the measurement data, image data of the high-density OCT B-scan; the instruction generating module (830) is configured to generate, in a case where the one of the plurality of different types of pathology found to be present in the image (400) is drusen, and as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an optical coherence tomography, OCT, B-scan of the region in the portion of the eye, and the receiver module (810) is configured to receive, as the measurement data, image data of the OCT B-scan; and the instruction generating module (830) is configured to generate, in a case where the one of the plurality of different types of pathology found to be present in the image (400) is oedema, and as the respective instruction for the eye measurement apparatus (300) of the selected imaging modality to image the portion of the eye, an instruction for the eye measurement apparatus (300) to perform an optical coherence tomography, OCT, scan of the region in the portion of the eye, and the receiver module (810) is configured to receive, as the measurement data, image data of the OCT scan.
45. The apparatus (800) of claim 41, wherein the instruction generating module (830) is configured to generate, in response to at least one of the plurality of different types of pathology being found to be present in the image by the search module (820), an instruction for an eye measurement apparatus (300) of a selected measurement modality to measure a functional response of the eye to light stimulation.
46. The apparatus (800) of any one of claims 42 to 44, wherein the instruction generating module (830) is further configured to generate instructions for controlling a display unit (215) to display the recorded location of the region (410) in the image (400) of the portion of the eye and a representation of the received measurement data.
47. The apparatus (800) of any one of claims 42 to 44, wherein the learning algorithm (630) is a supervised learning algorithm.
48. The apparatus (800) of claim 47, wherein the supervised learning algorithm comprises a neural network, and the search module (820) is configured to search for a region (410) indicative of one of the different types of pathology found to be present in the image (400) by deconstructing the neural network.
49. The apparatus of claim 48, wherein the neural network is a convolutional neural network, and the search module (820) is configured to deconstruct the neural network by: performing, for each of a plurality of different sections of the image (400) that is defined by the received image data, processes of: masking the section of the image (400) to generate a masked image; searching for the region in the masked image by processing image data defining the masked image using the learning algorithm; and determining a difference between a result of the search performed using the image data defining the masked image and a result of a search performed using the received image data; and determining, as the location to be recorded, a location of a section for which the determined difference is largest.
50. The apparatus (800) of claim 48, wherein the neural network is a convolutional neural network, and the search module (820) is configured to deconstruct the convolutional neural network by: determining a relevance of each input variable of the neural network to an output of the neural network by applying a Taylor decomposition to each layer of the neural network, from a top layer of the neural network to an input layer of the neural network; and determining the location to be recorded based on at least one section of the received image data corresponding to the most relevant input variables of the neural network.
51. The apparatus (800) of claim 48, wherein the neural network is a convolutional neural network, and the search module (820) is configured to deconstruct the convolutional neural network by determining a deconvolution of the convolutional neural network.
52. An apparatus for searching for a region indicative of a pathology in an image (400) of a portion of an eye acquired by an ocular imaging system (520; 720), the apparatus (100) comprising a processor and a memory storing computer program instructions which, when executed by the processor, cause the processor to perform a method as set out in at least one of claims 1 to 24.
</claims>
</document>
