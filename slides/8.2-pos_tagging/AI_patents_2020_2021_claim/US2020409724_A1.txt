<document>

<filing_date>
2019-06-26
</filing_date>

<publication_date>
2020-12-31
</publication_date>

<priority_date>
2019-06-26
</priority_date>

<ipc_classes>
G06F3/0481,G06F9/451,G06K9/00,G06N20/00
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
PINEL, FLORIAN
BYRON, DONNA K.
DIMASCIO, CARMINE M.
</inventors>

<docdb_family_id>
74043016
</docdb_family_id>

<title>
USER INTERFACE WIDGET RECOMMENDATION
</title>

<abstract>
In an approach for user interface widget recommendation, a processor receives a plurality of widgets. A processor applies natural language processing to the plurality of widgets to determine features wherein the features include contexts and layouts associated with the plurality of widgets. A processor trains a widget classifier based on the determined features. The widget classifier predicts a widget type. A processor trains a component classifier based on the widget type associated with the determined features. The component classifier predicts a component type and a component element type.
</abstract>

<claims>
1. A computer-implemented method comprising: receiving, by one or more processors, a plurality of widgets from one or more sources, each widget including one or more components that perform a specific user function; applying, by one or more processors, natural language processing to the plurality of widgets to determine features wherein: the features include contexts and layouts associated with the plurality of widgets, and applying the natural language processing includes using computer vision techniques: (i) to identify the contexts and layouts for the plurality of widgets which are non-declarative widgets and (ii) to find the non-declarative widgets by using background color and edge detection; training, by one or more processors, a widget classifier based on the determined features, the widget classifier predicting a widget type; training, by one or more processors, a component classifier based on the widget type associated with the determined features, the component classifier predicting a component type and a component element type; presenting, by one or more processors, a first widget to a user based on the trained widget classifier, the trained component classifier, and an input of the user; and performing, by one or more processors, an inference operation to identify a second widget to present to the user.
2. The computer-implemented method of claim 1, wherein applying the natural language processing includes extracting texts and icons to determine the contexts for the plurality of widgets which are represented via a declarative syntax.
3. The computer-implemented method of claim 1, wherein applying the natural language processing includes extracting the layouts for the plurality of widgets which are encoded via HTML.
4. 4-5. (canceled)
6. The computer-implemented method of claim 1, further comprising presenting, by one or more processors, the first widget based on a location of a user interaction which is selected from the group consisting of: mouse clicking, touching, and eye tracking.
7. (canceled)
8. A computer program product for user interface widget recommendation, the computer program product comprising: one or more computer readable storage media and program instructions stored on the one or more computer readable storage media, the program instructions comprising: program instructions to receive a plurality of widgets from one or more sources, each widget including one or more components that perform a specific user function; program instructions to apply natural language processing to the plurality of widgets to determine features wherein: the features include contexts and layouts associated with the plurality of widgets, and program instructions to apply the natural language processing include program instructions to use computer vision techniques: (i) to identify the contexts and layouts for the plurality of widgets which are non-declarative widgets and (ii) to find the non-declarative widgets by using background color and edge detection; program instructions to train a widget classifier based on the determined features, the widget classifier predicting a widget type; program instructions to train a component classifier based on the widget type associated with the determined features, the component classifier predicting a component type and a component element type; program instructions to present a first widget to a user based on the trained widget classifier, the trained component classifier, and an input of the user; and program instructions to perform an inference operation to identify a second widget to present to the user.
9. The computer program product of claim 8, wherein program instructions to apply the natural language processing include program instructions to extract texts and icons to determine the contexts for the plurality of widgets which are represented via a declarative syntax.
10. The computer program product of claim 8, wherein program instructions to apply the natural language processing include program instructions to extract the layouts for the plurality of widgets which are encoded via HTML.
11. 11-12. (canceled)
13. The computer program product of claim 8, further comprising: program instructions, stored on the one or more computer-readable storage media, to present the first widget based on a location of a user interaction which is selected from the group consisting of: mouse clicking, touching, and eye tracking.
14. (canceled)
15. A computer system for user interface widget recommendation, the computer system comprising: one or more computer processors, one or more computer readable storage media, and program instructions stored on the one or more computer readable storage media for execution by at least one of the one or more computer processors, the program instructions comprising: program instructions to receive a plurality of widgets from one or more sources, each widget including one or more components that perform a specific user function; program instructions to apply natural language processing to the plurality of widgets to determine features wherein: the features include contexts and layouts associated with the plurality of widgets, and program instructions to apply the natural language processing include program instructions to use computer vision techniques: (i) to identify the contexts and layouts for the plurality of widgets which are non-declarative widgets and (ii) to find the non-declarative widgets by using background color and edge detection; program instructions to train a widget classifier based on the determined features, the widget classifier predicting a widget type; program instructions to train a component classifier based on the widget type associated with the determined features, the component classifier predicting a component type and a component element type; program instructions to present a first widget to a user based on the trained widget classifier, the trained component classifier, and an input of the user; and program instructions to perform an inference operation to identify a second widget to present to the user.
16. The computer system of claim 15, wherein program instructions to apply the natural language processing include program instructions to extract texts and icons to determine the contexts for the plurality of widgets which are represented via a declarative syntax.
17. The computer system of claim 15, wherein program instructions to apply the natural language processing include program instructions to extract the layouts for the plurality of widgets which are encoded via HTML.
18. 18-19. (canceled)
20. The computer system of claim 15, further comprising: program instructions, stored on the one or more computer-readable storage media, to present the first widget based on a location of a user interaction which is selected from the group consisting of: mouse clicking, touching, and eye tracking.
</claims>
</document>
