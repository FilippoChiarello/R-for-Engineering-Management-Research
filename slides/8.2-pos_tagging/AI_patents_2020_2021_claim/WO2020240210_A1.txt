<document>

<filing_date>
2020-06-01
</filing_date>

<publication_date>
2020-12-03
</publication_date>

<priority_date>
2019-05-31
</priority_date>

<ipc_classes>
G06T7/11,G06T7/194,G06T7/564
</ipc_classes>

<assignee>
REALITY ZERO ONE LIMITED
</assignee>

<inventors>
EASTHAM, Robert
</inventors>

<docdb_family_id>
67385841
</docdb_family_id>

<title>
3D MODEL CAPTURE SYSTEM
</title>

<abstract>
The present invention relates to capturing data for modelling objects in three dimensions. More particularly, the present invention relates to a method and apparatus for capturing images and dimensions of objects in order to create three-dimensional models of these objects. The present invention seeks to provide a three-dimensional (3D) model of an object generated from multiple photos of that object.
</abstract>

<claims>
1 . A method of capturing data for modelling an object in three dimensions, comprising:
receiving a plurality of images of the object, wherein the plurality of images of the object comprises a plurality of images of the object each having a different perspective view of the object;
generating a plurality of masks for each of the plurality of images of the object;
determining a final mask for each of the plurality of images, wherein the final mask is determined from one or more of the plurality of masks generated for each of the plurality of images of the object; and
outputting a plurality of final masks, comprising a final mask for each of the plurality of images of the object.
2. The method of any preceding claim, further comprising determining a confidence score for each of the generated plurality of masks for each of the plurality of images of the object.
3. The method of any preceding claim, wherein determining a final mask for each of the plurality of images further comprises selecting a primary mask from the plurality of masks.
4. The method of claim 3 when dependent on claim 2, wherein selecting the primary mask comprises selecting the mask having the highest confidence score of the plurality of masks.
5. The method of any preceding claim, wherein each of the plurality of images is segmented into masked and unmasked segments using one or more of the plurality of masks for each of the plurality of images.
6. The method of claim 5 when dependent on claims 3 or 4, further comprising the step of determining the largest unmasked segment of each of the plurality of images when masked with the primary mask and segmenting all smaller unmasked segments of each of the plurality of images when masked with the primary mask as masked segments.
7. The method of claim 6, further comprising determining one or more overlapping portions of (a) any masked segments in any of the images when masked with any of the other masks other than the primary mask and (b) the determined largest unmasked segment of the images when masked with the primary mask; and segmenting the overlapping portions of each largest unmasked segment as masked.
8. The method of any preceding claim, further comprising applying each final mask to each of the respective plurality of images of the object.
9. The method of any preceding claim, further comprising outputting each of the plurality of images of the object, wherein the final mask for each of the plurality of images of the object has been applied to each of the plurality of images of the object.
10. The method of any preceding claim wherein the final mask of the plurality of masks comprises a combination of two or more of the plurality of masks.
1 1. The method of any preceding claim, wherein the plurality of masks comprises any or any combination of: a difference mask; a grab cut mask; an edge detection mask; a mask determined by iterative edge detection; a mask determined by Sobel edge detection; a mask determined by canny edge detection; a mask to remove holes detected in the object; a mask determined by boundary aware salient object detection (BASNet); a mask determined by the UA2-Net technique; a mask to remove hands and/or fingers; a mask determined using the Hand-CNN technique; a mask determined by comparing polarised and non-polarised images; a mask trained using machine learning techniques to detect certain types of objects in a scene based on previous known good masks of a similar object/subject; a mask to remove pixels of a certain colour, pattern or range of colours and/or patterns; a mask to detect one or more elements of a scanning apparatus.
12. The method of any preceding claim wherein determining the final mask for each of the plurality of images comprises using any or any combination of: a decision tree; a learned approach; a machine learned approach; a weighted approach; a weighted average ensemble approach; a weighted average ensemble prediction approach; an approach trained on a plurality of images from earlier scans.
13. The method of any preceding claim, wherein the plurality of images comprises polarised and unpolarised images; and further comprising a step of determining surface properties of the object using the determined differences between the polarised and unpolarised images, optionally using a learned model to detect materials and/or surface properties of the object, optionally the surface properties comprising specularity.
14. The method of any preceding claim, wherein the plurality of images is obtained from and/or using any or any combination of: one or more image sensors; one or more cameras; one or more video cameras; one or more stereo cameras; one or more 3D object capture apparatus; a rotating platform on which to place the object; one or more background assemblies having known colours and/or patterns; substantially optimised lighting; one or more polarisers; a user holding the object; a head mounted display system; an augmented reality headset; one or more unmanned aerial vehicles provided with images sensors.
15. A 3D object capture apparatus for capturing data for modelling objects in three dimensions, comprising:
a rotatable platform;
a lighting assembly;
one or more digital cameras operable to generate one or more digital images; and
a processor in electronic communication with the rotatable platform and the one or more digital cameras; wherein the processor is operable to:
instruct one or more rotational movements of the rotatable platform; instruct the one or more digital cameras to generate one or more digital images for each of the one or more rotational movements; receive one or more digital images generated by the one or more digital cameras; and transmit the one or more digital images to a server.
16. The apparatus of claim 15, further comprising a backdrop.
17. The apparatus of claim 16, wherein the backdrop comprises a curved lamina surface, optionally wherein the curved lamina surface substantially forms an"L" shape in cross-section.
18. The apparatus of any one of claims 16 or 17, wherein the backdrop is removable and/or replaceable.
19. The apparatus of any one of claims 16 to 18, wherein the backdrop is provided in a first configuration and a second configuration, optionally wherein the first configuration is narrower than the second configuration.
20. The apparatus of any of claims 15 to 19, wherein the one or more digital images comprise one or more sets of raw image data and/or any other suitable image data format.
21 . The apparatus of any of claims 15 to 20, wherein the lighting assembly is integrated into the apparatus.
22. The apparatus of any of claims 15 to 21 , wherein the lighting assembly comprises one or more light emitting diodes (LEDs), optionally wherein the one or more LEDs are provided in the form of one or more lighting panels, optionally wherein the lighting panels comprise non-LED flash panels or units.
23. The apparatus of any of claims 15 to 22, wherein the lighting assembly further comprises a polarising light filter positioned between the lighting assembly and the rotatable platform.
24. The apparatus of claim 23, wherein the one or more digital cameras comprise a polarising camera filter positioned between the digital camera and the rotatable platform.
25. The apparatus of claim 24, wherein the polarising camera filter and the polarising light filter are orientated orthogonally with respect to each other.
26. The apparatus of claim 25, wherein the processor is further operable to:
orientate the polarising light filter and/or the polarising camera filter according to the one or more digital images received.
27. The apparatus of any preceding claim, wherein the one or more rotational movements are made with reference to a predefined angle.
28. The apparatus of any preceding claim, wherein the server is remote from the processor.
29. The apparatus of claim 28, wherein the server comprises a cloud storage database.
30. The apparatus of any preceding claim, wherein the server is operable to process the one or more digital images into a three-dimensional (3D) model.
31 . The apparatus of claim 30, wherein the processor is further operable to:
modify one or more of the digital images such that computational expense is reduced when the server processes the one or more digital images into a 3D model.
32. The apparatus of any preceding claim, wherein the one or more digital images are in the form of digital video data.
33. The apparatus of claim 32, wherein the processor is further operable to:
extract one or more digital images from the digital video data.
34. The apparatus of any preceding claim, wherein the rotatable platform is integrated into the apparatus.
35. The apparatus of any preceding claim, wherein the rotatable platform comprises one or more object holding posts.
36. The apparatus of claim 35, wherein the one or more object holding posts comprise one or more magnets.
37. The apparatus of any preceding claim, wherein the processor is in electronic communication with the lighting assembly, and further wherein the processor is operable to instruct the lighting assembly to illuminate the rotatable platform for each of the one or more rotational movements.
38. A rigid frame comprising the apparatus of any preceding claim.
39. The rigid frame of claim 38, comprising one or more retractable and/or removeable elements.
40. A capture apparatus for generating a digital replica of a painting, comprising:
a frame;
a moveable mount, wherein the moveable mount is provided on the frame; one or more digital cameras operable to generate one or more digital images; and
a processor in electronic communication with the moveable mount and the one or more digital cameras; wherein the processor is operable to:
instruct one or more movements of the moveable mount;
instruct the one or more digital cameras to capture one or more digital images for each of the one or more movements;
receive one or more digital images generated by the one or more digital cameras; and
transmit the one or more digital images to a server.
41 . The apparatus according to any of claims 15 to 40 operable to perform the method of any of claims 1 to 14.
</claims>
</document>
