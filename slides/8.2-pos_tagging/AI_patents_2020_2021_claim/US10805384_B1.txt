<document>

<filing_date>
2018-09-13
</filing_date>

<publication_date>
2020-10-13
</publication_date>

<priority_date>
2018-09-13
</priority_date>

<ipc_classes>
H04L29/06,H04L29/08
</ipc_classes>

<assignee>
PARALLELS INTERNATIONAL
</assignee>

<inventors>
DOBROVOLSKIY, NIKOLAY
BELOUSSOV, SERGUEI
PACHKOV, SERGEY
Marnat, Igor
Kutuzov, Alexey
</inventors>

<docdb_family_id>
72749968
</docdb_family_id>

<title>
Systems and methods for load balancing server infrastructure
</title>

<abstract>
The present disclosure generally relates to the field of distributed system server administration, and more specifically, to systems and methods for load balancing server infrastructure and improving the performance of peer-to-peer connections between computing devices.
</abstract>

<claims>
1. A method, comprising: receiving, by a server, from a first computing device, a first information comprising one or more identities of one or more proxy servers accessible by the first computing device; receiving, from a second computing device, a second information comprising one or more identities of one or more proxy servers accessible by the second computing device; receiving, by the server, a request from the first computing device to initiate a connection to the second computing device; identifying, based on the first information, the second information, and a plurality of values of a workload metric for each proxy server of the one or more proxy servers accessible by the first computing device and the second computing device, a proxy server accessible to the first computing device and the second computing device; and transmitting, to the first computing device, an identifier of the proxy server accessible to the first computing device and the second computing device.
2. The method of claim 1, wherein the first information further comprises values of a network performance metric on respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
3. The method of claim 2, wherein the network performance metric reflects numbers of hops on respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
4. The method of claim 2, wherein the network performance metric reflects latencies of respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
5. The method of claim 2, wherein the network performance metric reflects available bandwidths of respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
6. The method of claim 2, wherein the network performance metric reflects number of dropped packets on respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
7. The method of claim 2, wherein the proxy server accessible to the first computing device and the second computing device is selected based on the values of the network performance metric.
8. The method of claim 1, wherein the server is a cloud-based server.
9. The method of claim 1, wherein the first information is received by the server according to a schedule.
10. The method of claim 1, wherein the first information further comprises values of a network performance metric on respective end-to-end paths connecting the first computing device and the second computing device via each proxy server of the one or more proxy servers accessible by the first computing device and the second computing device.
11. The method of claim 1, wherein the first information further comprises values reflecting geographic proximity of each proxy server of the one or more proxy servers to the first computing device and the second computing device.
12. A server computer system, comprising: a memory; and a processor, coupled to the memory, the processor configured to: receive, from a first computing device, a first information comprising one or more identities of one or more proxy servers accessible to each respective by the first computing device; receive, from a second computing device, a second information comprising one or more identities of one or more proxy servers accessible by the second computing device; receive a request from the first computing device to initiate a connection to the second computing device; identify, based on the first information, the second information, and a plurality of values of a workload metric for each proxy server of the one or more proxy servers accessible by the first computing device and the second computing device, a proxy server accessible to the first computing device and the second computing device; and transmit, to the first computing device, an identifier of the proxy server accessible to the first computing device and the second computing device.
13. The system of claim 12, wherein the first information further comprises values of a network performance metric on respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
14. The system of claim 13, wherein the network performance metric reflects numbers of hops on respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
15. The system of claim 13, wherein the network performance metric reflects latencies of respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
16. The system of claim 13, wherein the network performance metric reflects available bandwidths of respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
17. The system of claim 13, wherein the network performance metric reflects number of dropped packets on respective network paths between the first computing device and each of the one or more proxy servers accessible by the first computing device.
18. The system of claim 13, wherein the proxy server accessible to the first computing device and the second computing device is selected based on the values of the network performance metric.
19. The system of claim 12, wherein the first information is received by the server computer system according to a schedule.
20. The system of claim 12, wherein the first information further comprises values of a network performance metric on respective end-to-end paths connecting the first computing device and the second computing device via each proxy server of the one or more proxy servers accessible by the first computing device and the second computing device.
</claims>
</document>
