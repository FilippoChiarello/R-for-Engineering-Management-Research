<document>

<filing_date>
2018-09-19
</filing_date>

<publication_date>
2020-03-25
</publication_date>

<priority_date>
2018-09-19
</priority_date>

<ipc_classes>
A61B5/0215,A61B5/11
</ipc_classes>

<assignee>
PHILIPS ELECTRONICS
</assignee>

<inventors>
MUEHLSTEFF, JENS
LAMICHHANE, BISHAL
</inventors>

<docdb_family_id>
63642842
</docdb_family_id>

<title>
DEVICE, SYSTEM AND METHOD FOR PROVIDING A SKELETON MODEL
</title>

<abstract>
The present invention relates to a device, system, method and computer program for providing a skeleton model, wherein the device comprises a joint identification unit configured to obtain an image and corresponding image data of the patient comprising depth information and to generate joint location data by localizing one or more joints of the patient in said image, a pose estimation unit configured to generate pose estimation data by estimating a pose of the patient using the joint location data and/or the image data, a sensor location unit configured to obtain body location data, comprising information about a location of a sensor on the patient's body, and image location data, comprising information about the location of the sensor in the image, and to generate sensor location data, assigning a sensor location in the image to a body location of the patient, based on the body location data and the image location data, an assignment unit configured to perform an assignment of the one or more joints to one or more body locations of the patient by using the joint location data, the pose estimation data and the sensor location data, and a skeleton modelling unit configured to generate a skeleton model of the patient based on the assignment of the joints to a body location. The present invention further relates to a device for localizing a sensor on a patient's body.
</abstract>

<claims>
1. A device (10) for providing a skeleton model (36) of a patient, the device (10) comprising: - a joint identification unit (12) configured to obtain an image and corresponding image data (22) of the patient comprising depth information and to generate joint location data (24) by localizing one or more joints of the patient in said image (22), - a pose estimation unit (14) configured to generate pose estimation data (26) by estimating a pose of the patient using the joint location data (24) and/or the image data (22), - a sensor location unit (16) configured to obtain body location data (30), comprising information about a location of a sensor on the patient's body, and image location data (32), comprising information about the location of the sensor in the image (22), and to generate sensor location data (28), assigning a sensor location in the image (22) to a body location of the patient, based on the body location data (30) and the image location data (32), - an assignment unit (18) configured to perform an assignment (34) of the one or more joints to one or more body locations of the patient by using the joint location data (24), the pose estimation data (26) and the sensor location data (28), and - a skeleton modelling unit (20) configured to generate a skeleton model (36) of the patient based on the assignment (34) of the joints to a body location.
2. The device (10) according to claim 1,
further comprising a sensor information unit (38) configured to obtain a sensor signal (42) corresponding to a vital sign of the patient and to generate the body location data (30) and/or pose estimation data (26) based on said sensor signal (42).
3. The device (10) according to claims 1 or 2,
further comprising a sensor recognition unit (40) configured to generate image location data (32) by localizing the sensor in the image (22).
4. The device (10) according to any one of the preceding claims,
wherein the pose estimation unit (14) is configured to generate the pose estimation data (26) further using the sensor location data (28).
5. The device (10) according to claims 2 to 4,
wherein the sensor signal (42) corresponding to a vital sign comprises any one of electrocardiography data, photoplethysmography data, blood pressure data, body temperature data, blood oxygen saturation data, pulse rate data, pulse strength data and pulse arrival time data.
6. The device (10) according to any one of the preceding claims,
wherein the pose estimation unit (14) is configured to distinguish between a supine pose, wherein the patient is lying in a supine pose, a prone pose, wherein the patient is lying prone, and a side pose, wherein the patient is lying on a side of his or her body.
7. The device (10) according to any one of the preceding claims,
wherein the pose estimation unit (14) is configured to estimate the pose of the patient by identifying a distribution of the one or more joints in the image (22).
8. The device (10) according to any one of the preceding claims,
wherein the joint identification unit (12) is configured to localize one or more extreme points in the image (22), wherein the pose estimation unit (14) is configured to estimate the pose of the patient by identifying a distribution of said extreme points in the image (22).
9. The device (10) according to any one of the preceding claims,
wherein the joint identification unit (12) localizes the one or more joints using a machine learning method, particularly a deep learning algorithm, more particularly a convolutional neural network.
10. The device (10) according to any one of the preceding claims,
further comprising a tracking unit (46) configured to track movements of the patient based on two or more subsequent depth images (22) and the corresponding two or more skeleton models (36).
11. The device (10) according to claim 10,
wherein the tracking unit (46) is configured to perform a comparison between the two or more skeleton models (36), wherein the joint location unit (12) is configured to adapt the joint location data (24) based on said comparison and/or wherein the skeleton modelling unit (20) is configured to adapt the skeleton models (36) based on said comparison.
12. A system (100) for providing a skeleton model (36) of a patient, the system comprising: - a device (10) for providing a skeleton model of a patient as claimed in claims 1 to 11, and - one or more sensors (52, 54) configured to generate one or more sensor signals by detecting one or more vital signs of the patient and/or a depth camera (50) configured to acquire an image (22) of the patient and to generate corresponding image data (22) comprising depth information.
13. A method for providing a skeleton model (36) of a patient, the method comprising the steps of: - obtaining an image and corresponding image data (22) of the patient comprising depth information and generating joint location data (24) by localizing one or more joints of the patient in said image (22), - generating pose estimation data (26) by estimating a pose of the patient using the joint location data (24) and/or the image data (22), - obtaining body location data (30), comprising information about a location of a sensor on the patient's body, and image location data (32), comprising information about the location of the sensor in the image (22), and generating sensor location data (28) assigning a sensor location in the image (22) to a body location of the patient based on the body location data (30) and the image location data (32),, - performing an assignment of the one or more joints to one or more body locations of the patient by using the joint location data (24), the pose estimation data (26) and the sensor location data (28), and - generating a skeleton model (36) of the patient based on the assignment (34) of the joints to a body location.
14. A computer program for providing a skeleton model of a patient comprising program code means for causing a computer to carry out the steps of the method as claimed in claim 13 when said computer program is carried out on the computer.
15. A device (300) for localizing a sensor on a patient's body, the device comprising: - a comparison unit (302) configured to obtain a left sensor signal (56) and a right sensor signal (58) corresponding to a vital sign of the patient, wherein the left sensor signal (56) is obtained from a left sensor (52) detecting the vital sign on a left part of the patient's body and the right sensor signal (58) is obtained from a right sensor (54) detecting the vital sign on a right part of the patient's body, and to perform a comparison (310) of a feature of the left and right sensor signals (52, 54) with each other and/or with a reference value, and - an analysis unit (304) configured to generate body location data (30) by localizing the left sensor (52) and the right sensor (54) on the patient's body based on the comparison (310).
</claims>
</document>
