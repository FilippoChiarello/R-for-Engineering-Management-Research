<document>

<filing_date>
2018-10-13
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2018-10-13
</priority_date>

<ipc_classes>
G06K9/00,G06K9/32,G06K9/62
</ipc_classes>

<assignee>
APPLIED RESEARCH
</assignee>

<inventors>
KWAN, CHIMAN
</inventors>

<docdb_family_id>
70727927
</docdb_family_id>

<title>
Method and System for Object Tracking and Recognition Using Low Power Compressive Sensing Camera in Real-Time Applications
</title>

<abstract>
The present invention integrates a low power and high compression pixel-wise coded exposure (PCE) camera with advanced object detection, tracking, and classification algorithms into a real-time system. A PCE camera can control exposure time of every pixel in the camera and at the same time can compress multiple frames into a compressed frame. Consequently, it can significantly improve the dynamic range as well as reduce data storage and transmission bandwidth usage. Conventional approaches utilize PCE camera for object detection, tracking and classification, require the compressed frames to be reconstructed. These approaches are extremely time consuming and hence makes the PCE cameras unsuitable for real-time applications. The present invention presents an integrated solution that incorporates advanced algorithms into the PCE camera, saving reconstruction time and making it feasible to work in real-time applications.
</abstract>

<claims>
1. A system for object tracking and recognition in real-time applications comprising: a compressive sensing camera generates video frames of motion coded images; the motion coded images are directly connected to an object tracking and recognition unit without frames reconstruction; wherein the object tracking and recognition unit having a video frames trainer including: a histogram matching unit with an output connected to a You Only Look Once (YOLO) tracker and another output connected a data augmentation unit; a vehicle label and location unit with an output connected to the YOLO tracker; a Residual Network (ResNet) classifier is connected to an output of the data augmentation unit; an output of the YOLO tracker and an output of the ResNet classifier are connected to a performance metrics unit; and an output of the performance metrics unit is being fed-back to both the YOLO tracker and the ResNet classifier, respectively.
2. A system for object tracking and recognition in real-time applications in accordance to claim 1, wherein: the compressive sensing camera is either a pixel-wise coded exposure (PCE) or a Coded Aperture (CA) camera.
3. A system for object tracking and recognition in real-time applications in accordance to claim 2, further comprising: a cropped object histogram matching unit connected between the output of the YOLO tracker and an input of the ResNet classifier; and a majority voting unit is connected to an output of the ResNet classifier.
4. A system for object tracking and recognition in real-time applications in accordance to claim 3, wherein: the compressive sensing camera generates measurements at a variable compression ratio to save video data storage space and transmission bandwidth.
5. A system for object tracking and recognition in accordance to claim 4, wherein: individual exposure control is applied to each pixel to compress the video data to improve dynamic range of the motion coded image.
6. A system for object tracking and recognition in real-time applications in accordance to claim 5, wherein: the YOLO tracker is a deep learning based tracker which tracks multiple objects simultaneously without initial bounding boxes on the objects.
7. A system for object tracking and recognition in real-time applications in accordance to claim 6, wherein: two deep learning algorithms are integrated into the compressive sensing camera.
8. A system for object tracking and recognition in real-time applications in accordance to claim 7, wherein: the algorithms can be implemented in low cost Digital Signal Processor (DSP) and Field Programmable Gate Array (FPGA) for real-time processing.
9. A method for object tracking and recognition in real-time applications, comprising the steps of: using a compressive sensing camera to produce motion coded images containing raw sensing measurements; generating training video frames from the raw sensing measurements directly without frames reconstruction; histogram matching the training video frames to a common frame reference; extracting and saving object label and location information from the motion coded images; training a You Only Look Once (YOLO) tracker using outputs from the histogram matched video frames and the extracted label and location information; training a Residual Network (ResNet) classifier by augmenting data generated by the histogram matching; selecting classification metrics from training results of the YOLO tracker and ResNet classifier, respectively; and feeding back the selected training results to the YOLO tracker and ResNet classifier.
10. A method for object tracking and recognition in real-time applications in accordance to claim 9, wherein: the compressive sensing camera is either a pixel-wise coded exposure (PCE) or a Coded Aperture (CA) camera.
11. A method for object tracking and recognition in real-time applications in accordance to claim 10, further comprising the steps of: cropping the histogram matched video frame objects from outputs of the YOLO tracker; histogram matching the cropped video frame objects to a common frame reference before sending the output to the Residual Network (ResNet) classifier; applying a decision level fusion based on majority voting to the ResNet classifier to improve classification performance; and displaying target type and location information on output videos.
12. A method for object tracking and recognition in real-time applications in accordance to claim 11, wherein the cropping step further comprising the steps of: scaling up and down the cropped objects; rotating the cropped objects by different angles; or lightening up and down the cropped objects.
</claims>
</document>
