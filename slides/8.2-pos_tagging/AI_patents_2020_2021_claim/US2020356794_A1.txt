<document>

<filing_date>
2020-05-20
</filing_date>

<publication_date>
2020-11-12
</publication_date>

<priority_date>
2018-06-26
</priority_date>

<ipc_classes>
G05D1/00,G06F40/30,G06K9/00,G06K9/34,G06N3/08,G06T11/20
</ipc_classes>

<assignee>
WAYMO
</assignee>

<inventors>
LI, CONGCONG
SILVER, DAVID HARRISON
KERSHAW, CARL
WU, CHEN
CHAUDHARI, PANKAJ
DEAN, VICTORIA
KRETZSCHMAR, HENRIK
OGALE, ABHIJIT S.
</inventors>

<docdb_family_id>
68980707
</docdb_family_id>

<title>
Phrase recognition model for autonomous vehicles
</title>

<abstract>
Aspects of the disclosure relate to training and using a phrase recognition model to identify phrases in images. As an example, a selected phrase list may include a plurality of phrases is received. Each phrase of the plurality of phrases includes text. An initial plurality of images may be received. A training image set may be selected from the initial plurality of images by identifying the phrase-containing images that include one or more phrases from the selected phrase list. Each given phrase-containing image of the training image set may be labeled with information identifying the one or more phrases from the selected phrase list included in the given phrase-containing images. The model may be trained based on the training image set such that the model is configured to, in response to receiving an input image, output data indicating whether a phrase of the plurality of phrases is included in the input image.
</abstract>

<claims>
1. A method of controlling an autonomous vehicle based on phrases of a road sign, the method comprising: receiving, by one or more server computing devices, a plurality of images captured by a perception system of the vehicle; determining, by the one or more computing devices, one or more areas of road signs in one of the plurality of images, wherein the one or more areas include one or more phrases included in a phrase list including a plurality of phrases; determining, by the one or more computing devices, a confidence score indicating how likely it is that text in the one or more areas includes the one or more phrases included in the phrase list; comparing, by the one or more computing devices, the confidence score to one or more thresholds; and controlling, by the one or more computing devices, the vehicle based on a result of the comparing.
2. The method of claim 1, wherein the plurality of images captured by the perception system of the vehicle include context and orientation information associated with one or more road signs.
3. The method of claim 1 wherein the plurality of phrases of the phrase list are predetermined, and the method further comprises: performing an analysis on individual characters of the text; and in response to results of the analysis, identifying one or more phrases in the one or more areas that are not included in the phrase list.
4. The method of claim 1, wherein the result of the comparing is used to determine whether the vehicle should respond to at least one semantic meaning of any identified phrase of the phrase list.
5. The method of claim 1, further comprising: predicting a confidence score of individual characters being present inside the one or more areas; and comparing the confidence score to a threshold value to determine whether the vehicle should respond to one or more semantic meanings of any identified phrases of the phrase list.
6. The method of claim 5, wherein if the comparing results in a determination that the confidence score is below the threshold, ignoring a phrase including the individual characters.
7. The method of claim 1, further comprising: determining contextual information based on a location of the text, and using the determined contextual information to control the vehicle.
8. The method of claim 7, further comprising: determining that the text is part of an unrecognized phrase; determining at least part of the unrecognized phrase; and using the determined at least part of the unrecognized phrase to control the vehicle.
9. The method of claim 1, wherein at least some text of the plurality of predetermined phrases includes one or more words providing rules that the vehicle should follow when maneuvering on a roadway.
10. The method of claim 1, wherein at least some text of the plurality of predetermined phrases includes phrases providing rules the vehicle should follow when maneuvering on a roadway.
11. A system for controlling an autonomous vehicle based on phrases of a road sign, the system comprising: a perception system configured to capture a plurality of images; and one or more server computing devices configured to: receive a plurality of images captured by a perception system of the vehicle; determine one or more areas of road signs in one of the plurality of images, wherein the one or more areas include one or more of the phrases included in a phrase list including a plurality of phrases; determine a confidence score indicating how likely it is that text in the one or more areas includes the one or more phrases included in the phrase list; perform a comparison of the confidence score to one or more thresholds; and control the vehicle based on a result of the comparison.
12. The system of claim 11, further comprising the vehicle.
13. The system of claim 11, wherein the plurality of images captured by the perception system of the vehicle includes context and orientation information associated with one or more road signs.
14. The system of claim 11, wherein the plurality of phrases of the phrase list are predetermined and the one or more server computing devices are further configured to: performing an analysis on individual characters of the text; and in response to results of the analysis, identifying one or more phrases in the one or more areas that are not included in the phrase list.
15. The system of claim 11, wherein the result of the comparison is used to determine whether the vehicle should respond to at least one semantic meaning of any identified phrases of the phrase list.
16. The system of claim 11, wherein the one or more server computing devices are further configured to: predict a confidence score of individual characters being present inside the one or more areas; and performing a comparison of the confidence score to a threshold value to determine whether the vehicle should respond to one or more semantic meanings of any identified phrases of the phrase list.
17. The system of claim 16, wherein if the comparison results in a determination that the confidence score is below the threshold, ignoring a phrase including the individual characters.
18. A non-transitory, computer readable medium on which instructions are stored, the instructions, when executed by one or more processors, cause the one or more processors to perform a method, the method comprising: receiving a plurality of images captured by a perception system of an autonomous vehicle; determining one or more areas of road signs in one of the plurality of images, wherein the one or more areas include one or more phrases included in a phrase list including a plurality of phrases; determining, a confidence score indicating how likely it is that text in the one or more areas includes the one or more phrases included in the phrase list; comparing the confidence score to one or more thresholds; and controlling the vehicle based on a result of the comparing.
19. The non-transitory, computer readable medium of claim 18, wherein the plurality of images captured by the perception system of the vehicle include context and orientation information associated with one or more road signs.
20. The non-transitory, computer readable medium of claim 18, wherein the result of the comparing is used to determine whether the vehicle should respond to at least one semantic meaning of any identified phrases of the phrase list.
</claims>
</document>
