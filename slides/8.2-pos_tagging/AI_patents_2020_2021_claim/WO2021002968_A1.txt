<document>

<filing_date>
2020-05-21
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2019-07-02
</priority_date>

<ipc_classes>
G06N20/20,G06N3/04,G06N3/08,G06N5/04
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
GONG MING
JIANG, DAXIN
SHOU, LINJUN
YANG, ZE
BAI, Xuanyu
LIN, Wutao
CHENG, Feixiang
WANG, Xueyun
</inventors>

<docdb_family_id>
71016708
</docdb_family_id>

<title>
MODEL GENERATION BASED ON MODEL COMPRESSION
</title>

<abstract>
The present disclosure provides a method and apparatus for model generation. A pre-training dataset can be scored through a plurality of pre-training models, the plurality of pre-training models performing a first task. An initial model can be pre-trained with the scored pre-training dataset. The initial model can be updated based on a plurality of reference models to obtain a target model, the plurality of reference models performing a second task. A reference dataset can be scored through the plurality of reference models. The target model can be trained with the scored reference dataset.
</abstract>

<claims>
1. A method for model generation, comprising:
scoring a pre-training dataset through a plurality of pre-training models, the plurality of pre-training models performing a first task;
pre-training an initial model with the scored pre-training dataset;
updating the initial model based on a plurality of reference models to obtain a target model, the plurality of reference models performing a second task;
scoring a reference dataset through the plurality of reference models; and
training the target model with the scored reference dataset.
2. The method of claim 1, wherein the pre-training dataset comprises a plurality of samples, and wherein the scoring the pre-training dataset comprises, for each sample of the plurality of samples:
scoring the sample through the plurality of pre-training models, respectively, to obtain a plurality of target probability distributions of the sample.
3. The method of claim 1, wherein the initial model comprises a multi-decoder layer, the multi-decoder layer comprising a plurality of initial decoders corresponding to the plurality of pre-training models.
4. The method of claim 3, wherein the scored pre-training dataset comprises a plurality of samples, each sample having a plurality of target probability distributions produced by the plurality of pre-training models, and wherein the pre-training the initial model includes, for each sample:
scoring the sample through the plurality of initial decoders, respectively, to obtain a plurality of predicted probability distributions of the sample;
calculating a plurality of prediction losses corresponding to the plurality of predicted probability distributions;
calculating a comprehensive prediction loss corresponding to the sample based on the plurality of prediction losses; and
optimizing the initial model by minimizing the comprehensive prediction loss.
5. The method of claim 4, wherein the calculating the plurality of prediction losses corresponding to the plurality of predicted probability distributions comprises, for each predicted probability distribution of the plurality of predicted probability distributions: determining a pre-training model corresponding to an initial decoder that produces the predicted probability distribution;
extracting a target probability distribution produced by the pre-training model from the plurality of target probability distributions of the sample; and
calculating a prediction loss corresponding to the predicted probability distribution based on the extracted target probability distribution and the predicted probability distribution.
6. The method of claim 1, wherein the reference dataset comprises a plurality of samples, and wherein the scoring the reference dataset comprises, for each sample of the plurality of samples:
scoring the sample through the plurality of reference models, respectively, to obtain a plurality of target probability distributions of the sample.
7. The method of claim 1, wherein the updating comprises:
updating a multi-decoder layer of the initial model to include a first target decoder and a plurality of second target decoders corresponding to the plurality of reference models.
8. The method of claim 7, wherein the scored reference dataset comprises a plurality of samples, each sample having an initial label and a plurality of target probability distributions produced by the plurality of reference models, and wherein the training the target model includes, for each sample:
scoring the sample through the first target decoder to obtain a first predicted probability distribution of the sample;
calculating a first prediction loss corresponding to the first predicted probability distribution based on the initial label and the first predicted probability distribution;
scoring the sample through the plurality of second target decoders to obtain a plurality of second predicted probability distributions of the sample;
calculating a plurality of second prediction losses corresponding to the plurality of second predicted probability distributions;
calculating a comprehensive prediction loss corresponding to the sample based on the first prediction loss and the plurality of second prediction losses; and
optimizing the target model by minimizing the comprehensive prediction loss.
9. The method of claim 8, wherein the calculating the plurality of second prediction losses corresponding to the plurality of second predicted probability distributions comprises, for each second predicted probability distribution of the plurality of second predicted probability distributions:
determining a reference model corresponding to a second target decoder that produces the second predicted probability distribution;
extracting a target probability distribution produced by the reference model from the plurality of target probability distributions of the sample;
calculating a second prediction loss corresponding to the second predicted probability distribution based on the extracted target probability distribution and the second predicted probability distribution.
10. The method of claim 1, wherein the target model is trained to perform the second task.
11. The method of claim 1, further comprising:
receiving an input related to the second task;
scoring the input through a plurality of decoders in the target model to obtain a plurality of predicted probability distributions of the input; and
determining a predicted result of the input based on the plurality of predicted probability distributions.
12. The method of claim 1, wherein the first task or the second task comprises one or more of a matching task, a classification task, a generation task, a language understanding task, and a named entity recognition task.
13. The method of claim 1, wherein the plurality of pre-training models have different model structures or have different hyper-parameters, and the plurality of reference models have different model structures or have different hyper-parameters.
14. An apparatus for model generation, comprising:
a first scoring module, for scoring a pre-training dataset through a plurality of pre training models, the plurality of pre-training models performing a first task;
a pre-training module, for pre-training an initial model with the scored pre-training dataset;
a updating module, for updating the initial model based on a plurality of reference models to obtain a target model, the plurality of reference models performing a second task; a second scoring module, for scoring a reference dataset through the plurality of reference models; and
a training module, for training the target model with the scored reference dataset.
15. An apparatus for model generation, comprising:
at least one processor; and
a memory storing computer executable instructions that, when executed, cause the at least one processor to:
score a pre-training dataset through a plurality of pre-training models, the plurality of pre-training models performing a first task; pre-train an initial model with the scored pre-training dataset;
update the initial model based on a plurality of reference models to obtain a target model, the plurality of reference models performing a second task;
score a reference dataset through the plurality of reference models; and train the target model with the scored reference dataset.
</claims>
</document>
