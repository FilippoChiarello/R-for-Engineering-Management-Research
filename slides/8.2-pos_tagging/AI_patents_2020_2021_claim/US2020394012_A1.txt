<document>

<filing_date>
2018-05-30
</filing_date>

<publication_date>
2020-12-17
</publication_date>

<priority_date>
2017-05-30
</priority_date>

<ipc_classes>
G02B27/01,G06F3/01,G06F3/0481,G06F3/0488,G06F3/14,G06F3/16,G06K9/00,G06Q10/00,G06T7/73
</ipc_classes>

<assignee>
PTC
</assignee>

<inventors>
MAHENDRAN, ARUNGUNDRAM
LECHLEITER, JOHN JAMES
YAMAKAWA, DEVENDER
WRIGHT, JR., GERALD
Gervautz, Michael
Gauglitz, Steffen
Kolsch, Mathias
</inventors>

<docdb_family_id>
62778998
</docdb_family_id>

<title>
Use of Coordinated Local User Devices During a Shared Augmented Reality Session
</title>

<abstract>
A shared augmented reality system can support the sharing of video captured by a local user, using a head mounted display (HMD), with a remote user. The remote user may add augmented reality annotations (markings, notes, drawings) to certain objects within the environment captured within the video, where the annotations track the movement of those objects within the shared video. An HMD may not, however, provide a convenient interface for performing certain user-interface intensive tasks, which might be better performed on an additional device such as a mobile phone, tablet, or computer. During a shared augmented reality session, the additional device can be configured to communicate with a HMD such that certain tasks can be performed by the user through the additional device, and other tasks can be performed or experienced through the HMD. The additional device, the HMD and the remote user's device can communicatively coordinate during the session.
</abstract>

<claims>
1. 1-20. (canceled)
21. A method of sharing a user interface between first and second mobile devices, the method comprising: receiving a selection of an instructional sequence from a user with the first mobile device; transmitting data indicative of the selected instructional sequence from the first mobile device to the second mobile device; in response to receiving the data indicative of the selected instructional sequence: capturing a first sequence of images with a camera of the second mobile device, detecting an object within the first sequence of images, the detected object being identified by the selected instructional sequence, tracking the object within the first sequence of images, and displaying the instructional sequence overlaid on the first sequence of images with a display of the second mobile device.
22. The method of claim 21, wherein the first mobile device comprises a handheld mobile device and the second mobile device comprises a head mounted display.
23. The method of claim 21, wherein the first mobile device comprises a touch screen configured to receive input from the user, and wherein the second mobile device comprises an auxiliary input device, different from the touch screen, configured to receive input from the user.
24. The method of claim 21, wherein the instructional sequence comprises a set of repair instructions for repairing the object.
25. The method of claim 21, further comprising receiving a voice command from the user to navigate the instructional sequence with a microphone of the second mobile device.
26. The method of claim 21, further comprising: transmitting data indicative of completion of the instructional sequence from the second mobile device to the first mobile device; and receiving user input related to the completed instructional sequence from the user with the first mobile device.
27. The method of claim 21, further comprising: capturing a second sequence of images with a camera of the first mobile device; detecting the object within the second sequence of images; and displaying a plurality of instructional sequences associated with the detected object with a display of the first mobile device, wherein the selection of the instructional sequence received from the user is in response to displaying the plurality of instructional sequences associated with the detected object.
28. The method of claim 21, wherein displaying the instructional sequence comprises: establishing a connection between the second mobile device and a remote individual; receiving, at the second mobile device, at least a portion of the instructional sequence via the connection with the remote individual; and displaying the received portion of the instructional sequence overlaid on the first sequence of images with the display of the second mobile device.
29. The method of claim 28, wherein the received portion of the instructional sequence comprises an annotation anchored to the tracked object.
30. The method of claim 21, further comprising: receiving administrative data from the user associated with the selected instructional sequence with the first mobile device prior to transmitting the data indicative of the selected instructional sequence to the second mobile device.
31. A head mounted display (HMD), comprising: a display configured to display images; a camera; a processor; and a memory in communication with the processor and having stored thereon computer-executable instructions to cause the processor to: receive data indicative of a selected instructional sequence from a mobile device, the instructional sequence being received at the mobile device based on a user selection, capture a first sequence of images with the camera in response to receiving the data indicative of the selected instructional sequence, detect an object within the first sequence of images, the detected object being identified by the selected instructional sequence, track the object within the first sequence of images, and display the instructional sequence overlaid on the first sequence of images with the display.
32. The HMD of claim 31, wherein the mobile device comprises a touch screen configured to receive input from the user, and wherein the HMD comprises an auxiliary input device, different from the touch screen, configured to receive input from the user.
33. The HMD of claim 31, wherein the display comprises a semi-transparent display screen configured to display the images in a semi-transparent manner.
34. The HMD of claim 31, further comprising a microphone, wherein the memory further has stored thereon computer-executable instructions to cause the processor to receive a voice command from the user to navigate the instructional sequence with the microphone.
35. The HMD of claim 31, wherein the memory further has stored thereon computer-executable instructions to cause the processor to: establish a connection with a remote individual, receive at least a portion of the instructional sequence via the connection with the remote individual, and display the received portion of the instructional sequence overlaid on the first sequence of images with the display.
36. A non-transitory computer readable storage medium having stored thereon instructions that, when executed by a processor, cause a head mounted display (HMD) to: receive data indicative of a selected instructional sequence from a mobile device, the instructional sequence being received at the mobile device based on a user selection; capture a first sequence of images with a camera of the HMD in response to receiving the data indicative of the selected instructional sequence; detect an object within the first sequence of images, the detected object being identified by the selected instructional sequence; track the object within the first sequence of images; and display the instructional sequence overlaid on the first sequence of images with a display of the HMD.
37. The non-transitory computer readable storage medium of claim 36, wherein the mobile device comprises a touch screen configured to receive input from the user and wherein the HMD comprises an auxiliary input device, different from the touch screen, configured to receive input from the user.
38. The non-transitory computer readable storage medium of claim 36, wherein the instructional sequence comprises a set of repair instructions for repairing the tracked object.
39. The non-transitory computer readable storage medium of claim 36, further having stored thereon instructions that, when executed by the processor, cause the HMD to: receive a voice command from the user to navigate the instructional sequence with a microphone of the HMD.
40. The non-transitory computer readable storage medium of claim 36, further having stored thereon instructions that, when executed by the processor, cause the HMD to: establish a connection with a remote individual; receive at least a portion of the instructional sequence via the connection with the remote individual; and display the received portion of the instructional sequence overlaid on the first sequence of images with the display.
41. 41-60. (canceled)
</claims>
</document>
