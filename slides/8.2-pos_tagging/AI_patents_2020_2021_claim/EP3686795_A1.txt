<document>

<filing_date>
2019-10-30
</filing_date>

<publication_date>
2020-07-29
</publication_date>

<priority_date>
2019-01-25
</priority_date>

<ipc_classes>
G06K9/46,G06K9/62,G06N3/04,G06N3/08,G06T7/12
</ipc_classes>

<assignee>
STRADVISION
</assignee>

<inventors>
JANG, TAEWOONG
KIM, HAK-KYOUNG
KIM, KYE-HYEON
NAM, WOONHYUN
SUNG, MYUNGCHUL
YEO, DONGHUN
KIM, YONGJOONG
KIM, INSU
JE, HONGMO
CHO, HOJIN
RYU, WOOJU
BOO, SUKHOON
JEONG, KYUNGJOONG
</inventors>

<docdb_family_id>
67845092
</docdb_family_id>

<title>
LEARNING METHOD AND LEARNING DEVICE FOR IMPROVING SEGMENTATION PERFORMANCE TO BE USED FOR DETECTING EVENTS INCLUDING PEDESTRIAN EVENT, VEHICLE EVENT, FALLING EVENT AND FALLEN EVENT USING EDGE LOSS AND TEST METHOD AND TEST DEVICE USING THE SAME
</title>

<abstract>
A learning method for improving a segmentation performance to be used for detecting events including a pedestrian event, a vehicle event, a falling event, and a fallen event using a learning device is provided. The method includes steps of: the learning device (a) instructing k convolutional layers to generate k encoded feature maps; (b) instructing k-1 deconvolutional layers to sequentially generate k-1 decoded feature maps, wherein the learning device instructs h mask layers to refer to h original decoded feature maps outputted from h deconvolutional layers corresponding thereto and h edge feature maps generated by extracting edge parts from the h original decoded feature maps; and (c) instructing h edge loss layers to generate h edge losses by referring to the edge parts and their corresponding GTs. Further, the method allows a degree of detecting traffic sign, landmark, road marker, and the like to be increased.
</abstract>

<claims>
1. A learning method for improving a segmentation performance using a learning device, wherein the learning device includes (i) a first to a k-th convolutional layers, which respectively generate a first to a k-th encoded feature maps by applying one or more convolution operations to at least one feature map corresponding to at least one training image, (ii) a (k-1)-th to a first deconvolutional layers, which respectively generate a (k-1)-th to a first decoded feature maps by applying one or more deconvolution operations to the k-th encoded feature map, (iii) a first to an h-th mask layers respectively corresponding to h deconvolutional layers among the (k-1) deconvolutional layers, and (iv) a first to an h-th edge loss layers respectively corresponding to the first to the h-th mask layers, and wherein the h is an integer from 1 to (k-1), comprising steps of: (a) the learning device, if the training image is inputted, instructing the first to the k-th convolutional layers to generate the first to the k-th encoded feature maps; (b) the learning device instructing the (k-1)-th to the first deconvolutional layers to sequentially generate the (k-1)-th to the first decoded feature maps, wherein the learning device instructs the h-th to the first mask layers to (i) generate an h-th to a first edge feature maps by extracting edge parts from h original decoded feature maps each of which is outputted from each of the h deconvolutional layers corresponding to each of the h-th to the first mask layers, and (ii) generate h edge reinforced decoded feature maps serving as at least part of the (k-1)-th to the first decoded feature maps by referring to the h original decoded feature maps and the h-th to the first edge feature maps; and (c) the learning device instructing the first to the h-th edge loss layers to generate a first to an h-th edge losses by referring to the edge parts and their corresponding GTs(ground truths), to thereby adjust one or more parameters of at least part of the first to the (k-1)-th deconvolutional layers and the k-th to the first convolutional layers through backpropagation by using the first to the h-th edge losses.
2. The learning method of Claim 1, wherein the first to the h-th edge loss layers generate the first to the h-th edge losses by calculating differences between the edge parts and their corresponding GTs, wherein the GTs are respectively extracted from a first to an h-th GT images whose sizes correspond respectively to sizes of the first to the h-th edge feature maps.
3. The learning method of Claim 1, wherein, at the step of (b), the (k-1)-th to the first deconvolutional layers sequentially generate the (k-1)-th to the first decoded feature maps (i) by element-wise adding each of the h-th to the first edge feature maps and each of the h original decoded feature maps outputted from the h deconvolutional layers corresponding to the h-th to the first mask layers and (ii) by generating k-h original decoded feature maps serving as at least part of the k-1 decoded feature maps via applying the deconvolution operations to feature maps from each previous layer of each of k-h deconvolutional layers, which do not correspond to the h-th to the first mask layers.
4. The learning method of Claim 3, wherein the learning device further includes (v) a first to an r-th loss layers located corresponding to r deconvolutional layers among the first to the (k-1)-th deconvolutional layers, and
wherein the step of (c) includes a step of: (c1) the learning device instructing the first to the r-th loss layers to generate a first to an r-th losses respectively by referring to each of r decoded feature maps, outputted from the r deconvolutional layers corresponding to the first to the r-th loss layers, and its corresponding GT image, to thereby adjust the parameters of at least part of the first to the (k-1)-th deconvolutional layers and the k-th to the first convolutional layers through backpropagation by using the first to the r-th losses.
5. The learning method of Claim 4, wherein the first to the r-th loss layers respectively calculate the first to the r-th losses by referring to each of r converted feature maps, generated by applying each of auxiliary convolution operations to each of the r decoded feature maps, and its corresponding GT image, to thereby generate the first to the r-th losses.
6. The learning method of Claim 3, wherein the learning device further includes (vi) a first to an h-th intermediate layers each of which is located between each output end of the first to the h-th mask layers and each output end of their corresponding convolutional layers; and
wherein the step of (b) includes steps of: (b1) the learning device instructing the first to the h-th intermediate layers to generate a first to an h-th intermediate feature maps by inputting h encoded feature maps thereto which are outputted from h convolutional layers corresponding to the first to the h-th mask layers; (b2) the learning device instructing the first to the h-th mask layers to generate the first to the h-th edge feature maps by extracting the edge parts from the h original decoded feature maps each of which is outputted from each of the h deconvolutional layers corresponding to each of the first to the h-th mask layers; and (b3) the learning device (i) instructing a first to an h-th element-wise product layers to generate each of a first to an h-th element-wise products through element-wise multiplying each of the first to the h-th intermediate feature maps and its corresponding edge feature map and (ii) instructing a first to an h-th element-wise summing layers to element-wise add each of the first to the h-th element-wise products and its corresponding original decoded feature map among the h original decoded feature maps, to thereby generate h decoded feature maps among the first to the (k-1)-th decoded feature maps.
7. The learning method of Claim 6, wherein the learning device further includes an additional (h+1)-th intermediate layer between an output end of the k-th convolutional layer and an input end of the (k-1)-th deconvolutional layer, and wherein the additional (h+1)-th intermediate layer generates an (h+1)-th intermediate feature map by applying one or more intermediate operations to the k-th encoded feature maps and forwards the (h+1)-th intermediate feature map to the (k-1)-th deconvolutional layer.
8. The learning method of Claim 6, wherein at least one of the first to the h-th intermediate layers performs one or more dilated convolution operations.
9. The learning method of Claim 6, wherein, at the step of (b2), the learning device instructs at least an m-th mask layer among the first to the h-th mask layers to generate an m-th edge feature map by extracting edge parts from an n-th original decoded feature map outputted from an n-th deconvolutional layer, corresponding to the m-th mask layer, among the k-1 deconvolutional layers, and
wherein, at the step of (b3), the learning device (i) instructs an m-th element-wise product layer to generate an m-th element-wise product through element-wise multiplying the m-th edge feature map and an m-th intermediate feature map, outputted from an m-th intermediate layer corresponding to the m-th mask layer, and (ii) instructs an m-th element-wise summing layer to element-wise add the m-th element-wise product and the n-th original decoded feature map, to generate an n-th decoded feature map.
10. The learning method of Claim 9, wherein the learning device further includes (v) a first to an r-th loss layers located corresponding to r deconvolutional layers among the first to the (k-1)-th deconvolutional layers, wherein the learning device further includes an additional deconvolutional layer capable of receiving the first decoded feature map and outputting an adjusted first decoded feature map, to be inputted to the first loss layer, and wherein the step of (c) includes a step of: (c1) the learning device instructing the first to the r-th loss layers to generate a first to an r-th losses respectively by referring to each of r decoded feature maps, outputted from the r deconvolutional layers corresponding to the first to the r-th loss layers, and its corresponding GT image, to thereby adjust the parameters of at least part of the first to the (k-1)-th deconvolutional layers and the k-th to the first convolutional layers through backpropagation by using the first to the r-th losses.
11. A testing method for a segmentation of at least one test image comprising steps of: (a) on condition that, assuming that a learning device includes (i) a first to a k-th convolutional layers, which respectively generate a first to a k-th encoded feature maps for training by applying one or more convolution operations to at least one feature map corresponding to at least one training image, (ii) a (k-1)-th to a first deconvolutional layers, which respectively generate a (k-1)-th to a first decoded feature maps for training by applying one or more deconvolution operations to the k-th encoded feature map for training, (iii) a first to an h-th mask layers respectively corresponding to h deconvolutional layers among the (k-1) deconvolutional layers, and (iv) a first to an h-th edge loss layers respectively corresponding to the first to the h-th mask layers, and wherein the h is an integer from 1 to (k-1), the learning device (1) has instructed the first to the k-th convolutional layers to generate the first to the k-th encoded feature maps for training, (2) has instructed the (k-1)-th to the first deconvolutional layers to sequentially generate the (k-1)-th to the first decoded feature maps for training, wherein the learning device has instructed the h-th to the first mask layers to (i) generate an h-th to a first edge feature maps for training by extracting edge parts for training from h original decoded feature maps for training each of which is outputted from each of the h deconvolutional layers corresponding to each of the h-th to the first mask layers, and (ii) generate h edge reinforced decoded feature maps for training serving as at least part of the (k-1)-th to the first decoded feature maps for training by referring to the h original decoded feature maps for training and the h-th to the first edge feature maps for training, and (3) has instructed the first to the h-th edge loss layers to generate a first to an h-th edge losses by referring to the edge parts for training and their corresponding GTs(ground truths), to thereby adjust one or more parameters of at least part of the first to the (k-1)-th deconvolutional layers and the k-th to the first convolutional layers through backpropagation by using the first to the h-th edge losses; a testing device, if the test image is inputted, instructing the first to the k-th convolutional layers to generate a first to a k-th encoded feature maps for testing; and (b) the testing device instructing the (k-1)-th to the first deconvolutional layers to sequentially generate a (k-1)-th to a first decoded feature maps for testing, wherein the testing device instructs the h-th to the first mask layers to (i) generate an h-th to a first edge feature maps for testing by extracting edge parts for testing from h original decoded feature maps for testing each of which is outputted from each of the h deconvolutional layers corresponding to each of the h-th to the first mask layers, and (ii) generate h edge reinforced decoded feature maps for testing serving as at least part of the (k-1)-th to the first decoded feature maps for testing by referring to the h original decoded feature maps for testing and the h-th to the first edge feature maps for testing.
12. The testing method of Claim 11, wherein, at the step of (b), the (k-1)-th to the first deconvolutional layers sequentially generate the (k-1)-th to the first decoded feature maps for testing (i) by element-wise adding each of the h-th to the first edge feature maps for testing and each of the h original decoded feature maps for testing outputted from the h deconvolutional layers corresponding to the h-th to the first mask layers and (ii) by generating k-h original decoded feature maps for testing serving as at least part of the k-1 decoded feature maps for testing via applying the deconvolution operations to feature maps for testing from each previous layer of each of k-h deconvolutional layers, which do not correspond to the h-th to the first mask layers.
13. The testing method of Claim 12, wherein the testing device further includes (v) a first to an h-th intermediate layers each of which is located between each output end of the first to the h-th mask layers and each output end of their corresponding convolutional layers; and
wherein the step of (b) includes steps of: (b1) the testing device instructing the first to the h-th intermediate layers to generate a first to an h-th intermediate feature maps for testing by inputting h encoded feature maps for testing thereto which are outputted from h convolutional layers corresponding to the first to the h-th mask layers; (b2) the testing device instructing the first to the h-th mask layers to generate the first to the h-th edge feature maps for testing by extracting the edge parts for testing from the h original decoded feature maps for testing each of which is outputted from each of the h deconvolutional layers corresponding to each of the first to the h-th mask layers; and (b3) the testing device (i) instructing a first to an h-th element-wise product layers to generate each of a first to an h-th element-wise products for testing through element-wise multiplying each of the first to the h-th intermediate feature maps for testing and its corresponding edge feature map for testing and (ii) instructing a first to an h-th element-wise summing layers to element-wise add each of the first to the h-th element-wise products for testing and its corresponding original decoded feature map for testing among the h original decoded feature maps for testing, to thereby generate h decoded feature maps for testing among the first to the (k-1)-th decoded feature maps for testing.
14. The testing method of Claim 13, wherein the testing device further includes an additional (h+1)-th intermediate layer between an output end of the k-th convolutional layer and an input end of the (k-1)-th deconvolutional layer, and wherein the additional (h+1)-th intermediate layer generates an (h+1)-th intermediate feature map for testing by applying one or more intermediate operations to the k-th encoded feature maps for testing and forwards the (h+1)-th intermediate feature map for testing to the (k-1)-th deconvolutional layer.
15. The testing method of Claim 13, wherein, at the step of (b2), the testing device instructs at least an m-th mask layer among the first to the h-th mask layers to generate an m-th edge feature map for testing by extracting edge parts for testing from an n-th original decoded feature map for testing outputted from an n-th deconvolutional layer, corresponding to the m-th mask layer, among the k-1 deconvolutional layers, and
wherein, at the step of (b3), the testing device (i) instructs an m-th element-wise product layer to generate an m-th element-wise product for testing through element-wise multiplying the m-th edge feature map for testing and an m-th intermediate feature map for testing, outputted from an m-th intermediate layer corresponding to the m-th mask layer, and (ii) instructs an m-th element-wise summing layer to element-wise add the m-th element-wise product for testing and the n-th original decoded feature map for testing, to generate an n-th decoded feature map for testing.
</claims>
</document>
