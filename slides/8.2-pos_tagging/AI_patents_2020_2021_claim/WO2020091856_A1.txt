<document>

<filing_date>
2019-07-12
</filing_date>

<publication_date>
2020-05-07
</publication_date>

<priority_date>
2018-10-31
</priority_date>

<ipc_classes>
G06N20/00,G06N3/02
</ipc_classes>

<assignee>
CHEN, RUXIN
LIU XIAOYU
SONY INTERACTIVE ENTERTAINMENT
CHEN, MIN-HUNG
YOO, JAE KWON
</assignee>

<inventors>
CHEN, RUXIN
LIU XIAOYU
CHEN, MIN-HUNG
YOO, JAE KWON
</inventors>

<docdb_family_id>
70326920
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR DOMAIN ADAPTATION IN NEURAL NETWORKS USING CROSS-DOMAIN BATCH NORMALIZATION
</title>

<abstract>
A domain adaptation module (1800) is used to optimize a first domain (1804) derived from a second domain (1802) using respective outputs from respective parallel hidden layers of the domains.
</abstract>

<claims>
1. An apparatus, comprising:
at least one processor; and
at least one computer storage that is not a transitory signal and that comprises instructions executable by the at least one processor to:
access a first neural network, the first neural network being associated with a first data type;
access a second neural network, the second neural network being associated with a second data type different from the first data type,
provide, as input, first training data to the first neural network;
provide, as input, second training data to the second neural network, the first training data being different from the second training data;
identify a first output from an intermediate layer of the first neural network, the first output being based on the first training data;
identify a second output from an intermediate layer of the second neural network, the second output being based on the second training data, the respective intermediate layers of the first and second neural networks being parallel layers,
identify a ratio to normalize the first output and the second output;
apply an equation that accounts for the ratio to change one or more weights of the intermediate layer of the second neural network.
The apparatus of Claim 1, wherein the ratio pertains to a mean value.
3. The apparatus of Claim 1 , wherein mean and variance between the first output and the second output are both analyzed to apply the equation.
4. The apparatus of Claim 1, wherein the ratio is identified and the equation is applied using cross-domain batch normalization (CDBN).
5. The apparatus of Claim 1, wdierein the second neural netwOrk is established by a copy of the first neural network prior to the second training data being provided to the second neural network.
6. The apparatus of Claim 1, wherein the intermediate layers of the first and second neural networks are layers other than output layers.
7. The apparatus of Claim 1, wherein the first training data is related to the second training data, wherein the first and second neural networks pertain to action recognition, and wherein the first training data is related to the second training data in that the first and second training data both pertain to a same action
8. The apparatus of Claim 1, wherein the first training data is related to the second training data, wherein the first and second neural networks pertain to object recognition, and wherein the first training data is related to the second training data in that the first and second training data both pertain to a same object.
9. A method, comprising:
accessing a first neural network, the first neural network being associated with a first data type;
accessing a second neural network, the second neural network being associated with a second data type different from the first data type;
providing, as input, first training data to the first neural network;
providing, as input, second training data to the second neural network, the first training data being different from the second training data;
identifying a first output from a hidden layer of the first neural network, the first output being based on the first training data;
identifying a second output from a hidden layer of the second neural network, the second output being based on the second training data, the respective hidden layers of the first and second neural networks being parallel layers;
identifying a ratio to normalize the first output and the second output;
applying the ratio to outputs from the hidden layer of the second neural network to normalize the outputs from the hidden layer of the second neural network
10. The method of Claim 9, wherein the ratio pertains to a mean value
11. The method of Claim 9, wherein the identifying and applying steps are performed using a cross-domain batch normalization (CDBN) module.
12 An apparatus, comprising: at least one computer storage that is not a transitory signal and that comprises instructions executable by at least one processor to:
access a first domain of training data, the first domain being associated with a first domain genre;
access a second domain of training data, the second domain being associated with a second domain genre different from the first domain genre;
using the training data from the first and second domains, classify a target data set; and
output a classification of the target data set, wherein the target data set is classified by a domain adaptation module comprising a cross-domain batch normalization (CDBN) module to adaptively select domain statistics to normalize inputs.
13. The apparatus of Claim 12, wherein the first domain comprises real world video and the second domain comprises computer game video.
14. The apparatus of Claim 12, wherein the first domain comprises information derived from a first voice and the second domain comprises information derived from a second voice.
15. The apparatus of Claim 12, wherein the first domain comprises standard font text and the second domain comprises cursive script.
16. The apparatus of Claim 12, comprising the at least one processor.
17. The apparatus of Claim 12, wherein the CDBN module is operatively disposed after a fully connected layer in a spatial model.
18. The apparatus of Claim 12, wherein the instructions are executable to execute a training operation to learn a ratio to normalize both source and target data.
19. The apparatus of Claim 18, wherein the instructions are executable to execute a test operation to use the ratio and statistics related to the target to normalize statistics for both the source and the target.
20. The apparatus of Claim 18, wherein the instructions are executable to use entropy loss to separate unlabeled target data.
</claims>
</document>
