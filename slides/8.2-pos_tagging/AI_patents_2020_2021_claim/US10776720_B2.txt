<document>

<filing_date>
2019-02-05
</filing_date>

<publication_date>
2020-09-15
</publication_date>

<priority_date>
2019-02-05
</priority_date>

<ipc_classes>
G06N20/00,G06Q40/02
</ipc_classes>

<assignee>
CAPITAL ONE SERVICES
</assignee>

<inventors>
FLOREZ CHOQUE, OMAR
KHAZANE, ANISH
SALIMOV, ALAN
</inventors>

<docdb_family_id>
71836555
</docdb_family_id>

<title>
Techniques for bimodal learning in a financial context
</title>

<abstract>
Techniques for bi-modal learning in a financial context are described. These techniques are configured to improve a user's financial acumen and bring the user into an optimal financial state. Some of these techniques are embodied in a device that operates financial education lessons specifically configured for the improving the user's current financial state. These techniques may implement rewards/penalties (in tokens) for correct/incorrect user responses to financial decisions being presented in these lessons for user to make. By exploiting the user's desire for rewards and tokens and the desire to improve the user's current financial state, these techniques may leverage machine learning techniques to identify an appropriate financial education lesson that is most likely to have a positive effect on the user. Over time, administrating the financial education lessons builds customer loyalty to the device that implements these techniques. Other embodiments are described and claimed.
</abstract>

<claims>
1. An apparatus, comprising: a processing circuit; and logic stored in computer memory and executed on the processing circuit, the logic operative to cause the processing circuit to: process a policy model corresponding to a plurality of programs of which each program corresponds to a reward or a penalty to a current financial state, the policy model to configure the plurality of programs to improve upon the current financial state, wherein the current financial state comprises a debt-to-token ratio; identify, from the policy model, a program to run based upon a behavior model, the behavior model corresponding to past decisions with respect to at least one of the plurality of programs; run the program and process user response data; modify the behavior model and update the current financial state based upon the user response data; compare the updated financial state with an optimal financial state from an optimizer model to produce a comparison result; and modify the policy model based upon the comparison result, and wherein the policy model, the behavior model, and the optimizer model are implemented as components of a generative adversarial network.
2. The apparatus of claim 1 wherein the logic is executed until the debt-to-token ratio substantially equals the optimal financial state.
3. The apparatus of claim 1 further comprising logic operative to cause the processing circuit to initialize the behavior model with feature information corresponding to user financial activities.
4. The apparatus of claim 1 further comprising logic operative to cause the processing circuit to initialize the policy model with one or more programs appropriate for an age group of the user.
5. The apparatus of claim 1 further comprising logic operative to cause the processing circuit to modify the optimal financial state in response to a change in user age.
6. The apparatus of claim 1 further comprising a robot comprising the logic and the processing circuit.
7. The apparatus of claim 1 further comprising logic operative to cause the processing circuit to identify the program having a highest expected reward amongst the plurality of programs.
8. The apparatus of claim 1 further comprising logic operative to cause the processing circuit to select the program configured to decrease a debt-to-token ratio.
9. A computer-implemented method operative on a processing circuit, comprising: processing a policy model corresponding to a plurality of programs of which each program corresponds to a reward or a penalty to a current financial state, the policy model to configure the plurality of programs to improve upon the current financial state, the current financial state comprising a debt-to-token ratio; identifying, from the policy model, a program to improve the current financial state based upon a behavior model, the behavior model corresponding to past decisions with respect to at least one of the plurality of programs; running the program and processing user response data; modifying the behavior model and updating the current financial state based upon the user response data; and comparing the updated financial state with an optimal financial state and based upon the comparing, modifying the policy model to decrease the debt-to-token ratio, and wherein the policy model, and the behavior model are implemented as components of a generative adversarial network.
10. The computer-implemented method of claim 9, comprising modifying the reward or the penalty associated with the program or modifying a reward or a penalty of another program of the plurality of programs.
11. The computer-implemented method of claim 9, comprising selecting a program to decrease the debt-to-token ratio.
12. The computer-implemented method of claim 9, comprising unlocking or locking features based upon the user response data.
13. The computer-implemented method of claim 9, comprising crediting tokens in response to a correct user response or debiting tokens in response to an incorrect user response.
14. At least one non-transitory computer-readable storage medium comprising instructions that, when executed, cause a system to: process a policy model corresponding to a plurality of programs of which each program provides a reward or a penalty to a current debt-to-token ratio, the policy model to configure the plurality of programs to increase the current debt-to-token ratio; identify, from the policy model, a program configured to increase the current debt-to-token ratio to an optimal debt-to-token ratio based upon a behavior model corresponding to past user decisions with respect to the plurality of programs; run the program and process user response data; modify the behavior model and update the current debt-to-token ratio based upon the user response data; compare the updated debt-to-token ratio to an optimal debt-to-token ratio for an age group of the user to determine a difference between the updated debt-to-token ratio and the optimal debt-to-token ratio; and modify the policy model to reduce the difference, and wherein the policy model, the behavior model, and the optimizer model are implemented as components of a generative adversarial network.
15. The at least one non-transitory computer-readable storage medium of claim 14, wherein the instructions are executed until the optimal debt-to-token ratio is achieved.
16. The at least one non-transitory computer-readable storage medium of claim 14, wherein the system comprises a robot.
17. The at least one non-transitory computer-readable storage medium of claim 16, comprising instructions that when executed cause the system to unlock or lock components of the robot in response to running the program.
18. The at least one non-transitory computer-readable storage medium of claim 14, comprising instructions that when executed cause the system to modify the program to decrease the debt-to-token ratio.
19. The at least one non-transitory computer-readable storage medium of claim 14, comprising instructions that when executed cause the system to establish an optimal debt-to-token ratio for another age group.
</claims>
</document>
