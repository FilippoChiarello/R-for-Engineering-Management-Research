<document>

<filing_date>
2017-07-21
</filing_date>

<publication_date>
2020-03-24
</publication_date>

<priority_date>
2017-07-21
</priority_date>

<ipc_classes>
G06K9/00,G06K9/32,G06K9/34,G06K9/62,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
ASENTE, PAUL
YANG, XIAO
YUMER, MEHMET ERSIN
</inventors>

<docdb_family_id>
65019110
</docdb_family_id>

<title>
Semantic page segmentation of vector graphics documents
</title>

<abstract>
Disclosed systems and methods categorize text regions of an electronic document into document object types based on a combination of semantic information and appearance information from the electronic document. A page segmentation application executing on a computing device accesses textual feature representations that represent text portions in a vector space, where a set of pixels from the page is mapped to a textual feature representation. The page segmentation application generates a visual feature representation, which corresponds to an appearance of a document portion including the set of pixels, by applying a neural network to the page of the electronic document. The page segmentation application generates an output page segmentation of the electronic document by applying the neural network to the textual feature representation and the visual feature representation.
</abstract>

<claims>
1. A method for categorizing text regions of an electronic document into document object types based on a combination of semantic information from the electronic document and appearance information from the electronic document, the method comprising: accessing, by a processing device: (i) a textual feature representation that represents, in a vector space, a semantic meaning of textual content within a document, and (ii) a visual feature representation representing an appearance of a portion of the document that includes a set of pixels depicting the textual content; generating, by the processing device and based on both the visual feature representation and the textual feature representation corresponding to the set of pixels, an output page segmentation of the electronic document by applying a neural network to the textual feature representation and the visual feature representation; and outputting, by the processing device, a classification of the set of pixels as a particular document object type based on a correspondence between (i) a first location of the set of pixels in the electronic document and (ii) a second location of the particular document object type in the output page segmentation.
2. The method of claim 1, wherein portions of the output page segmentation represent different document object types, and wherein the different document object types comprise two or more of a table object type, a paragraph object type, and a caption object type.
3. The method of claim 1, wherein the method further comprises training the neural network by performing operations comprising: identifying, by the processing device, training bounding boxes from rendering commands in a training document, each training bounding box identifying a respective object in the electronic document; and iteratively adjusting the neural network based on a consistency loss computed from training feature representations in a training document, wherein iteratively adjusting the neural network comprises: computing a value of the consistency loss, wherein the value of the consistency loss indicates that a first document region included in a training bounding box and a second document region included in the training bounding box are represented by different training feature representations; modifying the neural network such that a subsequent value of the consistency loss is decreased in a subsequent iteration; and ceasing iteration based on the consistency loss being minimized.
4. The method of claim 1, wherein the neural network is trained with a set of training documents, wherein the method further comprises generating a training document from the set of training documents by performing operations comprising: receiving a human-generated sentence; receiving a human-generated section heading; receiving a human-generated list comprising elements from a common source; receiving a human-generated caption; and creating the training document by inserting at least one of a paragraph, a sentence, a section heading, or a caption into a human-generated unstructured vector graphics document.
5. The method of claim 1, further comprising generating the visual feature representation by applying a first portion of a neural network to the electronic document, wherein the output page segmentation is generated by applying a second portion of the neural network to the textual feature representation and the visual feature representation, wherein an output of the second portion of the neural network is a raw page segmentation, and wherein generating the output page segmentation comprises transforming the raw page segmentation into the output page segmentation by performing operations comprising: identifying a first segmentation portion of the raw page segmentation that corresponds to the particular document object type and a second segmentation portion of the raw page segmentation that corresponds to a different document object type; identifying, from rendering commands in the electronic document, a common bounding box that includes locations in the electronic document corresponding to the first segmentation portion and the second segmentation portion; determining that the first segmentation portion is larger than the second segmentation portion; and modifying the raw page segmentation based on the first segmentation portion being larger than the second segmentation portion and the common bounding box having locations corresponding to the first and second segmentation portions, wherein modifying the raw page segmentation causes both the first segmentation portion and the second segmentation portion to correspond to the particular document object type.
6. The method of claim 5, the operations further comprising: identifying a third segmentation portion of the raw page segmentation that corresponds to the particular document object type or the different document object type; determining that the third segmentation portion corresponds to a third location in the electronic document that is outside the common bounding box; and modifying the raw page segmentation based on the third segmentation portion corresponding to the third location that is outside the common bounding box, wherein modifying the raw page segmentation causes the third segmentation portion to correspond to a background object type.
7. The method of claim 1, wherein the neural network comprises: a set of encoder blocks followed by a set of decoder blocks trained to output the visual feature representation, wherein the set of encoder blocks and the set of decoder blocks are included in a first portion of the neural network; an additional decoder block that receives, as a first input, the visual feature representation outputted from the set of decoder blocks, wherein the additional decoder block is included in a second portion of the neural network; and a bridge connection that provides the textual feature representation from a text map generator to the additional decoder block as a second input.
8. A system comprising: a non-transitory computer-readable medium storing computer-executable instructions for categorizing text regions of an electronic document into document object types; and a processor communicatively coupled to the non-transitory computer-readable medium for executing the computer-executable instructions, wherein executing the computer-executable instructions configures the processor to perform operations comprising: accessing: (i) a textual feature representation corresponding to text from a page, wherein the textual feature representation represents, in a vector space, a semantic meaning of textual content within a document, and (ii) a text mapping that maps the textual feature representation to a set of pixels from the page, wherein each pixel in the set of pixels is mapped to the textual feature representation based on the set of pixels depicting the textual content; matching, to the textual feature representation from the text mapping, a visual feature representation representing an appearance of a portion of the page document that includes the set of pixels; generating an output page segmentation of the electronic document by applying a neural network to the textual feature representation and the visual feature representation; and outputting a classification of the set of pixels as a particular document object type based on a correspondence between (i) a first location of the set of pixels in the electronic document and (ii) a second location of the particular document object type in the output page segmentation.
9. The system of claim 8, wherein portions of the output page segmentation represent different document object types, wherein the different document object types comprise two or more of a table object type, a paragraph object type, and a caption object type.
10. The system of claim 8, wherein executing the computer-executable instructions further configures the processor to perform operations comprising: identifying training bounding boxes from rendering commands in a training document, each training bounding box identifying a respective object in the electronic document; and iteratively adjusting the neural network based on a consistency loss computed from training feature representations in a training document, wherein iteratively adjusting the neural network comprises: computing a value of the consistency loss, wherein the value of the consistency loss indicates that a first document region included in a training bounding box and a second document region included in the training bounding box are represented by different training feature representations; modifying the neural network such that a subsequent value of the consistency loss is decreased in a subsequent iteration; and ceasing iteration based on the consistency loss being minimized.
11. The system of claim 8, wherein executing the computer-executable instructions further configures the processor to train the neural network with a set of training documents and to generate a training document from the set of training documents by performing operations comprising: receiving a human-generated sentence; receiving a human-generated section heading; receiving a human-generated list comprising elements from a common source; receiving a human-generated caption; and creating the training document by inserting at least one of a paragraph, a sentence, a section heading, or a caption into a human-generated unstructured vector graphics document.
12. The system of claim 8, wherein the visual feature representation is generated by applying a first portion of a neural network to the page of the electronic document and the output page segmentation is generated by applying a second portion of the neural network to the textual feature representation and the visual feature representation, wherein an output of the second portion of the neural network is a raw page segmentation, wherein executing the computer-executable instructions that configure the processor to perform operations for generating the output page segmentation further configure the processor to transform the raw page segmentation into the output page segmentation by performing operations comprising: identifying a first segmentation portion of the raw page segmentation that corresponds to the particular document object type and a second segmentation portion of the raw page segmentation that corresponds to a different document object type; identifying, from rendering commands in the electronic document, a common bounding box that includes locations in the electronic document corresponding to the first segmentation portion and the second segmentation portion; determining that the first segmentation portion is larger than the second segmentation portion; and modifying the raw page segmentation based on the first segmentation portion being larger than the second segmentation portion and the common bounding box having locations corresponding to the first and second segmentation portions, wherein modifying the raw page segmentation causes both the first segmentation portion and the second segmentation portion to correspond to the particular document object type.
13. The system of claim 12, wherein executing the computer-executable instructions further configures the processor to perform operations comprising: identifying a third segmentation portion of the raw page segmentation that corresponds to the particular document object type or the different document object type; determining that the third segmentation portion corresponds to a third location in the electronic document that is outside the common bounding box; and modifying the raw page segmentation based on the third segmentation portion corresponding to the third location that is outside the common bounding box, wherein modifying the raw page segmentation causes the third segmentation portion to correspond to a background object type.
14. The system of claim 8, wherein the neural network comprises: a set of encoder blocks followed by a set of decoder blocks trained to output the visual feature representation, wherein the set of encoder blocks and the set of decoder blocks are included in a first portion of the neural network; an additional decoder block that receives, as a first input, the visual feature representation outputted from the set of decoder blocks, wherein the additional decoder block is included in a second portion of the neural network; and a bridge connection that provides the textual feature representation from a text map generator to the additional decoder block as a second input.
15. A non-transitory computer-readable storage medium storing computer-executable program instructions, wherein when executed by a processing device, the computer-executable program instructions cause the processing device to perform operations comprising: a step for accessing (i) a textual feature representation that represents, in a vector space, a representation of textual content of a document and (ii) a visual feature representation representing an appearance of a portion of the document that includes a set of pixels depicting the textual content, wherein the representation of textual content comprises a character, a word, or a sentence of text; a step for generating an output page segmentation of the document from the textual feature representation and the visual feature representation; and a step for outputting a classification of the set of pixels as a particular document object type based on a correspondence between (i) a first location of the set of pixels in the document and (ii) a second location of the particular document object type in the output page segmentation.
16. The non-transitory computer-readable storage medium of claim 15, wherein portions of the output page segmentation represent different document object types, wherein the different document object types comprise two or more of a table object type, a paragraph object type, and a caption object type.
17. The non-transitory computer-readable storage medium of claim 15, wherein, when executed by a processor, the computer-executable program instructions cause the processor to perform a step for training a neural network used to generate the output page segmentation, the step comprising: a step for identifying training bounding boxes from rendering commands in a training document, each training bounding box identifying a respective object in the training document; and a step for iteratively adjusting the neural network based on a consistency loss computed from training feature representations in a training document, wherein iteratively adjusting the neural network comprises: a step for computing a value of the consistency loss, wherein the value of the consistency loss indicates that a first document region included in a training bounding box and a second document region included in the training bounding box are represented by different training feature representations; a step for modifying the neural network such that a subsequent value of the consistency loss is decreased in a subsequent iteration; and a step for ceasing iteration based on the consistency loss being minimized.
18. The non-transitory computer-readable storage medium of claim 15, wherein, when executed by a processor, the computer-executable program instructions cause the processor to perform a step for training a neural network used to generate the output page segmentation, the neural network trained with a set of training documents, the step comprising generating a training document from the set of training documents by performing operations comprising: a step for receiving a human-generated sentence; a step for receiving a human-generated section heading; a step for receiving a human-generated list comprising elements from a common source; a step for receiving a human-generated caption; and a step for creating the training document by inserting at least one of a paragraph, a sentence, a section heading, or a caption into a human-generated unstructured vector graphics document.
19. The non-transitory computer-readable storage medium of claim 15, wherein the step for generating the output page segmentation comprises transforming a raw page segmentation generated from the textual feature representation and the visual feature representation into the output page segmentation by performing operations comprising: a step for identifying a first segmentation portion of the raw page segmentation that corresponds to the particular document object type and a second segmentation portion of the raw page segmentation that corresponds to a different document object type; a step for identifying, from rendering commands in the document, a common bounding box that includes locations in the document corresponding to the first segmentation portion and the second segmentation portion; a step for determining that the first segmentation portion is larger than the second segmentation portion; and a step for modifying the raw page segmentation based on the first segmentation portion being larger than the second segmentation portion and the common bounding box having locations corresponding to the first and second segmentation portions, wherein modifying the raw page segmentation causes both the first segmentation portion and the second segmentation portion to correspond to the particular document object type.
20. The non-transitory computer-readable storage medium of claim 19, wherein, when executed by a processor, the computer-executable program instructions cause the processor to perform: a step for identifying a third segmentation portion of the raw page segmentation that corresponds to the particular document object type or the different document object type; a step for determining that the third segmentation portion corresponds to a third location in the document that is outside the common bounding box; and a step for modifying the raw page segmentation based on the third segmentation portion corresponding to the third location that is outside the common bounding box, wherein modifying the raw page segmentation causes the third segmentation portion to correspond to a background object type.
</claims>
</document>
