<document>

<filing_date>
2020-04-10
</filing_date>

<publication_date>
2020-09-24
</publication_date>

<priority_date>
2016-06-30
</priority_date>

<ipc_classes>
G06F3/0482,G06F3/16,G10L13/033,H04B1/3827,H04L29/08
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
BOTROS, JOHN
KIM, ANDY
</inventors>

<docdb_family_id>
70856141
</docdb_family_id>

<title>
GRAPHICAL INTERFACE FOR SPEECH-ENABLED PROCESSING
</title>

<abstract>
Methods and devices for sampling applications using a touch input are described herein. In some embodiments, an electronic device detects a touch input, which may cause the electronic device to send identifiers to a backend system. The backend system may then determine an application and sample audio request associated with the received identifiers. The backend system may then receive text data representing the sample audio request and text data representing a response to the sample audio request. The backend system may generate audio data representing the received text data and send the audio data to the electronic device. If, the touch input is still occurring, the backend system may find and send more sample audio requests and the responses thereof. If the touch input stops occurring during the sample, the backend system may send instructions to the electronic device to stop outputting the sample.
</abstract>

<claims>
1. 1-20. (canceled)
21. A computer-implemented method, comprising: causing a graphical user interface (GUI) to be displayed on a device; receiving a user selection corresponding to an application displayed using the GUI; receiving input audio data corresponding to a command corresponding to the application; processing the input audio data to determine input text data; processing the input text data to determine intent data corresponding to the command; using the intent data to determine output text data; performing text-to-speech processing on the output text data to determine output audio data; and causing output audio data to be sent to the device.
22. The computer-implemented method of claim 21, further comprising: determining the intent data corresponds to a first invocation of the application; sending the intent data to the application; and receiving at least a portion of the output text data from the application.
23. The computer-implemented method of claim 21, wherein the GUI is configured to display data corresponding to a plurality of applications.
24. The computer-implemented method of claim 21, further comprising: receiving, from the device, a first identifier corresponding to the application, wherein a representation corresponding to the first identifier was selected from a displayed set of options on the GUI.
25. The computer-implemented method of claim 21, wherein the user selection corresponds to a touch input.
26. The computer-implemented method of claim 21, further comprising: determining, based at least in part on the application, data corresponding to a voice type, wherein the performing the text-to-speech processing is based at least in part on the data corresponding to the voice type.
27. The computer-implemented method of claim 21, further comprising: causing a microphone associated with the device to determine the input audio data based at least in part on audio corresponding to the command.
28. The computer-implemented method of claim 27, wherein the causing the microphone to determine the audio is performed at least in part in response to the user selection.
29. The computer-implemented method of claim 21, further comprising: determining a second user selection; and in response to the second user selection, ceasing certain processing with regard to the input audio data.
30. The computer-implemented method of claim 21, wherein the processing the input text data to determine the intent data is based at least in part on the application.
31. A system comprising: at least one processor; and at least one memory comprising instructions that, when executed by the at least one processor, cause the system to: cause a graphical user interface (GUI) to be displayed on a device; receive a user selection corresponding to an application displayed using the GUI; receive input audio data corresponding to a command corresponding to the application; process the input audio data to determine input text data; process the input text data to determine intent data corresponding to the command; use the intent data to determine output text data; perform text-to-speech processing on the output text data to determine output audio data; and cause output audio data to be sent to the device.
32. The system of claim 31, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: determine the intent data corresponds to a first invocation of the application; send the intent data to the application; and receive at least a portion of the output text data from the application.
33. The system of claim 31, wherein the GUI is configured to display data corresponding to a plurality of applications.
34. The system of claim 31, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: receive, from the device, a first identifier corresponding to the application, wherein a representation corresponding to the first identifier was selected from a displayed set of options on the GUI.
35. The system of claim 31, wherein the user selection corresponds to a touch input.
36. The system of claim 31, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: determine, based at least in part on the application, data corresponding to a voice type, wherein performing the text-to-speech processing is based at least in part on the data corresponding to the voice type.
37. The system of claim 31, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: cause a microphone associated with the device to determine the input audio data based at least in part on audio corresponding to the command.
38. The system of claim 37, wherein causing the microphone to determine the audio is performed at least in part in response to the user selection.
39. The system of claim 31, wherein the at least one memory further comprises instructions that, when executed by the at least one processor, further cause the system to: determine a second user selection; and in response to the second user selection, cease certain processing with regard to the input audio data.
40. The system of claim 31, wherein processing the input text data to determine the intent data is based at least in part on the application.
</claims>
</document>
