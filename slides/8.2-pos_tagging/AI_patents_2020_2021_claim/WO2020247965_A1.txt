<document>

<filing_date>
2020-07-06
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-05-06
</priority_date>

<ipc_classes>
G06F3/041
</ipc_classes>

<assignee>
QEEXO COMPANY
</assignee>

<inventors>
STONE, JOSHUA
CHEN, YANFEI
XIAO, Bo Robert
DORBALA, Shyama
</inventors>

<docdb_family_id>
73046286
</docdb_family_id>

<title>
MANAGING ACTIVITY STATES OF AN APPLICATION PROCESSOR IN RELATION TO TOUCH OR HOVER INTERACTIONS WITH A TOUCH SENSITIVE DEVICE
</title>

<abstract>
Techniques that can improve efficiency of a touch sensitive device are presented. A touch controller (TC) can comprise a hover classification engine and an application processor (AP) can comprise a touch classification engine usable to classify touch or hover interactions of an object(s) with a touch sensitive surface (TSS) of the device. In response to classifying a touch or hover interaction with TSS as unintentional, AP can reject such interaction and can transition from an active state to an inactive state. TC can continue to monitor touch or hover interactions with TSS. In response to determining there is an intentional touch interaction with TSS or no unintentional face/ear interaction with TSS, TC can transmit a notification signal to AP. In response to the notification signal, AP can transition from the inactive state to active state, and can process the intentional touch interaction or monitor the TSS.
</abstract>

<claims>
What is claimed is:
1. A method, comprising:
monitoring, by a system comprising a processor, a touch sensitive surface of a device for a touch interaction or a hover interaction by an object with the touch sensitive surface; and
controlling, by the system, activity states of an application processor of the device based at least in part on the touch interaction or the hover interaction by the object with the touch sensitive surface.
2. The method of claim 1, further comprising:
detecting, by the system, the touch interaction or the hover interaction based at least in part on sensor data, wherein at least a portion of the sensor data is associated with the touch sensitive surface, and wherein the sensor data indicates that the touch interaction or the hover interaction of the object with the touch sensitive surface has occurred; and
determining, by the system, a classification of the touch interaction or the hover interaction based at least in part on results of analyzing the sensor data, wherein the classification is one of an intentional touch interaction, an unintentional touch interaction, or an unintentional hover interaction, of the object with the touch sensitive surface.
3. The method of claim 2, further comprising:
in response to determining that the touch interaction is the intentional touch interaction of the object with the touch sensitive surface, processing, by the system, the touch interaction to perform an operation based at least in part on the touch interaction.
4. The method of claim 2, wherein the activity states of the application processor comprise an active state and an inactive state, wherein the application processor is in the active state, and wherein the method further comprises: in response to determining that the touch interaction or the hover interaction is the unintentional touch interaction or the unintentional hover interaction of the object with the touch sensitive surface, rejecting, by the system, the unintentional touch interaction or the unintentional hover interaction; and
transitioning, by the system, the application processor to the inactive state.
5. The method of claim 4, further comprising:
transitioning, by the system, a display screen of the device from an on state to an off state.
6. The method of claim 4, further comprising:
determining, by the system, that the device is using a phone application for a phone call or using a non-data application that does not utilize the application processor; and
determining, by the system, that the application processor is able to be transitioned to the inactive state during the phone call or use of the non-data application.
7. The method of claim 2, wherein the activity states of the application processor comprise an active state and an inactive state, wherein the application processor is in the inactive state, and wherein the method further comprises:
in response to determining that the touch interaction is the intentional touch interaction of the object with the touch sensitive surface, generating, by the system, a notification signal regarding the intentional touch interaction; and
transmitting, by the system, the notification signal from a touch controller of the device to the application processor.
8. The method of claim 7, further comprising:
in response to the notification signal, transitioning, by the system, the application processor from the inactive state to the active state;
transitioning, by the system, a display screen of the device from an off state to an on state; and processing, by the system, the touch interaction to perform an operation based at least in part on the touch interaction, wherein the application processor facilitates the processing of the touch interaction to perform the operation.
9. The method of claim 2, wherein the activity states of the application processor comprise an active state and an inactive state, wherein the application processor is in the inactive state, and wherein the method further comprises:
in response to determining that the touch interaction or the hover interaction is the unintentional touch interaction or the unintentional hover interaction of the object with the touch sensitive surface, rejecting, by the system, the unintentional touch interaction or the unintentional hover interaction, wherein no notification signal is transmitted by a touch controller of the device to the application processor to transition the application processor to the active state, and wherein the application processor remains in the inactive state.
10. The method of claim 1, wherein the object is a finger of a user of the device, an ear of the user, a portion of a face of the user, a palm of the user, or a stylus;
wherein an unintentional touch interaction comprises an unintentional finger touch of the finger of the user, an unintentional touch of the ear of the user, an unintentional touch of the portion of the face of the user, an unintentional touch of the palm of the user, or an unintentional touch of the stylus, on the touch sensitive surface;
wherein an unintentional hover interaction comprises an unintentional hover of the finger of the user, an unintentional hover of the ear of the user, an unintentional hover of the portion of the face of the user, an unintentional hover of the palm of the user, or an unintentional hover of the stylus, in proximity to the touch sensitive surface; and
wherein an intentional touch interaction comprises an intentional finger touch of the finger of the user on the touch sensitive surface or an intentional touch of the stylus on the touch sensitive surface.
11. A system, comprising: an application processor that monitors a touch sensitive surface of a device for a touch interaction by an object with the touch sensitive surface; and
a touch controller component that monitors the touch sensitive surface for a hover interaction by the object with the touch sensitive surface, wherein activity states of the application processor are controlled based at least in part on the touch interaction or the hover interaction by the object with the touch sensitive surface.
12. The system of claim 11, wherein the activity states comprise at least an active state and an inactive state, wherein the application processor is in the active state, wherein the application processor or the touch controller component detect the touch interaction or the hover interaction based at least in part on sensor information, wherein at least a portion of the sensor information is associated with the touch sensitive surface, and wherein the sensor information indicates that the touch interaction or the hover interaction of the object with the touch sensitive surface has occurred; and
wherein the application processor or the touch controller component determines a classification of the touch interaction or the hover interaction based at least in part on results of analyzing the sensor information, wherein the classification is one of an intentional touch interaction, an unintentional touch interaction, or an unintentional hover interaction, of the object with the touch sensitive surface.
13. The system of claim 12, wherein, in response to determining that the touch interaction is the intentional touch interaction of the object with the touch sensitive surface, the application processor processes the touch interaction to perform an operation based at least in part on the touch interaction.
14. The system of claim 12, wherein, in response to determining that the touch interaction or the hover interaction is the unintentional touch interaction or the unintentional hover interaction of the object with the touch sensitive surface, the application processor rejects the unintentional touch interaction or the unintentional hover interaction, and the application processor switches the application processor to the inactive state.
15. The system of claim 14, wherein, prior to the application processor switching to the inactive state, the application processor switches a display screen component of the device from an on state to an off state.
16. The system of claim 14, wherein, prior to the application processor switching to the inactive state, the application processor determines that the device is using a phone application for a phone call or using a non-data application that does not utilize the application processor, and determines that the application processor is able to be switched to the inactive state during the phone call or use of the non-data application.
17. The system of claim 11, wherein the activity states of the application processor comprise at least an active state and an inactive state, and wherein the application processor is in the inactive state;
wherein the touch controller component detects the touch interaction or the hover interaction based at least in part on sensor information, wherein at least a portion of the sensor information is associated with the touch sensitive surface, and wherein the sensor information indicates that the touch interaction or the hover interaction of the object with the touch sensitive surface has occurred; and
wherein the touch controller component determines a classification of the touch interaction or the hover interaction based at least in part on results of analyzing the sensor information, wherein the classification is one of an intentional touch interaction, an unintentional touch interaction, or an unintentional hover interaction, with the touch sensitive surface.
18. The system of claim 17, wherein, in response to determining that the touch interaction is the intentional touch interaction of the object with the touch sensitive surface, the touch controller generates a notification signal regarding the intentional touch interaction and communicates the notification signal to the application processor.
19. The system of claim 18, wherein, in response to receiving the notification signal, the application processor switches from the inactive state to the active state, switches a display screen component of the device from an off state to an on state, and processes the touch interaction to perform an operation based at least in part on the touch interaction.
20. The system of claim 17, wherein, in response to determining that the touch interaction or the hover interaction is the unintentional touch interaction or the unintentional hover interaction of the object with the touch sensitive surface, the touch controller component rejects the unintentional touch interaction or the unintentional hover interaction, wherein no notification signal is communicated by the touch controller component to the application processor to switch the application processor to the active state, and wherein the application processor remains in the inactive state.
21. The system of claim 11, wherein the object is a finger of a user of the device, an ear of the user, a portion of a face of the user, a palm of the user, or a stylus;
wherein an unintentional touch interaction comprises an unintentional finger touch of the finger of the user, an unintentional touch of the ear of the user, an unintentional touch of the portion of the face of the user, an unintentional touch of the palm of the user, or an unintentional touch of the stylus, on the touch sensitive surface;
wherein an unintentional hover interaction comprises an unintentional hover of the finger of the user, an unintentional hover of the ear of the user, an unintentional hover of the portion of the face of the user, an unintentional hover of the palm of the user, or an unintentional hover of the stylus, in proximity to the touch sensitive surface; and
wherein an intentional touch interaction comprises an intentional finger touch of the finger of the user on the touch sensitive surface or an intentional touch of the stylus on the touch sensitive surface.
22. The system of claim 11, wherein the application processor comprises a touch classification engine, wherein the touch controller component comprises a hover classification engine, wherein the touch classification engine or the hover classification engine analyze sensor information associated with the touch sensitive surface or the device, and wherein the touch classification engine or the hover classification engine determines a classification of the touch interaction or the hover interaction as one of an intentional touch interaction, an unintentional touch interaction, or an unintentional hover interaction, of the object with the touch sensitive surface, based at least in part on results of the analysis of the sensor information.
23. The system of claim 22, wherein the sensor information comprises touch surface information associated with the touch sensitive surface, accelerometer information associated with the device, gyroscope information associated with the device, ultrasonic information associated with the device, vibro-acoustic information associated with the device, inertial measurement unit information associated with the device, acceleration information indicating an acceleration of the device, velocity information indicating a velocity of the device, angular rate information indicating an angular rate of the device, position information indicating a position or a change in position of the device, or orientation information indicating an orientation or a change in orientation of the device.
24. The system of claim 22, wherein the application processor or the touch controller component receive the sensor information from at least one sensor of a set of sensors associated with the touch sensitive surface, an accelerometer, a gyroscope, an ultrasonic sensor, or an inertial measurement unit.
25. The system of claim 22, wherein the touch classification engine or the hover classification engine compare first characteristics of the sensor information to second characteristics relating to unintentional touch interactions associated with the touch sensitive surface and third characteristics relating to intentional touch interactions associated with the touch sensitive surface, and determines the classification of the touch interaction or the hover interaction based at least in part on a result of the comparison of the first characteristics to the second characteristics and the third characteristics.
26. The system of claim 11, further comprising a buffer component that stores at least a portion of at least one of motion-related information associated with the device or touch surface information associated with the touch sensitive surface, to facilitate analysis of at least the portion of the motion-related information or the touch surface information by at least one of the application processor or the touch controller component.
27. A machine-readable medium, comprising executable instructions that, when executed by a processor, facilitate performance of operations, comprising:
in connection with an electronic device being used with a phone application for a phone call or a non-data application that does not utilize an application processor of the electronic device, determining whether there is a touch interaction or a hover interaction by an object with a touch sensitive surface of the electronic device; and
managing activity modes of the application processor based at least in part on a result of the determining of whether there is the touch interaction or the hover interaction by the object with the touch sensitive surface, wherein the activity modes comprise at least an awake mode and a sleep mode.
28. The machine-readable medium of claim 27, wherein the operations further comprise:
at least one of:
with the application processor in the awake state, in response to determining that the touch interaction or the hover interaction is an unintentional touch interaction or an unintentional hover interaction of the object with the touch sensitive surface, rejecting the unintentional touch interaction or the unintentional hover interaction, and transitioning the application processor from the awake state to the sleep state; or
with the application processor in the sleep state, in response to determining that the touch interaction is an intentional touch interaction of the object with the touch sensitive surface, or in response to determining there is no touch or hover interaction of the object with the touch sensitive surface, or in response to determining there is no touch or hover interaction of the object, when the object comprises an ear or a face of a user of the electronic device, with the touch sensitive surface, generating a notification signal regarding the intentional touch interaction, and
transmitting the notification signal from a touch controller of the electronic device to the application processor to facilitate transitioning the application processor from the sleep state to the awake state.
</claims>
</document>
