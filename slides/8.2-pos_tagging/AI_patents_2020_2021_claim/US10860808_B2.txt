<document>

<filing_date>
2019-02-04
</filing_date>

<publication_date>
2020-12-08
</publication_date>

<priority_date>
2015-08-25
</priority_date>

<ipc_classes>
G06F17/27,G06F17/28,G06F40/205,G06F40/30,G06F40/44,G06F40/55
</ipc_classes>

<assignee>
ALIBABA GROUP
</assignee>

<inventors>
LIN FENG
LUO, WEIHUA
SONG, KAI
</inventors>

<docdb_family_id>
58095636
</docdb_family_id>

<title>
Method and system for generation of candidate translations
</title>

<abstract>
Implementations herein relate to methods and devices for generating candidate translations and for quantizing text as well as words. A method may include generating, by a computing device, pending candidate translations of text to be translated based on predetermined translation rules. The computing device may generate translation probabilities from the text to be translated to the pending candidate translations based on features having impacts on translation probabilities of the pending candidate translations and a predetermined translation probability prediction model. The computing device may then select a predetermined number of pending candidate translations that have the translation probabilities higher than other pending candidate translations in the pending candidate translations to be the candidate translations of the text to be translated. In implementations, the features having impacts on the translation probabilities may include degrees of semantic similarity between the text to be translated and the candidate translations.
</abstract>

<claims>
1. A device for quantification of text, the device comprising: one or more processors; and memory to maintain a plurality of components executable by the one or more processors, the plurality of components comprising: an acquiring module configured to acquire a text to be quantized; mapping module configured to acquire word vectors corresponding to words of the text to be translated based on a predetermined correspondence relationship between the words in a source language and the word vectors; and a predicting module configured to generate a text vector of the text to be quantized based on the word vectors corresponding to the words of the text to be quantized and a predetermined text vector prediction model of a first language corresponding to a language of the text to be quantized, wherein the word vectors are capable of showing bilingual semantic information, and the text vector is capable of showing bilingual semantic information.
2. The device of claim 1, wherein the plurality of components further comprise: a parsing module configured to parse the text to be quantized and acquire the words of the text to be quantized.
3. The device of claim 1, wherein the plurality of components further comprise: a generating module configured to generate the text vector prediction model of the first language.
4. The device of claim 3, wherein the generating module comprises: a reading sub-module configured to read a pre-stored parallel corpus; a training sub-module configured to: set a training goal as to maximize average translation probabilities of sentences in the parallel corpus between a target language and the corresponding source language as background, and train a predetermined bilingual encoding and decoding model for text vectors; a setting sub-module configured to: if the language of the text to be quantized is the source language, designate an encoding part of the bilingual encoding and decoding model for the text vectors as the text vector prediction model of the first language, and if the language of the text to be quantized is the target language, designate a reverse model of the encoding part of the trained bilingual encoding and decoding model for text vectors as the text vector prediction model of the first language; wherein: an input layer of the bilingual encoding and decoding model for text vectors comprises words of sentences of the source language and the word vectors corresponding to the words of the sentences of the source language, an output layer of the bilingual encoding and decoding model for text vectors comprises words of sentences of the target language and word vectors corresponding to the words of the sentences of the target language, the input layer of the encoding part comprises text vectors of the sentences of the source language, and the text vectors of the sentences of the source language comprise the input layer of the encoding part.
5. The device of claim 4, wherein the generating module further comprises: a parsing sub-module configured to: parse sentences in the parallel corpus, and acquire words of the source language and words of the target language in the parallel corpus; an initializing sub-module configured to: set word vectors having a first predetermined dimension for the words of the source language in the parallel corpus, form a correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors, set word vectors having a first predetermined dimension for the words of the target language in the parallel corpus, and form a correspondence relationship to be adjusted between the words of the target language in the parallel corpus and the word vectors.
6. The device of claim 4, wherein the training module comprises: a first calculating sub-module configured to: traverse parallel corpora of sentence pairs of the parallel corpus sentences, calculate translation probabilities between sentences of the target language of the parallel corpora of sentence pairs and corresponding sentences in the source language as the background based on the correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors, the correspondence relationship to be adjusted between the words of a target language and the word vectors, and the predetermined bilingual encoding and decoding model for text vectors; a second calculating sub-module configured to calculate an average value of the translation probabilities between sentences in the target language of the parallel corpora of sentence pairs and corresponding sentences in the source language as the background to be designated as an average translation probability; a determining sub-module configured to: determine whether the average translation probability is greater than a previous average translation probability, in response to a determination that the average translation probability is greater than the previous average translation probability: adopt an optimization algorithm, update the word vectors and connection weights of the predetermined bilingual encoding and decoding model for text vectors, and re-traverse the parallel corpora of sentence pairs of the parallel corpus sentences; a setting sub-module configured to: in response to a determination that the average translation probability is not greater than the previous average translation probability: if the language of the text to be quantized is the source language, designate the adjusted correspondence relationship to be adjusted between the words of the source language and the word vectors as the predetermined correspondence relationship between the words of the source language and the word vectors, and if the language of the text to be quantized is the target language, designate the adjusted correspondence relationship to be adjusted between the words of the target language and the word vectors as the predetermined correspondence relationship between the words of the target language and the word vectors.
7. One or more computer-readable media storing executable instructions that, when executed by one or more processors, cause the one or more processors to perform acts comprising: reading a pre-stored parallel corpus; parsing sentences in the parallel corpus; acquiring words of a source language and words of a target language in the parallel corpus; setting word vectors having a first predetermined dimension for the words of the source language in the parallel corpus; forming a correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors; setting word vectors having a first predetermined dimension for the words of the target language in the parallel corpus; forming a correspondence relationship to be adjusted between the words of the target language in the parallel corpus and the word vectors; training a predetermined bilingual encoding and decoding model for text vectors based on the parallel corpus; and adjusting the correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors and the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors to learn word vectors capable of showing semantic information in the source language and word vectors capable of showing semantic information in the target language.
8. The one or more computer-readable media of claim 7, wherein the bilingual prediction model for text vectors is a bilingual encoding and decoding model for text vectors, and wherein training the predetermined bilingual encoding and decoding model for text vectors based on the parallel corpus and adjusting the correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors and the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors to learn word vectors capable of showing semantic information in the source language and word vectors capable of showing semantic information in the target language are implemented by: setting a training goal as to maximize average translation probabilities of sentences in the parallel corpus between the target language and the corresponding source language as background and the training the predetermined bilingual encoding and decoding model for the text vectors; adjusting the correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors and the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors; acquiring the word vectors capable of showing semantic information in the source language, the word vectors capable of showing semantic information in the target language, wherein: an input layer of the bilingual encoding and decoding model for text vectors comprises words of sentences of the source language and the word vectors corresponding to the words of the sentences of the source language, an output layer of the bilingual encoding and decoding model for text vectors comprises words of sentences of the target language and word vectors corresponding to the words of the sentences of the target language, the input layer of the encoding part comprises text vectors of the sentences of the source language, and the text vectors of the sentences of the source language comprise the input layer of the encoding part.
9. The one or more computer-readable media of claim 7, wherein the setting the training goal as to maximize average translation probabilities of the sentences in the parallel corpus between the target language and the corresponding source language as background, and training the predetermined bilingual encoding and decoding model for the text vectors, adjusting the correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors and the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors, and acquiring the word vectors capable of showing semantic information in the source language and word vectors capable of showing semantic information in the target language comprise: traversing parallel corpora of sentence pairs of the parallel corpus sentence; calculating translation probabilities between sentences of the target language of the parallel corpora of sentence pairs and corresponding sentences in the source language as the background based on the correspondence relationship to be adjusted between the words of the source language and the word vectors, a correspondence relationship to be adjusted between the words of the target language and the word vectors, and the predetermined bilingual encoding and decoding model for text vectors; calculating an average value of the translation probabilities between the sentences in the target language of the parallel corpora of sentence pairs and the corresponding sentences in the source language as the background to be an average translation probability; determining whether the average translation probability is greater than a previous average translation probability; in response to a determination that the average translation probability is greater than the previous average translation probability: adopting an optimization algorithm, updating the correspondence relationship to be adjusted between the words of the source language and the word vectors and the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors, and connection weights of the bilingual encoding and decoding model for text vectors, and re-traversing the parallel corpora of sentence pairs of the parallel corpus sentences; in response to a determination that the average translation probability is not greater than the previous average translation probability: designating the word vectors of the adjusted correspondence relationship to be adjusted between the words of the source language and the word vectors as the word vectors capable of showing semantic information in the source language, and designating the adjusted correspondence relationship to be adjusted between the words of the target language and the word vectors as the predetermined correspondence relationship between the words of the target language and the word vectors as the word vectors capable of showing semantic information in the source language.
10. The one or more computer-readable media of claim 9, wherein adopting the optimization algorithm comprises adopting a stochastic gradient algorithm, and wherein adopting an optimization algorithm and updating the correspondence relationship to be adjusted between the words of the source language and the word vectors and the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors and connection weights of the bilingual encoding and decoding model for text vectors comprise: calculating the correspondence relationship to be adjusted between the words of the source language and the word vectors and a gradient of the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors, and gradients of the connection weights of the bilingual encoding and decoding model for text vectors based on a predetermined learning rate and an equation of the average translation probability; and updating the correspondence relationship to be adjusted between the words of the source language and the word vectors, the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors, and the connection weights of the predetermined bilingual encoding and decoding model for text vectors based on the correspondence relationship to be adjusted between the words of the source language and the word vectors and the gradient of the word vectors of the correspondence relationship to be adjusted between the words of the target language and the word vectors, and gradients of the connection weights of the bilingual encoding and decoding model for text vectors.
11. A method, comprising: acquiring a text to be quantized; acquiring word vectors corresponding to words of the text to be translated based on a predetermined correspondence relationship between the words in a source language and the word vectors; and generating a text vector of the text to be quantized based on the word vectors corresponding to the words of the text to be quantized and a predetermined text vector prediction model of a first language corresponding to a language of the text to be quantized, wherein the word vectors are capable of showing bilingual semantic information, and the text vector is capable of showing bilingual semantic information.
12. The method of claim 11, further comprising: parsing the text to be quantized; and acquiring the words of the text to be quantized.
13. The method of claim 11, further comprising: generating the text vector prediction model of the first language.
14. The method of claim 13, further comprising: reading a pre-stored parallel corpus; setting a training goal as to maximize average translation probabilities of sentences in the parallel corpus between a target language and the corresponding source language as background; training a predetermined bilingual encoding and decoding model for text vectors; if the language of the text to be quantized is the source language, designating an encoding part of the bilingual encoding and decoding model for the text vectors as the text vector prediction model of the first language; and if the language of the text to be quantized is the target language, designating a reverse model of the encoding part of the trained bilingual encoding and decoding model for text vectors as the text vector prediction model of the first language; wherein: an input layer of the bilingual encoding and decoding model for text vectors comprises words of sentences of the source language and the word vectors corresponding to the words of the sentences of the source language, an output layer of the bilingual encoding and decoding model for text vectors comprises words of sentences of the target language and word vectors corresponding to the words of the sentences of the target language, the input layer of the encoding part comprises text vectors of the sentences of the source language, and the text vectors of the sentences of the source language comprise the input layer of the encoding part.
15. The method of claim 14, further comprising: parsing sentences in the parallel corpus, acquiring words of the source language and words of the target language in the parallel corpus; setting word vectors having a first predetermined dimension for the words of the source language in the parallel corpus, forming a correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors; setting word vectors having a first predetermined dimension for the words of the target language in the parallel corpus; and forming a correspondence relationship to be adjusted between the words of the target language in the parallel corpus and the word vectors.
16. The method of claim 14, further comprising: traversing parallel corpora of sentence pairs of the parallel corpus sentences; calculating translation probabilities between sentences of the target language of the parallel corpora of sentence pairs and corresponding sentences in the source language as the background based on the correspondence relationship to be adjusted between the words of the source language in the parallel corpus and the word vectors, the correspondence relationship to be adjusted between the words of a target language and the word vectors, and the predetermined bilingual encoding and decoding model for text vectors; calculating an average value of the translation probabilities between sentences in the target language of the parallel corpora of sentence pairs and corresponding sentences in the source language as the background to be designated as an average translation probability; determining whether the average translation probability is greater than a previous average translation probability; in response to a determination that the average translation probability is greater than the previous average translation probability: adopting an optimization algorithm; updating the word vectors and connection weights of the predetermined bilingual encoding and decoding model for text vectors; and re-traversing the parallel corpora of sentence pairs of the parallel corpus sentences; in response to a determination that the average translation probability is not greater than the previous average translation probability: if the language of the text to be quantized is the source language, designating the adjusted correspondence relationship to be adjusted between the words of the source language and the word vectors as the predetermined correspondence relationship between the words of the source language and the word vectors; and if the language of the text to be quantized is the target language, designating the adjusted correspondence relationship to be adjusted between the words of the target language and the word vectors as the predetermined correspondence relationship between the words of the target language and the word vectors.
</claims>
</document>
