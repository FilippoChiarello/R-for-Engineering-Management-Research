<document>

<filing_date>
2019-06-05
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-05
</priority_date>

<ipc_classes>
G06F11/34,G06F9/451,G06N20/00
</ipc_classes>

<assignee>
BUSINESS OBJECTS SOFTWARE
</assignee>

<inventors>
YAO, CHENG YU
</inventors>

<docdb_family_id>
73650724
</docdb_family_id>

<title>
CONTEXTUAL MODELING USING APPLICATION METADATA
</title>

<abstract>
Provided is a system and method for building context from software applications and applying the context to visual settings in a graphical user interface. In one example, the method may include receiving an identification of actions performed by a user with respect to a user interface of a software application, receiving application metadata of the actions from the software application, the application metadata providing context associated with the actions, training one or more predictive models to predict user interface preferences for the user based on the actions and the application metadata, and storing the one or more trained predictive models via a storage device.
</abstract>

<claims>
1. A computing system comprising: a processor configured to receive an identification of actions performed by a user with respect to a user interface of a software application, receive application metadata of the actions from the software application, the application metadata providing context associated with the actions, and train one or more predictive models to predict user interface preferences for the user based on the actions and the application metadata; and a storage configured to store the one or more trained predictive models.
2. The computing system of claim 1, wherein the processor is configured to train the one or more predictive model to change default visual settings of the user interface based on interactions of the user over time with the default settings of the user interface.
3. The computing system of claim 1, wherein the application metadata comprises at least one of measures and dimensions being viewed with the user interface.
4. The computing system of claim 1, wherein the processor is configured to train a first plurality of contextual models which are associated with a plurality of dimensions of data capable of being viewed with the user interface, respectively.
5. The computing system of claim 1, wherein the processor is configured to train a second plurality of contextual models which are associated with a plurality of measures of data capable of being viewed with the user interface, respectively.
6. The computing system of claim 1, wherein the processor is further configured to receive a request from the user for a visualization of a type of data, and predict user interface preferences of the user for viewing the type of data based on a trained predictive model associated with the type of data.
7. The computing system of claim 6, wherein the processor is configured to predict a drill-down level of the user interface for viewing hierarchical attributes of the type of data via execution of the one or more trained predictive models.
8. The computing system of claim 6, wherein the processor is configured to predict one or more data filters to apply to the type of data for removing unwanted attributes of the type of data via execution of the one or more trained predictive models.
9. A method comprising: receiving an identification of actions performed by a user with respect to a user interface of a software application; receiving application metadata of the actions from the software application, the application metadata providing context associated with the actions; training one or more predictive models to predict user interface preferences for the user based on the actions and the application metadata; and storing the one or more trained predictive models via a storage device.
10. The method of claim 9, wherein the training comprises training the one or more predictive model to change default visual settings of the user interface based on interactions of the user over time with the default settings of the user interface.
11. The method of claim 9, wherein the application metadata comprises at least one of measures and dimensions being viewed with the user interface.
12. The method of claim 9, wherein the training comprises training a first plurality of contextual models which are associated with a plurality of dimensions of data capable of being viewed with the user interface, respectively.
13. The method of claim 9, wherein the training comprises training a second plurality of contextual models which are associated with a plurality of measures of data capable of being viewed with the user interface, respectively.
14. The method of claim 9, further comprising receiving a request from the user for a visualization of a type of data, and predicting user interface preferences of the user for viewing the type of data based on a trained predictive model associated with the type of data.
15. The method of claim 14, wherein the predicting comprises predicting a drill-down level of the user interface for viewing hierarchical attributes of the type of data.
16. The method of claim 14, wherein the predicting comprises predicting one or more data filters to apply to the type of data for removing unwanted attributes of the type of data.
17. A non-transitory computer-readable medium storing program instructions which when executed by a processor cause a computer to perform a method comprising: receiving an identification of actions performed by a user with respect to a user interface of a software application; receiving application metadata of the actions from the software application, the application metadata providing context associated with the actions; training one or more predictive models to predict user interface preferences for the user based on the actions and the application metadata; and storing the one or more trained predictive models via a storage device.
18. The non-transitory computer-readable medium of claim 17, wherein the method further comprises receiving a request from the user for a visualization of a type of data, and predicting user interface preferences of the user for viewing the type of data based on a trained predictive model associated with the type of data.
19. The non-transitory computer-readable medium of claim 17, wherein the predicting comprises predicting a drill-down level of the user interface for viewing hierarchical attributes of the type of data.
20. The non-transitory computer-readable medium of claim 17, wherein the predicting comprises predicting one or more data filters to apply to the type of data for removing unwanted attributes of the type of data.
</claims>
</document>
