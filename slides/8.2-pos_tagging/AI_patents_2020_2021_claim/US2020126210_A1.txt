<document>

<filing_date>
2019-10-16
</filing_date>

<publication_date>
2020-04-23
</publication_date>

<priority_date>
2018-10-19
</priority_date>

<ipc_classes>
G06F16/53,G06F17/15,G06N20/00,G06N3/04,G06T7/00
</ipc_classes>

<assignee>
GENENTECH
</assignee>

<inventors>
LI, ZHENG
</inventors>

<docdb_family_id>
70280742
</docdb_family_id>

<title>
Defect Detection in Lyophilized Drug Products with Convolutional Neural Networks
</title>

<abstract>
In one embodiment, a method includes receiving one or more querying images associated with a container of a pharmaceutical product, each of the one or more querying images being based on a particular angle of the container of the pharmaceutical product, calculating one or more confidence scores associated with one or more defect indications, respectively for the container of the pharmaceutical product, by processing the one or more querying images using a target machine-learning model, and determining a defect indication for the container of the pharmaceutical product from the one or more defect indications based on a comparison between the one or more confidence scores and one or more predefined threshold scores, respectively.
</abstract>

<claims>
1. A method comprising, by a computing system: receiving one or more querying images associated with a container of a pharmaceutical product, wherein each of the one or more querying images is based on a particular angle of the container of the pharmaceutical product; calculating, for the container of the pharmaceutical product, one or more confidence scores associated with one or more defect indications, respectively, by processing the one or more querying images using a target machine-learning model; and determining, for the container of the pharmaceutical product, a defect indication from the one or more defect indications based on a comparison between the one or more confidence scores and one or more predefined threshold scores, respectively.
2. The method of claim 1, wherein calculating the one or more confidence scores associated with the one or more defect indications for the one or more querying images comprises: generating one or more feature representations of the one or more querying images by processing the one or more querying images using the target machine-learning model; and calculating the one or more confidence scores associated with the one or more defect indications based on one or more of: a relationship between the feature representations of the plurality of target training images and the plurality of defect indications; or the generated one or more feature representations of the one or more querying images.
3. The method of claim 1, further comprising: obtaining the one or more querying images using one or more optical camera sensors, wherein the one or more optical camera sensors capture the one or more querying images for the container of the pharmaceutical product from one or more angles, respectively.
4. The method of claim 1, wherein the container comprises one or more of a cap, a seal, a stopper, a neck, a shoulder, a body, or a base.
5. The method of claim 1, wherein the pharmaceutical product comprises a lyophilized product.
6. The method of claim 5, wherein the lyophilized product is associated with one or more product-attributes, wherein each product-attribute is a physical form factor, a color, a level of transparency, viscosity, or a fill volume.
7. The method of claim 1, wherein the defect indication comprises one or more of a critical defect, a major defect, or a minor defect.
8. The method of claim 7, wherein the pharmaceutical product comprises a lyophilized product, and wherein the critical defect comprises one or more of a cake appearance defect or a fill volume defect.
9. The method of claim 8, wherein the cake appearance defect comprises one or more of a meltback, an extreme shrunken cake, an un-lyophilized cake, or a discoloration.
10. The method of claim 7, wherein the pharmaceutical product comprises a lyophilized product, and wherein the major defect comprises a cake appearance defect, the cake appearance defect comprising one or more of an extreme product splash, a slanted cake, or a shrunken cake.
11. The method of claim 1, wherein the target machine-learning model is based on a convolutional neural network.
12. The method of claim 1, wherein each of the one or more predefined threshold scores is determined based on an acceptance quality limit associated with the defect indication.
13. The method of claim 1, further comprising: accessing a plurality of target training samples, the target training samples comprising a plurality of target training images associated with containers of the pharmaceutical product and a plurality of defect indications associated with the plurality of target training images, respectively; selecting a plurality of auxiliary training samples based on the target training samples, the auxiliary training samples comprising a plurality of auxiliary training images and a plurality of content categories associated with the plurality of auxiliary training images, respectively; and training the target machine-learning model, the training comprising: training an auxiliary machine-learning model based on the plurality of auxiliary training samples; generating feature representations of the plurality of target training images based on the auxiliary machine-learning model; and learning, based on the generated feature representations and the plurality of defect indications, a relationship between the feature representations of the plurality of target training images and the plurality of defect indications.
14. The method of claim 13, wherein the pharmaceutical product comprises a lyophilized product, and wherein the lyophilized product is visible inside the containers in at least one of the target training images.
15. The method of claim 13, further comprising: obtaining the plurality of target training images using one or more optical camera sensors, wherein the one or more optical camera sensors capture one or more images for a selected product from one or more angles, respectively.
16. The method of claim 15, further comprising: dividing the plurality of target training images into one or more groups of target training images, the one or more groups being associated with the one or more camera sensors, respectively.
17. The method of claim 16, wherein training the target machine-learning model further comprises: generating one or more groups of feature representations for the one or more groups of target training images associated with the respective camera sensors, respectively; learning, based on the one or more groups of feature representations, one or more sub-models, respectively; and integrating the one or more sub-models to generate the target machine-learning model.
18. The method of claim 17, wherein the target machine-learning model is based on a convolutional neural network comprising a plurality of layers, and wherein generating the one or more groups of feature representations for the one or more groups of target training images associated with the respective camera sensors, respectively, comprises: dividing the plurality of layers into one or more groups of layers corresponding to the one or more camera sensors, respectively; and processing the one or more groups of target training images associated with the respective camera sensors by the one or more groups of layers.
19. The method of claim 13, wherein the plurality of content categories comprises a plurality of handwritten numeric digits.
20. The method of claim 13, wherein the plurality of content categories associated with the plurality of auxiliary training images do not match the plurality of defect indications associated with the plurality of target training images.
21. One or more computer-readable non-transitory storage media embodying software that is operable when executed to: receive one or more querying images associated with a container of a pharmaceutical product, wherein each of the one or more querying images is based on a particular viewpoint of the container of the pharmaceutical product; calculate, for the container of the pharmaceutical product, one or more confidence scores associated with one or more defect indications, respectively, by processing the one or more querying images using a target machine-learning model; and determine, for the container of the pharmaceutical product, a defect indication from the one or more defect indications based on a comparison between the one or more confidence scores and one or more predefined threshold scores, respectively.
22. An apparatus comprising: one or more cameras, wherein each camera corresponds to a different angle of view; one or more sensors; one or more lights; one or more trays; one or more height controls; one or more processors; and a non-transitory memory coupled to the processors comprising instructions executable by the processors, the processors operable when executing the instructions to: receive one or more querying images associated with a container of a pharmaceutical product, wherein each of the one or more querying images is based on a particular viewpoint of the container of the pharmaceutical product; calculate, for the container of the pharmaceutical product, one or more confidence scores associated with one or more defect indications, respectively, by processing the one or more querying images using a target machine-learning model; and determine, for the container of the pharmaceutical product, a defect indication from the one or more defect indications based on a comparison between the one or more confidence scores and one or more predefined threshold scores, respectively.
</claims>
</document>
