<document>

<filing_date>
2018-09-20
</filing_date>

<publication_date>
2020-10-13
</publication_date>

<priority_date>
2018-09-20
</priority_date>

<ipc_classes>
G06N99/00,G06T1/00,G06T9/00,H04N19/426,H04N19/62,H04N19/625,H04N19/63
</ipc_classes>

<assignee>
AT&T INTELLECTUAL PROPERTY I (AMERICAN TELEPHONE AND TELEGRAPH COMPANY INTELLECTUAL PROPERTY I)
</assignee>

<inventors>
GOPALAN, RAGHURAMAN
</inventors>

<docdb_family_id>
69884951
</docdb_family_id>

<title>
Enabling secure video sharing by exploiting data sparsity
</title>

<abstract>
In one example, the present disclosure describes a device, computer-readable medium, and method for enabling secure video sharing by exploiting data sparsity. In one example, the method includes applying a transformation to a video dataset containing a plurality of video samples, to produce a plurality of sparse vectors in a first dimensional space, wherein each sparse vector of the plurality of sparse vectors corresponds to one video sample of the plurality of video samples, and multiplying each sparse vector of the plurality of sparse vectors by a transformation matrix to produce a plurality of reduced vectors in a second dimensional space, wherein the dimension of the second dimensional space is smaller than a dimension of the first dimensional space, and wherein the plurality of reduced vectors in the second dimensional space hides information about the video dataset while preserving relational properties between the plurality of video samples.
</abstract>

<claims>
1. A method, comprising: applying, by a processor, a transformation to a video dataset containing a plurality of video samples, to produce a plurality of sparse vectors in a first dimensional space, wherein each sparse vector of the plurality of sparse vectors corresponds to one video sample of the plurality of video samples; multiplying, by the processor, each sparse vector of the plurality of sparse vectors by a transformation matrix to produce a plurality of reduced vectors in a second dimensional space, wherein a dimension of the second dimensional space is smaller than a dimension of the first dimensional space, and wherein the plurality of reduced vectors in the second dimensional space hides information about the video dataset while preserving relational properties between the plurality of video samples; providing, by the processor, the plurality of reduced vectors as inputs to a machine learning technique that trains a machine learning model; acquiring, by the processor, a new vector in the second dimensional space through operation of the machine learning model; and transforming, by the processor, the new vector, using the transformation matrix, into the first dimensional space.
2. The method of claim 1, wherein the transformation comprises a wavelet transform.
3. The method of claim 1, wherein the transformation comprises a Fourier transform.
4. The method of claim 1, wherein the transformation comprises a discrete cosine transform.
5. The method of claim 1, wherein the video dataset is labeled.
6. The method of claim 1, wherein the transformation matrix is an M×N matrix, wherein N is the dimension of the first dimensional space, and wherein M is the dimension of the second dimensional space.
7. The method of claim 6, wherein the M×N matrix is a random matrix.
8. The method of claim 1, wherein the relational properties comprise pairwise distances.
9. The method of claim 8, wherein distance ratios between pairs of the plurality of sparse vectors are equal to distance ratios between pairs of the plurality of reduced vectors corresponding to the pairs of the plurality of sparse vectors.
10. The method of claim 1, wherein the transformation matrix allows transformation of the plurality of reduced vectors back into the video dataset.
11. A device, comprising: a processor; and a non-transitory computer-readable medium storing instructions which, when executed by the processor, cause the processor to perform operations, the operations comprising: applying a transformation to a video dataset containing a plurality of video samples, to produce a plurality of sparse vectors in a first dimensional space, wherein each sparse vector of the plurality of sparse vectors corresponds to one video sample of the plurality of video samples; multiplying each sparse vector of the plurality of sparse vectors by a transformation matrix to produce a plurality of reduced vectors in a second dimensional space, wherein a dimension of the second dimensional space is smaller than a dimension of the first dimensional space, and wherein the plurality of reduced vectors in the second dimensional space hides information about the video dataset while preserving pairwise distances between the plurality of video samples; providing the plurality of reduced vectors as inputs to a machine learning technique that trains a machine learning model; acquiring a new vector in the second dimensional space through operation of the machine learning model; and transforming the new vector, using the transformation matrix, into the first dimensional space.
12. A non-transitory computer-readable medium storing instructions which, when executed by a processor, cause the processor to perform operations, the operations comprising: applying a transformation to a video dataset containing a plurality of video samples, to produce a plurality of sparse vectors in a first dimensional space, wherein each sparse vector of the plurality of sparse vectors corresponds to one video sample of the plurality of video samples; multiplying each sparse vector of the plurality of sparse vectors by a transformation matrix to produce a plurality of reduced vectors in a second dimensional space, wherein a dimension of the second dimensional space is smaller than a dimension of the first dimensional space, and wherein the plurality of reduced vectors in the second dimensional space hides information about the video dataset while preserving pairwise distances between the plurality of video samples; providing the plurality of reduced vectors as inputs to a machine learning technique that trains a machine learning model; acquiring a new vector in the second dimensional space through operation of the machine learning model; and transforming the new vector, using the transformation matrix, into the first dimensional space.
13. The non-transitory computer-readable medium of claim 12, wherein the transformation matrix is an M×N matrix, wherein N is the dimension of the first dimensional space, and wherein M is the dimension of the second dimensional space.
14. The non-transitory computer-readable medium of claim 13, wherein the M×N matrix is a random matrix.
15. The non-transitory computer-readable medium of claim 12, wherein the relational properties comprise pairwise distances.
16. The non-transitory computer-readable medium of claim 15, wherein distance ratios between pairs of the plurality of sparse vectors are equal to distance ratios between pairs of the plurality of reduced vectors corresponding to the pairs of the plurality of sparse vectors.
17. The non-transitory computer-readable medium of claim 12, wherein the transformation matrix allows transformation of the plurality of reduced vectors back into the video dataset.
18. The non-transitory computer-readable medium of claim 12, wherein the transformation comprises a wavelet transform.
19. The non-transitory computer-readable medium of claim 12, wherein the transformation comprises a Fourier transform.
20. The non-transitory computer-readable medium of claim 12, wherein the transformation comprises a discrete cosine transform.
</claims>
</document>
