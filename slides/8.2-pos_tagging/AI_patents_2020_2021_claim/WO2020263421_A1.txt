<document>

<filing_date>
2020-05-06
</filing_date>

<publication_date>
2020-12-30
</publication_date>

<priority_date>
2019-06-28
</priority_date>

<ipc_classes>
G06N3/04
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
CHEN CHENG
YANG, MAO
LIU, SHUGUANG
LIN, Haoxiang
</inventors>

<docdb_family_id>
70922144
</docdb_family_id>

<title>
VISUAL PROGRAMMING FOR DEEP LEARNING
</title>

<abstract>
Implementations of the present disclosure relate to visual programming for deep learning. A computer-implemented method comprises presenting a visual representation of an artificial neural network, the visual representation comprising graphical elements representing layers of the artificial neural network; in response to receiving a drag-and-drop operation on the graphical elements, modifying an intermediate representation of the artificial neural network, wherein the intermediate representation is independent of a deep learning framework and the drag-and-drop operation is configured to modify connections between the graphical elements; and modifying, based on the intermediate representation of the artificial neural network, code of the artificial neural network for a target deep learning framework.
</abstract>

<claims>
1. A computer-implemented method, comprising:
presenting a visual representation of an artificial neural network, the visual representation comprising graphical elements representing layers of the artificial neural network;
in response to receiving a drag-and-drop operation on the graphical elements, modifying an intermediate representation of the artificial neural network, wherein the intermediate representation is independent of a deep learning framework and the drag-anddrop operation is configured to modify connections between the graphical elements; and modifying, based on the intermediate representation of the artificial neural network, code of the artificial neural network for a target deep learning framework.
2. The method of claim 1, further comprising:
in response to an editing operation on the code, modifying the intermediate representation of the artificial neural network; and
adjusting the visual representation of the artificial neural network based on the modified intermediate representation.
3. The method of claim 1, further comprising:
in response to receiving the drag-and-drop operation on the graphical elements, validating dimensions of data associated with the layers of the artificial neural network.
4. The method of claim 1, further comprising:
in response to receiving a search operation associated with a keyword, presenting graphical elements representing at least one candidate layer corresponding to the keyword; and
in response to receiving a selection of graphical elements of the at least one candidate layer, adding the selected graphical elements to the visual representation.
5. The method of claim 1, further comprising:
presenting code stubs for customizing metrics of the artificial neural network; and in response to an editing operation on the code stubs, customizing the metrics of the artificial neural network.
6. The method of claim 1, further comprising:
modifying the intermediate representation of the artificial neural network in response to at least one of:
adding, into the visual representation, a new graphical element representing a layer of the artificial neural network; deleting, from the visual representation, a graphical elements representing a layer of the artificial neural network; and
modifying parameters of a graphical element representing a layer of the artificial neural network.
7. The method of claim 1, further comprising:
in response to receiving an instruction for changing the target deep learning framework to a further target deep learning framework, determining code of the artificial neural network for the further deep learning framework based on the intermediate representation of the artificial neural network.
8. A device comprising:
a processing unit; and
a memory coupled to the processing unit and having instructions stored thereon, the instructions, when executed by the processing unit, causing the device to perform acts comprising:
presenting a visual representation of an artificial neural network, the visual representations including graphical elements representing layers of the artificial neural network;
in response to receiving a drag-and-drop operation on the graphical elements, modifying an intermediate representation of the artificial neural network, wherein the intermediate representation is independent of a deep learning framework and the drag-anddrop operation is configured to modify connections between the graphical elements; and modifying, based on the intermediate representation of the artificial neural network, code of the artificial neural network for a target deep learning framework.
9. The device of claim 8, wherein the acts further comprise:
in response to an editing operation on the code, modifying the intermediate representation of the artificial neural network; and
adjusting, based on the modified intermediate representation, the visual representation of the artificial neural network.
10. The device of claim 8, wherein the acts further comprise:
in response to receiving the drag-and-drop operation on the graphical elements, validating dimensions of data associated with the layers of the artificial neural network.
11. The device of claim 8, wherein the acts further comprise:
in response to receiving a search operation associated with a keyword, presenting graphical elements representing at least one candidate layer corresponding to the keyword; and
in response to receiving a selection of graphical elements of the at least one candidate layer, adding the selected graphical elements to the visual representation.
12. The device of claim 8, wherein the acts further comprise:
presenting code stubs for customizing metrics of the artificial neural network; and in response to an editing operation on the code stubs, customizing the metrics of the artificial neural network.
13. The device of claim 8, wherein the acts further comprise:
modifying the intermediate representation of the artificial neural network in response to at least one of:
adding, into the visual representation, a new graphical element representing a layer of the artificial neural network;
deleting, from the visual representation, a graphical element representing a layer of the artificial neural network; and
modifying parameters of a graphical element representing a layer of the artificial neural network.
14. The device of claim 8, wherein the acts further comprise:
in response to receiving an instruction for changing the target deep learning framework to a further target deep learning framework, determining code of the artificial neural network for the further deep learning framework based on the intermediate representation of the artificial neural network.
15. A computer program product stored in a computer storage medium and comprising computer-executable instructions which, when executed by a device, cause the device to perform acts comprising:
presenting a visual representation of an artificial neural network, the visual representations including graphical elements representing layers of the artificial neural network;
in response to receiving a drag-and-drop operation on the graphical elements, modifying an intermediate representation of the artificial neural network, wherein the intermediate representation is independent of a deep learning framework and the drag-anddrop operation is configured to modify connections between the graphical elements; and modifying, based on the intermediate representation of the artificial neural network, code of the artificial neural network for a target deep learning framework.
</claims>
</document>
