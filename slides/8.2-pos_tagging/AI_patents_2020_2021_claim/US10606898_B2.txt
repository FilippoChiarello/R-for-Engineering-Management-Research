<document>

<filing_date>
2018-04-19
</filing_date>

<publication_date>
2020-03-31
</publication_date>

<priority_date>
2017-04-19
</priority_date>

<ipc_classes>
G06F15/76,G06F16/9032,G06F17/28,G06F17/30,G06N20/00,G06N3/00,G06N3/04,G06N3/08,G06N7/00,G10L15/10,G10L15/20,G10L15/22
</ipc_classes>

<assignee>
BROWN UNIVERSITY
</assignee>

<inventors>
ARUMUGAM, DILIP
GOPALAN, NAKUL
KARAMCHETI, SIDDHARTH
TELLEX, STEFANIE
WONG, LAWSON L. S.
</inventors>

<docdb_family_id>
63854624
</docdb_family_id>

<title>
Interpreting human-robot instructions
</title>

<abstract>
A system includes a robot having a module that includes a function for mapping natural language commands of varying complexities to reward functions at different levels of abstraction within a hierarchical planning framework, the function including using a deep neural network language model that learns how to map the natural language commands to reward functions at an appropriate level of the hierarchical planning framework.
</abstract>

<claims>
1. A system comprising: a robot comprising a module to interpret natural language commands, the module comprising a function for mapping natural language commands of varying complexities to reward functions at different levels of abstraction within a hierarchical planning framework, the function comprising: a deep neural network language model that learns how to map the natural language commands to reward functions at an appropriate level of the hierarchical planning framework; an Abstract Markov Decision Process to represent a decision-making problem involving a hierarchy of the robot's states and actions, the Abstract Markov Decision Process comprising: a set of states that define an environment specified in an object-oriented fashion with object classes and attributes; a set of actions an agent can execute to transition between states or to invoke a lower-level AMDP subtask; a transition probability distribution over all possible next states given a current state and executed action; a numerical reward earned for a particular transition; a discount factor or effective time horizon under consideration; and a state projection function that maps lower-level states to higher-level (AMDP) states.
2. A system comprising: a robot comprising a module comprising a function for mapping natural language commands of varying complexities to reward functions at different levels of abstraction within a hierarchical planning framework, the function comprising: a deep neural network language model that learns how to map the natural language commands to reward functions at an appropriate level of the hierarchical planning framework; an Abstract Markov Decision Process to represent a decision-making problem involving a hierarchy of the robot's states and actions, the Abstract Markov Decision Process comprising: a set of states that define an environment specified in an object-oriented fashion with object classes and attributes; a set of actions an agent can execute to transition between states or to invoke a lower-level AMDP subtask; a transition probability distribution over all possible next states given a current state and executed action; a numerical reward earned for a particular transition; a discount factor or effective time horizon under consideration; and a state projection function that maps lower-level states to higher-level (AMDP) states.
3. A method comprising: providing a mobile-manipulator robot; and providing a module that interprets and grounds natural language commands to a mobile-manipulator robot at multiple levels of abstraction, the module comprising a deep neural network language model that learns how to map the natural language commands to reward functions at an appropriate level of a hierarchical planning framework, the functions comprising an Abstract Markov Decision Process to represent a decision-making problem involving a hierarchy of the robot's states and actions, the Abstract Markov Decision Process comprising: a set of states that define an environment specified in an object-oriented fashion with object classes and attributes; a set of actions an agent can execute to transition between states or to invoke a lower-level AMDP subtask; a transition probability distribution over all possible next states given a current state and executed action; a numerical reward earned for a particular transition; a discount factor or effective time horizon under consideration; and a state projection function that maps lower-level states to higher-level (AMDP) states.
</claims>
</document>
