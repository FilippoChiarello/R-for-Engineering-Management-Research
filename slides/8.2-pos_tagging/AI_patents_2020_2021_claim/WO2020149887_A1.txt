<document>

<filing_date>
2019-08-29
</filing_date>

<publication_date>
2020-07-23
</publication_date>

<priority_date>
2019-01-18
</priority_date>

<ipc_classes>
G06N3/063
</ipc_classes>

<assignee>
SILICON STORAGE TECHNOLOGY
</assignee>

<inventors>
DO, NHAN
LEMKE, STEVEN
REITEN, MARK
TIWARI, VIPLN
TRAN HIEU VAN
</inventors>

<docdb_family_id>
71608608
</docdb_family_id>

<title>
NEURAL NETWORK CLASSIFIER USING ARRAY OF THREE-GATE NON-VOLATILE MEMORY CELLS
</title>

<abstract>
A neural network device with synapses having memory cells each having a floating gate and a first gate over first and second portions of a channel region disposed between source and drain regions, and a second gate over the floating gate or the source region. First lines each electrically connect the first gates in one of the memory cell rows, second lines each electrically connect the second gates in one of the memory cell rows, third lines each electrically connect the source regions in one of the memory cell columns, and fourth lines each electrically connect the drain regions in one of the memory cell columns. The synapses receive a first plurality of inputs as electrical voltages on the first or second lines, and provide a first plurality of outputs as electrical currents on the third or fourth lines.
</abstract>

<claims>
1. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over and insulated from a first portion of the channel region, a first gate disposed over and insulated from a second portion of the channel region, and a second gate disposed over and insulated from the floating gate or disposed over and insulated from the source region;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells;
a plurality of second lines each electrically connecting together the second gates in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the source regions in one of the columns of the memory cells;
a plurality of fourth lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines or on the plurality of second lines, and to provide the first plurality of outputs as electrical currents on the plurality of third lines or on the plurality of fourth lines.
2. The neural network device of claim 1 , wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of second lines, and to provide the first plurality of outputs as electrical currents on the plurality of third lines.
3. The neural network device of claim 1, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines, and to provide the first plurality of outputs as electrical currents on the plurality of third lines.
4. The neural network device of claim 1 , wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of second lines, and to provide the first plurality of outputs as electrical currents on the plurality of fourth lines.
5. The neural network device of claim 1 , wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines, and to provide the first plurality of outputs as electrical currents on the plurality of fourth lines.
6. The neural network device of claim 1, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
7. The neural network device of claim 6, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over and insulated from a first portion of the second channel region, a third gate disposed over and insulated from a second portion of the second channel region, and a fourth gate disposed over and insulated from the second floating gate or disposed over and insulated from the second source region;
each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fifth lines each electrically connecting together the third gates in one of the rows of the second memory cells;
a plurality of sixth lines each electrically connecting together the fourth gates in one of the rows of the second memory cells;
a plurality of seventh lines each electrically connecting together the second source regions in one of the columns of the second memory cells;
a plurality of eighth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fifth lines or on the plurality of sixth lines, and to provide the second plurality of outputs as electrical currents on the plurality of seventh lines or on the plurality of eighth lines.
8. The neural network device of claim 7, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of sixth lines, and to provide the second plurality of outputs as electrical currents on the plurality of seventh lines.
9. The neural network device of claim 7, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fifth lines, and to provide the second plurality of outputs as electrical currents on the plurality of seventh lines.
10. The neural network device of claim 7, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of sixth lines, and to provide the second plurality of outputs as electrical currents on the plurality of eighth lines.
11. The neural network device of claim 7, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fifth lines, and to provide the second plurality of outputs as electrical currents on the plurality of eighth lines.
12. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over and insulated from a first portion of the channel region, a first gate disposed over and insulated from a second portion of the channel region, and a second gate disposed over and insulated from the floating gate or disposed over and insulated from the source region;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells;
a plurality of second lines each electrically connecting together the second gates in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of fourth lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines or on the plurality of second lines or on the plurality of third lines, and to provide the first plurality of outputs as electrical currents on the plurality of fourth lines.
13. The neural network device of claim 12, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines.
14. The neural network device of claim 12, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of second lines.
15. The neural network device of claim 12, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of third lines.
16. The neural network device of claim 12, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
17. The neural network device of claim 16, further comprising: a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over and insulated from a first portion of the second channel region, a third gate disposed over and insulated from a second portion of the second channel region, and a fourth gate disposed over and insulated from the second floating gate or disposed over and insulated from the second source region;
each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fifth lines each electrically connecting together the third gates in one of the rows of the second memory cells;
a plurality of sixth lines each electrically connecting together the fourth gates in one of the rows of the second memory cells;
a plurality of seventh lines each electrically connecting together the second source regions in one of the rows of the second memory cells;
a plurality of eighth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fifth lines or on the plurality of sixth lines or on the plurality of seventh lines, and to provide the second plurality of outputs as electrical currents on the plurality of eighth lines.
18. The neural network device of claim 18, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fifth lines.
19. The neural network device of claim 18, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of sixth lines.
20. The neural network device of claim 18, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of seventh lines.
21. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over and insulated from a first portion of the channel region, a first gate disposed over and insulated from a second portion of the channel region, and a second gate disposed over and insulated from the floating gate or disposed over and insulated from the source region;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells; a plurality of second lines each electrically connecting together the second gates in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of fourth lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of fourth lines, and to provide the first plurality of outputs as electrical currents on the plurality of third lines.
22. The neural network device of claim 21 , further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
23. The neural network device of claim 22, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over and insulated from a first portion of the second channel region, a third gate disposed over and insulated from a second portion of the second channel region, and a fourth gate disposed over and insulated from the second floating gate or disposed over and insulated from the second source region;
each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values; wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fifth lines each electrically connecting together the third gates in one of the rows of the second memory cells;
a plurality of sixth lines each electrically connecting together the fourth gates in one of the rows of the second memory cells;
a plurality of seventh lines each electrically connecting together the second source regions in one of the rows of the second memory cells; a plurality of eighth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of eighth lines, and to provide the second plurality of outputs as electrical currents on the plurality of seventh lines.
24. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over and insulated from a first portion of the channel region, a first gate disposed over and insulated from a second portion of the channel region, and a second gate disposed over and insulated from the floating gate or disposed over and insulated from the source region;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises: a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells;
a plurality of second lines each electrically connecting together the second gates in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of fourth lines each electrically connecting together the drain regions in one of the columns of the memory cells;
a plurality of transistors each electrically connected in series with one of the fourth lines;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on gates of the plurality of transistors, and to provide the first plurality of outputs as electrical currents on the plurality of third lines.
25. The neural network device of claim 24, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
26. The neural network device of claim 25, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over and insulated from a first portion of the second channel region, a third gate disposed over and insulated from a second portion of the second channel region, and a fourth gate disposed over and insulated from the second floating gate or disposed over and insulated from the second source region; each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fifth lines each electrically connecting together the third gates in one of the rows of the second memory cells;
a plurality of sixth lines each electrically connecting together the fourth gates in one of the rows of the second memory cells;
a plurality of seventh lines each electrically connecting together the second source regions in one of the rows of the second memory cells; a plurality of eighth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
a second plurality of transistors each electrically connected in series with one of the eighth lines;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on gates of the second plurality of transistors, and to provide the second plurality of outputs as electrical currents on the plurality of seventh lines.
27. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over and insulated from a first portion of the channel region, a first gate disposed over and insulated from a second portion of the channel region, and a second gate disposed over and insulated from the floating gate or disposed over and insulated from the source region;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells;
a plurality of second lines each electrically connecting together the second gates in one of the columns of the memory cells;
a plurality of third lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of fourth lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of second lines or on the plurality of fourth lines, and to provide the first plurality of outputs as electrical currents on the plurality of third lines.
28. The neural network device of claim 27, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of second lines.
29. The neural network device of claim 27, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of fourth lines.
30. The neural network device of claim 27, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
31. The neural network device of claim 30, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over and insulated from a first portion of the second channel region, a third gate disposed over and insulated from a second portion of the second channel region, and a fourth gate disposed over and insulated from the second floating gate or disposed over and insulated from the second source region;
each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fifth lines each electrically connecting together the third gates in one of the rows of the second memory cells;
a plurality of sixth lines each electrically connecting together the fourth gates in one of the columns of the second memory cells;
a plurality of seventh lines each electrically connecting together the second source regions in one of the rows of the second memory cells; a plurality of eighth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of sixth lines or on the plurality of eighth lines, and to provide the second plurality of outputs as electrical currents on the plurality of seventh lines.
32. The neural network device of claim 31 , wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of sixth lines.
33. The neural network device of claim 31 , wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of eighth lines.
34. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over and insulated from a first portion of the channel region, a first gate disposed over and insulated from a second portion of the channel region, and a second gate disposed over and insulated from the floating gate or disposed over and insulated from the source region;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together the first gates in one of the columns of the memory cells; a plurality of second lines each electrically connecting together the second gates in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of fourth lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines or on the plurality of fourth lines, and to provide the first plurality of outputs as electrical currents on the plurality of third lines.
35. The neural network device of claim 34, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines.
36. The neural network device of claim 34, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of fourth lines.
37. The neural network device of claim 34, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
38. The neural network device of claim 37, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over and insulated from a first portion of the second channel region, a third gate disposed over and insulated from a second portion of the second channel region, and a fourth gate disposed over and insulated from the second floating gate or disposed over and insulated from the second source region;
each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fifth lines each electrically connecting together the third gates in one of the columns of the second memory cells;
a plurality of sixth lines each electrically connecting together the fourth gates in one of the rows of the second memory cells;
a plurality of seventh lines each electrically connecting together the second source regions in one of the rows of the second memory cells;
a plurality of eighth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fifth lines or on the plurality of eighth lines, and to provide the second plurality of outputs as electrical currents on the plurality of seventh lines.
39. The neural network device of claim 38, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fifth lines.
40. The neural network device of claim 38, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of eighth lines.
</claims>
</document>
