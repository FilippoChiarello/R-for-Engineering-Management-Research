<document>

<filing_date>
2018-12-21
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2018-12-21
</priority_date>

<ipc_classes>
G06F11/22,G06N20/20
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
LI ZHENG
YANG, YANG
GUPTA, SHILPA
NIE, KEXIN
CHEN, BOYI
JIANG, YANBIN
</inventors>

<docdb_family_id>
71097673
</docdb_family_id>

<title>
MACHINE LEARNING MODEL MONITORING
</title>

<abstract>
Technologies for monitoring performance of a machine learning model include receiving, by an unsupervised anomaly detection function, digital time series data for a feature metric; where the feature metric is computed for a feature that is extracted from an online system over a time interval; where the machine learning model is to produce model output that relates to one or more users' use of the online system; using the unsupervised anomaly detection function, detecting anomalies in the digital time series data; labeling a subset of the detected anomalies in response to a deviation of a time-series prediction model from a predicted baseline model exceeding a predicted deviation criterion; creating digital output that identifies the feature as associated with the labeled subset of the detected anomalies; causing, in response to the digital output, a modification of the machine learning model.
</abstract>

<claims>
1. A method for monitoring performance of a machine learning model, the method comprising: receiving, by an unsupervised anomaly detection function, digital time series data for a feature metric; wherein the feature metric is computed for a feature that is extracted from an online system over a time interval; wherein the machine learning model is to produce model output that relates to one or more users' use of the online system; using the unsupervised anomaly detection function, detecting anomalies in the digital time series data; labeling a subset of the detected anomalies in response to a deviation of a time-series prediction model from a predicted baseline model exceeding a predicted deviation criterion; creating digital output that identifies the feature as associated with the labeled subset of the detected anomalies; causing, in response to the digital output, a modification of the machine learning model; wherein the method is performed by one or more computing devices.
2. The method of claim 1, comprising causing, in response to the digital output, any one or more of the following: sending an electronic notification that contains the digital output, displaying the digital output on a display device, using the digital output to re-train the machine learning model, using the digital output to debug the machine learning model.
3. The method of claim 1, wherein the time interval comprises a daily time interval or a weekly time interval and the method comprises generating a daily report or a weekly report of the digital output.
4. The method of claim 1, comprising: receiving, by the unsupervised anomaly detection function, digital time series data for a model stability metric; wherein the model stability metric is computed by comparing output of the machine learning model to ground truth data over a time interval; using the unsupervised anomaly detection function, detecting anomalies in the digital time series data for the model stability metric; labeling a subset of the detected anomalies in the digital time series data for the model stability metric; creating the digital output in response to a co-occurrence of the subset of the detected anomalies in the digital time series data for the model stability metric and the subset of the detected anomalies in the digital time series data for the feature metric.
5. The method of claim 1, wherein the unsupervised anomaly detection function automatically adjusts the predicted baseline model in response to changes in the digital time series data for the feature metric.
6. The method of claim 1, wherein the unsupervised anomaly detection function uses group-level filtering or hypothesis testing to determine whether to label an anomaly detected by the unsupervised anomaly detection function.
7. The method of claim 1, comprising using a set of user-definable rules to rank the feature in relation to other features that are associated with other labeled anomalies.
8. The method of claim 1, wherein when the feature is a numeric feature, the feature metric comprises any one or more of the following: a feature value mean, a feature quantile, and when the feature is a categorical feature, the feature metric comprises any one or more of the following: a feature count, a feature count ratio.
9. The method of claim 4, wherein when the model output comprises a prediction, the model stability metric comprises an observed/estimated (O/E) ratio, and when the model output comprises a score, the model stability metric comprises a normalized discounted cumulative gain (NDCG) or a mean reciprocal rank (MRR).
10. The method of claim 1, wherein the model output is used by the online system to configure any one or more of the following: a content recommendation, a connection recommendation, a job opportunity recommendation, a search query.
11. A computer program product comprising one or more non-transitory computer-readable storage media comprising instructions which, when executed by one or more processors, cause the one or more processors to perform operations comprising: receiving, by an unsupervised anomaly detection function, digital time series data for a feature metric; wherein the feature metric is computed for a feature that is extracted from an online system over a time interval; wherein a machine learning model is to produce model output that relates to one or more users' use of the online system; using the unsupervised anomaly detection function, detecting anomalies in the digital time series data; labeling a subset of the detected anomalies in response to a deviation of a time-series prediction model from a predicted baseline model exceeding a predicted deviation criterion; creating digital output that identifies the feature as associated with the labeled subset of the detected anomalies; causing, in response to the digital output, a modification of the machine learning model.
12. The computer program product of claim 11, wherein the instructions, when executed by one or more processors, cause the one or more processors to perform operations comprising causing, in response to the digital output, any one or more of the following: sending an electronic notification that contains the digital output, displaying the digital output on a display device, using the digital output to re-train the machine learning model, using the digital output to debug the machine learning model.
13. The computer program product of claim 11, wherein the time interval comprises a daily time interval or a weekly time interval and the instructions, when executed by one or more processors, cause the one or more processors to perform operations comprising generating a daily report or a weekly report of the digital output.
14. The computer program product of claim 11, wherein the instructions, when executed by one or more processors, cause the one or more processors to perform operations comprising: receiving, by the unsupervised anomaly detection function, digital time series data for a model stability metric; wherein the model stability metric is computed by comparing output of the machine learning model to ground truth data over a time interval; using the unsupervised anomaly detection function, detecting anomalies in the digital time series data for the model stability metric; labeling a subset of the detected anomalies in the digital time series data for the model stability metric; creating the digital output in response to a co-occurrence of the subset of the detected anomalies in the digital time series data for the model stability metric and the subset of the detected anomalies in the digital time series data for the feature metric.
15. The computer program product of claim 11, wherein the unsupervised anomaly detection function automatically adjusts the predicted baseline model in response to changes in the digital time series data for the feature metric.
16. The computer program product of claim 11, wherein the unsupervised anomaly detection function uses group-level filtering or hypothesis testing to determine whether to label an anomaly detected by the unsupervised anomaly detection function.
17. The computer program product of claim 11, wherein the instructions, when executed by one or more processors, cause the one or more processors to perform operations comprising using a set of user-definable rules to rank the feature in relation to other features that are associated with other labeled anomalies.
18. The computer program product of claim 11, wherein when the feature is a numeric feature, the feature metric comprises any one or more of the following: a feature value mean, a feature quantile, and when the feature is a categorical feature, the feature metric comprises any one or more of the following: a feature count, a feature count ratio.
19. The computer program product of claim 14, wherein when the model output comprises a prediction, the model stability metric comprises an observed/estimated (O/E) ratio, and when the model output comprises a score, the model stability metric comprises a normalized discounted cumulative gain (NDCG) or a mean reciprocal rank (MRR).
20. The computer program product of claim 11, wherein the model output is used by the online system to configure any one or more of the following: a content recommendation, a connection recommendation, a job opportunity recommendation, a search query.
</claims>
</document>
