<document>

<filing_date>
2020-04-16
</filing_date>

<publication_date>
2020-10-22
</publication_date>

<priority_date>
2019-04-19
</priority_date>

<ipc_classes>
G10L15/18,G10L15/22,G10L15/26,G10L25/87,G10L25/93
</ipc_classes>

<assignee>
MAGIC LEAP
</assignee>

<inventors>
SHEEDER, ANTHONY ROBERT
ARORA, Tushar
</inventors>

<docdb_family_id>
72830867
</docdb_family_id>

<title>
IDENTIFYING INPUT FOR SPEECH RECOGNITION ENGINE
</title>

<abstract>
A method of presenting a signal to a speech recognition engine is disclosed. According to an example of the method, an audio signal is received from a user. A portion of the audio signal is identified, the portion having a first time and a second time. A pause in the portion of the audio signal, the pause comprising the second time, is identified. It is determined whether the pause indicates the completion of an utterance of the audio signal. In accordance with a determination that the pause indicates the completion of the utterance, the portion of the audio signal is presented as input to the speech recognition engine. In accordance with a determination that the pause does not indicate the completion of the utterance, the portion of the audio signal is not presented as input to the speech recognition engine.
</abstract>

<claims>
What is claimed is:
1. A method comprising:
receiving, via a microphone of a headwearable device, an audio signal, wherein the audio signal comprises voice activity;
determining whether the audio signal comprises a pause in the voice activity;
responsive to determining that the audio signal comprises a pause in the voice activity, determining whether the pause in the voice activity corresponds to an end point of the voice activity; and
responsive to determining that the pause in the voice activity corresponds to an end point of the voice activity, presenting a response to a user based on the voice activity.
2. The method of claim 1 further comprising:
responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, forgoing presenting a response to a user based on the voice activity.
3. The method of claim 1 further comprising:
responsive to determining that the audio signal does not comprise a pause in the voice activity, forgoing determining whether the pause in the voice activity corresponds to an end point of the voice activity.
4. The method of claim 1, wherein determining whether the audio signal comprises a pause in the voice activity comprises determining whether an amplitude of the audio signal falls below a threshold for a predetermined period of time.
5. The method of claim 4 further comprising:
responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, determining whether the audio signal comprises a second pause corresponding to the end point of the voice activity.
6. The method of claim 4 further comprising: responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, prompting the user to speak.
7. The method of claim 1, wherein determining whether the audio signal comprises a pause in the voice activity comprises determining whether the audio signal comprises one or more verbal cues corresponding to an end point of the voice activity.
8. The method of claim 7, wherein the one or more verbal cues comprise a characteristic of the user's prosody.
9. The method of claim 7, wherein the one or more verbal cues comprise a terminating phrase.
10. The method of claim 1, wherein determining whether the audio signal comprises a pause in the voice activity comprises evaluating non-verbal sensor data.
11. The method of claim 10, wherein the non-verbal sensor data is indicative of the user's gaze.
12. The method of claim 10, wherein the non-verbal sensor data is indicative of the user's facial expression.
13. The method of claim 10, wherein the non-verbal sensor data is indicative of the user's heart rate.
14. The method of claim 1, wherein determining whether the pause in the voice activity corresponds to an end point of the voice activity comprises identifying one or more interstitial sounds.
15. The method of claim 1, wherein determining whether the pause in the voice activity corresponds to an end point of the voice activity comprises evaluating non-verbal sensor data.
16. A system comprising:
a microphone of a head-wearable device,
one or more processors configured to execute a method comprising: receiving, via the microphone of the headwearable device, an audio signal, wherein the audio signal comprises voice activity;
determining whether the audio signal comprises a pause in the voice activity; responsive to determining that the audio signal comprises a pause in the voice activity, determining whether the pause in the voice activity corresponds to an end point of the voice activity; and
responsive to determining that the pause in the voice activity corresponds to an end point of the voice activity, presenting a response to a user based on the voice activity.
17. The system of claim 16 further comprising:
responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, forgoing presenting a response to a user based on the voice activity.
18. The system of claim 16 further comprising:
responsive to determining that the audio signal does not comprise a pause in the voice activity, forgoing determining whether the pause in the voice activity corresponds to an end point of the voice activity.
19. The system of claim 16, wherein determining whether the audio signal comprises a pause in the voice activity comprises determining whether an amplitude of the audio signal falls below a threshold for a predetermined period of time.
20. The system of claim 19 further comprising:
responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, determining whether the audio signal comprises a second pause corresponding to the end point of the voice activity.
21. The system of claim 19 further comprising:
responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, prompting the user to speak.
22. The system of claim 16, wherein determining whether the audio signal comprises a pause in the voice activity comprises determining whether the audio signal comprises one or more verbal cues corresponding to an end point of the voice activity.
23. The system of claim 22, wherein the one or more verbal cues comprise a
characteristic of the user's prosody.
24. The system of claim 22, wherein the one or more verbal cues compriese a terminating phrase.
25. The system of claim 16, wherein determining whether the audio signal comprises a pause in the voice activity comprises evaluating non-verbal sensor data.
26. The system of claim 25, wherein the non-verbal sensor data is indicative of the user's gaze.
27. The system of claim 25, wherein the non-verbal sensor data is indicative of the user's facial expression.
28. The system of claim 25, wherein the non-verbal sensor data is indicative of the user's heartrate.
29. The system of claim 16, wherein determining whether the pause in the voice activity corresponds to an end point of the voice activity comprises identifying one or more interstitial sounds.
30. The system of claim 16, wherein determining whether the pause in the voice activity corresponds to an end point of the voice activity comprises evaluating non-verbal sensor data.
31. A non-transitory computer-readable medium storing one or more instructions, which, when executed by one or more processors of an electronic device, cause the device to perform a method comprising:
receiving, via a microphone of a head-wearable device, an audio signal, wherein the audio signal comprises voice activity; determining whether the audio signal comprises a pause in the voice activity;
responsive to determining that the audio signal comprises a pause in the voice activity, determining whether the pause in the voice activity corresponds to an end point of the voice activity; and
responsive to determining that the pause in the voice activity corresponds to an end point of the voice activity, presenting a response to a user based on the voice activity.
32. The non-transitory computer-readable medium of claim 31 further comprising:
responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, forgoing presenting a response to a user based on the voice activity.
33. The non-transitory computer-readable medium of claim 31 further comprising:
responsive to determining that the audio signal does not comprise a pause in the voice activity, forgoing determining whether the pause in the voice activity corresponds to an end point of the voice activity.
34. The non-transitory computer-readable medium of claim 31, wherein determining whether the audio signal comprises a pause in the voice activity comprises determining whether an amplitude of the audio signal falls below a threshold for a predetermined period of time.
35. The non-transitory computer-readable medium of claim 34 further comprising:
responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, determining whether the audio signal comprises a second pause corresponding to the end point of the voice activity.
36. The non-transitory computer-readable medium of claim 34 further comprising:
responsive to determining that the pause in the voice activity does not correspond to an end point of the voice activity, prompting the user to speak.
37. The non-transitory computer-readable medium of claim 31, wherein determining whether the audio signal comprises a pause in the voice activity comprises determining whether the audio signal comprises one or more verbal cues corresponding to an end point of the voice activity.
38. The non-transitory computer-readable medium of claim 37, wherein the one or more verbal cues comprise a characteristic of the user's prosody.
39. The non-transitory computer-readable medium of claim 37, wherein the one or more verbal cues comprise a terminating phrase.
40. The non-transitory computer-readable medium of claim 31, wherein determining whether the audio signal comprises a pause in the voice activity comprises evaluating non verbal sensor data.
41. The non-transitory computer-readable medium of claim 40, wherein the non-verbal sensor data is indicative of the user's gaze.
42. The non-transitory computer-readable medium of claim 40, wherein the non-verbal sensor data is indicative of the user's facial expression.
43. The non-transitory computer-readable medium of claim 40, wherein the non-verbal sensor data is indicative of the user's heartrate.
44. The non-transitory computer-readable medium of claim 31, wherein determining whether the pause in the voice activity corresponds to an end point of the voice activity comprises identifying one or more interstitial sounds.
45. The non-transitory computer-readable medium of claim 31, wherein determining whether the pause in the voice activity corresponds to an end point of the voice activity comprises evaluating non-verbal sensor data.
</claims>
</document>
