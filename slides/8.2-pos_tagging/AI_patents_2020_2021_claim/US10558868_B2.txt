<document>

<filing_date>
2017-12-18
</filing_date>

<publication_date>
2020-02-11
</publication_date>

<priority_date>
2017-12-18
</priority_date>

<ipc_classes>
B60W30/12,B60W30/14,G05D1/02,G06K9/00,G06K9/46,G06K9/62,G06K9/66,G06T7/11
</ipc_classes>

<assignee>
GM GLOBAL TECHNOLOGY OPERATIONS
</assignee>

<inventors>
LITKOUHI, BAKHTIAR B.
WANG JINSONG
ZHAO, QINGRONG
WANG, TIANYU
JIN, JINGFU
</inventors>

<docdb_family_id>
66674665
</docdb_family_id>

<title>
Method and apparatus for evaluating a vehicle travel surface
</title>

<abstract>
A vehicle includes a plurality of on-vehicle cameras, and a controller executes a method to evaluate a travel surface by capturing images for fields of view of the respective cameras. Corresponding regions of interest for the images are identified, wherein each of the regions of interest is associated with the portion of the field of view of the respective camera that includes the travel surface. Portions of the images are extracted, wherein each extracted portion is associated with the region of interest in the portion of the field of view of the respective camera that includes the travel surface and wherein one extracted portion of the respective image includes the sky. The extracted portions of the images are compiled into a composite image datafile, and an image analysis of the composite image datafile is executed to determine a travel surface state. The travel surface state is communicated to another controller.
</abstract>

<claims>
1. A method for evaluating a travel surface for a vehicle, the method comprising: capturing, via a plurality of on-vehicle cameras, a plurality of images associated with a plurality of fields of view ("FOVs") of the respective cameras, wherein at least a portion of each of the fields of view includes the travel surface and the sky; identifying corresponding regions of interest for the images, wherein each of the regions of interest is associated with the portion of the field of view ("FOV") of the respective camera that includes the travel surface and the sky; extracting portions of the images, wherein each extracted portion of the respective image is associated with the region of interest in the portion of the FOV of the respective camera that includes the travel surface, wherein extracting the portions of the images includes extracting the sky to provide an indication of ambient lighting; compiling the extracted portions of the images into a composite image datafile; executing, via a controller, an image analysis of the composite image datafile based upon the indication of ambient lighting, including executing a statistical analysis, a template matching, and a color/brightness analysis of the composite image datafile to identify patterns that correlate to one of a plurality of travel surface conditions; determining a travel surface state based upon the image analysis of the composite image datafile; and communicating the travel surface state to an on-vehicle controller.
2. The method of claim 1, wherein the composite image datafile comprises a composite image that includes the travel surface that surrounds the vehicle.
3. The method of claim 2, wherein the composite image that includes the travel surface that surrounds the vehicle include a first portion associated with the travel surface in front of the vehicle, a second portion associated with the travel surface rearward of the vehicle, a third portion associated with the travel surface at a left side of the vehicle and a fourth portion associated with the travel surface at a right side of the vehicle.
4. The method of claim 1, wherein determining the travel surface state comprises determining one of a dry state, a wet state, an iced state and a snow-covered state.
5. The method of claim 1, wherein determining the travel surface state based upon the image analysis of the composite image datafile comprises: comparing results of the image analysis of the composite image datafile with the plurality of travel surface conditions; and classifying, via the controller, the travel surface state based upon the compared results of the image analysis.
6. The method of claim 5, wherein classifying the travel surface state comprises determining the travel surface state to be one of a dry state, a wet state, an iced state and a snow-covered state.
7. The method of claim 1, wherein capturing, via a plurality of on-vehicle cameras, a plurality of images comprises capturing a plurality of image files, wherein each of the image files comprises a digital representation of the FOV of the respective on-vehicle camera at its original resolution.
8. The method of claim 1, wherein the plurality of fields of view includes the travel surface comprises wherein at least a portion of each of the plurality of fields of view includes the travel surface.
9. The method of claim 1, wherein extracting portions of the images includes cropping the respective image to include the portion of the FOV of the respective camera that includes the travel surface.
10. The method of claim 1, wherein extracting portions of the images includes one of scaling, rotating and compressing the region of interest of the respective image in the portion of the FOV of the respective camera that includes the travel surface.
11. The method of claim 1, wherein capturing, via a plurality of on-vehicle cameras, a plurality of images associated with a plurality of fields of view of the respective cameras comprises simultaneously capturing the plurality of images.
12. The method of claim 1, wherein determining the travel surface state based upon the image analysis of the composite image datafile comprises determining the travel surface state based upon the correlation to one of the plurality of travel surface conditions.
13. A vehicle disposed on a travel surface, comprising: a vision system, including: a plurality of on-vehicle cameras disposed to monitor a corresponding plurality of fields-of-view surrounding the vehicle including the sky, a first controller operatively connected to the on-vehicle cameras and in communication with a second controller, the first controller including a first instruction set, the first instruction set executable to: capture, via the on-vehicle cameras, a plurality of images associated with a plurality of fields of view of the respective cameras, wherein at least a portion of each of the fields of view includes the travel surface and the sky; identify corresponding regions of interest for the images, wherein each of the regions of interest is associated with the portion of the field of view ("FOV") of the respective camera that includes the travel surface and the sky; extract portions of the images, wherein each extracted portion of the respective image is associated with the region of interest in the portion of the FOV of the respective camera that includes the travel surface and the sky, wherein the sky provides an indication of ambient lighting; compile the extracted portions of the images into a composite image datafile; execute an image analysis of the composite image datafile based upon the indication of ambient lighting, including executing a statistical analysis, a template matching, and a color/brightness analysis of the composite image datafile to identify patterns that correlate to one of a plurality of travel surface conditions; determine a travel surface state based upon the image analysis of the composite image datafile; and communicate the travel surface state to the second controller.
14. The vehicle of claim 13, wherein the second controller is operatively connected to a device configured to execute a vehicle function, the second controller including a second instruction set, the second instruction set executable to: monitor the travel surface state communicated from the first controller; and control the device configured to execute the vehicle function based upon the travel surface state.
15. The vehicle of claim 14, wherein the device configured to execute the vehicle function comprises a device configured to execute an autonomous vehicle function, and wherein the second instruction set is executable to modify operation of the device based upon the travel surface state.
16. The vehicle of claim 13, wherein the second controller comprises a telematics controller in communication with the first controller, wherein the telematics controller is disposed to communicate the travel surface state to an off-board controller via a communication network.
17. The vehicle of claim 13, wherein the second controller comprises a telematics controller in communication with the first controller, wherein the telematics controller is disposed to communicate the travel surface state to a second proximal vehicle and to an infrastructure monitoring system.
</claims>
</document>
