<document>

<filing_date>
2019-12-18
</filing_date>

<publication_date>
2020-07-02
</publication_date>

<priority_date>
2018-12-26
</priority_date>

<ipc_classes>
G06N3/08,H04N21/422,H04N21/442,H04N21/466
</ipc_classes>

<assignee>
SYNAPTICS
</assignee>

<inventors>
ARORA, GAURAV
GAUR, UTKARSH
</inventors>

<docdb_family_id>
71122009
</docdb_family_id>

<title>
ENROLLMENT-FREE OFFLINE DEVICE PERSONALIZATION
</title>

<abstract>
A method and apparatus for device personalization. A device is configured to receive first sensor data from one or more sensors, detect biometric information in the first sensor data, encode the biometric information as a first vector using one or more neural network models stored on the device, and configure a user interface of the device based at least in part on the first vector. For example, the profile information may include configurations, settings, preferences, or content to be displayed or rendered via the user interface. In some implementations, the first sensor data may comprise an image of a scene and the biometric information may comprise one or more facial features of a user in the scene.
</abstract>

<claims>
What is claimed is:
1 . A method of personalizing a device, comprising:
receiving first sensor data from one or more sensors;
detecting biometric information in the first sensor data;
encoding the biometric information as a first vector using one or more neural network models stored on the device; and
configuring a user interface of the device based at least in part on the first vector.
2. The method of claim 1 , wherein the configuring comprises:
searching a lookup table for an entry matching the first vector, wherein the lookup table is configured to store profile information in association with each entry.
3. The method of claim 2, wherein the configuring further comprises: matching the first vector to a first entry stored in the lookup table; and retrieving the profile information associated with the first entry from the lookup table, wherein the user interface is configured based at least in part on the profile information associated with the first entry.
4. The method of claim 3, wherein the matching comprises:
calculating respective distances from the first vector to each of a plurality of entries, including the first entry, stored in the lookup table; and
determining that the distance to the first entry is the shortest among the calculated distances.
5. The method of claim 3, further comprising:
incrementing a count value indicating a number of instances a match has been detected for the first entry, wherein the profile information is retrieved only when the count value reaches a threshold number.
6. The method of claim 2, wherein the profile information includes configurations, settings, preferences, or content to be displayed or rendered via the user interface.
7. The method of claim 2, further comprising:
monitoring user interactions with the device; and
generating the profile information based at least in part on the user interactions.
8. The method of claim 2, further comprising:
storing the first vector as a new entry in the lookup table when no matching entry is detected.
9. The method of claim 1 , wherein the first sensor data comprises an image of a scene and the biometric information comprises one or more facial features of a user in the scene.
10. The method of claim 1 , further comprising:
receiving second sensor data from the one or more sensors;
detecting biometric information in the second sensor data;
encoding the biometric information of the second sensor data as a second vector using the one or more neural network models, wherein the second vector is at least a threshold distance away from the first vector; and changing the user interface based at least in part on the second vector.
1 1 . A device, comprising:
processing circuitry; and
memory storing instructions that, when executed by the processing circuitry, cause the device to:
receive first sensor data from one or more sensors; detect biometric information in the first sensor data; encode the biometric information as a first vector using one or more neural network models stored on the device; and configure a user interface of the device based at least in part on the first vector.
12. The device of claim 1 1 , further comprising:
a lookup table configured to store profile information in association with each entry, wherein execution of the instructions for configuring the user interface causes the device to search the lookup table for an entry matching the first vector.
13. The device of claim 12, wherein execution of the instructions for configuring the user interface further causes the device to:
match the first vector to a first entry stored in the lookup table; and retrieve the profile information associated with the first entry from the lookup table, wherein the user interface is configured based at least in part on the profile information associated with the first entry.
14. The device of claim 13, wherein execution of the instructions for matching the first vector to the first entry causes the device to:
calculate respective distances from the first vector to each of a plurality of entries, including the first entry, stored in the lookup table; and
determining that the distance to the first entry is the shortest among the calculated distances.
15. The device of claim 13, wherein execution of the instructions further causes the device to:
increment a count value indicating a number of instances a match has been detected for the first entry, wherein the profile information is retrieved only when the count value reaches a threshold number.
16. The device of claim 12, wherein execution of the instructions further causes the device to:
monitor user interactions with the device; and generate the profile information based at least in part on the user interactions, wherein the profile information includes configurations, settings, preferences, or content to be displayed or rendered via the user interface.
17. The device of claim 12, wherein execution of the instructions further causes the device to:
store the first vector as a new entry in the lookup table when no matching entry is detected.
18. The device of claim 1 1 , wherein the first sensor data comprises an image of a scene and the biometric information comprises one or more facial features of a user in the scene.
19. The device of claim 1 1 , wherein execution of the instructions further causes the device to:
receive second sensor data from the one or more sensors;
detect biometric information in the second sensor data;
encode the biometric information of the second sensor data as a second vector using the one or more neural network models, wherein the second vector is at least a threshold distance away from the first vector; and
change the user interface based at least in part on the second vector.
20. A system comprising:
a memory storing one or more neural network models;
one or more sensors configured to capture sensor data;
a vector generator configured to:
detect biometric information in the captured sensor data; and encode the biometric information as a vector using the one or more neural network models stored in memory; and
a display configured to display a personalized user interface based at least in part on the encoded vector.
</claims>
</document>
