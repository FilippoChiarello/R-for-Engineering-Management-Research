<document>

<filing_date>
2019-03-20
</filing_date>

<publication_date>
2020-05-19
</publication_date>

<priority_date>
2017-03-02
</priority_date>

<ipc_classes>
G06K9/46,G06N3/04,G06N3/08,G06T7/11,G06T7/194,G06T7/90
</ipc_classes>

<assignee>
ADOBE
</assignee>

<inventors>
COHEN, SCOTT
PRICE, BRIAN LYNN
SCHILLER, STEPHEN
XU, NING
</inventors>

<docdb_family_id>
60788499
</docdb_family_id>

<title>
Image matting using deep learning
</title>

<abstract>
Methods and systems are provided for generating mattes for input images. A neural network system can be trained where the training includes training a first neural network that generates mattes for input images where the input images are synthetic composite images. Such a neural network system can further be trained where the training includes training a second neural network that generates refined mattes from the mattes produced by the first neural network. Such a trained neural network system can be used to input an image and trimap pair for which the trained system will output a matte. Such a matte can be used to extract an object from the input image. Upon extracting the object, a user can manipulate the object, for example, to composite the object onto a new background.
</abstract>

<claims>
1. A computer-implemented method comprising: receiving an image, the image having a corresponding trimap that indicates a blended region of the image; identifying, by a neural network system, structure or texture information corresponding to an object in the image; determining, by the neural network system, percentages of foreground information for pixels in the blended region of the image using the structure or texture information, the blended region of the image indicated using the trimap; and generating, by the neural network system, a matte for the image using the percentages of foreground information for the pixels in the blended region.
2. The computer-implemented method of claim 1, further comprising: determining the image is larger than a predefined size; and dividing the image into tiles, wherein the tiles are processed by the neural network system to determine the percentages of foreground information for pixels in the blended region of the tiles of the image using the structure or texture information.
3. The computer-implemented method of claim 2, further comprising: combining the tiles to produce the matte for the image; and removing, using the neural network system, artifacts from the matte to generate a refined matte.
4. The computer-implemented method of claim 1, further comprising: running a portion of the neural network system at a lower resolution to generate the matte with the lower resolution; and upsampling the matte with the lower resolution to generate the matte with a desired resolution.
5. The computer-implemented method of claim 1, further comprising: generating, by the neural network system, a refined matte using refined percentages of foreground information for the pixels in the blended region of the image.
6. The computer-implemented method of claim 1, further comprising: receiving a user selection of a background image; generating a composite image by placing an extracted object from the image onto the background image, wherein the object is extracted using the matte.
7. The computer-implemented method of claim 1, wherein the neural network system is comprised of a trained matting neural network.
8. The computer-implemented method of claim 7, wherein the neural network system is further comprised of a trained refining neural network.
9. One or more computer-readable media having a plurality of executable instructions embodied thereon, which, when executed by one or more processors, cause the one or more processors to: receive an image, the image having a corresponding trimap that indicates a blended region of the image; identify, by a neural network system, structure or texture information corresponding to an object in the image; determine, by the neural network system, percentages of foreground information for pixels in the blended region of the image using the structure or texture information, the blended region of the image indicated using the trimap; and generate, by the neural network system, a matte for the image using the percentages of foreground information for the pixels in the blended region.
10. The media of claim 9, to further: determine the image is larger than a predefined size; and divide the image into overlapping tiles, wherein the tiles are processed by the neural network system to determine the percentages of foreground information for pixels in the blended region of the tiles of the image using the structure or texture information.
11. The media of claim 10, to further: combine the tiles to produce the matte for the image; and remove, using the neural network system, artifacts from the matte to generate a refined matte.
12. The media of claim 9, to further: generate, by the neural network system, a refined matte using refined percentages of foreground information for the pixels in the blended region of the image.
13. The media of claim 9, to further: receive a user selection of a background image; generate a composite image by placing an extracted object from the image onto the background image, wherein the object is extracted using the matte.
14. The media of claim 9, wherein the neural network system is comprised of a trained matting neural network.
15. The media of claim 14, wherein the neural network system is further comprised of a trained refining neural network.
16. The media of claim 15, to further: run the matting neural network of the neural network system at a lower resolution to generate the matte with the lower resolution; and upsample, using the refining neural network, the matte with the lower resolution to generate the matte with a desired resolution.
17. A computing system comprising: means for identifying structure or texture information corresponding to an object in an image; means for determining percentages of foreground information for pixels in a blended region of the image using the structure or texture information; and means for generating a matte for the image using the percentages of foreground information for the pixels in the blended region.
18. The system of claim 17, further comprising: means for dividing the image into tiles; and means for processing the tiles to determine the percentages of foreground information for pixels in the blended region of the tiles of the image using the structure or texture information.
19. The system of claim 17, further comprising: means for generating a composite image by placing an extracted object from the image onto the background image, wherein the object is extracted using the matte.
20. The system of claim 17, further comprising: means for generating a refined matte using refined percentages of foreground information for the pixels in the blended region of the image.
</claims>
</document>
