<document>

<filing_date>
2017-10-26
</filing_date>

<publication_date>
2020-07-14
</publication_date>

<priority_date>
2017-10-26
</priority_date>

<ipc_classes>
G06F3/16,G10L15/22,G10L15/26,G10L17/22,H04L29/08
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
BAO, YU
</inventors>

<docdb_family_id>
71519906
</docdb_family_id>

<title>
Remote system processing based on a previously identified user
</title>

<abstract>
Techniques for implementing a "sticky" user ID are described. A system receives first input audio data and determines first speech processing results therefrom. The system also determines a first user ID of a user that spoke an utterance represented in the first input audio data and associates the first user ID with a device, which originated the first input audio data, for a predetermined length of time. The system determines first output data responsive to the first speech processing data and causes the device to present first output content corresponding thereto. The system then receives second input audio data and determines second speech processing results therefrom. The system also determines a time of receipt of the second input audio data is within the predetermined length of time. Based at least in part thereon, the system determined second output data responsive to the second speech processing data using the first user ID. The system then causes the device to present second output content corresponding to the second output data.
</abstract>

<claims>
1. A computer-implemented method comprising: receiving, from a device corresponding to a device identifier (ID), first audio data corresponding to a first utterance; determining first speech characteristics corresponding to the first utterance; determining the first speech characteristics correspond to stored speech characteristics data associated with a user ID; storing first data associating the user ID with the device ID for a length of time; determining first speech processing data representing the first audio data; based at least in part on the first speech processing data and the user ID, determining second data responsive to the first utterance; causing the device to output the second data; after causing the device to output the second data, receiving, from the device within the length of time, second audio data corresponding to a second utterance; determining second speech characteristics corresponding to the second utterance; determining the second speech characteristics are unassociated with profile data associated with the device; determining the user ID is to be used to respond to the second utterance based at least in part on determining the second speech characteristics are unassociated with the profile data; determining second speech processing data representing the second audio data; based at least in part on the second speech processing data and the user ID, determining third data responsive to the second utterance; and causing the device to output the third data.
2. The computer-implemented method of claim 1, further comprising: prior to determining the third data, causing the device to output fourth data requesting confirmation that the second utterance is to be processed using the user ID; receiving, from the device, third audio data corresponding to a third utterance; performing speech processing on the third audio data to determine the third utterance confirms the second utterance is to be processed using the user ID; and based at least in part on the speech processing, determining the third data based at least in part on the user ID.
3. A system comprising: at least one processor; and at least one memory including instructions that, when executed by the at least one processor, cause the system to: receive, from a device corresponding to a device identifier (ID), first audio data corresponding to a first utterance; determine a user ID associated with the first audio data; store first data associating the user ID with the device ID for a length of time; determine first speech processing data representing the first audio data; based at least in part on the first speech processing data and the user ID, determine second data responsive to the first utterance; cause the device to output the second data; after causing the device to output the second data, receive, from the device within the length of time, second audio data corresponding to a second utterance; determine speech characteristics corresponding to the second utterance; determine the speech characteristics are unassociated with profile data associated with the device; determine the user ID is to be used to respond to the second utterance based at least in part on determining the speech characteristics are unassociated with the profile data; determine second speech processing data representing the second audio data; based at least in part on the second speech processing data and the user ID, determine third data responsive to the second utterance; and cause the device to output the third data.
4. The system of claim 3, wherein the at least one memory further includes instructions that, when executed by the at least one processor, further cause the system to: determine second speech characteristics corresponding to the first utterance; determine the second speech characteristics correspond to stored speech characteristics associated with at least one individual under eighteen years of age; and determine the first speech processing data by performing speech processing with respect to a subset of functions corresponding to content selected for at least one individual under eighteen years of age.
5. The system of claim 3, wherein the at least one memory further includes instructions that, when executed by the at least one processor, further cause the system to: determine the speech characteristics correspond to a second user ID; prior to determining the third data, cause the device to output fourth data requesting confirmation that the second utterance is to be processed using the user ID; receive, from the device, third audio data corresponding to a third utterance; perform speech processing on the third audio data to determine the third utterance confirms the second utterance is to be processed using the user ID; and based at least in part on the speech processing, determine the third data based at least in part on the user ID.
6. The system of claim 5, wherein the at least one memory further includes instructions that, when executed by the at least one processor, further cause the system to: determine second speech characteristics corresponding to the third utterance; determine the second speech characteristics correspond to stored speech characteristics associated with the user ID; and based at least in part on the second speech characteristics corresponding to the stored speech characteristics, determine the third data based at least in part on the user ID.
7. The system of claim 3, wherein the at least one memory further includes instructions that, when executed by the at least one processor, further cause the system to: determine the device ID is associated with an indication of a user under eighteen years of age; and determine the first speech processing data by performing speech processing with respect to a subset of functions corresponding to content selected for at least one individual under eighteen years of age.
8. The system of claim 3, wherein the at least one memory further includes instructions that, when executed by the at least one processor, further cause the system to: determine the second utterance requests an output inappropriate for at least one individual under eighteen years of age, wherein the third data corresponds to an indication that the system cannot execute.
9. The system of claim 3, wherein: the first speech processing data is associated with a first component configured to process with respect to first natural language understanding data; and the second speech processing data is associated with a second component configured to process with respect to second natural language understanding data.
10. A computer-implemented method comprising: receiving, from a device corresponding to a device identifier (ID), first audio data corresponding to a first utterance; determining a user ID associated with the first audio data; storing first data associating the user ID with the device ID for a length of time; determining first speech processing data representing the first audio data; based at least in part on the first speech processing data and the user ID, determining second data responsive to the first utterance; causing the device to output the second data; after causing the device to output the second data, receiving, from the device within the length of time, second audio data corresponding to a second utterance; determining speech characteristics corresponding to the second utterance; determining the speech characteristics are unassociated with profile data associated with the device; determining the user ID is to be used to respond to the second utterance based at least in part on determining the speech characteristics are unassociated with the profile data; determining second speech processing data representing the second audio data; based at least in part on the second speech processing data and the user ID, determining third data responsive to the second utterance; and causing the device to output the third data.
11. The computer-implemented method of claim 10, further comprising: determining second speech characteristics corresponding to the first utterance; determining the second speech characteristics correspond to stored speech characteristics associated with at least one individual under eighteen years of age; and determining the first speech processing data by performing speech processing with respect to a subset of functions corresponding to content selected for at least one individual under eighteen years of age.
12. The computer-implemented method of claim 10, further comprising: determining the speech characteristics correspond to a second user ID; prior to determining the third data, causing the device to output fourth data requesting confirmation that the second utterance is to be processed using the user ID; receiving, from the device, third audio data corresponding to a third utterance; performing speech processing on the third audio data to determine the third utterance confirms the second utterance is to be processed using the user ID; and based at least in part on the speech processing, determining the third data based at least in part on the user ID.
13. The computer-implemented method of claim 12, further comprising: determining second speech characteristics corresponding to the third utterance; determining the second speech characteristics correspond to stored speech characteristics associated with the user ID; and based at least in part on the second speech characteristics corresponding to the stored speech characteristics, determining the third data based at least in part on the user ID.
14. The computer-implemented method of claim 10, further comprising: determining the device ID is associated with an indication of a user under eighteen years of age; and determining the first speech processing data by performing speech processing with respect to a subset of functions corresponding to content selected for at least one individual under eighteen years of age.
15. The computer-implemented method of claim 10, further comprising: determining the second utterance requests an output inappropriate for at least one individual under eighteen years of age, wherein the third data corresponds to an indication that a system cannot execute.
16. The computer-implemented method of claim 10, wherein: the first speech processing data is associated with a first component configured to process with respect to first natural language understanding data; and the second speech processing data is associated with a second component configured to process with respect to second natural language understanding data.
</claims>
</document>
