<document>

<filing_date>
2020-05-22
</filing_date>

<publication_date>
2020-12-10
</publication_date>

<priority_date>
2019-06-05
</priority_date>

<ipc_classes>
H04N13/239,H04N13/271,H04N5/225,H04N5/247
</ipc_classes>

<assignee>
SYNAPTICS
</assignee>

<inventors>
GOVE, ROBERT J.
</inventors>

<docdb_family_id>
73650822
</docdb_family_id>

<title>
UNDER-DISPLAY IMAGE SENSOR
</title>

<abstract>
A device includes a display and a first light source configured to emit light, wherein the first light source is proximate to the display. The device further includes a first camera disposed behind the display, wherein the first camera is configured to detect reflections of the light emitted by the first light source. The first camera is further configured to capture a first image based at least in part on the reflections, wherein the reflections are partially occluded by the display. The device also includes a second camera proximate to the display, wherein the second camera is configured to capture a second image. In addition, the device includes a depth map generator configured to generate depth information about one or more objects in a field-of-view (FOV) of the first and second cameras based at least in part on the first and second images.
</abstract>

<claims>
What is claimed is:
1 . A device comprising:
a display;
a first light source configured to emit light, the first light source proximate to the display;
a first camera disposed behind the display, the first camera configured to detect reflections of the light emitted by the first light source and to capture a first image based at least in part on the reflections, wherein the reflections are partially occluded by the display;
a second camera proximate to the display, the second camera configured to capture a second image; and
a depth map generator configured to generate depth information about one or more objects in a field-of-view (FOV) of the first and second cameras based at least in part on the first and second images.
2. The device of claim 1 , wherein the first light source is configured to emit near infrared (NIR) light, and each of the first and second cameras is configured to detect the NIR light.
3. The device of claim 1 , wherein the first light source is configured to emit near infrared (NIR) light, the first camera is configured to detect the NIR light, and the second camera is configured to detect visible light.
4. The device of claim 1 , wherein the display comprises a plurality of display pixels, wherein an empty space separates each display pixel from other display pixels of the plurality of display pixels, and wherein each empty space is configured to transmit the reflections.
5. The device of claim 1 , wherein the display comprises an organic light-emitting diode display. 6. The device of claim 1 , wherein the display comprises a micro lightemitting diode display.
7. The device of claim 1 , wherein the first camera comprises a plurality of first optical sensors that are aligned with display pixels of the display.
8. The device of claim 7, wherein each optical sensor of the plurality of first optical sensors is aligned with a display pixel of a region of the display, wherein the region contains a plurality of display pixels comprising a repeating pixel pattern.
9. The device of claim 1 , further comprising:
an image filter configured to filter out noise or interference from the first image captured by the first camera.
10. The device of claim 9, wherein the depth map generator is further configured to generate the depth information about the one or more objects in the FOV of the first and second cameras based at least in part on the filtered first image.
1 1 . The device of claim 9, wherein the image filter uses a neural network model to filter out the noise or interference from the first image captured by the first camera.
12. The device of claim 9, wherein the image filter uses a reverse point spread function transform to filter out the noise or interference from the first image captured by the first camera.
13. The device of claim 1 , wherein the depth map generator is further configured to generate a three-dimensional image based at least in part on the depth information. 14. A method comprising:
receiving a first image captured by a first camera based at least in part on reflections of light emitted by a first light source, wherein the reflections are partially occluded by an electronic display disposed in front of the first camera; receiving a second image captured by a second camera proximate to the electronic display; and
generating depth information about one or more objects in a field-of-view (FOV) of the first and second cameras based at least in part on the first and second images.
15. The method of claim 14, further comprising:
emitting near infrared (NIR) light from the first light source, wherein each of the first and second cameras is configured to detect the NIR light.
16. The method of claim 14, further comprising:
emitting near infrared (NIR) light from the first light source, wherein the first camera is configured to detect the NIR light, and the second camera is configured to detect visible light.
17. The method of claim 14, further comprising:
filtering out noise or interference from the first image.
18. The method of claim 17, wherein generating the depth information about the one or more objects in the FOV of the first and second cameras is further based at least in part on the filtered first image.
19. The method of claim 14, further comprising:
filtering out noise or interference from the first image using a neural network model.
20. The method of claim 14, further comprising:
filtering out noise or interference from the first image using a reverse point spread function transform. 21 . The method of claim 14, further comprising:
generating a three-dimensional image based at least in part on the depth information.
22. A processing system comprising:
a processor; and
a memory storing instructions that, when executed by the processor, cause the processing system to:
receive a first image captured by a first camera based at least in part on reflections of light emitted by a first light source, wherein the reflections are partially occluded by an electronic display disposed in front of the first camera;
receive a second image captured by a second camera proximate to the electronic display; and
generate depth information about one or more objects in a field-ofview (FOV) of the first and second cameras based at least in part on the first and second images.
</claims>
</document>
