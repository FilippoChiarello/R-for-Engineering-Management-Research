<document>

<filing_date>
2016-10-21
</filing_date>

<publication_date>
2020-07-28
</publication_date>

<priority_date>
2016-10-21
</priority_date>

<ipc_classes>
G06K9/00,G08B13/16,G08B13/196,G11B27/031,H04M1/725,H04N7/18
</ipc_classes>

<assignee>
XINOVA
</assignee>

<inventors>
KIM, SEUNG IL
</inventors>

<docdb_family_id>
62019608
</docdb_family_id>

<title>
Selecting media from mass social monitoring devices
</title>

<abstract>
Technologies are generally described that relate to managing videos relating to events. An example technique can include analyzing audio content captured by an audio capture component and associated with video content captured by an image capture component to facilitate determining whether a defined event exists in the audio content. The technique also can include, in response to determining that the defined event exists in the audio content based on the analyzing, determining whether the image capture component captured event-related video content related to the defined event based on a result of analyzing a first direction in which the defined event occurred relative to the audio capture component in relation to a second direction that the image capture component was facing while capturing the video content, in accordance with a defined match criterion, to facilitate determining whether to present, emphasize, or select at least the video content.
</abstract>

<claims>
1. A method, comprising: analyzing, by a device comprising a processor, audio content captured by an audio capture component and associated with video content captured by an image capture component to identify a defined event in the audio content; analyzing a first direction in which the identified defined event occurred relative to the audio capture component in relation to a second direction that the image capture component was facing while capturing the video content; determining, by the device, whether the image capture component captured event-related video content is related to the defined event based on a result of analyzing the first direction in which the defined event occurred; and in response to determining the image capture component captured the event-related video content is related to the defined event, presenting, by a display screen of the device, a first portion of the video content or a first portion of the audio content corresponding to the event-related video content.
2. The method of claim 1, further comprising: in response to identifying the defined event in the audio content, identifying, by the device, the first direction in which the defined event occurred relative to the audio capture component based on the analyzing of the audio content.
3. The method of claim 2, further comprising: comparing, by the device, the second direction that the image capture component was facing to the first direction in which the defined event occurred; and determining, by the device, whether the image capture component captured the event-related video content is related to the defined event based on a comparison result of the comparing.
4. The method of claim 1, wherein the analyzing the audio content comprises analyzing a first portion of the audio content captured by a first audio sensor of the audio capture component and a second portion of the audio content captured by a second audio sensor of the audio capture component, and wherein the method further comprises: identifying, by the device, the first direction in which the defined event occurred based on a time difference between capture of the first portion of the audio content and capture of at least the second portion of the audio content.
5. The method of claim 1, wherein the analyzing the audio content comprises analyzing a first portion of the audio content captured by a first audio sensor of the audio capture component, a second portion of the audio content captured by a second audio sensor of the audio capture component, and a third portion of the audio content captured by a third audio sensor of the audio capture component, and wherein the method further comprises: identifying, by the device, the first direction in which the defined event occurred by triangulating a source of a sound associated with the defined event in the audio content based on the analyzing of the first portion, the second portion, and the third portion of the audio content.
6. The method of claim 1, further comprising: identifying, by the device, the second direction that the image capture component was facing while capturing the video content; determining, by the device, a field of view of the image capture component; and comparing, by the device, the field of view of the image capture component to the first direction in which the defined event occurred to facilitate determining whether the first direction is within the field of view of the image capture component.
7. The method of claim 1, further comprising: in response to determining the image capture component captured the event-related video content is related to the defined event, presenting, by the device, an indicator on the display screen, wherein the indicator indicates the video content comprises the event-related video content.
8. The method of claim 1, further comprising: in response to determining the image capture component captured the event-related video content is related to the defined event, determining, by the device, an amount of time, prior to the defined event occurring, that the image capture component was at least substantially facing the second direction; determining, by the device, whether the amount of the time satisfies a defined threshold amount of time related to a type of event; and in response to determining the amount of the time satisfies the defined threshold amount of time, presenting or selecting, by the device, the video content or the audio content.
9. The method of claim 1, wherein the analyzing the audio content comprises analyzing sounds in the audio content other than different sounds that are received from a third direction that is substantially opposite to the second direction that the image capture component was facing while capturing the video content.
10. The method of claim 1, wherein the analyzing the audio content comprises analyzing a pattern of characteristics of the audio content to facilitate determining whether the defined event exists in the audio content, and wherein the characteristics comprise at least one of a short-time energy value, a zero-crossing rate, a linear predictive coding coefficient, or a mel-frequency cepstral coefficient, associated with the audio content.
11. The method of claim 1, further comprising: in response to determining the image capture component captured the event-related video content is related to the defined event, transmitting to be presented, through the communicator component, the first portion of the video content or the first portion of the audio content corresponding to the event-related video content.
12. A system, comprising: a memory operable to store executable components; a display screen; a communicator component; and a processor, coupled to the memory, the display screen, and the memory, the processor operable to execute or facilitate execution of one or more of the executable components, the executable components comprising: an analyzer component configured to: analyze audio content captured by an audio capture component and associated with video content captured by an image capture component to identify a defined event in the audio content; and analyze a first direction in which the identified defined event occurred relative to the audio capture component in relation to a second direction that the image capture component was facing while capturing the video content; and a media management component configured to: determine whether the image capture component captured event-related video content is related to the identified defined event based on a result of analyzing the first direction in which the defined event occurred relative to the audio capture component; and in response to determining the image capture component captured the event-related video content is related to the defined event, presenting, through the display screen, or transmitting to be presented, through the communicator component, a first portion of the video content or a first portion of the audio content corresponding to the event-related video content.
13. The system of claim 12, wherein, in response to the identification of the defined event in the audio content, the media management component is configured to determine the first direction in which the defined event occurred relative to the audio capture component based on the analysis of the audio content, evaluate the second direction that the image capture component was facing in relation to the first direction in which the defined event occurred, and determine whether the image capture component captured the event-related video content is related to the defined event based on an evaluation result of the evaluation.
14. The system of claim 12, wherein the analyzer component is configured to analyze a first portion of the audio content captured by a first audio sensor of the audio capture component and at least a second portion of the audio content captured by at least a second audio sensor of the audio capture component, and wherein, based on the analysis of the first portion and at least the second portion of the audio content, the media management component is configured to estimate the first direction in which the defined event occurred at least one of based on a time difference between capturing of the first portion of the audio content and capturing of at least the second portion of the audio content, or based on a triangulation of a source of a sound associated with the defined event contained in the audio content that is determined using the first portion of the audio content and at least the second portion of the audio content.
15. The system of claim 12, wherein the media management component is configured to determine the second direction that the image capture component was facing while capturing the video content, and determine a defined area that defines a field of view of the image capture component.
16. The system of claim 15, wherein the media management component is configured to compare the defined area that defines the field of view of the image capture component to the first direction in which the defined event occurred to facilitate determining whether the first direction is within the defined area that defines the field of view of the image capture component.
17. The system of claim 16, wherein the media management component is configured to determine that the first direction corresponds to the second direction based on a comparison result that indicates that the first direction is within the defined area that defines the field of view of the image capture component, or determine that the first direction does not correspond to the second direction based on a different comparison result that indicates that the first direction is not within the defined area that defines the field of view of the image capture component.
18. The system of claim 12, wherein the executable components further comprise an emphasizer component, wherein, in response to a determination that the image capture component captured the event-related video content related to the defined event, the emphasizer component is configured to at least one of generate an indicator that is displayed on the display screen or highlight the event-related video content, and wherein the indicator indicates the video content comprises the event-related video content.
19. The system of claim 12, wherein the executable components further comprise a communicator component configured to receive respective items of video content and respective items of audio content from respective devices in connection with a location associated with the defined event, wherein the analyzer component is configured to analyze the respective items of video content and the respective items of audio content, and wherein the respective items of video content and the respective items of audio content associated with the respective devices comprise a first item of video content and a first item of audio content associated with a first device of the respective devices and a second item of video content and a second item of audio content associated with a second device of the respective devices different than the first device.
20. The system of claim 19, wherein the video content is the first item of video content and the audio content is the first item of audio content, and wherein, in response to a determination that the defined event exists in the first item of audio content and the second item of audio content, the media management component is configured to determine whether a second image capture component of the second device captured second event-related video content relating to the defined event in connection with capture of the second item of video content based on a result of analyzing a third direction in which the defined event occurred with respect to a second audio capture component of the second device in relation to a fourth direction that the second image capture component was facing while capturing the second item of video content, in accordance with a defined match criterion.
21. The system of claim 20, wherein the first device comprises the video capture component and the audio capture component, wherein, in response to a first determination that the video capture component captured the event-related video content of the first item of video content and a second determination that the second video capture component did not capture the second event-related video content in connection with capturing the second item of content, the media management component is configured to at least one of select at least a portion of the first item of video content comprising the event-related video content for presentation or present an indicator in connection with at least the portion of the first item of video content, and wherein the indicator facilitates indicating that at least the portion of the first item of video content comprises the event-related video content due to the first direction associated with the first item of audio content substantially corresponding to the second direction associated with the first item of video content.
22. A machine-readable storage device comprising executable instructions that, in response to execution, cause a system comprising a processor to perform operations, the operations comprising: analyzing audio information captured by an audio capture component and associated with video information captured by an image capture component to identify a defined event in the audio content; analyzing a first direction in which the identified defined event occurred relative to the audio capture component in relation to a second direction that the image capture component was facing while capturing the video content; determining, based on analyzing the first direction in which the identified defined event occurred, whether the image capture component captured event-related video information is related to the defined event; presenting the image capture component captured video content based on the determination; and indicating the image capture component captured video content as event-related during presentation.
23. The machine-readable storage device of claim 22, wherein the operations further comprise: identifying the first direction in which the defined event occurred relative to the audio capture component based on the analyzing of the audio information; comparing the second direction that the image capture component was facing to the first direction in which the defined event occurred; and determining whether the image capture component captured the event-related video information is related to the defined event based on a comparison result of the comparing.
24. The machine-readable storage device of claim 23, wherein the operations further comprise: based on a result of determining whether the image capture component captured the event-related video information is related to the defined event, at least one of: determining whether to present or select at least a portion of the video information that comprises the event-related video information or at least a portion of the audio information, or determining whether to present a match indicator in connection with the video information.
25. A method, comprising: analyzing audio content captured by a plurality of audio capture components; identifying an event in the analyzed audio content from one of the plurality of audio capture components; identifying a first direction in which the identified event occurred relative to the one of the plurality of audio capture components; identifying a second direction that an image capture component was facing while capturing video content; comparing the first direction and the second direction; determining whether the video content captured by the image capture component is related to the identified event based on the comparison; presenting through a display component the video content captured by the image capture component based on the determination; and indicating the video content as event-related during presentation.
26. The method of claim 25, wherein analyzing the audio content captured by the audio capture component comprises analyzing two or more portions of the audio content captured by two or more audio sensors of the audio capture component; and identifying the first direction in which the identified event occurred relative to the audio capture component comprises identifying the first direction based on a time difference between capture of the two or more portions of the audio content or triangulation of a source of a sound associated with the identified event in the two or more portions of the audio content.
27. The method of claim 25, further comprising: determining a field of view of the image capture component; and comparing the field of view of the image capture component to the first direction in which the identified event occurred to facilitate determining whether the first direction is within the field of view of the image capture component.
</claims>
</document>
