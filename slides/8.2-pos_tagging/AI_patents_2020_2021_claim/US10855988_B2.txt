<document>

<filing_date>
2018-12-19
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2018-12-19
</priority_date>

<ipc_classes>
G06N20/10,H04N19/11,H04N19/132,H04N19/139,H04N19/149,H04N19/159,H04N19/172
</ipc_classes>

<assignee>
QUALCOMM
</assignee>

<inventors>
WANG XIANGLIN
JIN, GUOXIN
</inventors>

<docdb_family_id>
71097942
</docdb_family_id>

<title>
Adaptive prediction structures
</title>

<abstract>
Systems, methods, and computer-readable media are described for providing improved video or image encoding, including adaptive prediction structures for encoding video frames. In some examples, systems, methods, and computer-readable media can include obtaining a sequence of frames; determining, based on frame statistics associated with a first frame in the sequence of frames, a prediction structure for encoding the sequence of frames, the prediction structure defining an order in which frames in the sequence of frames are encoded and a prediction distance representing a maximum distance permitted between referencing frames and reference frames in the sequence of frames, and the frame statistics indicating an amount of motion in the first frame. The systems, methods, and computer-readable media can also include encoding one or more of the sequence of frames based on the prediction structure.
</abstract>

<claims>
1. A method of encoding frames, the method comprising: obtaining a sequence of frames at an encoder; determining frame statistics associated with a first frame in the sequence of frames; determining, based on the determined frame statistics associated with the first frame in the sequence of frames, to change from a first prediction structure currently being used to a second prediction structure for encoding one or more frames that occur later in coding order in the sequence of frames than the first frame, the second prediction structure defining an order in which frames in the sequence of frames are encoded and a prediction distance representing a maximum distance permitted between any referencing frames and reference frames available for reference by the referencing frames when performing inter-prediction, the prediction distance defined by the second prediction structure being different than a prediction distance defined by the first prediction structure; and encoding the one or more frames based on the second prediction structure.
2. The method of claim 1, further comprising: obtaining an additional sequence of frames at the encoder; determining, based on additional frame statistics associated with a second frame in the additional sequence of frames, a different prediction structure for encoding the additional sequence of frames, the different prediction structure defining a different order in which frames in the additional sequence of frames are encoded and a different prediction distance representing a different maximum distance permitted between referencing frames and reference frames in the additional sequence of frames; and encoding one or more of the additional sequence of frames based on the different prediction structure.
3. The method of claim 2, wherein the frame statistics indicate an amount of motion in the first frame and the additional frame statistics indicate an amount of motion in the second frame, wherein the prediction distance defined by the second prediction structure is smaller than the different prediction distance when the amount of motion in the first frame is greater than the amount of motion in the second frame, and wherein the prediction distance defined by the second prediction structure is larger than the different prediction distance when the amount of motion in the first frame is less than the amount of motion in the second frame.
4. The method of claim 2, further comprising: calculating a first feature vector representing an amount of motion in the first frame, the first feature vector being calculated based on at least one of a first respective motion vector computed for the first frame, a first respective intra ratio computed for the first frame, a first respective skip ratio computed for the first frame, a weight, and a bias value; and calculating a second feature vector representing an amount of motion in the second frame, the second feature vector being calculated based on at least one of a second respective motion vector computed for the second frame, a second respective intra ratio computed for the second frame, a second respective skip ratio computed for the second frame, the weight, and the bias value.
5. The method of claim 4, further comprising: based on the first feature vector, determining, using a classifier, at least one of the second prediction structure for encoding the one or more frames and a first respective size of the prediction distance defined by the second prediction structure, the classifier comprising one of a linear classifier or a decision tree classifier; and based on the second feature vector, determining, using the classifier, at least one of the different prediction structure for encoding the additional sequence of frames and a second respective size of the different prediction distance.
6. The method of claim 4, further comprising: calculating a training feature vector for at least one frame in a sample sequence of frames; adjusting, based on an accuracy or error associated with the training feature vector, at least one of a respective weight and a respective bias value used to calculate the training feature vector to generate a trained weight and a trained bias value; and using the trained weight and the trained bias value to determine the weight and the bias value associated with the first feature vector and the second feature vector.
7. The method of claim 4, wherein the first respective intra ratio comprises a first percentage of pixels coded in the first frame by intra prediction and the second respective intra ratio comprises a second percentage of pixels coded in the second frame by intra prediction, wherein the first respective skip ratio comprises a third percentage of pixels coded by skip mode from among the pixels coded in the first frame by intra prediction, and wherein the second respective skip ratio comprises a fourth percentage of pixels coded by skip mode from among the pixels coded in the second frame by intra prediction.
8. The method of claim 4, wherein the first respective motion vector is calculated at least partly by averaging a first set of motion vectors corresponding to a first plurality of blocks in the first frame, and wherein the second respective motion vector is calculated at least partly by averaging a second set of motion vectors corresponding to a second plurality of blocks in the second frame.
9. The method of claim 1, wherein determining to change from the first prediction structure to the second prediction structure comprises: selecting, based on respective frame statistics associated with at least one frame from the sequence of frames, a prediction mode for encoding operations associated with the sequence of frames, the prediction mode comprising a short prediction mode or a long prediction mode, wherein the respective frame statistics comprise a respective amount of motion calculated for the at least one frame, wherein the short prediction mode is selected when an amount of motion in the first frame is below a threshold or a type of content in the first frame comprises screen content, and wherein the long prediction mode is selected when the amount of motion in the first frame is above the threshold.
10. The method of claim 9, further comprising: processing the first frame using a content classifier; and determining, based on an output from the content classifier, that the type of content in the first frame comprises screen content.
11. The method of claim 9, wherein the prediction mode comprises the short prediction mode and the second prediction structure is associated with the short prediction mode, the method further comprising: when processing a frame from the sequence of frames, determining whether to switch to the long prediction mode and change the second prediction structure to a long distance prediction structure having a longer prediction distance than the prediction distance defined by the second prediction structure; and in response to determining to switch to the long prediction mode and change the second prediction structure to the long distance prediction structure, encoding the frame from the sequence of frames based on the long prediction mode and the long distance prediction structure.
12. The method of claim 9, wherein the prediction mode comprises the long prediction mode and the second prediction structure is associated with the long prediction mode, the method further comprising: for each anchor frame in the sequence of frames that is processed while the long prediction mode is selected, determining whether to switch to the short prediction mode and a short distance prediction structure having a shorter prediction distance than the prediction distance defined by the second prediction structure; and in response to determining to switch to the short prediction mode and change the second prediction structure to the short distance prediction structure, encoding a frame from the sequence of frames based on the short prediction mode and the short distance prediction structure.
13. The method of claim 1, wherein encoding the one or more frames is further based on a respective rate control model selected for each frame, the respective rate control model comprising a q-domain model, a p-domain model, or a λ-domain model.
14. An apparatus for encoding frames, the apparatus comprising: memory configured to store data; and one or more processors configured to: obtain a sequence of frames; determine frame statistics associated with a first frame in the sequence of frames; determine, based on the determined frame statistics associated with the first frame in the sequence of frames, to change from a first prediction structure currently being used to a second prediction structure for encoding one or more frames that occur later in coding order in the sequence of frames than the first frame, the second prediction structure defining an order in which frames in the sequence of frames are encoded and a prediction distance representing a maximum distance permitted between any referencing frames and reference frames available for reference by the referencing frames when performing inter-prediction, the prediction distance defined by the second prediction structure being different than a prediction distance defined by the first prediction structure; and encode the one or more frames based on the second prediction structure.
15. The apparatus of claim 14, wherein the one or more processors are further configured to: obtain an additional sequence of frames; determine, based on additional frame statistics associated with a second frame in the additional sequence of frames, a different prediction structure for encoding the additional sequence of frames, the different prediction structure defining a different order in which frames in the additional sequence of frames are encoded and a different prediction distance representing a different maximum distance permitted between referencing frames and referenced frames in the additional sequence of frames; and encode one or more of the additional sequence of frames based on the different prediction structure.
16. The apparatus of claim 15, wherein the frame statistics indicate an amount of motion in the first frame and the additional frame statistics indicate an amount of motion in the second frame, wherein the prediction distance defined by the second prediction structure is smaller than the different prediction distance when the amount of motion in the first frame is greater than the amount of motion in the second frame, and wherein the prediction distance defined by the second prediction structure is larger than the different prediction distance when the amount of motion in the first frame is less than the amount of motion in the second frame.
17. The apparatus of claim 15, wherein the one or more processors are further configured to: calculate a first feature vector representing an amount of motion in the first frame, the first feature vector being calculated based on at least one of a first respective motion vector computed for the first frame, a first respective intra ratio computed for the first frame, a first respective skip ratio computed for the first frame, a weight, and a bias value; and calculate a second feature vector representing an amount of motion in the second frame, the second feature vector being calculated based on at least one of a second respective motion vector computed for the second frame, a second respective intra ratio computed for the second frame, a second respective skip ratio computed for the second frame, the weight, and the bias value.
18. The apparatus of claim 17, wherein the one or more processors are further configured to: based on the first feature vector, determine, using a classifier, at least one of the second prediction structure for encoding the one or more frames and a first respective size of the prediction distance defined by the second prediction structure, the classifier comprising one of a linear classifier or a decision tree classifier; and based on the second feature vector, determine, using the classifier, at least one of the different prediction structure for encoding the additional sequence of frames and a second respective size of the different prediction distance.
19. The apparatus of claim 17, wherein the one or more processors are further configured to: calculate a training feature vector for at least one frame in a sample sequence of frames; adjust, based on an accuracy or error associated with the training feature vector, at least one of a respective weight and a respective bias value used to calculate the training feature vector to generate a trained weight and a trained bias value; and determine, based on the trained weight and the trained bias value, the weight and the bias value associated with the first feature vector and the second feature vector.
20. The apparatus of claim 17, wherein the first respective intra ratio comprises a first percentage of pixels coded in the first frame by intra prediction and the second respective intra ratio comprises a second percentage of pixels coded in the second frame by intra prediction, wherein the first respective skip ratio comprises a third percentage of pixels coded by skip mode from among the pixels coded in the first frame by intra prediction, and wherein the second respective skip ratio comprises a fourth percentage of pixels coded by skip mode from among the pixels coded in the second frame by intra prediction.
21. The apparatus of claim 17, wherein the first respective motion vector is calculated at least partly by averaging a first set of motion vectors corresponding to a first plurality of blocks in the first frame, and wherein the second respective motion vector is calculated at least partly by averaging a second set of motion vectors corresponding to a second plurality of blocks in the second frame.
22. The apparatus of claim 14, wherein determining to change from the first prediction structure to the second prediction structure comprises: selecting, based on respective frame statistics associated with at least one frame from the sequence of frames, a prediction mode for encoding operations associated with the sequence of frames, the prediction mode comprising a short prediction mode or a long prediction mode, wherein the respective frame statistics comprise a respective amount of motion calculated for the at least one frame, wherein the short prediction mode is selected when an amount of motion in the first frame is below a threshold or a type of content in the first frame comprises screen content, and wherein the long prediction mode is selected when the amount of motion in the first frame is above the threshold.
23. The apparatus of claim 22, wherein the one or more processors are further configured to: process the first frame using a content classifier; and determine, based on an output from the content classifier, that the type of content in the first frame comprises screen content.
24. The apparatus of claim 22, wherein the prediction mode comprises the short prediction mode and the second prediction structure is associated with the short prediction mode, wherein the one or more processors are further configured to: when processing a frame from the sequence of frames, determine whether to switch to the long prediction mode and change the second prediction structure to a long distance prediction structure having a longer prediction distance than the prediction distance defined by the second prediction structure; and in response to determining to switch to the long prediction mode and change the second prediction structure to the long distance prediction structure, encode the frame from the sequence of frames based on the long prediction mode and the long distance prediction structure.
25. The apparatus of claim 22, wherein the prediction mode comprises the long prediction mode and the second prediction structure is associated with the long prediction mode, wherein the one or more processors are further configured to: for each anchor frame in the sequence of frames that is processed while the long prediction mode is selected, determine whether to switch to the short prediction mode and a short distance prediction structure having a shorter prediction distance than the prediction distance defined by the second prediction structure; and in response to determining to switch to the short prediction mode and change the second prediction structure to the short distance prediction structure, encode a frame from the sequence of frames based on the short prediction mode and the short distance prediction structure.
26. The apparatus of claim 14, wherein encoding the one or more frames is further based on a respective rate control model selected for each frame, the respective rate control model comprising a q-domain model, a p-domain model, or a λ-domain model.
27. The apparatus of claim 14, further comprising a mobile device.
28. The apparatus of claim 14, further comprising a display for displaying one or more frames.
29. The apparatus of claim 14, further comprising an encoding device.
30. A non-transitory computer-readable storage medium for encoding frames, the non-transitory computer-readable storage medium comprising instructions stored thereon which, when executed by one or more processors, cause the one or more processors to: obtain a sequence of frames; determine frame statistics associated with a first frame in the sequence of frames; determine, based on the determined frame statistics associated with the first frame in the sequence of frames, to change from a first prediction structure currently being used to a second prediction structure for encoding one or more frames that occur later in coding order in the sequence of frames than the first frame, the second prediction structure defining an order in which frames in the sequence of frames are encoded and a prediction distance representing a maximum distance permitted between any referencing frames and reference frames available for reference by the referencing frames when performing inter-prediction, the prediction distance defined by the second prediction structure being different than a prediction distance defined by the first prediction structure; and encode the one or more frames based on the second prediction structure.
</claims>
</document>
