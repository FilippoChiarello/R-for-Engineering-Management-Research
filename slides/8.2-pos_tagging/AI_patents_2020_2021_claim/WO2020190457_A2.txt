<document>

<filing_date>
2020-02-24
</filing_date>

<publication_date>
2020-09-24
</publication_date>

<priority_date>
2019-03-15
</priority_date>

<ipc_classes>
G06F9/38
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
ANANTARAMAN, ARAVINDH
GEORGE VARGHESE
KOKER, ALTUG
MAIYURAN, SUBRAMANIAM
ANDREI, Valentin
KIM, SungYe
</inventors>

<docdb_family_id>
70057240
</docdb_family_id>

<title>
SYSTEMS AND METHODS FOR SYNCHRONIZATION OF MULTI-THREAD LANES
</title>

<abstract>
Apparatuses to synchronize lanes that diverge or threads that drift are disclosed. In one embodiment, a graphics multiprocessor includes a queue having an initial state of groups with a first group having threads of first and second instruction types and a second group having threads of the first and second instruction types. A regroup engine (or regroup circuitry) regroups threads into a third group having threads of the first instruction type and a fourth group having threads of the second instruction type.
</abstract>

<claims>
What is claimed is:
1. A graphics multiprocessor, comprising:
a queue having an initial state of groups with a first group having threads of first and second instruction types and a second group having threads of the first and second instruction types; and
a regroup engine to regroup threads into a third group having threads of the first instruction type and a fourth group having threads of the second instruction type.
2. The graphics multiprocessor of claim 1, wherein the regroup engine to cause the third group to replace the first group in the queue and the fourth group to replace the second group in the queue having a regrouped state.
3. The graphics multiprocessor of claim 1, wherein each of the first instruction type and the second instruction type comprise one of a load/store instruction, an integer instruction, a floating point instruction, an integer mac instruction, an integer add instruction, a floating point add instruction, a floating point fma instruction, a floating point sine instruction, or a floating point cosine instruction.
4. The graphics multiprocessor of claim 1, further comprising:
a thread scheduler coupled to the queue; and
a plurality of execution units coupled to the thread scheduler.
5. The graphics multiprocessor of claim 4, wherein the thread scheduler is configured to schedule the first instruction type of the third group for execution on a first execution unit with full utilization of this first execution unit.
6. The graphics multiprocessor of claim 4, wherein the thread scheduler is configured to schedule the second instruction type of the fourth group for execution on a second execution unit with full utilization of this second execution unit.
7. The graphics multiprocessor of claim 1, wherein the regroup engine utilizes regrouping policies and an order that a new regrouped group is inserted in the queue is optimized depending on latencies.
8. The graphics multiprocessor of claim 1, wherein the regroup engine utilizes regrouping policies to minimize divergence between threads.
9. A graphics processor, comprising:
a queue having a first group of first and second instruction types and a second group having second and third instruction types; and
a regroup engine to regroup threads into a modified first group of the first instruction type, a modified second group of the second instruction type, and a third group of the third instruction type.
10. The graphics processor of claim 9, wherein the regroup engine to cause the modified first group to replace the first group in the queue and the modified second group to replace the second group in the queue.
11. The graphics multiprocessor of claim 9, wherein each of the first, second, and third instruction types comprise one of a load/store instruction, an integer instruction, or a floating point instruction.
12. The graphics multiprocessor of claim 9, further comprising:
a scheduler coupled to the queue; and
a plurality of execution units coupled to the scheduler.
13. The graphics multiprocessor of claim 12, wherein the scheduler is configured to schedule the first instruction type of the modified first group for execution on a first execution unit with full utilization of this first execution unit, wherein the scheduler is configured to schedule the second instruction type of the modified second group for execution on a second execution unit with full utilization of this second execution unit.
14. A graphics processor, comprising:
processing engines to process threads; and thread control circuitry coupled to the processing engines, the thread control circuitry is configured to determine groupings of instantiated threads, to dynamically determine progress of the threads for processing a task on a processing engine, and to determine drift between threads.
15. The graphics processor of claim 14, wherein the thread control circuitry is further configured to determine whether any drift between threads exceeds a threshold drift.
16. The graphics processor of claim 14, wherein the thread control circuitry is further configured to accelerate at least one thread that lags other threads by at least the threshold drift.
17. The graphics processor of claim 14, wherein the thread control circuitry accelerates the at least one thread by applying a higher priority to this at least one thread than other threads.
18. The graphics processor of claim 14, wherein the processing engines to execute threads for a single instruction multiple data (SIMD) execution model.
19. A method for scheduling optimization of threads of a graphics processing unit, comprising:
determining, with the graphics processing unit, groupings of threads;
starting execution of the threads on a plurality of processing engines;
dynamically monitoring, with a thread control circuitry of the graphics processing unit, progress of each thread for a group; and
determining, with the thread control circuitry, drift between threads.
20. The method of claim 19, further comprising:
determining, with the thread control circuitry, whether any drift between threads exceeds a threshold drift.
21. The method of claim 20, further comprising:
rescheduling, with the thread control circuitry, at least one thread that lags other threads.
22. The method of claim 19, wherein the thread control circuitry provides a higher priority level for the at least one thread that lags other threads to reschedule the at least one thread. 23. The method of claim 19, wherein the processing engines to execute threads for a single instruction multiple data (SIMD) execution model.
</claims>
</document>
