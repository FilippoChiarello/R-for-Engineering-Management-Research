<document>

<filing_date>
2020-02-21
</filing_date>

<publication_date>
2020-08-27
</publication_date>

<priority_date>
2019-02-21
</priority_date>

<ipc_classes>
B25J5/00,B25J9/16,E04F21/16,G01N21/88
</ipc_classes>

<assignee>
CANVAS CONSTRUCTION
</assignee>

<inventors>
ALBERT, KEVIN B.
DAVIS, IRENE M.
DE ALBA, JASON
HEIN, GABRIEL F.
OTHENIN-GIRARD, ZELDA
TELLERIA, MARIA J.
TONOYAN, HENRY
</inventors>

<docdb_family_id>
72141498
</docdb_family_id>

<title>
SURFACE FINISH QUALITY EVALUATION SYSTEM AND METHOD
</title>

<abstract>
A surface evaluation system that includes one or more vision systems that generate target surface data during evaluation of a surface, the one or more vision systems comprising two or more of: at least one light, a camera, a structured light camera, a laser scanner and a 3D scanner.
</abstract>

<claims>
What is claimed is:
1. An automated drywall finishing system comprising:
a mobile base unit;
a robotic arm that extends between a base end and a distal end, the robotic arm coupled to the mobile base unit at the base end of the robotic arm;
an end effector coupled at the distal end of the robotic arm;
a surface evaluation system comprising at least one light and one or more vision systems that generate target surface data to evaluate a surface of a wall assembly;
a computing device executing a computational planner that:
obtains the target surface data from the one or more vision systems;
generates instructions for driving the end effector, robotic arm, and base unit to perform at one or more drywalling task via the end effector based at least in part on the target surface data, the generating instructions for driving the end effector, robotic arm, and base unit including tuning parameters of at least one of the end effector, robotic arm, and base unit based at least in part on the target surface data, and wherein the one or more dry walling task includes at least one of re-touching at least one first portion of the surface of the wall assembly that is evaluated to be below a finish quality threshold and re-finishing at least one second portion of the surface to achieve a finish that is evaluated to be above the finish quality threshold; and
automatically drives, the end effector, robotic arm, and base unit to perform the one or more drywalling task based on the generated instructions.
2. The automated drywall finishing system of claim 1, wherein the one or more vision systems comprise one or more of a 3D scanner, laser scanner, and a camera.
3. The automated drywall finishing system of claim 1, wherein the at least one light is controlled by the surface evaluation system when generating the target surface data, including one or more of:
modulating intensity of the at least one light;
modulating a wavelength of the at least one light;
changing an incident angle of the at least one light; and
turning the at least one light on and off.
4. The automated drywall finishing system of claim 1, wherein at least one of the at least one light and one or more vision systems are disposed on the end effector.
5. The automated drywall finishing system of claim 1, wherein at least one of the at least one light and one or more vision systems are disposed on the end effector.
6. The automated drywall finishing system of claim 1, wherein the one or more vision systems take one or more surface evaluation images or surface evaluation measurements of the surface, and
wherein position data, corresponding to a previous position of the automated drywall finishing system when the one or more surface evaluation images or surface evaluation measurements were taken, is generated based at least in part on the one or more surface evaluation images or surface evaluation measurements, and
wherein the computational planner determines a position error of the automated drywall finishing system based at least in part on the position data.
7. The automated drywall finishing system of claim 1, wherein the surface evaluation system configures the at least one light for at least one of: to simulate room lighting conditions; and
to apply a harshest lighting setting to the surface to highlight defects in the surface.
8. The automated drywall finishing system of claim 1, wherein the computational planner uses wall assembly information from uploaded at least one of an architectural drawing and a building information model (BIM) for one or more of:
to establish the finish quality threshold; and
to set lighting generated by the at least one light to be representative of room lighting determined based on the wall assembly information or an environmental lighting model.
9. A surface evaluation system comprising:
one or more vision systems that generate target surface data during evaluation of a surface, the one or more vision systems comprising two or more of:
at least one light,
a camera,
a structured light camera,
a laser scanner, and
a 3D scanner.
10. The surface evaluation system of claim 9, wherein the surface comprises a coating and wherein the coating is tinted to highlight topography of the coating on the surface, the highlighted topography observable by the one or more vision systems.
11. The surface evaluation system of claim 9, wherein the at least one light is configured to highlight topography of the surface via at least one of: shining the at least one light at an incident angle to the surface to highlight topography of the surface; and
applying a first and second set of wavelengths of light to the surface when capturing a respective first and second set of images of the surface, the first and second set of wavelengths of light selected to highlight topography of the surface in the first and second set of images.
12. The surface evaluation system of claim 9, and wherein the at least one light applies light to the surface in a way that simulates anticipated lighting conditions in a room after the room is built.
13. The surface evaluation system of claim 9, wherein the surface evaluation system is disposed in a handheld unit that includes:
a plurality of lights,
a first camera, and
a display configured to present feedback regarding the surface.
14. The surface evaluation system of claim 13, wherein the plurality of lights and camera are enclosed in a light box that enables the camera to take images with controlled lighting generated by the plurality of lights.
15. The surface evaluation system of claim 9, wherein the one or more vision systems comprise a thermal imaging camera, and wherein one or more images generated by the thermal imaging camera are used for one or more of:
to identify a portion of the surface where a coating has been applied to the surface, to identify areas of different coating thicknesses applied to the surface, and to determine that coating applied to the surface has dried and meets criteria to be sanded.
16. The surface evaluation system of claim 9, further comprising an augmented reality system, the augmented reality system configured for one or more of:
indicating at least one area of the surface where a coating applied to the surface does not meet a finish quality threshold; and
indicating a location of the surface where the surface evaluation system should be positioned by a user,
wherein the augmented reality system comprises one or more screens, projectors, lasers, or augmented glasses.
17. The surface evaluation system of claim 9 wherein the surface evaluation system uses building assembly information from uploaded at least one of an architectural drawing and a building information model (BIM) for one or more of: to establish a finish quality threshold; and
to set lighting generated by the at least one light to be representative of room lighting determined based on the building assembly information or an environmental lighting model.
18. The surface evaluation system of claim 9, wherein the surface evaluation system generates surface quality data that is used to create a report on quality of a finish of at least a portion of the surface.
19. The surface evaluation system of claim 9, wherein calibration data is used to calibrate an image analysis program that establishes surface quality based at least in part on images generated by the one or more vision systems, wherein the calibration data comprises at least one of topography
measurements of the surface and human labeled datasets.
20. The surface evaluation system of claim 9, wherein the surface evaluation system evaluates a finish of the surface based at least in part on one or more surface finish characteristics, the one or more surface finish characteristics including at least one of:
surface texture,
surface porosity,
size and number of defects on the surface,
surface reflectivity,
surface sheen, and
surface planarity, and
wherein the evaluation of the surface comprises determining whether the one or more surface finish characteristics meet a respective defined surface finish quality threshold.
</claims>
</document>
