<document>

<filing_date>
2018-11-21
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2018-11-21
</priority_date>

<ipc_classes>
B25J9/16
</ipc_classes>

<assignee>
FORD GLOBAL TECHNOLOGIES
</assignee>

<inventors>
SOLTANI BOZCHALOOI, IMAN
</inventors>

<docdb_family_id>
70545909
</docdb_family_id>

<title>
AUTOMATION SAFETY AND PERFORMANCE ROBUSTNESS THROUGH UNCERTAINTY DRIVEN LEARNING AND CONTROL
</title>

<abstract>
A control and learning module for controlling a robotic arm includes at least one learning module including at least one neural network. The at least one neural network is configured to receive and be trained by both state measurements based on measurements of current state and observation measurements based on observation data during an initial learning phase. The at least one learning module is further configured to be re-tuned by updated observation data for improved performance during an operations and secondary learning phase when the robotic arm is in normal operation and after the initial learning phase.
</abstract>

<claims>
1. A control and learning module for controlling a robotic arm, comprising: at least one learning module including at least one neural network, wherein the at least one neural network is configured to receive and be trained by both state measurements based on measurements of current state and observation measurements based on observation data during an initial learning phase and is configured to be re-tuned by updated observation data for improved performance during an operations and secondary learning phase when the robotic arm is in normal operation and after the initial learning phase.
2. The control and learning module according to claim 1, wherein the state measurements are obtained by sensors and represent actual current state.
3. The control and learning module according to claim 1, wherein the at least one neural network is represented as a Bayesian neural network.
4. The control and learning module according to claim 1, wherein the at least one neural network is configured to generate an output relating to an output task and a variance associated with the output, the variance being a measure of uncertainty relating to reliability of the output task.
5. The control and learning module according to claim 1, wherein the at least one learning module comprises: a state estimation module configured to provide an estimated state based on only the observation measurements; and a dynamics modeling module configured to generate a dynamics model and a dynamics model output variance, the dynamics model output variance representing an uncertainty of the dynamics model.
6. The control and learning module according to claim 5, wherein the state estimation module is configured to output a first estimated current state and a variance associated with the first estimated current state.
7. The control and learning module according to claim 6, wherein the dynamics modeling module is configured to output a second estimated current state.
8. The control and learning module according to claim 7, wherein the state estimation module and the dynamics modeling module are each configured to receive an input relating to a difference between the first estimated current state and the second estimated current state to improve performance during the operations and secondary learning phase.
9. The control and learning system according to claim 5, wherein the estimated state includes estimated positions of obstacles and target objects in an environment.
10. The control and learning module according to claim 5, further comprising a control policy module configured to generate a control policy command and a control policy variance associated with the control policy command based on the estimated state from the state estimation module.
11. The control and learning module according to claim 10, wherein the control policy module is configured to generate the control policy command and the control policy variance only during the operations and secondary learning phase.
12. The control and learning module according to claim 10, further comprising an optimal control module configured to generate an optimal control command based on the dynamics model from the dynamics modeling module and one of the state measurements and estimated states.
13. The control and learning module according to claim 12, wherein the optimal control module is configured to override the control policy command from the control policy module when the control policy variance is larger than a predefined variance threshold value.
14. The control and learning module according to claim 13, further comprising a reachability analysis module configured to receive the state measurements, the dynamics model parameters and the associated output variance from the dynamics modeling module, and determine whether the current state is in a safe state.
15. The control and learning module according to claim 14, wherein the reachability analysis module is configured to generate a robust control command overriding the optimal control command from the optimal control module when the reachability analysis module determines that the current state is in an unsafe state.
16. The control and learning module according to claim 10, wherein the state estimation module, the dynamics modeling module, and the control policy module each include a neural network which receives training in both the initial learning phase and the operations and secondary learning phase.
17. The control and learning module according to claim 16, wherein the state estimation module, the dynamics modeling module, and the control policy module each output a variance representing uncertainty of each of the state estimation module, the dynamics modeling module, and the control policy module.
18. The control and learning module according to claim 5, wherein the dynamics modeling module includes a preliminary dynamics model and a complementary dynamics model, the preliminary dynamics model being predetermined and providing state prediction based on existing knowledge about system dynamics of the robotic arm.
19. The control and learning module according to claim 18, wherein the complementary dynamics model is configured to generate a correction parameter to correct the state prediction provided by the preliminary dynamics model.
20. The control and learning module according to claim 17, wherein the complementary dynamics model is configured to generate the dynamics model variance associated with the correction parameter.
</claims>
</document>
