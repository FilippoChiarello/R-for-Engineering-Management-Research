<document>

<filing_date>
2020-01-24
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2018-09-25
</priority_date>

<ipc_classes>
G06T1/20,G06T3/00,G06T3/20,G06T3/40,G06T7/55,H04N13/00,H04N13/111,H04N13/122,H04N13/139,H04N13/15,H04N13/161,H04N13/243,H04N13/271,H04N19/51,H04N19/523,H04N19/82,H04N5/232
</ipc_classes>

<assignee>
INTEL CORPORATION
</assignee>

<inventors>
CHAUDHURI, BINDITA
NESTARES, OSCAR
ZHANG, FAN
</inventors>

<docdb_family_id>
65230114
</docdb_family_id>

<title>
View interpolation of multi-camera array images with flow estimation and image super resolution using deep learning
</title>

<abstract>
Techniques related to interpolating an intermediate view image from multi-view images are discussed. Such techniques include downsampling first and second images that represent a view of a scene, generating a disparity map based on applying a first CNN to the downscaled first and second images, translating the downscaled first and second images using the disparity map, applying a second CNN to the translated downscaled first and second images and the disparity map to generate a downscaled intermediate image, and upscaling the downscaled intermediate image to an intermediate image at the resolution of the first and second images using an image super-resolution convolutional neural network.
</abstract>

<claims>
1. 1-24. (canceled)
25. A system for implementing a convolutional neural network (CNN) comprising: a memory to store first and second images, wherein the first and second images comprise different views of a scene and are at a first resolution; and a processor coupled to the memory, the processor to: generate at least one disparity map based at least in part on application of a first convolutional neural network to a first input volume comprising first and second downscaled images corresponding to the first and second images, respectively; determine first and second translated downscaled images based at least in part on the disparity map; apply a second convolutional neural network to a second input volume comprising the first and second translated downscaled images and the disparity map to generate a downscaled intermediate image comprising a view between the first and second translated downscaled images; and generate an intermediate image at the first resolution based at least in part on application of an image super-resolution convolutional neural network to the downscaled intermediate image.
26. The system of claim 25, wherein the first convolutional neural network comprises a first encoder-decoder convolutional neural network, and wherein the processor to generate the at least one disparity map comprises the processor to: apply the first encoder-decoder convolutional neural network to the first input volume to generate first and second disparity maps; translate the first and second downscaled images using the first and second disparity maps to generate third and fourth translated downscaled images; and apply a second encoder-decoder convolutional neural network to a third input volume comprising the third and fourth translated downscaled images to generate the at least one disparity map.
27. The system of claim 26, wherein the first and second encoder-decoder convolutional neural networks have the same architecture and implement the same neural network weights.
28. The system of claim 25, wherein the first convolutional neural network comprises an encoder-decoder convolutional neural network, the processor to generate the at least one disparity map comprises the processor to apply the encoder-decoder convolutional neural network to the first input volume to generate first and second disparity maps, and the first encoder-decoder convolutional neural network comprises an encoder portion having encoder layers to extract features from the first input volume at differing resolutions and a decoder portion to combine the extracted features using skip connections corresponding to ones of the encoder layers to estimate optical flow.
29. The system of claim 25, application of the image super-resolution convolutional neural network comprises the processor to: apply, to the downscaled intermediate image, a plurality of adjacent convolutional layers and a deconvolutional layer following the plurality of adjacent convolutional layers to generate a feature image at a second resolution greater than a third resolution of the downscaled intermediate image; upsample the downscaled intermediate image to generate a second intermediate image at the second resolution; and combine the feature image and the second intermediate image to generate an upsampled intermediate image.
30. The system of claim 29, wherein the plurality of adjacent convolutional layers are separated into blocks, wherein each block comprises a predetermined number of convolutional layers and each block implements the same neural network weights, and wherein residual connections are provided between each block of convolutional layers, the residual connections to combine inputs and outputs of each block.
31. The system of claim 29, wherein the processor to apply the image super-resolution convolutional neural network further comprises the processor to: apply, to the upsampled intermediate image, a plurality of second adjacent convolutional layers and a second deconvolutional layer following the plurality of second adjacent convolutional layers to generate a second feature image at the first resolution; upsample the upsampled intermediate image to generate a third intermediate image at the first resolution; and combine the second feature image and the third intermediate image to generate a final upsampled intermediate image.
32. The system of claim 25, wherein the downscaled intermediate image is in a first color space, the processor further to: convert the downscaled intermediate image to a second color space comprising a luma channel and one or more second channels; separate the luma channel and the one or more second channels, wherein the image super-resolution convolutional neural network is applied to only the luma channel of the downscaled intermediate image; upscale the one or more second channels of the downscaled intermediate images; and concatenate an output image of the image super-resolution convolutional neural network having only a luma channel with the upscaled one or more second channels of the downscaled intermediate images to generate the intermediate image.
33. A computer-implemented method for generating an intermediate image from multi-view images comprising: generating at least one disparity map based at least in part on applying a first convolutional neural network to a first input volume comprising first and second downscaled images corresponding to first and second images that are at a first resolution that comprise different views of a scene; determining first and second translated downscaled images based at least in part on the disparity map; applying a second convolutional neural network to a second input volume comprising the first and second translated downscaled images and the disparity map to generate a downscaled intermediate image comprising a view between the first and second translated downscaled images; and generating the intermediate image at the first resolution based at least in part on applying an image super-resolution convolutional neural network to the downscaled intermediate image.
34. The method of claim 33, wherein the first convolutional neural network comprises a first encoder-decoder convolutional neural network, and wherein generating the at least one disparity map comprises: applying the first encoder-decoder convolutional neural network to the first input volume to generate first and second disparity maps; translating the first and second downscaled images using the first and second disparity maps to generate third and fourth translated downscaled images; and applying a second encoder-decoder convolutional neural network to a third input volume comprising the third and fourth translated downscaled images to generate the at least one disparity map.
35. The method of claim 34, wherein the first and second encoder-decoder convolutional neural networks have the same architecture and implement the same neural network weights.
36. The method of claim 33, wherein applying the image super-resolution convolutional neural network comprises: applying, to the downscaled intermediate image, a plurality of adjacent convolutional layers and a deconvolutional layer following the plurality of adjacent convolutional layers to generate a feature image at a second resolution greater than a third resolution of the downscaled intermediate image; upsampling the downscaled intermediate image to generate a second intermediate image at the second resolution; and combining the feature image and the second intermediate image to generate an upsampled intermediate image.
37. The method of claim 36, wherein the plurality of adjacent convolutional layers are separated into blocks, wherein each block comprises a predetermined number of convolutional layers and each block implements the same neural network weights, and wherein residual connections are provided between each block of convolutional layers, the residual connections to combine inputs and outputs of each block.
38. The method of claim 36, wherein applying the image super-resolution convolutional neural network further comprises: applying, to the upsampled intermediate image, a plurality of second adjacent convolutional layers and a second deconvolutional layer following the plurality of second adjacent convolutional layers to generate a second feature image at the first resolution; upsampling the upsampled intermediate image to generate a third intermediate image at the first resolution; and combining the second feature image and the third intermediate image to generate a final upsampled intermediate image.
39. At least one machine readable medium comprising a plurality of instructions that, in response to being executed on a computing device, cause the computing device to generate an intermediate image from multi-view images by: generating at least one disparity map based at least in part on applying a first convolutional neural network to a first input volume comprising first and second downscaled images corresponding to first and second images that are at a first resolution that comprise different views of a scene; determining first and second translated downscaled images based at least in part on the disparity map; applying a second convolutional neural network to a second input volume comprising the first and second translated downscaled images and the disparity map to generate a downscaled intermediate image comprising a view between the first and second translated downscaled images; and generating the intermediate image at the first resolution based at least in part on applying an image super-resolution convolutional neural network to the downscaled intermediate image.
40. The machine readable medium of claim 39, wherein the first convolutional neural network comprises a first encoder-decoder convolutional neural network, and wherein generating the at least one disparity map comprises: applying the first encoder-decoder convolutional neural network to the first input volume to generate first and second disparity maps; translating the first and second downscaled images using the first and second disparity maps to generate third and fourth translated downscaled images; and applying a second encoder-decoder convolutional neural network to a third input volume comprising the third and fourth translated downscaled images to generate the at least one disparity map.
41. The machine readable medium of claim 40, wherein the first and second encoder-decoder convolutional neural networks have the same architecture and implement the same neural network weights.
42. The machine readable medium of claim 39, wherein applying the image super-resolution convolutional neural network comprises: applying, to the downscaled intermediate image, a plurality of adjacent convolutional layers and a deconvolutional layer following the plurality of adjacent convolutional layers to generate a feature image at a second resolution greater than a third resolution of the downscaled intermediate image; upsampling the downscaled intermediate image to generate a second intermediate image at the second resolution; and combining the feature image and the second intermediate image to generate an upsampled intermediate image.
43. The machine readable medium of claim 42, wherein the plurality of adjacent convolutional layers are separated into blocks, wherein each block comprises a predetermined number of convolutional layers and each block implements the same neural network weights, and wherein residual connections are provided between each block of convolutional layers, the residual connections to combine inputs and outputs of each block.
44. The machine readable medium of claim 42, wherein applying the image super-resolution convolutional neural network further comprises: applying, to the upsampled intermediate image, a plurality of second adjacent convolutional layers and a second deconvolutional layer following the plurality of second adjacent convolutional layers to generate a second feature image at the first resolution; upsampling the upsampled intermediate image to generate a third intermediate image at the first resolution; and combining the second feature image and the third intermediate image to generate a final upsampled intermediate image.
</claims>
</document>
