<document>

<filing_date>
2020-05-14
</filing_date>

<publication_date>
2020-09-03
</publication_date>

<priority_date>
2018-05-22
</priority_date>

<ipc_classes>
G10L15/06,G10L15/08,G10L15/22,G10L15/30,G10L17/00,G10L17/22,G10L25/51
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
GRUENSTEIN, ALEXANDER H.
BACCHIANI, MICHIEL A.U.
JOGLEKAR, TARAL PRADEEP
PEDDINTI, VIJAYADITYA
</inventors>

<docdb_family_id>
68614842
</docdb_family_id>

<title>
HOTWORD SUPPRESSION
</title>

<abstract>
A method includes obtaining, by data processing hardware, a plurality of non-watermarked speech samples. Each non-watermarked speech does not include an audio watermark sample. The method includes, from each non-watermarked speech sample of the plurality of non-watermarked speech samples, generating one or more corresponding watermarked speech samples that each include at least one audio watermark. The method includes training, using the plurality of non-watermarked speech samples and corresponding watermarked speech samples, a model to determine whether a given audio data sample includes an audio watermark, and after training the model, transmitting the trained model to a user computing device.
</abstract>

<claims>
1. A method comprising: obtaining, by data processing hardware, a plurality of non-watermarked speech samples, each non-watermarked speech not including an audio watermark sample; from each non-watermarked speech sample of the plurality of non-watermarked speech samples, generating, by the data processing hardware, one or more corresponding watermarked speech samples that each include at least one audio watermark: training, by the data processing hardware, using the plurality of non-watermarked speech samples and corresponding watermarked speech samples, a model to determine whether a given audio data sample includes an audio watermark; and after training the model, transmitting, by the data processing hardware, the trained model to a user computing device, the user computing device configured to: receive audio data corresponding to playback of an utterance: obtain, using the trained model, data indicating whether the audio data includes the audio watermark; and based on the data indicating whether the audio data includes the audio watermark, determine to continue or cease processing the received audio data.
2. The method of claim 1, wherein each of the plurality of non-watermarked speech samples comprises an utterance of a hotword.
3. The method of claim 1, wherein a portion of the plurality of non-watermarked speech samples comprise an utterance of a hotword.
4. The method of claim 1, wherein at least one of the plurality of non-watermarked speech samples is recorded by a device that is different than a device used to record at least one other one of the plurality of non-watermarked speech samples.
5. The method of claim 1, wherein at least one of the plurality of non-watermarked speech samples comprises different spoken terms than at least one other one of the plurality of non-watermarked speech samples.
6. The method of claim 1, wherein at least some of the plurality non-watermarked speech samples comprise background noise.
7. The method of claim 1, wherein generating the one or more corresponding watermarked speech samples that each include at least one audio watermark comprises, from at least one of the plurality of non-watermarked speech samples that comprises an utterance of a hotword, generating at least one corresponding watermarked speech sample that includes the at least one audio watermark only overlapping the hotword.
8. The method of claim 1, wherein generating the one or more corresponding watermarked speech samples that each include at least one audio watermark comprises, from at least one of the plurality of non-watermarked speech samples that comprises an utterance of a hotword, generating at least one corresponding watermarked speech sample that includes a sequence of audio watermarks that overlap the hotword and precede the hotword.
9. The method of claim 1, wherein generating the one or more corresponding watermarked speech samples comprises, from at least one of the plurality of non-watermarked speech samples: generating a first corresponding watermarked speech samples that includes a first sequence of equally-spaced audio watermarks, and generating a second corresponding watermarked speech sample that includes a second sequence of equally-spaced audio watermarks, wherein a duration between the audio watermarks in the second sequence of equally-spaced audio watermarks is different than a duration between the audio watermarks in the first sequence of equally-spaced audio watermarks.
10. The method of claim 1, wherein the at least one audio watermark in one of the watermarked speech samples is different than the at least one audio watermark in another one of the watermarked speech samples.
11. The method of claim 1, further comprising, prior to training the model: labeling, by the data processing hardware, each of the plurality of non-watermarked speech samples used to train the model as including an audio watermark; and labeling, by the data processing hardware, each of the corresponding watermarked speech samples used to train the model as not including an audio watermark.
12. The method of claim 1, wherein training the model comprises using machine learning to train the model on the plurality of non-watermarked speech samples and the corresponding watermarked speech samples to determine whether the given audio data sample includes the audio watermark.
13. The method of claim 1, wherein the user device is configured to use the trained model to obtain the data indicating whether the audio data includes the audio watermark in response to determining that the audio data includes an utterance of a particular, predefined hotword.
14. A system comprising: data processing hardware; and memory hardware in communication with the data processing hardware and storing instructions that when executed on the data processing hardware cause the data processing hardware to perform operations comprising: obtaining a plurality of non-watermarked speech samples, each non-watermarked speech not including an audio watermark sample; from each non-watermarked speech sample of the plurality of non-watermarked speech samples, generating one or more corresponding watermarked speech samples that each include at least one audio watermark; training, using the plurality of non-watermarked speech samples and corresponding watermarked speech samples, a model to determine whether a given audio data sample includes an audio watermark; and after training the model, transmitting the trained model to a user computing device, the user computing device configured to: receive audio data corresponding to playback of an utterance; obtain, using the trained model, data indicating whether the audio data includes the audio watermark; and based on the data indicating whether the audio data includes the audio watermark, determine to continue or cease processing the received audio data.
15. The system of claim 14, wherein each of the plurality of non-watermarked speech samples comprises an utterance of a hotword.
16. The system of claim 14, wherein a portion of the plurality of non-watermarked speech samples comprise an utterance of a hotword.
17. The system of claim 14, wherein at least one of the plurality of non-watermarked speech samples is recorded by a device that is different than a device used to record at least one other one of the plurality of non-watermarked speech samples.
18. The system of claim 14, wherein at least one of the plurality of non-watermarked speech samples comprises different spoken terms than at least one other one of the plurality of non-watermarked speech samples.
19. The system of claim 14, wherein at least some of the plurality non-watermarked speech samples comprise background noise.
20. The system of claim 14, wherein generating the one or more corresponding watermarked speech samples that each include at least one audio watermark comprises, from at least one of the plurality of non-watermarked speech samples that comprises an utterance of a hotword, generating at least one corresponding watermarked speech sample that includes the at least one audio watermark only overlapping the hotword.
21. The system of claim 14, wherein generating the one or more corresponding watermarked speech samples that each include at least one audio watermark comprises, from at least one of the plurality of non-watermarked speech samples that comprises an utterance of a hotword, generating at least one corresponding watermarked speech sample that includes a sequence of audio watermarks that overlap the hotword and precede the hotword.
22. The system of claim 14, wherein generating the one or more corresponding watermarked speech samples comprises, from at least one of the plurality of non-watermarked speech samples: generating a first corresponding watermarked speech samples that includes a first sequence of equally-spaced audio watermarks; and generating a second corresponding watermarked speech sample that includes a second sequence of equally-spaced audio watermarks, wherein a duration between the audio watermarks in the second sequence of equally-spaced audio watermarks is different than a duration between the audio watermarks in the first sequence of equally-spaced audio watermarks.
23. The system of claim 14, wherein the at least one audio watermark in one of the watermarked speech samples is different than the at least one audio watermark in another one of the watermarked speech samples.
24. The system of claim 14, wherein the operations further comprise, prior to training the model: labeling each of the plurality of non-watermarked speech samples used to train the model as including an audio watermark; and labeling each of the corresponding watermarked speech samples used to train the model as not including an audio watermark.
25. The system of claim 14, wherein training the model comprises using machine learning to train the model on the plurality of non-watermarked speech samples and the corresponding watermarked speech samples to determine whether the given audio data sample includes the audio watermark.
26. The system of claim 14, wherein the user device is configured to use the trained model to obtain the data indicating whether the audio data includes the audio watermark in response to determining that the audio data includes an utterance of a particular, predefined hotword.
</claims>
</document>
