<document>

<filing_date>
2019-12-16
</filing_date>

<publication_date>
2020-07-02
</publication_date>

<priority_date>
2018-12-30
</priority_date>

<ipc_classes>
G06N3/04
</ipc_classes>

<assignee>
ROBERT BOSCH
</assignee>

<inventors>
DUERICHEN, ROBERT
PETERS, CHRISTIAN
ROCZNIK, THOMAS
</inventors>

<docdb_family_id>
69055769
</docdb_family_id>

<title>
DISTRIBUTED NEURAL NETWORKS FOR EDGE DEVICES
</title>

<abstract>
To efficiently execute deep convolutional neural networks (CNN) on edge devices (e.g., wearable device like an Apple Watch or FitBit) it may be necessary to split the output tasks across different entities. For edge devices with multiple sensors that are connected to multiple hubs, simple activity spotting may then be executed on a sensor while the hub resides in a sleep-like state. The hub may then be activated when an activity is detected by a sensor and further activity classification may then be performed. It is also contemplated that the edge device may include multiple hubs for simultaneous processing of multiple classification tasks.
</abstract>

<claims>
1. A method for generating an activity classification, comprising: receiving a first data from a first sensor; extracting from the first data a first activity spotting feature using a first set of convolutional layers; receiving a second data from a second sensor; extracting from the second data a second activity spotting feature using a second set of convolutional layers; and extracting from the first activity spotting feature and second activity spotting feature an activity classification using a third set of convolutional layers and a softmax layer.
2. The method of claim 1, further comprising: extracting the first activity spotting feature using a first set of pooling layers; and extracting the second activity spotting feature using a second set of pooling layers.
3. The method of claim 1, further comprising: extracting the first activity spotting feature using a second softmax layer; and extracting the second activity spotting feature using a third softmax layer.
4. The method of claim 1, further comprising: extracting the activity classification using a third set of pooling layers.
5. The method of claim 1, further comprising: extracting the first activity spotting feature when the first sensor determines a first sensed activity has occurred; and extracting the second activity spotting feature when the second sensor determines a second sensed activity has occurred.
6. The method of claim 5, wherein the first activity spotting feature is a first binary classification indicating whether the first sensed activity has occurred; and the second activity spotting feature is a second binary classification indicating whether the second sensed activity has occurred.
7. The method of claim 6, further comprising: generating a first interrupt signal when the first activity spotting feature indicates the first sensed activity has occurred; and generating a second interrupt signal when the second activity spotting feature indicates the second sensed activity has occurred.
8. The method of claim 7, wherein the third set of convolutional layers and the softmax layer are activated from a sleeping mode state upon receiving the first interrupt signal and the second interrupt signal.
9. The method of claim 1, wherein the activity classification determines a user activity being performed.
10. A method for extracting an activity classification, comprising: receiving a first data from a first sensor; receiving a second data from a second sensor; extracting one or more activity spotting features from the first data and the second data using a first set of convolutional layers; and extracting an activity classification from the one or more activity spotting features using a softmax layer.
11. The method of claim 10, further comprising: extracting the one or more activity spotting features using a set of pooling layers.
12. The method of claim 10, further comprising: extracting the one or more activity spotting features using a second softmax layer.
13. The method of claim 10, further comprising: extracting the activity classification using a set of pooling layers.
14. The method of claim 10, further comprising: extracting the one or more activity spotting features when the first sensor determines a first sensed activity has occurred.
15. The method of claim 14, wherein the one or more activity spotting features are a first binary classification indicating whether the first sensed activity has occurred.
16. A system that extracts an activity classification, comprising: a first sensor system that receives a first sensed data when a first user activity has occurred, the first sensor system extracting a first activity spotting feature from the first sensed data using a first set of convolutional layers; a second sensor system that receives a second sensed data when a second user activity has occurred, the second sensor system extracting a second activity spotting feature from the second sensed data using a second set of convolutional layers; and a hub that extracts an activity classification from the first activity spotting feature and the second activity spotting feature using a third set of convolutional layers and a softmax layer.
17. The system of claim 16, wherein the first sensor system further extracts the first activity spotting feature using a first set of pooling layers; and the second sensor system further extracts the second activity spotting feature using a second set of pooling layers.
18. The system of claim 16, wherein the first sensor system extracts the first activity spotting feature using a second softmax layer; and the second sensor system extracts the second activity spotting feature using a third softmax layer.
19. The system of claim 16, wherein the hub extracts the activity classification using a third set of pooling layers.
20. The system of claim 16, wherein the first sensor system generates a first interrupt signal when the first activity spotting feature indicates a first sensed activity has occurred; and the second sensor system generates a second interrupt signal when the second activity spotting feature indicates a second sensed activity has occurred.
</claims>
</document>
