<document>

<filing_date>
2018-03-30
</filing_date>

<publication_date>
2020-02-11
</publication_date>

<priority_date>
2018-03-30
</priority_date>

<ipc_classes>
G06F3/01,G06K9/62,G06T3/00,G06T7/73
</ipc_classes>

<assignee>
TOBII
</assignee>

<inventors>
LINDEN, ERIK
</inventors>

<docdb_family_id>
66000983
</docdb_family_id>

<title>
Deep learning for three dimensional (3D) gaze prediction
</title>

<abstract>
Techniques for generating 3D gaze predictions based on a deep learning system are described. In an example, the deep learning system includes a neural network. A scaled image is generated from 2D image showing a user face based on a rough distance between the user eyes and a camera that generated the 2D image. Image crops at different resolutions are generated from the scaled image and include a crop around each of the user eyes and a crop around the user face. These crops are input to the neural network. In response, the neural network outputs a distance correction and a 2D gaze vector per user eye. A corrected eye-to-camera distance is generated by correcting the rough distance based on the distance correction. A 3D gaze vector for each of the user eyes is generated based on the corresponding 2D gaze vector and the corrected distance.
</abstract>

<claims>
1. A computer-implemented method for detecting three dimensional (3D) gaze, the computer-implemented method comprising: generating, by an eye tracking system based on a two dimensional (2D) image, a warped image centered around a user eye from the 2D image, wherein the 2D image is generated by a camera associated with the eye tracking system; inputting, by the eye tracking system to a neural network, the warped image, wherein the neural network predicts a distance correction, a 2D gaze origin of the user eye in the warped image, and a 2D gaze direction of the user eye in the warped image based on the warped image; generating, by the eye tracking system, a corrected distance between the user eye and the camera by at least updating an estimated distance based on the distance correction; and generating, by the eye tracking system, 3D gaze information for the user eye based on the 2D gaze origin, the 2D gaze direction, and the corrected distance.
2. The computer-implemented method of claim 1, further comprising: determining, by the eye tracking system, the estimated distance between the camera and the user eye based on the 2D image; and estimating, by the eye tracking system, a position of the user eye in a 3D space based on the corrected distance and on a position of the camera in the 3D space, wherein the 3D gaze information comprises the position of the user eye in the 3D space.
3. The computer-implemented method of claim 2, further comprising: estimating, by the eye tracking system, a 3D gaze direction from the position of the user eye in the 3D space based on the 2D gaze origin and the 2D gaze direction, wherein the 3D gaze information comprises the 3D gaze direction.
4. The computer-implemented method of claim 1, wherein generating the warped image comprises normalizing the 2D image to generate a normalized image and cropping the normalized image around the user eye to generate the warped image.
5. The computer-implemented method of claim 1, wherein the 2D image further shows a second user eye and a user face, and further comprising: generating, by the eye tracking system, a second warped image around the second user eye from the 2D image; generating, by the eye tracking system, a third warped image around the user face from the 2D image; and inputting, by the eye tracking system to the neural network, the second warped image and third warped image, wherein the neural network predicts the distance correction further based on the second warped image and the third warped image.
6. The computer-implemented method of claim 5, further comprising: generating, by the eye tracking system, a second position of the second user eye in a 3D space and a second gaze direction from the second position in the 3D space based on the corrected distance, and wherein the 3D gaze information comprises the second position and the second gaze direction.
7. The computer-implemented method of claim 6, wherein the second warped image is a mirrored image around the second user eye.
8. The computer-implemented method of claim 5, wherein the warped image and the second warped image are generated at a first image resolution, and wherein the third warped image is generated at a second image resolution that is smaller than the first image resolution, wherein the second image resolution is lower than the first image resolution, wherein the first image resolution is based on a first predefined distance associated with projecting the warped image and the second warped image in a 3D gaze space, and wherein the second image resolution is based on a second predefined distance associated with projecting the third warped image in the 3D gaze space.
9. The computer-implemented method of claim 5, wherein the neural network further predicts a second 2D gaze origin and a second 2D gaze direction of the second user eye in the second warped image based on the warped image and the second warped image.
10. The computer-implemented method of claim 5, wherein the neural network further predicts a second 2D gaze origin and a second 2D gaze direction of the second user eye in the second warped image based on the second warped image and independently of the warped image.
11. The computer-implemented method of claim 1, wherein the neural network is trained based on training images that comprise a first set of training images and a second set of training images, wherein the first set of training images show user eyes associated with gaze points in a plane of the camera, and wherein the second set of training images show user eyes associated with gaze points outside the plane of the camera.
12. The computer-implemented method of claim 11, wherein training the neural network comprises: inputting a first training image to the neural network, wherein the first training image belongs to the first set of training images; inputting a second training image to the neural network, wherein the second training image belongs to the second set of training images; and minimizing a loss function of the neural network based on a distance between a gaze point and a gaze line, wherein the gaze point is associated with one of the first training image or the second training image, and wherein the gaze line is predicted by the neural network for a shown user eye from the one of the first training image or the second training image.
13. The computer-implemented method of claim 11, wherein the first training image shows the shown user eye while gazing at the gaze point according to a gaze angle, wherein the second training image shows the shown user eye while gazing at another gaze point according to the gaze angle.
14. The computer-implemented method of claim 11, wherein the first training image and the second training image show the shown user eye while gazing at the gaze point in a gaze angle, wherein the first training image corresponds to a first distance between a training camera and the shown user eye, and wherein the second training image corresponds to a second distance between the training camera and the shown user eye.
15. The computer-implemented method of claim 11, wherein the first training image shows the shown user eye while gazing at the gaze point according to a gaze angle, wherein the second training image shows the shown user eye while gazing at another gaze point according to a different gaze angle.
16. The computer-implemented method of claim 11, wherein training the neural network comprises: updating, during the training of the neural network, parameters of the neural network based on calibration parameters, wherein upon completion of the training, inputting updated values for the calibration parameters to the neural network.
17. An eye tracking system, comprising: a camera; a processor; and a memory storing computer-readable instructions that, upon execution by the processor, cause the eye tracking system to perform operations comprising: generating, based on a two dimensional (2D) image, a warped image centered around a user eye from the 2D image, wherein the 2D image is generated by the camera; inputting the warped image to a neural network, wherein the neural network predicts a distance correction, a 2D gaze origin of the user eye in the warped image, and a 2D gaze direction of the user eye in the warped image based on the warped image; generating a corrected distance between the user eye and the camera by at least updating an estimated distance based on the distance correction; and generating 3D gaze information for the user eye based on the 2D gaze origin, the 2D gaze direction, and the corrected distance.
18. The eye tracking system of claim 17, wherein the neural network is hosted on a remote system, wherein inputting the warped image comprising transmitting the warped image to the remote system over a data network, and wherein the operations further comprise receiving the distance correction, the 2D gaze origin, and the 2D gaze direction from the remote system over the data network.
19. The eye tracking system of claim 17, wherein the neural network is trained by a remote system, and wherein the operations further comprise downloading code of the neural network from the remote system.
20. A non-transitory computer-readable storage medium comprising instructions, that upon execution on a computer system, configure the computer system perform operations comprising: generating, based on a two dimensional (2D) image, a warped image centered around a user eye from the 2D image, wherein the 2D image is generated by a camera associated with an eye tracking system; inputting the warped image to a neural network, wherein the neural network predicts a distance correction, a 2D gaze origin of the user eye in the warped image, and a 2D gaze direction of the user eye in the warped image based on the warped image; generating a corrected distance between the user eye and the camera by at least updating an estimated distance based on the distance correction; and generating 3D gaze information for the user eye based on the 2D gaze origin, the 2D gaze direction, and the corrected distance.
</claims>
</document>
