<document>

<filing_date>
2020-03-06
</filing_date>

<publication_date>
2020-09-10
</publication_date>

<priority_date>
2019-03-06
</priority_date>

<ipc_classes>
G06T17/00,G06T7/00,G06T7/20
</ipc_classes>

<assignee>
ATMO AUTO POWER
</assignee>

<inventors>
AHRENS, JASON
</inventors>

<docdb_family_id>
72338410
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR THE UNIVERSAL CONTROL OF UNIFORM INITIAL JUDGMENT
</title>

<abstract>
A system for evaluating potential behavior from a captured image data includes an image capturing device that is adapted to capture three-dimensional image data. The system also has an electronic database, stored in computer memory, of prior stored three-dimensional image data. The prior stored images have an associated behavior value. A computer processor is adapted to compare captured three-dimensional image data in real-time with the prior stored three-dimensional image data to identify a match. The computer processor sets a potential behavior value of the captured image data to the behavior of a respective behavior value associated with the image data in the database that matches the captured image data. An output device receives the potential behavior value from the computer processor wherein the output device is observable by a user. A method for evaluating a potential behavior from captured image data is also provided.
</abstract>

<claims>
1. A system for evaluating a potential behavior from captured image data, said system comprising:
an image capturing device adapted to capture three-dimensional image data;
an electronic database, stored in computer memory, of prior stored
three-dimensional image data, said prior stored images having an associated behavior value;
a computer processor adapted to compare captured three-dimensional image data, in real-time, with the prior stored three-dimensional image data to identify a match, and said computer processor setting a potential behavior value of the captured image data to the behavior value of a respective behavior associated with the image data in the database that matches the captured image data; and
an output device that receives the potential behavior value from the computer processor, wherein the output device is observable by a user.
2. The system of claim 1 , further comprising a behavior assessment input device for an individual to assign a behavior value to the prior stored image data in the database, wherein said behavior value is subsequently associated with the respective three dimensional image data in the electronic database.
3. The system of claim 2, further comprising a virtual reality system for viewing prior stored three dimensional image data whereby a user can view the prior stored three dimensional image data when evaluating a potential behavior and for assigning a behavior value to the prior stored three dimensional image data.
4. The system of claim 1 , the output device is a portable, wearable device.
5. The system of claim 4, wherein the wearable device is a watch or bracelet.
6. The system of claim 1 , wherein the image capturing device is disposed away from the user, capturing three dimensional images establishing a locus of view that includes both the user and immediate surrounding adjacent the user.
7. The system of claim 1 , wherein the image capturing device is attached to a vehicle. 8. A method for evaluating a potential behavior from captured image data, said method comprising:
capturing three-dimensional image data, using an image capturing device, of a locus that includes a user and the immediate surroundings of the user;
comparing the captured three-dimensional image data, in real-time, to prior stored three-dimensional image data present in an electronic database, using a computer processor, to determine a match, wherein the prior stored image data's respective associated behavior values;
identifying, using the processor, a potential behavior in the captured
three-dimensional image data as the behavior value of the prior stored image data that matches the captured three-dimensional image data; and
alerting the user of the potential behavior.
9. The method of claim 8, further comprising assessing behavior, present in prior captured three-dimensional image data, by a user viewing the prior captured
three-dimensional image data and manually assigning a behavior value to the prior stored three-dimensional data using an input device, the behavior value being assigned to the prior stored three-dimensional image data in the electronic database.
10. The method of claim 9, wherein the assessing behavior comprises the user viewing the prior stored three-dimensional image data using a virtual reality system.
1 1. The method of claim 8, wherein altering the user comprises sending a signal from the processor to an output device worn by the user.
12. The method of claim 8, wherein capturing the three-dimensional image data comprises establishing a locus of view that includes both the user and immediate surroundings adjacent the user, using an image capturing device that is disposed away from the user.
13. The method of claim 12, wherein the image capturing device is attached to a vehicle.
14. The method of claim 8, wherein capturing three-dimensional image data comprises identifying an object within the image data and tracking the object using the image capturing device. 15. The method of claim 14, wherein associate behavior values of the prior stored image data correspond to actions of objects within the image data.
16. The method of claim 15, further comprising assessing behavior, present in prior captured three-dimensional image data, by a user viewing the prior captured
three-dimensional image data and manually assigning a behavior value of objects in the image data, using an input device, the behavior value being assigned to the prior stored three-dimensional image data in the electronic database.
17. The method of claim 8, wherein capturing the three dimensional image data comprises using the image capturing device that is disposed away from the user to identify an object within the image data and tracking the object using the image capturing device, thereby establishing a dynamic locus of view, that moves with the tracked object and includes both the user and immediate surroundings adjacent the user.
</claims>
</document>
