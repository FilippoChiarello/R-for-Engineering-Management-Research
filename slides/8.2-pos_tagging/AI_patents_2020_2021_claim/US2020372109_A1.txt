<document>

<filing_date>
2019-05-21
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2019-05-21
</priority_date>

<ipc_classes>
G06F11/30,G06F16/11,G06F16/31,G06F16/35,G06N5/04
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
BRAKE, KYLE M.
FROST, KEITH G.
BOXWELL, STEPHEN A.
Vernier, Stanley J.
</inventors>

<docdb_family_id>
73457145
</docdb_family_id>

<title>
Routine Evaluation of Accuracy of a Factoid Pipeline and Staleness of Associated Training Data
</title>

<abstract>
A mechanism is provided for routinely evaluating an accuracy of a request processing pipeline. A set of questions is executed through the request processing pipeline, producing a list of answers, supporting documents, and accuracy metrics. A determination is made as to whether a document contribution value of each document associated with the answer is equal to or above a document contribution threshold value. For those documents equal to or above the document contribution threshold value, a snapshot is stored in a training-data data structure. Based on a clustering of questions, for each question cluster, a determination is made of an average accuracy metric. A comparison is performed and a determination is made as to whether an accuracy metric delta exceeds the accuracy metric threshold value. If so, a differential report is generated indicating a review is needed of a training of the request processing pipeline.
</abstract>

<claims>
1. A method, in a data processing system, for routinely evaluating an accuracy of a request processing pipeline, the method comprising: responsive to ingesting a set of new documents into a corpus of a request processing pipeline, executing a set of questions through the request processing pipeline, producing a list of answers, supporting documents, and accuracy metrics; for each answer in the list of answers, determining whether a document contribution value of each document associated with the answer is equal to or above a document contribution threshold value; for those documents with a document contribution value associated with the answer that is equal to or above the document contribution threshold value, storing a snapshot of the answers, highly-contributing supporting documents, and accuracy metrics in a training-data data structure; clustering together the questions using topic modeling; based on the clustering, for each question cluster, determining an average accuracy metric across the questions using the accuracy metrics associated with the answers stored in training-data data structure; comparing the average accuracy metric to an initial average accuracy metric; determining whether an accuracy metric delta identified in the comparison exceeds the accuracy metric threshold value; and responsive to the accuracy metric delta the accuracy metric threshold value, generating a differential report indicating a review is needed of a training of the request processing pipeline.
2. The method of claim 1, wherein the set of questions is from a list of QA training pairs.
3. The method of claim 1, further comprising: sending the differential report to an administrator; responsive to the administrator indicating that the request processing pipeline is to be retrained, culling one or more documents from the corpus; and initiating a retraining of the request processing pipeline.
4. The method of claim 1, further comprising: sending the differential report to an administrator; responsive to the administrator indicating that the request processing pipeline is to be retrained, updating a list of QA training pairs used to train the request processing pipeline; and initiating a retraining of the request processing pipeline.
5. The method of claim 1, wherein the initial average accuracy metric is generated by the method comprising: receiving a list of QA training pairs for initial training of the request processing pipeline; executing a set of questions from the list of QA training pair through the request processing pipeline, producing an initial list of answers, initial set of supporting documents, and initial accuracy metrics; for each initial answer in the initial list of answers, determining whether a document contribution value of each document associated with the initial answer is equal to or above a document contribution threshold value; for those documents with a document contribution value associated with the initial answer that is equal to or above the document contribution threshold value, storing an initial snapshot of the initial list of answers, initial highly-contributing of supporting documents, and the initial accuracy metrics in a training-data data structure; clustering together the initial questions using topic modeling; and based on the clustering, for each question cluster, determining the initial average accuracy metric across the initial questions using the initial accuracy metrics associated with the initial answers stored in training-data data structure.
6. The method of claim 1, wherein the accuracy metric threshold value identifies changes in accuracy metrics of the request processing pipeline.
7. The method of claim 1, wherein the document contribution threshold value identifies a consideration of documents in the corpus and their individual contribution to the confidence of a particular answer.
8. A computer program product comprising a computer readable storage medium having a computer readable program for routinely evaluating an accuracy of a request processing pipeline stored therein, wherein the computer readable program, when executed on a computing device, causes the computing device to: responsive to ingesting a set of new documents into a corpus of a request processing pipeline, execute a set of questions through the request processing pipeline, producing a list of answers, supporting documents, and accuracy metrics; for each answer in the list of answers, determine whether a document contribution value of each document associated with the answer is equal to or above a document contribution threshold value; for those documents with a document contribution value associated with the answer that is equal to or above the document contribution threshold value, store a snapshot of the answers, highly-contributing supporting documents, and accuracy metrics in a training-data data structure; cluster together the questions using topic modeling; based on the clustering, for each question cluster, determine an average accuracy metric across the questions using the accuracy metrics associated with the answers stored in training-data data structure; compare the average accuracy metric to an initial average accuracy metric; determine whether an accuracy metric delta identified in the comparison exceeds the accuracy metric threshold value; and responsive to the accuracy metric delta the accuracy metric threshold value, generate a differential report indicating a review is needed of a training of the request processing pipeline.
9. The computer program product of claim 8, wherein the set of questions is from a list of QA training pairs.
10. The computer program product of claim 8, wherein the computer readable program further causes the computing device to: send the differential report to an administrator; responsive to the administrator indicating that the request processing pipeline is to be retrained, cull one or more documents from the corpus; and initiate a retraining of the request processing pipeline.
11. The computer program product of claim 8, wherein the computer readable program further causes the computing device to: send the differential report to an administrator; responsive to the administrator indicating that the request processing pipeline is to be retrained, update a list of QA training pairs used to train the request processing pipeline; and initiate a retraining of the request processing pipeline.
12. The computer program product of claim 8, wherein the computer readable program to generate the initial average accuracy metric further causes the computing device to: receive a list of QA training pairs for initial training of the request processing pipeline; execute a set of questions from the list of QA training pair through the request processing pipeline, producing an initial list of answers, initial set of supporting documents, and initial accuracy metrics; for each initial answer in the initial list of answers, determine whether a document contribution value of each document associated with the initial answer is equal to or above a document contribution threshold value; for those documents with a document contribution value associated with the initial answer that is equal to or above the document contribution threshold value, store an initial snapshot of the initial list of answers, initial highly-contributing of supporting documents, and the initial accuracy metrics in a training-data data structure; cluster together the initial questions using topic modeling; and based on the clustering, for each question cluster, determine the initial average accuracy metric across the initial questions using the initial accuracy metrics associated with the initial answers stored in training-data data structure.
13. The computer program product of claim 8, wherein the accuracy metric threshold value identifies changes in accuracy metrics of the request processing pipeline.
14. The computer program product of claim 8, wherein the document contribution threshold value identifies a consideration of documents in the corpus and their individual contribution to the confidence of a particular answer.
15. An apparatus for routinely evaluating an accuracy of a request processing pipeline comprising: a processor; and a memory coupled to the processor, wherein the memory comprises instructions which, when executed by the processor, cause the processor to: responsive to ingesting a set of new documents into a corpus of a request processing pipeline, execute a set of questions through the request processing pipeline, producing a list of answers, supporting documents, and accuracy metrics; for each answer in the list of answers, determine whether a document contribution value of each document associated with the answer is equal to or above a document contribution threshold value; for those documents with a document contribution value associated with the answer that is equal to or above the document contribution threshold value, store a snapshot of the answers, highly-contributing supporting documents, and accuracy metrics in a training-data data structure; cluster together the questions using topic modeling; based on the clustering, for each question cluster, determine an average accuracy metric across the questions using the accuracy metrics associated with the answers stored in training-data data structure; compare the average accuracy metric to an initial average accuracy metric; determine whether an accuracy metric delta identified in the comparison exceeds the accuracy metric threshold value; and responsive to the accuracy metric delta the accuracy metric threshold value, generate a differential report indicating a review is needed of a training of the request processing pipeline.
16. The apparatus of claim 15, wherein the set of questions is from a list of QA training pairs.
17. The apparatus of claim 15, wherein the instructions further cause the processor to: send the differential report to an administrator; responsive to the administrator indicating that the request processing pipeline is to be retrained, cull one or more documents from the corpus; and initiate a retraining of the request processing pipeline.
18. The apparatus of claim 15, wherein the instructions further cause the processor to: send the differential report to an administrator; responsive to the administrator indicating that the request processing pipeline is to be retrained, update a list of QA training pairs used to train the request processing pipeline; and initiate a retraining of the request processing pipeline.
19. The apparatus of claim 15, wherein the instructions to generate the initial average accuracy metric further cause the computing device to: receive a list of QA training pairs for initial training of the request processing pipeline; execute a set of questions from the list of QA training pair through the request processing pipeline, producing an initial list of answers, initial set of supporting documents, and initial accuracy metrics; for each initial answer in the initial list of answers, determine whether a document contribution value of each document associated with the initial answer is equal to or above a document contribution threshold value; for those documents with a document contribution value associated with the initial answer that is equal to or above the document contribution threshold value, store an initial snapshot of the initial list of answers, initial highly-contributing of supporting documents, and the initial accuracy metrics in a training-data data structure; cluster together the initial questions using topic modeling; and based on the clustering, for each question cluster, determine the initial average accuracy metric across the initial questions using the initial accuracy metrics associated with the initial answers stored in training-data data structure.
20. The apparatus of claim 15, wherein the accuracy metric threshold value identifies changes in accuracy metrics of the request processing pipeline and wherein the document contribution threshold value identifies a consideration of documents in the corpus and their individual contribution to the confidence of a particular answer.
</claims>
</document>
