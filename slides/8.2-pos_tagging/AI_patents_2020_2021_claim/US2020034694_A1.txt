<document>

<filing_date>
2019-07-25
</filing_date>

<publication_date>
2020-01-30
</publication_date>

<priority_date>
2018-07-25
</priority_date>

<ipc_classes>
G06K9/62,G06N3/04
</ipc_classes>

<assignee>
ELEMENT AI
</assignee>

<inventors>
LACOSTE, ALEXANDRE
ORESHKIN, BORIS
</inventors>

<docdb_family_id>
69178517
</docdb_family_id>

<title>
MULTIPLE TASK TRANSFER LEARNING
</title>

<abstract>
Systems and methods relating to multitask transfer learning. Neural networks are used to accomplish a number of tasks and the results of these tasks are used to determine parameters common to these and other tasks. These parameters can then be used to accomplish other related tasks. In the description, data fitting as well as image related tasks are used. Task conditioning as well as the use of a KL regularizer have greatly improved results when testing the methods of the invention.
</abstract>

<claims>
We claim:
1. A method for accomplishing a first task, the method comprising: a) accomplishing a plurality of second tasks, each of said second tasks being related to said first task; b) compiling results from accomplishing said plurality of second tasks; c) using said results from said plurality of second tasks to determine parameters common to all of said plurality of second tasks and to said first task; d) using said parameters determined in step c) to accomplish said first task.
2. The method according to claim 1, wherein step a) comprises using a plurality of neural networks to accomplish said plurality of second tasks.
3. The method according to claim 2, wherein similar neural networks are used to accomplish each of said plurality of second tasks.
4. The method according to claim 2, wherein different types of neural networks are used to accomplish each of said plurality of second tasks.
5. The method according to claim 2, wherein neural networks used to accomplish said first task are similar to neural networks used to accomplish said plurality of second tasks.
6. The method according to claim 1, wherein step c) comprises determining parameters used in a neural network for accomplishing one or more of said plurality of second tasks.
7. The method according to claim 1, wherein said plurality of second tasks and said first task are data fitting related tasks.
8. The method according to claim 1, further comprising using task conditioning to accelerate training of neural networks used in said method.
9. The method according to claim 1, further comprising training a latent classifier component on a subset of said results.
10. A system for accomplishing a first task, the system comprising at least one neural network having a plurality of parameters, said plurality of parameters comprising parameters determined by use of results from accomplishing at least one second task, said first task being related to said at least one second task.
11. The system according to claim 10 wherein at least one second neural network is used to accomplish said at least one second task.
12. The system according to claim 11 wherein said at least one second neural network is executed on a second system different from said system.
13. The system according to claim 12 wherein said second system is a dedicated machine learning data processing system.
14. The system according to claim 13 wherein said parameters include weights used by said at least one neural network.
15. The system according to claim 10 wherein said first task and said at least one second task are data fitting related tasks.
16. The system according to claim 11 wherein said at least one neural network and said at least one second neural networks are similar neural networks.
</claims>
</document>
