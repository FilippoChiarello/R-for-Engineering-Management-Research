<document>

<filing_date>
2020-01-17
</filing_date>

<publication_date>
2020-07-23
</publication_date>

<priority_date>
2019-01-21
</priority_date>

<ipc_classes>
G06F40/216,G06Q10/10,H04L12/58,H04W4/12
</ipc_classes>

<assignee>
BITDEFENDER IPR MANAGEMENT
</assignee>

<inventors>
BUGOIU, BOGDAN
AFLOAREI, ANDREI M.
MIRON, ADRIAN
BOTEZATU, LOREDANA
ZAVOIU, VIOREL
PATRU, ELENA M.
HOLBAN, LIVIU A.
</inventors>

<docdb_family_id>
71609505
</docdb_family_id>

<title>
Anti-Cyberbullying Systems and Methods
</title>

<abstract>
Some embodiments use text and/or image processing methods to determine whether a user of an electronic messaging platform is subject to an online threat such as cyberbullying, sexual grooming, and identity theft, among others. In some embodiments, a text content of electronic messages is automatically harvested and aggregated into conversations. Conversation data are then analyzed to extract various threat indicators. A result of a text analysis may be combined with a result of an analysis of an image transmitted as part of the respective conversation. When a threat is detected, some embodiments automatically send a notification to a third party (e.g., parent, teacher, etc.)
</abstract>

<claims>
1. A parental control method comprising employing at least one hardware processor of a computer system to: analyze a conversation to determine an aggressiveness score and a friendliness score, wherein the conversation comprises a sequence of electronic messages exchanged between a first user and a second user, the aggressiveness score indicating a level of aggressiveness of the conversation, the friendliness score indicating a level of friendliness of the conversation, and wherein at least one of the aggressiveness score and the friendliness score is determined according to multiple messages of the conversation; determine whether the first user is bullied by the second user according to the aggressiveness and friendliness scores; and in response, when the first user is bullied, transmit a parental notification to a parental reporting device identified from a plurality of devices according to the first user, the parental notification indicating that the first user is bullied.
2. The method of claim 1, further comprising: determining a first sentiment score and a second sentiment score according to the conversation, the first sentiment score indicative of an inferred sentiment of the first user and the second sentiment score indicative of an inferred sentiment of the second user; and determining whether the first user is bullied further according to the first and second sentiment scores.
3. The method of claim 1, further comprising: determining a sexual content score according to the conversation, the sexual content score indicating whether the conversation comprises sexually-explicit language; and determining whether the first user is bullied further according to the sexual content score.
4. The method of claim 1, wherein the aggressiveness score indicates whether the first user uses aggressive language within the conversation.
5. The method of claim 1, comprising determining the aggressiveness score according to whether multiple messages of the conversation include aggressive language.
6. The method of claim 5, comprising determining the aggressiveness score according to a count of messages that include aggressive language.
7. The method of claim 5, comprising determining the aggressiveness score according to a count of consecutive messages separating two messages within the conversation that both include aggressive language.
8. The method of claim 1, comprising determining that the first user is not bullied when the aggressiveness and friendliness scores indicate that the conversation is both aggressive and friendly.
9. The method of claim 1, comprising determining that the first user is bullied when the aggressiveness score indicates that a language of the second user is substantially more aggressive than a language of the first user.
10. A computer system comprising at least one hardware processor configured to execute a conversation analyzer and a parental notification dispatcher, wherein: the conversation analyzer is configured to: analyze a conversation to determine an aggressiveness score and a friendliness score, wherein the conversation comprises a sequence of electronic messages exchanged between a first user and a second user, the aggressiveness score indicating a level of aggressiveness of the conversation, the friendliness score indicating a level of friendliness of the conversation, and wherein at least one of the aggressiveness score and the friendliness score is determined according to multiple messages of the conversation, and determine whether the first user is bullied by the second user according to the aggressiveness and friendliness scores; and the parental notification dispatcher is configured, in response to the conversation analyzer determining that first user is bullied, to transmit a parental notification to a parental reporting device identified from a plurality of devices according to the first user, the notification message indicating that the first user is bullied.
11. The computer system of claim 10, wherein the conversation analyzer is further configured to: determine a first sentiment score and a second sentiment score according to the conversation, the first sentiment score indicative of an inferred sentiment of the first user and the second sentiment score indicative of an inferred sentiment of the second user; and determine whether the first user is bullied further according to the first and second sentiment scores.
12. The computer system of claim 10, wherein the conversation analyzer is further configured to: determine a sexual content score according to the conversation, the sexual content score indicating whether the conversation comprises sexually-explicit language; and determine whether the first user is bullied further according to the sexual content score.
13. The computer system of claim 10, wherein the aggressiveness score indicates whether the first user uses aggressive language within the conversation.
14. The computer system of claim 10, wherein the conversation analyzer is configured to determine the aggressiveness score according to whether multiple messages of the conversation include aggressive language.
15. The computer system of claim 14, wherein the conversation analyzer is configured to determine the aggressiveness score according to a count of messages that include aggressive language.
16. The computer system of claim 14, wherein the conversation analyzer is configured to determine the aggressiveness score according to a count of consecutive messages separating two messages within the conversation that both include aggressive language.
17. The computer system of claim 10, wherein the conversation analyzer is configured to determine that the first user is not bullied when the aggressiveness and friendliness scores indicate that the conversation is both aggressive and friendly.
18. The computer system of claim 10, wherein the conversation analyzer is configured to determine that the first user is bullied when the aggressiveness score indicates that a language of the second user is substantially more aggressive than a language of the first user.
19. A non-transitory computer-readable medium storing instructions which, when executed by at least one hardware processor of a computer system, cause the computer system to form a conversation analyzer and a parental notification dispatcher, wherein: the conversation analyzer is configured to: analyze a conversation to determine an aggressiveness score and a friendliness score, wherein the conversation comprises a sequence of electronic messages exchanged between a first user and a second user, the aggressiveness score indicating a level of aggressiveness of the conversation, the friendliness score indicating a level of friendliness of the conversation, and wherein at least one of the aggressiveness score and the friendliness score is determined according to multiple messages of the conversation, and determine whether the first user is bullied by the second user according to the aggressiveness and friendliness scores; and the parental notification dispatcher is configured, in response to the conversation analyzer determining that first user is bullied, to transmit a parental notification to a parental reporting device identified from a plurality of devices according to the first user, the notification message indicating that the first user is bullied.
</claims>
</document>
