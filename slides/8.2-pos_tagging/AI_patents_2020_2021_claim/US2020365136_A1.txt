<document>

<filing_date>
2019-05-14
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-14
</priority_date>

<ipc_classes>
G10L13/033,G10L13/04,G10L13/047
</ipc_classes>

<assignee>
SONY CORPORATION
</assignee>

<inventors>
CANDELORE, BRANT
NEJAT, MAHYAR
</inventors>

<docdb_family_id>
73245149
</docdb_family_id>

<title>
SPEECH SYNTHESIZING DEVICES AND METHODS FOR MIMICKING VOICES OF PUBLIC FIGURES
</title>

<abstract>
Speech synthesizing devices and methods are disclosed for mimicking the voices of public figures. A text-to-speech deep neural network (DNN) can be used to do so, with the DNN being trained using publicly available audio recordings of a given public figure speaking as well as text corresponding to the words that are spoken by the public figure in the audio recordings. The DNN may then be used to produce various audio outputs in the voice of the public figure.
</abstract>

<claims>
1. An apparatus, comprising: at least one computer memory that is not a transitory signal and that comprises instructions executable by at least one processor to: extract recorded speech of a celebrity from at least one piece of content that is publicly available; analyze the recorded speech of the celebrity; and based on the analysis, configure an artificial intelligence model that can mimic the voice of the celebrity to output additional speech in the voice of the celebrity.
2. The apparatus of claim 1, wherein the instructions are executable to: analyze the recorded speech to train at least one neural network to mimic the voice of the celebrity, the artificial intelligence model comprising the at least one neural network.
3. The apparatus of claim 2, wherein the at least one neural network is at least n part trained unsupervised.
4. The apparatus of claim 3, wherein the at least one neural network is trained unsupervised at least in part using text that indicates words spoken by the celebrity in the recorded speech.
5. The apparatus of claim 4, wherein the text is associated with closed captioning data corresponding to the recorded speech.
6. The apparatus of claim 4, wherein the at least one neural network is trained unsupervised at least in part using the recorded speech of the celebrity.
7. The apparatus of claim 6, wherein the recorded speech of the celebrity is extracted based on identification of the recorded speech as not including speech from other speakers during one or more segments of the recorded speech.
8. The apparatus of claim 2, wherein the neural network creates a model of the celebrity which may be shared with other devices with text-to-speech engines.
9. The apparatus of claim 2, wherein the at least one neural network is trained at least in part as supervised by a human, the at least one processor receiving an indication from the human that the recorded speech is that of the celebrity.
10. The apparatus of claim 1, wherein the recorded speech is extracted from one or more of: a movie, a television show, other publicly available audio video (AV) content, a publicly available audio recording.
11. The apparatus of claim 1, wherein the additional speech is output using text-to-speech software and text accessible to the at least one processor.
12. The apparatus of claim 1, comprising the at least one processor, and comprising at least one speaker through which the additional speech is output.
13. A method, comprising: analyzing, using a device, words spoken by a public figure; and based on the analysis, configuring a speech synthesizer to duplicate the public figure's voice for producing audio corresponding to text accessible to the device.
14. The method of claim 13, wherein the speech synthesizer uses a text-to-speech system duplicate the public figure's voice.
15. The method of claim 14, wherein the speech synthesizer is configured to employ a deep neural network (DNN) to produce the audio in the voice of the public figure, the DNN trained to the public figure's voice, the DNN establishing at least part of the text-to-speech system.
16. The method of claim 15, comprising: training the DNN using one or more audio recordings of the words spoken by the public figure and using text indicating the words spoken by the public figure.
17. The method of claim 13, comprising: producing the audio as a response to a user's query to a digital assistant.
18. An apparatus, comprising: at least one computer readable storage medium that is not a transitory signal, the at least one computer readable storage medium comprising instructions executable by at least one processor to: use a trained deep neural network (DNN) to produce a representation of a public figure's voice as speaking audio corresponding to first text that is either presented on an electronic display, second text from Closed Captioning, or that is to be used by a digital assistant as part of a response to a query, the trained DNN being trained using both audio of words spoken by the public figure and second text corresponding to the words, the first text being different from the second text.
19. The apparatus of claim 18, wherein the apparatus is embodied in a server, and wherein the server executes the instructions.
20. The apparatus of claim 18, wherein the apparatus is embodied as a consumer electronics device, and wherein the consumer electronic device comprises the electronics display.
</claims>
</document>
