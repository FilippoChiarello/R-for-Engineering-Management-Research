<document>

<filing_date>
2020-07-03
</filing_date>

<publication_date>
2021-01-06
</publication_date>

<priority_date>
2019-07-05
</priority_date>

<ipc_classes>
G06K9/00
</ipc_classes>

<assignee>
VAION
</assignee>

<inventors>
LANCIA, Samuel
</inventors>

<docdb_family_id>
67623323
</docdb_family_id>

<title>
COMPUTER-IMPLEMENTED METHOD
</title>

<abstract>
A computer-implemented method of identifying an object within a video stream from a camera, and determining the consistency with which the object is identified within plural temporally spaced video frames of the video stream. The method comprising: receiving a first video frame of the plural video frames at a first time; identifying an object within the first video frame, and labelling the object; storing the label of the object, together with the position of the object within the first video frame; receiving a second video frame of the plural video frames corresponding to a second time, temporally after the first time; identifying an object within the second video frame, and labelling the object, wherein the object in the second video frame is the same as the object in the first video frame; deriving a cumulative motion vector between the first video frame and the second video frame, using the position of the object in the first frame and the position of the object in the second frame; and determining a consistency with which the object in the first video frame and the object in the second video frame have been identified, using the derived cumulative motion vector.
</abstract>

<claims>
1. A computer-implemented method of identifying an object within a video stream from a camera, and determining the consistency with which the object is identified within plural temporally spaced video frames of the video stream, the method comprising: receiving a first video frame of the plural video frames at a first time; identifying an object within the first video frame, and labelling the object; storing the label of the object, together with the position of the object within the first video frame; receiving a second video frame of the plural video frames corresponding to a second time, temporally different from the first time; identifying an object within the second video frame, and labelling the object, wherein the object in the second video frame is the same as the object in the first video frame; deriving a motion vector between the first video frame and the second video frame, using the position of the object in the first frame and the position of the object in the second frame; and determining a consistency with which the object in the first video frame and the object in the second video frame have been identified, using the derived cumulative motion vector.
2. The computer-implemented method of claim 1, wherein identifying the object within the first and/or second video frame is performed via an object classifier algorithm.
3. The computer-implemented method of either claim 1 or claim 2, wherein the camera is a first camera, and the method further comprises the steps of: receiving a comparator video frame from a second video stream of a second camera, said second video stream having a field of view at least partially overlapping with a field of view of the video stream of the first camera, the comparator video frame corresponding to the first time; identifying an object within the comparator video frame; and determining whether the object present in the overlapping fields of view are consistently labelled between the first video frame and the comparator video frame.
4. The computer-implemented method of any preceding claim, including a step of storing one or both of the first video frame and the second video frame, with data indicative of the labelled object, when it is determined that the object has been identified consistently between the first video frame and the second video frame.
5. The computer-implemented method of any preceding claim, further comprising a step of storing one or both of the first video frame and the second video frame, with data indicative of the labelled object, when it is determined that a difference between the first video frame and the second video frame exceeds a threshold and when it has been determined that the object has been identified consistently between the first video frame and the second video frame.
6. The computer-implemented method of either of claims 4 or 5, wherein the method is repeated so as to build a training dataset formed of stored video frames.
7. A computer-implemented method of training a machine learning based object classifier, using the dataset according to the method of claim 6.
8. A system, including a processor, wherein the processor is configured to: receive a first video frame of a video stream, the video stream including plural temporally spaced video frames, the first video frame corresponding to a first time; identify an object within the first video frame, and label the object; store the label of the object, together with the position of the object within the first video frame; receive a second video frame of the plural video frames, corresponding to a second time, temporally different from the first time; identify an object within the second video frame, and label the object; derive a motion vector between the first video frame and the second video frame, using the position of the object in the first frame and the position of the object in the second frame; and determine a consistency with which the object in the first video frame and the object in the second video frame have been identified, using the derived cumulative motion vector.
9. The system of claim 8, wherein the processor is configured to identify the object within the first and/or second video frame via an object classifier algorithm.
10. The system of either of claims 8 or 9, wherein the camera is a first camera, and the system further includes a second camera, and the processor is configured to: receive a comparator video frame from a second video stream of the second camera, said second video stream having a field of view which at least partially overlaps with a field of view of the first video stream of the first camera, the comparator video frame corresponding to the first time; identify an object within the comparator video frame; and determine whether the object present in the overlapping fields of view are consistently labelled between the first video frame and the comparator video frame.
11. The system of any of claims 8 - 10, wherein the system includes a storage medium, and the processor is configured to store one or both of the first video frame and the second video frame in the storage medium, with data indicative of the labelled object, when the processor determines that the object has been identified consistently between the first video frame and the second video frame.
12. The system of any of claims 8 - 11, wherein the system includes a storage medium, and the processor is configured to store one or both of the first video frame and the second video frame in the storage medium, with data indicative of the labelled object, when the processor determines that a difference between the first video frame and the second video frame exceeds a threshold and when the processor determines that the object has been identified consistently between the first video frame and the second video frame.
13. The system of either of claims 11 or 12, wherein the processor is configured to repeat the steps so as to build a training dataset of stored video frames.
</claims>
</document>
