<document>

<filing_date>
2019-09-11
</filing_date>

<publication_date>
2020-11-12
</publication_date>

<priority_date>
2019-05-07
</priority_date>

<ipc_classes>
B60W50/06,G05B13/02,G06K9/00,G06N3/08,G06T7/20
</ipc_classes>

<assignee>
FORESIGHT AI
</assignee>

<inventors>
YUAN, CHANG
SIDDIQUI, MATHEEN
Lin, Cheng-Yi
</inventors>

<docdb_family_id>
73047062
</docdb_family_id>

<title>
DRIVING SCENARIO MACHINE LEARNING NETWORK AND DRIVING ENVIRONMENT SIMULATION
</title>

<abstract>
Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating a driving scenario machine learning network and providing a simulated driving environment. One of the operations is performed by receiving video data that includes multiple video frames depicting an aerial view of vehicles moving about an area. The video data is processed and driving scenario data is generated which includes information about the dynamic objects identified in the video. A machine learning network is trained using the generated driving scenario data. A 3-dimensional simulated environment is provided which is configured to allow an autonomous vehicle to interact with one or more of the dynamic objects.
</abstract>

<claims>
1. A system comprising one or more processors, and a non-transitory computer-readable medium including one or more sequences of instructions that, when executed by the one or more processors, cause the system to perform operations comprising: receiving video data, the video data comprising multiple video frames depicting an aerial view of vehicles moving about an area; generating driving scenario data based on the received video data, the driving scenario data comprising information about one or more dynamic objects; and training a machine learning network based on the generated driving scenario data.
2. The system of claim 1, wherein generating driving scenario data further comprises: identifying the one or more dynamic objects in two or more videos frames of the video; and determining a trajectory of the one or more identified dynamic objects and a velocity of the one or more identified dynamic objects.
3. The system of claim 1, wherein training the machine learning network further comprises: training the machine learning network to generate a control signal by evaluating the input signals of one or more of a local road network, a location of primary dynamic object, locations of secondary dynamic object, a trajectory of the primary dynamic object, and trajectories of the secondary dynamic object.
4. The system of claim 1, wherein training the machine learning network further comprises: determining a policy based on evaluating the motion of one or more dynamic objects from the generated driving scenario data.
5. The system of claim 1, wherein training the machine learning network further comprises: modifying the generated scenario data to change data values for one or more of a goal of a dynamic object, a location of a dynamic object, a local map characteristic, a trajectory of a dynamic object and a velocity of a dynamic object.
6. The system of claim 1, wherein training the machine learning network further comprises: training the machine learning network to generate one or more control signals of a predicted instantaneous velocity of a dynamic object, a predicted trajectory of a dynamic object and a predicted velocity of a dynamic object.
7. The system of claim 1, the operations further comprising: providing a 3-dimensional simulated environment configured for interaction of an autonomous vehicle with one or more of the dynamic objects.
8. The system of claim 7, the operations further comprising: rendering in the 3-dimensional simulated environment one or more dynamic objects as 3-dimensional bounding boxes or as 3-dimensional vehicles.
9. The system of claim 7, the operations further comprising: receiving a selection of a dynamic object to act as an autonomous self-driving vehicle.
10. The system of claim 7, the operations further comprising: generating simulated sensor data based on a sensor of the autonomous vehicle as to other dynamic objects in view of the simulated sensor.
11. The system of claim 7, wherein at least one dynamic object in the 3-dimensional environment moves in response to its proximity to the autonomous vehicle, the movement determined according to a policy of the machine learning network.
12. The system of claim 7, wherein at least one dynamic object in the 3-dimensional environment moves according to historical movement data for the at least one dynamic object from the generated driving scenario data.
13. The system of claim 7, the operations further comprising: determining a performance score of the autonomous vehicle based on one or more performance criteria.
14. A method implemented by a system comprising one or more processors, the method comprising: receiving video data, the video data comprising multiple video frames depicting an aerial view of vehicles moving about an area; generating driving scenario data based on the received video data, the driving scenario data comprising information about one or more dynamic objects; and training a machine learning network based on the generated driving scenario data.
15. The method of claim 14, wherein generating driving scenario data further comprises: identifying the one or more dynamic objects in two or more videos frames of the video; and determining a trajectory of the one or more identified dynamic objects and a velocity of the one or more identified dynamic objects.
16. The system of claim 14, wherein training the machine learning network further comprises: training the machine learning network to generate a control signal by evaluating the input signals of one or more of a local road network, a location of primary dynamic object, locations of secondary dynamic object, a trajectory of the primary dynamic object, and trajectories of the secondary dynamic object.
17. The method of claim 14, wherein training the machine learning network further comprises: determining a policy based on evaluating the motion of one or more dynamic objects from the generated driving scenario data.
18. The method of claim 14, wherein training the machine learning network further comprises: modifying the generated scenario data to change data values for one or more of a goal of a dynamic object, a location of a dynamic object, a local map characteristic, a trajectory of a dynamic object and a velocity of a dynamic object.
19. The method of claim 14, wherein training the machine learning network further comprises: training the machine learning network to generate one or more control signals of a predicted instantaneous velocity of a dynamic object, a predicted trajectory of a dynamic object and a predicted velocity of a dynamic object.
20. The method of claim 14, the operations further comprising: providing a 3-dimensional simulated environment configured for interaction of an autonomous vehicle with one or more of the dynamic objects.
21. The method of claim 20, the operations further comprising: rendering in the 3-dimensional simulated environment one or more dynamic objects as 3-dimensional bounding boxes or as 3-dimensional vehicles.
22. The method of claim 20, the operations further comprising: receiving a selection of a dynamic object to act as an autonomous self-driving vehicle.
23. The method of claim 20, the operations further comprising: generating simulated sensor data based on a simulated sensor of the autonomous vehicle as to other dynamic objects in view of the simulated sensor.
24. The method of claim 20, wherein at least one dynamic object in the 3-dimensional environment moves in response to its proximity to the autonomous vehicle, the movement determined according to a policy of the machine learning network.
25. The method of claim 20, wherein at least one dynamic object in the 3-dimensional environment moves according to historical movement data for the at least one dynamic object from the generated driving scenario data.
26. The method of claim 20, the operations further comprising: determining a performance score of the autonomous vehicle based on one or more performance criteria.
</claims>
</document>
