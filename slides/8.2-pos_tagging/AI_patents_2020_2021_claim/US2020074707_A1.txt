<document>

<filing_date>
2018-11-27
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2018-09-04
</priority_date>

<ipc_classes>
G06K9/62,G06K9/72,G06T11/60,G06T3/00,G06T7/30
</ipc_classes>

<assignee>
NVIDIA CORPORATION
</assignee>

<inventors>
GU, JINWEI
KAUTZ, JAN
LEE, DONGHOON
LIU, MING-YU
LIU, SIFEI
</inventors>

<docdb_family_id>
69639957
</docdb_family_id>

<title>
JOINT SYNTHESIS AND PLACEMENT OF OBJECTS IN SCENES
</title>

<abstract>
One embodiment of a method includes applying a first generator model to a semantic representation of an image to generate an affine transformation, where the affine transformation represents a bounding box associated with at least one region within the image. The method further includes applying a second generator model to the affine transformation and the semantic representation to generate a shape of an object. The method further includes inserting the object into the image based on the bounding box and the shape.
</abstract>

<claims>
1. A method, comprising: applying a first generator model to a semantic representation of an image to generate an affine transformation, wherein the affine transformation represents a bounding box associated with at least one region within the image; applying a second generator model to the affine transformation and the semantic representation to generate a shape of an object; and inserting the object into the image based on the bounding box and the shape.
2. The method of claim 1, further comprising: calculating one or more errors associated with the first generator model and the second generator model based on output from discriminator models associated with at least one of the first generator model and the second generator model; and updating parameters of at least one of the first generator model and the second generator model based on the one or more errors.
3. The method of claim 2, wherein updating the parameters comprises: executing an unsupervised path to update the parameters of the first generator model and the second generator model based on a first error in the one or more errors; and executing a supervised path comprising ground truths for the first generator model and the second generator model to update the parameters of the first and second generator models based on a second error in the one or more errors.
4. The method of claim 3, wherein the first error comprises an unsupervised adversarial loss that is calculated from a first discriminator model for at least one of the first and second generator models.
5. The method of claim 4, wherein the second error comprises a supervised adversarial loss that is calculated from a second discriminator model for at least one of the first and second generator models.
6. The method of claim 3, wherein the first error comprises a reconstruction loss associated with random input to at least one of the first and second generator models.
7. The method of claim 2, wherein a first discriminator model associated with the first generator model comprises a layout discriminator model that categorizes a location of the bounding box as real or fake or an affine discriminator model that categorizes the affine transformation as real or fake.
8. The method of claim 2, wherein a first discriminator model associated with the second generator model comprises a layout discriminator model that categorizes a location of the shape as real or fake or a shape discriminator model that categorizes the shape as real or fake.
9. The method of claim 1, wherein inserting the object into the image based on the bounding box and the shape comprises applying the affine transformation to the shape.
10. The method of claim 1, wherein each of the first generator model and the second generator model comprises at least one of a variational autoencoder (VAE) and a spatial transformer network.
11. A non-transitory computer readable medium storing instructions that, when executed by a processor, cause the processor to at least: apply a first generator model to a semantic representation of an image to generate an affine transformation, wherein the affine transformation represents a bounding box associated with at least one region within the image; apply a second generator model to the affine transformation and the semantic representation to generate a shape of an object; and insert the object into the image based on the bounding box and the shape.
12. The non-transitory computer readable medium of claim 11, further comprising program instructions to cause the processor to: calculate one or more errors associated with the first generator model and the second generator model based on output from discriminator models associated with at least one of the first generator model and the second generator model; and update parameters of at least one of the first generator model and the second generator model based on the one or more errors.
13. The non-transitory computer readable medium of claim 12, wherein updating the parameters comprises: executing an unsupervised path to update the parameters of the first generator model and the second generator model based on a first error in the one or more errors; and executing a supervised path comprising ground truths for the first generator model and the second generator model to update the parameters of the first and second generator models based on a second error in the one or more errors.
14. The non-transitory computer readable medium of claim 13, wherein the first and second errors comprise at least one of an unsupervised adversarial loss that is calculated from a first discriminator model, a supervised adversarial loss that is calculated from a second discriminator model, and a reconstruction loss associated with random input to at least one of the first generator model and the second generator model.
15. The non-transitory computer readable medium of claim 12, wherein the discriminator models comprise a layout discriminator model that categorizes a location of the bounding box as real or fake, an affine discriminator model that categorizes the affine transformation as real or fake, a layout discriminator model that categorizes a location of the shape as real or fake, and a shape discriminator model that categorizes the shape as real or fake.
16. A system, comprising: a memory storing one or more instructions; and a processor that executes the instructions to at least: apply a first generator model to a semantic representation of an image to generate an affine transformation, wherein the affine transformation represents a bounding box associated with at least one region within the image; apply a second generator model to the affine transformation and the semantic representation to generate a shape of an object; and insert the object into the image based on the bounding box and the shape.
17. The system of claim 16, wherein the processor executes the instructions to: calculate one or more errors associated with the first generator model and the second generator model based on output from discriminator models associated with at least one of the first generator model and the second generator model; and update parameters of at least one of the first generator model and the second generator model based on the one or more errors in the one or more errors.
18. The system of claim 17, wherein updating the parameters comprises: executing an unsupervised path to update the parameters of the first generator model and the second generator model based on a first error in the one or more errors; and executing a supervised path comprising ground truths for the first generator model and the second generator model to update the parameters of the first and second generator models based on a second error.
19. The system of claim 18, wherein the first and second errors comprise at least one of an unsupervised adversarial loss that is calculated from a first discriminator model, a supervised adversarial loss that is calculated from a second discriminator model, and a reconstruction loss associated with random input to at least one of the first generator model and the second generator model.
20. The system of claim 16, wherein inserting the object into the image based on the bounding box and the shape comprises applying the affine transformation to the shape.
</claims>
</document>
