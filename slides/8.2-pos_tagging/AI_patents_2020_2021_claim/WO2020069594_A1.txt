<document>

<filing_date>
2019-08-13
</filing_date>

<publication_date>
2020-04-09
</publication_date>

<priority_date>
2018-10-03
</priority_date>

<ipc_classes>
H04N21/2368,H04N21/80,H04N5/04
</ipc_classes>

<assignee>
VIDEOLOCALIZE
</assignee>

<inventors>
ZHAO, JIE
</inventors>

<docdb_family_id>
70054957
</docdb_family_id>

<title>
PIECEWISE HYBRID VIDEO AND AUDIO SYNCHRONIZATION
</title>

<abstract>
The present disclosure provides a method and apparatus for automatically synchronizing a first stream of media data with a second, and outputting a third by decoding the streams into channels, splitting the channels into a plurality of piecewise segments defined by control points that the control points with the same index are to be synchronized in time across all the channels, automatically and intelligently adjusting the length of the media data in each segment in an optimal and hybrid manner using a linear or non-linear digital signal processing algorithm, synchronizing and mixing all the processed segments, and outputting the final mixed and encoded data stream. Specifically, one of the media data is video and the other is audio or a translation voice in a different language. With a controlled minimized distortion, one can achieve faster post-processing speed and optimal synchronization quality, therefore save both time and cost for video language localization services.
</abstract>

<claims>
1. A method of generating synchronized media from digital input data with a number of channels, comprising:
determining a same number of thresholds, one for each of the channels;
identifying a plurality of control points indexed in chronological order, excluding the beginning point, within each channel, wherein the content at a control point within a channel is to be synchronized with the content at the control point with the same index within each of the other channels based on the data content;
using each channel's control points to partition it into a same plurality of piecewise segments so that each segment starts and ends at a control point except for the first segment, which starts at the beginning point and ends at the first control point; applying a first algorithm to determine a same plurality of target lengths, one for all segments with the same index across all channels, as well as a set of parameters for each segmen - applying a second algorithm to modify the data of each segment to match the target length, using the segment's set of parameters;
regenerating each channel by joining the modified segments in order;
wherein the content at each control point within any channel occurs at the same time as that across all other channels during media playback;
wherein the content anywhere within all channels is perceived to be synchronized; wherein the perceived quality difference between the modified and input channels is within the threshold.
2. The method of claim 1, wherein the first algorithm is based on a method with machine learning, artificial intelligence prediction model, and neural networks, or a solution to an optimization problem.
3. The method of claim 1, wherein the second algorithm is a linear or non-linear media data conversion method.
4. The method of claim 1, wherein the input data are decoded from a media stream file, and the generated media data are encoded into another media stream file.
5. The method of claim 1, wherein the full processing is automatic.
6. The method of claim 1, wherein at least one of the generated channels is from mixing at least two synchronized channels.
7. The method of claim 1, wherein the control points are searched for and identified by human selection, clapboard, or other AV interactive methods.
8. The method of claim 1, wherein one of the channels is a video, and another channel is audio.
9. The method of claim 8, wherein the second algorithm includes interpolating,
decimating, or resampling frames for video, and changing samples' pitch, tempo, or speed for audio.
10. The method of claim 8, wherein the video is unchanged, and the audio is modified to match the video in time.
11. The method of claim 8, wherein the audio is unchanged, and the video is modified to match the audio in time.
12. The method of claim 8, wherein both the video and audio are modified to match a different length in time.
13. The method of claim 8, wherein at least one video segment is modified to match an audio segment, and at least one audio segment is modified to match a video segment.
14. The method of claim 1, wherein there is at least one segment that cannot be
synchronized within the threshold, so truncation is applied if the original length is longer than the target length or the blank is filled if the original length is shorter than the target length.
15. An apparatus for automatically synchronizing at least a first stream of media data with a second and outputting a third, comprising:
a decoder that decodes a video channel and a first audio channel from the first stream of media data and a second audio channel from the second stream of media data; a control module that stores settings and parameters and determines thresholds;
a processor that identifies at least a first and second control point within each of three channels, which are the video, first audio, and second audio channels;
wherein all the first control points are to be synchronized in time across all the channels; so are all the second control points;
wherein the processor partitions each of the three channels into at least a first and
second piecewise segment, wherein the first segment starts at the channel's beginning point and ends at the channel's first control point; the second segment starts at the channel's first control point and ends at the channel's second control point; wherein the processor uses an algorithm to determine a first target length for all the first segments across all channels; and a second target length for all the second segments across all channels; as well as a set of parameters for each of the segments;
a video processor that modifies each video segment to match the target length with the set of parameters and settings, joins all segments, and generates a processed video channel;
an audio processor that modifies each audio segment to match the target length with the set of parameters and settings, joins all segments, and mixes the synchronized first and second audio channels into a processed audio channel;
an encoder encodes the processed video and audio channels into the third stream of media data.
wherein the content at each control point within any channel occurs at the same time as that across all other channels during media playback;
wherein the content anywhere within all channels is perceived to be synchronized; wherein the perceived quality difference between the modified and original channels is within the threshold.
16. The apparatus of claim 15, wherein the algorithm is based on a machine-learning and artificial-intelligence prediction model or network.
17. The apparatus of claim 15, wherein the control points are searched for and identified by manual or automatic digital signal processing.
18. The apparatus of claim 15, wherein the video processor uses a linear or non-linear method of interpolating, decimating, or resampling frames and the audio processor uses a linear or non-linear method of changing samples' pitch, tempo, or speed.
19. The apparatus of claim 15, wherein the first audio channel is void.
20. The apparatus of claim 15, wherein at least one segment cannot be synchronized within the threshold, so truncation is applied if the original length is longer than the target length, or the blank is filled if the original length is shorter than the target length.
</claims>
</document>
