<document>

<filing_date>
2019-01-02
</filing_date>

<publication_date>
2021-01-28
</publication_date>

<priority_date>
2018-02-23
</priority_date>

<ipc_classes>
G10L17/18,G10L17/22
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
CHOI, HYUNGTAK
HWANG, INCHUL
KIM, HONGCHUL
KIM, JIHIE
KO, HYEONMOK
</inventors>

<docdb_family_id>
67687635
</docdb_family_id>

<title>
ELECTRONIC DEVICE AND CONTROL METHOD THEREOF
</title>

<abstract>
Disclosed is an electronic device. The electronic device comprises: a microphone comprising circuitry; a speaker comprising circuitry; and a processor electrically connected to the microphone and speaker, wherein the processor, when a first user's voice is input through the microphone, identifies a user who uttered the first user's voice and provides a first response sound, which is obtained by inputting the first user's voice to an artificial intelligence model learned through an artificial intelligence algorithm, through the speaker, and when a second user's voice is input through the microphone, identifies a user who uttered the second user's voice, and if the user who uttered the first user's voice is the same as the user who uttered the second user's voice, provides a second response sound, which is obtained by inputting the second user's voice and utterance history information to the artificial intelligence model, through the speaker. In particular, at least some of the methods of providing a response sound to a user's voice may use an artificial intelligence model learned in accordance with at least one of a machine learning, neural network, or deep learning algorithm.
</abstract>

<claims>
1. An electronic device comprising: a microphone comprising circuitry; a speaker comprising circuitry; and a processor electrically connected to the microphone and the speaker, wherein the processor is configured to: based on a first user's voice being input via the microphone, identify a user who uttered the first user's voice and provide a first response sound obtained by inputting the first user's voice to an artificial intelligence model trained through an artificial intelligence algorithm via the speaker, and based on a second user's voice being input via the microphone, identify a user who uttered the second user's voice, and based on the user who uttered the first user's voice being the same as the user who uttered the second user's voice, provide a second response sound obtained by inputting the second user's voice and utterance history information to the artificial intelligence model via the speaker.
2. The device according to claim 1, further comprising: a storage comprising circuitry, wherein the processor is configured to: based on the user who uttered the second user's voice being different from the user who uttered the first user's voice, store the second user's voice in the storage, and based on a user's voice not being input from the user who uttered the first user's voice for a predetermined period of time or longer, provide a third response sound obtained by inputting the second user's voice to the artificial intelligence model via the speaker.
3. The device according to claim 1, wherein the processor is further configured to: based on the first user's voice being input, identify a first user who uttered the first user's voice and provide the first response sound obtained by inputting the first user's voice to the artificial intelligence model via the speaker, and based on the second user's voice being input, identify a second user who uttered the second user's voice and provide a third response sound obtained by inputting the second user's voice to the artificial intelligence model via the speaker to be distinct from the first response sound.
4. The device according to claim 3, wherein the processor is further configured to: based on a first additional user's voice being input by the first user, provide a first additional response sound obtained by inputting the first additional user's voice and first utterance history information corresponding to the first user's voice to the artificial intelligence model via the speaker, and based on a second additional user's voice being input by the second user, provide a second additional response sound obtained by inputting the second additional user's voice and second utterance history information corresponding to the second user's voice to the artificial intelligence model via the speaker to be distinct from the first additional response sound.
5. The device according to claim 4, further comprising: a display electrically connected to the processor, wherein the processor is further configured to: control the display to display a first UI corresponding to the first user while providing the first additional response sound, and control the display to display a second UI corresponding to the second user via the display while providing the second additional response sound.
6. The device according to claim 1, wherein the processor is further configured to: based on the user who uttered the first user's voice being different from the user who uttered the second user's voice, obtain a first domain corresponding to the first user's voice and a second domain corresponding to the second user's voice, and based on the first domain being the same as the second domain, provide the second response sound obtained by inputting the second user's voice and the utterance history information to the artificial intelligence model via the speaker.
7. The device according to claim 1, further comprising: a storage electrically connected to the processor, wherein the processor is further configured to: based on the second user's voice being input within a first predetermined period of time from a point when the first user's voice is input, the user who uttered the first user's voice being the same as the user who uttered the second user's voice, and a first domain corresponding to the first user's voice being different from a second domain corresponding to the second user's voice, store the first user's voice in the storage without providing the first response sound, and provide a third response sound obtained by inputting the second user's voice to the artificial intelligence model via the speaker.
8. The device according to claim 7, wherein the processor is further configured to, based on a user's voice corresponding to the second domain not being input from the user for a second predetermined period of time or longer, provide the first response sound obtained by inputting the first user's voice stored in the storage to the artificial intelligence model via the speaker.
9. The device according to claim 1, further comprising: a camera comprising circuitry, wherein the processor is further configured to identify the user based on at least one of an image captured by the camera or a user's voice input via the microphone.
10. The device according to claim 9, wherein the processor is further configured to: identify the user who uttered the first user's voice based on a shape of mouth of a user included in the image for a period of time during which the first user's voice is input, and based on the shape of mouth of the identified user included in the image being changed for a period of time during which the second user's voice is input, identify the user who uttered the second user's voice to be the same as the user who uttered the first user's voice.
11. A method for controlling an electronic device, the method comprising: based on a first user's voice being input, identifying a user who uttered the first user's voice; providing a first response sound obtained by inputting the first user's voice to an artificial intelligence model trained through an artificial intelligence algorithm; based on a second user's voice being input, identifying a user who uttered the second user's voice; and based on the user who uttered the first user's voice being the same as the user who uttered the second user's voice, providing a second response sound obtained by inputting the second user's voice and utterance history information to the artificial intelligence model.
12. The method according to claim 11, further comprising: based on the user who uttered the second user's voice being different from the user who uttered the first user's voice, storing the second user's voice; and based on a user's voice not being input from the user who uttered the first user's voice for a predetermined period of time or longer, providing a third response sound obtained by inputting the second user's voice to the artificial intelligence model.
13. The method according to claim 11, wherein the identifying a user who uttered the first user's voice comprises, based on the first user's voice being input, identifying a first user who uttered the first user's voice, wherein the providing a first response sound comprises providing the first response sound obtained by inputting the first user's voice to the artificial intelligence model, wherein the identifying a user who uttered the second user's voice comprises identifying a second user who uttered the second user's voice, and wherein the method further comprises providing a third response sound obtained by inputting the second user's voice to the artificial intelligence model to be distinct from the first response sound.
14. The method according to claim 13, further comprising: based on a first additional user's voice being input by the first user, providing a first additional response sound obtained by inputting the first additional user's voice and first utterance history information corresponding to the first user's voice to the artificial intelligence model; and based on a second additional user's voice being input by the second user, providing a second additional response sound obtained by inputting the second additional user's voice and second utterance history information corresponding to the second user's voice to the artificial intelligence model to be distinct from the first additional response sound.
15. The method according to claim 14, wherein the providing a first additional response sound comprises a first UI corresponding to the first user while providing the first additional response sound, and wherein the providing a second additional response sound to be distinct from the first additional response sound comprises displaying a second UI corresponding to the second user while providing the second additional response sound.
</claims>
</document>
