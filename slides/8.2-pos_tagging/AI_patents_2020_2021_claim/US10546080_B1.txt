<document>

<filing_date>
2018-12-27
</filing_date>

<publication_date>
2020-01-28
</publication_date>

<priority_date>
2018-12-27
</priority_date>

<ipc_classes>
G06F11/26,G06N20/00
</ipc_classes>

<assignee>
CADENCE DESIGN SYSTEMS
</assignee>

<inventors>
ASHKENAZI, YONATAN
TABAKMAN, TAL
CHAZAN, NADAV
GIL, YOTAM
HADAYA, NIR
</inventors>

<docdb_family_id>
69179987
</docdb_family_id>

<title>
Method and system for identifying potential causes of failure in simulation runs using machine learning
</title>

<abstract>
A method for identifying a potential cause of a failure in simulation runs on a design under test (DUT) using machine learning is disclosed.
</abstract>

<claims>
1. A method for identifying a potential cause of a failure in simulation runs on a design under test (DUT), the method comprising: using a processor, analyzing each of a plurality of recorded failed simulation runs of verification tests, starting from a suspected error, constructing a tree of causes for that suspected error, down to one or a plurality of points of entry HDL signals; using a processor, based on driver tracing, and on a tree of causes for each of said one or a plurality of points of entry HDL signals, collecting signals that have contributed to a value of each of said one or a plurality of points of entry HDL signals, at a time said one or a plurality of points of entry HDL signals had affected the suspected error; using a processor, analyzing each of a plurality of recorded successfully passed simulation runs of verification tests, choosing randomly a value of each of said one or a plurality of points of entry HDL signals and based on driver tracing and on a tree of causes, collecting signals that have contributed to said value; using a processor, extracting features from said collected signals; using a processor, training a machine learning algorithm to distinguish between failed and successfully passed runs based on the extracted features and using results of the training process to identify one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed run; using a processor, causing the identified one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed run to be output on an output device.
2. The method of claim 1, wherein the suspected error is indicated by an error message.
3. The method of claim 1, wherein the output device is a display device.
4. The method of claim 1, wherein the features are selected from the group consisting of values of single bit signals, entire bus values, separate bits of bus values and driver source code line numbers.
5. The method of claim 4, wherein zero or a predetermined value are excluded from the randomly chosen value of each of said one or a plurality of points of entry HDL signals.
6. The method of claim 1, wherein a depth of the driver tracing is defined by a user.
7. The method of claim 1, further comprising validating the applied machine learning on a set of withheld successfully passed or failed recorded simulation runs.
8. The method of claim 7, wherein causing the identified one or a plurality of features of said extracted features that were found significant in predicting a failed run or a successfully passed run to be output on an output device is performed only if said one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed runs were validated on the set of withheld passed or failed recorded simulation runs.
9. A system for identifying a potential cause for a failure in simulation runs on a design under test (DUT), the system comprising: a memory, and a processor configured to: analyze each of a plurality of recorded failed simulation runs of verification tests, starting from a suspected error, constructing a tree of causes for that suspected error, down to one or a plurality of points of entry HDL signals; based on driver tracing and on a tree of causes for each of said one or a plurality of points of entry HDL signals, collect signals that have contributed to a value of each of said one or a plurality of points of entry HDL signals, at a time said one or a plurality of points of entry HDL signals had affected the suspected error; analyze each of a plurality of recorded successfully passed simulation runs of verification tests, choosing randomly a value of each of said one or a plurality of points of entry HDL signals and, based on driver tracing and on a tree of causes, collect signals that have contributed to said value; extract features from said collected signals; train a machine learning algorithm to distinguish between failed and successfully passed runs based on the extracted features, and use results of the training process to identify one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed run; and cause the identified one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed run to be output on an output device.
10. The system of claim 9, wherein the suspected error is indicated by an error message.
11. The system of claim 9, wherein the output device is a display device.
12. The system of claim 9, wherein the features are selected from the group consisting of values of single bit signals, entire bus values, separate bits of bus values and driver source code line numbers.
13. The system of claim 12, wherein zero or a predetermined value are excluded from the randomly chosen value of each of said one or a plurality of points of entry HDL signals.
14. The system of claim 9, wherein a depth of the driver tracing is defined by a user.
15. The system of claim 9, wherein the processor is further configured to validate the applied machine learning on a set of withheld successfully passed or failed recorded simulation runs.
16. The system of claim 15, wherein the processor is configured to cause the identified one or a plurality of features of said extracted features that were found significant in predicting a failed run or a successfully passed run to be output on an output device only if said one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed runs were validated on the set of withheld passed or failed recorded simulation runs.
17. A non-transitory computer readable storage medium for identifying a potential cause for a failure in simulation runs on a design under test (DUT), having stored thereon instructions that when executed by a processor will cause the processor to: analyze each of a plurality of recorded failed simulation runs of verification tests, starting from a suspected error, constructing a tree of causes for that suspected error, down to one or a plurality of points of entry HDL signals; based on driver tracing and on a tree of causes for each of said one or a plurality of points of entry HDL signals, collect signals that have contributed to a value of each of said one or a plurality of points of entry HDL signals, at a time said one or a plurality of points of entry HDL signals had affected the suspected error; analyze each of a plurality of recorded successfully passed simulation runs of verification tests, choosing randomly a value of each of said one or a plurality of points of entry HDL signals and, based on driver tracing and on a tree of causes, collect signals that have contributed to said value; extract features from said collected signals; train a machine learning algorithm to distinguish between failed and successfully passed runs based on the extracted features and use results of the training process to identify one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed run; and cause the identified one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed run to be output on an output device.
18. The non-transitory computer readable storage medium of claim 17, wherein the suspected error is indicated by an error message.
19. The non-transitory computer readable storage medium of claim 17, having stored thereon instructions that when executed by a processor will cause the processor to validate the applied machine learning on a set of withheld successfully passed or failed recorded simulation runs.
20. The non-transitory computer readable storage medium of claim 19, having stored thereon instructions that, when executed by a processor, will cause the processor to cause the identified one or a plurality of features of said extracted features that were found significant in predicting a failed run or a successfully passed run to be output on an output device to be performed only if said one or a plurality of features of said extracted features that are significant in predicting a failed run or a successfully passed runs were validated on the set of withheld passed or failed recorded simulation runs.
</claims>
</document>
