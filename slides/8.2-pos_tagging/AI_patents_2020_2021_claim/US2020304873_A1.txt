<document>

<filing_date>
2020-06-04
</filing_date>

<publication_date>
2020-09-24
</publication_date>

<priority_date>
2018-12-20
</priority_date>

<ipc_classes>
G06N3/08,H04N21/466
</ipc_classes>

<assignee>
ROVI GUIDES
</assignee>

<inventors>
MILLER, KYLE
</inventors>

<docdb_family_id>
69187968
</docdb_family_id>

<title>
DEEP REINFORCEMENT LEARNING FOR PERSONALIZED SCREEN CONTENT OPTIMIZATION
</title>

<abstract>
Systems and methods are described for selecting content item identifiers for display. The system may identify a set of content items that are likely to be requested in the future based on a history of content item requests. The system then selects a first plurality of content categories using a category selection neural net and selects a first set of recommended content items for the first plurality of content categories. The system increases a reward score for the first plurality of content categories based on receiving a request for a content item that is included in the first set of recommended content items. The system also decreases the reward score for the first plurality of content categories based on determining that the requested content item is included in the set of content items that are likely to be requested in the future. The neural net is trained based on the reward score of the first plurality of content categories to reinforce reward score maximization. The trained neural net is the used to select content items for display.
</abstract>

<claims>
1. 1.-50. (canceled)
51. A method for selecting content item identifiers for display, the method comprising: identifying, based on history of content item requests, a set of content items, wherein each content item in the set of content items is likely to be requested by a user in the future without having previously been recommended; generating for display a first set of recommended content items that were selected for a first plurality of content categories using a category selection model; based on receiving a request for a content item that is included in the first set of recommended content items, increasing a reward score for the first plurality of content categories; based on determining that the requested content item is included in the set of content items that are likely to be requested in the future, decreasing the reward score for the first plurality of content categories, wherein each content item in the set of content items is likely to be requested in the future without having previously been recommended; modifying the category selection model based on the reward score; and generating for display a second set of recommended content items that were selected for a second plurality of content categories using a modified category selection model.
52. The method of claim 51, further comprising, in response to determining that the first plurality of content categories comprises a first category and second category that is related to the first category, decreasing the reward score for the first plurality of content categories.
53. The method of claim 51, further comprising: receiving another request for a further content item that is included in the first set of recommended content items; and based on determining that the requested content item and the further requested content item belong to different content categories, increasing a reward score for the first plurality of content categories.
54. The method of claim 51, wherein the neural net comprises a plurality of neurons connecting a plurality of features with a superset of content categories; and wherein training the category selection neural net based on the reward score of the first plurality of content categories comprises adjusting connections between the plurality of neurons.
55. The method of claim 54, wherein the plurality of features comprises at least two of: content item requests data, content category requests data, time data, and collaborative filtering vectors.
56. The method of claim 54, further comprising reducing the plurality of features by performing principal component analysis.
57. The method of claim 54, wherein training the category selection neural net comprises: adjusting the neural net by using a deep deterministic policy gradients technique to reinforce reward score maximization.
58. The method of claim 51, further comprising: modifying the first set of recommended content items to remove at least one content item that also belongs to the set of content items that are likely to be requested in the future.
59. The method of claim 51, wherein identifying the set of content items that are likely to be requested in the future comprises: making an API call to a prediction engine; and receiving an identification of the set of content items that are likely to be requested in the future from the prediction engine.
60. The method of claim 51, wherein selecting a first set of recommended content items comprises: making an API call to a recommendation engine; and receiving an identification of the first set of content items from the recommendation engine.
61. A system for selecting content item identifiers for display, the system comprising: control circuitry configured to: identify, based on history of content item requests, a set of content items, wherein each content item in the set of content items is likely to be requested by a user in the future without having previously been recommended; generate for display a first set of recommended content items that were selected for a first plurality of content categories using a category selection model; based on receiving a request for a content item that is included in the first set of recommended content items, increase a reward score for the first plurality of content categories; based on determining that the requested content item is included in the set of content items that are likely to be requested in the future, decrease the reward score for the first plurality of content categories, wherein each content item in the set of content items is likely to be requested in the future without having previously been recommended; modify the category selection model based on the reward score; and a display generation circuitry configured to: generate for display a second set of recommended content items that were selected for a second plurality of content categories using a modified category selection model.
62. The system of claim 61, wherein the control circuitry is further configured to, in response to determining that the first plurality of content categories comprises a first category and second category that is related to the first category, decrease the reward score for the first plurality of content categories.
63. The system of claim 61, wherein the control circuitry is further configured to: receive another request for a further content item that is included in the first set of recommended content items; and based on determining that the requested content item and the further requested content item belong to different content categories, increase a reward score for the first plurality of content categories.
64. The system of claim 61, wherein the neural net comprises a plurality of neurons connecting a plurality of features with a superset of content categories; and wherein the control circuitry is further configured, when training the category selection neural net based on the reward score of the first plurality of content categories, to adjust connections between the plurality of neurons.
65. The system of claim 64, wherein the plurality of features comprises at least two of: content item requests data, content category requests data, time data, and collaborative filtering vectors.
66. The system of claim 64, wherein the control circuitry is further configured to reduce the plurality of features by performing principal component analysis.
67. The system of claim 64, wherein the control circuitry is further configured, when training the category selection neural net, to: adjust the neural net by using a deep deterministic policy gradients technique to reinforce reward score maximization.
68. The system of claim 61, wherein the control circuitry is further configured to: modify the first set of recommended content items to remove at least one content item that also belongs to the set of content items that are likely to be requested in the future.
69. The system of claim 61, wherein the control circuitry is further configured to, when identifying the set of content items that are likely to be requested in the future, to: make an API call to a prediction engine; and receive an identification of the set of content items that are likely to be requested in the future from the prediction engine.
70. The system of claim 61, wherein the control circuitry is further configured, when selecting a first set of recommended content items, to: make an API call to a recommendation engine; and receive an identification of the first set of content items from the recommendation engine.
</claims>
</document>
