<document>

<filing_date>
2020-01-10
</filing_date>

<publication_date>
2020-10-06
</publication_date>

<priority_date>
2019-01-31
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N3/04,G06N3/08
</ipc_classes>

<assignee>
STRADVISION
</assignee>

<inventors>
LEE, HYUNG SOO
SHIN, DONGSOO
KIM, HAK-KYOUNG
CHO, HOJIN
NAM, WOONHYUN
YEO, DONGHUN
KIM, YONGJOONG
RYU, WOOJU
BOO, SUKHOON
JE, HONGMO
SUNG, MYUNGCHUL
JANG, TAEWOONG
JEONG, KYUNGJOONG
KIM, KYE-HYEON
LEE, MYEONG-CHUN
</inventors>

<docdb_family_id>
69191878
</docdb_family_id>

<title>
Method for integrating driving images acquired from vehicles performing cooperative driving and driving image integrating device using same
</title>

<abstract>
A method for integrating images from vehicles performing a cooperative driving is provided. The method includes steps of: a main driving image integrating device on one main vehicle (a) inputting one main driving image into a main object detector to (1) generate one main feature map by applying convolution operation via a main convolutional layer, (2) generate main ROIs via a main region proposal network, (3) generate main pooled feature maps by applying pooling operation via a main pooling layer, and (4) generate main object detection information on the main objects by applying fully-connected operation via a main fully connected layer; (b) inputting the main pooled feature maps into a main confidence network to generate main confidences; and (c) acquiring sub-object detection information and sub-confidences from sub-vehicles, and integrating the main object detection information and the sub-object detection information using the main & the sub-confidences to generate object detection result.
</abstract>

<claims>
1. A method for integrating driving images acquired from one or more vehicles performing a cooperative driving, comprising steps of: (a) a main driving image integrating device, installed on at least one main vehicle among said one or more vehicles, performing (i) a process of inputting at least one main driving image, acquired from at least one main camera installed on the main vehicle, into a main object detector, to thereby allow the main object detector to (i-1) generate at least one main feature map by applying at least one convolution operation to the main driving image via a main convolutional layer, (i-2) generate one or more main ROIs (Regions Of Interest), corresponding to one or more regions where one or more main objects are estimated as located, on the main feature map, via a main region proposal network, (i-3) generate one or more main pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to the main ROIs, on the main feature map, via a main pooling layer, and (i-4) generate multiple pieces of main object detection information on the main objects located on the main driving image by applying at least one fully-connected operation to the main pooled feature maps via a main fully connected layer; (b) the main driving image integrating device performing a process of inputting the main pooled feature maps into a main confidence network, to thereby allow the main confidence network to generate each of one or more main confidences of each of the main ROIs corresponding to each of the main pooled feature maps; and (c) the main driving image integrating device performing a process of acquiring multiple pieces of sub-object detection information and one or more sub-confidences from each of one or more sub-vehicles in the cooperative driving, and a process of integrating the multiple pieces of the main object detection information and the multiple pieces of the sub-object detection information by using the main confidences and the sub-confidences as weights, to thereby generate at least one object detection result of the main driving image, wherein the multiple pieces of the sub-object detection information and the sub confidences are generated by each of one or more sub-driving image integrating devices, installed on each of the sub-vehicles, wherein each of the sub-driving image integrating devices performs (i) a process of inputting each of sub-driving images into corresponding each of sub-object detectors, to thereby allow said each of the sub-object detectors to (i-1) generate each of sub-feature maps by applying at least one convolution operation to each of the sub-driving images via corresponding each of sub-convolutional layers, (i-2) generate one or more sub-ROIs, corresponding to one or more regions where one or more sub-objects are estimated as located, on each of the sub-feature maps, via corresponding each of sub-region proposal networks, (i-3) generate each of one or more sub pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to each of the sub-ROIs, on each of the sub-feature maps, via corresponding each of sub-pooling layers, (i-4) generate the multiple pieces of the sub-object detection information on the sub-objects located on each of the sub-driving images by applying at least one fully connected operation to each of the sub-pooled feature maps via corresponding each of sub fully connected layers, and (i-5) input each of the sub-pooled feature maps into corresponding each of sub-confidence networks, to thereby allow each of the sub-confidence networks to generate the sub-confidences of the sub-ROIs corresponding to each of the sub pooled feature maps, wherein the main object detector and the main confidence network have been learned by a learning device, wherein the learning device has learned the main object detector by performing, if training data including one or more driving images for training are acquired, (i) a process of sampling (i-1) 1-st training data including a (1_1)-st driving image for training to a (1_m)-th driving image for training wherein m is an integer larger than 0 and (i-2) 2-nd training data including a (2_1)-st driving image for training to a (2_n)-th driving image for training wherein n is an integer larger than 0, from the training data, (ii) a process of inputting a (1 _j)-th driving image for training, among the (1_1)-st driving image for training to the (1_m)-th driving image for training, into the main convolutional layer, to thereby allow the main convolutional layer to generate at least one 1-st feature map by applying at least one convolution operation to the (1 _j) th driving image for training, (iii) a process of inputting the 1-st feature map into the main region proposal network, to thereby allow the main region proposal network to generate one or more 1-st ROIs, corresponding to one or more objects for training, on the 1-st feature map, (iv) a process of instructing the main pooling layer to generate one or more 1-st pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to the 1-st ROIs, on the 1-st feature map, (v) a process of instructing the main fully connected layer to generate multiple pieces of 1-st object detection information corresponding to the objects for training located on the (1 _j)-th driving image for training by applying at least one fully-connected operation to the 1-st pooled feature maps or at least one 1-st feature vector corresponding to the 1-st pooled feature maps, (vi) a process of instructing a 1-st loss layer to calculate one or more 1 st losses by referring to the multiple pieces of the 1-st object detection information and at least one object ground truth of the (1 _j)-th driving image for training, and (vii) a process of updating at least one parameter of the main fully connected layer and the main convolutional layer via backpropagation using the 1-st losses such that the 1-st losses are minimized, for each of the (1_1)-st driving image for training to the (1 _m)-th driving image for training, and wherein the learning device has learned the main confidence network by performing (i) a process of acquiring each of one or more 1-st confidences of each of the 1-st ROIs by referring to the object ground truth and the multiple pieces of the 1-st object detection information corresponding to each of the (1_1)-st driving image for training to the (1 _m)-th driving image for training, (ii) a process of inputting a (2 _k)-th driving image for training, among the (2_1)-st driving image for training to the (2 _n)-th driving image for training, into the main convolutional layer, to thereby allow the main convolutional layer to generate at least one 2-nd feature map by applying at least one convolution operation to the (2 _k)-th driving image for training, (iii) a process of inputting the 2-nd feature map into the main region proposal network, to thereby allow the main region proposal network to generate one or more 2-nd ROIs corresponding to the objects for training located on the 2-nd feature map, (iv) a process of instructing the main pooling layer to generate one or more 2-nd pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to the 2-nd ROIs, on the 2-nd feature map, (v) a process of inputting the 2-nd pooled feature maps into the main confidence network, to thereby allow the main confidence network to generate one or more 2-nd confidences corresponding to the 2-nd pooled feature maps through deep learning, (vi) a process of instructing a 2-nd loss layer to calculate one or more 2-nd losses by referring to the 2-nd confidences and the 1-st confidences, and (vii) a process of updating at least one parameter of the main confidence network via backpropagation using the 2-nd losses such that the 2-nd losses are minimized, for each of the (2_1)-st driving image for training to the (2 _n)-th driving image for training.
2. The method of claim 1, wherein the learning device acquires the 1-st confidences of each of the 1-st ROIs by referring to the multiple pieces of the 1-st object detection information and their object ground truths, wherein each of the 1-st confidences is 0 if each of the objects for training is absent in each of the 1-st ROIs, and each of the 1-st confidences is 1-box_error×class_error if said each of the objects for training is present in said each of the 1-st ROIs, and wherein each box_error is each error of bounding boxes included in the multiple pieces of the 1-st object detection information, and each class_error is each error of class information included in the multiple pieces of the 1-st object detection information.
3. The method of claim 2, wherein (i) said each box_error is each ratio of (i 1) each size of each of the objects for training to (i-2) a summation of errors of each of center points of the bounding boxes, and (ii) said each class_error is each summation of class errors of each estimation value on each class, to be used for classifying each of the objects for training, included in the multiple pieces of the 1-st object detection information.
4. A method for integrating driving images acquired from one or more vehicles performing a cooperative driving, comprising steps of: (a) a main driving image integrating device, installed on at least one main vehicle among said one or more vehicles, performing (i) a process of inputting at least one main driving image, acquired from at least one main camera installed on the main vehicle, into a main object detector, to thereby allow the main object detector to (i-1) generate at least one main feature map by applying at least one convolution operation to the main driving image via a main convolutional layer, (i-2) generate one or more main ROIs (Regions Of Interest), corresponding to one or more regions where one or more main objects are estimated as located, on the main feature map, via a main region proposal network, (i-3) generate one or more main pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to the main ROIs, on the main feature map, via a main pooling layer, and (i-4) generate multiple pieces of main object detection information on the main objects located on the main driving image by applying at least one fully-connected operation to the main pooled feature maps via a main fully connected layer; (b) the main driving image integrating device performing a process of inputting the main pooled feature maps into a main confidence network, to thereby allow the main confidence network to generate each of one or more main confidences of each of the main ROIs corresponding to each of the main pooled feature maps; and (c) the main driving image integrating device performing a process of acquiring multiple pieces of sub-object detection information and one or more sub-confidences from each of one or more sub-vehicles in the cooperative driving, and a process of integrating the multiple pieces of the main object detection information and the multiple pieces of the sub-object detection information by using the main confidences and the sub-confidences as weights, to thereby generate at least one object detection result of the main driving image, wherein the multiple pieces of the sub-object detection information and the sub confidences are generated by each of one or more sub-driving image integrating devices, installed on each of the sub-vehicles, wherein each of the sub-driving image integrating devices performs (i) a process of inputting each of sub-driving images into corresponding each of sub-object detectors, to thereby allow said each of the sub-object detectors to (i-1) generate each of sub-feature maps by applying at least one convolution operation to each of the sub-driving images via corresponding each of sub-convolutional layers, (i-2) generate one or more sub-ROIs, corresponding to one or more regions where one or more sub-objects are estimated as located, on each of the sub-feature maps, via corresponding each of sub-region proposal networks, (i-3) generate each of one or more sub pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to each of the sub-ROIs, on each of the sub-feature maps, via corresponding each of sub-pooling layers, (i-4) generate the multiple pieces of the sub-object detection information on the sub-objects located on each of the sub-driving images by applying at least one fully connected operation to each of the sub-pooled feature maps via corresponding each of sub fully connected layers, and (i-5) input each of the sub-pooled feature maps into corresponding each of sub-confidence networks, to thereby allow each of the sub-confidence networks to generate the sub-confidences of the sub-ROIs corresponding to each of the sub pooled feature maps, wherein, in order to integrate the multiple pieces of the main object detection information and the multiple pieces of the sub-object detection information by using the main confidences and the sub-confidences as weights, the main driving image integrating device performs (i) a process of weighted summation of each estimation value on each class included in each piece of the specific object detection information by using each of specific confidences, corresponding to each piece of the specific object detection information, among the main confidences and the sub-confidences, as each weight, and a process of acquiring a specific class having a highest value, among weight-summed classes, as optimal class information corresponding to the specific object, and (ii) a process of weighted summation of each piece of specific regression information included in each piece of the specific object detection information by using each of the specific confidences corresponding to each piece of the specific object detection information as weights, and a process of acquiring weight-summed regression information as optimal regression information corresponding to the specific object.
5. The method of claim 4, wherein, in order to integrate the multiple pieces of the main object detection information and the multiple pieces of the sub-object detection information by using the main confidences and the sub-confidences as weights, if 1-st overlapping object detection information among the 1-st object detection information and 2-nd overlapping object detection information among the 2-nd object detection information are determined as present which overlap each other, the main driving image integrating device performs (i) a process of determining that the 1-st overlapping object detection information and the 2-nd overlapping object detection information correspond to the specific object if an intersection over union of a 1-st bounding box corresponding to the 1-st overlapping object detection information and a 2-nd bounding box corresponding to the 2-nd overlapping object detection information is equal to or greater than a preset threshold, and (ii) a process of determining that the 1-st overlapping object detection information and the 2-nd overlapping object detection information correspond to different objects if the intersection over union is less than the preset threshold.
6. A main driving image integrating device, installed on at least one main vehicle among one or more vehicles in a cooperative driving, for integrating driving images acquired from the vehicles, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform or support another device to perform: (I) a process of inputting at least one main driving image, acquired from at least one main camera installed on the main vehicle, into a main object detector, to thereby allow the main object detector to (I-1) generate at least one main feature map by applying at least one convolution operation to the main driving image via a main convolutional layer, (I-2) generate one or more main ROIs (Regions Of Interest), corresponding to one or more regions where one or more main objects are estimated as located, on the main feature map, via a main region proposal network, (I-3) generate one or more main pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to the main ROIs, on the main feature map, via a main pooling layer, and (I-4) generate multiple pieces of main object detection information on the main objects located on the main driving image by applying at least one fully-connected operation to the main pooled feature maps via a main fully connected layer, (II) a process of inputting the main pooled feature maps into a main confidence network, to thereby allow the main confidence network to generate each of one or more main confidences of each of the main ROIs corresponding to each of the main pooled feature maps, and (III) a process of acquiring multiple pieces of sub-object detection information and one or more sub confidences from each of one or more sub-vehicles in the cooperative driving, and a process of integrating the multiple pieces of the main object detection information and the multiple pieces of the sub-object detection information by using the main confidences and the sub confidences as weights, to thereby generate at least one object detection result of the main driving image, wherein the multiple pieces of the sub-object detection information and the sub confidences are generated by each of one or more sub-driving image integrating devices, installed on each of the sub-vehicles, and wherein each of the sub-driving image integrating devices performs (i) a process of inputting each of sub-driving images into corresponding each of sub-object detectors, to thereby allow said each of the sub-object detectors to (i-1) generate each of sub-feature maps by applying at least one convolution operation to each of the sub-driving images via corresponding each of sub-convolutional layers, (i-2) generate one or more sub-ROIs, corresponding to one or more regions where one or more sub-objects are estimated as located, on each of the sub-feature maps, via corresponding each of sub-region proposal networks, (i-3) generate each of one or more sub-pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to each of the sub-ROIs, on each of the sub-feature maps, via corresponding each of sub-pooling layers, (i-4) generate the multiple pieces of the sub-object detection information on the sub-objects located on each of the sub-driving images by applying at least one fully-connected operation to each of the sub-pooled feature maps via corresponding each of sub-fully connected layers, and (i-5) input each of the sub-pooled feature maps into corresponding each of sub-confidence networks, to thereby allow each of the sub-confidence networks to generate the sub-confidences of the sub-ROIs corresponding to each of the sub pooled feature maps, wherein the main object detector and the main confidence network have been learned by a learning device, wherein the learning device has learned the main object detector by performing, if training data including one or more driving images for training are acquired, (i) a process of sampling (i-1) 1-st training data including a (1_1)-st driving image for training to a (1_m)-th driving image for training wherein m is an integer larger than 0 and (i-2) 2-nd training data including a (2_1)-st driving image for training to a (2_n)-th driving image for training, from the training data wherein n is an integer larger than 0, (ii) a process of inputting a (1 _j)-th driving image for training, among the (1_1)-st driving image for training to the (1_m)-th driving image for training, into the main convolutional layer, to thereby allow the main convolutional layer to generate at least one 1-st feature map by applying at least one convolution operation to the (1 _j) th driving image for training, (iii) a process of inputting the 1-st feature map into the main region proposal network, to thereby allow the main region proposal network to generate one or more 1-st ROIs, corresponding to one or more objects for training, on the 1-st feature map, (iv) a process of instructing the main pooling layer to generate one or more 1-st pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to the 1-st ROIs, on the 1-st feature map, (v) a process of instructing the main fully connected layer to generate multiple pieces of 1-st object detection information corresponding to the objects for training located on the (1 _j)-th driving image for training by applying at least one fully-connected operation to the 1-st pooled feature maps or at least one 1-st feature vector corresponding to the 1-st pooled feature maps, (vi) a process of instructing a 1-st loss layer to calculate one or more 1 st losses by referring to the multiple pieces of the 1-st object detection information and at least one object ground truth of the (1 _j)-th driving image for training, and (vii) a process of updating at least one parameter of the main fully connected layer and the main convolutional layer via backpropagation using the 1-st losses such that the 1-st losses are minimized, for each of the (1_1)-st driving image for training to the (1 _m)-th driving image for training, and wherein the learning device has learned the main confidence network by performing (i) a process of acquiring each of one or more 1-st confidences of each of the 1-st ROIs by referring to the object ground truth and the multiple pieces of the 1-st object detection information corresponding to each of the (1_1)-st driving image for training to the (1 _m)-th driving image for training, (ii) a process of inputting a (2 _k)-th driving image for training, among the (2_1)-st driving image for training to the (2 _n)-th driving image for training, into the main convolutional layer, to thereby allow the main convolutional layer to generate at least one 2-nd feature map by applying at least one convolution operation to the (2_k)-th driving image for training, (iii) a process of inputting the 2-nd feature map into the main region proposal network, to thereby allow the main region proposal network to generate one or more 2-nd ROIs corresponding to the objects for training located on the 2-nd feature map, (iv) a process of instructing the main pooling layer to generate one or more 2-nd pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to the 2-nd ROIs, on the 2-nd feature map, (v) a process of inputting the 2-nd pooled feature maps into the main confidence network, to thereby allow the main confidence network to generate one or more 2-nd confidences corresponding to the 2-nd pooled feature maps through deep learning, (vi) a process of instructing a 2-nd loss layer to calculate one or more 2-nd losses by referring to the 2-nd confidences and the 1-st confidences, and (vii) a process of updating at least one parameter of the main confidence network via backpropagation using the 2-nd losses such that the 2-nd losses are minimized, for each of the (2_1)-st driving image for training to the (2 _n)-th driving image for training.
7. The main driving image integrating device of claim 6, wherein the learning device acquires the 1-st confidences of each of the 1-st ROIs by referring to the multiple pieces of the 1-st object detection information and their object ground truths, wherein each of the 1-st confidences is 0 if each of the objects for training is absent in each of the 1-st ROIs, and each of the 1-st confidences is 1-box_error×class_error if said each of the objects for training is present in said each of the 1-st ROIs, and wherein each box_error is each error of bounding boxes included in the multiple pieces of the 1-st object detection information, and each class_error is each error of class information included in the multiple pieces of the 1-st object detection information.
8. The main driving image integrating device of claim 7, wherein (i) said each box_error is each ratio of (i-1) each size of each of the objects for training to (i-2) a summation of errors of each of center points of the bounding boxes, and (ii) said each class_error is each summation of class errors of each estimation value on each class, to be used for classifying each of the objects for training, included in the multiple pieces of the 1-st object detection information.
9. A main driving image integrating device, installed on at least one main vehicle among one or more vehicles in a cooperative driving, for integrating driving images acquired from the vehicles, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform or support another device to perform: (I) a process of inputting at least one main driving image, acquired from at least one main camera installed on the main vehicle, into a main object detector, to thereby allow the main object detector to (I-1) generate at least one main feature map by applying at least one convolution operation to the main driving image via a main convolutional layer, (I-2) generate one or more main ROIs (Regions Of Interest), corresponding to one or more regions where one or more main objects are estimated as located, on the main feature map, via a main region proposal network, (I-3) generate one or more main pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to the main ROIs, on the main feature map, via a main pooling layer, and (I-4) generate multiple pieces of main object detection information on the main objects located on the main driving image by applying at least one fully-connected operation to the main pooled feature maps via a main fully connected layer, (II) a process of inputting the main pooled feature maps into a main confidence network, to thereby allow the main confidence network to generate each of one or more main confidences of each of the main ROIs corresponding to each of the main pooled feature maps, and (III) a process of acquiring multiple pieces of sub-object detection information and one or more sub confidences from each of one or more sub-vehicles in the cooperative driving, and a process of integrating the multiple pieces of the main object detection information and the multiple pieces of the sub-object detection information by using the main confidences and the sub confidences as weights, to thereby generate at least one object detection result of the main driving image, wherein the multiple pieces of the sub-object detection information and the sub confidences are generated by each of one or more sub-driving image integrating devices, installed on each of the sub-vehicles, and wherein each of the sub-driving image integrating devices performs (i) a process of inputting each of sub-driving images into corresponding each of sub-object detectors, to thereby allow said each of the sub-object detectors to (i-1) generate each of sub-feature maps by applying at least one convolution operation to each of the sub-driving images via corresponding each of sub-convolutional layers, (i-2) generate one or more sub-ROIs, corresponding to one or more regions where one or more sub-objects are estimated as located, on each of the sub-feature maps, via corresponding each of sub-region proposal networks, (i-3) generate each of one or more sub-pooled feature maps by applying at least one pooling operation to one or more regions, corresponding to each of the sub-ROIs, on each of the sub-feature maps, via corresponding each of sub-pooling layers, (i-4) generate the multiple pieces of the sub-object detection information on the sub-objects located on each of the sub-driving images by applying at least one fully-connected operation to each of the sub-pooled feature maps via corresponding each of sub-fully connected layers, and (i-5) input each of the sub-pooled feature maps into corresponding each of sub-confidence networks, to thereby allow each of the sub-confidence networks to generate the sub-confidences of the sub-ROIs corresponding to each of the sub pooled feature maps, wherein, in order to integrate the multiple pieces of the main object detection information and the multiple pieces of the sub-object detection information by using the main confidences and the sub-confidences as weights, the processor performs (i) a process of weighted summation of each estimation value on each class included in each piece of the specific object detection information by using each of specific confidences, corresponding to each piece of the specific object detection information, among the main confidences and the sub-confidences, as each weight, and a process of acquiring a specific class having a highest value, among weight-summed classes, as optimal class information corresponding to the specific object, and (ii) a process of weighted summation of each piece of specific regression information included in each piece of the specific object detection information by using each of the specific confidences corresponding to each piece of the specific object detection information as weights, and a process of acquiring weight-summed regression information as optimal regression information corresponding to the specific object.
10. The main driving image integrating device of claim 9, wherein, in order to integrate the multiple pieces of the main object detection information and the multiple pieces of the sub-object detection information by using the main confidences and the sub confidences as weights, if 1-st overlapping object detection information among the 1-st object detection information and 2-nd overlapping object detection information among the 2-nd object detection information are determined as present which overlap each other, the processor performs (i) a process of determining that the 1-st overlapping object detection information and the 2-nd overlapping object detection information correspond to the specific object if an intersection over union of a 1-st bounding box corresponding to the 1-st overlapping object detection information and a 2-nd bounding box corresponding to the 2-nd overlapping object detection information is equal to or greater than a preset threshold, and (ii) a process of determining that the 1-st overlapping object detection information and the 2-nd overlapping object detection information correspond to different objects if the intersection over union is less than the preset threshold.
</claims>
</document>
