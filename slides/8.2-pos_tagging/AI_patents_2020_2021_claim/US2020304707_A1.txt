<document>

<filing_date>
2020-03-12
</filing_date>

<publication_date>
2020-09-24
</publication_date>

<priority_date>
2019-03-19
</priority_date>

<ipc_classes>
G06N20/00,G06T7/73,G06T7/80,H04N5/232
</ipc_classes>

<assignee>
SONY INTERACTIVE ENTERTAINMENT
</assignee>

<inventors>
CAPPELLO, FABIO
GUPTA, RAJEEV
WILLIAMS, NIGEL JOHN
Breugelmans, Mark Jacobus
</inventors>

<docdb_family_id>
66381023
</docdb_family_id>

<title>
System and Camera Device for Capturing Images
</title>

<abstract>
A system for adjusting the pose of a camera relative to a subject in a scene is provided. The system comprises a camera operable to capture images of a scene; an identification unit configured to identify an object of interest in images of the scene; a pose processor configured to obtain a pose of the object of interest in the scene relative to the camera; a scene analyser operable to determine, based on at least one of the obtained pose of the object of interest and images captured by the camera, a scene quality associated with images captured by the camera. A controller is configured to cause the pose of the camera to be adjusted based on a determination that the scene quality of an image captured at a current pose is less than a threshold value. A corresponding device is also provided.
</abstract>

<claims>
1. A system comprising: a camera operable to capture images of a scene; an identification unit configured to identify an object of interest in images of the scene; a pose processor configured to obtain a pose of the object of interest in the scene relative to the camera; a scene analyser operable to determine, based on at least one of the obtained pose of the object of interest and images captured by the camera, a scene quality associated with images captured by the camera at a respective pose; wherein the scene analyser comprises a first machine learning model trained to determine the scene quality associated with the images captured by cameras at respective poses; and a controller configured to cause a pose of the camera to be adjusted based on a determination that the scene quality of an image captured at a current pose is less than a threshold value.
2. A system according to claim 1, wherein the first machine learning model is trained with pose data indicating a pose of the object of interest in the scene relative to the camera that captured the training images and or training images of objects of interest wherein the pose data and or training images are labelled with respective scene qualities.
3. A system according to claim 2, wherein the pose data and or training images are labelled as having a high scene quality based on at least one of a source of the pose data and or training images and user feedback associated with the pose data and or training images.
4. A system according to claim 2, wherein the controller is configured to adjust one or more intrinsic parameters of the camera based on the determination that the scene quality of an image captured at a current pose is less than a threshold value; and wherein the first machine learning model is further trained with intrinsic data indicating one or more intrinsic parameters of the cameras for which the pose data and or training images were obtained.
5. A system according to claim 1, wherein the controller comprises a second machine learning model trained to determine a pose of the camera that is likely to result in the capture of an image of the object of interest having a higher scene quality.
6. A system according to claim 5, wherein the second machine learning model comprises an agent trained using deep reinforcement learning; and wherein the agent is trained to learn a pose that maximises the scene quality of images captured by the camera, the agent being trained by moving around multiple different virtual scenes and capturing virtual images of objects of interest within those scenes.
7. A system according to claim 6, wherein the second machine learning model is configured to determine a scene quality associated with the virtual images by inputting the virtual images into the first trained machine learning model.
8. A system according to claim 1, wherein the identification unit is configured to identify a type of scene that the images captured by the camera corresponds to; and wherein the scene analyser is further configured to determine a scene quality associated with the images captured by the camera at a respective pose, based on the identified scene type.
9. A system according to claim 8, wherein the identification unit comprises a third machine learning model trained to identify a type of scene that the images captured by the camera corresponds to, the third machine learning model being trained with images of different types of scene and corresponding scene identifiers.
10. A system according to claim 1, wherein the object of interest comprises a character in a scene, and wherein the scene quality model is trained with pose data and or training images of characters in scenes.
11. A system according to claim 10, wherein the object of interest comprises a plurality of characters, the system comprising: an input unit operable to receive an input from a user indicating one or more characters that are to be included in the captured images; and wherein the scene analyser is configured to determine a scene quality based on the 3D poses of the characters that are to be included in the captured images and or the images captured by the camera.
12. A system according to claim 11, comprising: an audio unit operable to receive speech data indicative that at least one of the characters is or is about to start speaking; wherein the identification unit is configured to identify, based on the speech data, at least one of the characters as a primary character; and wherein the scene analyser is configured to detect the scene quality based on the pose of the at least one primary character in the scene relative to the camera and or the images captured by the camera.
13. A system according to claim 1, wherein the identification unit is configured to identify a source of audio in the scene and the pose processor is configured to determine a pose of the source of audio relative to the camera; and wherein the scene analyser is further configured to determine a scene quality associated with the captured images, based on the detected pose of the source of audio relative to the camera.
14. A system according to claim 1, wherein the camera is real or virtual, being operable to capture images of a real or virtual scene.
15. A system according to claim 1, wherein the camera is a real camera, the system comprising motion means for controlling the position and or orientation of the camera; and wherein motion means comprises at least one of wheels and propellers, the motion means being arranged to receive an input from the controller.
16. A system according to claim 1, in which the camera device comprises: a sensor operable to capture images of a scene; and one or more selected from the list consisting of: i. the identification unit, ii. the pose processor, iii. the scene analyser, and iv. the controller.
</claims>
</document>
