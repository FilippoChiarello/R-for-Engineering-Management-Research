<document>

<filing_date>
2017-02-27
</filing_date>

<publication_date>
2020-03-10
</publication_date>

<priority_date>
2017-01-13
</priority_date>

<ipc_classes>
G06K9/00,G06K9/32,G06K9/62,G06N20/00
</ipc_classes>

<assignee>
GOOGLE
GOOGLE
</assignee>

<inventors>
PAVETIC, FILIP
TOCHILKIN, DMITRII
LEUNG, KING HONG THOMAS
</inventors>

<docdb_family_id>
60327376
</docdb_family_id>

<title>
Using machine learning to detect which part of the screen includes embedded frames of an uploaded video
</title>

<abstract>
A system and methods are disclosed for training a machine learning model to identify constituent images within composite images. In one implementation, a composite image is generated, where the composite image comprises a first portion containing pixel data of a first constituent image, and a second portion containing pixel data of a second constituent image. A first training input comprising pixel data of the composite image and a first target output for the first training input are generated, where the first target output identifies a position of the first portion within the composite image. The training data is provided to train the machine learning model on (i) a set of training inputs comprising the first training input and (ii) a set of target outputs comprising the first target output.
</abstract>

<claims>
1. A method for training a machine learning model to identify constituent images within composite images, the method comprising: generating training data for the machine learning model, wherein generating the training data comprises: generating a composite image comprising a first portion containing pixel data of a first constituent image, and a second portion containing pixel data of a second constituent image; generating a first training input comprising pixel data of the composite image; and generating a first target output for the first training input, wherein the first target output identifies a position of the first portion within the composite image; and providing the training data to train the machine learning model on (i) a set of training inputs comprising the first training input and (ii) a set of target outputs comprising the first target output, wherein the trained machine learning model is to receive a new image as input and to produce a new output based on the new input, the new output indicating whether the new image is a composite image containing a constituent image.
2. The method of claim 1 wherein the second portion of the composite image surrounds the first portion of the composite image.
3. The method of claim 1 wherein the first constituent image is a frame of a first video and the second constituent image is a frame of a second video.
4. The method of claim 1 wherein the position of the first portion within the composite image comprises coordinates of an upper left corner of the first constituent image and coordinates of a lower right corner of the first constituent image.
5. The method of claim 1 wherein each training input in the set of training inputs is mapped to a target output in the set of target outputs.
6. The method of claim 1 wherein the machine learning model is configured to process a new image and generate one or more outputs indicating (i) a level of confidence that the new image is a composite image including a constituent image, and (ii) a spatial area in which the constituent image is located within the new image.
7. An apparatus comprising: a memory to store a first image; and a processing device, operatively coupled to the memory, to: provide pixel data of the first image as input to a machine learning model trained using training data comprising pixel data of a plurality of composite images that each include pixel data of respective constituent images; obtain one or more outputs from the trained machine learning model; and extract, from the one or more outputs, a level of confidence that: the first image is a composite image that includes a constituent image, and at least a portion of the constituent image is in a particular spatial area of the first image.
8. The apparatus of claim 7, wherein the processing device is further to: determine that the level of confidence satisfies a threshold condition; and extract the constituent image from the particular spatial area of the first image.
9. The apparatus of claim 7 wherein the first spatial area is one of a plurality of spatial areas of the first image, and wherein the plurality of spatial areas are uniform in size and shape.
10. The apparatus of claim 7 wherein the first spatial area is one of a plurality of spatial areas of the first image, and wherein at least two of the plurality of spatial areas have different sizes.
11. The apparatus of claim 7 wherein the first spatial area is one of a plurality of spatial areas of the first image, and wherein at least two of the plurality of spatial areas overlap.
12. The apparatus of claim 7 wherein the first spatial area is one of a plurality of spatial areas of the first image, and wherein the plurality of spatial areas are non-overlapping.
13. The apparatus of claim 7 wherein the first spatial area is one of a plurality of spatial areas of the first image, and wherein at least two of the plurality of spatial areas have different shapes.
14. The apparatus of claim 7 wherein the training data comprises an input and an output, the input based on pixel data of a composite image of the plurality of composite images, the composite image comprising a first portion containing pixel data of a fourth image and a second portion containing pixel data of a fifth image, and the output identifying a position of the first portion within the composite image, wherein each of the fourth and fifth images is one of the respective constituent images.
15. A method comprising: receiving an input image; processing the input image using a machine learning model trained using training data comprising pixel data of a plurality of composite images that each include pixel data of respective constituent images; and obtaining, based on the processing of the input image using the trained machine learning model, one or more outputs indicating (i) a level of confidence that the input image is a composite image including a constituent image, and (ii) a spatial area that includes the constituent image within the input image.
16. The method of claim 15, further comprising: determining that the level of confidence satisfies a threshold condition; and extracting the constituent image from the spatial area within the input image.
17. The method of claim 15 wherein the input image comprises a second constituent image that surrounds the constituent image.
18. The method of claim 15 wherein the constituent image is a frame of a video.
19. The method of claim 15 wherein the spatial area is one of a plurality of spatial areas of the input image, and wherein a union of the plurality of spatial areas contains all pixels of the input image.
20. The method of claim 15 wherein the first spatial area is one of a plurality of spatial areas of the input image, and wherein the plurality of spatial areas are uniform in size and shape.
21. The method of claim 15 wherein the spatial area is one of a plurality of spatial areas of the input image, and wherein at least two of the plurality of spatial areas have different sizes.
22. The method of claim 15 wherein the spatial area is one of a plurality of spatial areas of the input image, and wherein at least two of the plurality of spatial areas have different shapes.
23. A method comprising: receiving an input image; and processing the input image using a trained model that is configured to generate, based on pixel data of the input image, one or more outputs indicating (i) a level of confidence that the input image is a composite image including a constituent image, and (ii) a spatial area that includes the constituent image within the input image, wherein the trained model was trained using training data comprising pixel data of a plurality of other composite images that each include pixel data of respective other constituent images.
24. The method of claim 23, further comprising: determining that the level of confidence satisfies a threshold condition; extracting the constituent image from the spatial area within the input image; creating a fingerprint of the constituent image; and comparing the created fingerprint with stored fingerprints of a plurality of images to determine whether the constituent image is similar to any of the plurality of images.
</claims>
</document>
