<document>

<filing_date>
2020-04-02
</filing_date>

<publication_date>
2020-10-08
</publication_date>

<priority_date>
2019-04-03
</priority_date>

<ipc_classes>
G01C21/30,G01C21/32,G06K9/00,G06T7/70
</ipc_classes>

<assignee>
CEPTION TECHNOLOGIES
</assignee>

<inventors>
ISRAEL, TAL
BUDA, Yossef Israel (yossi)
</inventors>

<docdb_family_id>
66768888
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR DETERMINING LOCATION AND ORIENTATION OF AN OBJECT IN A SPACE
</title>

<abstract>
A system and method for determining location and/or orientation of a sensor may include, stored in a database a representation of an element in a first space. A mapping between the representation and input from a first sensor may be created. Using the mapping and input from a second sensor in a second space, one or more elements in the database may be identified. A location and/or orientation of the second sensor in the second space may be determined based on the one or more elements.
</abstract>

<claims>
1. A method of determining at least one of a location and an orientation of a sensor, the method comprising: including in a database a representation of at least one element in a first space; creating a mapping between the representation and input from a first perception sensor; using the mapping and input from a second perception sensor in a second space, to identify one or more elements in the database; and using attributes of the identified one or more elements to determine at least one of a location and an orientation of the second perception sensor in the second space.
2. The method of claim 1, wherein a first mapping is according to a first condition and a second mapping is according to a second condition and wherein one of the first and second mappings is selected based on a condition related to the second sensor.
3. The method according to any one of claims 1-2, wherein the representation of an element in the database is based on a first point of view and wherein the input from the second perception sensor is related to a second, different point of view.
4. The method according to any one of claims 1-3, comprising, creating a plurality of mappings for a respective plurality of sensor types and wherein a mapping is selected based on the type of the second sensor.
5. The method according to any one of claims 1-4, wherein identifying one or more elements in the database is based on a subset of elements in the database, the subset selected based on the type of the second sensor.
6. The method according to any one of claims 1-5, comprising updating the representation of an element in the database based on input from the second sensor.
7. The method according to any one of claims 1-6, wherein at least one element in the database is sensed by at least one of: light signals, audio signals, heat, moisture level and electromagnetic waves.
8. The method according to any one of claims 1-7, wherein an element in the database is created based on at least one of: an image, an aerial image, a structural map, a digital elevation model (DEM), a construction plan, a road map, a blue print, a satellite view, a street view, a top view, a side view an architectural plan and vector data.
9. The method according to any one of claims 1-8, wherein information included in the database is related to, and the location and orientation of the first sensor in the space are determined according to, at least one of: a local coordinate system, a common coordinate system and a global coordinate system.
10. The method according to any one of claims 1-9, wherein information in the database matched with the input is selected based on received or calculated location information.
11. The method according to any one of claims 1-10, wherein an estimation of a location of the first sensor in the space is determined based on location information related to the sensor.
12. The method according to any one of claims 1-11, wherein an element is defined based on raw data received from a perception sensor.
13. The method according to any one of claims 1-12, comprising encoding data from a plurality of sources to produce a unified format representation of the data and including the unified format representation in the database.
14. The method according to any one of claims 1-13, utilizing at least one machine learning module to identify a set of elements in the database and to match the input with the set of elements.
15. A method of determining location and orientation of a three dimensional (3D) space, the method comprising: obtaining a 3D representation of the space using input from a mobile sensor; and determining a location and orientation of the space by correlating the 3D representation with a top view representation of the space.
16. The method of claim 15, comprising projecting the 3D representation on the top view representation.
17. The method according to any one of claims 15-16, comprising receiving a set of images and using a relative location in at least some of the images to generate the 3D representation.
18. The method according to any one of claims 15-17 , wherein the top view includes at least one of: an aerial image, a satellite image, a structural map, a road map and a DEM.
19. The method according to any one of claims 15-18, wherein a portion of the top view representation is selected based on location information of the space.
20. The method according to any one of claims 15-19, wherein a relative location of elements in the space is determined based on at least one of: input from a sensor and processing a set of inputs having a respective set of points of view.
21. A system for determining location and orientation of a sensor, the system comprising: a non-transitory memory device, wherein modules of instruction code are stored, and a processor associated with the memory device, and configured to execute the modules of instruction code, whereupon execution of said modules of instruction code, the processor is configured to: include in a database a representation of an element in a first space; create a mapping between the representation and input from a first perception sensor; use the mapping and input from a second perception sensor in a second space, to identify one or more elements in the database; and use attributes of the identified one or more elements to determine a location and orientation of the second perception sensor in the second space.
22. The system of claim 21, wherein a first mapping is according to a first condition and a second mapping is according to a second condition and wherein one of the first and second mappings is selected based on a condition related to the second sensor.
23. The system according to any one of claims 21-22, wherein the representation of an element in the database is based on a first point of view and wherein the input from the second perception sensor is related to a second, different point of view.
24. The system according to any one of claims 21-23, wherein the controller is further configured to create a plurality of mappings for a respective plurality of sensor types and wherein a mapping is selected based on the type of the second sensor.
25. The system according to any one of claims 21-24, wherein identifying one or more elements in the database is based on a subset of elements in the database, the subset selected based on the type of the second sensor.
26. The system according to any one of claims 21-25, wherein the controller is further configured to update the representation of an element in the database based on input from the second sensor.
27. The system according to any one of claims 21-26, wherein an element in the database can be sensed by at least one of: light signals, audio signals, heat, moisture level and electromagnetic waves.
28. The system according to any one of claims 21-27, wherein an element in the database is created based on at least one of: an image, an aerial image, a structural map, a DEM, a construction plan, a road map, a blue print, a satellite view, a street view, a top view, a side view an architectural plan and vector data.
29. The system according to any one of claims 21-29, wherein information included in the database is related to, and the location and orientation of the first sensor in the space are determined according to, at least one of: a local coordinate system, a common coordinate system and a global coordinate system.
30. The system according to any one of claims 21-29, wherein information in the database matched with the input is selected based on received or calculated location information.
31. The system according to any one of claims 21-30, wherein an estimation of a location of the first sensor in the space is determined based on location information related to the sensor.
32. The system according to any one of claims 21-31, wherein an element is defined based on raw data received from a perception sensor.
33. The system according to any one of claims 21-32, wherein the controller is further configured to encode data from a plurality of sources to produce a unified format representation of the data and including the unified format representation in the database.
34. The system according to any one of claims 21-33, wherein the controller is further configured to utilize machine learning to identify a set of elements in the database and matching the input with the set of elements.
35. A system comprising: a memory; and a hardware controller configured to: obtain a 3D representation of the space using input from a mobile sensor; and determine at least one of a location and orientation of the space by correlating the 3D representation with a top view representation of the space.
36. The system of claim 35, wherein the controller is further configured to project the 3D representation on the top view representation.
37. The system according to any one of claims 35-36, wherein the controller is further configured to receive a set of images and use a relative location in at least some of the images to generate the 3D representation.
38. The system according to any one of claims 35-37, wherein the top view includes at least one of: an aerial image, a satellite image, a structural map, a road map and a DEM.
39. The system according to any one of claims 35-38, wherein a portion of the top view representation is selected based on location information of the space.
40. The system according to any one of claims 35-39, wherein a relative location of elements in the space is determined based on at least one of: input from a sensor and processing a set of inputs having a respective set of points of view.
41. The method according to any one of claims 1-14, wherein the at least one element is a location indicative element, and wherein the method further comprises extracting, by the at least one machine learning module the at least one location indicative element, as a characteristic of a geographical location.
42. The method according to any one of claims 1-14 and 41, wherein the location indicative element is not associated with a specific physical object, perceivable by a human observer or by a sensor.
</claims>
</document>
