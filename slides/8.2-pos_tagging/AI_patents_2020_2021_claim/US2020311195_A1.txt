<document>

<filing_date>
2019-04-01
</filing_date>

<publication_date>
2020-10-01
</publication_date>

<priority_date>
2019-04-01
</priority_date>

<ipc_classes>
G06N3/08
</ipc_classes>

<assignee>
IBM (INTERNATIONAL BUSINESS MACHINES CORPORATION)
</assignee>

<inventors>
JAIN, PARAG
SANKARANARAYANAN, KARTHIK
AZAD, AMAR P.
MISHRA, ABHIJIT
</inventors>

<docdb_family_id>
72608026
</docdb_family_id>

<title>
Controllable Style-Based Text Transformation
</title>

<abstract>
Methods, systems and computer program products for multi-style text transformation are provided herein. A computer-implemented method includes obtaining input text and selecting a set of style specifications for transforming the input text. The set of style specifications include one or more target writing style domains selected from a plurality of writing style domains, weights for each of the target writing style domains representing relative impact of the target writing style domains for transformation of the input text, and weights for each of a set of linguistic aspects for transformation of the input text. The computer-implemented method also includes generating one or more style-transformed output texts based at least in part on the set of style specifications utilizing an unsupervised neural network.
</abstract>

<claims>
1. A computer-implemented method, comprising steps of: obtaining input text; selecting a set of style specifications for transforming the input text, the set of style specifications comprising: one or more target writing style domains selected from a plurality of writing style domains; weights for each of the target writing style domains representing relative impact of the target writing style domains for transformation of the input text; and weights for each of a set of linguistic aspects for transformation of the input text; and generating one or more style-transformed output texts based at least in part on the set of style specifications, utilizing an unsupervised neural network; wherein the steps are carried out by at least one processing device.
2. The computer-implemented method of claim 1, wherein the plurality of writing style domains comprises two or more of: a default domain; an academic domain; a technical domain; an advertisement domain; a legal domain; and a medical domain.
3. The computer-implemented method of claim 1, wherein the set of linguistic aspects comprises at least one of formalness, sentiment intensity, and tone.
4. The computer-implemented method of claim 1, wherein said selecting the set of style specifications comprises providing real number inputs as the weights for the selected target writing style domains in proportion to a desired relative impact of the selected target writing style domains on the style-transformed output texts.
5. The computer-implemented method of claim 1, wherein said selecting the set of style specifications comprises providing real number inputs as the weights for each of the set of linguistic aspects corresponding to a desired impact of the linguistic aspects on the style-transformed output texts.
6. The computer-implemented method of claim 1, wherein the unsupervised neural network comprises a deep learning network comprising a plurality of gated recurrent units.
7. The computer-implemented method of claim 1, wherein said generating the one or more style-transformed output texts comprises: generating embeddings for the input text; generating domain-specific style-transformed output text utilizing each of a subset of a plurality of decoders, the subset of the plurality of decoders being associated with the selected target writing style domains and being provided with the embeddings for the input text, the weights for the selected target writing style domains, and the weights for the set of linguistic aspects; and generating a given one of the style-transformed output texts as a combination of the domain-specific style-transformed output texts from each of the subset of the plurality of decoders.
8. The computer-implemented method of claim 1, comprising: training the unsupervised neural network, wherein training the unsupervised neural network comprises: generating an embedding for a given training text from a given one of the plurality of domains; generating domain-specific style-transformed training output texts utilizing a plurality of decoders associated with the plurality of writing style domains, a given one of the decoders corresponding to the given domain being provided with a set of training weights for a set of training writing style domains and the set of linguistic aspects, other ones of the decoders corresponding to other ones of the plurality of domains being provided with null weights for the training writing style domains and the set of linguistic aspects; and generating a given style-transformed training output text as a combination of the domain-specific style-transformed training output texts from the plurality of decoders.
9. The computer-implemented method of claim 8, wherein said training the unsupervised neural network comprises: determining a domain style score vector for the given style-transformed training output text, the domain style score vector comprising a list of scores each indicating to what degree the given style-transformed training output text follows the style of one of a set of training writing style domains; and determining a linguistic aspect score vector for the given style-transformed output text, the linguistic aspect score vector comprising a score corresponding to each of the set of linguistic aspects computed using a natural language processing tool trained for that linguistic aspect.
10. The computer-implemented method of claim 9, wherein said training the unsupervised neural network comprises: computing a first control loss indicating a gap between (i) the training weights for the set of training writing style domains; and (ii) the scores in the domain style score vector; computing a second control loss indicating a gap between (i) the training weights for the set of linguistic aspects; and (ii) the scores in the linguistic aspect score vector; computing a reconstruction loss by comparing fluency of the training input text and fluency of the given style-transformed training output text; and computing a back-translation loss by performing back-translation of the given style-transformed training output text through the plurality of decoders.
11. The computer-implemented method of claim 10, wherein said training the unsupervised neural network comprises minimizing the first control loss, the second control loss, the reconstruction loss and the back-translation loss.
12. A computer program product, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by at least one computing device to cause the at least one computing device to perform steps of: obtaining input text; selecting a set of style specifications for transforming the input text, the set of style specifications comprising: one or more target writing style domains selected from a plurality of writing style domains; weights for each of the target writing style domains representing relative impact of the target writing style domains for transformation of the input text; and weights for each of a set of linguistic aspects for transformation of the input text; and generating one or more style-transformed output texts based at least in part on the set of style specifications utilizing an unsupervised neural network.
13. The computer program product of claim 12, wherein said generating the one or more style-transformed output texts comprises: generating embeddings for the input text; generating domain-specific style-transformed output text utilizing each of a subset of a plurality of decoders, the subset of the plurality of decoders being associated with the selected target writing style domains and being provided with the embeddings for the input text, the weights for the selected target writing style domains, and the weights for the set of linguistic aspects; and generating a given one of the style-transformed output texts as a combination of the domain-specific style-transformed output texts from each of the subset of the plurality of decoders.
14. The computer program product of claim 12, wherein the program instructions are executable by the at least one computing device to cause the at least one computing device to perform the step of training the unsupervised neural network, wherein said training the unsupervised neural network comprises: generating an embedding for a given training text from a given one of the plurality of domains; generating domain-specific style-transformed training output texts utilizing a plurality of decoders associated with the plurality of writing style domains, a given one of the decoders corresponding to the given domain being provided with a set of training weights for a set of training writing style domains and the set of linguistic aspects, other ones of the decoders corresponding to other ones of the plurality of domains being provided with null weights for the training writing style domains and the set of linguistic aspects; and generating a given style-transformed training output text as a combination of the domain-specific style-transformed training output texts from the plurality of decoders.
15. A system comprising: a memory; and at least one processor coupled to the memory and configured for: obtaining input text; selecting a set of style specifications for transforming the input text, the set of style specifications comprising: one or more target writing style domains selected from a plurality of writing style domains; weights for each of the target writing style domains representing relative impact of the target writing style domains for transformation of the input text; and weights for each of a set of linguistic aspects for transformation of the input text; and generating one or more style-transformed output texts based at least in part on the set of style specifications utilizing an unsupervised neural network.
16. The system of claim 15, wherein said generating the one or more style-transformed output texts comprises: generating embeddings for the input text; generating domain-specific style-transformed output text utilizing each of a subset of a plurality of decoders, the subset of the plurality of decoders being associated with the selected target writing style domains and being provided with the embeddings for the input text, the weights for the selected target writing style domains, and the weights for the set of linguistic aspects; and generating a given one of the style-transformed output texts as a combination of the domain-specific style-transformed output texts from each of the subset of the plurality of decoders.
17. The system of claim 15, wherein the at least one processor is configured for training the unsupervised neural network, wherein said training the unsupervised neural network comprises: generating an embedding for a given training text from a given one of the plurality of domains; generating domain-specific style-transformed training output texts utilizing a plurality of decoders associated with the plurality of writing style domains, a given one of the decoders corresponding to the given domain being provided with a set of training weights for a set of training writing style domains and the set of linguistic aspects, other ones of the decoders corresponding to other ones of the plurality of domains being provided with null weights for the training writing style domains and the set of linguistic aspects; and generating a given style-transformed training output text as a combination of the domain-specific style-transformed training output texts from the plurality of decoders.
18. A computer-implemented method, comprising steps of: receiving an input text snippet to be style-transformed in accordance with a set of style control parameters specified in a control vector; passing the input text snippet to an unsupervised neural network comprising a plurality of gated recurrent units; determining a hidden representation of the input text snippet utilizing a first subset of the plurality of gated recurrent units arranged in a stacked layer providing an encoder; and generating a style-transformed output text snippet utilizing a second subset of the plurality of gated recurrent units providing a decoder, the decoder generating each word of the style-transformed output text snippet utilizing a non-linear function that outputs a probability distribution for a given word of the style-transformed output text snippet based on (i) an embedding of a previously generated word of the style-transformed output text snippet, (ii) the control vector, (iii) a vector obtained by attending over the hidden representation of the input text snippet, and (iv) a hidden state of a decoder of the unsupervised neural network; wherein the steps are carried out by at least one processing device.
19. The computer-implemented method of claim 18, comprising: training the unsupervised neural network by repeating the passing, determining and generating steps for each of a plurality of training input text snippets and, for each generated style-transformed output text snippet corresponding to a given one of the training input text snippets: producing a set of variants of the generated style-transformed output text snippet; selecting a given one of the variants of the generated style-transformed output text snippet based at least in part on semantic relatedness to the given training input text snippet, fluency of the given variant of the generated style-transformed output text snippet as measured using a designated language model, and a readability grade score of the given variant of the generated style-transformed output text snippet; and determining a set of style control parameters associated with the given variant of the generated style-transformed output text snippet.
20. The computer-implemented method of claim 19, comprising: utilizing the given variant of the generated style-transformed output text snippet and its associated set of style control parameters as labeled training data to train the encoder and decoder of the unsupervised neural network.
</claims>
</document>
