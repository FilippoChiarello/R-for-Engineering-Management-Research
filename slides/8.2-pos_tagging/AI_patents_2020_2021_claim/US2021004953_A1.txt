<document>

<filing_date>
2020-04-30
</filing_date>

<publication_date>
2021-01-07
</publication_date>

<priority_date>
2019-07-01
</priority_date>

<ipc_classes>
G05B19/418,G06F16/9035,G06N3/08,G06T7/00
</ipc_classes>

<assignee>
SAS INSTITUTE
</assignee>

<inventors>
WU, XUNLEI
Ghadyali, Hamza Mustafa
Pathan, Sharmin
Oliveira, Ivan Borges
</inventors>

<docdb_family_id>
73746640
</docdb_family_id>

<title>
OBJECT AND DATA POINT TRACKING TO CONTROL SYSTEM IN OPERATION
</title>

<abstract>
A computing system obtains image data capturing first and second objects. The system determines, based on user-identified data points, boundaries of the objects and generates a component of a dataset by computing a first data value related to an attribute of a key point in the first image; and computing a second data value related to an attribute of a key point in the first image. The system generates a second component of the dataset, the second component representing updated relative information between the first and second object by generating predicted changes in the first data value and second data value for the second image. The system computes a third data value and a fourth data value related to respective data points in a first and second polygon in the second image. The generating the updated relative information is based on the predicted changes and computed values.
</abstract>

<claims>
1. A computer-program product tangibly embodied in a non-transitory machine-readable storage medium, the computer-program product including instructions operable to cause a computing system to: obtain data representing a first image of a plurality of images, each of the plurality of images capturing different time points of a system in operation, the system in operation comprising a first object and a second object different from the first object; receive an indication of user-identified data points in a plurality of data points in the data representing the first image, wherein the indication indicates an image coordinate location for each of the user-identified data points in a first coordinate system associated with the first image, and wherein the user-identified data points identify the first object and the second object in the first image; determine, based on a first set of data points of the user-identified data points, a first boundary of the first object in the first image; determine, based on a second set of data points of the user-identified data points, a second boundary of the second object in the first image; identify a first polygon defined by the first boundary, the first polygon representing the first object in the system in operation; identify a second polygon defined by the second boundary, the second polygon representing the second object in the system in operation; generate a first component of a dataset, the first component representing initial relative information between the first object and the second object, by: computing a first data value related to an attribute of a key point of the first set of data points in the first image; computing a second data value related to an attribute of a key point of the second set of data points in the first image; generating, based on the first data value and the second data value, the initial relative information between the first object and the second object; generate a second component of the dataset, the second component representing updated relative information between the first object and the second object, by: obtaining data representing a second image of the plurality of images subsequent to the first image; detecting the first polygon and the second polygon in the second image; determining one or more data points in the first polygon in the second image; determining one or more data points in the second polygon in the second image; generating a predicted change in the first data value for the second image; generating a predicted change in the second data value for the second image; computing a third data value related to a data point of the one or more data points in the first polygon in the second image, the data point corresponding to the key point of the first set of data points in the first image; computing a fourth data value related to a data point of the one or more data points in the second polygon in the second image, the data point corresponding to the key point of the second set of data points in the first image; generating the updated relative information between the first object and the second object, wherein the generating the updated relative information is based on the predicted change in the first data value, the predicted change in the second data value, the third data value, and the fourth data value; and output one or more components of the dataset.
2. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to: extract the data representing the first image from a real-time video feed comprising the plurality of images; and generate a plurality of data models for identifying the first polygon in the plurality of images by: augmenting the extracted data by performing one or more of the following to one or more components of the first image: color jittering, sharpening, lightening, flipping, changing one or more dimensions; and cropping; and setting as data models equivalent ones of the first polygon in the augmented extracted data.
3. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to compute the first data value related to the attribute of the key point of the plurality of data points in the first image by deriving the key point, from one or more of the user-identified data points, that is a data point different from the user-identified data points.
4. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to compute a first data value related to the attribute of the key point of the plurality of data points in the first image by: obtaining a first cropped area encompassing the first polygon in a cropping from the first image; defining a first cropped area image location of the key point in a second coordinate system defined by the first cropped area which is different than the first coordinate system; deriving the first data value based on the cropped image location; obtaining a second cropped area encompassing the first polygon in a cropping from the second image; determining a second cropped area image location in the second cropped area for each of the one or more data points of the plurality of data points in the first polygon in the second image; and deriving the third data value based on the second cropped area image location.
5. The computer-program product of claim 1, wherein the first object has a non-rectangular shape in the first image; and the instructions are operable to cause the computing system to detect the first polygon in the second image by: determining a rectangular bounding box for the first polygon; implementing a you only look once (YOLO) detection algorithm on the rectangular bounding box; and identifying a non-rectangular shape in the second image corresponding to the non-rectangular shape in the first image.
6. The computer-program product of claim 5, the instructions are operable to cause the computing system to receive user-identified data points for each corner of the first object shown in the first image; and wherein the determining the rectangular bounding box for the first polygon comprises extrapolating corners for the rectangular bounding box based on: determining a maximum distance between one or more of the user-identified data points; and providing an offset from any corners of the first object.
7. The computer-program product of claim 5, wherein implementing the YOLO detection algorithm on the rectangular bounding box comprises selectively setting, based on a size of a first object, a granularity of a coordinate system associated with the first image or a cropped area from the first image.
8. The computer-program product of claim 1, wherein the first object is rectangular; and wherein the instructions are operable to cause the computing system to detect a first polygon in the second image that has a trapezoid shape due to an angle of a recording device that captured the second image.
9. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to: predict a predicted change in the first data value by applying a Kalman filter to generate a data table of uncertainties for estimates of the predicted change; and update the estimates based on the third data value and a weighted average derived from the data table of uncertainties for predicting another data value different from the first data value and the third data value.
10. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to detect the first polygon in the second image by: determining an additional boundary for the first object in the second image; generating a data set representing pixels within the first boundary and the additional boundary; and labeling, in the data set, pixels within the additional boundary with a same identifier as pixels within the first boundary; and wherein the pixels within the additional boundary have a different pixel resolution or pixel coding than pixels within the first boundary.
11. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to: predict that the first object will undergo a change to become two separate objects in the system in operation; detect the first polygon in the second image by detecting two detected polygons each corresponding to components of the first polygon; and assign identifiers to each of the two detected polygons indicating its relationship to the first polygon in the first image.
12. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to determine the one or more data points in the first polygon in the second image by determining less corresponding data points as the user-identified data points.
13. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to: compute an actual change in the first data value to the third data value; compare the actual change to the predicted change in the first data value for the second image; and based on the comparison of the actual change to the predicted change in the first data value for the second image, determine a velocity, acceleration, size, or orientation of the first polygon, or one or more data points within the first polygon, indicates to correct an operation of the system in operation.
14. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to: compare the updated relative information to a predicted change for the relative information, wherein the predicted change for the relative information is based on the predicted change in the first data value for the second image and the predicted change in the second data value for the second image; and based on the comparison, trigger a control to correct the system in operation.
15. The computer-program product of claim 14, wherein the instructions are operable to cause the computing system to trigger a control to correct the system in operation by one or more of the following: sending an electronic notification to an operator of the system in operation; stopping the operation of the system in operation; and augmenting the system in operation to correct for the operation.
16. The computer-program product of claim 14, wherein the instructions are operable to cause the computing system to trigger a control to correct an operation of the system in operation by: selectively storing data related to a plurality of different objects in the plurality of images in storage for further analysis of the operation of the system in operation; and analyzing data of the storage to determine whether to correct an operation of the system in operation.
17. The computer-program product of claim 1, wherein: the system in operation is a system for manufacturing a plurality of products; the first object is one of the plurality of products; and the first boundary encompasses edges of the first object in view of a device capturing the first image; and the instructions are operable to cause the computing system to: predict a predicted change in the first data value based on a predetermined pathway for a given product in the plurality of products during manufacture of the plurality of products in the system in operation; and trigger a control to correct an operation of the system in operation based on a comparison indicating that the given product has moved beyond a tolerance allowed in the predetermined pathway.
18. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to: compute a missing attribute of a data point in an intermediate image between the first image and the second image in the plurality of images, the missing attribute due to an obstruction in a view of the system in operation; and predict a predicted change in the first data value for a second image subsequent to the first image accounting for the obstruction.
19. The computer-program product of claim 1, wherein the instructions are operable to cause the computing system to detect the first polygon in the second image by training, in an overlapping time period, an object detection model on the first boundary and a data point detection model on one or more data points of the plurality of data points.
20. The computer-program product of claim 1, wherein: the instructions are operable to cause the computing system to detect the first polygon in the second image amongst a plurality of polygons based on received information regarding one or more attributes of the first object; and the system in operation is a facial recognition system and the first object is a facial component; or the system in operation is a transportation, warehouse or manufacturing system and the first object is a product or a vehicle for transporting a product.
21. A computer-implemented method comprising: obtaining data representing a first image of a plurality of images, each of the plurality of images capturing different time points of a system in operation, the system in operation comprising a first object and a second object different from the first object; receiving an indication of user-identified data points in a plurality of data points in the data representing the first image, wherein the indication indicates an image coordinate location for each of the user-identified data points in a first coordinate system associated with the first image, and wherein the user-identified data points identify the first object and the second object in the first image; determining, based on a first set of data points of the user-identified data points, a first boundary of the first object in the first image; determining, based on a second set of data points of the user-identified data points, a second boundary of the second object in the first image; identifying a first polygon defined by the first boundary, the first polygon representing the first object in the system in operation; identifying a second polygon defined by the second boundary, the second polygon representing the second object in the system in operation; generating a first component of a dataset, the first component representing initial relative information between the first object and the second object, by: computing a first data value related to an attribute of a key point of the first set of data points in the first image; computing a second data value related to an attribute of a key point of the second set of data points in the first image; generating, based on the first data value and the second data value, the initial relative information between the first object and the second object; generating a second component of the dataset, the second component representing updated relative information between the first object and the second object, by: obtaining data representing a second image of the plurality of images subsequent to the first image; detecting the first polygon and the second polygon in the second image; determining one or more data points in the first polygon in the second image; determining one or more data points in the second polygon in the second image; generating a predicted change in the first data value for the second image; generating a predicted change in the second data value for the second image; computing a third data value related to a data point of the one or more data points in the first polygon in the second image, the data point corresponding to the key point of the first set of data points in the first image; computing a fourth data value related to a data point of the one or more data points in the second polygon in the second image, the data point corresponding to the key point of the second set of data points in the first image; generating the updated relative information between the first object and the second object, wherein the generating the updated relative information is based on the predicted change in the first data value, the predicted change in the second data value, the third data value, and the fourth data value; and outputting one or more components of the dataset.
22. The computer-implemented method of claim 21, wherein the computing the first data value comprises deriving the key point, from one or more of the user-identified data points, that is a data point different from the user-identified data points.
23. The computer-implemented method of claim 21, wherein the computing the first data value comprises: obtaining a first cropped area encompassing the first polygon in a cropping from the first image; defining a first cropped area image location of the key point in a second coordinate system defined by the first cropped area which is different than the first coordinate system; deriving the first data value based on the cropped image location; obtaining a second cropped area encompassing the first polygon in a cropping from the second image; determining a second cropped area image location in the second cropped area for each of the one or more data points of the plurality of data points in the first polygon in the second image; and deriving the third data value based on the second cropped area image location.
24. The computer-implemented method of claim 21, wherein the first object has a non-rectangular shape in the first image; and wherein the detecting the first polygon in the second image comprises: determining a rectangular bounding box for the first polygon; implementing a you only look once (YOLO) detection algorithm on the rectangular bounding box; and identifying a non-rectangular shape in the second image corresponding to the non-rectangular shape in the first image.
25. The computer-implemented method of claim 21, wherein the predicting a predicted change in the first data value comprises applying a Kalman filter to generate a data table of uncertainties for estimates of the predicted change; and the computer-implemented method further comprises updating the estimates based on the third data value and a weighted average derived from the data table of uncertainties for predicting another data value different from the first data value and the third data value.
26. The computer-implemented method of claim 21, wherein the detecting the first polygon in the second images comprises: determining an additional boundary for the first object in the second image; generating a data set representing pixels within the first boundary and the additional boundary; labeling, in the data set, pixels within the additional boundary with a same identifier as pixels within the first boundary; and wherein the pixels within the additional boundary have a different pixel resolution or pixel coding than pixels within the first boundary.
27. The computer-implemented method of claim 21 further comprising: computing an actual change in the first data value to the third data value; comparing the actual change to the predicted change in the first data value for the second image; and based on the comparison of the actual change to the predicted change in the first data value for the second image, determining a velocity, acceleration, size, or orientation of the first polygon, or one or more data points within the first polygon, indicates to correct an operation of the system in operation.
28. The computer-implemented method of claim 21 further comprising: comparing the updated relative information to a predicted change for the relative information, wherein the predicted change for the relative information is based on the predicted change in the first data value for the second image and the predicted change in the second data value for the second image; and based on the comparison, triggering a control to correct the system in operation.
29. The computer-implemented method of claim 28, wherein the triggering a control comprises one or more of the following: sending an electronic notification to an operator of the system in operation; stopping the operation of the system in operation; augmenting the system in operation to correct for the operation; and selectively storing data related to a plurality of different objects in the plurality of images in storage for further analysis of the operation of the system in operation.
30. A computing system comprising processor and memory, the memory containing instructions executable by the processor wherein the computing system is configured to: obtain data representing a first image of a plurality of images, each of the plurality of images capturing different time points of a system in operation, the system in operation comprising a first object and a second object different from the first object; receive an indication of user-identified data points in a plurality of data points in the data representing the first image, wherein the indication indicates an image coordinate location for each of the user-identified data points in a first coordinate system associated with the first image, and wherein the user-identified data points identify the first object and the second object in the first image; determine, based on a first set of data points of the user-identified data points, a first boundary of the first object in the first image; determine, based on a second set of data points of the user-identified data points, a second boundary of the second object in the first image; identify a first polygon defined by the first boundary, the first polygon representing the first object in the system in operation; identify a second polygon defined by the second boundary, the second polygon representing the second object in the system in operation; generate a first component of a dataset, the first component representing initial relative information between the first object and the second object, by: computing a first data value related to an attribute of a key point of the first set of data points in the first image; computing a second data value related to an attribute of a key point of the second set of data points in the first image; generating, based on the first data value and the second data value, the initial relative information between the first object and the second object; generate a second component of the dataset, the second component representing updated relative information between the first object and the second object, by: obtaining data representing a second image of the plurality of images subsequent to the first image; detecting the first polygon and the second polygon in the second image; determining one or more data points in the first polygon in the second image; determining one or more data points in the second polygon in the second image; generating a predicted change in the first data value for the second image; generating a predicted change in the second data value for the second image; computing a third data value related to a data point of the one or more data points in the first polygon in the second image, the data point corresponding to the key point of the first set of data points in the first image; computing a fourth data value related to a data point of the one or more data points in the second polygon in the second image, the data point corresponding to the key point of the second set of data points in the first image; generating the updated relative information between the first object and the second object, wherein the generating the updated relative information is based on the predicted change in the first data value, the predicted change in the second data value, the third data value, and the fourth data value; and output one or more components of the dataset.
</claims>
</document>
