<document>

<filing_date>
2018-12-24
</filing_date>

<publication_date>
2020-01-28
</publication_date>

<priority_date>
2012-08-31
</priority_date>

<ipc_classes>
B25J9/16,B60K11/02,F01P11/16,F01P3/20,F01P7/16,G01N1/22,G01N1/44,G01N30/72,G01N33/00,G01N35/00,G05B19/42
</ipc_classes>

<assignee>
GO PRO
</assignee>

<inventors>
MEIER, PHILIP
</inventors>

<docdb_family_id>
54434461
</docdb_family_id>

<title>
Apparatus and methods for controlling attention of a robot
</title>

<abstract>
A method includes receiving, from an imaging device associated with a robotic apparatus, an image signal including an object of interest represented in the image signal; receiving, by the robotic apparatus from an external agent, a task indication related to the object of interest, the task indication representative of a task to be performed by the robotic apparatus with respect to the object of interest; and responsive to receipt of the task indication: detecting salient features of the object of interest within the image; storing, by the robotic apparatus, a task context, the task context comprising data pertaining to the salient features and data pertaining to the task indication; and commencing, by the robotic apparatus, the task with respect to the object of interest.
</abstract>

<claims>
1. A method, comprising: receiving, from an imaging device associated with a robotic apparatus, an image signal including an object of interest represented in the image signal; receiving, by the robotic apparatus from an external agent, a task indication related to the object of interest, the task indication representative of a task to be performed by the robotic apparatus with respect to the object of interest; and responsive to receipt of the task indication: storing, by the robotic apparatus, a task context, the task context comprising data pertaining to the task indication and being configured to cause the robotic apparatus to perform the task; commencing, by the robotic apparatus, the task with respect to the object of interest; and providing, by the robotic apparatus to the external agent, a confirmation signal that the robotic apparatus has commenced task execution.
2. The method of claim 1, wherein the task includes at least one of approaching the object of interest, exploring an area of interest around the object of interest, or capturing an image of the object of interest.
3. The method of claim 1, wherein the task indication is provided by the external agent through physical input to an input/output interface and comprises a touch-screen input, a speech input, a single click input to a button, or a double click input to the button.
4. The method of claim 1, wherein the confirmation signal includes a feedback indicator configured to provide the external agent confirmation that the task context was received by the robotic apparatus and wherein the feedback indicator comprises at least one of a vibration, an audible indication, and a visual indication.
5. A method, comprising: receiving, from an imaging device associated with a robotic apparatus, an image signal including an object of interest represented in the image signal; receiving, by the robotic apparatus from an external agent, a task indication related to the object of interest, the task indication representative of a task to be performed by the robotic apparatus with respect to the object of interest; and responsive to receipt of the task indication: detecting salient features of the object of interest within the image signal; storing, by the robotic apparatus, a task context, the task context comprising data pertaining to the salient features and being configured to cause the robotic apparatus to perform the task; and commencing, by the robotic apparatus, the task with respect to the object of interest.
6. The method of claim 5, wherein the task includes at least one of approaching the object of interest, exploring an area of interest around the object of interest, or capturing an image of the object of interest.
7. The method of claim 5, wherein the task indication includes an encoded task identifier that is detectable within the image signal.
8. The method of claim 5, wherein the task indication is irradiation of the object of interest by a beam of visible or invisible electromagnetic radiation.
9. The method of claim 5, wherein the task indication includes a task identifier in the form of a physical input executed by the external agent.
10. The method of claim 9, wherein the physical input comprises a touch-screen input, a speech input, a single click input to a button, or a double click input to the button.
11. The method of claim 5, wherein the salient features are detected using processing techniques comprising at least one of contrast enhancement, edge tracing, spectral transforms, spatial transforms, and spatio-temporal methodologies.
12. The method of claim 5, wherein data pertaining to the salient features includes a size of the salient features and a location of the salient features within the image signal.
13. The method of claim 5, responsive to receipt of the task indication, further comprising: providing, by the robotic apparatus to the external agent, a confirmation signal that the robotic apparatus has commenced task execution.
14. The method of claim 13, wherein the confirmation signal includes a feedback indicator configured to provide the external agent confirmation that the task context was received by the robotic apparatus.
15. The method of claim 14, wherein the feedback indicator comprises at least one of a vibration, an audible indication, and a visual indication.
16. The method of claim 15, wherein the visual indication includes at least one of an LED light and an indication visible to the external agent on a mini-display.
17. An interface apparatus for a robot operable in an environment, comprising: an input interface that receives a sequence of images of the environment; and an input/output interface that receives a physical input executed by an external agent, wherein the physical input identifies a task to perform in reference to an object of interest present in the sequence of images of the environment, and wherein the physical input provides a specific robotic context configured to cause the robot to perform the task using previous training for the task over a plurality of different contexts.
18. The interface apparatus of claim 17, wherein the task includes at least one of approaching the object of interest, exploring an area of interest around the object of interest, or capturing an image of the object of interest.
19. The interface apparatus of claim 17, wherein the physical input comprises a touch-screen input, a speech input, a single click input to a button, or a double click input to the button.
20. The interface apparatus of claim 17, wherein the input/output interface includes a feedback indicator configured to provide the external agent confirmation that the robot has commenced task execution.
</claims>
</document>
