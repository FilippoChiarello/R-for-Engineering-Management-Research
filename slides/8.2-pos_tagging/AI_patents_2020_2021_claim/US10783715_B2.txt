<document>

<filing_date>
2018-01-11
</filing_date>

<publication_date>
2020-09-22
</publication_date>

<priority_date>
2017-01-11
</priority_date>

<ipc_classes>
G06T15/20,G06T19/00,G06T5/00
</ipc_classes>

<assignee>
ELBIT SYSTEMS
</assignee>

<inventors>
LIVNEH, OFER
</inventors>

<docdb_family_id>
61028131
</docdb_family_id>

<title>
Augmented reality display reflective of visibility affecting features in real-world environment
</title>

<abstract>
Method and system for displaying augmented reality reflective of environmental features affecting visibility. Characteristics of a virtual object to be displayed on view of scene is determined. Environmental features affecting visibility along a line-of-sight from scene origin to virtual object are detected. When detected feature is at least one non-obstructing feature, its effect on visibility is determined, and virtual object is displayed superimposed onto view of scene such that appearance of virtual object is consistent with determined effect on visibility. When detected feature includes an amorphous obstructing feature, its range and contour is determined, and obstructed portions of virtual object is determined based on difference between range of virtual object and range of amorphous obstructing feature, and virtual object is displayed superimposed onto view of scene such that determined obstructed portions of virtual object appear obstructed in displayed view.
</abstract>

<claims>
1. A method for displaying augmented reality reflective of environmental features affecting visibility, the method comprising the procedures of: determining characteristics of at least one virtual object to be displayed on a view of a scene; detecting at least one visibility affecting environmental feature at the scene present along a line-of-sight (LOS) between the scene origin to the virtual object; when the detected feature comprises a non-obstructing feature, determining the effect on visibility due to the non-obstructing feature present along the LOS between the scene origin to the virtual object, and displaying the virtual object superimposed onto a view of the scene such that the appearance of the virtual object in the displayed view is consistent with the determined effect on visibility as perceived from the scene origin; and when the detected feature comprises an amorphous obstructing feature continuously moving and changing form, determining the range and the contour of the amorphous obstructing feature, determining obstructed portions of the virtual object based on the difference between the range of the virtual object and the range of the amorphous obstructing feature and based on the contour of the amorphous obstructing feature in relation to the virtual object, and displaying the virtual object superimposed onto a view of the scene such that the determined obstructed portions of the virtual object appear obstructed in the displayed view.
2. The method of claim 1, wherein the virtual object is displayed on an image of the scene.
3. The method of claim 1, wherein the virtual object is displayed on a see-through display overlaid onto a view of the scene.
4. The method of claim 1, wherein the non-obstructing feature comprising an amorphous non-obstructing feature.
5. The method of claim 1, wherein the virtual object is displayed with at least one visual attribute modified.
6. The method of claim 5, wherein the visual attribute is selected from the group consisting of: brightness; contrast; and color intensity.
7. The method of claim 1, wherein the environmental feature at the scene or the effect on visibility is determined using at least one source selected from the group consisting of: image processing; a comparison of different images of the scene; an examination of spectral properties of at least one image of the scene; information relating to the scene obtained from at least one sensor; a geographic information source; a weather/climate information source; a digital terrain model; a prediction model; a machine learning process; and a manual indication.
8. The method of claim 1, wherein determining the effect on visibility due to the non-obstructing feature comprises determining the effect of shadows in the scene, based on detected shadow casting elements and the relative location of at least one light source in the scene.
9. A system for displaying augmented reality reflective of environmental features affecting visibility, the system comprising: a processor, configured to determine characteristics of at least one virtual object to be displayed on a view of a scene, and to detect at least one visibility affecting environmental feature at the scene present along a LOS between the scene origin to the virtual object, and when the detected feature comprises a non-obstructing feature, the processor is further configured to determine the effect on visibility due to the non-obstructing feature present along the LOS between the scene origin to the virtual object, and when the detected feature comprises an amorphous obstructing feature continuously moving and changing form, the processor is further configured to determine the range and the contour of the amorphous obstructing feature, and to determine obstructed portions of the virtual object based on the difference between the range of the virtual object and the range of the amorphous obstructing feature and based on the contour of the amorphous obstructing feature in relation to the virtual object; and a display, configured to display the virtual object superimposed onto a view of the scene such that the appearance of the virtual object in the displayed view is consistent with the determined effect on visibility as perceived from the scene origin when the detected feature comprises a non-obstructing feature, the display further configured to display the virtual object superimposed onto a view of the scene such that the determined obstructed portions of the virtual object appear obstructed in the displayed view when the detected feature comprises an amorphous obstructing feature.
10. The system of claim 9, further comprising an image sensor, configured to capture an image of the scene, wherein the virtual object is displayed on the captured image.
11. The system of claim 9, wherein the display comprises a see-through display, configured to display the virtual object overlaid onto a view of the scene.
12. The system of claim 9, wherein the non-obstructing feature comprising an amorphous non-obstructing feature.
13. The system of claim 9, wherein the virtual object is displayed with at least one visual attribute modified.
14. The system of claim 13, wherein the visual attribute is selected from the group consisting of: brightness; contrast; and color intensity.
15. The system of claim 9, wherein the environmental feature at the scene or the effect on visibility is determined using at least one source selected from the group consisting of: image processing; a comparison of different images of the scene; an examination of spectral properties of an image of the scene; information relating to the scene obtained from at least one sensor; a geographic information source; a weather/climate information source; a digital terrain model; a prediction model; a machine learning process; and a manual indication.
16. The system of claim 9, wherein determining the effect on visibility due to the non-obstructing feature comprises determining the effect of shadows in the scene, based on detected shadow casting elements and the relative location of at least one light source in the scene.
17. The system of claim 9, further comprising at least one sensor, configured to detect information relating to environmental features in the scene.
18. The system of claim 9, further comprising a database, comprising information relating to environmental features in the scene.
19. The system of claim 9, wherein the image sensor is situated on a moving platform.
</claims>
</document>
