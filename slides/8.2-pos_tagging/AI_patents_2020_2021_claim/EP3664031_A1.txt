<document>

<filing_date>
2019-12-03
</filing_date>

<publication_date>
2020-06-10
</publication_date>

<priority_date>
2018-12-04
</priority_date>

<ipc_classes>
G06T7/579
</ipc_classes>

<assignee>
HERE GLOBAL
</assignee>

<inventors>
VISWANATHAN, ANIRUDH
</inventors>

<docdb_family_id>
68766622
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR PROVIDING FEATURE TRIANGULATION
</title>

<abstract>
An approach is provided for feature triangulation from images. The approach includes retrieving the plurality of images, wherein the plurality of images is captured by a sensor of a vehicle during a drive; determining a vehicle trajectory of the vehicle during the drive; selecting a first image and a second image from the plurality of images, wherein the first image and second image are arranged in reverse time order based on respective image capture times determined using the vehicle trajectory; after detecting the feature in the first image, processing the second image to detect the feature and to associate the feature as detected in the second image with the feature previously detected in the first image; and processing the detected feature in the first image and the second image to triangulate the location of the feature.
</abstract>

<claims>
1. A method for triangulating a location of a feature from a plurality of images, the method comprising: retrieving the plurality of images, wherein the plurality of images is captured by a sensor of a vehicle during a drive; determining a vehicle trajectory of the vehicle during the drive; selecting a first image and a second image from the plurality of images, wherein the first image and second image are arranged in reverse time order based on respective image capture times determined using the vehicle trajectory; after detecting the feature in the first image, processing the second image to detect the feature and to associate the feature as detected in the second image with the feature previously detected in the first image; and processing the detected feature in the first image and the second image to triangulate the location of the feature.
2. The method of claim 1, wherein the location of the feature is triangulated based on sensor pose data for the first image and the second image, and respective image locations of the detected feature in the first image frame and the second image frame.
3. The method of claim 2, wherein the processing of the detected feature in the first image and the second image comprises calculating a parallax value, and wherein the feature is further triangulated based on the parallax value.
4. The method of claim 1, wherein a first image size of the feature in the first image is larger than a second image size of the feature in the second image.
5. The method of claim 1, wherein a first image position of the feature in the first image is closer to an image edge than a second image position of the feature in the second image.
6. The method of claim 1, wherein the vehicle trajectory indicates that the vehicle is traveling towards the feature during the drive.
7. The method of claim 2, wherein the sensor is a camera sensor, and wherein the sensor pose data indicates a camera position, a camera pointing direction, a camera field of view, or a combination thereof.
8. The method of claim 1, wherein the vehicle trajectory is a time-ordered sequence of location probe points determined by a location sensor of the vehicle.
9. The method of claim 1, wherein the feature comprises a fixture positioned along a side of a roadway.
10. The method of claim 9, wherein the feature comprises a road sign or traffic light.
11. An apparatus for triangulating a location of a feature from a plurality of images comprising: at least one processor; and at least one memory including computer program code for one or more programs, the at least one memory and the computer program code configured to, with the at least one processor, cause the apparatus to perform at least the following, retrieve the plurality of images, wherein the plurality of images is captured by a sensor of a vehicle during a drive; determine a vehicle trajectory of the vehicle during the drive; select a first image and a second image from the plurality of images, wherein the first image and second image are arranged in reverse time order based on respective image capture times determined using the vehicle trajectory; after detecting the feature in the first image, process the second image to detect the feature and to associate the feature as detected in the second image with the feature previously detected in the first image; and processing the detected feature in the first image and the second image to triangulate the location of the feature.
12. The apparatus of claim 11, wherein the location of the feature is triangulated based on sensor pose data for the first image and the second image, and respective image locations of the detected feature in the first image frame and the second image frame.
13. The apparatus of claim 12, wherein the processing of the detected feature in the first image and the second image comprises calculating a parallax value, and wherein the feature is further triangulated based on the parallax value.
14. The apparatus of claim 11, wherein a first image size of the feature in the first image is larger than a second image size of the feature in the second image.
15. A non-transitory computer-readable storage medium for determining a feature correspondence between image views, carrying one or more sequences of one or more instructions which, when executed by one or more processors, cause an apparatus to perform: retrieving the plurality of images, wherein the plurality of images is captured by a sensor of a vehicle during a drive; determining a vehicle trajectory of the vehicle during the drive; selecting a first image and a second image from the plurality of images, wherein the first image and second image are arranged in reverse time order based on respective image capture times determined using the vehicle trajectory; after detecting the feature in the first image, processing the second image to detect the feature and to associate the feature as detected in the second image with the feature previously detected in the first image; and processing the detected feature in the first image and the second image to triangulate the location of the feature.
</claims>
</document>
