<document>

<filing_date>
2020-05-14
</filing_date>

<publication_date>
2020-11-19
</publication_date>

<priority_date>
2019-05-14
</priority_date>

<ipc_classes>
G10L13/033,G10L15/00,G10L15/06,G10L21/0224
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
LIU WEI
LIU SONG
ZHANG FAN
TU, MEI
</inventors>

<docdb_family_id>
73228353
</docdb_family_id>

<title>
METHOD, APPARATUS, ELECTRONIC DEVICE, AND COMPUTER READABLE STORAGE MEDIUM FOR VOICE TRANSLATION
</title>

<abstract>
A method for voice translation includes: receiving a voice signal of a first language; obtaining a plurality of voice segments forming the voice signal; determining integrity of a first voice segment with respect to a second voice segment based on a voice feature of the first voice segment and a voice feature of the second voice segment; obtaining an output voice segment based on the integrity of the first voice segment with respect to the second voice segment; and outputting a text in a second language corresponding to the voice signal of the first language based on the output voice segment.
</abstract>

<claims>
1. A method for voice translation, the method comprising: receiving a voice signal of a first language; obtaining a plurality of voice segments forming the voice signal; determining integrity of a first voice segment with respect to a second voice segment based on a voice feature of the first voice segment and a voice feature of the second voice segment; obtaining an output voice segment based on the integrity of the first voice segment with respect to the second voice segment; and outputting a text in a second language corresponding to the voice signal of the first language based on the output voice segment.
2. The method of claim 1, wherein the first voice segment is a voice segment prior to the second voice segment in a time sequence.
3. The method of claim 1, wherein the integrity of the first voice segment comprises semantic integrity of the first voice segment.
4. The method of claim 3, wherein the semantic integrity of the first voice segment indicates the first voice segment constitute a full sentence.
5. The method of claim 1, wherein the integrity of the first voice segment is associated with a probability of the integrity of the first voice segment.
6. The method of claim 1, wherein the output voice segment is a translation unit for translating the first language into the second language.
7. The method of claim 1, wherein the output voice segment includes the first voice segment and the second voice segment.
8. The method of claim 1, wherein the first voice segment and the second voice segment are combined as the output voice segment.
9. The method of claim 8, wherein the voice feature of the first voice segment and the voice feature of the second voice segment are combined to determine a feature vector based on the combined output voice segment
10. The method of claim 1, wherein the first voice segment is a starting voice segment.
11. The method of claim 1, wherein the outputting the text in the second language corresponding to the voice signal of the first language based on the output voice segment comprises: combining a first text in the second language corresponding to the first voice segment and a second text in the second language corresponding to the second voice segment; and outputting the text of the second language based on performing correction on the combined first and second texts in the second language.
12. The method of claim 1, wherein the output voice segment is dependent on both of the first voice segment and the second voice segment when the integrity of the first voice segment is less than a threshold.
13. The method of claim 1, wherein the output voice segment is independent of the first voice segment when the integrity of the first voice segment is equal to or greater than a threshold.
14. The method of claim 1, further comprising determining a voice length of the first voice segment, wherein the obtaining the output voice segment comprises obtaining the output voice segment based on the voice length of the first voice segment.
15. The method of claim 1, further comprising determining voice speed of the first voice segment, wherein the obtaining the output voice segment comprises obtaining the output voice segment based on the voice speed of the first voice segment.
16. The method of claim 1, wherein the integrity of the first voice segment with respect to the second voice segment is determined based on a first neural layer for the first voice segment and a second neural layer for the second voice segment, and wherein the first neural layer is different from the second neural layer.
17. The method of claim 16, the first neural layer and the second neural layer is generated based on training translation data.
18. The method of claim 1, wherein the voice feature of the first voice segment is extracted from the first voice segment, and the voice feature of the second voice segment is extracted from the second voice segment.
19. An apparatus for voice translation comprising: a memory storing instructions; and at least one processor configured to, based on the instructions, to: receive a voice signal of a first language; obtain a plurality of voice segments forming the voice signal; determine integrity of a first voice segment with respect to a second voice segment based on a voice feature of the first voice segment and a voice feature of the second voice segment; obtain an output voice segment based on the integrity of the first voice segment with respect to the second voice segment; and output a text in a second language corresponding to the voice signal of the first language based on the output voice segment.
20. A computer program product comprising a non-transitory computer readable medium comprising instructions, which when executed by at least one processor, cause the at least one processor to carry out the method of claim 1.
</claims>
</document>
