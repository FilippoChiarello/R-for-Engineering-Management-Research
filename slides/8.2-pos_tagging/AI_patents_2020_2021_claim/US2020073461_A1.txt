<document>

<filing_date>
2018-08-29
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2018-08-29
</priority_date>

<ipc_classes>
G06F1/32,G06N3/02,G06T1/20
</ipc_classes>

<assignee>
AMD (ADVANCED MICRO DEVICES)
</assignee>

<inventors>
SADOWSKI, GREG
</inventors>

<docdb_family_id>
69642260
</docdb_family_id>

<title>
NEURAL NETWORK POWER MANAGEMENT IN A MULTI-GPU SYSTEM
</title>

<abstract>
Systems, apparatuses, and methods for managing power consumption for a neural network implemented on multiple graphics processing units (GPUs) are disclosed. A computing system includes a plurality of GPUs implementing a neural network. In one implementation, the plurality of GPUs draw power from a common power supply. To prevent the power consumption of the system from exceeding a power limit for long durations, the GPUs coordinate the scheduling of tasks of the neural network. At least one or more first GPUs schedule their computation tasks so as not to overlap with the computation tasks of one or more second GPUs. In this way, the system spends less time consuming power in excess of a power limit, allowing the neural network to be implemented in a more power efficient manner.
</abstract>

<claims>
1. A system comprising: a plurality of processing units; and one or more links between the plurality of processing units; wherein each processing unit of the plurality of processing units is configured to perform a computing task; and wherein at least one processing unit is configured to change a time at which a given computing task is performed with respect to tasks being performed by other processing units, responsive to detecting a first condition.
2. The system as recited in claim 1, wherein the first condition is at least one of: a power limit being exceeded; and a number of processing units which share a computing task phase alignment is greater than a threshold.
3. The system as recited in claim 1, wherein the computing task performed by each of the plurality of processing units comprises a same algorithm.
4. The system as recited in claim 1, wherein the change in time implemented by the at least one processing unit comprises delaying processing of the given computing task to a later time.
5. The system as recited in claim 4, wherein the later time is selected to coincide with a period of higher power consumption by a computing task being performed by a processing unit other than the at least one processing unit.
6. The system as recited in claim 5, wherein the plurality of processing units are implementing at least one of a machine learning model and a neural network.
7. The system as recited in claim 1, wherein each of the plurality of processing units communicate information comprising one or more of power consumption and task execution phases via one or more links.
8. A method comprising: performing, by each processing unit of a plurality of processing units, a computing task; changing, by at least one processing unit, a time at which a given computing task is performed with respect to tasks being performed by other processing units, responsive to detecting a first condition.
9. The method as recited in claim 8, wherein the first condition is at least one of: a power limit being exceeded; and a number of processing units which share a computing task phase alignment is greater than a threshold.
10. The method as recited in claim 8, wherein the computing task performed by each of the plurality of processing units comprises a same algorithm.
11. The system as recited in claim 8, wherein changing the time by the at least one processing unit comprises delaying processing of the given computing task to a later time.
12. The method as recited in claim 11, further comprising selecting the later time to coincide with a period of higher power consumption by a computing task being performed by a processing unit other than the at least one processing unit.
13. The method as recited in claim 12, wherein the plurality of processing units are implementing at least one of a machine learning model and a neural network.
14. The method as recited in claim 8, wherein each of the plurality of processing units communicate information comprising one or more of power consumption and task execution phases via one or more links.
15. An apparatus comprising: a first processing unit; and a second processing unit; wherein the first processing unit is configured to: perform a first portion of a common computing task; receive power consumption data and task status from the second processing unit performing a second portion of the common computing task; and change a time at which a given computing task is performed with respect to a task being performed by the second processing unit, responsive to detecting a first condition.
16. The apparatus as recited in claim 15, wherein the first condition is at least one of: a power limit being exceeded; and a number of processing units which share a computing task phase alignment is greater than a threshold.
17. The apparatus as recited in claim 15, wherein the computing task performed by each of the first and second processing units comprises a same algorithm.
18. The apparatus as recited in claim 15, wherein the change in time implemented by the first processing unit comprises delaying processing of the given computing task to a later time.
19. The apparatus as recited in claim 18, wherein the later time is selected to coincide with a period of higher power consumption by a computing task being performed by the second processing unit.
20. The apparatus as recited in claim 15, wherein the change in time reduces an amount of a time during which total power consumption by the first and second processing units exceeds a power limit.
</claims>
</document>
