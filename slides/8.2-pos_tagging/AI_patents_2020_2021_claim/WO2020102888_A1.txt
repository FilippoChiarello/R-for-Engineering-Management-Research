<document>

<filing_date>
2019-11-18
</filing_date>

<publication_date>
2020-05-28
</publication_date>

<priority_date>
2018-11-19
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
TANDEMLAUNCH
</assignee>

<inventors>
ASKARIHEMMAT, MOHAMMADHOSSEIN
MASTROPIETRO, OLIVIER
SABOORI, EHSAN
SAWYER, DAVIS MANGAN
</inventors>

<docdb_family_id>
70773445
</docdb_family_id>

<title>
SYSTEM AND METHOD FOR AUTOMATED PRECISION CONFIGURATION FOR DEEP NEURAL NETWORKS
</title>

<abstract>
There is provided a system and method of automated precision configuration for deep neural networks. The method includes obtaining an input model and one or more constraints associated with an application and/or target device or process used in the application configured to utilize a deep neural network; learning an optimal low-precision configuration of the architecture using constraints, the training data set, and the validation data set; and deploying the optimal configuration on the target device or process for use in the application.
</abstract>

<claims>
1. A method of automated precision configuration for deep neural networks, the method comprising:
obtaining an input model and one or more constraints associated with an application and/or target device or process used in the application configured to utilize a deep neural network;
learning an optimal low-precision configuration of the optimal architecture using the input model, constraints, a training data set, and a validation data set; and
deploying the optimal configuration on the target device or process for use in the application.
2. The method of claim 1 , wherein the optimal configuration is learned using a policy to generate an optimized model from the input model.
3. The method of claim 2, wherein the optimal low-precision configuration of the optimal architecture is learned using the policy to generate a quantized network, the method further comprising:
fine tuning the quantized network with a knowledge distillation process;
evaluating the fine-tuned network;
applying a reward function; and
iterating for at least one additional quantized network and selecting the optimal lowprecision configuration.
4. The method of claim 3, wherein selecting the optimal low-precision configuration comprises selecting a precision configuration that achieves the best reward as determined by the reward function, for the constraints on the target device or process.
5. The method of any one of claims 1 to 4, wherein learning the optimal low-precision configuration comprises exploiting low precision weights using reinforcement learning to learn the optimal low-precision configuration across the deep neural network.
6. The method of claim 5, wherein each layer comprises a different precision.
7. The method of any one of claims 1 to 6, wherein the constraints comprise at least one of: accuracy, power, cost, supported precision, speed.
8. The method of claim 7, wherein a computation constraint comprises a bit budget.
9. The method of any one of claims 1 to 8, wherein the application is an artificial intelligence-based application.
10. A computer readable medium comprising computer executable instructions for automated design space exploration for deep neural networks, the computer executable instructions comprising instructions for performing the method of any one of claims 1 to 9.
1 1. A deep neural network optimization engine configured to perform automated design space exploration for deep neural networks, the engine comprising a processor and memory, the memory comprising computer executable instructions for performing the method of any one of claims 1 to 9.
</claims>
</document>
