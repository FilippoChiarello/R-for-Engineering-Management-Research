<document>

<filing_date>
2019-06-26
</filing_date>

<publication_date>
2020-12-31
</publication_date>

<priority_date>
2019-06-26
</priority_date>

<ipc_classes>
G06F7/48,G06F7/544
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
BOBROV, BORIS
WALL, LARRY MARVIN
PETRE, GEORGE
MCBRIDE, CHAD BALLING
AMBARDEKAR, Amol A.
CEDOLA, Kent D.
</inventors>

<docdb_family_id>
70919088
</docdb_family_id>

<title>
NEURAL PROCESSING ELEMENT WITH SINGLE INSTRUCTION MULTIPLE DATA (SIMD) COMPUTE LANES
</title>

<abstract>
An architecture is disclosed for an neural processing element having single instruction, multiple data ("SIMD") compute lanes. The neural processing element includes compute lanes having multipliers configured to multiply a binary operand with another binary operand to generate a binary output. The neural processing element also includes a single adder tree for summing the binary outputs of the hardware binary multipliers. The neural processing element also includes a storage element for storing a binary output of the single hardware binary adder tree.
</abstract>

<claims>
1. A deep neural network (DNN) processor, comprising: an even number of hardware binary multipliers, each of the hardware binary multipliers configured to multiply a first operand with a second operand to generate a binary output, and a single hardware binary adder tree for summing binary outputs of the hardware binary multipliers.
2. The deep neural network processor of claim 1, further comprising a storage element for storing a binary output of the single hardware binary adder tree.
3. The deep neural network processor of claim 1, wherein the first operand and the second operand comprise binary numbers having a number of bits equal to a power of two plus one.
4. The deep neural network processor of claim 1, wherein the binary outputs of the hardware binary multipliers comprise 18-bit binary numbers.
5. The deep neural network processor of claim 1, wherein a binary output of the single hardware binary adder tree comprises a 21-bit binary number.
6. The deep neural network processor of claim 1, wherein the single hardware binary adder tree comprises an even number of first hardware binary adders for summing the binary outputs of the hardware binary multipliers.
7. The deep neural network processor of claim 6, wherein outputs of the first hardware binary adders comprise 19-bit binary numbers.
8. The deep neural network processor of claim 6, wherein the single hardware binary adder tree comprises an even number of second hardware binary adders for summing outputs of the first hardware binary adders.
9. The deep neural network processor of claim 8, wherein outputs of the second hardware binary adders comprise 20-bit binary numbers.
10. The deep neural network processor of claim 8, wherein the single hardware binary adder tree comprises a third hardware binary adder for summing outputs of the second hardware binary adders.
11. The deep neural network processor of claim 9, wherein an output of the third hardware binary adder comprises a 21-bit binary number.
12. A processing system, comprising: a deep neural network (DNN) processor comprising at least one neural processing element, the at least one neural processing element comprising: eight hardware binary multipliers, each of the hardware binary multipliers configured to multiply a first operand with a second operand to generate a binary output, and a single hardware binary adder tree configured to sum binary outputs of the eight hardware binary multipliers.
13. The processing system of claim 12, wherein the first operand and the second operand comprise 9-bit binary numbers and wherein the binary outputs of the eight hardware binary multipliers comprise 18-bit binary numbers.
14. The processing system of claim 13, wherein the single hardware binary adder tree comprises an even number of first hardware binary adders for summing the binary outputs of the eight hardware binary multipliers and wherein outputs of the first hardware binary adders comprise 19-bit binary numbers.
15. The processing system of claim 14, wherein the single hardware binary adder tree further comprises an even number of second hardware binary adders for summing outputs of the first hardware binary adders and wherein outputs of the second hardware binary adders comprise 20-bit binary numbers.
16. The processing system of claim 15, wherein the single hardware binary adder tree further comprises a third hardware binary adder for summing outputs of the second hardware binary adders and wherein an output of the third hardware binary adder comprises a 21-bit binary number.
17. The processing system of claim 16, wherein the at least one neural processing element further comprises a storage element for storing the output of the third hardware binary adder.
18. A deep neural network (DNN) processor, comprising: a plurality of neural processing elements, each of the plurality of neural processing elements comprising an even number of hardware binary multipliers configured to multiply a first 9-bit binary operand with a second 9-bit binary operand to generate an 18-bit binary output, a single hardware binary adder tree configured to sum the 18-bit binary outputs of the hardware binary multipliers to generate a 21-bit binary output, and a storage element configured to store the 21-bit binary output of the single hardware binary adder tree.
19. The DNN processor of claim 18, wherein the single hardware binary adder tree comprises: four first hardware binary adders configured to sum the 18-bit binary outputs of the hardware binary multipliers; and two second hardware binary adders configured to sum binary outputs of the four first hardware binary adders.
20. The DNN processor of claim 19, wherein the single hardware binary adder tree further comprises a third hardware binary adder configured to sum binary outputs of the two second hardware binary adders to generate the 21-bit binary output of the single hardware binary adder tree and to store the 21-bit binary output of the single hardware binary adder tree in the storage element.
</claims>
</document>
