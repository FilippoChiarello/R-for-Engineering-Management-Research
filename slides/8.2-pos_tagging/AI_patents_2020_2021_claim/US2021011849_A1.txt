<document>

<filing_date>
2020-09-29
</filing_date>

<publication_date>
2021-01-14
</publication_date>

<priority_date>
2019-04-01
</priority_date>

<ipc_classes>
G06F12/06,G06F13/28
</ipc_classes>

<assignee>
WAVE COMPUTING
</assignee>

<inventors>
SIMPSON, DAVID JOHN
JOHNSON, STEPHEN CURTIS
Trauben, Richard Douglas
</inventors>

<docdb_family_id>
74101915
</docdb_family_id>

<title>
PROCESSOR CLUSTER ADDRESS GENERATION
</title>

<abstract>
Techniques for data manipulation using processor cluster address generation are disclosed. One or more processor clusters capable of executing software-initiated work requests are accessed. A plurality of dimensions from a tensor is flattened into a single dimension. A work request address field is parsed, where the address field contains unique address space descriptors for each of the plurality of dimensions, along with a common address space descriptor. A direct memory access (DMA) engine coupled to the one or more processor clusters is configured. Addresses are generated based on the unique address space descriptors and the common address space descriptor. The plurality of dimensions can be summed to generate a single address. Memory is accessed using two or more of the addresses that were generated. The addresses are used to enable DMA access.
</abstract>

<claims>
1. A processor-implemented method for data manipulation comprising: accessing one or more processor clusters capable of executing software-initiated work requests; flattening a tensor having a plurality of dimensions into a single dimension; parsing a work request address field, wherein the address field contains unique address space descriptors for each of the plurality of dimensions of the tensor along with a common address space descriptor; generating addresses, based on the unique address space descriptors and the common address space descriptor; and accessing memory, using two or more of the addresses that were generated.
2. The method of claim 1 further comprising configuring a direct memory access (DMA) engine coupled to the one or more processor clusters.
3. The method of claim 2 further comprising jumping an address offset within a flattened dimensional space based on the flattening.
4. The method of claim 3 wherein the address offset is based on a DMA dimension.
5. The method of claim 3 further comprising jumping a second address offset within the flattened dimensional space.
6. The method of claim 5 wherein the second address offset is based on a second DMA dimension.
7. The method of claim 2 wherein the addresses are used to enable DMA access.
8. The method of claim 1 further comprising summing across the plurality of dimensions to generate a single address.
9. The method of claim 1 wherein the plurality of dimensions includes four dimensions.
10. The method of claim 9 wherein the plurality of dimensions does not include channels.
11. The method of claim 10 further comprising summing across channels as part of a convolution operation.
12. The method of claim 1 further comprising using five dimensions to read results of the flattening.
13. The method of claim 12 wherein the results of the flattening comprise a two-dimensional object.
14. The method of claim 12 wherein the five dimensions include height√ówidth within a first dimension.
15. The method of claim 14 wherein channels comprise a second dimension.
16. The method of claim 15 wherein the channels comprise RGB information.
17. The method of claim 15 wherein batch size comprises a third dimension.
18. The method of claim 1 wherein the generating comprises establishing five programming loops to accomplish five-dimensional (5-D) address generation.
19. The method of claim 18 wherein the 5-D address generation enables a convolution to be performed on a matrix multiply engine.
20. The method of claim 18 wherein the 5-D address is a portion of a larger dimensional address.
21. The method of claim 18 wherein an innermost dimension is defined by hardware.
22. 22-32. (canceled)
33. A computer program product embodied in a non-transitory computer readable medium for data manipulation, the computer program product comprising code which causes one or more processors to perform operations of: accessing one or more processor clusters capable of executing software-initiated work requests; flattening a tensor having a plurality of dimensions into a single dimension; parsing a work request address field, wherein the address field contains unique address space descriptors for each of the plurality of dimensions of the tensor along with a common address space descriptor; generating addresses, based on the unique address space descriptors and the common address space descriptor; and accessing memory, using two or more of the addresses that were generated.
34. A computer system for data manipulation comprising: a memory which stores instructions; one or more processors coupled to the memory wherein the one or more processors, when executing the instructions which are stored, are configured to: access one or more processor clusters capable of executing software-initiated work requests; flatten a tensor having a plurality of dimensions into a single dimension; parse a work request address field, wherein the address field contains unique address space descriptors for each of the plurality of dimensions of the tensor along with a common address space descriptor; generate addresses, based on the unique address space descriptors and the common address space descriptor; and access memory, using two or more of the addresses that were generated.
</claims>
</document>
