<document>

<filing_date>
2019-12-04
</filing_date>

<publication_date>
2020-12-22
</publication_date>

<priority_date>
2019-12-04
</priority_date>

<ipc_classes>
G02B27/00,G02B27/01,G06F3/01,G06T19/00
</ipc_classes>

<assignee>
FACEBOOK TECHNOLOGY COMPANY
</assignee>

<inventors>
LANSEL, STEVEN PAUL
SAN AGUSTIN LOPEZ, JAVIER
SZTUK, SEBASTIAN
</inventors>

<docdb_family_id>
73823577
</docdb_family_id>

<title>
Predictive eye tracking systems and methods for variable focus electronic displays
</title>

<abstract>
Various aspects of the subject technology relate to prediction of eye movements of a user of a head-mountable display device. Predictive foveated display systems and methods, using the predicted eye movements are also disclosed. Predictive variable focus display systems and methods using the predicted eye movements are also disclosed. Predicting eye movements may include predicting a future gaze location and/or predicting a future vergence plane for the user's eyes, based on the current motion of one or both of the user's eyes. The predicted gaze location may be used to pre-render a foveated display image frame with a high-resolution region at the predicted gaze location. The predicted vergence plane may be used to modify an image plane of a display assembly to mitigate or avoid a vergence/accommodation conflict for the user.
</abstract>

<claims>
1. A head-mountable display device, comprising: a housing; a display assembly within the housing, the display assembly comprising: a display panel; an optical block comprising at least one optical element configured to focus display light from the display panel; and one or more eye tracking units configured to obtain eye tracking data; an eye tracking module configured to apply the eye tracking data to a saccade model, a smooth-pursuit model, a vestibulo-ocular model, and a vergence model to identify a type of an eye movement from among a plurality of types of eye movements including a saccade movement, a smooth pursuit movement, a vestibulo-ocular movement, a vergence movement, or a combination of one or more of the saccade movement, the smooth pursuit movement, the vestibulo-ocular movement, or the vergence movement; an eye prediction module configured to generate a predicted future vergence plane based on the identified type of eye movement; and a varifocal actuation block configured to adjust at least one of the display panel or a component of the optical block based on the predicted future vergence plane.
2. The head-mountable display device of claim 1, wherein the varifocal actuation block is configured to adjust the at least one of the display panel or the component of the optical block based on the predicted future vergence plane during the eye movement.
3. The head-mountable display device of claim 2, wherein the varifocal actuation block is configured to move an image plane, by the adjustment of the at least one of the display panel or the component of the optical block.
4. The head-mountable display device of claim 3, further comprising a vergence processing module configured to determine a predicted zone of comfort based on the predicted future vergence plane, and wherein the varifocal actuation block is configured to move the image plane into the predicted zone of comfort, by the adjustment of the at least one of the display panel or the component of the optical block.
5. The head-mountable display device of claim 4, wherein the predicted zone of comfort comprises a first edge and a second edge, wherein the first edge is closer to a current image plane of the display assembly than the current image plane is to the second edge, and wherein the varifocal actuation block is configured to move the image plane into the predicted zone of comfort by moving the image plane to the first edge of the zone of comfort.
6. The head-mountable display device of claim 4, wherein the zone of comfort extends 1.5 diopters from each side of the predicted future vergence plane.
7. The head-mountable display device of claim 4, wherein the eye prediction module is further configured to generate a vergence plane confidence level for the predicted future vergence plane.
8. The head-mountable display device of claim 7, wherein the vergence processing module is configured to determine the predicted zone of comfort based, in part, on the vergence plane confidence level.
9. A method, comprising: obtaining eye tracking data for a user of a head-mountable display device having a display panel and an optical block for the display panel; determining a current direction and speed of an eye movement, based on the eye tracking data; applying the current direction and speed of the eye movement to a saccade model, a smooth-pursuit model, a vestibulo-ocular model, and a vergence model to identify a type of the eye movement from among a plurality of types of eye movements including a saccade movement, a smooth pursuit movement, a vestibulo-ocular movement, a vergence movement, or a combination of one or more of the saccade movement, the smooth pursuit movement, the vestibulo-ocular movement, or the vergence movement; generating a predicted future vergence plane based on the identified type of eye movement; and adjusting at least one of the display panel or a component of the optical block based on the predicted future vergence plane.
10. The method of claim 9, wherein the optical block comprises a pair of pancake lenses, and wherein adjusting the at least one of the display panel or a component of the optical block based on the predicted future vergence plane comprises modifying a position or a shape of one of each of the pairs of pancake lenses.
11. The method of claim 9, wherein adjusting the at least one of the display panel or a component of the optical block based on the predicted future vergence plane comprises adjusting the at least one of the display panel or the component of the optical block based on the predicted future vergence plane before a left eye and a right eye of the user verge at the predicted future vergence plane.
12. The method of claim 9, wherein generating the predicted future vergence plane comprises: determining that the eye movement is a vergence movement; and generating the predicted future vergence plane based on the current direction and speed of the eye movement and a vergence model of the eye movement.
13. The method of claim 9, further comprising: identifying a static vergence plane after adjusting the at least one of the display panel or the component of the optical block based on the predicted future vergence plane; and further adjusting the at least one of the display panel or the component of the optical block based on the static vergence plane.
14. The method of claim 9, further comprising: generating a predicted future gaze location based on the current direction and speed of the eye movement; and generating a foveated display image frame for display by the display panel, based on the predicted future gaze location.
15. The method of claim 14, further comprising blurring a portion of the foveated display image frame based on the predicted future vergence plane.
16. A method of operating a head-mountable display system having a head-mountable display device that includes a display panel, an optical block configured to focus display light from the display panel, and left and right eye tracking units, the method comprising: obtaining, with an eye prediction module of the head-mountable display system, eye tracking data from the left and right eye tracking units; determining, with the eye prediction module: a first predicted gaze location based on the eye tracking data and a saccade model of an eye movement, a second predicted gaze location based on the eye tracking data and a smooth-pursuit model of the eye movement, a third predicted gaze location based on the eye tracking data and a vestibulo-ocular model of the eye movement, and a predicted vergence plane based on the eye tracking data and a vergence model of the eye movement.
17. The method of claim 16, wherein generating the first predicted gaze location, the second predicted gaze location, the third predicted gaze location, and the predicted vergence plane comprises concurrently generating the first predicted gaze location, the second predicted gaze location, the third predicted gaze location, and the predicted vergence plane.
18. The method of claim 17, further comprising determining, with the eye prediction module: a first gaze location confidence level based on the eye tracking data and the saccade model of the eye movement, a second gaze location confidence level based on the eye tracking data and the smooth-pursuit model of the eye movement, a third gaze location confidence level based on the eye tracking data and the vestibulo-ocular model of the eye movement, and a vergence location confidence level based on the eye tracking data and the vergence model of the eye movement.
19. The method of claim 18, further comprising outputting, from the eye prediction module, the first predicted gaze location, the second predicted gaze location, the third predicted gaze location, or the predicted vergence plane, based on the first gaze location confidence level, the second gaze location confidence level, the third gaze location confidence level, and the vergence location confidence level.
20. The method of claim 19, wherein outputting, from the eye prediction module, the first predicted gaze location, the second predicted gaze location, the third predicted gaze location, or the predicted vergence plane, based on the first gaze location confidence level, the second gaze location confidence level, the third gaze location confidence level, and the vergence location confidence level comprises comparing each of the first gaze location confidence level, the second gaze location confidence level, the third gaze location confidence level, and the vergence location confidence level to a threshold.
</claims>
</document>
