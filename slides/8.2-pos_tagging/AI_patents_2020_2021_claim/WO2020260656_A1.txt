<document>

<filing_date>
2020-06-26
</filing_date>

<publication_date>
2020-12-30
</publication_date>

<priority_date>
2019-06-26
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08
</ipc_classes>

<assignee>
FRAUNHOFER
</assignee>

<inventors>
WIEGAND, THOMAS
SEEGERER, PHILIPP
MÃœLLER, KLAUS-ROBERT
SAMEK, WOJCIECH
WIEDEMANN, SIMON
LAPUSCHKIN, SEBASTIAN
YEOM, Seul-Ki
</inventors>

<docdb_family_id>
67070767
</docdb_family_id>

<title>
PRUNING AND/OR QUANTIZING MACHINE LEARNING PREDICTORS
</title>

<abstract>
Pruning and/or quantizing a machine learning predictor or, in other words, a machine learning model such as a neural network is rendered more efficient if the pruning and/or quantizing is performed using relevance scores which are determined for portions of the machine learning predictor on the basis of an activation of the portions of the machine learning predictor manifesting itself in one or more inferences performed by the machine learning (ML) predictor.
</abstract>

<claims>
1. Apparatus for pruning and/or quantizing of a machine learning (ML) predictor (10), the apparatus being configured to determine (34) relevance scores (44) for portions of the ML predictor (10) on the basis of an activation (40; 42) of the portions of the ML predictor (10) manifesting itself in one or more inferences performed by the ML predictor (10), pruning and/or quantizing (36) the ML predictor (10) using the relevance scores
(44).
2. Apparatus of claim 1 , configured to use a pruned and/or quantized version (46) of the ML predictor which results from the pruning and/or quantizing, to perform one or more further inferences, and recursively repeat the determining (34) the relevance scores and the pruning and/or quantizing (36) on the basis of an activation of the portions of the ML predictor manifesting itself in the one or more further inferences.
3. Apparatus of claim 1 or 2, configured to subject (80) a non-pruned-away and/or not quantized to zero portion of the ML predictor which results from pruning and/or quantizing, to training using training data.
4. Apparatus of any of claims 1 to 3, wherein the ML predictor (10) comprises nodes (14, 18, 20) and node interconnections (22, 24) and the apparatus is configured to determine the relevance scores for the nodes and/or the node interconnections of the ML predictor by back propagating an initial relevance score at an output of the ML predictor by distributing a relevance score at a predetermined node (20) of the ML predictor onto predecessor nodes of the predetermined node according to fractions which correspond to further fractions at which activations of the predecessor nodes contribute to an activation of the predetermined node in the one or more inferences.
5. Apparatus of claim 4, configured to determine the relevance score for a predetermined portion of the ML predictor, composed of more than one node and/or node inter connection of the ML predictor by aggregating the relevance scores of the more than one node and/or node interconnection the predetermined portion is composed of.
6. Apparatus of claim 5, configured to determine the predetermined portion by analyzing the distribution of relevance scores over the ML predictor.
7. Apparatus of any of claims 1 to 6, configured to, in pruning and/or quantizing the ML predictor using the relevance scores, prune away predetermined portions of the ML predictor whose relevance according to the relevance score determined for the predetermined portions is lower than a predetermined threshold.
8. Apparatus of any of claims 1 to 6, configured to, in pruning and/or quantizing the ML predictor using the relevance scores, prune away predetermined first portions of the ML predictor whose relevance according to the relevance score determined for the predetermined nodes fulfills a predetermined criterion, and second portions which contribute to an output of the ML predictor via the first portions exclusively.
9. Apparatus of claim 7 or 8, configured to, in pruning and/or quantizing the ML predictor using the relevance scores, perform the pruning away so that the predetermined threshold decreases towards an output of the ML predictor.
10. Apparatus of any of claims 1 to 9, configured to, in pruning and/or quantizing the ML predictor using the relevance scores, prune away predetermined portions of the ML predictor whose relevance according to the relevance score determined for the predetermined portions is lower than the relevance of more than a predetermined fraction of portions of the ML predictor.
11. Apparatus of any of claims 1 to 10, configured to prune and/or quantize the ML predictor using an optimization scheme with an objective function (96) which depends on a weighted distance between quantized weights and unquantized weights of the ML predictor, weighted based on the relevance scores.
12. Apparatus of claim 11 , wherein the objective function (96) depends on a sum of the weighted distance and a code length of the quantized weights.
13. Apparatus of claim 11 or 12, wherein the optimization scheme is a k-means clustering.
14. Apparatus of claim 13, configured to perform, for each iteration of the k-means clustering, a cluster formation step (92) associating each ML predictor node interconnection with one of a plurality (94) of quantization values so as to reduce the optimization function, and a quantizer update step (98) updating each quantization value using a weighted sum of the unquantized weights of the predictor node interconnection associated with the respective quantization value, weighted with a relevance score determined for the respective ML predictor node interconnection.
15. Apparatus of claim 13 or 14, configured to repeat performing the k-means clustering with, after each performance, accepting the quantized weights for predictor node interconnections for which the acceptance increases the optimization function less than a predetermined threshold or less than a predetermined fraction of remaining unquantized weights.
16. Apparatus of claim 15, configured to re-train the ML predictor with respect to unquantized weights for which no quantized weight has yet been accepted before any repetition of the k-means clustering.
17. Apparatus of claim 14, configured to re-train the ML predictor with respect to unquantized weights for which no quantized weight has yet been accepted.
18. Apparatus of any of the previous claims, configured to retrieve a definition of the ML predictor from a server, apply the ML predictor onto local input data so as to make the ML predictor performing the one or more inferences, replace the ML predictor with a pruned and/or quantized version of the ML predictor which results from the pruning and/or quantizing and apply the pruned and/or quantized version of the ML predictor onto further input data such as replenishments of the local input data to subject the further input data to inference.
19. Apparatus of any of the previous claims, configured to retrieve a definition of a general ML predictor from a server, removing portions of the general ML predictor exclusively interconnected to one or more predetermined uninterested outputs of the ML predictor to obtain the ML predictor.
20. Method for pruning and/or quantizing of a machine learning (ML) predictor (10), the comprising determine (34) relevance scores (44) for portions of the ML predictor (10) on the basis of an activation (40; 42) of the portions of the ML predictor (10) manifesting itself in one or more inferences performed by the ML predictor (10), pruning and/or quantizing (36) the ML predictor (10) using the relevance scores (44).
21. Computer program having a program code for performing, when running on a computer, a method of claim 20.
</claims>
</document>
