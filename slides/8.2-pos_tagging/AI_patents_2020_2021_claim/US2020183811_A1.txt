<document>

<filing_date>
2018-12-06
</filing_date>

<publication_date>
2020-06-11
</publication_date>

<priority_date>
2018-12-06
</priority_date>

<ipc_classes>
G06F11/36
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
RAJASHEKARA, SHASHIDHAR
SINGH, RITU
GANGULY, SANDIPAN
KRISHNAN, VIJAY
KUKREJA, MUSKAN
</inventors>

<docdb_family_id>
68966075
</docdb_family_id>

<title>
Automatically Performing and Evaluating Pilot Testing of Software
</title>

<abstract>
A method of and system for performing pilot testing of a software program in an organization is carried out by collecting pilot testing data generated from a pilot testing of a software program run on one or more hardware assets in the organization, determining whether a sufficient amount of pilot testing data has been collected, and, when so, calculating one or more pilot test metrics from the collected data. The calculated pilot test metrics may then be compared to similar metrics in a target population to evaluate the software program.
</abstract>

<claims>
1. A device comprising: one or more processors; and a memory in communication with the one or more processors, the memory comprising executable instructions that, when executed by the one or more processors, cause the device to perform functions of: collecting pilot testing data generated from a pilot testing of a software program which is running on one or more hardware assets in an organization; determining whether an amount of the collected pilot testing data satisfies a threshold amount of data; upon determining that the amount of the collected pilot testing data satisfies the threshold amount of data, calculating a pilot test metric from the collected pilot testing data; and comparing the pilot testing metric with a corresponding metric in a target population to automatically evaluate the software program.
2. The device of claim 1, wherein the executable instructions when executed by the one or more processors, further cause the device to perform functions of: receiving a request to perform the pilot testing; configuring one or more parameters for performing the pilot testing; and automatically determining, at least in part, based on results of evaluating the software program if the pilot testing should be extended to one or more other hardware assets, if the software program should be fully deployed in the organization, or if the pilot testing should be stopped.
3. The device of claim 1, wherein the executable instructions, when executed by the one or more processors, further cause the device to perform functions of calculating a validation score for the pilot testing.
4. The device of claim 3, wherein the executable instructions, when executed by the one or more processors, further cause the device to perform functions of generating a validation pass or fail notification based at least in part on the validation score.
5. The device of claim 1, wherein the pilot test metric includes at least one of a system health metric, usage metric, customer sentiment metric and performance metric.
6. The device of claim 1, wherein the target population comprises at least one of a pre-pilot testing population, a pilot testing population of one or more other organizations, and a global target population.
7. The device of claim 6, wherein the one or more other organizations are organizations in a similar industry as that of the organization.
8. A method for performing pilot testing of a software program in an organization comprising: collecting pilot testing data generated from the performing of the pilot testing of the software program on one or more hardware assets in the organization; determining whether an amount of the collected pilot testing data satisfies a threshold amount of data; upon determining that the amount of the collected pilot testing data satisfies the threshold amount of data, calculating a pilot test metric from the collected pilot testing data; and comparing the pilot testing metric with a corresponding metric in a target population to evaluate the software program.
9. The method of claim 8, further comprising: identifying one or more parameters to collect the pilot testing data for during the pilot testing; selecting the target population; and setting a threshold level for the pilot testing metric.
10. The method of claim 9, further comprising calculating a validation score for the pilot testing.
11. The method of claim 10, further comprising generating a validation pass or fail notification based at least in part on the validation score.
12. The method of claim 10, further comprising automatically selecting a course of action based at least in part on the validation score.
13. The method of claim 8, further comprising selecting the one or more hardware assets.
14. The method of claim 8, wherein the pilot test metric includes at least one of a system health metric, usage metric, customer sentiment metric and performance metric.
15. A non-transitory computer readable medium on which are stored instructions that when executed cause a programmable device to: collect pilot testing data generated from a pilot testing of a software program run on one or more hardware assets in an organization; determine whether an amount of the collected pilot testing data satisfies a threshold amount of data; upon determining that the amount of the collected pilot testing data satisfies the threshold amount of data, calculate a pilot test metric from the collected pilot testing data; compare the pilot testing metric with a corresponding metric in a target population to evaluate the software program.
16. The non-transitory computer readable medium of claim 15, wherein the instructions further cause the programmable device to: identify one or more parameters to collect the pilot testing data for during the pilot testing; select the target population; and set a threshold level for the pilot testing metric.
17. The non-transitory computer readable medium of claim 15, wherein the instructions further cause the programmable device to calculate a validation score for the pilot testing.
18. The non-transitory computer readable medium of claim 17, wherein the instructions further cause the programmable device to generate a validation pass or fail notification based at least in part on the validation score.
19. The non-transitory computer readable medium of claim 15, wherein the pilot test metric includes at least one of a system health metric, usage metric, customer sentiment metric and performance metric.
20. The non-transitory computer readable medium of claim 15, wherein the target population comprises at least one of a pre-pilot testing population, a pilot testing population of one or more other organizations, and a global target population.
21. The device of claim 5, wherein calculating the pilot test metric includes: determining the system health metric by calculating at least one of a number of sudden exists, a number of exact crash stack, and a product reliability indication; determining the usage metric by calculating at least one of an engagement time, a number of collaborations, a number of files accessed, and a number of clicks; determining the customer sentiment by calculating at least one of a net promotor score, emoticon use, a survey result, and a customer feeling indication; and determining the performance metric by calculating at least one of an amount of time to complete an action, and a response time.
</claims>
</document>
