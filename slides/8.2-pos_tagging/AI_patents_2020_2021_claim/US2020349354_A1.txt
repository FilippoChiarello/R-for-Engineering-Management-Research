<document>

<filing_date>
2020-07-21
</filing_date>

<publication_date>
2020-11-05
</publication_date>

<priority_date>
2018-11-09
</priority_date>

<ipc_classes>
G06F3/0481,G06K9/00,G06K9/62,G06T5/00,G06T5/50,G08B7/06,H04L29/08,H04N5/33,H04W4/024,H04W4/38
</ipc_classes>

<assignee>
QWAKE TECHNOLOGIES, LLC
</assignee>

<inventors>
LONG, II, JOHN DAVIS
COSSMAN, SAM J.
HACIOMEROGLU, OMER
RALSTON, MICHAEL E.
</inventors>

<docdb_family_id>
67908920
</docdb_family_id>

<title>
COGNITIVE LOAD REDUCING PLATFORM FOR FIRST RESPONDERS
</title>

<abstract>
A platform comprises one or more sensors that collect information about an environment as sensor data. A processor is in communication with the one or more sensors, wherein the processor executes enhancement engines that processes the sensor data into enhanced characterization data having a reduced amount of data compared to the sensor data. An output device electronically communicate the enhanced characterization data to a user, wherein the sensor and the output device comprise an assisted perception module worn by the user during an incident. A command interface device remote from the user to enable a person of authority to manage the incident and the user by receiving and displaying the enhanced characterization data, and by transmitting data and commands back to the assisted perception module.
</abstract>

<claims>
We claim:
1. A platform, comprising: one or more sensors that collect information about an environment as sensor data; a processor complex comprising one or more processors in communication with the one or more sensors, wherein the one or more processors execute one or more software-based enhancement engines that process the sensor data from the one or more sensors into enhanced characterization data having a reduced amount of data compared to the sensor data; one or more output devices to electronically communicate the enhanced characterization data to a user in a high stress environment such that the enhanced characterization data is integrated into natural senses of the user and optimized for the performance of a specific task of the user, wherein at least one of the one or more sensors and at least one of the one or more output devices comprise an assisted perception module worn by the user during an incident; and a command and control interface displayed on a display device remote from the user to enable a person of authority to manage the incident and user by receiving and displaying the enhanced characterization data from the assisted perception module, and by transmitting data and commands back to the assisted perception module.
2. The platform of claim 1, wherein multiple users are equipped with respective assisted perception modules, the command and control interface further comprising multiple sub-panels to display the enhanced characterization data from each of the assisted perception modules, wherein in a first communication mode, any of the subpanels is selected to engage in audio or visual icon based communication, and wherein in a second communication mode, the audio or visual icon based communication is broadcast to all of the assisted perception modules.
3. The platform of claim 2, further comprising: a cloud service in communication over a network with the command and control interface to perform data aggregation, predictive analytics, and archiving on one or more of the sensor data and the enhanced characterization data.
4. The platform of claim 3, wherein the command and control interface and the display device transmits to the cloud service telemetry data, the telemetry data comprising the enhanced characterization data and the sensor data from the assisted perception modules.
5. The platform of claim 3, wherein the display device of the command and control interface communicates with both the assisted perception modules and with the cloud service using 5G cellular mobile communications.
6. The platform of claim 3, wherein one of the command and control interface and the cloud service aggregates the telemetry data from the assisted perception modules to construct a map of the interior of a structure in which the incident occurs.
7. The platform of claim 6, wherein the map includes a location of hotspots and a virtual path marker showing paths the users took to a current location in the structure to aid in rapid egress.
8. The platform of claim 3, wherein the cloud service automatically archives the telemetry data in a repository.
9. The platform of claim 8, wherein the cloud service operates as a software as a service (SaaS) wherein statistical data generated by the cloud service is made available to customers of the cloud service.
10. The platform of claim 8, wherein, the cloud service aggregates the telemetry data and third party data collected over the network, the third party data including maps, weather conditions, building schematics, time/date, and building control information.
11. The platform of claim 10, wherein the cloud service aggregates the telemetry data and third party data according to any combination of: first responder unit, incident, first responder department, city, county, state, country, continent, and worldwide for crowdsourced data collection.
12. The platform of claim 1, wherein the processor complex is one of part of the assisted perception module and located on a remote server.
13. The platform of claim 1, wherein the assisted perception module is integrated with a mask or helmet of a self-contained breathing apparatus (SCBA), and wherein the sensor comprise a thermal imaging camera (TIC) and the one or more enhancement engines executed by the processor comprises one or more edge enhancement engines to processes thermal images from the TIC to enhance the edges of objects and declutter information in the thermal images.
14. A method comprising: collecting, using one or more sensors, information about an environment as sensor data; executing, by one or more processors in communication with the one or more sensors, one or more software-based enhancement engines that process the sensor data from the one or more sensors into enhanced characterization data having a reduced amount of data compared to the sensor data; electronically communicating, using one or more output devices, the enhanced characterization data to a user in a high stress environment such that the enhanced characterization data is integrated into natural senses of the user and optimized for the performance of a specific task of the user, wherein at least one of the one or more sensors and at least one of the one or more output devices comprise an assisted perception module worn by the user during an incident; and displaying a command and control interface on a display device remote from the user to enable a person of authority to manage the incident and user by receiving and displaying the enhanced characterization data from the assisted perception module, and by transmitting data and commands back to the assisted perception module.
15. The method of claim 14, further comprising: using, by multiple users, respective assisted perception modules, and configuring the command and control interface with multiple sub-panels to display the enhanced characterization data from each of the assisted perception modules, wherein in a first communication mode, any of the subpanels is selected to engage in audio or visual icon based communication, and wherein in a second communication mode, the audio or visual icon based communication is broadcast to all of the assisted perception modules.
16. The method of claim 15, further comprising: providing a cloud service in communication over a network with the command and control interface to perform data aggregation, predictive analytics, and archiving on one or more of the sensor data and the enhanced characterization data.
17. The method of claim 16, further comprising: transmitting by the display device of the command and control interface, telemetry data to the cloud service, the telemetry data comprising the enhanced characterization data and the sensor data from the assisted perception modules.
18. The method of claim 16, further comprising: communicating, by the display device of the command and control interface, with both the assisted perception modules and with the cloud service using 5G cellular mobile communications.
19. The method of claim 16, further comprising: aggregating, by one of the command and control interface and the cloud service, the telemetry data from the assisted perception modules to construct a map of the interior of a structure in which the incident occurs.
20. The method of claim 19, further comprising: including on the map a location of hotspots and a virtual path marker showing paths the users took to a current location in the structure to aid in rapid egress.
21. The method of claim 16, further comprising: automatically archiving the telemetry data in a repository by the cloud service.
22. The method of claim 21, further comprising: operating the cloud service as a software as a service (SaaS) wherein statistical data generated by the cloud service is made available to customers of the cloud service.
23. The method of claim 21, further comprising: aggregating, by the cloud service, the telemetry data and third party data collected over the network, the third party data including maps, weather conditions, building schematics, time/date, and building control information.
24. The method of claim 23, further comprising aggregating, by the cloud service, the telemetry data and third party data according to any combination of: first responder unit, incident, first responder department, city, county, state, country, continent, and worldwide for crowdsourced data collection.
25. A platform, comprising: an assisted perception module, comprising: a thermal imaging camera (TIC) carried by a user in a high stress environment to collect thermal images of an incident as sensor data; a processor coupled to the TIC, wherein the processor executes one or more enhancement engines, including an edge enhancement engine, the edge enhancement engine to process the thermal images into enhanced characterization images that enhances edges of objects and declutters information in the thermal images, wherein the processor is carried by the user or is located at a remote server; and a display unit in a line of sight of the user to electronically receive the enhanced characterization images from the processor and to display the enhanced characterization images as augmented reality images; and a command and control interface device located in proximity to the incident but remote from the user, the command interface device in communication with the assisted perception module to enable a person of authority to manage the incident and the user by receiving and displaying the enhanced characterization data from the display unit, and by transmitting data and commands back to the assisted perception module.
26. The platform of claim 25, further comprising: a cloud service in communication over a network with the command and control interface to perform data aggregation, predictive analytics, and archiving on one or more of the sensor data and the enhanced characterization images.
</claims>
</document>
