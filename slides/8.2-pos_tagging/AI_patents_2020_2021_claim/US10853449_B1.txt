<document>

<filing_date>
2017-09-21
</filing_date>

<publication_date>
2020-12-01
</publication_date>

<priority_date>
2016-01-05
</priority_date>

<ipc_classes>
G06K9/00,G06N20/00,G06T7/00,G16H50/20
</ipc_classes>

<assignee>
DEEPRADIOLOGY
</assignee>

<inventors>
LUFKIN, ROBERT BURNHAM
MERKOW, JAMESON TYLER
NGUYEN, KIM
</inventors>

<docdb_family_id>
73554909
</docdb_family_id>

<title>
Report formatting for automated or assisted analysis of medical imaging data and medical diagnosis
</title>

<abstract>
Methods and systems for medical diagnosis by machine learning are disclosed. Imaging data obtained from different medical techniques can be used as a training set for a machine learning method, to allow diagnosis of medical conditions in a faster a more efficient manner. A three-dimensional convolutional neural network can be employed to interpret volumetric data available from multiple scans of a patient.
</abstract>

<claims>
1. A medical device for analysis of medical imaging data to diagnose abnormalities, the medical device comprising: a processor and memory configured to implement the steps of: receiving imaging data relating to a body part of a human patient; classifying by machine learning the imaging data into a normal or an abnormal class; for the abnormal class, spatially localizing an abnormality within the imaging data of the body part, and categorizing by machine learning the abnormality within a category to provide a categorized abnormality for diagnostic purposes; grouping taxonomies into broad categories that relate to a particular physiology; and implementing computer code of a convolutional neural network (CNN), the CNN comprising a plurality of layers in a sequence, each layer comprising a plurality of nodes, wherein: each node of each layer is connected to at least one other node of a subsequent or preceding layer in the sequence; each node accepts an input value and outputs an output value; the classifying, spatially localizing and categorizing are performed by the CNN; the CNN is trained by deep supervision based on known anatomy of the body part; the category is derived from a taxonomy created by a physician; the medical imaging data comprises at least one of X-ray slides, computerized tomography, magnetic-resonance (MR), diffusion-tensor (DT), functional MR, gene-expression data, dermatological images, and optical imaging of tissue slices; the category has a normal or abnormal flag; the processor and memory are further configured to implement the step of compiling a human readable report based on the imaging data and the normal or abnormal flag, the step of compiling using a lookup table by selecting pre-formatted text based on the category and the normal or abnormal flag; and the pre-formatted text includes quantitative descriptions for the abnormality.
2. The device of claim 1, wherein the processor and memory are further configured to implement the step of: grouping taxonomies into broad categories that relate to a particular physiology.
3. The device of claim 1, wherein the category overlaps at least one other category.
4. The device of claim 1, wherein the plurality of layers comprises convolutional layers, rectified linear unit layers, non-linear pooling layers and fully connected layers.
5. The device of claim 4, wherein the non-linear pooling layers are max pooling layers that partition at least one image of the imaging data into non-overlapping sub-regions and output a maximum value for each sub-region.
6. The device of claim 1, wherein the imaging data comprises a collection of two-dimensional slices comprising a volume image in computerized tomography or magnetic-resonance.
7. A method for analysis of medical imaging data to diagnose abnormalities, the method comprising: receiving, by a computer, imaging data relating to a body part of a human patient; classifying by machine learning the imaging data into a normal or an abnormal class; for the abnormal class, spatially localizing an abnormality within the imaging data of the body part, and categorizing by machine learning the abnormality within a category derived from a taxonomy created by a physician to provide a categorized abnormality for diagnostic purposes; implementing computer code of a convolutional neural network (CNN); grouping taxonomies into broad categories that relate to a particular physiology; and training the CNN using deep supervision based on known anatomy of the body part, wherein the CNN comprises a plurality of layers in a sequence, each layer comprising a plurality of nodes; each node of each layer is connected to at least one other node of a subsequent or preceding layer in the sequence; each node accepts an input value and outputs an output value; the classifying, spatially localizing and categorizing are by the CNN; the medical imaging data comprises at least one of X-ray slides, computerized tomography, magnetic-resonance (MR), diffusion-tensor (DT), functional MR, gene-expression data, dermatological images, and optical imaging of tissue slices; the category has a normal or abnormal flag; the processor and memory are further configured to implement the step of compiling a human readable report based on the imaging data and the normal or abnormal flag, the step of compiling using a lookup table by selecting pre-formatted text based on the category and the normal or abnormal flag; and the pre-formatted text includes quantitative descriptions for the abnormality.
8. The method of claim 7, wherein the category overlaps at least one other category.
9. The method of claim 7, wherein the plurality of layers comprises convolutional layers, rectified linear unit layers, non-linear down-sampling layers and fully connected layers.
10. The method of claim 9, wherein the non-linear down-sampling layers are max pooling layers, and further comprising: partitioning, by the max pooling layers, at least one image of the imaging data into non-overlapping sub-regions, and outputting a maximum value for each sub-region.
</claims>
</document>
