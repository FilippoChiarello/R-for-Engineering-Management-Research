<document>

<filing_date>
2018-08-07
</filing_date>

<publication_date>
2020-02-13
</publication_date>

<priority_date>
2018-08-07
</priority_date>

<ipc_classes>
G06N3/08,G06N7/00,G06T7/246,G06T7/73
</ipc_classes>

<assignee>
QUALCOMM
</assignee>

<inventors>
SNOEK, CORNELIS GERARDUS MARIA
DIJKMAN, DANIEL HENDRICUS FRANCISCUS
VAN DE SANDE, KOEN ERIK ADRIAAN
HABIBIAN, AMIRHOSSEIN
RODRIGUEZ LOPEZ, ANTONIO LEONARDO
NG, YUE HEI
</inventors>

<docdb_family_id>
69406064
</docdb_family_id>

<title>
DECOUPLED MOTION MODELS FOR OBJECT TRACKING
</title>

<abstract>
A visual tracker may track an object by identifying the object in a frame, and the visual tracker by identify the object in the frame within a search region. The search region may be provided by a motion modeling system that independently models the motion of the object and models the motion of the camera. For example, an object motion model of the motion modeling system may first model the motion of the object, assuming the camera is not in motion, in order to identify the expected position of the object. A camera motion model of the motion modeling system may then update the expected position of the object, obtained from the object motion model, based on the motion of the camera.
</abstract>

<claims>
1. A method of tracking an object in motion, the method comprising: obtaining first image data that depicts at least a portion of an object that is in first motion over a set of previous time steps, the first image data being obtained from an image sensor that is in second motion over the set of previous time steps; determining, using a first motion model, an expected position at a future time step of the object that is in the first motion based on the first motion over the set of previous time steps; adjusting, using a second motion model, the determined expected position of the object based on the second motion of the image sensor over the set of previous time steps; and outputting the expected position of the object for tracking of the object in second image data corresponding to the future time step.
2. The method of claim 1, wherein the expected position of the object indicates a search region for a future frame at the future time step.
3. The method of claim 1, wherein the first motion model comprises an object motion model that is based on absence of the second motion of the image sensor over the set of previous time steps.
4. The method of claim 3, wherein the object motion model comprises at least one of a recurrent neural network (RNN) or a Bayesian filter.
5. The method of claim 1, wherein the determining, using the first motion model, the expected position at the future time step of the object that is in the first motion based on the first motion over the set of previous time steps comprises: modeling the first motion of the object based on at least one of a constant velocity or a constant acceleration associated with the object over the set of previous time steps.
6. The method of claim 1, wherein the second motion model comprises a camera motion model that models the second motion of the image sensor over the set of previous time steps.
7. The method of claim 6, wherein the camera motion model models the second motion of the image sensor over the set of previous time steps based on at least one of visual odometry or inertial odometry.
8. The method of claim 1, wherein the adjusting, using the second motion model, the determined expected position of the object based on the second motion of the image sensor over the set of previous time steps comprises: obtaining one or more measurements indicating the second motion in three-dimensional coordinate space; translating the one or more measurements from the three-dimensional coordinate space to two-dimensional coordinate space; and adjusting the expected position based on the one or more measurements translated to the two-dimensional coordinate space.
9. The method of claim 1, further comprising: training the first motion model independently from the second motion model based on a first set of training data that indicates a fixed position of the image sensor.
10. The method of claim 1, further comprising: identifying, based on the expected position of the object, the object depicted in the second image data at the future time step.
11. An apparatus for tracking an object in motion, the apparatus comprising: a memory; and at least one processor coupled to the memory and configured to: obtain first image data that depicts at least a portion of an object that is in first motion over a set of previous time steps, the first image data being obtained from an image sensor that is in second motion over the set of previous time steps; determine, using a first motion model, an expected position at a future time step of the object that is in the first motion based on the first motion over the set of previous time steps; adjust, using a second motion model, the determined expected position of the object based on the second motion of the image sensor over the set of previous time steps; and output the expected position of the object for tracking of the object in second image data corresponding to the future time step.
12. The apparatus of claim 11, wherein the expected position of the object indicates a search region for a future frame at the future time step.
13. The apparatus of claim 11, wherein the first motion model comprises an object motion model that is based on absence of the second motion of the image sensor over the set of previous time steps.
14. The apparatus of claim 13, wherein the object motion model comprises at least one of a recurrent neural network (RNN) or a Bayesian filter.
15. The apparatus of claim 11, wherein the determination, using the first motion model, of the expected position at the future time step of the object that is in the first motion based on the first motion over the set of previous time steps comprises to: model the first motion of the object based on at least one of a constant velocity or a constant acceleration associated with the object over the set of previous time steps.
16. The apparatus of claim 11, wherein the second motion model comprises a camera motion model that models the second motion of the image sensor over the set of previous time steps.
17. The apparatus of claim 16, wherein the camera motion model models the second motion of the image sensor over the set of previous time steps based on at least one of visual odometry or inertial odometry.
18. The apparatus of claim 11, wherein the adjustment, using the second motion model, of the determined expected position of the object based on the second motion of the image sensor over the set of previous time steps comprises to: obtain one or more measurements indicating the second motion in three-dimensional coordinate space; translate the one or more measurements from the three-dimensional coordinate space to two-dimensional coordinate space; and adjust the expected position based on the one or more measurements translated to the two-dimensional coordinate space.
19. The apparatus of claim 11, wherein the at least one processor is further configured to: train the first motion model independently from the second motion model based on a first set of training data that indicates a fixed position of the image sensor.
20. The apparatus of claim 11, wherein the at least one processor is further configured to: identify, based on the expected position of the object, the object depicted in the second image data at the future time step.
21. An apparatus for tracking an object in motion, the apparatus comprising: means for obtaining first image data that depicts at least a portion of an object that is in first motion over a set of previous time steps, the first image data being obtained from an image sensor that is in second motion over the set of previous time steps; means for determining, using a first motion model, an expected position at a future time step of the object that is in the first motion based on the first motion over the set of previous time steps; means for adjusting, using a second motion model, the determined expected position of the object based on the second motion of the image sensor over the set of previous time steps; and means for outputting the expected position of the object for tracking of the object in second image data corresponding to the future time step.
22. The apparatus of claim 21, wherein the expected position of the object indicates a search region for a future frame at the future time step.
23. The apparatus of claim 21, wherein the first motion model comprises an object motion model that is based on absence of the second motion of the image sensor over the set of previous time steps.
24. The apparatus of claim 23, wherein the object motion model comprises at least one of a recurrent neural network (RNN) or a Bayesian filter.
25. The apparatus of claim 21, wherein the means for determining, using the first motion model, the expected position at the future time step of the object that is in the first motion based on the first motion over the set of previous time steps is configured to: model the first motion of the object based on at least one of a constant velocity or a constant acceleration associated with the object over the set of previous time steps.
26. The apparatus of claim 21, wherein the second motion model comprises a camera motion model that models the second motion of the image sensor over the set of previous time steps.
27. The apparatus of claim 26, wherein the camera motion model models the second motion of the image sensor over the set of previous time steps based on at least one of visual odometry or inertial odometry.
28. The apparatus of claim 21, wherein the means for adjusting, using the second motion model, the determined expected position of the object based on the second motion of the image sensor over the set of previous time steps is configured to: obtain one or more measurements indicating the second motion in three-dimensional coordinate space; translate the one or more measurements from the three-dimensional coordinate space to two-dimensional coordinate space; and adjust the expected position based on the one or more measurements translated to the two-dimensional coordinate space.
29. The apparatus of claim 21, further comprising: means for identifying, based on the expected position of the object, the object depicted in the second image data at the future time step.
30. A computer-readable medium storing computer-executable code for tracking an object in motion using two motion models, comprising code to: obtain first image data that depicts at least a portion of an object that is in first motion over a set of previous time steps, the first image data being obtained from an image sensor that is in second motion over the set of previous time steps; determine, using a first motion model, an expected position at a future time step of the object that is in the first motion based on the first motion over the set of previous time steps; adjust, using a second motion model, the determined expected position of the object based on the second motion of the image sensor over the set of previous time steps; and output the expected position of the object for tracking of the object in second image data corresponding to the future time step.
</claims>
</document>
