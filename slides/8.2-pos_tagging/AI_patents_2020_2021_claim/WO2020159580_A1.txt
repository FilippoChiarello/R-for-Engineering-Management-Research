<document>

<filing_date>
2019-08-29
</filing_date>

<publication_date>
2020-08-06
</publication_date>

<priority_date>
2019-01-29
</priority_date>

<ipc_classes>
G06N3/063
</ipc_classes>

<assignee>
SILICON STORAGE TECHNOLOGY
</assignee>

<inventors>
DO, NHAN
LEMKE, STEVEN
REITEN, MARK
TIWARI, VIPIN
TRAN HIEU
</inventors>

<docdb_family_id>
71612006
</docdb_family_id>

<title>
NEURAL NETWORK CLASSIFIER USING ARRAY OF STACKED GATE NON-VOLATILE MEMORY CELLS
</title>

<abstract>
A neural network device with synapses having memory cells each having source and drain regions in a semiconductor substrate with a channel region extending there between, a floating gate over an entirety of the channel region, and a first gate over the floating gate. First lines each electrically connect together the first gates in one of the memory cell rows, second lines each electrically connect together the source regions in one of the memory cell rows, and third lines each electrically connect together the drain regions in one of the memory cell columns. The synapses are configured to receive a first plurality of inputs as electrical voltages on the first lines or on the second lines, and to provide a first plurality of outputs as electrical currents on the third lines.
</abstract>

<claims>
1. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over an entirety of and insulated from the channel region, and a first gate disposed over and insulated from the floating gate;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells;
a plurality of second lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines or on the plurality of second lines, and to provide the first plurality of outputs as electrical currents on the plurality of third lines.
2. The neural network device of claim 1 , wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines.
3. The neural network device of claim 1, wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of second lines.
4. The neural network device of claim 1, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
5. The neural network device of claim 4, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over an entirety of and insulated from the second channel region, and a second gate disposed over and insulated from the second floating gate;
each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fourth lines each electrically connecting together the second gates in one of the rows of the second memory cells;
a plurality of fifth lines each electrically connecting together the second source regions in one of the rows of the second memory cells;
a plurality of sixth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells; wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fourth lines or on the plurality of fifth lines, and to provide the second plurality of outputs as electrical currents on the plurality of sixth lines.
6. The neural network device of claim 5, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fourth lines.
7. The neural network device of claim 5, wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fifth lines.
8. The neural network device of claim 5, further comprising:
a second plurality of neurons configured to receive the second plurality of outputs.
9. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over an entirety of and insulated from the channel region, and a first gate disposed over and insulated from the floating gate;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises: a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells;
a plurality of second lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of third lines, and to provide the first plurality of outputs as electrical currents on the plurality of second lines.
10. The neural network device of claim 9, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
11. The neural network device of claim 10, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over an entirety of and insulated from the second channel region, and a second gate disposed over and insulated from the second floating gate;
each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises: a plurality of fourth lines each electrically connecting together the second gates in one of the rows of the second memory cells;
a plurality of fifth lines each electrically connecting together the second source regions in one of the rows of the second memory cells;
a plurality of sixth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of sixth lines, and to provide the second plurality of outputs as electrical currents on the plurality of fifth lines.
12. The neural network device of claim 11 , further comprising:
a second plurality of neurons configured to receive the second plurality of outputs.
13. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over an entirety of and insulated from the channel region, and a first gate disposed over and insulated from the floating gate;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells; a plurality of second lines each electrically connecting together the source regions in one of the columns of the memory cells;
a plurality of third lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines, and to provide the first plurality of outputs as electrical currents on the plurality of second lines or on the plurality of third lines.
14. The neural network device of claim 13, wherein the first plurality of synapses is configured to provide the first plurality of outputs as electrical currents on the plurality of second lines.
15. The neural network device of claim 13, wherein the first plurality of synapses is configured to provide the first plurality of outputs as electrical currents on the plurality of third lines.
16. The neural network device of claim 13, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
17. The neural network device of claim 16, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over an entirety of and insulated from the second channel region, and a second gate disposed over and insulated from the second floating gate; each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fourth lines each electrically connecting together the second gates in one of the rows of the second memory cells;
a plurality of fifth lines each electrically connecting together the second source regions in one of the columns of the second memory cells;
a plurality of sixth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fourth lines, and to provide the second plurality of outputs as electrical currents on the plurality of fifth lines or on the plurality of sixth lines.
18. The neural network device of claim 17, wherein the second plurality of synapses is configured to provide the second plurality of outputs as electrical currents on the plurality of fifth lines.
19. The neural network device of claim 17, wherein the second plurality of synapses is configured to provide the second plurality of outputs as electrical currents on the plurality of sixth lines.
20. The neural network device of claim 17, further comprising:
a second plurality of neurons configured to receive the second plurality of outputs.
21. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over an entirety of and insulated from the channel region, and a first gate disposed over and insulated from the floating gate;
each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together at least some of the first gates in one of the columns of the memory cells;
a plurality of second lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the drain regions in one of the columns of the memory cells;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on the plurality of first lines, and to provide the first plurality of outputs as electrical currents on the plurality of second lines.
22. The neural network device of claim 21, wherein each of the first lines is electrically connected to all of the first gates of the memory cells in one of columns of the memory cells.
23. The neural network device of claim 21 , wherein the rows of the memory cells are arranged in alternating even and odd numbered rows, and wherein: each of the columns of the memory cells includes one of the first lines electrically connecting together the first gates of the memory cells in the column of memory cells that are in the odd numbered rows of the memory cells, and another one of the first lines electrically connecting together the first gates of the memory cells in the column of memory cells that are in the even numbered rows of the memory cells.
24. The neural network device of claim 21 , further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
25. The neural network device of claim 24, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over an entirety of and insulated from the second channel region, and a second gate disposed over and insulated from the second floating gate;
each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fourth lines each electrically connecting together at least some of the second gates in one of the columns of the second memory cells; a plurality of fifth lines each electrically connecting together the second source regions in one of the rows of the second memory cells; a plurality of sixth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on the plurality of fourth lines, and to provide the second plurality of outputs as electrical currents on the plurality of fifth lines.
26. The neural network device of claim 25, wherein each of the fourth lines is electrically connected to all of the second gates of the second memory cells in one of columns of the second memory cells.
27. The neural network device of claim 25, wherein the rows of the second memory cells are arranged in alternating even and odd numbered rows, and wherein:
each of the columns of the second memory cells includes one of the fourth lines electrically connecting together the second gates of the second memory cells in the column of second memory cells that are in the odd numbered rows of the second memory cells, and another one of the fourth lines electrically connecting together the second gates of the second memory cells in the column of second memory cells that are in the even numbered rows of the second memory cells.
28. The neural network device of claim 25, further comprising:
a second plurality of neurons configured to receive the second plurality of outputs.
29. A neural network device, comprising:
a first plurality of synapses configured to receive a first plurality of inputs and to generate therefrom a first plurality of outputs, wherein the first plurality of synapses comprises:
a plurality of memory cells, wherein each of the memory cells includes spaced apart source and drain regions formed in a semiconductor substrate with a channel region extending there between, a floating gate disposed over an entirety of and insulated from the channel region, and a first gate disposed over and insulated from the floating gate; each of the plurality of memory cells is configured to store a weight value corresponding to a number of electrons on the floating gate;
the plurality of memory cells are configured to generate the first plurality of outputs based upon the first plurality of inputs and the stored weight values; wherein the memory cells of the first plurality of synapses are arranged in rows and columns, and wherein the first plurality of synapses comprises:
a plurality of first lines each electrically connecting together the first gates in one of the rows of the memory cells;
a plurality of second lines each electrically connecting together the source regions in one of the rows of the memory cells;
a plurality of third lines each electrically connecting together the drain regions in one of the columns of the memory cells;
a plurality of transistors each electrically connected in series with one of the third lines;
wherein the first plurality of synapses is configured to receive the first plurality of inputs as electrical voltages on gates of the plurality of transistors, and to provide the first plurality of outputs as electrical currents on the plurality of second lines.
30. The neural network device of claim 29, further comprising:
a first plurality of neurons configured to receive the first plurality of outputs.
31. The neural network device of claim 30, further comprising:
a second plurality of synapses configured to receive a second plurality of inputs from the first plurality of neurons and to generate therefrom a second plurality of outputs, wherein the second plurality of synapses comprises:
a plurality of second memory cells, wherein each of the second memory cells includes spaced apart second source and second drain regions formed in the semiconductor substrate with a second channel region extending there between, a second floating gate disposed over an entirety of and insulated from the second channel region, and a second gate disposed over and insulated from the second floating gate; each of the plurality of second memory cells is configured to store a second weight value corresponding to a number of electrons on the second floating gate;
the plurality of second memory cells are configured generate the second plurality of outputs based upon the second plurality of inputs and the stored second weight values;
wherein the second memory cells of the second plurality of synapses are arranged in rows and columns, and wherein the second plurality of synapses comprises:
a plurality of fourth lines each electrically connecting together the second gates in one of the rows of the second memory cells;
a plurality of fifth lines each electrically connecting together the second source regions in one of the rows of the second memory cells;
a plurality of sixth lines each electrically connecting together the second drain regions in one of the columns of the second memory cells;
a second plurality of transistors each electrically connected in series with one of the sixth lines;
wherein the second plurality of synapses is configured to receive the second plurality of inputs as electrical voltages on gates of the second plurality of transistors, and to provide the second plurality of outputs as electrical currents on the plurality of fifth lines.
32. The neural network device of claim 31 , further comprising:
a second plurality of neurons configured to receive the second plurality of outputs.
</claims>
</document>
