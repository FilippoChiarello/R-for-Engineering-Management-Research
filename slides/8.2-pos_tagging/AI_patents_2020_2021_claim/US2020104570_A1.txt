<document>

<filing_date>
2019-02-15
</filing_date>

<publication_date>
2020-04-02
</publication_date>

<priority_date>
2018-09-28
</priority_date>

<ipc_classes>
G06K9/00,G06N3/04
</ipc_classes>

<assignee>
APPLE
</assignee>

<inventors>
TANG, FENG
HAMSICI, ONUR C.
LIEBELT, JOERG A.
KUMAR, ATULIT
</inventors>

<docdb_family_id>
69947682
</docdb_family_id>

<title>
NETWORK PERFORMANCE BY INCLUDING ATTRIBUTES
</title>

<abstract>
An image captured using a camera on a device (e.g., a mobile device) may be operated on by one or more processes to determine properties of a user's face in the image. A first process may determine one or more first properties of the user's face in the image. A second process operating downstream from the first process may determine at least one second property of the user's face in the image. The second process may use at least one of the first properties from the first process to determine the second property.
</abstract>

<claims>
1. A device, comprising: a camera; an illuminator; a memory configured to store program instructions; and a processor, wherein the processor is configured to execute the program instructions and to cause the device to: capture at least one image using the camera, wherein the at least one image comprises an image captured while illuminating subjects in the image with the illuminator; determine a plurality of first properties associated with the face in the captured image; operate on the captured image using a neural network, wherein the neural network comprises a plurality of network layers, and wherein the neural network is configured to execute the program instructions and to cause the device to: apply at least one of the first properties to a first network layer of the neural network; provide a first output from the first network layer as an input to a second network layer of the neural network; apply at least one of the first properties to the second network layer; and provide an output from the neural network, wherein the output comprises at least one second property of the face of the user in the captured image.
2. The device of claim 1, wherein the output from the neural network is determined, at least in part, by operation of the first network layer and the second network layer.
3. The device of claim 1, wherein the first network layer comprises a convolutional network layer, and wherein the at least one first property applied to the first network layer comprises a scalar value applied to a bias of the first network layer.
4. The device of claim 3, wherein the scalar value applied to the bias of the first network layer shifts the first output from the first network layer.
5. The device of claim 1, wherein the second network layer comprises a convolutional network layer, and wherein the at least one first property applied to the second network layer comprises a scalar value applied to a bias of the second network layer.
6. The device of claim 1, wherein the processor is configured to execute the program instructions and to cause the device to operate a face detection process to determine the plurality of first properties associated with the face in the captured image.
7. The device of claim 6, wherein the plurality of first properties determined by the face detection process include a pose of the face, the pose of the face including the pitch, yaw, and roll of the face in the captured image.
8. The device of claim 7, wherein at least one of the pitch, yaw, and roll of the face is applied to the first network layer, and wherein at least one of the pitch, yaw, and roll of the face is applied to the second network layer.
9. The device of claim 8, wherein the output from the neural network comprises a gaze of the user in the captured image.
10. A method, comprising: capturing at least one image of a face of a user using a camera located on a device, the device comprising a computer processor, a memory, and at least one neural network associated with the computer processor, wherein the at least one image comprises an image captured while illuminating subjects in the image with an illuminator located on the device; determining, using the computer processor, one or more properties of the face in the captured image, wherein at least one of properties includes a pose of the face in the captured image, the pose of the face comprising pitch, yaw, and roll of the face in the captured image; operating on the captured image using the at least one neural network, wherein the at least one neural network comprises a plurality of network layers, and wherein operating on the captured image comprises: applying a first property to a first network layer of the neural network, wherein the first property includes at least one of the pitch, yaw, or roll of the face in the captured image; applying a second property to a second network layer of the neural network, wherein the second property includes at least one of the pitch, yaw, or roll of the face in the captured image not applied to the first network layer; applying a third property to a third network layer of the neural network, wherein the third property includes at least one of the pitch, yaw, or roll of the face in the captured image not applied to the first network layer and the second network layer; and providing an output from by the neural network, wherein the output comprises at least one additional property of the face of the user determined by the neural network.
11. The method of claim 10, wherein determining the one or more properties of the face in the captured image comprises operating a face detection process on the captured image.
12. The method of claim 10, wherein the first property, the second property, and the third property are applied as scalar values to the first network layer, the second network layer, and the third network layer, and wherein the scalar values are applied to a bias of the network layers.
13. The method of claim 10, wherein determining the one or more properties of the face in the captured image comprises determining a distance between the face of the user and the device, and wherein the method further comprises: applying the determined distance to a fourth network layer of the neural network.
14. The method of claim 10, wherein the first property applied to the first network layer comprises the roll of the face in the captured image, wherein the second property applied to the second network layer comprises the yaw of the face in the captured image, and wherein the third property applied to the third network layer comprises the pitch of the face in the captured image.
15. The method of claim 10, wherein the at least one additional property determined by the neural network comprises a gaze of the face of the user in the captured image.
16. The method of claim 10, further comprising operating a facial recognition authentication process using the captured image, wherein the facial recognition authentication process is used to authenticate the user to operate at least one function on the device.
17. A non-transient computer-readable medium including instructions that, when executed by one or more processors, cause the one or more processors to perform a method, comprising, comprising: capturing at least one image of a face of a user using a camera located on a device, the device comprising a computer processor, a memory, and at least one neural network associated with the computer processor, wherein the at least one image comprises an image captured while illuminating subjects in the image with an illuminator located on the device; determining, using the computer processor, one or more properties of the face in the captured image, wherein at least one of properties includes a pose of the face in the captured image, the pose of the face comprising pitch, yaw, and roll of the face in the captured image; operating on the captured image using the at least one neural network, wherein the at least one neural network comprises a plurality of network layers, and wherein operating on the captured image comprises: applying a first property to a first network layer of the neural network, wherein the first property includes at least one of the pitch, yaw, or roll of the face in the captured image; applying a second property to a second network layer of the neural network, wherein the second property includes at least one of the pitch, yaw, or roll of the face in the captured image not applied to the first network layer; applying a third property to a third network layer of the neural network, wherein the third property includes at least one of the pitch, yaw, or roll of the face in the captured image not applied to the first network layer and the second network layer; and providing an output from by the neural network, wherein the output comprises at least one additional property of the face of the user determined by the neural network.
18. The non-transient computer-readable medium of claim 17, further comprising providing the output from the neural network to at least one additional operation on the device.
19. The non-transient computer-readable medium of claim 17, further comprising using the output from the neural network in at least one additional image processing operation on the device.
20. The non-transient computer-readable medium of claim 17, wherein the network layers comprises convolutional layers, and wherein the pitch, yaw, and roll of the face are applied to the network layers as scalar angular values to input biases of the network layers.
</claims>
</document>
