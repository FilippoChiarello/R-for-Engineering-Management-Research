<document>

<filing_date>
2020-04-22
</filing_date>

<publication_date>
2020-10-29
</publication_date>

<priority_date>
2019-04-23
</priority_date>

<ipc_classes>
G06F3/041,G06N3/08
</ipc_classes>

<assignee>
VULCAN CORPORATION
</assignee>

<inventors>
GERARD, RUSTY ALLEN
ROSENBAUM, OMER
SIMPKINSON, RICHARD EARL
ZAKARIYA, SHAMYL EMRICH
</inventors>

<docdb_family_id>
72917012
</docdb_family_id>

<title>
GESTURE RECOGNITION BASED ON SKELETAL MODEL VECTORS
</title>

<abstract>
A system for recognizing gestures generates a skeletal model from video data of a subject. A defined subset of attributes of the skeletal model are mapped to defined positions of a vector. A gesture is recognized by evaluating a neural network using the vector as input. The neural network, trained using training vectors generated according to the definitions of skeletal model attributes and vector positions, classifies a gesture based on the input vector.
</abstract>

<claims>
1. A system, comprising: at least one processor; and a memory comprising instructions that, in response to execution by the at least one processor, cause the system to at least: obtain image data of a subject; generate a skeletal model based at least in part on the image data, the skeletal model comprising a plurality of joint angle values corresponding to a plurality of joints, the plurality of joint angle values representative of a pose of the subject in the image data; generate a first vector based at least in part on the skeletal model, the first vector comprising a subset of the plurality of joint angle values corresponding to a selected subset of the plurality of joints; and obtain a classification of a gesture based, at least in part, on evaluation of a neural network using the first vector as input, the neural network trained based at least in part on a plurality of training vectors, the plurality of training vectors each comprising a plurality of joint angle values corresponding to the selected subset of the plurality of joints.
2. The system of claim 1, wherein joints in the selected subset of the plurality of joints are selected based at least in part on an association of the joints with the gesture.
3. The system of claim 1, wherein the selected subset of the plurality of joints excludes one or more joints of the plurality of joints of the skeletal model.
4. The system of claim 1, wherein the first vector comprises joint angle values for less than all of joint angle vectors in the training vectors used to train the neural network.
5. The system of claim 1, the memory comprising instructions that, in response to execution by the at least one processor, cause the system to at least: generate the first vector based at least in part on a consensus model generated based at least in part on a plurality of skeletal models, the plurality of skeletal models comprising the skeletal model.
6. The system of claim 5, wherein a first skeletal model, of the plurality of skeletal models, represents the pose of the subject, and a second skeletal model, of the plurality of skeletal models, represents a portion of the pose, the second skeletal model having greater detail associated with the portion than the first skeletal model.
7. A computer-implemented method, comprising: generating a skeletal model based at least in part on image data of a subject, wherein the skeletal model comprises a plurality of joint angle values corresponding to a plurality of joints, the skeletal model representative of a pose of the subject in the image data; generating a first vector from the skeletal model, the first vector comprising a subset of the plurality of joint angle values corresponding to a defined subset of the plurality of joints; and classifying a gesture of the subject based, at least in part, on evaluating a neural network using inputs comprising the first vector, wherein the neural network is trained based at least in part on a plurality of training vectors, wherein a training vector, of the plurality of training vectors, comprises a plurality of joint angle values corresponding to the defined subset of the plurality of joints.
8. The method of claim 7, further comprising: locating a joint in the skeletal model; and copying a joint angle value associated with the joint to a mapped position in the first vector.
9. The method of claim 7, wherein the defined subset of the plurality of joints excludes one or more joints of the plurality of joints of the skeletal model.
10. The method of claim 7, further comprising: generating the first vector to comprise less than all of joint angle vectors in the training vectors used to train the neural network.
11. The method of claim 7, further comprising: generating a consensus skeletal model based, at least in part, on the skeletal model and one or more additional skeletal models; and generating the first vector based at least in part on the consensus skeletal model.
12. The method of claim 11, wherein at least one of the one or more additional skeletal models excludes portions of the subject not associated with one or more gestures to be classified.
13. The method of claim 11, wherein at least one of the one or more additional skeletal models is generated from additional video data taken from an additional perspective other than a perspective used to obtain the video data.
14. A non-transitory computer-readable storage medium having stored thereon instructions that, in response to execution by at least one processor of a computing device, cause the computing device to at least: generate a skeletal model based at least in part on image data of a subject, wherein the skeletal model comprises a plurality of joint angle values corresponding to a plurality of joints, the skeletal model representative of a pose of the subject in the image data; generate a first vector from the skeletal model, the first vector comprising a subset of the plurality of joint angle values corresponding to a defined subset of the plurality of joints; and classify a gesture of the subject based, at least in part, on evaluating a neural network using inputs comprising the first vector, wherein the neural network is trained based at least in part on a plurality of training vectors, wherein a training vector, of the plurality of training vectors, comprises a plurality of joint angle values corresponding to the defined subset of the plurality of joints.
15. The non-transitory computer-readable storage medium of claim 14, having stored thereon instructions that, in response to execution by at least one processor of the computing device, cause the computing device to at least: locate a joint in the skeletal model; and copy a joint angle value associated with the joint to a mapped position in the first vector.
16. The non-transitory computer-readable storage medium of claim 14, wherein the defined subset of the plurality of joints excludes one or more joints of the plurality of joints of the skeletal model.
17. The non-transitory computer-readable storage medium of claim 14, having stored thereon instructions that, in response to execution by at least one processor of the computing device, cause the computing device to at least: generate the first vector to comprise less than all of joint angle vectors in the training vectors used to train the neural network.
18. The non-transitory computer-readable storage medium of claim 14, having stored thereon instructions that, in response to execution by at least one processor of the computing device, cause the computing device to at least: generate a consensus skeletal model based, at least in part, on the skeletal model and one or more additional skeletal models; and generate the first vector based at least in part on the consensus skeletal model.
19. The non-transitory computer-readable storage medium of claim 18, wherein at least one of the one or more additional skeletal models excludes portions of the subject not associated with one or more gestures to be classified.
20. The non-transitory computer-readable storage medium of claim 18, wherein at least one of the one or more additional skeletal models is generated from additional video data taken from an additional perspective other than a perspective used to obtain the video data.
</claims>
</document>
