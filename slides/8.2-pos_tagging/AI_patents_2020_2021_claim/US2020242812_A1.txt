<document>

<filing_date>
2020-04-13
</filing_date>

<publication_date>
2020-07-30
</publication_date>

<priority_date>
2018-06-28
</priority_date>

<ipc_classes>
G06N3/04,G06T9/00,H04L12/58
</ipc_classes>

<assignee>
SNAP
</assignee>

<inventors>
SHETH, RAHUL BHUPENDRA
ZHANG, NING
REHFELD, DRAKE AUSTIN
</inventors>

<docdb_family_id>
70736535
</docdb_family_id>

<title>
ENCODING AND DECODING A STYLIZED CUSTOM GRAPHIC
</title>

<abstract>
Disclosed are methods for encoding information in a graphic image. The information may be encoded so as to have a visual appearance that adopts a particular style, so that the encoded information is visually pleasing in the environment in which it is displayed. An encoder and decoder are trained during an integrated training process, where the encoder is tuned to minimize a loss when its encoded images are decoded. Similarly, the decoder is also trained to minimize loss when decoding the encoded images. Both the encoder and decoder may utilize a convolutional neural network in some aspects to analyze data and/or images. Once data is encoded, a style from a sample image is transferred to the encoded data. When decoding, the decoder may largely ignore the style aspects of the encoded data and decode based on a content portion of the data.
</abstract>

<claims>
We claim:
1. A method comprising: accessing a bit string; generating using an encoder, image data encoding the bit string, the encoder trained to minimize a loss in relation to training data generated by the encoder and decoded by a decoder; transferring, by hardware processing circuitry, a style from a sample image to the image data; and filling a graphic image with the image data encoding the bit string and having the style.
2. The method of claim 1, wherein the training data comprises a plurality of training bit strings.
3. The method of claim 1, wherein the decoder is also trained to minimize loss in relation to the training data being decoded by the decoder.
4. The method of claim 1, further comprising: generating the graphic image; and writing the filled graphic image to an output device.
5. The method of claim 1, wherein the transferring of the style from the sample image to the image data comprises minimizing a loss function of the style and a second style of the image data by modifying the image data, and minimizing a second loss function of a content of the image data and a second content of the modified image data.
6. The method of claim 1, wherein the style of the sample image and a second style of the image data are based on feature correlations between multiple layers of a convolutional neural network applied to each of the sample image and the image data respectively.
7. The method of claim 1, wherein the encoder includes convolutional layers comprising: a) dense layer at (32*32) units b) reshape to 1, 32, 32, c) convolution of 64 units, 3×3 d) max pooling at 2×2, stride 2 e) deconvolution at 64, 3×3, stride 2 f) convolution of 64 units, 3×3 g) max pooling at 2×2 stride h) deconvolution at 64, 3×3, stride 2 i) convolution of 64 units, 3×3 j) max pooling at 2×2 stride 2 k) deconvolution at 3, 3×3, stride 2.
8. The method of claim 1, wherein the encoder is configured to return an image tensor of (1, 32, 32, 3) based on a hyperbolic tangent.
9. The method of claim 1, wherein the decoder includes layers comprising: a) convolution of 64 filters at 3×3 b) convolution of 64 filters at 3×3 c) pooling filter stride 2, 2×2 d) convolution of 64 filters at 3×3 e) convolution of 64 filters at 3×3 f) pooling filter stride 2, 2×2 g) convolution of 64 filters at 3×3 h) convolution of 64 filters, 3×3 i) pooling filter stride 2, 2×2 j) dense layer at 128 units k) dense layer at 9 units.
10. The method of claim 1, wherein the decoder is configured to return a bit string tensor of shape (1,1,1,9).
11. The method of claim 1, wherein the loss is minimized via a stochastic gradient descent algorithm.
12. The method of claim 1, wherein minimizing the loss comprises updating a first set of weights defining convolution and deconvolution layers of the encoder based on the loss and updating a second set of weights defining convolution and deconvolution layers of the decoder based on the loss.
13. The method of claim 1, further comprising associating the bit string with an operation to be performed upon decoding of the bit string by a social network.
14. The method of claim 13, further comprising encoding instructions for the social network into the bit string.
15. A system, comprising: hardware processing circuitry; a hardware memory storing instructions that when executed configure the hardware processing circuitry to perform operations comprising: accessing a bit string; generating using an encoder, image data encoding the bit string, the encoder trained to minimize a loss in relation to training data generated by the encoder and decoded by a decoder; transferring, by hardware processing circuitry, a style from a sample image to the image data; and filling a graphic image with the image data encoding the bit string and haying the style.
16. The system of claim 15, wherein the training data comprises a plurality of training bit strings.
17. The system of claim 15, wherein the decoder is also trained to minimize loss in relation to the training data being decoded by the decoder.
18. A non-transitory computer readable medium comprising non-transitory computer readable instructions that, when executed by one or more processors, configured the one or more processors to perform operations comprising: accessing a bit string; generating using an encoder, image data encoding the bit string, the encoder trained to minimize a loss in relation to training data generated by the encoder and decoded by a decoder; transferring, by hardware processing circuitry, a style from a sample image to the image data; and filling a graphic image with the image data encoding the bit string and having the style.
19. The non-transitory computer readable medium of claim 18, wherein the training data comprises a plurality of training bit strings.
20. The non-transitory computer readable medium of claim 18, wherein the decoder is also trained to minimize loss in relation to the training data being decoded by the decoder.
</claims>
</document>
