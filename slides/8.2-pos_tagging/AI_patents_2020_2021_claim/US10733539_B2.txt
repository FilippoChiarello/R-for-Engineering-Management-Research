<document>

<filing_date>
2018-11-05
</filing_date>

<publication_date>
2020-08-04
</publication_date>

<priority_date>
2015-07-31
</priority_date>

<ipc_classes>
G06F11/30,G06F21/00,G06F21/56,G06N20/00,G06N5/04,H04L29/06,H04W12/12
</ipc_classes>

<assignee>
BLUVECTOR
</assignee>

<inventors>
MISERENDINO, SCOTT B.
KALOROUMAKIS, PETER E.
KLEIN, ROBERT H.
PETERS, RYAN V.
</inventors>

<docdb_family_id>
57886450
</docdb_family_id>

<title>
System and method for machine learning model determination and malware identification
</title>

<abstract>
A system and method for batched, supervised, in-situ machine learning classifier retraining for malware identification and model heterogeneity. The method produces a parent classifier model in one location and providing it to one or more in-situ retraining system or systems in a different location or locations, adjudicates the class determination of the parent classifier over the plurality of the samples evaluated by the in-situ retraining system or systems, determines a minimum number of adjudicated samples required to initiate the in-situ retraining process, creates a new training and test set using samples from one or more in-situ systems, blends a feature vector representation of the in-situ training and test sets with a feature vector representation of the parent training and test sets, conducts machine learning over the blended training set, evaluates the new and parent models using the blended test set and additional unlabeled samples, and elects whether to replace the parent classifier with the retrained version.
</abstract>

<claims>
1. A method comprising: receiving a first machine learning model and information indicating a first plurality of attributes associated with a first plurality of files, wherein training data, for the first machine learning model, comprises the first plurality of files; determining, based on the first machine learning model, a plurality of classifications for a second plurality of files; based on adjudicating one or more of the plurality of classifications, determining a second plurality of attributes associated with the second plurality of files; and determining, using at least a portion of the first plurality of attributes and at least a portion of the second plurality of attributes, a second machine learning model.
2. The method of claim 1, wherein the first plurality of attributes was extracted from the first plurality of files, wherein the first plurality of attributes comprises at least one of a file header property, a component of a file, or a binary sequence, and wherein the second plurality of attributes was extracted from the second plurality of files, wherein the second plurality of attributes comprises at least one of a file header property, a component of a file, or a binary sequence.
3. The method of claim 1, wherein the determining the second machine learning model comprises training and testing the second machine model based on a machine learning algorithm, wherein the first machine learning model was trained and tested based on the machine learning algorithm.
4. The method of claim 3, wherein the machine learning algorithm comprises a decision tree, support vector machine, a k-nearest neighbor algorithm, an artificial neural network, or a Bayesian network.
5. The method of claim 1, wherein each classification of the plurality of classifications comprises at least one of malicious content or benign content.
6. The method of claim 1, wherein the adjudicating comprises: confirming classifications of the plurality of classifications that are correct; and adjusting classifications of the plurality of classifications that are not correct.
7. The method of claim 1, wherein the adjudicating indicates an accuracy of the first machine learning model at determining the plurality of classifications and relevant attributes for determining the plurality of classifications.
8. The method of claim 1, wherein the determining the second machine learning model is triggered based on adjudicating a threshold number of classifications of the plurality of classifications.
9. The method of claim 1, further comprising: receiving, from at least one computing device, second information indicating a third plurality of attributes associated with a third plurality of files, wherein a third machine learning model was trained using the third plurality of files, wherein the determining the second machine learning model further uses at least a portion of the third plurality of attributes.
10. The method of claim 1, further comprising: determining, based on the second machine learning model, that at least one file comprises malicious content.
11. The method of claim 1, wherein the second plurality of files are unique to an organization.
12. The method of claim 1, wherein the second machine learning model is configured such that determining the second plurality of attributes is prevented when inputting the first plurality of files.
13. A device comprising: one or more processors; and memory storing instructions that, when executed by the one or more processors, cause the device to: receive a first machine learning model and information indicating a first plurality of attributes associated with a first plurality of files, wherein training data, for the first machine learning model, comprises the first plurality of files; determine, based on the first machine learning model, a plurality of classifications for a second plurality of files; based on adjudicating one or more of the plurality of classifications, determine a second plurality of attributes associated with the second plurality of files; and determine, using at least a portion of the first plurality of attributes and at least a portion of the second plurality of attributes, a second machine learning model.
14. The device of claim 13, wherein each classification of the plurality of classifications comprises at least one of malicious content or benign content.
15. The device of claim 13, wherein the adjudicating comprises: confirming classifications of the plurality of classifications that are correct; and adjusting classifications of the plurality of classifications that are not correct.
16. The device of claim 13, wherein the adjudicating indicates an accuracy of the first machine learning model at determining the plurality of classifications and relevant attributes for determining the plurality of classifications.
17. The device of claim 13, wherein the determining the second machine learning model is triggered based on adjudicating a threshold number of classifications of the plurality of classifications.
18. The device of claim 13, wherein the instructions, when executed by the one or more processors, further cause the device to: receive, from at least one computing device, second information indicating a third plurality of attributes associated with a third plurality of files, wherein a third machine learning model was trained using the third plurality of files, wherein the determining the second machine learning model further uses at least a portion of the third plurality of attributes.
19. The device of claim 13, wherein the instructions, when executed by the one or more processors, further cause the device to: determine, based on the second machine learning model, that at least one file comprises malicious content.
20. The device of claim 13, wherein the second plurality of files are unique to an organization.
21. The device of claim 13, wherein the second machine learning model is configured such that determining the second plurality of attributes is prevented when inputting the first plurality of files.
22. A non-transitory computer-readable storage medium storing computer-readable instructions that, when executed by a processor, cause: receiving a first machine learning model and information indicating a first plurality of attributes associated with a first plurality of files, wherein training data, for the first machine learning model, comprises the first plurality of files; determining, based on the first machine learning model, a plurality of classifications for a second plurality of files; based on adjudicating one or more of the plurality of classifications, determining a second plurality of attributes associated with the second plurality of files; and determining, using at least a portion of the first plurality of attributes and at least a portion of the second plurality of attributes, a second machine learning model.
23. The non-transitory computer-readable storage medium of claim 22, wherein the adjudicating comprises: confirming classifications of the plurality of classifications that are correct; and adjusting classifications of the plurality of classifications that are not correct.
24. The non-transitory computer-readable storage medium of claim 22, further storing computer-readable instructions that, when executed by the processor, cause: determining, based on the second machine learning model, that at least one file comprises malicious content.
25. The non-transitory computer-readable storage medium of claim 22, wherein the second plurality of files are unique to an organization.
26. The non-transitory computer-readable storage medium of claim 22, wherein the second machine learning model is configured such that determining the second plurality of attributes is prevented when inputting the first plurality of files.
</claims>
</document>
