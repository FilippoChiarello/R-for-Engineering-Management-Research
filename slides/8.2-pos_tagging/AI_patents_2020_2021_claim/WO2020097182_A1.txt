<document>

<filing_date>
2019-11-06
</filing_date>

<publication_date>
2020-05-14
</publication_date>

<priority_date>
2018-11-07
</priority_date>

<ipc_classes>
G06F21/62,G06N3/08,G06T9/00
</ipc_classes>

<assignee>
NEC LABORATORIES AMERICA
</assignee>

<inventors>
CHANDRAKER, MANMOHAN
SOHN, KIHYUK
TSAI, YI-HSUAN
</inventors>

<docdb_family_id>
70459959
</docdb_family_id>

<title>
PRIVACY-PRESERVING VISUAL RECOGNITION VIA ADVERSARIAL LEARNING
</title>

<abstract>
A method for protecting visual private data by preventing data reconstruction from latent representations of deep networks is presented. The method includes obtaining latent features (316) from an input image (312) and learning, via an adversarial reconstruction learning framework (318), privacy -preserving feature representations to maintain utility performance and prevent the data reconstruction by: simulating a black-box model inversion attack by training a decoder (332) to reconstruct the input image from the latent features and training an encoder (314) to maximize a reconstruction error to prevent the decoder from inverting the latent features while minimizing the task loss.
</abstract>

<claims>
1. A computerimplemented method executed on a processor for protecting visual private data by preventing data reconstruction from latent representations of deep networks, the method comprising:
obtaining latent features (316) from an input image (312); and
learning, via an adversarial reconstruction learning framework (318), privacy preserving feature representations to maintain utility performance and prevent the data reconstruction by:
simulating a black-box model inversion attack by training a decoder (332) to reconstruct the input image from the latent features; and
training an encoder (314) to maximize a reconstruction error to prevent the decoder from inverting the latent features while minimizing the task loss.
2. The method of claim 1 , wherein the latent features are transmitted and stored on a cloud for further processing.
3. The method of claim 1, wherein the adversarial reconstruction learning framework adopts a multilayer perceptron (MLP) classifier that predicts a utility label by minimizing a utility loss.
4. The method of claim 3, wherein the utility loss is given by: where f(Z) = c> C -EiieOO) " , Y v i ·s a ground ,-trut .h , la.be,l f·or u ,tirlitty, £*"' is a standard loss for utility, X is an input, and is private training data.
5. The method of claim 4, wherein the decoder is trained to compete against the encoder such that the decoder leams to decode an output of the encoder by minimizing a reconstruction loss.
6. The method of claim 5, wherein the reconstruction loss is given by:
>
where X is an input, Z is the output of the encoder, and *'l is private training data.
7. The method of claim 6, wherein a quality of reconstruction is modified by employing a perceptual similarity loss given by: where X is an input, Z is the output of the encoder, and LI is private training data.
8. The method of claim 7, wherein an overall training objective of a protector is given by: JC- £
where ^is the utility loss, is the reconstruction loss, the perceptual similarity loss.
9. A non-transitory computer-readable storage medium comprising a computerreadable program for protecting visual private data by preventing data reconstruction from latent representations of deep networks, wherein the computer-readable program when executed on a computer causes the computer to perform the steps of:
obtaining latent features (316) from an input image (312); and
learning, via an adversarial reconstruction learning framework (318), privacy preserving feature representations to maintain utility performance and prevent the data reconstruction by:
simulating a black-box model inversion attack by training a decoder (332) to reconstruct the input image from the latent features; and
training an encoder (314) to maximize a reconstruction error to prevent the decoder from inverting the latent features while minimizing the task loss.
10. The non-transitory computer-readable storage medium of claim 9, wherein the latent features are transmitted and stored on a cloud for further processing.
11. The non-transitory computer-readable storage medium of claim 9, wherein the adversarial reconstruction learning framework adopts a multilayer perceptron (MLP) classifier that predicts a utility label by minimizing a utility loss.
12. The non-transitory computer-readable storage medium of claim 11, wherein the utility loss is given by: ,
nd-truth label for u ,t rlitty, £ i .s a
V
standard loss for utility, X is an input, and is private training data.
13. The non-transitory computer-readable storage medium of claim 12, wherein the decoder is trained to compete against the encoder such that the decoder leams to decode an output of the encoder by minimizing a reconstruction loss.
14. The non-transitory computer-readable storage medium of claim 13, wherein the reconstruction loss is given by: where X is an input, Z is the output of the encoder, and is private training data.
15. The non-transitory computer-readable storage medium of claim 14, wherein a quality of reconstruction is modified by employing a perceptual similarity loss given by:
·> where X is an input, Z is the output of the encoder, and g is private training data.
16. The non-transitory computer-readable storage medium of claim 15, wherein an overall training objective of a protector is given by: where is the utility loss, the reconstruction loss, and is the perceptual similarity loss.
17. A system for protecting visual private data by preventing data reconstruction from latent representations of deep networks, the system comprising:
a memory; and
one or more processors in communication with the memory configured to:
obtain latent features (316) from an input image (312); and leam, via an adversarial reconstruction learning framework (318), privacy preserving feature representations to maintain utility performance and prevent the data reconstruction by:
simulating a black-box model inversion attack by training a decoder (332) to reconstruct the input image from the latent features; and
training an encoder (314) to maximize a reconstruction error to prevent the decoder from inverting the latent features while minimizing the task loss.
18. The system of claim 17, wherein the adversarial reconstruction learning framework adopts a multilayer perceptron (MLP) classifier that predicts a utility label by minimizing a utility loss given by: where f(Z) = c> C -EiieOO) " , Y v i ·s a ground ,-trut .h , la.be,l f·or u ,t rlitty, £*"' is a standard loss for utility, X is an input, and is private training data.
19. The system of claim 18, wherein the decoder is trained to compete against the encoder such that the decoder leams to decode an output of the encoder by minimizing a reconstruction loss given by: where X is an input, Z is the output of the encoder, and Y is private training data.
20. The system of claim 19, wherein a quality of reconstruction is modified by employing a perceptual similarity loss given by: where X is an input, Z is the output of the encoder, and is private training data.
</claims>
</document>
