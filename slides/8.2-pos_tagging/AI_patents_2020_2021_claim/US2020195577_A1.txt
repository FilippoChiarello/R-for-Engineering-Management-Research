<document>

<filing_date>
2019-12-09
</filing_date>

<publication_date>
2020-06-18
</publication_date>

<priority_date>
2018-12-17
</priority_date>

<ipc_classes>
G06N3/08,H04L12/911,H04L29/06,H04L29/08
</ipc_classes>

<assignee>
ETRI (ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE)
</assignee>

<inventors>
CHUNG, BYUNG CHANG
</inventors>

<docdb_family_id>
71073096
</docdb_family_id>

<title>
System and method for selecting optimal path in multi-media multi-path network
</title>

<abstract>
A system and method for selecting an optimal path in a multi-media multi-path network. The system for selecting an optimal path in a multi-media multi-path network includes a memory storing a program for selecting an optimal path in the multi-media multi-path network and a processor for executing the program, wherein the processor uses a network performance parameter, which serves as state information, as an input value of a reinforcement learning algorithm and selects an optimal path using a Q-table obtained by applying the reinforcement learning algorithm.
</abstract>

<claims>
1. A system for selecting an optical path in a multi-path network, the system comprising: a memory storing a program for selection of an optimal path in the multi-path network; and a processor configured to execute the program, wherein the processor uses a network performance parameter, which serves as state information, as an input value of a reinforcement learning algorithm and selects an optimal path using a Q-table obtained by applying the reinforcement learning algorithm.
2. The system of claim 1, wherein the network performance parameter comprises a round trip time (RTT) and input arrival rate information.
3. The system of claim 2, wherein the processor performs learning by matching the RTT with an action selection result of a previous section.
4. The system of claim 3, wherein the processor uses a predetermined RTT of an N-time previous section as an input value.
5. The system of claim 2, wherein the processor reflects the input arrival rate information as state information, together with path selection results of other services.
6. The system of claim 1, wherein the processor predicts the Q-table by applying a deep Q learning algorithm and outputs recommended path information for a corresponding user and service.
7. The system of claim 6, wherein the processor selects a path by considering whether multi-path transmission is to be performed and considering quality requirement values of the user and the service as user profile information and service profile information.
8. The system of claim 1, wherein the processor performs learning considering asynchronicity between an action and a reward using a time buffer.
9. A method of selecting an optical path in a multi-path network, the method comprising: (a) performing pre-processing to define an input value of a reinforcement learning algorithm for selection of an optimal path in the multi-path network; (b) obtaining a Q-table by applying the reinforcement learning algorithm to the input value; and (c) selecting an optimal path using the Q-table.
10. The method of claim 9, wherein (a) comprises defining a network performance parameter, which serves as state information, as the input value, the network performance parameter including a round trip time (RTT) and input arrival rate information.
11. The method of claim 10, wherein (b) comprises performing learning by matching the RTT with an action selection result of a previous section.
12. The method of claim 10, wherein (a) comprises reflecting the input arrival rate information as state information, together with path selection results of other services.
13. The method of claim 10, wherein (c) comprises selecting a path in consideration of user profile information and service profile information.
</claims>
</document>
