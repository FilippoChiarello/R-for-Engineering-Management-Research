<document>

<filing_date>
2019-09-02
</filing_date>

<publication_date>
2020-06-03
</publication_date>

<priority_date>
2018-11-30
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06K9/62
</ipc_classes>

<assignee>
BAIDU USA
</assignee>

<inventors>
HU, JIANGTAO
LI, DONG
MIAO, JINGHAO
SUN, HONGYI
ZHANG, LIANGLIANG
</inventors>

<docdb_family_id>
67841018
</docdb_family_id>

<title>
REAL TIME OBJECT BEHAVIOR PREDICTION
</title>

<abstract>
In one embodiment, a method, apparatus, and system may predict behavior of environmental objects using machine learning at an autonomous driving vehicle (ADV). A data processing architecture comprising at least a first neural network and a second neural network is generated, the first and the second neural networks having been trained with a training data set. Behavior of one or more objects in the ADV's environment is predicted using the data processing architecture comprising the trained neural networks. Driving signals are generated based at least in part on the predicted behavior of the one or more objects in the ADV's environment to control operations of the ADV.
</abstract>

<claims>
1. A computer-implemented method for predicting behavior of environmental objects using machine learning at an autonomous driving vehicle, ADV, comprising: applying a first neural network to perception data received from perception of the ADV at a point in time to extract a set of perception features; predicting behavior of one or more objects in the ADV's environment using a second neural network based on the extracted perception features from the first neural network and map information obtained from a map; and generating control commands based at least in part on the predicted behavior of the one or more objects in the ADV's environment to control operations of the ADV.
2. The method of claim 1, wherein the one or more objects comprise automobiles, bicycles, and/or pedestrians.
3. The method of claim 1 or 2, wherein the first neural network is a multilayer perceptron, and the second neural network is a convolutional neural network, CNN.
4. The method of any one of claims 1-3, wherein the first neural network receives historical features of the one or more objects from one or more previous planning cycles as inputs, and generates extracted historical features of the one or more objects as outputs, and wherein the second neural network receives the extracted historical features of the one or more objects and map information as inputs, and generates predicted behavior of the one or more objects as outputs.
5. The method of claim 4, wherein the historical features of the one or more objects comprise one or more of: a position, a speed, or an acceleration, and wherein the map information is derived from a high-definition map and comprises one or more of: a lane feature component, a traffic signal component, a static object component, or a general map information component.
6. The method of claim 4, wherein the extracted historical features of the one or more objects and the map information are labeled with associated block information based on a grid subdivision of a rectangular perception and prediction area of the ADV, the grid subdivision comprising subdividing the rectangular perception and prediction area of the ADV into a plurality of uniformly sized rectangular blocks based on a grid.
7. The method of claim 6, wherein predicted behavior of the one or more objects is represented as a list of numbers, the numbers indicating, for each block in the perception and prediction area that is predicted to contain an object, one or more of: an object type, one or more features relating to the predicted behavior of the object associated with the block, or a confidence level.
8. A non-transitory machine-readable medium having instructions stored therein, which when executed by a processor (1501), cause the processor (1501) to perform the method of any one of claims 1-7.
9. A data processing system, comprising: a processor (1501); and a memory (1503) coupled to the processor (1501) to store instructions, which when executed by the processor (1501), cause the processor (1501) to perform operations for predicting behavior of environmental objects using machine learning at an autonomous driving vehicle, ADV, the operations including: applying a first neural network to perception data received from perception of the ADV at a point in time to extract a set of perception features; predicting behavior of one or more objects in the ADV's environment using a second neural network based on the extracted perception features from the first neural network and map information obtained from a map; and generating control commands based at least in part on the predicted behavior of the one or more objects in the ADV's environment to control operations of the ADV.
10. The data processing system of claim 9, wherein the one or more objects comprise automobiles, bicycles, and/or pedestrians.
11. The data processing system of claim 9 or 10, wherein the first neural network is a multilayer perceptron, and the second neural network is a convolutional neural network, CNN.
12. The data processing system of any one of claims 9-11, wherein the first neural network receives historical features of the one or more objects from one or more previous planning cycles as inputs, and generates extracted historical features of the one or more objects as outputs, and wherein the second neural network receives the extracted historical features of the one or more objects and map information as inputs, and generates predicted behavior of the one or more objects as outputs.
13. The data processing system of claim 12, wherein the historical features of the one or more objects comprise one or more of: a position, a speed, or an acceleration, and wherein the map information is derived from a high-definition map and comprises one or more of: a lane feature component, a traffic signal component, a static object component, or a general map information component.
14. The data processing system of claim 12, wherein the extracted historical features of the one or more objects and the map information are labeled with associated block information based on a grid subdivision of a rectangular perception and prediction area of the ADV, the grid subdivision comprising subdividing the rectangular perception and prediction area of the ADV into a plurality of uniformly sized rectangular blocks based on a grid.
15. The data processing system of claim 14, wherein predicted behavior of the one or more objects is represented as a list of numbers, the numbers indicating, for each block in the perception and prediction area that is predicted to contain an object, one or more of: an object type, one or more features relating to the predicted behavior of the object associated with the block, or a confidence level.
</claims>
</document>
