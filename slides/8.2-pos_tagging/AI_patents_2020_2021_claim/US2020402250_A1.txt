<document>

<filing_date>
2020-09-03
</filing_date>

<publication_date>
2020-12-24
</publication_date>

<priority_date>
2017-11-15
</priority_date>

<ipc_classes>
G06N3/04,G06N3/08,G06T7/285,G06T7/579
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
WICKE, MARTIN
ANGELOVA, ANELIA
MAHJOURIAN, REZA
</inventors>

<docdb_family_id>
64572602
</docdb_family_id>

<title>
UNSUPERVISED LEARNING OF IMAGE DEPTH AND EGO-MOTION PREDICTION NEURAL NETWORKS
</title>

<abstract>
A system includes a neural network implemented by one or more computers, in which the neural network includes an image depth prediction neural network and a camera motion estimation neural network. The neural network is configured to receive a sequence of images. The neural network is configured to process each image in the sequence of images using the image depth prediction neural network to generate, for each image, a respective depth output that characterizes a depth of the image, and to process a subset of images in the sequence of images using the camera motion estimation neural network to generate a camera motion output that characterizes the motion of a camera between the images in the subset. The image depth prediction neural network and the camera motion estimation neural network have been jointly trained using an unsupervised learning technique.
</abstract>

<claims>
1. A system comprising: a neural network implemented by one or more computers, wherein the neural network comprises an image depth prediction neural network and a camera motion estimation neural network, wherein the neural network is configured to receive a sequence of images, and process each image in the sequence of images using the image depth prediction neural network to generate, for each image, a respective depth output that characterizes a depth of the image, and process a subset of images in the sequence of images using the camera motion estimation neural network to generate a camera motion output that characterizes the motion of a camera between the images in the subset, wherein the image depth prediction neural network and the camera motion estimation neural network have been jointly trained using an unsupervised learning technique.
2. The system of claim 1, wherein the sequence of images are frames of a video captured by the camera.
3. The system of claim 1, wherein the depth output comprises an estimated depth value for each pixel of a plurality of pixels in the image that represents a respective distance of a scene depicted at the pixel from a focal plane of the image.
4. The system of claim 1, wherein the camera motion output is a transformation matrix that transforms the position and orientation of the camera from its point of view while taking a first image in the subset to its point of view while taking a second image in the subset.
5. The system of claim 1, wherein the image depth prediction neural network includes convolutional neural network layers.
6. The system of claim 1, wherein the camera motion estimation neural network includes convolutional neural network layers.
7. The system of claim 1, wherein the subset of images includes two images in the sequence of images.
8. The system of claim 1, wherein the subset of images includes three or more images in the sequence of images.
9. One or more non-transitory computer-readable storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform operations comprising: receiving a sequence of images; processing, using an image depth prediction neural network, each image in the sequence of images to generate, for each image, a respective depth output that characterizes a depth of the image; and processing, using a camera motion estimation neural network, a subset of images in the sequence of images to generate a camera motion output that characterizes the motion of a camera between the images in the subset, wherein the image depth prediction neural network and the camera motion estimation neural network have been jointly trained using an unsupervised learning technique.
10. The one or more non-transitory computer-readable storage media of claim 9, wherein the sequence of images are frames of a video captured by the camera.
11. The one or more non-transitory computer-readable storage media of claim 9, wherein the depth output comprises an estimated depth value for each pixel of a plurality of pixels in the image that represents a respective distance of a scene depicted at the pixel from a focal plane of the image.
12. The one or more non-transitory computer-readable storage media of claim 9, wherein the camera motion output is a transformation matrix that transforms the position and orientation of the camera from its point of view while taking a first image in the subset to its point of view while taking a second image in the subset.
13. The one or more non-transitory computer-readable storage media of claim 9, wherein the image depth prediction neural network includes convolutional neural network layers.
14. The one or more non-transitory computer-readable storage media of claim 9, wherein the camera motion estimation neural network includes convolutional neural network layers.
15. The one or more non-transitory computer-readable storage media of claim 9, wherein the subset of images includes two images in the sequence of images.
16. The one or more non-transitory computer-readable storage media of claim 9, wherein the subset of images includes three or more images in the sequence of images.
17. A computer-implemented method comprising: receiving a sequence of images; processing, using an image depth prediction neural network, each image in the sequence of images to generate, for each image, a respective depth output that characterizes a depth of the image; and processing, using a camera motion estimation neural network, a subset of images in the sequence of images to generate a camera motion output that characterizes the motion of a camera between the images in the subset, wherein the image depth prediction neural network and the camera motion estimation neural network have been jointly trained using an unsupervised learning technique.
18. The method of claim 17, wherein the sequence of images are frames of a video captured by the camera.
19. The method of claim 17, wherein the depth output comprises an estimated depth value for each pixel of a plurality of pixels in the image that represents a respective distance of a scene depicted at the pixel from a focal plane of the image.
20. The method of claim 17, wherein the camera motion output is a transformation matrix that transforms the position and orientation of the camera from its point of view while taking a first image in the subset to its point of view while taking a second image in the subset.
</claims>
</document>
