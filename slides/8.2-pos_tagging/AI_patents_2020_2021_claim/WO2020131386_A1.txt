<document>

<filing_date>
2019-12-04
</filing_date>

<publication_date>
2020-06-25
</publication_date>

<priority_date>
2018-12-17
</priority_date>

<ipc_classes>
G06F17/00,G06F7/00,G06F9/44,G06K9/62
</ipc_classes>

<assignee>
SHAPE SECURITY
</assignee>

<inventors>
MILLER, KENTON
SHAH SAMIR
ZHANG BEI
</inventors>

<docdb_family_id>
71071073
</docdb_family_id>

<title>
DECISION TREE TRAINING USING A DATABASE SYSTEM
</title>

<abstract>
In an embodiment, a method for training a decision tree comprising a plurality of nodes using a database system comprises: storing in a database input data for training the decision tree, the input data comprising a plurality of feature values corresponding to a plurality of features; generating a particular node of the plurality of decision nodes by: selecting a subset of the plurality of features and a subset of the input data; using one or more queries to the database system, for each feature of the subset of the plurality of features, calculating an information gain associated with the feature based on the subset of the input data; identifying a particular feature of the subset of the plurality of features associated with the highest information gain; associating the particular node with the particular feature, wherein the particular node causes the decision tree to branch based on the particular feature.
</abstract>

<claims>
What is claimed is:
1. A computer-implemented method for training a decision tree using a database system, the decision tree comprising a plurality of decision nodes, the method comprising:
by one or more computing devices, storing in a database input data for training the decision tree, the input data comprising a plurality of feature values corresponding to a plurality of features;
by the one or more computing devices, generating a particular node of the plurality of decision nodes by:
selecting a subset of the plurality of features and a subset of the input data; using one or more queries to the database system, for each feature of the subset of the plurality of features, calculating an information gain associated with the feature based on the subset of the input data;
identifying a particular feature of the subset of the plurality of features associated with the highest information gain;
associating the particular node with the particular feature, wherein the particular node causes the decision tree to branch based on the particular feature.
2. The method of Claim 1 further comprising generating the plurality of decision nodes by performing the selecting, calculating, identifying, and associating for each decision nodes of the plurality of decision nodes of the decision tree.
3. The method of Claim 2 wherein generating at least a portion of multiple decision nodes among the plurality of decision nodes is performed in parallel.
4. The method of Claim 2 further comprising generating a query to the database system corresponding to the decision tree, wherein the query, when executed using the database system, applies the decision tree to a set of input data.
5. The method of Claim 2 further comprising generating one or more program instructions corresponding to the decision tree, wherein the one or more program instructions, when executed, applies the decision tree to a set of input data.
6. The method of Claim 2 further comprising generating a random forest comprising a plurality of decision trees by generating, for each decision tree of the plurality of decision trees, a respective plurality of decision nodes.
7. The method of Claim 6 further comprising generating a query to the database system corresponding to the random forest, wherein the query, when executed using the database system, applies each decision tree of the plurality of decision trees to a set of input data.
8. The method of Claim 6 further comprising generating a random forest comprising a plurality of decision trees by generating, for each decision tree of the plurality of decision trees, a respective plurality of decision nodes.
9. The method of Claim 1 wherein the selecting the subset of the plurality of features comprises randomly selecting the features in the subset.
10. The method of Claim 1 wherein the selecting the subset of the input data comprises randomly selecting data in the subset.
11. The method of Claim 1 wherein calculating the information gain associated with each feature comprises:
determining a data type associated with the feature;
based on the data type, identifying one or more conditions for partitioning the subset of the input data;
calculating a respective information gain for each condition of the one or more conditions;
selecting the highest respective information gain as the information gain associated with the feature.
12. The method of Claim 11 wherein the data type is categorical data and identifying the one or more conditions comprises identifying a plurality of feature categories.
13. The method of Claim 11 wherein the data type is numerical data and identifying the one or more conditions comprises identifying a plurality of numeric value ranges.
14. The method of Claim 11 wherein the data type is strings and identifying the one or more conditions comprises identifying a plurality of token sets, each token set comprising one or more string tokens.
15. The method of Claim 1, wherein the method is performed using a first computer of a distributed computing system and the database system is hosted using a second computer of the distributed computing system.
16. A database system configured to train a decision tree, the decision tree comprising a plurality of decision nodes, the database system comprising:
one or more processors;
a database;
a digital electronic memory storing instructions which, when executed using the one or more processors, cause:
storing, in the database, input data for training the decision tree, the input data comprising a plurality of feature values corresponding to a plurality of features;
generating a particular node of the plurality of decision nodes by:
selecting a subset of the plurality of features and a subset of the input data; using one or more queries to the database system, for each feature of the subset of the plurality of features, calculating an information gain associated with the feature based on the subset of the input data;
identifying a particular feature of the subset of the plurality of features associated with the highest information gain;
associating the particular node with the particular feature, wherein the particular node causes the decision tree to branch based on the particular feature.
17. The database system of Claim 16 further comprising further comprising instructions which, when executed using the one or more processors, cause generating the plurality of decision nodes by performing the selecting, calculating, identifying, and associating for each decision nodes of the plurality of decision nodes of the decision tree.
18. The database system of Claim 17 wherein generating at least a portion of multiple decision nodes among the plurality of decision nodes is performed in parallel.
19. The database system of Claim 17 further comprising instructions which, when executed using the one or more processors, cause generating a query to the database system corresponding to the decision tree, wherein the query, when executed using the database system, applies the decision tree to a set of input data.
20. The database system of Claim 17 further comprising instructions which, when executed using the one or more processors, cause generating one or more program instructions corresponding to the decision tree, wherein the one or more program instructions, when executed, applies the decision tree to a set of input data.
21. The database system of Claim 17 further comprising instructions which, when executed using the one or more processors, cause generating a random forest comprising a plurality of decision trees by generating, for each decision tree of the plurality of decision trees, a respective plurality of decision nodes.
22. The database system of Claim 21 further comprising instructions which, when executed using the one or more processors, cause generating a query to the database system corresponding to the random forest, wherein the query, when executed using the database system, applies each decision tree of the plurality of decision trees to a set of input data.
23. The database system of Claim 21 further comprising instructions which, when executed using the one or more processors, cause generating a random forest comprising a plurality of decision trees by generating, for each decision tree of the plurality of decision trees, a respective plurality of decision nodes.
24. The database system of Claim 16 wherein the selecting the subset of the plurality of features comprises randomly selecting the features in the subset.
25. The database system of Claim 16 wherein the selecting the subset of the input data comprises randomly selecting data in the subset.
26. The database system of Claim 16 wherein calculating the information gain associated with each feature comprises:
determining a data type associated with the feature;
based on the data type, identifying one or more conditions for partitioning the subset of the input data;
calculating a respective information gain for each condition of the one or more conditions;
selecting the highest respective information gain as the information gain associated with the feature.
27. The database system of Claim 26 wherein the data type is categorical data and identifying the one or more conditions comprises identifying a plurality of feature categories.
28. The database system of Claim 26 wherein the data type is numerical data and identifying the one or more conditions comprises identifying a plurality of numeric value ranges.
29. The database system of Claim 26 wherein the data type is strings and identifying the one or more conditions comprises identifying a plurality of token sets, each token set comprising one or more string tokens.
</claims>
</document>
