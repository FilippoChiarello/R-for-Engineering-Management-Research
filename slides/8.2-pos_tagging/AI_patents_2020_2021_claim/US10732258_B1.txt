<document>

<filing_date>
2016-09-26
</filing_date>

<publication_date>
2020-08-04
</publication_date>

<priority_date>
2016-09-26
</priority_date>

<ipc_classes>
G01S5/18,G06N3/08,G06N7/00,G10L15/22,G10L25/30,G10L25/84,G10L25/87,H03G3/00
</ipc_classes>

<assignee>
AMAZON TECHNOLOGIES
</assignee>

<inventors>
WANG RUI
SUNDARAM, SHIVA KUMAR
</inventors>

<docdb_family_id>
71838947
</docdb_family_id>

<title>
Hybrid audio-based presence detection
</title>

<abstract>
A system capable of detecting human presence based on output from a model-free detector and model-based detector(s). For example, the model-free detector may identify acoustic events and the model-based detectors can determine specific types of acoustic events and whether the acoustic events are associated with human activity. Using output from the model-based detectors, a device may confirm that an acoustic event identified by the model-free detector is associated with human activity or may determine that the acoustic event is associated with non-human activity and can be ignored. Thus, the device may detect human presence based on a wide variety of noises while reducing a number of false positives associated with the model-free detector.
</abstract>

<claims>
1. A computer-implemented method for detecting human activity, the method comprising: capturing input audio data using a microphone located at a location; generating a first feature vector from the input audio data using a feature extractor; processing the first feature vector using an audio activity detector to determine that a first audio signal level corresponding to a first portion of the first feature vector exceeds a reference audio signal level by more than a threshold value, the first portion of the first feature vector representing first audio captured during a first period of time; generating, by the audio activity detector, first indicator data including a first logic high level indicating, for the first period of time, detected audio activity; determining, using a trained neural network that is separate from the audio activity detector, that a second portion of the first feature vector corresponds to speech, the trained neural network configured to distinguish between types of acoustic events, the second portion of the first feature vector representing second audio captured during a second period of time that includes at least a portion of the first period of time; generating, by the trained neural network, second indicator data including a second logic high level indicating, for the second period of time, that the second portion of the first feature vector corresponds to detected speech, the second indicator data corresponding to a first confidence score that indicates a first likelihood that a human is present; processing, using a trained model, the first indicator data generated by the audio activity detector and the second indicator data generated by the trained neural network to determine a second confidence score indicating a second likelihood that a human is present; determining, by the trained model, that a human is present at the location during a third period of time, the third period of time longer than the second period of time; and generating output data indicating presence of a human during the third period of time at the location.
2. The computer-implemented method of claim 1, further comprising: generating a second feature vector from the input audio data using the feature extractor; processing the second feature vector using the audio activity detector to determine that a second audio signal level corresponding to a first portion of the second feature vector exceeds the reference audio signal level by more than the threshold value, the first portion of the second feature vector representing third audio captured during a fourth period of time; generating, by the audio activity detector, third indicator data including a third logic high level indicating, for the fourth period of time, detected audio activity; determining, using the trained neural network, that a second portion of the second feature vector corresponds to an audible sound associated with an animal, the second portion of the second feature vector representing fourth audio captured during a fifth period of time that includes a portion of the fourth period of time; generating, by the trained neural network, fourth indicator data including a fourth logic high level indicating, for the fifth period of time, that the second portion of the second feature vector corresponds to the audible sound associated with the animal; processing, using the trained model, the third indicator data and the fourth indicator data to determine that human presence is not detected at the location during the fourth period of time; and generating second output data indicating that human presence is not detected during the fourth period of time at the location.
3. The computer-implemented method of claim 1, further comprising, by the audio activity detector: receiving the first feature vector; determining, using the first portion of the first feature vector, the first audio signal level; determining the reference audio signal level associated with the input audio data, wherein the reference audio signal level corresponds to an average signal value of the input audio data over a duration of time; determining a difference between the first audio signal level and the reference audio signal level; determining that the difference exceeds the threshold value; and generating the first indicator data, the first indicator data indicating that the first audio signal level of the first portion of the first feature vector exceeds the reference audio signal level by more than the threshold value during the first period of time.
4. A computer-implemented method, comprising: receiving, from at least one microphone associated with a device, an audio signal; receiving, from an audio change detector associated with the device, first indication data indicating that a first energy level associated with a first portion of the audio signal exceeds a threshold value, the first portion of the audio signal corresponding to a first period of time, the audio change detector configured to detect changes in a signal level of the audio signal; determining, using a first acoustic event detector of the device that is separate from the audio change detector, based on the first portion of the audio signal, second indication data indicating that the audio signal corresponds to a first type of acoustic event during the first period of time, the first acoustic event detector configured to distinguish between the first type of acoustic event and other types of acoustic events, the second indication data corresponding to a first confidence score that indicates a first likelihood that a human is present; determining, based on the first indication data received from the audio change detector and the second indication data determined by the acoustic event detector, a second confidence score indicating a second likelihood that a human is present during the first period of time; determining that the second confidence score satisfies a condition; and in response to determining that the second confidence score satisfies the condition, generating output data indicating that a human is present during the first period of time.
5. The computer-implemented method of claim 4, further comprising: receiving, from a second acoustic event detector, third indication data indicating that the audio signal does not correspond to a second type of acoustic event during the first period of time, the second type being different than the first type; and determining, based on the first indication data, the second indication data, and the third indication data, that a human is present during the first period of time.
6. The computer-implemented method of claim 4, further comprising: receiving, from the audio change detector, third indication data indicating that a second energy level associated with a second portion of the audio signal corresponding to a second period of time exceeds the threshold value; determining, using a second acoustic event detector based on the second portion of the audio signal, fourth indication data indicating that the audio signal corresponds to a second type of acoustic event during the second period of time, the second acoustic event detector configured to distinguish between the second type of acoustic event and other types of acoustic events, the second type being different than the first type; determining, based on the third indication data and the fourth indication data, that a human is not present during the second period of time; and generating second output data indicating that a human is not present during the second period of time.
7. The computer-implemented method of claim 4, further comprising: receiving a feature vector, the feature vector generated from the audio signal; determining the first energy level using a first portion of the feature vector that corresponds to the first period of time; determining a reference audio signal level associated with the audio signal; determining a difference between the first energy level and the reference audio signal level; determining that the difference exceeds a threshold value; and generating the first indication data indicating that the first energy level associated with the first portion of the audio signal exceeds the threshold value during the first period of time.
8. The computer-implemented method of claim 4, further comprising: determining, based on the first indication data and the second indication data, a first signal to noise ratio corresponding to a first time duration and associated with the audio change detector; determining, based on the first indication data and the second indication data, a second signal to noise ratio corresponding to the first time duration and associated with the first acoustic event detector; and determining, based on the first indication data, the second indication data, the first signal to noise ratio and the second signal to noise ratio, the second confidence score indicating the second likelihood that a human is present during the first period of time.
9. The computer-implemented method of claim 4, further comprising: determining, based on the first indication data and the second indication data, a first signal to noise ratio corresponding to a first time duration; determining, based on the first indication data and the second indication data, a second signal to noise ratio corresponding to a second time duration; and determining, based on the first indication data, the second indication data, the first signal to noise ratio and the second signal to noise ratio, the second confidence score indicating the second likelihood that a human is present during the first period of time.
10. The computer-implemented method of claim 4, wherein the first acoustic event detector includes a deep neural-network configured to detect speech, the deep neural-network trained using a corpus of training data including a large number of acoustic events associated with speech, the deep neural-network configured to improve performance over time in response to acoustic events not included in the training data.
11. The computer-implemented method of claim 4, wherein the audio change detector generates the first indication data at least partially simultaneously to the first acoustic event detector generating the second indication data.
12. The computer-implemented method of claim 4, further comprising: in response to the output data indicating that a human is present during the first period of time, executing a computer executable command.
13. A device, comprising: at least one processor; memory including instructions operable to be executed by the at least one processor to cause the device to: receive, from at least one microphone associated with the device, an audio signal; receive, from an audio change detector associated with the device, first indication data indicating that a first energy level associated with a first portion of the audio signal exceeds a threshold value, the first portion of the audio signal corresponding to a first period of time, the audio change detector configured to detect changes in a signal level of the audio signal; determine, using a first acoustic event detector of the device that is separate from the audio change detector, second indication data indicating that a second portion of the audio signal corresponds to a first type of acoustic event, the second portion of the audio signal corresponding to a second period of time that includes at least a portion of the first period of time, the first acoustic event detector configured to distinguish between the first type of acoustic event and other types of acoustic events, the second indication data corresponding to a first confidence score that indicates a first likelihood that a human is present; determine, based on at least the second indication data, a second confidence score indicating a second likelihood that a human is present; determine, based on the second confidence score, that a human is present during at least the second period of time; determine, based on the first indication data received from the audio change detector and the second indication data determined by the first acoustic event detector, a third period of time in which human presence is detected, the third period of time being longer than the second period of time; and generate output data indicating that a human is present during the third period of time.
14. The device of claim 13, wherein the memory further comprises instructions that, when executed by the at least one processor, further cause the device to: receive, from a second acoustic event detector, third indication data indicating that the audio signal does not correspond to a second type of acoustic event during the first period of time, the second type being different than the first type; and determine, based on the first indication data, the second indication data, and the third indication data, that a human is present during the first period of time.
15. The device of claim 13, wherein the memory further comprises instructions that, when executed by the at least one processor, further cause the device to: receive, from the audio change detector, third indication data indicating that a second energy level associated with a second portion of the audio signal exceeds the threshold value, the second portion of the audio signal corresponding to a fourth period of time; determine, using a second acoustic event detector based on the second portion of the audio signal, fourth indication data indicating that the audio signal corresponds to a second type of acoustic event during the fourth period of time, the second acoustic event detector configured to distinguish between the second type of acoustic event and other types of acoustic events, the second type being different than the first type; determine, based on the third indication data and the fourth indication data, that a human is not present during the fourth period of time; and generate second output data indicating that a human is not present during the fourth period of time.
16. The device of claim 13, wherein the memory further comprises instructions that, when executed by the at least one processor, further cause the device to: receive a feature vector, the feature vector generated from the audio signal; determine the first energy level using a first portion of the feature vector that corresponds to the first period of time; determine a reference audio signal level associated with the audio signal; determine a difference between the first energy level and the reference audio signal level; determine that the difference exceeds a threshold value; and generate the first indication data indicating that the first energy level associated with the first portion of the audio signal exceeds the threshold value during the first period of time.
17. The device of claim 13, wherein the memory further comprises instructions that, when executed by the at least one processor, further cause the device to: determine that the second confidence score exceeds a confidence threshold value; and determine that a human is present during at least the second period of time.
18. The device of claim 13, wherein the memory further comprises instructions that, when executed by the at least one processor, further cause the device to: determine, based on the first indication data and the second indication data, a first signal to noise ratio corresponding to a first time duration and associated with the audio change detector; determine, based on the first indication data and the second indication data, a second signal to noise ratio corresponding to the first time duration and associated with the first acoustic event detector; and determine, based on the first indication data, the second indication data, the first signal to noise ratio and the second signal to noise ratio, that a human is present during at least the second period of time.
19. The device of claim 13, wherein the memory further comprises instructions that, when executed by the at least one processor, further cause the device to: determine, based on the first indication data and the second indication data, a first signal to noise ratio corresponding to a first time duration; determine, based on the first indication data and the second indication data, a second signal to noise ratio corresponding to a second time duration; and determine, based on the first indication data, the second indication data, the first signal to noise ratio and the second signal to noise ratio, that a human is present during at least the second period of time.
20. The device of claim 13, wherein the first acoustic event detector includes a deep neural-network configured to detect speech, the deep neural-network trained using a corpus of training data including a large number of acoustic events associated with speech, the deep neural-network configured to improve performance over time in response to acoustic events not included in the training data.
21. A computer-implemented method, comprising: receiving, from at least one microphone associated with a device, an audio signal; determining, using a first acoustic event detector of the device, first indication data indicating that the audio signal corresponds to a first type of acoustic event during a first period of time, the first acoustic event detector configured to distinguish between the first type of acoustic event and other types of acoustic events, the first indication data corresponding to a first confidence score indicating a first likelihood that a human is present; receiving, from an audio change detector associated with the device that is separate from the first acoustic event detector, second indication data indicating that an energy level associated with the audio signal exceeds a threshold value during a second period of time, the second period of time being longer than the first period of time and including at least a portion of the first period of time, the audio change detector configured to detect changes in a signal level of the audio signal; determining, based on the first indication data and the second indication data, a second confidence score indicating a second likelihood that a human is present during the second period of time; and generating, based on the second confidence score, output data indicating that a human is present during the second period of time.
</claims>
</document>
