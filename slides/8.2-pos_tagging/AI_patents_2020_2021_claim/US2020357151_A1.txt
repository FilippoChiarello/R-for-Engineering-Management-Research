<document>

<filing_date>
2020-05-04
</filing_date>

<publication_date>
2020-11-12
</publication_date>

<priority_date>
2019-05-08
</priority_date>

<ipc_classes>
G06T11/00,G06T7/00
</ipc_classes>

<assignee>
GE PRECISION HEALTHCARE
</assignee>

<inventors>
CAO, XIMIAO
WANG XUELI
XING, WEIWEI
ZHAO, Bingjie
</inventors>

<docdb_family_id>
70613693
</docdb_family_id>

<title>
IMAGING METHOD AND DEVICE
</title>

<abstract>
The present application provides an imaging method and system, and a non-transitory computer-readable storage medium. The imaging method comprises preprocessing projection data to obtain a predicted image of a truncated portion; performing forward projection on the predicted image to obtain predicted projection data of the truncated portion; and performing image reconstruction using the projection data obtained by forward projection and projection data of an untruncated portion.
</abstract>

<claims>
1. An imaging method, comprising: preprocessing projection data to obtain a predicted image of a truncated portion; performing forward projection on the predicted image to obtain predicted projection data of the truncated portion; and performing image reconstruction based on the predicted projection data and projection data of an untruncated portion.
2. The method according to claim 1, wherein the preprocessing projection data to obtain a predicted image of a truncated portion comprises: processing the truncated portion of the projection data based on the untruncated portion of the projection data, so as to obtain, by reconstruction, an initial image of the truncated portion; and calibrating the initial image based on a trained learning network to obtain the predicted image of the truncated portion.
3. The method according to claim 2, wherein padding the truncated portion of the projection data comprises padding the truncated portion with projection data information at a boundary of the untruncated portion.
4. The method according to claim 2, wherein the calibrating the initial image of the truncated portion based on a trained learning network to obtain the predicted image of the truncated portion comprises: converting pixels of the initial image of the truncated portion from polar coordinates to rectangular coordinates, to obtain a pixel matrix of the initial image; calibrating the pixel matrix based on the trained learning network; and converting the calibrated pixel matrix from rectangular coordinates to polar coordinates, to obtain the predicted image of the truncated portion.
5. The method according to claim 2, wherein the trained learning network is obtained by training based on a virtual distorted image and a comparison image.
6. The method according to claim 5, wherein the trained learning network is obtained by training based on a pixel matrix of the virtual distorted image obtained by coordinate transformation and a pixel matrix of the comparison image obtained by coordinate transformation.
7. The method according to claim 5, wherein a method for obtaining the virtual distorted image and the comparison image comprises: obtaining an original image without data truncation; virtually offsetting a portion of the original image corresponding to a target object to move it partially out of a scanning field, so as to obtain the comparison image; performing virtual scanning and virtual data acquisition on the comparison image to generate virtual truncated projection data; and performing image reconstruction on the virtual truncated projection data to obtain the virtual distorted image.
8. The method according to claim 5, wherein a method for obtaining the virtual distorted image and the comparison image comprises: obtaining an original image without data truncation, the original image being used as the comparison image; obtaining projection data corresponding to the original image; padding channels on two sides of the projection data to generate virtual truncated projection data; and performing image reconstruction on the virtual truncated projection data to obtain the virtual distorted image.
9. An imaging system, comprising: a prediction device, configured to preprocess projection data to obtain a predicted image of a truncated portion; an image processing device, configured to perform forward projection on the predicted image to obtain predicted projection data of the truncated portion; and an image reconstruction device, configured to perform image reconstruction based on the predicted projection data and projection data of an untruncated portion.
10. The system according to claim 9, wherein the prediction device comprises: a preprocessing device, configured to process the truncated portion of the projection data based on the untruncated portion of the projection data, so as to obtain an initial image of the truncated portion; and a control device, configured to calibrate the initial image based on a trained learning network to obtain the predicted image of the truncated portion.
11. The system according to claim 10, wherein the control device comprises: a transformation module, configured to convert pixels of the initial image of the truncated portion from polar coordinates to rectangular coordinates, to obtain a pixel matrix of the initial image; a calibration module, configured to calibrate the pixel matrix based on the trained learning network; and an inverse transformation module, configured to convert the calibrated pixel matrix from rectangular coordinates to polar coordinates, to obtain the predicted image of the truncated portion.
12. A non-transitory computer-readable storage medium for storing a computer program, wherein when executed by a computer, the computer program causes the computer to perform the imaging method according to claim 1.
</claims>
</document>
