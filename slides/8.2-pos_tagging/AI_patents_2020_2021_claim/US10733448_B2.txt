<document>

<filing_date>
2018-03-15
</filing_date>

<publication_date>
2020-08-04
</publication_date>

<priority_date>
2018-03-15
</priority_date>

<ipc_classes>
G06K9/00,G06N5/04,H04N13/261
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
HUBSCHMAN, JULIE
LONG, DONNA K.
SHAIKH, SAQIB
WOO, ALEX JUNGYEOP
YORK, KENDALL C.
ZIMMERMAN, ZACHARY T.
</inventors>

<docdb_family_id>
67905776
</docdb_family_id>

<title>
Machine learning of context data for social and contextual scene inferences
</title>

<abstract>
A system for contextual interpretation of a three-dimensional scene includes an object recognition engine that analyzes scene data collected from the three-dimensional scene to identify at least one object present in the three-dimensional scene. The system further includes a contextual inference engine trained on a context data training set to analyze context of the scene by identifying a potential contextual inference associated in memory with the at least one object identified by the object recognition engine; comparing the scene data to a subset of the context data training set identified as satisfying the potential contextual inference; and outputting scene context information conveying the potential contextual inference responsive to a determination that the scene data and the subset of the context data train set satisfy a predetermined correlation.
</abstract>

<claims>
1. A system for contextual interpretation of a three-dimensional scene, the system comprising: memory; a processor; an object recognition engine stored in the memory and executable by the processor to: analyze scene data collected from the three-dimensional scene to identify at least a first object and a second object present in the three-dimensional scene; and a contextual inference engine trained on a context data training set, the contextual inference engine stored in memory and executable by a processor to: identify a potential contextual inference associated in memory with a recognized spatial relationship between the first object and the second object; compare the scene data to a subset of the context data training set identified as satisfying the potential contextual inference; and output scene context information conveying the potential contextual inference responsive to a determination that the scene data and the subset of the context data training set satisfy a predetermined correlation.
2. The system of claim 1, wherein the potential contextual inference is a use context inference, the use context inference indicating viability of at least one of the first object and the second object for a potential user-object interaction.
3. The system of claim 1, wherein the potential contextual inference is a behavioral inference, the behavioral inference indicating a motivation for an action of a living object captured in the scene data.
4. The system of claim 1, wherein the contextual inference engine is further executable to: compute a confidence metric quantifying a likelihood that the scene data satisfies a correlation with the subset of the context data training set identified as satisfying the potential contextual inference; and output the scene context information conveying the potential contextual inference responsive to a determination that the computed confidence metric satisfies a predetermined threshold.
5. The system of claim 1, wherein context data training set includes instances of context data pre-identified as satisfying or not satisfying each of a plurality of contextual inferences.
6. The system of claim 1, wherein the system further comprises: at least one environmental sensor that collects the scene data from the three-dimensional scene.
7. The system of claim 1, wherein the context data training set includes sound data.
8. One or more computer-readable storage media of a tangible article of manufacture encoding computer-executable instructions for executing on a computer system a computer process for contextual interpretation of a three-dimensional scene, the computer process comprising: analyzing, with a processor, scene data collected from the three-dimensional scene to identify at least a first object and a second object present in the three-dimensional scene; identifying a potential contextual inference ssociated in memory with a recognized spatial relationship between the first object and the second object; comparing the scene data to a subset of a context data training set identified as satisfying the potential contextual inference; and outputting scene context information conveying the potential contextual inference responsive to a determination that the scene data and the subset of the context data training set satisfy a predetermined correlation.
9. The one or more computer-readable storage media of claim 8, wherein the context data training set includes instances of context data pre-identified as satisfying or not satisfying each of a plurality of contextual inferences associated with different objects.
10. The one or more computer-readable storage media of claim 8, wherein the potential contextual inference is a use context inference, the use context inference indicating viability of at least one of the first object and the second object for a potential user-object interaction.
11. The one or more computer-readable storage media of claim 8, wherein the potential contextual inference is a behavioral inference, the behavioral inference indicating a motivation for an action of a living object captured in the scene data.
12. The one or more computer-readable storage media of claim 8, wherein comparing the scene data to the subset of the context data training set further comprises: computing a confidence metric quantifying a likelihood that the scene data satisfies a correlation with the subset of the context data training set identified as satisfying the potential contextual inference; and outputting the scene context information responsive to a determination that the confidence metric satisfies a predetermined threshold.
13. A device for contextual interpretation of a three-dimensional scene, the device comprising: memory; a processor; an object recognition engine stored in the memory and executable by the processor to analyze scene data collected from the three-dimensional scene to identify at least a first object and a second object present in the three-dimensional scene; and a contextual inference engine trained on a context data training set, the contextual inference engine stored in memory and executable by a processor to: identify a potential contextual inference associated in memory with a recognized spatial relationship between the first object and the second object; compare the scene data to a subset of the context data training set identified as satisfying the potential contextual inference; and output scene context information conveying the potential contextual inference responsive to a determination that the scene data and the subset of the context data training set satisfy a predetermined correlation.
14. The device of claim 13, wherein the device further comprises: at least one environmental sensor that collects the scene data from the three-dimensional scene.
15. The device of claim 13, wherein the potential contextual inference is a use context inference, the use context inference indicating viability of at least one of the first object and the second object for a potential user-object interaction.
16. The device of claim 13, wherein the potential contextual inference is a behavioral inference, the behavioral inference indicating a motivation for an action of a living object captured in the scene data.
17. The device of claim 13, wherein the contextual inference engine is further executable to: compute a confidence metric quantifying a likelihood that the scene data satisfies a correlation with the subset of the context data training set identified as satisfying the potential contextual inference; and output the scene context information conveying the potential contextual inference responsive to a determination that the computed confidence metric satisfies a predetermined threshold.
18. The device of claim 17, wherein the context data training set includes sound data.
</claims>
</document>
