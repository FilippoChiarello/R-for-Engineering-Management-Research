<document>

<filing_date>
2018-07-11
</filing_date>

<publication_date>
2020-05-21
</publication_date>

<priority_date>
2017-09-22
</priority_date>

<ipc_classes>
G06K9/00,G06K9/62,G06N20/00
</ipc_classes>

<assignee>
SAMSUNG ELECTRONICS COMPANY
</assignee>

<inventors>
CHOI, HYUN-SOO
CHOI, IN-KWON
JUNG, HYUN-JOO
KIM, SUNG JIN
LEE, GUN-HEE
</inventors>

<docdb_family_id>
65811462
</docdb_family_id>

<title>
METHOD AND APPARATUS FOR RECOGNIZING OBJECT
</title>

<abstract>
Provided are an artificial intelligence (AI) system that simulates functions of a human brain such as recognition and judgment by utilizing a machine learning algorithm such as deep learning, etc., and an application of the AI system. Provided are an AI system and a method of recognizing an object according to the application of the AI system, the method including: obtaining a plurality of pieces of sensor data about the object from a plurality of different types of sensors; converting at least some of the plurality of pieces of sensor data into two-dimensional (2D) sensor data; and recognizing the object by using a previously generated learning network model based on 2D image data obtained from an image sensor, which is one of the plurality of sensors, and the 2D sensor data.
</abstract>

<claims>
1. A method of recognizing an object, the method comprising: obtaining a plurality of pieces of sensor data about the object from a plurality of different types of sensors; converting at least some of the plurality of pieces of sensor data into two-dimensional (2D) sensor data; and recognizing the object by using a previously generated learning network model based on 2D image data obtained from an image sensor, which is one of the plurality of sensors, and the 2D sensor data.
2. The method of claim 1, wherein the converting comprises converting the at least some of the plurality of pieces of sensor data into the 2D sensor data by using a learning network model, for conversion of sensor data, which is generated as a result of learning a reference for converting one-dimensional (1D) sensor data into the 2D sensor data.
3. The method of claim 2, further comprising: obtaining the 1D sensor data by reconverting the 2D sensor data; determining an error having occurred in the conversion of the sensor data based on a result of comparing 1D sensor data which is at least part of the obtained plurality of pieces of sensor data and the 1D sensor data obtained as a result of the reconversion; and based on the determined error, updating a parameter of a plurality of layers constituting the learning network model for the conversion of the sensor data.
4. The method of claim 1, wherein the converting comprises: obtaining 1D sensor data in a first axial direction from at least one of the plurality of sensors; and generating the 2D sensor data by upsampling the 1D sensor data in the first axial direction in a second axial direction.
5. The method of claim 1, wherein the recognizing of the object comprises: obtaining image feature information representing the object from the 2D image data by using a learning network model generated as a result of learning a reference for obtaining image feature information from at least one piece of image data; and recognizing the object by using the previously generated learning network model based on the image feature information and the 2D sensor data.
6. The method of claim 1, wherein the previously generated learning network model comprises a plurality of layers, and wherein a parameter of each of the plurality of layers is determined based on a result of learning a reference for selecting at least one piece of data used for object recognition from among the image data and the 2D sensor data and combining the selected at least one piece of data.
7. The method of claim 1, further comprising: determining an error having occurred in the object recognition based on a result of comparing a category of the recognized object with a category of the object; and updating parameters of a plurality of layers constituting the previously generated learning network model based on the determined error.
8. An apparatus for recognizing an object, the apparatus comprising: a memory storing one or more instructions; a display; a plurality of sensors configured to obtain a plurality of pieces of sensor data about the object; and a processor configured to execute the one or more instructions stored in the memory to: obtain the plurality of pieces of sensor data about the object from the plurality of sensors, convert at least some of the plurality of pieces of sensor data into two-dimensional (2D) sensor data; and recognize the object by using a previously generated learning network model based on 2D image data obtained from an image sensor, which is one of the plurality of sensors, and the 2D sensor data.
9. The apparatus of claim 8, wherein the processor is further configured to execute the one or more instructions to convert the at least some of the plurality of pieces of sensor data into the 2D sensor data by using a learning network model, for conversion of sensor data, which is generated as a result of learning a reference for converting one-dimensional (1D) sensor data into the 2D sensor data.
10. The apparatus of claim 9, wherein the processor is further configured to execute the one or more instructions to: obtain the 1D sensor data by reconverting the 2D sensor data; determine an error having occurred in the conversion of the sensor data based on a result of comparing 1D sensor data which is at least part of the obtained plurality of pieces of sensor data and the 1D sensor data obtained as a result of the reconversion; and based on the determined error, update a parameter of a plurality of layers constituting the learning network model for the conversion of the sensor data.
11. The apparatus of claim 8, wherein the processor is further configured to execute the one or more instructions to: obtain 1D sensor data in a first axial direction from at least one of the plurality of sensors; and generate the 2D sensor data by upsampling the 1D sensor data in the first axial direction in a second axial direction.
12. The apparatus of claim 8, wherein the processor is further configured to execute the one or more instructions to: obtain image feature information representing the object from the 2D image data by using a learning network model generated as a result of learning a reference for obtaining the image feature information from at least one piece of image data; and recognize the object by using the previously generated learning network model based on the image feature information and the 2D sensor data.
13. The apparatus of claim 8, wherein the previously generated learning network model comprises a plurality of layers, and wherein a parameter of each of the plurality of layers is determined based on a result of learning a reference for selecting at least one piece of data used for object recognition from among the image data and the 2D sensor data and combining the selected at least one piece of data.
14. The apparatus of claim 8, wherein the processor is further configured to execute the one or more instructions to: determine an error having occurred in an object recognition based on a result of comparing a category of the recognized object with a category of the object; and update parameters of a plurality of layers constituting the previously generated learning network model based on the determined error.
15. A computer-readable recording medium having recorded thereon a program for performing the method of claim 1 on a computer.
</claims>
</document>
