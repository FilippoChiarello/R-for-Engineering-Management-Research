<document>

<filing_date>
2019-11-08
</filing_date>

<publication_date>
2020-03-05
</publication_date>

<priority_date>
2010-06-07
</priority_date>

<ipc_classes>
A61B5/00,A61B5/16,A61B5/18,G06K9/00,G16H30/40
</ipc_classes>

<assignee>
AFFECTIVA
</assignee>

<inventors>
EL KALIOUBY, RANA
MAHMOUD, ABDELRAHMAN N.
MISHRA, TANIYA
PITRE, BOISY G.
TURCOT, PANU JAMES
ZEILMAN, ANDREW TODD
</inventors>

<docdb_family_id>
69641401
</docdb_family_id>

<title>
IMAGE ANALYSIS USING A SEMICONDUCTOR PROCESSOR FOR FACIAL EVALUATION IN VEHICLES
</title>

<abstract>
Analysis for convolutional processing is performed using logic encoded in a semiconductor processor. The semiconductor chip evaluates pixels within an image of a person in a vehicle, where the analysis identifies a facial portion of the person. The facial portion of the person can include facial landmarks or regions. The semiconductor chip identifies one or more facial expressions based on the facial portion. The facial expressions can include a smile, frown, smirk, or grimace. The semiconductor chip classifies the one or more facial expressions for cognitive response content. The semiconductor chip evaluates the cognitive response content to produce cognitive state information for the person. The semiconductor chip enables manipulation of the vehicle based on communication of the cognitive state information to a component of the vehicle.
</abstract>

<claims>
1. An apparatus for analysis comprising: a device containing convolutional processing logic encoded in a semiconductor chip comprising: evaluation logic trained to analyze pixels within an image of a person in a vehicle, wherein the analysis identifies a facial portion of the person; identification logic trained to identify one or more facial expressions based on the facial portion; classifying logic trained to classify the one or more facial expressions for cognitive response content; scoring logic trained to evaluate the cognitive response content to produce cognitive state information for the person; and interface logic that enables manipulation of the vehicle based on communication of the cognitive state information to a component of the vehicle.
2. The apparatus of claim 1 further comprising categorization logic that updates a cognitive state profile of an individual associated with the facial portion.
3. The apparatus of claim 2 wherein the cognitive state profile summarizes the cognitive state information of the individual.
4. The apparatus of claim 3 wherein the cognitive state profile is based on cognitive state event temporal signatures.
5. The apparatus of claim 1 wherein an additional facial portion from an image of an additional person within the vehicle is evaluated, identified, classified, and scored to produce additional cognitive state information for the additional person.
6. The apparatus of claim 1 wherein the cognitive state information is used to communicate one or more of drowsiness, fatigue, distraction, sadness, stress, happiness, anger, frustration, confusion, disappointment, hesitation, cognitive overload, focusing, engagement, attention, boredom, exploration, confidence, trust, delight, disgust, skepticism, doubt, satisfaction, excitement, laughter, calmness, curiosity, humor, depression, envy, sympathy, embarrassment, poignancy, or mirth.
7. The apparatus of claim 1 further comprising logic for augmenting the cognitive state information based on audio data collected from within the vehicle, wherein the audio data is collected contemporaneously with the image.
8. The apparatus of claim 7 wherein the audio data includes voice data.
9. The apparatus of claim 1 wherein the manipulation of the vehicle includes a locking out operation, a recommending a break for an occupant, a recommending a different route for the vehicle, a recommending how far to drive, a responding to traffic, an adjusting of seats, mirrors, climate control, lighting, music, audio stimuli, or interior temperature, a brake activation, or a steering control.
10. The apparatus of claim 1 further comprising logic for tagging the cognitive state information with sensor data received from the vehicle.
11. The apparatus of claim 1 wherein the cognitive state information that was analyzed is based on intermittent occurrences of the facial portion within a series of images.
12. The apparatus of claim 1 wherein a series of images is supplied to the device and wherein the series of images is sourced from a video stream.
13. The apparatus of claim 12 further comprising tracking logic trained for tracking the facial portion and identifying that the facial portion is no longer within images from the video stream.
14. The apparatus of claim 13 wherein the tracking logic identifies that a face has left the images from the video stream.
15. The apparatus of claim 14 wherein the tracking logic identifies that the face has returned to the images from the video stream and associates information previously collected about the face from before the face left the video stream.
16. The apparatus of claim 1 wherein the cognitive response content includes facial expressions.
17. The apparatus of claim 1 wherein the classifier logic is further trained to identify a gender, age, or ethnicity for the face.
18. The apparatus of claim 17 wherein the gender, age, or ethnicity is provided with an associated probability.
19. 19-20. (canceled)
21. The apparatus in claim 1 wherein the cognitive state information is used by a software application running on a processor coupled to the device.
22. The apparatus in claim 1 wherein the device sends one or more images to a web service for external classification based on the cognitive state information.
23. The apparatus in claim 1 wherein the device further performs smoothing of the cognitive state information.
24. The apparatus in claim 1 wherein the device further performs image correction for the image including one or more of lighting correction, contrast correction, near infrared lighting correction, or noise filtering.
25. The apparatus in claim 1 wherein physiological information is gleaned from a video containing the image.
26. (canceled)
27. A computer program product embodied in a non-transitory computer readable medium for image analysis, the computer program product comprising: code for executing on a device containing a convolutional processing logic encoded in a semiconductor chip comprising: evaluation logic trained to analyze pixels within an image of a person in a vehicle, wherein the analysis identifies a facial portion of the person; identification logic trained to identify one or more facial expressions based on the facial portion; classifying logic trained to classify the one or more facial expressions for cognitive response content; scoring logic trained to evaluate the cognitive response content to produce cognitive state information for the person; and interface logic that enables manipulation of the vehicle based on communication of the cognitive state information to a component of the vehicle.
28. A processor-implemented method for analysis comprising: using a device containing convolutional processing logic encoded in a semiconductor chip to perform: analyzing pixels within an image of a person in a vehicle, wherein the analysis identifies a facial portion of the person; identifying one or more facial expressions based on the facial portion; classifying the one or more facial expressions for cognitive response content; evaluating the cognitive response content to produce cognitive state information for the person; and manipulating the vehicle based on communication of the cognitive state information to a component of the vehicle.
</claims>
</document>
