<document>

<filing_date>
2018-09-11
</filing_date>

<publication_date>
2020-06-23
</publication_date>

<priority_date>
2018-09-11
</priority_date>

<ipc_classes>
H04N19/124,H04N19/13,H04N19/70,H04N19/91
</ipc_classes>

<assignee>
GOOGLE
</assignee>

<inventors>
HE, DAKE
XU, RUIJIE
</inventors>

<docdb_family_id>
67809737
</docdb_family_id>

<title>
Video coding using separate learning and filtering pathways
</title>

<abstract>
Separate pathways for filtering and for machine learning are introduced within a video coder. A first pathway filters a first copy of a reconstructed frame to produce a filtered frame, which is included in an output video stream for display at a user device. A second pathway processes a second copy of the reconstructed frame using a learning model, such as for training and/or inference. The first and second pathways are introduced after the reconstruction stage of an encoder or decoder. The input to each of the first and second pathways is thus produced without using a non-injective function, and, while the first pathway includes at least one non-injective function, the second pathway does not. As a result, training the learning model using the second copy of the reconstructed frame results in a greater classification accuracy upper bound than training the learning model using the filtered frame.
</abstract>

<claims>
1. A decoder, comprising: an entropy decoding stage that entropy decodes syntax elements representative of an encoded video frame from an encoded bitstream to produce quantized transform coefficients; a dequantization stage that dequantizes the quantized transform coefficients to produce transform coefficients; an inverse transform stage that inverse transforms the transform coefficients to produce a prediction residual; a reconstruction stage that reconstructs the prediction residual to produce a reconstructed frame; a first post-reconstruction pathway that filters a first copy of the reconstructed frame using one or more filtering techniques and outputs the filtered frame within an output video stream for display at a user device; and a second post-reconstruction pathway that trains a learning model for video content identification using a second copy of the reconstructed frame and outputs a trained learning model, wherein training the learning model using the second copy of the reconstructed frame results in a greater classification accuracy upper bound for the learning model than training the learning model using the filtered frame.
2. The decoder of claim 1, wherein the second post-reconstruction pathway trains the learning model using the second copy of the reconstructed frame and filter side information received from the first post-reconstruction pathway.
3. The decoder of claim 1, wherein each function performed at the entropy decoding stage, the dequantization stage, the inverse transform stage, the reconstruction stage, and the second post-reconstruction pathway is an injective function, wherein at least one function performed at the first post-reconstruction pathway is a non-injective function.
4. The decoder of claim 1, wherein the reconstructed frame is a first reconstructed frame, wherein the reconstruction stage produces a second reconstruction frame, wherein the first post-reconstruction pathway filters a first copy of the second reconstructed frame, wherein the second post-reconstruction pathway performs one or more inference operations against a second copy of the second reconstructed frame using the trained learning model.
5. The decoder of claim 1, wherein the one or more filtering techniques include a filtering technique performed using an in-loop filter.
6. A method, comprising: dequantizing quantized transform coefficients representative of encoded video data to produce transform coefficients; inverse transforming the transform coefficients to produce a prediction residual; reconstructing the prediction residual to produce a reconstructed frame; filtering a first copy of the reconstructed frame to produce a filtered frame to include within an output video stream; and training and outputting a learning model, wherein training the learning model includes processing a second copy of the reconstructed frame to identify video content.
7. The method of claim 6, wherein training and outputting the learning model comprises: training the learning model to identify the video content using the second copy of the reconstructed frame.
8. The method of claim 7, wherein training the learning model using the second copy of the reconstructed frame results in a greater classification accuracy upper bound for the learning model than training the learning model using the filtered frame.
9. The method of claim 7, wherein training the learning model to identify the video content using the second copy of the reconstructed frame comprises: training the learning model using filter side information, wherein the filter side information is used for the filtering of the first copy of the reconstructed frame.
10. The method of claim 6, wherein the filtered frame is produced using at least one non-injective function, wherein the second copy of the reconstructed frame is produced without using the at least one non-injective function.
11. The method of claim 6, wherein filtering the first copy of the reconstructed frame to produce the filtered frame to include within the output video stream comprises: processing the first copy of the reconstructed frame using an in-loop filter.
12. The method of claim 6, wherein the encoded video data is first encoded video data, the method further comprising: performing one or more inference operations against second encoded video data using the trained learning model.
13. The method of claim 6, wherein the encoded video data is decoded from an encoded bitstream, the method further comprising: outputting the filtered frame within the output video stream for display at a user device.
14. An integrated circuit comprising a processor that executes instructions, the instructions comprising: decoding encoded video data from an encoded bitstream to produce a reconstructed frame; processing a first copy of the reconstructed frame over a first decoding pathway using an in-loop filter to produce an output video stream for display at a user device; and processing a second copy of the reconstructed frame over a second decoding pathway to train and output a learning model for identifying video content.
15. The integrated circuit of claim 14, wherein the instructions for decoding the encoded video data from the encoded bitstream to produce the reconstructed frame comprise instructions for: dequantizing quantized transform coefficients representative of the encoded video data to produce transform coefficients; inverse transforming the transform coefficients to produce a prediction residual; and reconstructing the prediction residual to produce a reconstructed frame.
16. The integrated circuit of claim 14, wherein the instructions for processing the second copy of the reconstructed frame over the second decoding pathway to train and output the learning model for identifying the video content comprise instructions for: training the learning model using the second copy of the reconstructed frame.
17. The integrated circuit of claim 16, wherein the instructions for training the learning model using the second copy of the reconstructed frame comprise instructions for: training the learning model using filter side information from the first decoding pathway.
18. The integrated circuit of claim 14, wherein the encoded video data is decoded from an encoded bitstream and the instructions comprise instructions for: performing one or more inference operations against second encoded video data using the trained learning model.
19. The integrated circuit of claim 14, wherein training the learning model by processing the second copy of the reconstructed frame results in a greater classification accuracy upper bound for the learning model than training the learning model by processing a filtered frame produced by filtering the first copy of the reconstructed frame using the in-loop filter.
20. The integrated circuit of claim 14, wherein processing the first copy of the reconstructed frame over the first decoding pathway includes using at least one non-injective function, wherein processing the second copy of the reconstructed frame over the second decoding pathway omits using the at least one non-injective function.
</claims>
</document>
