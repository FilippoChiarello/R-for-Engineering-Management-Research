<document>

<filing_date>
2020-05-14
</filing_date>

<publication_date>
2020-11-26
</publication_date>

<priority_date>
2019-05-17
</priority_date>

<ipc_classes>
A61B5/107,A61B8/00,A61B8/08,A61B8/12
</ipc_classes>

<assignee>
PHILIPS ELECTRONICS
</assignee>

<inventors>
BHARAT SHYAM
ERRICO CLAUDIA
SRINIVASA NAIDU RAGHAVENDRA
</inventors>

<docdb_family_id>
70738561
</docdb_family_id>

<title>
SYSTEM, DEVICE AND METHOD FOR ASSISTANCE WITH CERVICAL ULTRASOUND EXAMINATION
</title>

<abstract>
For each of a plurality of time frames in the scan session for producing acoustic images of an area of interest, including a cervix, a system and method: construct (1520) a three dimensional volume of the area of interest from one or more image signals and the inertial measurement signal; apply (1530) a deep learning algorithm to the constructed three dimensional volume of interest to qualify an image plane for obtaining a candidate cervical length for the cervix; perform (1540) image segmentation and object detection for the qualified image plane to obtain the candidate cervical length. The shortest candidate cervical length from the plurality of time frames is selected as the measured cervical length for the scan session. A display device (116) displays an image of the cervix corresponding to the measured cervical length for the scan session, and an indication of the measured cervical length for the scan session.
</abstract>

<claims>
What is claimed is:
1. A system (100), comprising:
an acoustic probe (120), the acoustic probe having an array (122) of acoustic transducer elements;
an inertial measurement circuit (121), the inertial measurement circuit configured to provide an inertial measurement signal indicating a pose of the acoustic probe; and
an acoustic imaging instrument (110) connected to the acoustic probe and configured to provide transmit signals to least some of the acoustic transducer elements to cause the array of acoustic transducer elements to transmit an acoustic probe signal (15) to an area of interest (10) including a cervix, and further configured to produce acoustic images of the area of interest in response to acoustic echoes received by the acoustic probe from the area of interest in response to the acoustic probe signal, the acoustic imaging instrument including:
a display device (116);
a communication interface (115) configured to receive one or more image signals from the acoustic probe produced from the acoustic echoes from the area of interest, and to receive the inertial measurement signal; and
a processor (112, 900), and associated memory (111), configured to:
for each of a plurality of time frames (1120-1/1120/27/1120-269) in a scan session:
construct (1520) a three dimensional volume (1220) of the area of interest from the one or more image signals and the received inertial measurement signal,
apply (1530) a deep learning algorithm (1122) to the constructed three dimensional volume of the area of interest to qualify (1340) an image plane for obtaining a candidate cervical length for the cervix, and
perform (1540) image segmentation and object detection for the qualified image plane to obtain (1350) the candidate cervical length, and
select (1570) a shortest candidate cervical length from the plurality of time frames as a measured cervical length for the scan session,
wherein the processor is configured to control the display device to display an image of the cervix corresponding to the measured cervical length for the scan session, and an indication of the measured cervical length for the scan session.
2. The system (100) of claim 1, wherein the processor is configured to control the display device to display a graph (1410) showing the candidate cervical lengths and to display the indication of the measured cervical length for the scan session on the graph.
3. The system (100) of claim 1, wherein the processor is configured to store in a nonvolatile memory device (932, 934, 935, 936) the measured cervical length for the scan session and a date of the scan session.
4. The system (100) of claim 3,
wherein the nonvolatile memory device is configured to store a plurality of measured cervical lengths for a plurality of scan sessions performed at corresponding times, and
wherein the processor is configured to cause the display to display a graph plotting the cervical lengths for the scan sessions against the corresponding times.
5. The system (100) of claim 1, wherein the processor is configured to generate image data for the qualified image plane and to perform image segmentation by applying the image data for the qualified image plane to a You Only Look Once (Y OLO) neural network.
6. The system (100) of claim 1, wherein the processor is configured to generate image data for the qualified image plane and to perform object detection for the qualified image plane by applying the image data for the qualified image plane to a U-Net
Convolutional network.
7. The system (100) of claim 1,
wherein the processor is configured to generate image data for a plurality of image planes of the three dimensional volume, and
wherein the deep learning algorithm employs one or more qualifying anatomical landmarks which qualify image planes of the three dimensional volume, and employs one or more disqualifying anatomical landmarks which disqualify image planes of the three dimensional volume.
8. The system (100) of claim 7, wherein a first cervical shape is employed as one of the disqualifying anatomical landmarks and a second cervical shape is employed as one of the qualifying anatomical landmarks.
9. The system (100) of claim 1, wherein the processor is configured to generate image data for a plurality of image planes of the three dimensional volume, and wherein the deep learning algorithm applies the image data to one of a convolutional neural network (CNN), a You Only Look Once (Y OLO) neural network, or a U-Net
Convolutional network.
10. A method (1500), comprising:
performing (1510) real time two-dimensional acoustic imaging of an area of interest (10) during a scan session, including a cervix, with an acoustic probe (120), including producing one or more image signals of the area of interest and producing an inertial measurement signal indicating a pose of the acoustic probe;
for each of a plurality of time frames in the scan session:
constructing (1520) a three dimensional volume (1220) of the area of interest from the one or more image signals and the inertial measurement signal,
applying a (1530) deep learning algorithm to the constructed three dimensional volume of the area of interest to qualify an image plane for obtaining a candidate cervical length for the cervix, and
performing (1540) image segmentation and object detection for the qualified image plane to obtain the candidate cervical length; and
selecting (1570) a shortest candidate cervical length from the plurality of time frames as a measured cervical length for the scan session; and
displaying (1570) on a display device (116) an image of the cervix corresponding to the measured cervical length for the scan session, and an indication of the measured cervical length for the scan session.
11. The method (1500) of claim 10, further comprising displaying a graph (1410) showing the candidate cervical lengths and displaying the indication of the measured cervical length for the scan session on the graph.
12. The method (1500) of claim 10, further comprising storing the measured cervical length for the scan session and a date of the scan session in a nonvolatile memory device (932, 934, 935, 936).
13. The method (1500) of claim 12, further comprising:
storing in the nonvolatile memory device (932, 934, 935, 936) a plurality of measured cervical lengths for a plurality of scan sessions performed at corresponding times; and
displaying on the display device a graph (1410) plotting the cervical lengths for the scan sessions against the corresponding times.
14. The method (1500) of claim 10, further comprising generating image data for the qualified image plane and performing image segmentation by applying the image data for the qualified image plane to a You Only Look Once (Y OLO) neural network.
15. The method (1500) of claim 10, further comprising:
generating image data for the qualified image plane; and
performing object detection for the qualified image plane by applying the image data for the qualified image plane to a U-Net Convolutional network.
16. The method (1500) of claim 10, further comprising:
generating image data for a plurality of image planes of the three dimensional volume;
employing one or more qualifying anatomical landmarks which qualify image planes of the three dimensional volume; and
employing one or more disqualifying anatomical landmarks which disqualify image planes of the three dimensional volume in order.
17. The method (1500) of claim 16, further comprising:
employing a first cervical shape as one of the disqualifying anatomical landmarks; and
employing a second cervical shape as one of the qualifying anatomical landmarks.
18. The method (1500) of claim 10, further comprising:
generating image data for a plurality of image planes of the three dimensional volume; and
applying the image data to one of a convolutional neural network (CNN), a You Only Look Once (Y OLO) neural network, or a U-Net Convolutional network to qualify an image plane for obtaining a candidate cervical length for the cervix.
</claims>
</document>
