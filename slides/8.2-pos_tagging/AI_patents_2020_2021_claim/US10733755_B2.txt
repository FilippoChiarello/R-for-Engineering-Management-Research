<document>

<filing_date>
2018-07-18
</filing_date>

<publication_date>
2020-08-04
</publication_date>

<priority_date>
2017-07-18
</priority_date>

<ipc_classes>
G06K9/00,G06K9/46,G06K9/62,G06N3/04,G06N3/08,G06N5/04,G06T15/00,G06T7/194,G06T7/33,G06T7/50,G06T7/60,G06T7/73
</ipc_classes>

<assignee>
QUALCOMM
</assignee>

<inventors>
GAVVES, EFSTRATIOS
LIAO, SHUAI
SNOEK, CORNELIS GERARDUS MARIA
</inventors>

<docdb_family_id>
65023392
</docdb_family_id>

<title>
Learning geometric differentials for matching 3D models to objects in a 2D image
</title>

<abstract>
A method aligns, with an artificial neural network, a three-dimensional (3D) model to an object in a 2D image. The method includes detecting, with an object detector, the object from the 2D image. The method also includes estimating a geodesic distance value between the object and multiple discretized poses of the 3D model. The method further includes selecting a discretized pose of the multiple discretized poses corresponding to a smallest geodesic distance value. The method still further includes propagating pose parameters of the selected discretized pose of the 3D model to the object.
</abstract>

<claims>
1. A method, comprising: detecting, with an object detector, an object from a two-dimensional (2D) image; estimating a geodesic distance value between the object from the 2D image and a plurality of discretized poses of a three-dimensional (3D) model of the object; selecting a discretized pose from the plurality of discretized poses of the 3D model corresponding to a smallest geodesic distance value of the estimated geodesic distance values between the object from the 2D image and the plurality of discretized poses of the 3D model, such that the selected discretized pose of the 3D model aligns with the object in the 2D image; and propagating pose parameters of the selected discretized pose of the 3D model to the object.
2. The method of claim 1, further comprising: performing 3D model analysis of the object based on the propagated pose parameters; and controlling movement of a device based on the 3D model analysis.
3. The method of claim 2, in which the 3D model analysis determines at least one of an orientation of the object, a distance of the object relative to the device, a movement direction of the object, or a combination thereof.
4. The method of claim 1, in which estimating the geodesic distance value comprises: determining a first feature map based on an appearance of the object; determining a second feature map based on an appearance of the 3D model; and estimating the geodesic distance value based on the first feature map and the second feature map.
5. The method of claim 1, in which the 3D model is textureless and the object is textured.
6. The method of claim 1, in which the pose parameters comprise at least one of an azimuth, an elevation, an in-plane rotation, a camera distance, a principle offset, a focal length, a viewport, or a combination thereof.
7. An apparatus, comprising: a memory; and at least one processor coupled to the memory, the at least one processor configured: to detect, with an object detector, an object from a two-dimensional (2D) image; to estimate a geodesic distance value between the object from the 2D image and a plurality of discretized poses of a three-dimensional (3D) model of the object; to select a discretized pose from the plurality of discretized poses of the 3D model corresponding to a smallest geodesic distance value of the estimated geodesic distance values between the object from the 2D image and the plurality of discretized poses of the 3D model, such that the selected discretized pose of the 3D model aligns with the object in the 2D image; and to propagate pose parameters of the selected discretized pose of the 3D model to the object.
8. The apparatus of claim 7, in which the at least one processor is further configured: to perform 3D model analysis of the object based on the propagated pose parameters; and to control movement of a device based on the 3D model analysis.
9. The apparatus of claim 8, in which the 3D model analysis determines at least one of an orientation of the object, a distance of the object relative to the device, a movement direction of the object, or a combination thereof.
10. The apparatus of claim 7, in which the at least one processor is further configured to estimate the geodesic distance value by: determining a first feature map based on an appearance of the object; determining a second feature map based on an appearance of the 3D model; and estimating the geodesic distance value based on the first feature map and the second feature map.
11. The apparatus of claim 7, in which the 3D model is textureless and the object is textured.
12. The apparatus of claim 7, in which the pose parameters comprise at least one of an azimuth, an elevation, an in-plane rotation, a camera distance, a principle offset, a focal length, a viewport, or a combination thereof.
13. A non-transitory computer-readable medium having program code recorded thereon, the program code executed by a processor and comprising: program code to detect, with an object detector, an object from a two-dimensional (2D) image; program code to estimate a geodesic distance value between the object from the 2D image and a plurality of discretized poses of a three-dimensional (3D) model of the object; program code to select a discretized pose from the plurality of discretized poses of the 3D model corresponding to a smallest geodesic distance value of the estimated geodesic distance values between the object from the 2D image and the plurality of discretized poses of the 3D model, such that the selected discretized pose of the 3D model aligns with the object in the 2D image; and program code to propagate pose parameters of the selected discretized pose of the 3D model to the object.
14. The non-transitory computer-readable medium of claim 13, in which the program code further comprises: program code to perform 3D model analysis of the object based on the propagated pose parameters; and program code to control movement of a device based on the 3D model analysis.
15. The non-transitory computer-readable medium of claim 14, in which the program code to perform 3D model analysis determines at least one of an orientation of the object, a distance of the object relative to the device, a movement direction of the object, or a combination thereof.
16. The non-transitory computer-readable medium of claim 13, in which the program code to estimate the geodesic distance value further comprises: program code to determine a first feature map based on an appearance of the object; program code to determine a second feature map based on an appearance of the 3D model; and program code to estimate the geodesic distance value based on the first feature map and the second feature map.
17. The non-transitory computer-readable medium of claim 13, in which the 3D model is textureless and the object is textured.
18. The non-transitory computer-readable medium of claim 13, in which the pose parameters comprise at least one of an azimuth, an elevation, an in-plane rotation, a camera distance, a principle offset, a focal length, a viewport, or a combination thereof.
19. An apparatus, comprising: means for detecting an object from a two-dimensional (2D) image; means for estimating a geodesic distance value between the object from the 2D image and a plurality of discretized poses of a three-dimensional (3D) model of the object; means for selecting a discretized pose from the plurality of discretized poses of the 3D model corresponding to a smallest geodesic distance value of the estimated geodesic distance values between the object from the 2D image and the plurality of discretized poses of the 3D model, such that the selected discretized pose of the 3D model aligns with the object in the 2D image; and means for propagating pose parameters of the selected discretized pose of the 3D model to the object.
20. The apparatus of claim 19, further comprising: means for performing 3D model analysis of the object based on the propagated pose parameters; and means for controlling movement of a device based on the 3D model analysis.
21. The apparatus of claim 20, in which the means for performing 3D model analysis comprises means for determining at least one of an orientation of the object, a distance of the object relative to the device, a movement direction of the object, or a combination thereof.
22. The apparatus of claim 19, in which the means for performing estimating the geodesic distance value comprises: means for determining a first feature map based on an appearance of the object; means for determining a second feature map based on an appearance of the 3D model; and means for estimating the geodesic distance value based on the first feature map and the second feature map.
23. The apparatus of claim 19, in which the 3D model is textureless and the object is textured.
24. The apparatus of claim 19, in which the pose parameters comprise at least one of an azimuth, an elevation, an in-plane rotation, a camera distance, a principle offset, a focal length, a viewport, or a combination thereof.
</claims>
</document>
